<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ramsey partitions and proximity data structures *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Manor</forename><surname>Mendel</surname></persName>
							<email>mendelma@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">The Open University of Israel</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Assaf</forename><surname>Naor</surname></persName>
							<email>anaor@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Ramsey partitions and proximity data structures *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">79070EFCBA5814EF4140502B57F20D53</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper addresses the non-linear isomorphic Dvoretzky theorem and the design of good approximate distance oracles for large distortion. We introduce and construct optimal Ramsey partitions, and use them to show that for every ε ∈ (0, 1), any n-point metric space has a subset of size n 1-ε which embeds into Hilbert space with distortion O(1/ε). This result is best possible and improves part of the metric Ramsey theorem of Bartal, Linial, Mendel and Naor <ref type="bibr" target="#b4">[5]</ref>, in addition to considerably simplifying its proof.</p><p>We use our new Ramsey partitions to design approximate distance oracles with a universal constant query time, closing a gap left open by Thorup and Zwick in <ref type="bibr" target="#b25">[26]</ref>. Namely, we show that for any n point metric space X, and k ≥ 1, there exists an O(k)-approximate distance oracle whose storage requirement is O n 1+1/k , and whose query time is a universal constant. We also discuss applications to various other geometric data structures, and the relation to well separated pair decompositions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Motivated by the search for a non-linear version of Dvoretzky's theorem, Bourgain, Figiel and Milman <ref type="bibr" target="#b7">[8]</ref> posed the following problem, which is known today as the metric Ramsey problem: Given a target distortion α &gt; 1 and an integer n, what is the largest k such that every npoint metric space has a subset of size k which embeds into Hilbert space with distortion α? (Recall that a metric space (X, d X ) is said to embed into Hilbert space with distortion α if there exists a mapping f : X → L 2 such that for every x, y ∈ X, we have d X (x, y) ≤ f (x) -f (y) 2 ≤ αd X (x, y)). This problem has since been investigated by several authors, motivated in part by the discovery of its applications to online algorithms -we refer to <ref type="bibr" target="#b4">[5]</ref> for a discussion of the history and applications of the metric Ramsey problem.</p><p>The most recent work on the metric Ramsey problem is due to Bartal, Linial, Mendel and Naor <ref type="bibr" target="#b4">[5]</ref>, who obtained various nearly optimal upper and lower bounds in several contexts. Among the results in <ref type="bibr" target="#b4">[5]</ref> is the following theorem which deals with the case of large distortion: For every ε ∈ (0, 1), any n-point metric space has a subset of size n 1-ε which embeds into an ultrametric with distortion O log(2/ε) ε (recall that an ultrametric (X, d X ) is a metric space satisfying for every x, y, z ∈ X, d X (x, y) ≤ max {d X (x, z), d X (y, z)}). Since ultrametrics embed isometrically into Hilbert space, this is indeed a metric Ramsey theorem. Moreover, it was shown in <ref type="bibr" target="#b4">[5]</ref> that this result is optimal up to the log(2/ε) factor, i.e. there exists arbitrarily large n-point metric spaces, every subset of which of size n 1-ε incurs distortion Ω(1/ε) in any embedding into Hilbert space. The main result of this paper closes this gap: Theorem 1.1. Let (X, d X ) be an n-point metric space and ε ∈ (0, 1). Then there exists a subset Y ⊆ X with |Y | ≥ n 1-ε such that (Y, d X ) is equivalent to an ultrametric with distortion at most 128 ε . In the four years that elapsed since our work on <ref type="bibr" target="#b4">[5]</ref> there has been remarkable development in the structure theory of finite metric spaces. In particular, the theory of random partitions of metric spaces has been considerably refined, and was shown to have numerous applications in mathematics and computer science (see for example <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b0">1]</ref> and the references therein). The starting point of the present paper was our attempt to revisit the metric Ramsey problem using random partitions. It turns out that this approach can indeed be used to resolve the metric Ramsey problem for large distortion, though it requires the introduction of a new kind of random partition, an improved "padding inequality" for known partitions, and a novel application of the random partition method in the setting of Ramsey problems. In Section 2 we introduce the notion of Ramsey partitions, and show how they can be used to address the metric Ramsey problem. We then proceed in Section 3 to construct optimal Ramsey partitions, yielding Theorem 1.1. Our construction is inspired in part by Bartal's probabilistic embedding into trees <ref type="bibr" target="#b3">[4]</ref>, and is based on a random partition due to Calinescu, Karloff and Rabani <ref type="bibr" target="#b8">[9]</ref>, with an improved analysis which strengthens the work of Fakcharoenphol, Rao and Talwar <ref type="bibr" target="#b14">[15]</ref>. In particular, our proof of Theorem 1.1 is self contained, and considerably simpler than the proof of the result from <ref type="bibr" target="#b4">[5]</ref> quoted above. Nevertheless, the construction of <ref type="bibr" target="#b4">[5]</ref> is deterministic, while our proof of Theorem 1.1 is probabilistic. Moreover, we do not see a simple way to use our new approach to simplify the proof of another main result of <ref type="bibr" target="#b4">[5]</ref>, namely the phase transition at distortion α = 2 (we refer to <ref type="bibr" target="#b4">[5]</ref> for details, as this result will not be used here).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Proximity data structures</head><p>The main algorithmic application of the metric Ramsey theorem in <ref type="bibr" target="#b4">[5]</ref> is to obtain the best known lower bounds on the competitive ratio of the randomized k-server problem. We refer to <ref type="bibr" target="#b4">[5]</ref> and the references therein for more information on this topic, as Theorem 1.1 does not yield improved k-server lower bounds. However, Ramsey partitions are useful to obtain positive results, and not only algorithmic lower bounds, which we now describe.</p><p>A finite metric space can be thought of as given by its n × n distance matrix. However, in many algorithmic contexts it is worthwhile to preprocess this data so that we store significantly less than n 2 numbers, and still be able to quickly find out approximately the distance between two query points. In other words, quoting Thorup and Zwick <ref type="bibr" target="#b25">[26]</ref>, "In most applications we are not really interested in all distances, we just want the ability to retrieve them quickly, if needed". The need for such "compact" representation of metrics also occurs naturally in mathematics; for example the methods developed in theroetical computer science (specifically <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b17">18]</ref>) are a key tool in the recent work of Fefferman and Klartag <ref type="bibr" target="#b15">[16]</ref> on the extension of C m functions defined on n points in R d to all of R d .</p><p>An influential compact representation of metrics used in theoretical computer science is the approximate distance oracle <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b17">18]</ref>. Stated formally, a (P, S, Q, D)approximate distance oracle on a finite metric space (X, d X ) is a data structure that takes expected time P to preprocess from the given distance matrix, takes space S to store, and given two query points x, y ∈ X, computes in time Q a number E(x, y) satisfying d X (x, y) ≤ E(x, y) ≤ D • d X (x, y). Thus the distance matrix itself is a (P = O(1), S = O(n 2 ), Q = O(1), D = 1)approximate distance oracle, but clearly the interest is in compact data structures in the sense that S = o(n 2 ). In what follows we will depart from the above somewhat cumbersome terminology, and simply discuss D-approximate distance oracles (emphasizing the distortion D), and state in words the values of the other relevant parameters.</p><p>An important paper of Thorup and Zwick <ref type="bibr" target="#b25">[26]</ref> constructs the best known approximate distance oracles. Namely, they show that for every integer k, every n-point metric space has a (2k -1)-approximate distance oracle which can be preprocessed in O n 2 time, requires storage O k • n 1+1/k , and has query time O(k). Moreover, it is shown in <ref type="bibr" target="#b25">[26]</ref> that this distortion/storage tradeoff is almost tight: A widely believed combinatorial conjecture of Erdős <ref type="bibr" target="#b13">[14]</ref> is shown in <ref type="bibr" target="#b25">[26]</ref> (see also <ref type="bibr" target="#b22">[23]</ref>) to imply that any data structure supporting approximate distance queries with distortion at most 2k -1 must be of size at least Ω n Another application of Ramsey partitions is to the construction of data structures for approximate ranking. This problem is motivated in part by web search and the analysis of social networks, in addition to being a natural extension of the ubiquitous approximate nearest neighbor search problem (see <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b11">12]</ref> and the references therein). In the approximate nearest neighbor search problem we are given c &gt; 1, a metric space (X, d X ), and a subset Y ⊆ X. The goal is to preprocess the data points Y so that given a query point x ∈ X \ Y we quickly return a point y ∈ Y which is a c-approximate nearest neighbor of x, i.e. d X (x, y) ≤ cd X (x, Y ). More generally, one might want to find the second closest point to x in Y , and so forth (this problem has been studied extensively in computational geometry, see for example <ref type="bibr" target="#b1">[2]</ref>). In other words, by ordering the points in X in increasing distance from x ∈ X we induce a proximity ranking of the points of X. Each point of X induces a different ranking of this type, and computing it efficiently is a natural generalization of the nearest neighbor problem. Using our new Ramsey partitions we design the following data structure for solving this problem approximately: Theorem 1.3. Fix k &gt; 1, and an n-point metric space (X, d X ). Then there exist a data structure which can be preprocessed in time O kn 2+1/k log n , uses only O kn 1+1/k storage space, and supports the following type of queries: Given x ∈ X, have "fast access" to a permutation of π (x) of X satisfying for every</p><formula xml:id="formula_0">1 ≤ i &lt; j ≤ n, d X x, π (x) (i) ≤ O(k)•d X x, π (x) (j)</formula><p>. By "fast access" to π (x) we mean that we can do the following:</p><p>1. Given a point x ∈ X, and i ∈ {1, . . . , n}, find π (x) (i) in constant time. 2. For any x, u ∈ X, compute j ∈ {1, . . . , n} such that π (x) (j) = u in constant time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Ramsey partitions and their equivalence to the metric Ramsey problem</head><p>Let (X, d X ) be a metric space. In what follows for x ∈ X and r ≥ 0 we let B X (x, r) = {y ∈ X : d X (x, y) ≤ r} be the closed ball of radius r centered at x. Given a partition P of X and x ∈ X we denote by P(x) the unique element of P containing x. For ∆ &gt; 0 we say that P is ∆-bounded if for every</p><formula xml:id="formula_1">C ∈ P, diam(C) ≤ ∆. A partition tree of X is a sequence of partitions {P k } ∞</formula><p>k=0 of X such that P 0 = {X}, for all k ≥ 0 the partition P k is 8 -k diam(X)-bounded, and P k+1 is a refinement of P k (the choice of 8 as the base of the exponent in this definition is convenient, but does not play a crucial role here). For β, γ &gt; 0 we shall say that a probability distribution Pr over partition trees</p><formula xml:id="formula_2">{P k } ∞ k=0 of X is completely β-padded with exponent γ if for every x ∈ X, Pr ∀ k ∈ N, B X x, β • 8 -k diam(X) ⊆ P k (x) ≥ |X| -γ .</formula><p>We shall call such probability distributions over partition trees Ramsey partitions.</p><p>The following lemma shows that the existence of good Ramsey partitions implies a solution to the metric Ramsey problem. In fact, it is possible to prove the converse direction, i.e. that the metric Ramsey theorem implies the existence of good Ramsey partitions (with appropriate dependence on the various parameters). We defer the proof of this implication to the full version of this paper, as it will not be used in this paper due to the fact that in Section 3 we will construct directly optimal Ramsey partitions. Lemma 2.1. Let (X, d X ) be an n-point metric space which admits a distribution over partition trees which is completely β-padded with exponent γ. Then there exists a subset Y ⊆ X with |Y | ≥ n 1-γ which is 8/β equivalent to an ultrametric.</p><p>Proof. We may assume without loss of generality that diam(X) = 1. Let {P k } ∞ k=0 be a distribution over partition trees of X which is completely β-padded with exponent γ. We define an ultrametric ρ on X as follows. For</p><p>x, y ∈ X let k be the largest integer for which P k (x) = P k (y), and set ρ(x, y) = 8 -k . It is straightforward to check that ρ is indeed an ultrametric. Consider the random subset Y ⊆ X given by</p><formula xml:id="formula_3">Y = x ∈ X : ∀ k ∈ N, B X x, β • 8 -k ⊆ P k (x) .</formula><p>Then by linearity of the expectation, E|Y | ≥ n 1-γ . We can therefore choose Y ⊆ X with |Y | ≥ n 1-γ such that for all x ∈ Y and all k ≥ 0 we have B X x, β • 8 -k ⊆ P k (x). Fix x, y ∈ X, and let k be the largest integer for which</p><formula xml:id="formula_4">P k (x) = P k (y). Then d X (x, y) ≤ diam(P k (x)) ≤ 8 -k = ρ(x, y). On the other hand, if x ∈ X and y ∈ Y then, since P k+1 (x) = P k+1 (y), the choice of Y implies that x / ∈ B X y, β • 8 -k-1 . Thus d X (x, y) &gt; β • 8 -k-1 = β 8 ρ(x, y).</formula><p>It follows that the metrics d X and ρ are equivalent on Y with distortion 8/β.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Constructing optimal Ramsey partitions</head><p>The following lemma gives improved bounds on the "padding probability" of a distribution over partitions which was discovered by Calinescu, Karloff and Rabani in <ref type="bibr" target="#b8">[9]</ref>. Lemma 3.1. Let (X, d X ) be a finite metric space. Then for every ∆ &gt; 0 there exists a distribution Pr over ∆-bounded partitions of X such that for every 0 &lt; t ≤ ∆/8 and every x ∈ X,</p><formula xml:id="formula_5">Pr [B X (x, t) ⊆ P(x)] ≥ |B X (x, ∆/8)| |B X (x, ∆)| 16t ∆ .<label>(1)</label></formula><p>Remark 3.1. The distribution over partitions used in the proof of Lemma 3.1 is precisely the distribution introduced by Calinescu, Karloff and Rabani in <ref type="bibr" target="#b8">[9]</ref>. In <ref type="bibr" target="#b14">[15]</ref> Fakcharoenphol, Rao and Talwar proved the following estimate for the same distribution</p><formula xml:id="formula_6">Pr [B X (x, t) ⊆ P(x)] ≥ 1 -O t ∆ log |B X (x, ∆)| |B X (x, ∆/8)| .<label>(2)</label></formula><p>Clearly the bound (1) is stronger than the bound (2), and in particular it yields a non-trivial estimate even for large values of t for which the lower bound in (2) is negative. This improvement is crucial for our proof of Theorem 1.1. The use of the "local ratio of balls" (or "local growth") in the estimate (2) of Fakcharoenphol, Rao and Talwar was a fundamental breakthrough, which, apart from their striking application in <ref type="bibr" target="#b14">[15]</ref>, has since found several applications in mathematics and computer science (see <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b0">1]</ref>).</p><p>Proof of Lemma 3.1. Write X = {x 1 , . . . , x n }. Let R be chosen uniformly at random from the interval [∆/4, ∆/2], and let π be a permutation of {1, . . . , n} chosen uniformly at random from all such permutations (here, and in what follows, R and π are independent). Define C 1 :=B X x π(1) , R and inductively for 2 ≤ j ≤ n, C j :=B X x π(j) , R \ j-1 i=1 C i . Finally we let P:={C 1 , . . . , C n } \ {∅}. Clearly P is a (random) ∆bounded partition on X.</p><p>For every r ∈ [∆/4, ∆/2],</p><formula xml:id="formula_7">Pr [B X (x, t) ⊆ P(x)|R = r] ≥ |B X (x, r -t)| |B X (x, r + t)| .<label>(3)</label></formula><p>Indeed, if R = r, then the triangle inequality implies that if in the random order induced by the partition π on the points of the ball B X (x, r+t) the minimal element is from the ball B X (x, r -t), then B X (x, t) ⊆ P(x) (See Figure <ref type="figure" target="#fig_0">1</ref>). This event happens with probability |B X (x,r-t)| |B X (x,r+t)| , implying (3). Write ∆ 8t = k, and assume first that k is a positive integer. Then</p><formula xml:id="formula_8">Pr [B X (x, t) ⊆ P(x)] ≥ 4 ∆ ∆/2 ∆/4 |B X (x, r -t)| |B X (x, r + t)| dr<label>(4)</label></formula><formula xml:id="formula_9">= 4 ∆ k-1 j=0 ∆ 4 +2(j+1)t ∆ 4 +2jt |B X (x, r -t)| |B X (x, r + t)| dr = 4 ∆ 2t 0 k-1 j=0 B X x, ∆ 4 + 2jt + s -t B X x, ∆ 4 + 2jt + s + t ds ≥ 4k ∆ 2t 0 k-1 j=0 B X x, ∆ 4 + 2jt + s -t B X x, ∆ 4 + 2jt + s + t 1 k ds (5) = 4k ∆ 2t 0 B X x, ∆ 4 + s -t B X x, ∆ 4 + 2t (k -1) + s + t 1 k ds ≥ 8kt ∆ B X x, ∆ 4 -t B X x, ∆ 4 + 2kt + t 1 k = B X x, ∆ 4 -t B X x, ∆ 2 + t 8t ∆</formula><p>, where in (4) we used (3), and in (5) we used the arithmetic mean/geometric mean inequality. Only minor changes (as well as a loss of a factor of 2 in the exponent) are required to extend the above analysis to the case when k is not an integer (see the full version of this paper).</p><p>The following theorem, in conjunction with Lemma 2.1, implies Theorem 1.1. Theorem 3.2. For every α &gt; 1, every finite metric space (X, d X ) admits a completely 1/α padded random partition tree with exponent 16/α.  <ref type="bibr" target="#b2">(3)</ref>. clusters that are induced by points which lie outside the ball BX (x, r + t), such as c, cannot touch the ball BX (x, t). On the other hand, if a point from BX (x, r -t), such as a, appeared first in the random order among the points in BX (x, r + t) then its cluster will "swallow" the ball BX (x, t). Only points in the shaded region can split the ball BX (x, t).</p><p>Proof. Fix α &gt; 1. Without loss of generality we may assume that diam(X) = 1. We construct a partition tree {E k } ∞ k=0 of X as follows. Set E 0 = {X}. Having defined E k we let P k+1 be a partition as in Lemma 3.1 with ∆ = 8 -k and t = ∆/α (the random partition P k+1 is chosen independently of the random partitions P 1 , . . . , P k ). Define E k+1 to be the common refinement of E k and P k+1 , i.e. E k+1 :={C ∩ C : C ∈ E k , C ∈ P k+1 }. The construction implies that for every x ∈ X and every k ≥ 0 we have E k+1 (x) = E k (x) ∩ P k+1 (x). Thus one proves inductively that</p><formula xml:id="formula_10">∀ k ∈ N, B X x, 8 -k α ⊆ P k (x) =⇒ ∀ k ∈ N, B X x, 8 -k α ⊆ E k (x).</formula><p>From Lemma 3.1 and the independence of</p><formula xml:id="formula_11">{P k } ∞ k=1 it fol- lows that Pr ∀ k ∈ N, B X x, 8 -k α ⊆ E k (x) ≥ Pr ∀ k ∈ N, B X x, 8 -k α ⊆ P k (x) ≥ ∞ k=1 |B X (x, 8 -k-1 )| |B X (x, 8 -k ) 16 α = |B X (x, 1/8)| -16 α ≥ |X| -16 α .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Applications to proximity data structures</head><p>In this section we show how Theorem 3.2 can be applied to the design of various proximity data structures, which are listed below. Before doing so we shall recall some standard facts about tree representations of ultrametrics, all of which can be found in the discussion in <ref type="bibr" target="#b4">[5]</ref>. Any finite ultrametric (X, ρ) can be represented by a rooted tree T = (V, E) with labels ∆ : V → (0, ∞), whose leaves are X, and such that if u, v ∈ V and v is a child of u then ∆(v) ≤ ∆(u). Given x, y ∈ X we then have ρ(x, y) = ∆ (lca(x, y)), where lca(x, y) is the least common ancestor of x and y in T . The labelled tree described above is called an HST (hierarchically well separated tree). Lemma 4.1 (Extending ultrametrics). Let (X, d X ) be a finite metric space, and α ≥ 1. Fix ∅ = Y ⊆ X, and assume that there exits an ultrametric ρ on Y such that for every x, y ∈ Y , d X (x, y) ≤ ρ(x, y) ≤ αd X (x, y). Then there exists an ultrametric ρ defined on all of X such that for every x, y ∈ X we have d X (x, y) ≤ ρ(x, y), and if x ∈ X and y ∈ Y then ρ(x, y) ≤ 6αd X (x, y).</p><p>Proof. Let T = (V, E) be the HST representation of ρ, with labels ∆ : V → (0, ∞). In other words, the leaves of T are Y , and for every x, y ∈ Y we have ∆(lca(x, y)) = ρ(x, y). It will be convenient to augment T by adding an incoming edge to the root with ∆(parent(root)) = ∞. This clearly does not change the induced metric on Y . For every x ∈ X \ Y let y ∈ Y be its closest point in Y , i.e. d X (x, y) = d X (x, Y ). Let u be the least ancestor of y for which ∆(u) ≥ d X (x, y) (such a u must exist because we added the incoming edge to the root). Let v be the child of u along the path connecting u and y. We add a vertex w on the edge {u, v} whose label is d X (x, y), and connect x to T as a child of w. The resulting tree is clearly still an HST. Repeating this procedure for every x ∈ X \ Y we obtain an HST T whose leaves are X. Denote the labels on T by ∆.</p><p>Fix x, y ∈ X, and let x , y ∈ Y the nearest neighbors of x, y (respectively) used in the above construction. Then</p><formula xml:id="formula_12">∆ lca e T (x, y) = max ∆ lca e T (x, x ) , ∆ lca e T (y, y ) , ∆ lca e T (x , y ) ≥ max {d X (x, x ), d X (y, y ), d X (x , y )} ≥ d X (x, x ) + d X (y, y ) + d X (x , y ) 3 ≥ 1 3 d X (x, y).<label>(6)</label></formula><p>In the reverse direction, if x ∈ X and y ∈ Y let x ∈ Y be the closest point in Y to x used in the construction of T . Then d X (x , y) ≤ d X (x , x) + d X (x, y) ≤ 2d X (x, y). If lca e T (y, x ) is an ancestor of lca e T (x, x ) then</p><formula xml:id="formula_13">∆ lca e T (x, y) = ∆ lca e T (x , y) = ρ(x , y) ≤ α • d X (x , y) ≤ 2α • d X (x, y). (7)</formula><p>If, on the other hand, lca e T (y, x ) is a descendant of lca e T (x, x ) then</p><formula xml:id="formula_14">∆ lca e T (x, y) = ∆ lca e T (x, x ) = d X (x, x ) ≤ d X (x, y). (<label>8</label></formula><formula xml:id="formula_15">)</formula><p>Scaling the labels of T by a factor of 3, the required result is a combination of ( <ref type="formula" target="#formula_12">6</ref>), ( <ref type="formula">7</ref>) and ( <ref type="formula" target="#formula_14">8</ref>).</p><p>The following lemma is a structural result on the existence of a certain distribution over decreasing chains of subsets of a finite metric space. In what follows we shall call such a distribution a stochastic Ramsey chain. A schematic description of this notion, and the way it is used in the ensuing arguments, is presented in Figure <ref type="figure">2</ref> below. Lemma 4.2 (Stochastic Ramsey chains). Let (X, d X ) be an n-point metric space and k ≥ 1. Then there exists a distribution over decreasing sequences of subsets</p><formula xml:id="formula_16">X = X 0 X 1 X 2 • • • X s = ∅ (s itself is a random variable), such that for all p &gt; -1/k, E s-1 j=0 |X j | p ≤ max k 1+pk , 1 • n p+1/k , (<label>9</label></formula><formula xml:id="formula_17">)</formula><p>and such that for each j ∈ {1, . . . , s} there exists an ultrametric ρ j on X satisfying for every x, y ∈ X, ρ j (x, y) ≥ d X (x, y), and if x ∈ X and y ∈</p><formula xml:id="formula_18">X j-1 \ X j then ρ j (x, y) ≤ O(k) • d X (x, y). Remark 4.1.</formula><p>In what follows we will only use the cases p ∈ {0, 1, 2} in Lemma 4.2. Observe that for p = 0, (9) is simply the estimate Es ≤ kn 1/k . Lemma 4.2 is proven by inductively applying Theorem 3.2 and Lemma 2.1. We leave the complete proof to the full version, since we have the following easy observation. Before passing to the description of our new data structures, we need to say a few words about the algorithmic implementation of Lemma 4.2 (this will be the central preprocessing step in our constructions). The computational model we use is the "Unit cost floating-point word RAM model", discussed in Section 2.2 of <ref type="bibr" target="#b17">[18]</ref>. The natural implementation of the Calinescu-Karloff-Rabani (CKR) random partition used in the proof of Lemma 3.1 takes O n 2 time. Denote by Φ = Φ(X) the aspect ratio of X, i.e. the diameter of X divided by the minimal positive distance in X. The construction of the distribution over partition trees in the proof of Theorem 3.2 requires performing O(log Φ) such decompositions. This results in O n 2 log Φ preprocessing time to sample one partition tree from the distribution. Using a standard technique we dispense with the dependence on the aspect ratio and obtain that the expected preprocessing time of one partition tree is O n 2 log n . The full version conrains more details.</p><p>The Ramsey chain in Lemma 4.2 will be used in two different ways in the ensuing constructions. For our approximate distance oracle data structure we will just need that the ultrametric ρ j is defined on X j-1 (and not all of X). Thus, by the above argument, and Lemma 4.2, the expected preprocessing time in this case is</p><formula xml:id="formula_19">O E s-1 j=1 |X j | 2 log |X j | = O(n 2+1/k log n) and the expected storage space is O E s-1 j=1 |X j | = O(n 1+1/k ).</formula><p>For the purpose of our approximate ranking data structure we will really need the metrics ρ j to be defined on all of X. Thus in this case the expected preprocessing time will be O n 2 log n • Es = O kn 2+1/k log n , and the expected storage space is O(n • Es) = O(kn 1+1/k ).</p><p>1) Approximate distance oracles. Our improved approximate distance oracle is contained in Theorem 1.2, which we now prove.</p><p>Proof of Theorem 1.2. We shall use the notation in the statement of Lemma 4.2. Let T j = (V j , E j ) and ∆ j : V j → (0, ∞) be the HST representation of the ultrametric ρ j (which was actually constructed explicitly in the proofs of Lemma 2.1 and Lemma 4.2). The usefulness of the tree representation stems from the fact that it is very easy to handle algorithmically. In particular there exists a simple scheme that takes a tree and preprocesses it in linear time so that it is possible to compute the least common ancestor of two given nodes in constant time (see <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b5">6]</ref>). Hence, we can preprocess any HST so that the distance between any two points can be computed in O(1) time.</p><p>For every point x ∈ X let i x be the largest index for which x ∈ X ix-1 . Thus, in particular, x ∈ Y ix . We further maintain for every x ∈ X a vector (in the sense of data-structures) vec x of length i x (with O(1) time direct access), such that for i ∈ {0, . . . , i x -1}, vec x [i] is a pointer to the leaf representing x in T i . Now, given a query x, y ∈ X assume without loss of generality that i x ≤ i y . It follows that x, y ∈ X ix-1 . We locate the leaves x = vec x [i x ], and ŷ = vec y [i x ] in T ix , and then compute ∆(lca (x, ŷ)) to obtain an O(k) approximation to d X (x, y). Observe that the above data structure only requires ρ j to be defined on X j-1 (and satisfying the conclusion of Lemma 4.2 for x, y ∈ X j-1 ). The expected preprocessing time is O(n 2+1/k log n). The size of the above data structure is</p><formula xml:id="formula_20">O s j=0 |X j | , which is in expectation O(n 1+1/k ).</formula><p>2) Approximate ranking. Before passing to our αapproximate ranking data structure (Theorem 1.3) we recall the setting of the problem. Thinking of X as a metric on {1, . . . , n}, and fixing α &gt; 1, the goal here is to associate with every x ∈ X a permutation π (x) of {1, . . . , n}</p><formula xml:id="formula_21">such that d X x, π (x) (i) ≤ α • d X x, π (x) (j) for every 1 ≤ i ≤ j ≤ n.</formula><p>This relaxation of the exact proximity ranking induced by the metric d X allows us to gain storage efficiency, while enabling fast access to this data. By fast access we mean that we can preform the following tasks:</p><p>1. Given an element x ∈ X, and i ∈ {1, . . . , n}, find π (x) (i) in O(1) time. 2. Given an element x ∈ X and y ∈ X, find number i ∈ {1, . . . , n}, such that π (x) (i) = y, in O(1) time. Before passing to the proof of Theorem 1.3 we require the following lemma. Lemma 4.3. Let T = (V, E) be a rooted tree with n leaves. For v ∈ V , let L T (v) be the set of leaves in the subtree rooted at v, and denote T (v) = |L T (v)|. Then there exists a data structure, that we call Size-Ancestor, which can be constructed in time O(n), and answers in time O(1) the following query: Given ∈ N and a leaf x ∈ V , find an ancestor u of x such that T (u) &lt; ≤ (parent(u)). Here we use the convention (parent(root)) = ∞.</p><p>To the best of our knowledge, the data structure described in Lemma 4.3 has not been previously studied. We therefore include a proof of Lemma 4.3 in Appendix A, and proceed at this point to conclude the proof of Theorem 1.3.</p><p>Proof of Theorem 1.3. We shall use the notation in the statement of Lemma 4.2. Let T j = (V j , E j ) and ∆ j : V j → [0, ∞) be the HST representation of the ultrametric ρ j . We may assume without loss of generality that each of these trees is binary and does not contain a vertex which has only one child. Before presenting the actual implementation of the data structure, let us explicitly describe the permutation π (x) that the data structure will use. For every internal vertex v ∈ V j assign arbitrarily the value 0 to one of its children, and the value 1 to the other. This induces a unique (lexicographical) order on the leaves of T j . Next, fix x ∈ X and i x such that x ∈ Y ix . The permutation π (x) is defined as follows. Starting from the leaf x in T ix , we scan the path from x to the root of T ix . On the way, when we reach a vertex u from its child v, let w denote the sibling of v, i.e. the T 1</p><formula xml:id="formula_22">T 2 T 3 T 4 T 1 T 2 T 3 T 4 Figure 2.</formula><p>A schematic description of Ramsey chains and the way they are used to construct approximate distance oracles and approximate ranking data structures. Ramsey chains are obtained by iteratively applying Theorem 3.2 and Lemma 2.1 to find a decreasing chain of subsets X = X0 X1 X2 • • • Xs = ∅ such that Xj \ Xj+1 can be approximated by a tree metric Tj+1. The tree Tj+1 is, in a sense, a "distance estimator" for Xj \ Xj+1. These trees form an array which is an approximate distance oracle. In the case of approximate ranking we also need to extend the tree Tj+1 to a tree on the entire space X using Lemma 4.1. The nodes that were added to these trees are illustrated by empty circles. other child of u. We next output all the leafs which are descendants of w according to the total order described above. Continuing in this manner until we reach the root of T ix we obtain a permutation π (x) of X.</p><p>We claim that the permutation π (x) constructed above is an O(k)-approximation to the proximity ranking induced by x. Indeed, fix y, z ∈ X such that Ck • d X (x, y) &lt; d X (x, z), where C is a large enough absolute constant. We claim that z will appear after y in the order induced by π (x) . This is true since the distances from x are preserved up to a factor of O(k) in the ultrametric T ix . Thus for large enough C we are guaranteed that d Ti x (x, y) &lt; d Ti x (x, z), and therefore lca Ti x (x, z) is a proper ancestor of lca Ti x (x, y). Hence in the order just describe above, y will be scanned before z.</p><p>We now turn to the description of the actual data structure, which is an enhancement of the data structure constructed in the proof of Theorem 1.2. As in the proof of Theorem 1.2 our data structure will consist of a "vector of the trees T j ", where we maintain for each x ∈ X a pointer to the leaf representing x in each T j . The remaining description of our data structure will deal with each tree T j separately. First of all, with each vertex v ∈ T j we also store the number of leaves which are the descendants of v, i.e. |L Tj (v)| (note that all these numbers can be computed in O(n) time using, say, depth-first search). With each leaf of T j we also store its index in the order described above. There is a reverse indexing by a vector for each tree T j that allows, given an index, to find the corresponding leaf of T j in O(1) time. Each internal vertex contains a pointer to its leftmost (smallest) and rightmost (largest) descendant leaves. This data structure can be clearly constructed in O(n) time using, e.g., depth-first transversal of the tree. We now give details on how to answer the required queries using the "ammunition" we have listed above.</p><p>1. Using Lemma 4.3, find an ancestor v of x such that</p><formula xml:id="formula_23">Tj (v) &lt; i ≤ Tj (parent(v)) in O(1) time. Let u = parent<label>(</label></formula><p>v) (note that v can not be the root). Let w be the sibling of v (i.e. the other child of u). Next we pick the leaf numbered i -Tj (v) + left(w) -1, where left(w) is the index to the leftmost descendant of w. 2. Find u = lca(x, y) (in O(1) time, using <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b5">6]</ref>). Let v and w be the children of u, which are ancestors of x and y, respectively. Return Tj (v) + ind(y)left(w), where ind(y) is the index of y in the total order of the leaves of the tree. This concludes the construction of our approximate ranking data structure. Because we need to have the ultrametric ρ j defined on all of X, the preprocessing time is O kn 2+1/k log n and the storage size is O kn 1+1/k , as required.</p><p>3) Computing the Lipschitz constant. In the full version of this paper we describe a data structure for estimating the Lipschitz constant of a given mapping between metric spaces. Formally we prove: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Concluding Remarks</head><p>An s-well separated pair decomposition (WSPD) of an n-point metric space (X, d X ) is a collection of pair of subsets {(A i , B i )} M i=1 , A i , B i ⊂ X, such that 1. ∀x, y ∈ X if x = y then (x, y) ∈ M i=1 (A i × B i ). 2. For all i = j, (A i × B i ) ∩ (A j × B j ) = ∅.</p><p>3. For all i ∈ {1, . . . , M },</p><formula xml:id="formula_24">d X (A i , B i ) ≥ s • max{diam(A i ), diam(B i )}.</formula><p>The notion of s-WSPD was first defined for Euclidean spaces in an influential paper of Callahan and Kosaraju <ref type="bibr" target="#b10">[11]</ref>, where it was shown that for n-point subsets of a fixed dimensional Euclidean space there exists such a collection of size O(n) that can be constructed in O(n log n) time. Subsequently, this concept has been used in many geometric algorithms (e.g. <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b9">10]</ref>), and is today considered to be a basic tool in computational geometry. Recently the definition and the efficient construction of WSPD were generalized to the more abstract setting of doubling metrics <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b17">18]</ref>. These papers have further demonstrated the usefulness of this tool.</p><p>It would be clearly desirable to have a notion similar to WSPD in general metrics. However, as formulated above, no non-trivial WSPD is possible in high dimensional spaces, since any 2-WSPD of an n-point equilateral space must be of size Ω(n 2 ). The present paper suggests that Ramsey partitions might be a partial replacement of this notion which works for arbitrary metric spaces. Indeed, among the applications of WSPD in fixed dimensional metrics are approximate ranking (though this application does not seem to have appeared in print -it was pointed out to us by Sariel Har-Peled), approximate distance oracles <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>, spanners <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b17">18]</ref>, and computation of the Lipschitz constant <ref type="bibr" target="#b17">[18]</ref>. These applications have been obtained for general metrics using Ramsey partitions in the present paper (spanners were not discussed here since our approach does not seem to beat previously known constructions). We believe that this direction deserves further scrutiny, as there are more applications of WSPD which might be transferable to general metrics using Ramsey partitions.</p><p>The procedure for constructing stochastic Ramsey chains presented in Section 4 takes O * (n 2+1/k ). It would be desirable to improve that to O * (n 2 ). Construction time of proximity data structures for graph metrics is a well studied topic, see for example <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b23">24]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1.A schematic description of the lower bound in<ref type="bibr" target="#b2">(3)</ref>. clusters that are induced by points which lie outside the ball BX (x, r + t), such as c, cannot touch the ball BX (x, t). On the other hand, if a point from BX (x, r -t), such as a, appeared first in the random order among the points in BX (x, r + t) then its cluster will "swallow" the ball BX (x, t). Only points in the shaded region can split the ball BX (x, t).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Observation 4 . 2 .</head><label>42</label><figDesc>If one does not mind losing a factor of O(log n) in the construction time and storage of the Ramsey chain, then an alternative to Lemma 4.2 is to randomly and independently sample O n 1/k log n ultrametrics from the Ramsey partitions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Theorem 4 . 4 .</head><label>44</label><figDesc>Given k ≥ 1, any n-point metric space (X, d X ) can be preprocessed in time O n 2+1/k log n , yielding a data structure requiring storage O n 1+1/k which can answer in O n 1+1/k time the following query: Given a metric space (Y, d Y ) and a mapping f : X → Y , compute a value A ≥ 0, such that f Lip ≥ A ≥ f Lip /O(k).</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In fact, for distortions larger than Ω(log n/ log log n) our storage space is slightly better.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. We are grateful to Sariel Har-Peled for letting us use here his insights on the approximate ranking problem. We also thank Yair Bartal, and Martin Farach-Colton for helpful comments.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The Size-Ancestor data structure</head><p>In this appendix we prove Lemma 4.3. Without loss of generality we assume that the tree T does not contain vertices with only one child. Indeed, such vertices will never be returned as an answer for a query, and thus can be eliminated in O(n) time in a preprocessing step.</p><p>Our data structure is composed in a modular way of two different data structures, the first of which is described in the following lemma, while the second is discussed in the proof of Lemma 4.3 that will follow.</p><p>Lemma A.1. Fix m ∈ N, and let T be as in Lemma 4. <ref type="bibr" target="#b2">3</ref>. Then there exists a data structure which can be preprocessed in time O n + n log n m , and answers in time O(1) the following query: Given ∈ N and a leaf x ∈ V , find an ancestor u of x such that T (u) &lt; m ≤ (parent(u)).</p><p>Here we use the convention (parent(root)) = ∞.</p><p>Proof. Denote by X the set of leaves of T . For every internal vertex v ∈ V , order its children non-increasingly according to the number of leaves in the subtrees rooted at them. Such a choice of labels induces a unique total order on X (the lexicographic order). Denote this order by and let f : {1, . . . , n} → X be the unique increasing map in the total order . For every v ∈ V , f -1 (L T (v)) is an interval of integers. Moreover, the set of intervals f -1 (L T (v)) : v ∈ V forms a laminar set, i.e., for every pair of intervals in this set either one is contained in the other, or they are disjoint. For ev-</p><p>and there is no descendant of v satisfying these two conditions. Since at most two disjoint intervals of length at least im can intersect a given interval of length im, we see that for all i, j, |F i (j)| ≤ 2.</p><p>Claim A.2. Let x ∈ X be a leaf of T , and ∈ N. Let u ∈ V be the least ancestor of x for which</p><p>m then since we are assuming that that T (u) ≥ m, and</p><p>. Thus u = lca(x, v), by the fact that any ancestor w of v satisfies T (w) ≥ T (v) ≥ m, and the minimality of u.</p><p>The preprocessing of the data structure begins with ordering the children of vertices non-increasingly according to the number of leaves in their subtrees. The following algorithm achieves it in linear time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SORT-CHILDREN(u)</head><p>Compute { T (u)} u∈V using depth first search. Sort V non-increasingly according to T (•). Let (v i ) i be the set V sorted as above. Initialize ∀u ∈ V , the list ChildrenSortedList u = ∅.</p><p>Computing f , and the intervals {I u } u∈V is now done by a depth first search of T that respects the above order of the children.</p><p>We next compute {F i (j) : i ∈ {1, . . . , n/m }, j ∈ {1, . . . , n/(im) } using the following algorithm:</p><p>Here is an informal explanation of the correctness of this algorithm. The only relevant sets F i (•) which will contain the vertex u ∈ V are those in the range i</p><p>Above this range I u does not meet the size constraint, and below this range any F i (j) which intersects I u must also intersect one of the children of u, which also satisfies the size constraint, in which case one of the descendants of u will be in F i (j). In the aforementioned range, we add u to F i (j) only for j such that the interval [(j -1)im + 1, jim] does not intersect one of the children of u in a set of size larger than im. Here we use the fact that the intervals of the children are sorted in non-increasing order according to their size. Regarding running time, this reasoning implies that each vertex of T , and each entry in F i (j), is accessed by this algorithm only a constant number of times, and each access involves only constant number of computation steps. So the running time is</p><p>We conclude with the query procedure. Given a query x ∈ X and ∈ N, access</p><p>, check whether lca(x, v) is the required vertex (we are thus using here also the data structure for computing the lca of <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b5">6]</ref>. Observe also that since |F i (j)| ≤ 2, we only have a constant number of checks to do). By Claim A.2 this will yield the required result.</p><p>By setting m = 1 in Lemma A.1, we obtain a data structure for the Size-Ancestor problem with O(1) query time, but O(n log n) preprocessing time. To improve upon this, we set m = Θ(log n) in Lemma A.1, and deal with the resulting gaps by enumerating all the possible ways in which the remaining m -1 leaves can be added to the tree. Exact details are given below.</p><p>We next construct in memory a vector enum of size 2 m , where enum[#A] is a vector of size m, with integer index in the range {1, . . . , m}, such that enum</p><p>For each vertex u we compute and store:</p><p>• depth(u), the edge's distance from the root to u.</p><p>• T (u), the number of leaves in the subtree rooted at u.</p><p>• The number #A u , where</p><p>. . , m -1} : u has an ancestor with exactly T (u) + k descendant leaves .</p><p>We also apply the level ancestor data-structure, that after O(n) preprocessing time, answers in constant time queries of the form: Given a vertex u and an integer d, find an ancestor of u at depth d (if it exists) (such a data structure is constructed in <ref type="bibr" target="#b6">[7]</ref>). Lastly, we use the data structure from Lemma A.1 With all this machinary in place, a query for the least ancestor of a leaf x having at least leaves is answered in constant time as follows. First compute q = /m . Apply a query to the data structure of Lemma A.1, with x and q, and obtain u, the least ancestor of x such that T (u) ≥ qm. If T (u) ≥ then u is the least ancestor with leaves, so the data-structure returns u. Otherwise, T (u) &lt; , and let a = enum[#A u ][ -T (u)]. Note that depth(u) -a is the depth of the least ancestor of u having at least leaves, thus the query uses the level ancestor data-structure to return this ancestor. Clearly the whole query takes a constant time.</p><p>It remains to argue that the data structure can be preprocessed in linear time. We already argued about most parts of the data structure, and T (u) and depth(u) are easy to compute in linear time. Thus we are left with computing #A u for each vertex u. This is done using a top-down scan of the tree (e.g., depth first search). The root is assigned with 1.</p><p>For each non-root vertex u, whose parent is v, #A u is assigned 1 if T (v) ≥ T (u) + m, and #A v • 2 T (v)-T (u) + 1 (mod 2 m ) otherwise. It is clear that this indeed computes #A u . The relevant exponents are computed in advance and stored in a lookup table.</p><p>Remark A.1. This data structure can be modified in a straightforward way to answer queries to the least ancestor having at least a given number of vertices in its subtree. It is also easy to extend it to queries to non-leaf vertices.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Euclidean distortion and the sparsest cut</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC &apos;05: Proceedings of the thirtyseventh annual ACM symposium on Theory of computing</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="553" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An optimal algorithm for approximate nearest neighbor searching</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Mount</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Netanyahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Silverman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="891" to="923" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Nearlinear time construction of sparse neighborhood covers</title>
		<author>
			<persName><forename type="first">B</forename><surname>Awerbuch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cowen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Peleg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="263" to="277" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Probabilistic approximations of metric space and its algorithmic application</title>
		<author>
			<persName><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">37th Annual Symposium on Foundations of Computer Science</title>
		<imprint>
			<date type="published" when="1996-10">Oct. 1996</date>
			<biblScope unit="page" from="183" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On metric Ramsey type phenomena</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bartal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Linial</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mendel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. of Math</title>
		<imprint>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="643" to="709" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The lca problem revisited</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Farach-Colton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th Latin Amer. Symp. on Theor. Info</title>
		<meeting>4th Latin Amer. Symp. on Theor. Info</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="88" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The level ancestor problem simplified</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Farach-Colton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">321</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="12" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On Hilbertian subsets of finite metric spaces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bourgain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Figiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Milman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Israel J. Math</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="147" to="152" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Approximation algorithms for the 0-extension problem</title>
		<author>
			<persName><forename type="first">G</forename><surname>Calinescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Karloff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rabani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="358" to="372" />
			<date type="published" when="2004">2004/05</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dealing with higher dimensions: the wellseparated pair decomposition and its applications</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Callahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Sci</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<pubPlace>Baltimore, Maryland</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Johns Hopkins University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A decomposition of multidimensional point sets with applications to k-nearestneighbors and n-body potential fields</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Callahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kosaraju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="90" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Nearest-Neighbor Searching and Metric Space Dimensions</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Clarkson</surname></persName>
		</author>
		<ptr target="http://cm.bell-labs.com/who/clarkson/nn_survey/p.pdf" />
	</analytic>
	<monogr>
		<title level="m">Nearest-Neighbor Methods for Learning and Vision: Theory and Practice</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast algorithms for constructing t-spanners and paths with stretch t</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="210" to="236" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Extremal problems in graph theory</title>
		<author>
			<persName><forename type="first">P</forename><surname>Erdős</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory of Graphs and its Applications (Proc. Sympos. Smolenice, 1963)</title>
		<meeting><address><addrLine>Prague</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1964">1964</date>
			<biblScope unit="page" from="29" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A tight bound on approximating arbitrary metrics by tree metrics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fakcharoenphol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. System Sci</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="485" to="497" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Fitting C m smooth functions to data I</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fefferman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Klartag</surname></persName>
		</author>
		<ptr target="http://www.math.princeton.edu/facultypapers/Fefferman/FittingData_Part_I.pdf" />
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Approximate distance oracles for geometric graphs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gudmundsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Levcopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Smid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SODA &apos;02: Proceedings of the thirteenth annual ACM-SIAM symposium on Discrete algorithms</title>
		<title level="s">Society for Industrial and Applied Mathematics</title>
		<meeting><address><addrLine>Philadelphia, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="828" to="837" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast construction of nets in low dimensional metrics, and their applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Har-Peled</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mendel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="page" from="1143" to="1184" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fast algorithms for finding nearest common ancestors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Harel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Tarjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="338" to="355" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Nearest neighbors in high-dimensional spaces</title>
		<author>
			<persName><forename type="first">P</forename><surname>Indyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of discrete and computational geometry</title>
		<meeting><address><addrLine>Boca Raton, FL, USA</addrLine></address></meeting>
		<imprint>
			<publisher>CRC Press, Inc</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="877" to="892" />
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Measured descent: A new embedding method for finite metrics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Krauthgamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mendel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geom. Funct. Anal</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="839" to="858" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Extending Lipschitz functions via random metric partitions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Invent. Math</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="95" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On the distortion required for embedding finite metric space into normed spaces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Matoušek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Israel J. Math</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="333" to="344" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deterministic constructions of approximate distance oracles and spanners</title>
		<author>
			<persName><forename type="first">L</forename><surname>Roditty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Thorup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Zwick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automata, languages and programming</title>
		<title level="s">Lecture Notes in Comput. Sci.</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3580</biblScope>
			<biblScope unit="page" from="261" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Bypassing the embedding: algorithms for low dimensional metrics</title>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC &apos;04: Proceedings of the thirty-sixth annual ACM symposium on Theory of computing</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="281" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Approximate distance oracles</title>
		<author>
			<persName><forename type="first">M</forename><surname>Thorup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Zwick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An O(n log n) algorithm for the all-nearestneighbors problem</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Vaidya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Comput. Geom</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="101" to="115" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Exact and approximate distances in graphs-a survey</title>
		<author>
			<persName><forename type="first">U</forename><surname>Zwick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Algorithms-ESA 2001 ( Århus)</title>
		<title level="s">Lecture Notes in Comput. Sci.</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">2161</biblScope>
			<biblScope unit="page" from="33" to="48" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
