<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SFA: A Symbolic Fourier Approximation and Index for Similarity Search in High Dimensional Datasets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Schäfer</surname></persName>
							<email>patrick.schaefer@zib.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Zuse Institute</orgName>
								<address>
									<settlement>Berlin Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mikael</forename><surname>Högqvist</surname></persName>
							<email>hoegqvist@zib.de</email>
							<affiliation key="aff1">
								<orgName type="institution">Zuse Institute</orgName>
								<address>
									<settlement>Berlin Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SFA: A Symbolic Fourier Approximation and Index for Similarity Search in High Dimensional Datasets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5309A1E3DBC3120770F9F229A8C78ECD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 [Information Search and Retrieval]: Search process</term>
					<term>G.3 [Probability and Statistics]: Time series analysis</term>
					<term>E.1 [Data Structures]: Trees Algorithms, Performance Time Series, Data Mining, Symbolic Representation, Discretisation, Indexing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Time series analysis, as an application for high dimensional data mining, is a common task in biochemistry, meteorology, climate research, bio-medicine or marketing. Similarity search in data with increasing dimensionality results in an exponential growth of the search space, referred to as Curse of Dimensionality. A common approach to postpone this effect is to apply approximation to reduce the dimensionality of the original data prior to indexing. However, approximation involves loss of information, which also leads to an exponential growth of the search space. Therefore, indexing an approximation with a high dimensionality, i.e. high quality, is desirable.</p><p>We introduce Symbolic Fourier Approximation (SFA) and the SFA trie which allows for indexing of not only large datasets but also high dimensional approximations. This is done by exploiting the trade-off between the quality of the approximation and the degeneration of the index by using a variable number of dimensions to represent each approximation. Our experiments show that SFA combined with the SFA trie can scale up to a factor of 5-10 more indexed dimensions than previous approaches. Thus, it provides lower page accesses and CPU costs by a factor of 2-25 respectively 2-11 for exact similarity search using real world and synthetic data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Time series databases, resulting from recording data over time, range from meteorological data like sediments from drill holes <ref type="bibr" target="#b20">[20]</ref>, financial data like stock prices or product sales, biomedical and biochemical data like ECG signals <ref type="bibr" target="#b14">[14]</ref> or cellular networks <ref type="bibr" target="#b23">[23]</ref>. Unlike exact search, similarity based search finds results that are similar to a query based on a similarity metric. Examples of similarity queries include:</p><p>-find all stocks that show similar trends -find the patients with the 10 most similar ECGs -find all products with a similar sales pattern.</p><p>A time series consisting of n measured values can be seen as a point in n-dimensional space, where the i-th measured value represents the i-th dimension. By indexing this ndimensional point using a spatial index, the problem of finding similar time series is reduced to finding nearby points in n-dimensional space.</p><p>Indexing high dimensional data is a considerable challenge, as spatial index structures, like the R-Tree <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b13">13]</ref> suffer from a phenomenon called the Curse of Dimensionality: with increasing dimensionality of the search space, the performance of similarity based queries on the index becomes worse than a linear scan of all data. Spatial index structures usually degenerate with 10-20 dimensions <ref type="bibr" target="#b12">[12]</ref>.</p><p>Work in <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b11">11]</ref> introduces the idea of dimensionality reduction prior to indexing, and proved that, by using a lower bounding distance measure, queries are guaranteed to return the exact same result in reduced dimensional search space as if they were executed in the original space. In order to reduce the dimensionality of a time series an approximation technique is applied, effectively reducing dimensionality of the time series by 10:1 to 50:1. By use of an approximation technique the Curse of Dimensionality is shifted to 10-20 indexable dimensions of the approximations. The problem with approximation is that information from the original time series is lost. A goal of approximation is to find representations of the original data, so that each representation is distinct. For example, similar time series will have the same representation after an approximation if the reduced dimensionality is too low.</p><p>For two reasons the choice of the optimal dimensionality of the approximations is difficult:</p><p>1. Firstly, a higher dimensionality of the approximations helps to find distinct representations of the original time series. However, a spatial index degenerates exponentially with an increase of dimensions.</p><p>2. Secondly, with a high dimensionality we overrepresent dissimilar time series, while with a low dimensionality we underrepresent similar time series. Both of these issues impact the index negatively up to a point where a similarity search results in a sequential scan of the whole database.</p><p>We propose a technique which uses a variable number of dimensions for indexing time series approximations in order to postpone the impact of both issues. The idea is to group similar approximations based on a small common prefix. The length of the prefix is increased by 1 until each approximation in distinct. This can be implemented by using a trie, which is built over a set of strings. This introduces the problem of how to represent a time series as a string. Furthermore, it must be possible to extend the length of an approximation on the fly without the need to recalculate the approximation. This is why we introduce a symbolic representation based on the frequency domain as opposed to the spatial domain. In the frequency domain each dimension contains approximate information about the whole time series. By increasing the dimensionality we can add detail, thus improving the overall quality of the approximation. In the spatial domain we have to decide on a length of the approximation in advance and a prefix of this length only represents a subset of the time series.</p><p>In this paper we introduce a novel symbolic representation called Symbolic Fourier Approximation (SFA) and the SFA trie, an index structure utilising the properties of the frequency domain nature of SFA. As part of this technique we</p><p>• propose a symbolic representation based on Discrete Fourier Transform (DFT) for approximation and show the benefits compared to other techniques such as Piecewise Aggregate Approximation (PAA),</p><p>• introduce a novel discretisation technique called multiple coefficient binning (MCB) which improves pruning of the search space during the query execution,</p><p>• provide a proof of an Euclidean lower bounding distance measure for SFA which guarantees that the query results of a similarity search in SFA reduced space are the same as in the original space,</p><p>• introduce the SFA trie, a modification of a prefix tree built from the strings of the SFA approximations, and</p><p>• show through experiments that SFA and the SFA trie scale to a factor of 5-10 higher indexed dimensions than previous approaches and can index very large datasets. Furthermore, the SFA trie is better than previous approaches by up to a factor of 2-25 in terms of exact search performance on real and synthetic time series datasets.</p><p>The rest of the paper is organised as follows: Section 2 begins with related work and background material. Section 3 introduces our novel discretisation technique, our symbolic representation and the lower bounding distance measure. Section 4 presents the SFA trie. In Section 5 we perform exhaustive experiments on pruning power and indexing performance. In Section 6 we give a conclusion and suggest future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BACKGROUND AND RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Similarity Search in High Dimensions</head><p>A time series C = c1 . . . cn of length n can be represented by a point in n-dimensional space. Finding similar time series is thus reduced to finding similar or nearby points in a high dimensional space.</p><p>The similarity of two points Q and C is expressed in terms of a real value using a distance measure Dtrue(Q, C) → R. The distance measure is application dependent. Similarity queries include nearest neighbour or epsilon-range queries, for example. Definition 1. k-nearest neighbour (k-NN) query: a k-NN query for Q is a similarity query in n-dimensional space DS n , which returns a subset N N k (Q) ⊆ DS n that contains k objects with the following condition:</p><formula xml:id="formula_0">∀tǫN N k (Q), ∀oǫDS n -N N k (Q) : Dtrue(t, Q) ≤ Dtrue(o, Q).</formula><p>Work in <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b11">11]</ref> introduced a general framework called GEM-INI for indexing high dimensional data: A time series C = c1 . . . cn is mapped into a much lower dimensional space by the use of an approximation technique, called dimensionality reduction. This much lower dimensional space is indexed using a spatial index and a similarity query can be answered by traversing the index.</p><p>Approximation involves loss of information and the distance of any two points in original space is not preserved in lower dimensional space. To guarantee the absence of false dismissals, we have to define a lower bounding distance measure D IndexSpace (Q, C) in lower dimensional space, which underestimates the true distance Dtrue(Q, C) between the time series Q and C in original space. This property is called the lower bounding lemma <ref type="bibr" target="#b11">[11]</ref>:</p><formula xml:id="formula_1">D IndexSpace (Q, C) Dtrue(Q, C)<label>(1)</label></formula><p>Similarity search can be divided into two categories:</p><p>1. whole matching: given N time series and a query for Q, all of length n, find the time series most similar to Q according to distance measure Dtrue.</p><p>2. subsequence matching: given a short query for Q of length m and a long time series, find all subsequences within the long time series similar to Q.</p><p>Subsequence matching can be reduced to whole matching by using a sliding window, which is shifted along the long time series to extract time series of length m which are then compared to Q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Dimensionality Reductions</head><p>Dimensionality reductions can be divided into two groups: symbolic and numerical. In these methods a time series is represented as a sequence of discrete values (symbols) or real values respectively. Since symbolic representations are essentially a character string, they can also be used in data structures and algorithms in the field of data-mining such as tries, hashing, Markov models, string-matching <ref type="bibr" target="#b19">[19]</ref>. Furthermore, they allow for indexing large datasets <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b26">26]</ref>.</p><p>The process of transforming a time series into a symbolic representation can be generalised to two parts:</p><p>1. approximation is applied to map a time series into lower dimensional space resulting in a vector of real values, and</p><p>The SFA Euclidean lower bounding distance between a DFT representation QDF T = (q ′ 1 . . . q ′ w ) and an SFA representation CSF A = (c ′′ 1 . . . c ′′ w ) is calculated by exchanging the pairwise difference of the numerical values in Eq. 2 by a disti function, which measures the distance between the i-th symbol and the i-th numerical value:</p><formula xml:id="formula_2">D 2 SF A (C SF A , Q DF T ) ≡ 2 i=2 dist i (c ′′ i , q ′ i ) 2<label>(3)</label></formula><p>The distance disti between a numerical value q ′ i and a symbol c ′′ i = symbola, represented by its lower and upper discretisation breakpoints βi(a -1) and βi(a), is defined as the distance to the lower discretisation breakpoint if q ′ i is smaller or the upper discretisation breakpoint if q ′ i is larger:</p><formula xml:id="formula_3">disti(c ′′ i , q ′ i ) ≡      0, if q ′ i ǫDIi(a) βi(a -1) -q ′ i , if q ′ i &lt; βi(a -1) q ′ i -βi(a), if q ′ i &gt; βi(a)<label>(4)</label></formula><p>Figure <ref type="figure">4</ref> (right) illustrates the difference between the iSAX dist and the MCB disti definition. MCB uses different breakpoints while iSAX uses the same breakpoints for each symbol.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Proof of Correctness</head><p>To prove correctness of SFA approximation using Eq. 3 and Eq. 4, we have to show that the Euclidean lower bounding lemma holds for SFA.</p><formula xml:id="formula_4">Claim 1. The distance measure D 2 SF A for two time series QDF T = q ′ 1 . . . q ′ w and CDF T = c ′ 1 . . . c ′ w , CSF A = c ′′ 1 . . . c ′′ w</formula><p>holds the Euclidean lower bounding lemma:</p><formula xml:id="formula_5">D 2 SF A (CSF A, QDF T ) D 2 T rue (C, Q) Proof.</formula><p>iSAX allows Euclidean lower bounding using distance dist(c, q). It is obvious, following proof <ref type="bibr" target="#b19">[19]</ref>, that the distance disti(c ′′ i , q ′ i ) using MCB breakpoints is still always smaller than the distance of two DF T -transformed coefficients q ′ i and c ′ i :</p><formula xml:id="formula_6">dist 2 i (c ′′ i , q ′ i ) ≤ (c ′ i -q ′ i ) 2 This yields D 2 true (C, Q) D 2 DF T (CDF T , QDF T ) (5) = 2 i (c ′ i -q ′ i ) 2 (6) 2 i disti(c ′′ i , q ′ i ) 2 (7) = D 2 SF A (CSF A, QDF T )<label>(8)</label></formula><p>where Eq. 5 is proven and Eq. 6 is defined in <ref type="bibr" target="#b24">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Runtime Complexity</head><p>Claim 2. The transformation of N SFA words of length w over an alphabet of size c from a set of N time series of length n has a complexity of O(N • n log n).</p><p>Proof. The calculation of the N DFT approximations requires O(N • n log n) operations, resulting in N approximations of length w. The calculation of the MCB discretisation intervals requires O(N w) operations, as it involves scanning all approximations of length w. The N SFA words require N w lookups in the breakpoints for the c intervals.</p><p>Assuming we use binary search for those lookups this results in O(N w • log c) operations. This leads to a total of</p><formula xml:id="formula_7">O(N • (n log n + w + w log c)) = O(N • n log n) operations for N time series (Table 1).</formula><p>This means the transformation is dominated by the N DFTs and there is negligible impact by the SFA word length w or alphabet size c.</p><formula xml:id="formula_8">Technique DFT SFA PAA SAX/iSAX Time O(N n log n) O(N n log n) O(N n) O(N n)</formula><p>Table <ref type="table">1</ref>: Asymptotic runtime complexity of dimensionality reductions for N approximations of time series of length n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Memory Complexity</head><p>Claim 3. Given N SFA words of length w, SFA requires O(N w) bytes for an alphabet of size 256.</p><p>Proof. The memory footprint of SFA consists of the size of the approximations and the size of the lookup tables. An alphabet of size 256 can be encoded in log 2 256 bits or 1 byte. Thus, an approximation of length w requires w bytes. Given N time series this results in N w bytes. Additionally SFA requires an overhead of w(c -1) • 8 bytes for storing the w lookup tables containing the c -1 real-valued breakpoints with 8 bytes (Double) each. Since these lookup tables are stored only once, the overhead in terms of memory is negligible for large N , resulting in a total complexity of O(N w) bytes.</p><p>Claim 4. SFA has the same asymptotic memory complexity as iSAX.</p><p>Proof. For an alphabet of size 256 iSAX/SAX requires w log 2 256 bits or w bytes for each approximation. Additionally iSAX requires a small overhead of (c-1)•8 bytes for the lookup table containing the c -1 real-valued break points with 8 bytes (Double) each. Following the same reasoning as for SFA, this overhead is negligible for large N , resulting in a total complexity of O(N w) bytes.</p><p>In case of numerical dimensionality reductions each realvalued coefficient of the approximation is stored in a Double, which allocates 8 bytes, resulting in a total of w • 8 bytes for each approximation. Symbolic representations allow for indexing terabyte sized data <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b5">5]</ref> due to this 8-fold lower memory footprint by utilising discretisation on top of approximation (Table <ref type="table" target="#tab_1">2</ref>).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">INDEXING SFA</head><p>The purpose of indexing is to partition the search space into equal-sized groups containing similar entries and to adapt the MBR of that child using the DFT approximation (line 3).</p><p>If that child is an internal node (line 4), we recursively insert the time series and increase the length of the prefix by one. If that child is a leaf node (line 6), we add the time series and check if the insertion caused the leaf to split (line 8). For splitting, we simply flag the child node as an internal node, and reinsert all time series T S into that node (line 9-11), causing the length of the prefix to grow by one.</p><p>If the child node does not exist (line 12-14), we create a new child and add the time series.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Complexity of Insertion</head><p>Claim 5. The total complexity for approximation (SFA) and insertion (SFA trie) of a time series of length n is O(n log n + w(w + th)) operations.</p><p>Proof. The number of operations for insertion is bounded by the depth of the SFA trie, which is limited by the SFA word length w. Thus, descending the SFA trie to find the corresponding leaf node requires O(w) operations, assuming we use a hash for storing (label,edge)-pairs with O(1) lookup (line 1). Adjusting the MBRs (line 3) requires O(w) operations for each level of the trie, due to the need to calculate the minimum and maximum value for each dimension. Splitting (line 10-11) is applied locally and a maximum of th time series are reinserted causing the MBRs to adjust. This leads to a total of O(w • (w + th)) operations for insertion in case of a split and O(w 2 ) otherwise. This results in a total complexity for approximation and insertion of a time series of length n of O(n log n + w(w + th)) operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">SFA Trie -MBR distance</head><p>During query processing, the minimal distance of a query to an MBR is calculated. An MBR consists of real-valued upper and lower bounds: MBR=((l1, u1), . . . , (lw, uw)). The distance between a DFT representation QDF T = (q ′ 1 . . . q ′ w ) and an MBR is defined as a sum over all dimensions similar to SFA (Eq. 3):</p><formula xml:id="formula_9">mindist 2 (M BR, QDF T ) = 2 i=2 dist mbr ((li, ui), q ′ i ) 2</formula><p>The distance between a DFT coefficient q ′ i and a tuple (li, ui), is defined as the distance to the lower bound, if q ′ i is smaller, and the distance to the upper bound, if q ′ i is larger. </p><formula xml:id="formula_10">dist mbr ((li, ui), q ′ i ) ≡      0, if li q ′ i ui li -q ′ i , if q ′ i &lt; li q ′ i -ui, if q ′ i &gt; ui<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">SFA Trie: k-Nearest-Neighbour Exact Search</head><p>We introduce the k-NN exact search algorithm for SFA based on the SFA trie. The algorithm is an adaptation of the multistep 1-NN algorithm introduced in <ref type="bibr" target="#b26">[26]</ref>. The algorithm uses a candidate list which is generated by using mindist in reduced space and later refined by using the original distance Dtrue. In contrast to the multistep 1-NN algorithm it makes use of an approximate search (line 2) and the pruning of index branches based on that search result (line 14).</p><p>Input parameters are the query Q, the DFT approximation of the query QDF T and k. A priority queue queue is used for index navigation and storage of the nodes having the smallest distance in reduced space. Another priority queue temp is used to store all raw time series currently known. The queue result is used to store the k-NN of our query. A time series is transferred from temp to queue (line 6-8) as soon as there are no index branches with a smaller distance available (line 6-8).</p><p>The algorithm starts by performing an approximate search (line 2) within the SFA trie. The approximate search exploits the fact that the nearest neighbours and the query are likely to have the same SFA word. Therefore, we search the leaf node with the same SFA word as the query and add those time series to temp to enable pruning of the trie (line 14).</p><p>Starting with the root node of the index (line 3), we pop the node having the smallest distance from queue (line 5). If the node is an internal node and it's distance is lower than that of the best so far known time series in temp (line 13), we traverse and insert all child nodes and their mindist into queue (line 10-15). The distance of the k-th best so far known time series is used for pruning (line 11), which is the (k -|result|)-th element in temp. If the node is a leaf node (line 16), we retrieve the raw time series from disk (line 17) We conclude that differences in the discretisation intervals have a smaller impact on the tlb than the approximation when the number of symbols gets large. However, for the SFA trie high precision using small number of symbols is required, e.g. 4-16 symbols. Thus, SFA is favourable over SFA-Dep and iSAX. SFA is favourable over DFT because of its 8-fold smaller memory footprint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Pruning Power</head><p>Motivated by the high tlb for SFA, we compared SFA with numerical and symbolic dimensionality reductions in terms of pruning power, which is the benchmark for the performance of 1-NN queries. The pruning power P is defined as the fraction of the database, that must be examined in reduced space before the 1-NN to a query is found <ref type="bibr" target="#b15">[15]</ref>:</p><formula xml:id="formula_11">P =</formula><p>number of objects to be examined total number of objects</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pruning Power Benchmark.</head><p>In this experiment we compare SFA to the most recently published numerical dimensionality reductions. We use iSAX pruning power as the base line and measure the relative improvement of the other dimensionality reductions given by 1 -P current P iSAX in percent, thus higher is better. The results were averaged over 29 datasets for a time series length l of 256, an increasing number of coefficients to represent one approximation and 256 symbols for SFA and iSAX.</p><p>Figure <ref type="figure">8</ref> shows that among the numerical representations DFT shows the best pruning power. SFA is better than most of the other numerical representations and slightly worse than DFT. SFA is on average up to a factor of 0.40 better than iSAX, that means on average 40% less time series have to be inspected to find the 1-NN.</p><p>Overall SFA is not only better than iSAX but the results indicate that it is competitive with the best numerical reductions. We conclude that these improvements are a result of the tight tlb achieved by MCB and DFT. On our website <ref type="bibr" target="#b25">[25]</ref> we show the pruning power for each of the 29 datasets.</p><p>DFT has the best pruning power. However, the advantage of SFA over DFT is the symbolic representation and thus 8fold lower memory footprint. This allows for indexing large and high dimensional datasets through the SFA trie. This is what we will show in the next experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Indexing High Dimensional Datasets</head><p>In these experiments we focus on two parameters:  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets.</head><p>We evaluate the performance of similarity search using SFA, iSAX and DFT on 10 synthetic random walk datasets from <ref type="bibr" target="#b14">[14]</ref> and the real world datasets presented in <ref type="bibr" target="#b26">[26]</ref>. We chose DFT as a representative for the numerical reductions, as DFT was best in the tlb and pruning power experiments. The synthetic datasets contain 100,000 overlapping time series each. The real world datasets contain 2.500 to 1 million overlapping time series. For the experiments we partitioned the real world datasets into two groups small and large, with 16 real datasets consisting of less than 100,000 time series and 11 real datasets consisting of more than 100,000 time series. We excluded npo141 and cl2fullLarge from the large datasets, as their wall clock time and page accesses are so high that they would dominate the other measurements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setup.</head><p>We compare the SFA trie with the iSAX index and DFT using R*-trees <ref type="bibr" target="#b3">[3]</ref>, a variant of the R-tree <ref type="bibr" target="#b13">[13]</ref>. We set the base cardinality (alphabet size) b = 4 and the threshold th = 100 for the iSAX index and the f illf actor = 100 and p = 0.80 for the R*-tree. We set the fanout of the SFA trie to 8 (equals 8 symbols) and the threshold th = 100. We tested using 256 symbols for iSAX. Each index has a maximum of 100 time series per leaf (same as in <ref type="bibr" target="#b26">[26]</ref>). All results have been averaged over 1000 10-NN queries.</p><p>A leaf node access accounts for one page access even if the leaf node spans more than one disk block or if two leaf nodes are stored in successive blocks on hard disk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact of Approximation/Word Length.</head><p>In this experiment we test the scalability of the SFA trie in terms of the length of the approximations, i.e. varying the word length, which correlates with the indexable time series length. This experiment was performed on large, small and synthetic datasets. Figure <ref type="figure" target="#fig_2">9</ref> shows the scalability in terms of the average wall clock time and the average page accesses to answer one k-NN query for an increasing length of the approximations. The minimum of each line shows the best configuration for each index structure. The labels on the top represent the time series lengths l. The labels on the right represent the different datasets.</p><p>Time Series Lengths (left to right plots): The iSAX index degenerates faster than the SFA trie when increasing l from 256 to 1024. The R*-tree is competitive to the iSAX index on the small datasets but scales badly with increasing l on the large and synthetic datasets.</p><p>X-Axis (Indexed Dimensions): Both measurements (wall clock time and page accesses) show the same trend. The SFA trie scales to 128 indexed dimensions without degeneration. 20 -32 dimensions seem to be a good trade-off between storage space and performance. This equals 60 -96 Bits for SFA. Comparing the optimal number of indexed dimensions for iSAX (4-8), DFT <ref type="bibr" target="#b8">(8)</ref><ref type="bibr" target="#b9">(9)</ref><ref type="bibr" target="#b10">(10)</ref><ref type="bibr" target="#b11">(11)</ref><ref type="bibr" target="#b12">(12)</ref><ref type="bibr" target="#b13">(13)</ref><ref type="bibr" target="#b14">(14)</ref><ref type="bibr" target="#b15">(15)</ref><ref type="bibr" target="#b16">(16)</ref> and SFA <ref type="bibr" target="#b20">(20)</ref><ref type="bibr" target="#b21">(21)</ref><ref type="bibr" target="#b22">(22)</ref><ref type="bibr" target="#b23">(23)</ref><ref type="bibr" target="#b24">(24)</ref><ref type="bibr" target="#b25">(25)</ref><ref type="bibr" target="#b26">(26)</ref><ref type="bibr">(27)</ref><ref type="bibr">(28)</ref><ref type="bibr">(29)</ref><ref type="bibr">(30)</ref><ref type="bibr">(31)</ref><ref type="bibr">(32)</ref>, the SFA trie is among the best indexes on the small and large real world datasets and only scores worse on the synthetic datasets for l = 256. iSAX performs well on random data, because the iSAX discretisation is based on normal distribution.</p><p>In the SFA trie an increasing dimensionality of the approximations causes dense leaf nodes to split, but the general structure of the trie remains unaffected as opposed to the R*-tree or the iSAX index. This is why the SFA trie improves when increasing the length of the approximation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Indexing High Dimensional Datasets.</head><p>For this experiment we compare the symbolic representations in terms of indexing time series datasets with a high dimensionality (very long time series). Only the optimal number of coefficients, i.e. those which had the lowest data page accesses, is compared for each dataset and representa- tion. In Figure <ref type="figure" target="#fig_3">10</ref> we illustrate the factor of improvement in wall clock time and page accesses for the SFA trie over the iSAX index for different time series lengths l. The factor is given by time iSAX time SF A and io iSAX io SF A , meaning higher is better. The largest dataset with 4096 dimensions and size 10 6 occupied approx. 32GB of memory.</p><p>On the large datasets the median improvement factor over iSAX rises with increasing l from about 1.5 to 3 (time) and to 2.8 (I/O). On some datasets the improvement is up to a factor of 25 <ref type="bibr" target="#b11">(11)</ref> in terms of I/O (time) for real (convertedkatafu) and 27 <ref type="bibr" target="#b22">(22)</ref> in terms of I/O (time) for synthetic datasets (synthetic 9 ). On the small datasets there seems to be little influence of l on the wall clock time and the median stays around a factor of 1.5, with some datasets showing an improvement of up to 5 (foetal-ecg/power-data). On the synthetic datasets and l = 256 the SFA trie shows a worse wall clock time than the iSAX index. However, the median improves to a factor of about 1.5 to 15.</p><p>We conclude that the SFA trie scales much better for increasing time series lengths on large and synthetic datasets due to the high number of indexable dimensions, as shown in the previous experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Use-Case: Cellular Networks</head><p>This experiment illustrates the necessity of indexing time series with a length of up to 66000 dimensions. Comparing cellular networks is a challenging problem that could provide insight into biology and therapeutics. Thus, heuristics such as graphlet frequency distribution have been proposed. In <ref type="bibr" target="#b23">[23]</ref> two networks are similar, if they contain similar subgraphs, named graphlets. A network is characterised by up to 73 graphlet degree distributions GDD of graphlets with 2-5 nodes. The GDD measures the number of nodes N j G (k) touching k graphlets at a particular node j in the graphlets, called orbit. For a fixed orbit j the GDD can be easily interpreted as a time series using k as the time axis and N j G (k) as the value. However, k might become arbitrarily large. The similarity D j of two graphs G and H is measured using the j-th normalised GDD:</p><formula xml:id="formula_12">D j (G, H) = ( ∞ k=1 N j G (k) -N j H (k) 2 ) 1/2 , jǫ[0 . . . 72]</formula><p>We indexed different orbits for 1450 randomly generated graphs from <ref type="bibr" target="#b10">[10]</ref>, consisting of 725 isomorph pairs, containing 20-600 nodes with eta=0.01. We indexed those orbits with a k degree of less than 66000 using the SFA trie and the iSAX index and did a 5-NN search, which is guaranteed to find the isomorph pair. Figure <ref type="figure" target="#fig_4">11</ref> shows that, due to the high degree k of the GDD, the iSAX index falls back to a sequential scan of all graphs. Meanwhile, the SFA trie, which was built using an SFA word length of 1024 up to 2048, scales well with the high degree k of the GDD and on average 150-400 out of 1450 graphs are scanned to find the 5-NN for an orbit. This is a factor of 3-7 improvement compared to iSAX and sequential scanning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Indexing Large Datasets (One Billion Time Series)</head><p>In this experiment we focus on the size of the dataset, i.e. the number of time series it contains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset.</head><p>iSAX and SFA qualify for indexing large sized datasets as both are symbolic representations and exhibit an approx. 8fold lower memory footprint than numerical dimensionality reductions. For this experiment, we indexed 10 6 to 10 9 synthetic time series with a length of 256, resulting in 2GB to 2TB raw data. Each data point was generated using standard normal distribution N(0,1) and the recursive function: xi+1 = N (xi, 1) (same as in <ref type="bibr" target="#b5">[5]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setup.</head><p>We set the word length w = 8 and base cardinality b = 4 for the iSAX index and w = 20 for the SFA trie and a leaf threshold th = 10000 for both. The iSAX index was implemented using the optimised node splitting policy presented in <ref type="bibr" target="#b5">[5]</ref>.</p><p>A leaf node access accounts for one page access even if the leaf node spans more than one disk block or if two leaf nodes are stored in successive blocks on hard disk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Index Size &amp; Leaf Node Occupancy.</head><p>In this experiment we measure the size of the index in (1) the total number of nodes (including leaf nodes), (2) the total number of leaf nodes, (3) the fillfactor of the leaf nodes and (4) the size of the index on disk excluding the raw time series data. Figure <ref type="figure" target="#fig_1">12</ref> shows that the SFA trie is a more compact representation than the iSAX index and requires a factor of 1.72 to 2.28 less nodes and 1.24 to 2.58 less leaf nodes to represent the data. This leads to a 1.24 to 2.58 higher fillfactor of the leaf nodes. The SFA trie is also more compact in terms of memory requirements, as it needs up to a factor of 2.4 less main memory compared to the iSAX index (excluding the raw time series data).</p><p>These results show that in terms of memory footprint the SFA trie qualifies for indexing large datasets such as the iSAX trie does <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b26">26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Similarity Search.</head><p>To benchmark the index structures, we compared the iSAX index and the SFA trie in terms of leaf node accesses, which is an objective measure for disk page accesses, and wall clock time, which is the time spent for each similarity query including disk page accesses. We did 100 5-NN queries each and averaged the results. This experiment (Figure <ref type="figure" target="#fig_1">13</ref>) demonstrates that the SFA trie requires less disk accesses and less wall time than the iSAX index to answer a similarity query. On average the SFA trie requires up to a factor of 2.45 less wall time and up to a factor of 2.6 less leaf node accesses.</p><p>A 5-NN query on the 1000 M dataset took on average 52 minutes for the SFA trie and 80 minutes for the iSAX index.</p><p>Note that the use of N(0,1) for data generation is in favour of iSAX, as iSAX discretisation is based on N(0,1). Still, the SFA trie requires less page accesses and wall time than the iSAX index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSIONS</head><p>We introduced the SFA trie and the symbolic representation SFA based on the discretisation of Discrete Fourier Transform (DFT). The SFA trie exploits the frequency domain nature of SFA by approximation of a time series using a high dimensionality and a variable prefix for indexing. With a variable prefix length it is possible to distinguish time series which have similar approximations. This leads to improved similarity query performance. The SFA trie is tailored for a variable prefix length as it grows in depth rather than width when increasing the length of similar approximations, which postpones the effects of the Curse of Dimensionality.</p><p>As part of SFA we introduced a novel discretisation technique called MCB. As DFT has a statistically significant tighter lower bound compared to PAA, SFA provides a tighter lower bound to the Euclidean distance than iSAX. Like iSAX it offers a high information density per bit and thus allows for indexing large datasets. Unlike iSAX, every SFA coefficient represents the whole signal due to the frequency domain, which allows for indexing high dimensional datasets. In our experiments the SFA trie is the best index structure in terms of page accesses and wall clock time on real and synthetic datasets. Future work includes a technique to efficiently rebalance the SFA trie, thereby avoiding degeneration due to updates.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 8 : 2 |symbols|</head><label>82</label><figDesc>Figure 8: Average pruning power over 29 time series datasets using iSAX as baseline (equals 0%) with varying number of coefficients (4 to 20). Each bar represents the average over 29 datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 .</head><label>1</label><figDesc>Approximation length/word length: this represents the Scalability of iSAX vs. SFA Trie approximation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Mean wall clock time and page accesses for real world and synthetic datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Ratio of page accesses and wall clock time for the SFA trie vs. the iSAX index on the 37 datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Number of graphs searched to find the 5-NN out of 1450 graphs. Each dot represents 1 to 10 queries. Only orbits with k &lt; 10 6 are shown.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 12 :Figure 13 :</head><label>1213</label><figDesc>Figure 12: Comparison of index size and leaf node occupancy with varying size of the synthetic dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Asymptotic memory complexity in bytes of dimensionality reductions for N approximations of length w and an alphabet of size 256 for symbolic representations SFA and SAX/iSAX.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Algorithm 1 SFA Trie Insertion function Insert(T,TSF A, TDF T , i, node)</figDesc><table><row><cell>1: child = node.getChild(TSF A[i]) 2: if (child != null) 3: child.adaptMBR(TDF T ) 4: if (child.isInternal()) 5: Insert(T, TSF A, TDF T , i + 1, child) 6: else if (child.isLeaf()) 7: child.add(T ) 8: if (child.split()) 9: child.setInternal() 10: foreach T S in child 11: Insert(T S, T SSF A, T SDF T , i + 1, child) 12: else 13: newchild = new Leaf 14: node.add(TSF A[i], newchild) 15: newchild.add(T )</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Algorithm 2 Exact k-Nearest-Neighbour Search function exactKNNSearch(Q, QDF T , k) 1: PriorityQueue queue, Queue result 2: PriorityQueue temp = approximateSearch(Q,QDF T ,k) 3: queue.push(root, 0) 4: while (!queue.isEmpty()) do 5: (minimum, distance) = queue.RemoveMinimum() 6: for all time series T in temp such that \</figDesc><table><row><cell>Dtrue(T, Q) distance do temp.remove(T ) result.insert(T ) 9: if |result| = k return result 7: 8: 10: if minimum is internal node 11: tempDist = temp.get(k-|result|).distance 12: for all node in minimum.children do 13: nodeDist = mindist(node.M BR, QDF T ) 14: if nodeDist&lt;tempDist 15: queue.push(node,nodeDist) 16: else if minimum is leaf node 17: signals=retrieve raw time series from hard disk 18: for all time series T in signals 19: temp.push(T,D true (T, Q)) 20: return result</cell></row><row><cell>We modify Eq. 4 by replacing breakpoints βi by the tuple</cell></row><row><cell>(li, ui):</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>The authors would like to thank Eamonn Keogh, for his valuable comments on previous versions of the paper and making available the time series datasets, and Ulrike Golas, for her valuable comments on the final version of the paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Efficient Similarity Search In Sequence Databases</title>
		<author>
			<persName><forename type="first">R</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. (FODO) (1993)</title>
		<meeting>FODO) (1993</meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The ts-tree: efficient time series search and retrieval</title>
		<author>
			<persName><forename type="first">I</forename><surname>Assent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Afschari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
		<idno>EDBT &apos;08</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th international conference on Extending database technology: Advances in database technology</title>
		<meeting>the 11th international conference on Extending database technology: Advances in database technology<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="252" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The R*-tree: an efficient and robust access method for points and rectangles</title>
		<author>
			<persName><forename type="first">N</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Seeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGMOD Rec</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="322" to="331" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Indexing spatio-temporal trajectories with chebyshev polynomials</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc of the 2004 ACM SIGMOD</title>
		<meeting>of the 2004 ACM SIGMOD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="599" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">isax 2.0: Indexing and mining one billion time series. Data Mining</title>
		<author>
			<persName><forename type="first">A</forename><surname>Camerra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Palpanas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="58" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Locally adaptive dimensionality reduction for indexing large time series databases</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIGMOD</title>
		<meeting>of ACM SIGMOD</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="151" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Haar wavelets for efficient similarity search of time-series: With and without time warping</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">K</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-P</forename><surname>Chee Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="686" to="705" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficient time series matching by wavelets</title>
		<author>
			<persName><forename type="first">K.-P</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="126" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Indexable PLA for efficient similarity search</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc of the VLDB</title>
		<meeting>of the VLDB</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="435" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A large database of graphs and its use for benchmarking graph isomorphism algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>De Santo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Foggia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sansone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vento</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn. Lett</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1067" to="1079" />
			<date type="published" when="2003-05">May 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast subsequence matching in time-series databases</title>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Manolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD Rec</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="419" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multidimensional access methods</title>
		<author>
			<persName><forename type="first">V</forename><surname>Gaede</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Günther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="170" to="231" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">R-trees: a dynamic index structure for spatial searching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Guttman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc of the 1984 ACM SIGMOD</title>
		<meeting>of the 1984 ACM SIGMOD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1984">1984</date>
			<biblScope unit="page" from="47" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<ptr target="http://www.cs.ucr.edu/eamonn/TSDMA/index.html" />
		<title level="m">The UCR time series data mining archive</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dimensionality reduction for fast similarity search in large time series databases</title>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pazzani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mehrotra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="263" to="286" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A simple dimensionality reduction technique for fast similarity search in large time series databases</title>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge Discovery and Data Mining PAKDD 2000</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">1805</biblScope>
			<biblScope unit="page" from="122" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficiently supporting ad hoc queries in large datasets of time sequences</title>
		<author>
			<persName><forename type="first">F</forename><surname>Korn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc of the 1997 ACM SIGMOD</title>
		<meeting>of the 1997 ACM SIGMOD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="289" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A symbolic representation of time series, with implications for streaming algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lonardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Chiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DMKD</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="2" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Experiencing SAX: a novel symbolic representation of time series</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lonardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="107" to="144" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cross recurrence plot based synchronization of time series</title>
		<author>
			<persName><forename type="first">N</forename><surname>Marwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Thiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Nowaczyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nonlinear Processes in Geophysics 9</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="325" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Online amnesic approximation of streaming time series</title>
		<author>
			<persName><forename type="first">T</forename><surname>Palpanas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gunopulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Truppel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="338" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Similarity search over time series data using wavelets</title>
		<author>
			<persName><forename type="first">I</forename><surname>Popivanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="212" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Biological network comparison using graphlet degree distribution</title>
		<author>
			<persName><forename type="first">N</forename><surname>Pržulj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="853" to="854" />
			<date type="published" when="2010-03">March 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Efficient retrieval of similar time sequences using DFT</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rafiei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mendelzon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. FODO Conference</title>
		<meeting>FODO Conference<address><addrLine>Kobe</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="249" to="257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">P</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Högqvist</surname></persName>
		</author>
		<author>
			<persName><surname>Sfa</surname></persName>
		</author>
		<author>
			<persName><surname>Page</surname></persName>
		</author>
		<ptr target="http://www.zib.de/patrick.schaefer/sfa/" />
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">iSAX: indexing and mining terabyte sized time series</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="623" to="631" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
