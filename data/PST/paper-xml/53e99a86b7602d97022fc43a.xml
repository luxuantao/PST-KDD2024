<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning dynamic algorithm portfolios</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2007-01-26">26 January 2007</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Matteo</forename><surname>Gagliolo</surname></persName>
							<email>matteo@idsia.ch</email>
						</author>
						<author>
							<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">IDSIA</orgName>
								<address>
									<addrLine>Galleria 2</addrLine>
									<postCode>6928</postCode>
									<settlement>Manno (Lugano)</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Informatics</orgName>
								<orgName type="institution">University of Lugano</orgName>
								<address>
									<addrLine>Via Buffi 13</addrLine>
									<postCode>6904</postCode>
									<settlement>Lugano</settlement>
									<country>Switzerland J. Schmidhuber</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">TU Munich</orgName>
								<address>
									<addrLine>Boltzmannstr. 3</addrLine>
									<postCode>85748</postCode>
									<settlement>Garching, München</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning dynamic algorithm portfolios</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2007-01-26">26 January 2007</date>
						</imprint>
					</monogr>
					<idno type="MD5">993E1818FD9282EB9E06F9526CF128AA</idno>
					<idno type="DOI">10.1007/s10472-006-9036-z</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Algorithm selection can be performed using a model of runtime distribution, learned during a preliminary training phase. There is a trade-off between the performance of model-based algorithm selection, and the cost of learning the model. In this paper, we treat this trade-off in the context of bandit problems. We propose a fully dynamic and online algorithm selection technique, with no separate training phase: all candidate algorithms are run in parallel, while a model incrementally learns their runtime distributions. A redundant set of time allocators uses the partially trained model to propose machine time shares for the algorithms. A bandit problem solver mixes the model-based shares with a uniform share, gradually increasing the impact of the best time allocators as the model improves. We present experiments with a set of SAT solvers on a mixed SAT-UNSAT benchmark; and with a set of solvers for the Auction Winner Determination problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Keywords</head><p>algorithm selection • algorithm portfolios • online learning • life-long learning • bandit problem • expert advice • survival analysis • satisfiability • constraint programming Mathematics Subject Classifications (2000) 68T05 • 68T20 • 62N99 • 62G99</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Motivation</head><p>Most problems in AI can be solved by more than one algorithm. Most algorithms feature a number of parameters that have to be set. Both choices can dramatically affect the quality of the solution, and the time spent obtaining it. Algorithm Selection <ref type="bibr" target="#b64">[63]</ref>, or Meta-learning <ref type="bibr" target="#b76">[75]</ref> techniques, address these questions in a machine learning setting. Based on a training set of performance data for a large number of problem instances, a model is learned that maps (problem, algorithm) pairs to expected performance. The model is later used to select and run, for each new problem, only the algorithm that is expected to give the best results.</p><p>A generalization of algorithm selection, inspired by the Algorithm Portfolio paradigm <ref type="bibr" target="#b32">[33]</ref>, is to use the model to select a subset of the available algorithms, and run them in parallel until the fastest one solves the problem. For some classes of algorithms, with a "heavy-tailed" runtime distribution, the execution of multiple parallel runs differing only for the random seed, can actually have an advantage over a single run <ref type="bibr" target="#b24">[25]</ref>. In any case, only a fraction of the computation time will be spent on the fastest solver.</p><p>These approaches, though preferable to the far more popular "trial and error", pose a number of problems:</p><p>1. Training set representativeness. Problem instances encountered during the training phase are assumed to be statistically representative of successive ones. This hypothesis is practically unavoidable for any model-based selection technique, if referred to a single instance. 2. Static selection. The actual algorithm performance on a given problem is assumed to be predictable with sufficient precision before even starting the algorithm. This assumption is often violated by stochastic algorithms, whose performance can exhibit large fluctuations across different runs (see, e. g., Section 7.1, or <ref type="bibr" target="#b24">[25]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Training cost. Generating the training data obviously requires solving each</head><p>training problem repeatedly, at least once for each of the algorithms. The computational cost of this initial training phase is neglected, even though it can be high enough to make algorithm selection impractical.</p><p>One common trait of the problems listed above, is that they can be related to the lack of feedback information from the actual execution of the chosen algorithms. Such a dynamic feedback can be used to update the model's predictions, and adapt the computational resource allocation accordingly, allowing for a finer distinction among problem instances (problem 2). It can also be used to guide the training phase itself, avoiding exceedingly long runs of inefficient algorithm/problem combinations (problem 3).</p><p>A step in this direction can be taken using a Dynamic Algorithm Portfolio (DAP) <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b60">59]</ref>. Instead of first choosing a portfolio and then running it, a DAP iteratively allocates a time slice that is shared among all the available algorithms, and updates the relative algorithm priorities, based on their current state, in order to favor the most promising ones. To this aim, a model is needed to map (problem, algorithm, current algorithm state) triples to the expected time to solve the problem.</p><p>To reduce training cost, the artificial boundary between training and usage should be dropped, adopting an online learning technique: after the first problem is solved, the model is updated, and used to guide the solution of the next problem.</p><p>In previous work, we termed this approach Adaptive Online Time Allocation (AOTA). In <ref type="bibr" target="#b20">[21]</ref>, we presented an oblivious time allocator, with no knowledge transfer across problem instances. Runtime predictions, evaluated by extrapolating recent performance improvements, were mapped to time allocation for the next time slice, based on a simple "ranking" heuristic. In <ref type="bibr" target="#b16">[17]</ref> we proposed a method for learning a probabilistic model online, while solving a problem sequence. The model was conditioned on features of both the problems and the algorithms (parameter values, current state). The downside of introducing knowledge transfer across problem instances was that the model would obviously be unreliable during the initial portion of the problem sequence. Time was then allocated according to a modification of the ranking heuristic: the first problem was solved with a uniform share, and the impact of the model on the time allocation was gradually increased through the sequence of tasks, according to a fixed schedule, independent of model performance.</p><p>In this work we keep the same dynamic online philosophy, but we separate the two problems of allocating time based on runtime predictions, and grading the impact of model-based allocation, giving a sound solution for both. In the following we briefly present some related work (Section 2), distinguishing between static techniques, in which the selection is performed before runtime, and dynamic ones, where the selection process is somehow adapted during the actual execution of the algorithms. We then introduce some simple concepts from survival analysis, which are relevant to our method, and to algorithm performance modeling in general. Section 4 describes an ideal implementation of a static portfolio, based on exact knowledge of the runtime distributions of the algorithms, illustrating different optimality criteria to share machine time among the algorithms. Section 5 introduces the dynamic extension, and the online learning scheme, discussing the exploration-exploitation trade-off determined by the online setting. In Section 6, we address this trade-off in the context of bandit problems <ref type="bibr" target="#b0">[1]</ref>, and present our new time allocator (TA) GambleTA. Section 7 analyzes experimental results on two challenging algorithm selection problems. In the first set of experiments, a local search and a complete SAT solver are controlled during the solution of a sequence of random satisfiable and unsatisfiable problems. In the second, we compare with results of a static algorithm selection approach <ref type="bibr" target="#b46">[45]</ref>, on a set of combinatorial Auction Winner Determination problems. Section 8 discusses originality, limitations, and viable improvements of GambleTA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Many algorithm selection, or parameter tuning, techniques, are tailored to a specific algorithm, and often present similar interesting solutions across different fields of research. We will give some examples of these, but we will keep our focus on "black box" techniques, that can be applied in more general settings.</p><p>We will first introduce some naming conventions. A first distinction needs to be made among decision problems, in which a binary criterion for recognizing a solution is available; and optimisation problems, in which different levels of solution quality can be attained, measured by an objective function <ref type="bibr" target="#b28">[29]</ref>. A decision problem can be viewed as an optimisation problem with a binary objective function; an optimisation problem can be turned into a decision problem, if a reachable target value of performance can be set in advance. Literature on algorithm selection is often focused on one of these two classes of problems. The selection is normally aimed at maximizing performance quality for optimisation problems; and at minimizing solution time for decision problems.</p><p>The selection among different algorithms can be performed once for an entire set of problem instances (per set selection, following the terminology of <ref type="bibr" target="#b33">[34]</ref>); or repeated for each instance (per instance selection). A further independent distinction <ref type="bibr" target="#b60">[59]</ref> can be made among static algorithm selection, in which any decision on the allocation of resources precedes algorithm execution; and dynamic, or reactive, algorithm selection, in which the allocation can be adapted during algorithm execution.</p><p>Another orthogonal feature is related to learning. Here we borrow from the machine learning terminology, distinguishing between offline or batch learning techniques, in which there is a separate training phase, after which the selection criteria are kept fixed; and online<ref type="foot" target="#foot_0">1</ref> or life-long learning <ref type="bibr" target="#b63">[62]</ref> techniques, in which the criteria are updated at every instance solution. Oblivious algorithm selection techniques do not transfer any knowledge across different problem instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Static algorithm selection</head><p>A seminal paper in this field is <ref type="bibr" target="#b64">[63]</ref>, in which offline, per instance algorithm selection is first advocated, both for decision and optimisation problems. More recently, similar concepts have been proposed, with different terminology (algorithm recommendation, ranking, model selection), by the Meta-Learning community <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b42">42,</ref><ref type="bibr" target="#b76">75]</ref>. For example, in <ref type="bibr" target="#b71">[70]</ref>, different values for the kernel parameter of a Support Vector Machine <ref type="bibr" target="#b75">[74]</ref> are evaluated on different training data sets. Each data set is described through a set of features. For an unseen data set, the features are first evaluated, and a ranking of the kernel parameter values is induced, using a k-nearest-neighbor estimate of performance, based on distance in feature space between the new data set, and the ones used for training.</p><p>Usually, meta-learning research deals with optimisation problems, and is focused on maximizing solution quality, without taking into account the computational aspect. An interesting exception is offered by landmarking techniques <ref type="bibr" target="#b62">[61]</ref> in which the performances of fast base-learners, not included in the algorithm set, are used as task features, in order to obtain a better discrimination of task difficulty.</p><p>Works on Empirical Hardness Models <ref type="bibr" target="#b46">[45,</ref><ref type="bibr" target="#b47">46,</ref><ref type="bibr" target="#b57">56,</ref><ref type="bibr" target="#b58">57]</ref> are instead applied to decision problems, and focus on obtaining accurate models of runtime performance, conditioned on numerous features of the problem instances, as well as on parameters of the solvers <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref>. The models are used to analyze this performance, or to generate harder benchmarks, but also to perform algorithm selection on a per instance basis. Online selection is advocated in <ref type="bibr" target="#b33">[34]</ref>.</p><p>Literature on algorithm portfolios <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b61">60]</ref> is usually focused on choice criteria for building the set of candidate solvers, such that their areas of good performance don't overlap; and optimal static allocation of computational resources among elements of the portfolio. <ref type="foot" target="#foot_2">2</ref>Other interesting research areas, in which both solution quality and computational aspects are taken into account, include anytime algorithm scheduling <ref type="bibr" target="#b7">[8]</ref>, and time limited planning <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b66">65,</ref><ref type="bibr" target="#b67">66]</ref>), in which time is allocated sequentially to a set of planning primitives (e. g., finding the path to a goal) and the subsequent actions exploiting the decisions taken (e. g., following the chosen path), in order to obtain a good compromise between solution quality and time spent computing it.</p><p>Bandit problem solvers (BPS) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6]</ref>, can in principle be applied to static per set algorithm selection, considering each available algorithm as an arm and runtime as a loss, to be minimized (see also Section 2.2, Section 6, <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b19">20]</ref>). As an alternative, one can consider the use of a BPS to solve selection problems on a per instance basis, in an oblivious setting, as in <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b74">73]</ref>, where the Max K-armed bandit problem is presented, and solvers for this game are used to maximize performance quality.</p><p>In <ref type="bibr" target="#b19">[20]</ref>, we presented an online method for learning a per set estimate of an optimal restart strategy (GambleR). The method consists in alternating the universal strategy of <ref type="bibr" target="#b52">[51]</ref>, and an estimated optimal strategy, again based on <ref type="bibr" target="#b52">[51]</ref>. The estimate is performed according to a model of runtime distribution on the set of instances, updated at every solution. Here the bandit problem solver is used at an upper level, to allocate runs of the two strategies: a similar approach will be taken in this work, to weight the decisions of different time allocators (Section 6).</p><p>The classification of Racing Algorithms <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b54">53]</ref> as static or dynamic depends on the definition of a problem instance. In these works, the algorithm set contains different parametrizations of a given supervised algorithm. Each is repeatedly run on a sequence of increasingly large leave-one-out training sets, which can be seen as a sequence of related problems; after a problem is solved, badly performing algorithms are discarded if statistically sufficient evidence is gathered against them, such that machine time is shared among fewer algorithms on next problem.</p><p>Search in program space can also be formalized as an algorithm selection problem. For example, the algorithm set of the Optimal Ordered Problem Solver <ref type="bibr" target="#b69">[68]</ref> may include all programs of a universal programming language. Time is allocated to these programs proportionally to a probability distribution that is updated when a problem is solved. Other interesting program search techniques include Genetic Programming <ref type="bibr" target="#b12">[13]</ref> and Probabilistic Incremental Program Evolution <ref type="bibr" target="#b68">[67]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Dynamic algorithm selection</head><p>A number of interesting dynamic exceptions to the static selection paradigm have been proposed recently. In <ref type="bibr" target="#b30">[31]</ref>, algorithm performance modeling is based on the behavior of the candidate algorithms during a predefined amount of time, called the observational horizon. Each algorithm is run on each training problem, with a high enough cutoff time, and features are extracted from the dynamic data recorded during this initial period. Runs are distinguished as belonging to two classes of "short" and "long" experiments, using the median of runtimes as a decision threshold. A mapping is learned from the static and dynamic features to the correct classification labels. The same approach is used in <ref type="bibr" target="#b40">[40]</ref> to implement dynamic context-sensitive restart policies for SAT solvers: the authors assume that the runtime distribution of their algorithm is not known in advance, but belongs to a known finite set of distributions, from which the correct one can be discriminated based on dynamic features.</p><p>Algorithmic chaining <ref type="bibr" target="#b8">[9]</ref> executes a predetermined sequence of Constraint Programming solvers, using an ad-hoc mechanism to decide when to switch to next algorithm, according to a prediction of "thrashing" behavior, given the current state. This can be viewed as a dynamic portfolio, but all its components are fixed, designed based on a priori expertise.</p><p>In anytime algorithm monitoring <ref type="bibr" target="#b25">[26]</ref>, the dynamic performance profile of a planning technique is updated according to its performance, in order to stop the planning phase when further improvements in the planned action sequence are not worth the time spent evaluating them. Also in this case, both the quality of a solution and its computational cost are taken into account.</p><p>In <ref type="bibr" target="#b72">[71]</ref>, the author presents a collection of ideas for solving sequences of timelimited optimisation problems by searching in a space of problem solving techniques, allocating time to them according to their probabilities, and updating the probabilities according to positive and negative results.</p><p>In a Reinforcement Learning <ref type="bibr" target="#b38">[38]</ref> setting, algorithm selection can be formulated as a Markov Decision Process: in <ref type="bibr" target="#b45">[44]</ref>, the algorithm set includes sequences of recursive algorithms, formed dynamically at run-time solving a sequential decision problem, and a variation of Q-learning is used to find a dynamic algorithm selection policy; in <ref type="bibr" target="#b59">[58,</ref><ref type="bibr" target="#b60">59]</ref>, from which we borrow some terminology, a set of deterministic algorithms is considered, and, under some limitations, static and dynamic schedules are obtained, based on dynamic programming. Success Story algorithms <ref type="bibr" target="#b70">[69]</ref> can undo policy modifications that did not improve the reward rate. A simple reinforcement learning feedback mechanism is used at runtime in <ref type="bibr" target="#b2">[3]</ref> to adapt the size of the prohibition list of a tabu-search algorithm.</p><p>Some dynamic selection methods are oblivious, i. e., are characterized by the absence of any knowledge transfer across problem instances.</p><p>The "parameterless GA" <ref type="bibr" target="#b26">[27]</ref> may be viewed as a specialized heuristic for dynamic selection. It consists of a sequence of simple generational Genetic Algorithms <ref type="bibr" target="#b27">[28]</ref>, with exponentially spaced population sizes, generated and executed according to a fixed interleaving schedule that assigns more runtime to smaller populations. Once a small population converges, or a larger one achieves a higher average fitness, the small one is discarded.</p><p>"Low-knowledge" approaches can be found in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">10]</ref>, in which various simple indicators of current solution improvement are used for algorithm selection, in order to achieve the best solution quality within a given time contract. In <ref type="bibr" target="#b3">[4]</ref>, all available algorithms are run for a fraction of the contract, and a performance predictor is then used to select a single one for the remaining time. In <ref type="bibr" target="#b9">[10]</ref>, the selection process is iterated: machine time shares are based on a recency-weighted average of performance improvements. This latter oblivious technique is actually a simple solver for time-varying bandit problems, here applied on a per instance basis.</p><p>In <ref type="bibr" target="#b20">[21]</ref> we adopted a similar approach. We considered algorithms with a scalar state, that had to reach a target value. The time to solution was estimated based on a shifting-window linear extrapolation of the learning curves: a recency-weighted average was tried at first, but its results were not competitive with the comparison term <ref type="bibr" target="#b26">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Algorithm survival analysis</head><p>This paper is focused on decision problems, in which a binary criterion for recognizing a solution is available. In this case, performance modeling aims at predicting the runtime, i. e., the time to solve a problem. More precisely, consider a randomized algorithm solving a given problem instance, or, equivalently, a randomized or deterministic algorithm solving a randomly selected problem instance. In both cases, the runtime spent before finding a solution can be treated as a random variable T, described by its cumulative distribution function (CDF),</p><formula xml:id="formula_0">F(t) = Pr{T ≤ t}, F : [0, ∞) → [0, 1],</formula><p>representing the probability that a solution is found within a time t. This function is referred to as the runtime distribution (RTD) in literature about algorithm performance modeling (see, e. g., <ref type="bibr" target="#b28">[29]</ref>).</p><p>A large corpus of research, known under the name of survival analysis<ref type="foot" target="#foot_3">3</ref>  <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b55">54]</ref>, is devoted to the modeling of events in time. In this section, we briefly review the basic concepts and terminology in these fields, and discuss their application to algorithm performance modeling.</p><p>We start by noting a difference between the events of interest in survival analysis, typically death, or failure, and problem solution: the latter does not necessarily have to happen. This can be described by a RTD with F(∞) &lt; 1. The resulting probability density function (pdf), defined as f (t) = dF(t)/dt, is improper, i. e., its integral over [0, ∞) does not sum to 1. In this situation, the expected runtime is ∞, and the usual formulation</p><formula xml:id="formula_1">E{T} = ∞ 0 t f (t)dt</formula><p>(1) cannot be applied. A quantile t α of a the RTD, defined as the time at which F intercepts the value α, can still be evaluated, solving the equation</p><formula xml:id="formula_2">t α = F -1 (α), α ∈ [0, F(∞)]. (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>Lifetime distributions are often described in terms of the survival function</p><formula xml:id="formula_4">S(t) = 1 -F(t),<label>(3)</label></formula><p>representing, in our case, the probability that the algorithm is still "alive" and running at time t.</p><p>Another ubiquitous concept in survival analysis is the hazard function h(t), quantifying the instantaneous probability of occurrence of the event of interest at time t, given that it was not observed earlier:</p><formula xml:id="formula_5">h(t) = lim t→0 Pr{T ≤ t + t|T &gt; t} = f (t) 1 -F(t) = f (t) S(t) , (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>where f (t)/S(t) = f (t|T &gt; t) is the pdf conditioned on observed survival until time t. The integral of ( <ref type="formula" target="#formula_5">4</ref>) is termed cumulative hazard, and can be shown to have the following relationship with the survival function:</p><formula xml:id="formula_7">H(t) = t 0 h(τ )dτ = t 0 dF(τ ) S(τ ) = -ln S(t),<label>(5)</label></formula><p>or S(t) = exp(-H(t)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Censored sampling</head><p>A typical problem that survival analysts have to face is the incompleteness of the data. For example, in biostatistics and medicine, patients might "drop-out" a group of study: in this case, only a lower bound on their lifetime would be known. A sample containing incomplete data is referred to as a censored sample. In failure analysis <ref type="bibr" target="#b55">[54]</ref>, censoring is normally the result of experimenter's decisions, aimed at reducing the duration of an experiment. For example, in estimating a duration model of a newly produced light bulb, an engineer could leave a large number of prototypes turned on for a predetermined period of time (type I censored sampling): in this case the number of observed failures is a random variable, related to the lifetime distribution of the bulbs. As an alternative, the experiment could end as soon as a predetermined number of bulbs has gone off (type II censored sampling). In this case, the duration of the experiment is a random variable. In both cases, only a lower bound on failure time would be available for the surviving bulbs. Unless the engineer is willing to wait for years, or the new product is quite cheap, this incomplete data will constitute a large portion of the collected sample. The precision of the model would clearly be affected. In other words, there is a trade-off between the duration of the experiment, and the precision of the obtained model: in any case, discarding incomplete data can result in an extremely biased model. In algorithm performance modeling, type I censoring is typically performed, imposing a threshold on runtime. Also in this case there is a trade-off between training time and model precision. In the context of algorithm selection techniques, this trade-off should rather be measured between training time and the gain in performance resulting from the use of the learned model: in this sense, the required precision can be much lower than expected. We give an example in <ref type="bibr" target="#b18">[19]</ref> where this trade-off is analyzed in the context of restart strategies, reporting the training times, and resulting performance, of model-based restart strategies, learned with different levels of censoring.</p><p>The treatment of censored data differs in the parametric and non-parametric settings. When fitting a parametric model f (t|θ), a censored runtime t c can be taken into account by expressing the likelihood of the parameter θ, given this piece of data, as the survival probability at time t c .</p><formula xml:id="formula_8">L c (t c |θ) = ∞ tc f (τ |θ)dτ = [1 -F(t c |θ)] = S(t c |θ).<label>(6)</label></formula><p>In nonparametric methods <ref type="bibr" target="#b41">[41,</ref><ref type="bibr" target="#b73">72]</ref>, estimates are based solely on the data observed so far. The simplest nonparametric method is the empirical CDF,</p><formula xml:id="formula_9">F(t) = ti&lt;t 1 n . (<label>7</label></formula><formula xml:id="formula_10">)</formula><p>In this setting, censored samples can be taken into account by distinguishing between the number of events recorded, and the number of individuals observed "at risk" (in our case: still running), at a time t. This is the essence of the Kaplan-Meier estimator of the hazard function <ref type="bibr" target="#b39">[39]</ref>:</p><formula xml:id="formula_11">ĥ(t) = ti=t,νi=1 1 ti≥t 1 , (<label>8</label></formula><formula xml:id="formula_12">)</formula><p>where ν i is the event indicator, and is 1 for uncensored observations, and 0 for censored ones. In these and other nonparametric methods, F(t), S(t), H(t) are "stepwise" functions, that change only at uncensored observations {t i |ν i = 1}, and are defined until the largest one; while f (t), h(t) are pulse trains, i. e., are 0 everywhere, but with a positive integral across the observation values t i . For example, a non-parametric hazard function can be represented as h(t) = i h i δ(tt i ), where h i is the hazard (8) at t i , and the corresponding cumulative hazard function is H(t) = ti&lt;t h i . In order to obtain meaningful predictions also for t / ∈ {t i }, hazard or density estimates can be smoothed <ref type="bibr" target="#b77">[76]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Conditional models</head><p>Conditional estimates <ref type="bibr" target="#b4">[5]</ref> take into account covariate or feature values x for each individual. If dynamic information about the algorithm is also available, this can be treated as a time-varying covariate, or longitudinal data <ref type="bibr" target="#b43">[43,</ref><ref type="bibr" target="#b50">49,</ref><ref type="bibr" target="#b56">55]</ref>, to update an estimated RTD. The simplest time-varying covariate is time itself: if an algorithm is still running at a time y, the RTD for the rest of the run can be evaluated by simply shifting and scaling the original</p><formula xml:id="formula_13">F F(t|T &gt; y) = F(t) -F(y) 1 -F(y) = F(t) -F(y) S(y) , (<label>9</label></formula><formula xml:id="formula_14">)</formula><p>defined only for t &gt; y. Given the definition of the hazard function ( <ref type="formula" target="#formula_5">4</ref>), its formula does not change, while the cumulative hazard becomes:</p><formula xml:id="formula_15">H(t|T &gt; y) = t y h(τ )dτ. (<label>10</label></formula><formula xml:id="formula_16">)</formula><p>Both cases can be represented in the non-parametric setting, simply discarding hazard values h i with t i ≤ y.</p><p>In the next section, we will apply the simple notions described here, to propose different optimisation criteria for a static algorithm portfolio. Literature on survival analysis is obviously much richer than this. Recent research is facing challenging applications, and developing advanced estimation techniques, with Bayesian methods playing a major role <ref type="bibr" target="#b36">[36]</ref>. For example, biostatisticians working on gene expression data <ref type="bibr" target="#b51">[50]</ref> have to deal with thousands of time-varying covariates, and often very small and censored samples. Both algorithm performance modeling, and modelbased algorithm selection, can profit from this field of research: for selection, also the computational complexity of modeling should be taken into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Static algorithm portfolios</head><p>Consider now a portfolio of K algorithms A = {a 1 , a 2 , ..., a K }, solving the same problem instance in parallel, and sharing the computational resources of a single machine according to a share s = {s 1 , .., s K }, s k ≥ 0, K i=1 s k = 1, i. e., for any amount t of machine time, a portion t k = s k t will be allocated<ref type="foot" target="#foot_4">4</ref> to a k . An a k that can solve the problem in a time t k if run alone, will spend a time t = t k /s k if run with a share s k . If the runtime distribution F k (t k ) of a k on the current problem is available, one can obtain the distribution F k,sk (t) of the event "a k solved the problem after a time t, using a share s k ", by simply substituting</p><formula xml:id="formula_17">t k = s k t in F k : F k,sk (t) = F k (s k t). (<label>11</label></formula><formula xml:id="formula_18">)</formula><p>If the execution of all the algorithms is stopped as soon as one of them solves the problem, as in Type II censored sampling (Section 3), the resulting duration of the solution process is a random variable, representing the runtime of the parallel portfolio. Its distribution F A,s (t) can be evaluated based on the share s, and the {F k }. The evaluation is more intuitive if we reason in terms of the survival distribution: at a given time t, the probability S A,s (t) of not having obtained a solution is equal to the joint probability that no single algorithm a k has obtained a solution within its time share s k t. Assuming that the solution events are independent for each a i , this joint probability can be evaluated as the product of the individual survival functions</p><formula xml:id="formula_19">S k (s k t) S A,s (t) = K k=1 S k (s k t), (<label>12</label></formula><formula xml:id="formula_20">)</formula><p>or, in CDF form:</p><formula xml:id="formula_21">F A,s (t) = 1 - K k=1 [1 -F k (s k t)]. (<label>13</label></formula><formula xml:id="formula_22">)</formula><p>Given ( <ref type="formula" target="#formula_7">5</ref>), ( <ref type="formula" target="#formula_19">12</ref>) has an elegant representation in terms of the cumulative hazard function<ref type="foot" target="#foot_5">5</ref> </p><formula xml:id="formula_23">H A,s (t) = -ln(S A,s (t)) = K i=1 -ln(S k (s k t)) = K i=1 H k (s k t). (<label>14</label></formula><formula xml:id="formula_24">)</formula><p>Algorithm selection can be represented in this framework by setting a single s k value to 1, while a uniform algorithm portfolio would have s = s U = (1/K, ..., 1/K). If the distributions F k are available, other alternatives can be implemented. One naive approach could consist in evaluating, for each a k , the probability that it will be the fastest, and using this value as the corresponding s k = Pr{T k &lt; T j =k }. This would only have a good performance if there is one algorithm in the set that greatly dominates the others. Otherwise, this method would share resources among similarly performing algorithms, resulting in a poor performance. In <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b20">21]</ref>, we mapped runtime predictions to s values based on an heuristic "ranking" approach, in which the rth expected fastest solver would get a share 2 -r . Here we propose three different analytic approaches, based on function optimisation. </p><formula xml:id="formula_25">s = arg min s S A,s (t u ). (<label>16</label></formula><formula xml:id="formula_26">)</formula><p>3. Quantile. In other applications, one could want to solve the problem with probability at least α, and minimize execution time. In this case, a quantile t A,s (α) = F -1 A,s (α) should be minimized:</p><formula xml:id="formula_27">s = arg min s F -1 A,s (α). (<label>17</label></formula><formula xml:id="formula_28">)</formula><p>If the F k are parametric, a gradient of the above quantities could be computed analytically, depending on the particular parametric form: otherwise, the optimisation can be performed numerically. Note that the shares s resulting from these three optimisation processes could differ: in the last two cases, they could also depend on the chosen values for t u and α respectively. In no case is there a guarantee of unimodality, and it might be advisable to repeat the optimisation process multiple times, with different random initial values for s, in case of extreme multimodality.</p><p>A choice among the three alternatives, as well as the choice of the relative parameters, might be imposed by the particular application, or left open as a design decision. We will postpone its discussion, and conclude this section remarking that the methods described here all rely on the assumption of independence of the runtime values among the different algorithms, which allows to express the joint probability (12) as a product. This assumption is met only if the F k represent the runtime distributions of the a k on the particular problem instance being solved. If instead the only F k available capture the behavior of the algorithms on a set of instances, which includes the current one, independence cannot be assumed: in this case, the methods presented should be viewed as approximations. In a less pessimistic scenario, one could have access to models M of the F k conditioned on features, or covariates, x of the current problem. In such a case the conditional independence of the runtime values would be sufficient, and the resulting joint survival probability could still be evaluated as a product</p><formula xml:id="formula_29">S A,s (t|x) = K i=1 S k (s k t|x). (<label>18</label></formula><formula xml:id="formula_30">)</formula><p>In practice, such a model is usually not available, and has to be estimated. The degree of approximation implied by assumption <ref type="bibr" target="#b17">(18)</ref> will depend on the fit of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">A continually learning dynamic portfolio</head><p>Let us now focus on the second of the issues mentioned in the introduction, namely, the difficulty of static runtime predictions. It is intuitive that re-evaluating s periodically could improve the performance, especially if the runtime values are spread on a large range. To be effective, this evaluation has to be based on a model M of the RTD conditioned also on the current state x k of each algorithm: in the simplest setting, one can always consider the time spent y k as the current state information, updating each F k as in <ref type="bibr" target="#b8">(9)</ref>.</p><p>A dynamic algorithm portfolio (Algorithm 1) can be implemented by reevaluating s periodically, each time based on F k conditioned on the current state information, and time already spent. Any of the three methods presented in Section 4 could be used as a time allocator TA to update s. An additional design decision would be required to set the sequence of time intervals t. Note also that in (Alg. 1) it is assumed that, for each incoming problem instance, there is at least one a k that can solve it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Dynamic algorithm portfolio</head><p>Algorithm set</p><formula xml:id="formula_31">A = {a 1 , ..., a K } Model M while problem not solved do update F k (t k ) := M(t k |x k , y k ) for k = 1, ..., K update t update s := TA({F k })</formula><p>run A with share s for a maximum time t end while</p><p>The conditional model M is usually not available, and would have to be estimated from experimental data. A straightforward application of the machine learning paradigm would require solving, with each algorithm, the same sequence of "training" problem instances, in order to collect a sufficient amount of runtime data. This approach would share the third issue mentioned in the introduction with other algorithm selection techniques: a huge amount of time would be spent solving the same training problems over and over again, in order to gather a sufficiently large amount of data.</p><p>A first idea for reducing training time is inspired by censored sampling techniques. As the engineers do with the light bulbs, we could run our portfolio with a uniform share s U = (1/K, 1/K, ..., 1/K) on each training problem instance, and instead of waiting for all the algorithms to end, we could stop after the first few solve the problem, and switch to the next. As said in Section 3, this would have an impact on the accuracy of the model, but the uniform share would at least assure that the fastest algorithm(s) would not be censored. In this way the model would be less accurate for less efficient algorithm/problem combinations. The downside of the uniform share, is that it would still have a huge overhead on performance. <ref type="foot" target="#foot_6">6</ref>Another speed-up could be obtained using a partially trained model to guide further training. There might be good algorithm/problem combinations that are easy to learn, and bad ones that are easy to avoid. Instead of keeping a uniform s U throughout the training sequence, we could periodically train the model M during the sequence, and run our static or dynamic portfolio of choice on the remaining training problems "mixing" the output of the chosen time allocator s M = TA(M), with the uniform s U , as</p><formula xml:id="formula_32">s = p M s M + (1 -p M )s U ; the mixing coefficient p M ∈ [0, 1]</formula><p>could be increased each time the model is updated. This would be more dangerous, as we would loose the positive effect of s U , and risk of censoring the fastest algorithm. It is intuitive that, if p M is increased too quickly, and the initial portion of the training sequence is somehow deceptive, an initially imprecise model could cause more time to be allocated to less efficient algorithms, and the execution of the fastest algorithms to be censored, thus reinforcing its own mistakes.</p><p>We are facing a trade-off between exploration of the performance of the various a k , and exploitation of the model obtained so far. In <ref type="bibr" target="#b16">[17]</ref>, we addressed this tradeoff heuristically, updating the model after each task solution, and gradually shifting through the problem sequence, from a uniform initial share to a model-based share, again heuristically evaluated. In the following section, we will treat this trade-off in the context of bandit problems with expert advice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Time allocation as a bandit problem</head><p>In its most basic form <ref type="bibr" target="#b65">[64]</ref>, the multi-armed bandit problem is faced by a gambler, playing a sequence of trials against a K-armed slot machine. At each trial, the gambler chooses one of the available arms, whose rewards are randomly generated from different stationary distributions. The gambler can then receive the corresponding reward r k , and, in the full information game, observe the rewards that he would have gained pulling any of the other arms. The aim of the game is to minimize the regret R, defined as the difference between the cumulative reward of the best arm, and the one earned by the gambler G R = max</p><formula xml:id="formula_33">k j x k ( j ) -G. (<label>19</label></formula><formula xml:id="formula_34">)</formula><p>A bandit problem solver (BPS) can be described as a mapping from the history of the observed rewards r k ∈ [0, 1] for each arm k, to a probability distribution p = ( p 1 , ..., p K ), from which the choice for the successive trial will be picked.</p><p>In recent works, the original restricting assumptions have been progressively relaxed, allowing for non-stationary reward distributions, partial information (only the reward for the pulled arm is observed), and adversarial bandits, that can set their rewards in order to deceive the player. In <ref type="bibr" target="#b0">[1]</ref>, no statistical assumptions are made about the process generating the rewards, which are allowed to be an arbitrary function of the entire history of the game (non-oblivious adversarial setting). Based on these pessimistic hypotheses, the authors describe probabilistic gambling strategies for the full and the partial information games, proving interesting bounds on the expected value of the regret.</p><p>Assuming that all a k can solve all problem instances, it is straightforward to describe static algorithm selection in a K-armed bandit setting, where "pick arm k" means "run algorithm a k on next problem instance." The reward for this game could be set based on the runtime of the chosen algorithm, for example as r k := 1/t k ; alternatively, runtime t k could represent a loss, to be minimized. The information would be partial: the runtime for other algorithms would not be available. The rewards would be generated by a rather complex mechanism, i.e., the algorithms a k themselves, so the bandit problem would fall into the adversarial setting. As BPS typically minimize the regret with respect to a single arm, this approach would only allow to implement per set selection, of the overall best algorithm.</p><p>To avoid excessively long t k , machine time could be subdivided into arbitrarily small intervals δt: "pick arm k" would mean "resume algorithm a k on current problem instance, for a time δt, then pause it." Reward could be attributed r k := 1/t k as before, t k being the total runtime of the winning algorithm. Information would again be partial: more precisely, in this case it would be censored, as a lower bound on performance, and a corresponding upper bound on reward, would be available for the other algorithms. The bandit would be a non-oblivious adversary, as the result of each arm pull would depend on previous pulls of the same arm.</p><p>On a large number of arm pulls, the expected value of time spent executing a k would be proportional to p k . And, typically, bounds on regret for a BPS are proved based on expected values. The game described above is then equivalent to a static portfolio, using the p of the BPS as the share value s, and updating it after a problem instance is solved. Again, the resulting selection technique is static, per set, <ref type="foot" target="#foot_7">7</ref> only profitable if one of the algorithms dominates the others on all problem instances.</p><p>A less restrictive, and more interesting hypothesis, is that there is one of a set of time allocators, whose performance dominates the others. At this higher level, one could use a BPS to select among different static time allocators, TA (1) , TA (2) ,..., working on a same algorithm set A. In this case, "pick arm n" would mean "use time allocator TA (n) on A to solve next problem instance." In the long term, the BPS would allow to select, on a per set basis, the TA (n) that is best at allocating time to algorithms in A on a per instance basis. If the BPS allows for time-varying reward distributions, it could also deal with time allocators that are learning to allocate time.</p><p>A more refined alternative is suggested by the bandit problem with expert advice, as described in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Two games are going on on parallel: at a lower level, a partial information game is played, based on the probability distribution obtained mixing the advice of different experts, represented as probability distributions on the K available arms. The experts can be arbitrary functions, and give a different advice for each trial. At a higher level, a full information game is played, with the N experts playing the roles of the different arms. The probability distribution p at this level is not used to pick a single expert, but to mix their advices, in order to generate the distribution for the lower level game. In <ref type="bibr" target="#b0">[1]</ref>, Auer et al. propose an algorithm called Exp4 (Alg. 2) to play this two-level game. Exp4 is a combination of the algorithms for the full and the partial information setting. It features a fixed lower bound γ on the exploration probability, which can be set, based on the total number of trials M, in order to obtain a bound on the expected regret relative to the performance of the best expert: pick arm k with probability</p><formula xml:id="formula_35">E(R) ≤ 2.63 √ MK ln N. (<label>20</label></formula><formula xml:id="formula_36">s k := (1 -γ ) N n=1 p n s (n) k + γ /K 8: observe reward r k ∈ [0, 1] 9:</formula><p>set rk := r k / p k 10:</p><p>update</p><formula xml:id="formula_37">w n := w n exp(γ s (n) k rk /K) for n = 1, ..</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>., N 11: end for</head><p>The original formulation is based on a finite upper bound on the cumulative reward of the best expert, which is at most M if each reward is in [0, 1]. A variant of the algorithm is proposed if M is unknown, or if the rewards are much smaller than 1. Bound <ref type="bibr" target="#b19">(20)</ref> requires that the uniform expert s = (1/K, ..., 1/K) is included in the set.</p><p>In our case, the time allocators play the role of the experts, each suggesting a different s, on a per instance basis; and the arms of the lower level game are the K algorithms, to be run in parallel with the mixture share. The partial information on the reward at the lower level (based on the runtime of the a k first to solution) is translated into full information at the upper level, based on the s (n) proposed by each TA (n) .</p><p>Before prosecuting, we need to decide how to attribute the rewards. Ideally, we would like Exp4 to select the time allocator that is better at giving more time to the fastest algorithms. As we cannot know the real fastest algorithm, one good idea could be to reward minimization of solution time, setting r k ∝ 1/t k . One possible side effect of this choice could be that, for problem sequences on which runtimes vary of different order of magnitudes, the rewards for the harder problems would be much lower than the ones for the easy ones. We will then adopt a logarithmic reward attribution, as in <ref type="bibr" target="#b19">[20]</ref>. As Exp4 requires normalized rewards, we can set lower and upper bounds t min , t max on runtime, and set the reward for the winning algorithm a k as</p><formula xml:id="formula_38">r k = ln t max -ln t k ln t max -ln t min . (<label>21</label></formula><formula xml:id="formula_39">)</formula><p>This reward will be then distributed by Exp4 to the time allocators, based on how much time they allocated to a k . The extension to dynamic time allocators (Alg. 1) is straightforward: in this case the s (n) would depend, for each allocator, on the sequence of intervals t(0), t(1), ..., and the corresponding s proposed during each interval, and the normalized value of j s (n) ( j ) t( j ) would be used in place of s (n)  at line 10 of Alg. 2.</p><p>We can then use Exp4 to address the exploration-exploitation trade-off that we left open in the last section. We can solve each problem in the training sequence mixing the uniform s U , and the s M evaluated by the model-based allocator, using the current output p of Exp4 as a mixing coefficient. In this way Exp4 would detect when the model is ready to use, and starts gaining a better performance than the uniform allocator. After each instance is solved, we can also update Exp4.</p><p>The regret rate ( <ref type="formula" target="#formula_35">20</ref>) is particularly interesting, as it depends on the logarithm of the number of experts N. We can exploit this fact to take the design decision that we left open in Section 4, namely, which allocator function to use: we can leave this decision to Exp4, picking a redundant set of time allocators. We can also try different values for the respective parameters. Note that all these allocators can share a common model M, so the computational overhead would depend on the cost of the time allocators alone. The resulting "gambling" time allocator (GambleTA) is described in Alg. 3.</p><p>Using a non-uniform share, there is no guarantee that the winner algorithm will be the actual fastest, so our reward scheme could be deceptive. The sequence of tasks can also be deceptive, and again cause the model to reinforce its own mistakes. All this is allowed in the pessimistic settings of Exp4, which will still guarantee that the expected regret, compared to the gain of the best time allocator, is bounded by <ref type="bibr" target="#b19">(20)</ref>.</p><p>This optimal regret is defined with respect to the best allocator. Nothing can be said about the performance w.r.t. the best algorithm. In a worst-case setting, if none of the time allocator learns anything, Exp4 will give most credit to the uniform share, which gains a reward rk /K at every trial. We will now see two example applications on which the performance of GambleTA is quite far from this pessimistic scenario. for each time allocator TA (1) , ..., TA (N) </p><formula xml:id="formula_40">do 11: update s (n) = TA (n) (M), s (n) ∈ [0, 1] K 12:</formula><p>end for <ref type="bibr">13:</ref> evaluate mix s = N n=1 p n s (n)   14:</p><p>run A with share s, for a maximum time t We present two experiments, both with very small algorithm sets (K = 2), but long, and challenging, problem sequences. The first experiment features a complete and a local search SAT solver, dealing with a mixed set of CNF3 SAT instances at the sat-unsat threshold. The second experiment features solvers for a published Auction Winner Determination Problem (WDP) benchmark <ref type="bibr" target="#b46">[45]</ref>.</p><p>Before proceeding, we will describe the remaining details of our time allocation algorithm. As said, we use Exp4 <ref type="bibr" target="#b0">[1]</ref> at the top level, to mix the share decisions s (n)  of different time allocators TA (n) (Alg. 3). No care was put in selecting the set of time allocators, as Exp4 is better at this game. The set included (see Section 4 for a description):</p><p>-The uniform time allocator, with share s = (1/K, ..., 1/K), required by Exp4.</p><p>-A set of nine quantile minimizers , s = arg min s F -1 A,s (α), with equally spaced values for the parameter α (0.1, 0.2, ..., 0.9).</p><p>-A "greedy" contract allocator, using the next time limit as a contract: s = arg min s S A,s ( t + K k=1 y k ), y k being the time spent so far by a k .</p><p>Each experiment was repeated using each one of the allocators, always accompanied by the uniform, but none of them could improve on the performance of the ensemble. Exp4 preferred different time allocators on the two benchmarks, but always discarded the quantile allocators with α ≥ 0.5.</p><p>The sequence of time intervals t employed by the dynamic portfolio was exponential, with base two. ( t 0 ,2 t 0 ,4 t 0 ,...). We set the initial t 0 to two different values for the two experiments. Also t min was different for the two benchmarks, while t max was kept fixed at 10 10 .</p><p>As a model, we used the conditional non-parametric hazard estimator ( ĥ(t|x)) by Wichert and Wilke (WW in the following) <ref type="bibr" target="#b78">[77]</ref>. This model is conceptually simple, and computationally efficient. As most non-parametric methods, it stores all the training data (x i , t i ): the time values t i of censored and uncensored events, and the covariates x i , evaluating an empirical CDF (7) F x (x) of the covariate value x. In order to predict the hazard function for an unseen value x of the covariate, it first estimates its CDF value F x (x), by simply evaluating its rank in the sorted list of covariates. The probability F x (x) is then compared to the F x (x i ) of each sample (again obtained from the rank), through a kernel function K, with bandwidth parameter b n , and the value of K((F x (x) -F x (x i ))/b n ) is used to weight the event t i . The weight values are used in place of "1" in <ref type="bibr" target="#b7">(8)</ref>, to evaluate a Kaplan-Meier estimate of the hazard for the covariate x:</p><formula xml:id="formula_41">ĥ(t|x) = ti=t,νi=1 K F(x)-F(xi) bn ti≥t K F(x)-F(xi) bn . (<label>22</label></formula><formula xml:id="formula_42">)</formula><p>If the covariates are multidimensional, the process is repeated for each dimension, and the products of the resulting kernel distances are used as weights. In short, <ref type="bibr" target="#b21">(22)</ref> performs a nearest neighbor estimate of the hazard: the kernel distance is measured on the distribution of covariate values, and is not sensitive to scaling. The kernel function K is required to be symmetric around 0, and integrate to 1. We used a uniform kernel (0.5 on [-1, 1], and 0 elsewhere), which is a common choice in non-parametric statistics. The convergence proof for the estimator requires the bandwidth parameter b n to be set based on the size n of the stored sample, as b n ∈ [n -1/2 , n -1/4 ]. We present results for b n = n -1/4 , which provides the widest allowed kernel.</p><p>A separate model was learned for each algorithm, using a small set of problem specific features as covariates. 8 The only dynamic feature taken into account was the time spent y k , as in <ref type="bibr" target="#b8">(9,</ref><ref type="bibr" target="#b9">10)</ref>, which, in the non-parametric setting, simply consists in discarding hazard values h j with t j ≤ y k . The RTD of the portfolio was evaluated based on the cumulative hazard 9 form <ref type="bibr" target="#b13">(14)</ref>. The time allocators described in Section 4 8 As the two algorithms are in both cases not related. For different parametrizations of the same algorithm, a single model can be used, conditioned also on parameter values. 9 The model (WW) outputs, for a given covariate x, two vectors, one of event times {t i }, one of the corresponding hazard estimates {h i }. Based on this data, a vector of hazard values for the algorithm running with share s k has first to be evaluated. Note that the derivative of H(s k t) would be s k h(s k t), but in the nonparametric setting the h i are pulses, not point values: scaling them by s k would not be correct. To see why, consider that the cumulative hazard at H(∞) should not vary by scaling time, so the integral across the scaled time values must remain the same. Only time has to be dilated, dividing the time values t i by the s k chosen by GambleTA. Hazard values relative to different algorithms are then merged, sorting the resulting list according to time values. The cumulative hazard <ref type="bibr" target="#b13">(14)</ref> can finally be evaluated, as the cumulative sum of the resulting hazard values. This value is used by two different functions, evaluating the quantile (3) and survival probability at the next contract (2), based on the survival function obtained from <ref type="bibr" target="#b4">(5)</ref>. These last two functions are passed as arguments to the Matlab function fminbnd, to be minimized.</p><p>were evaluated numerically, using a line search routine (see note 9), careless of multimodality: on runs that were monitored, we observed multimodality only for high levels of the parameters α or t u , for which the performance of the time allocators was poor anyway.</p><p>We repeated both experiments 50 times, each time with a different random reordering of the problem instances, and a different random seed for the algorithms, if randomized. Unless otherwise stated, all results reported are 95% confidence bounds, evaluated on 50 runs. For both experiments, the parallel execution of the algorithms was simulated, using stored runtime data; <ref type="foot" target="#foot_8">10</ref> the time values reported only include the algorithm runtimes. <ref type="foot" target="#foot_9">11</ref>We assess the performance of GambleTA by comparing it with the uniform time allocator s U = (1/K, ..., 1/K) alone; and the one of an oracle, with foresight of the runtime values, which only executes, for each problem instance, the algorithm that will be fastest. If t G ( j ) is the runtime of our time allocator on problem instance j, t k ( j ) is the runtime of algorithm a k , then t O ( j ) = min k {t k ( j )} is the runtime of the oracle, and t U = Kt O is the runtime of the uniform share. We will describe the performance of the allocator until task m reporting the cumulative time m j=1 t G ( j ), and the cumulative overhead</p><formula xml:id="formula_43">m j=1 t G ( j ) -t O ( j ) m j=1 t O ( j ) , (<label>23</label></formula><formula xml:id="formula_44">)</formula><p>relative to the performance of the oracle. These are fair performance indicators, also for a per instance selection technique, but do not capture the performance on a single instance. Plotting this information averaged on multiple runs is problematic, as the order of the instances is different for every run, and in both benchmarks the runtimes may differ of several orders of magnitude. We will then plot the performance on each instance, and for each run, against the runtime of the oracle, and the uniform share.</p><p>To underline the improvement during the problem sequence, we will also report separate statistics for the first and second halves of the two problem sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Satisfiability problems</head><p>Satisfiability (SAT) problems <ref type="bibr" target="#b21">[22]</ref> constitute a standard benchmark in AI. A conjunctive normal form CNF(k,n,m) problem consists in finding an instantiation of a set of n Boolean variables that simultaneously satisfies a set of m clauses, each being the logical OR of k literals, chosen from the set of variables and their negations. A problem instance is termed satisfiable (SAT) is there exists at least one of such instantiations, otherwise it is unsatisfiable (UNSAT). An instance is considered solved if a single solution is found, or if unsatisfiability is proved. With k = 3 the problem is NP-complete. Satisfiability of an instance depends in probability on the clauses to variables ratio: a phase transition <ref type="bibr" target="#b53">[52]</ref> can be observed at m/n ≈ 4.3, at which an instance is satisfiable with probability 0.5. This probability quickly goes to 0 for m/n above the threshold, and to 1 below. SAT solvers can be broadly classified in two categories: complete solvers, that execute a backtrack search on the tree of possible variable instantiations, and are guaranteed to determine the satisfiability of a problem in a finite, but possibly unfeasibly high, amount of time; and local search (LS) solvers, that cannot prove unsatisfiability, but are usually faster than complete solvers on satisfiable problems. In other words, a local search solver can only be applied to satisfiable instances: at the threshold, there is a 0.5 probability that the solver will run forever. The RTD of a complete solver will have F(∞) = 1 with a finite 1 quantile, for any value of m/n; while a local search solver has a F(∞) = 0.5 on instances at the 4.3 threshold. Users of LS interested in such benchmarks have then to first filter out unsatisfiable instances by running a complete solver, in order to test the local search algorithm on SAT instances only. This means that, at the phase transition, local search implies an additional cost, equal to the performance of a complete solver, which obviously does not make it competitive for such problem instances.</p><p>Our first experiment was performed using a portfolio of two SAT solvers from the two categories above. As a benchmark, we used the complete set of uf-n-m and uuf-n-m instances from SATLIB <ref type="bibr" target="#b29">[30]</ref>. These are randomly generated instances at the phase transition, with n ranging from 20 (resp. 50 for the unsat) to 250, 100 instances for each size, and m varying accordingly. The instances are subdivided in groups of satisfiable (uf * ) and unsatisfiable (uuf * ) instances. We merged all groups in a single sequence, of 1, 899 problems<ref type="foot" target="#foot_10">12</ref> in total, that was randomly re-ordered for each run of the experiment.</p><p>As a complete solver we picked Satz-Rand <ref type="bibr" target="#b24">[25]</ref>, a version of Satz <ref type="bibr" target="#b48">[47]</ref> in which random noise influences the choice of the branching variable. Satz is a modified version of the complete DPLL procedure, in which the choice of the variable on which to branch next follows an heuristic ordering, based on first and second level unit propagation. Satz-Rand differs in that, after the list is formed, the next variable to branch on is randomly picked among the top h fraction of the list. We present Fig. <ref type="figure">1</ref> SAT-UNSAT problems. These plots illustrate the functioning of the Contract (2) and Quantile (3) time allocators (Section 4), and are not generated from a run of GambleTA, but from a RTD estimate on problems of size n = 250 only. Left column: situation at t = 0. Right column: after t = 10 7 of uniform parallel run (5 × 10 6 for each algorithm). Top: RTD of the single algorithms, and of the uniform share. Middle: survival probability S A,s (t u ) (vertical axis) at a time contract t u , for different values of the share s 1 assigned to Satz-Rand (horizontal axis), and different values of the time contract t u (different lines). Bottom: quantiles of runtime for different values of α (different lines), and different values of time share allocated to Satz-Rand (horizontal axis). The minimum of each line in (b, c, e, f) is the share allocation decided by the corresponding TA results with the heuristic starting from the most constrained variables, as suggested also in <ref type="bibr" target="#b48">[47]</ref>, noise parameter set to 0.4, and the restart mechanism disabled, as the RTD of the algorithm does not display heavy-tailed behavior <ref type="bibr" target="#b24">[25]</ref> for this n/m ratio. As a local search solver we used G2-WSAT <ref type="bibr" target="#b49">[48]</ref>: for this algorithm, we set a high noise parameter (0.5), as advisable for problems at the phase threshold, and the diversification probability at the default 0.05. As both solvers are randomized, we also used a different random seed for each run.</p><p>As we needed a common measure of time, and the CPU runtime measures are quite inaccurate (see also <ref type="bibr" target="#b28">[29]</ref>, p. 169), we modified the original code of the two algorithms adding a counter, that is incremented at every loop in the code. The resulting time measure was consistent with the number of backtracks, for Satz-Rand, and the number of flips, for G2-WSAT. All runtimes reported for this benchmark are expressed in these loop cycles: on a 2.4 GHz machine, 10 9 cycles take about 1 min.</p><p>The only feature used for the model WW was n, the number of variables in the SAT problem, as the clauses-to-variable ratio m/n is practically constant. t 0 and t min where both set to 10 4 , the order of magnitude of the initialization cost of both algorithms on the smallest problem size.</p><p>This algorithm set/problem set combination is quite interesting. G2-WSAT almost always dominates the performance of Satz-Rand on satisfiable instances, while the latter is obviously the winner on all unsatisfiable ones, on which the runtime of G2-WSAT is infinite.</p><p>This situation is visualized in Fig. <ref type="figure">1a</ref>, which plots the empirical CDF of the runtimes for the two solvers, resulting from an estimate for a single random seed, on the two sets of larger instances (uf-250, uuf-250). One can clearly notice the advantage of G2-WSAT on satisfiable instances, represented by the small lower quantiles (below 10 6 ). From quantile 0.5 on, the RTD remains flat, reflecting the fact that half of the instances are unsatisfiable. Satz-Rand starts solving problems later, and is competitive with G2-WSAT only on a small number of satisfiable instances, but is able to solve also all the unsatisfiable ones, as indicated by the fact that the RTD reaches 1, i.e., the quantile t 1 is finite. The third line in the plot, labeled "uniform," represents the RTD of the uniform portfolio s U = (0.5, 0.5).</p><p>Algorithm selection would be easy in this case, if not for the fact that the satisfiability of an instance cannot be predicted in any way, before attempting solution. As G2-WSAT is incomplete, any sensible single algorithm selection technique would select Satz-Rand on all problems. The performance of this algorithm alone is better than the one of the uniform share, but obviously worse than the performance of the oracle, as this latter can profit from its foresight, and solve SAT instances with G2-WSAT.</p><p>Figure <ref type="figure" target="#fig_0">2a</ref> displays the evolution of the cumulative time during the task sequence, comparing for each task i the cumulative performance of GambleTA j&lt;i t G ( j ) to the cumulative performance of the oracle j&lt;i t O ( j ), and of the uniform share s U (K j&lt;i t O ( j )). The performance of Satz-Rand is also plotted, as this algorithm can solve all the problems. Lines represent upper confidence bounds, evaluated on 50 runs.</p><p>Figure <ref type="figure" target="#fig_0">2b</ref> plots the cumulative overhead <ref type="bibr" target="#b22">(23)</ref> of GambleTA, during the problem sequence. Here the dotted lines represent upper and lower 95% confidence bounds. GambleTA is quite quick in converging to the final performance, and then seems to oscillate; averaged on 50 runs, it ends the problem sequence with a cumulative Fig. <ref type="figure" target="#fig_0">2</ref> SAT-UNSAT problems. a Cumulative time on the SAT-UNSAT problem set. Upper 95% confidence bounds on 50 runs, with random reordering of the problems. GambleTA is our time allocator. Oracle is the lower bound on performance. Uniform is the (0.5,0.5) share. Satz-Rand is the single algorithm. b Cumulative overhead <ref type="bibr" target="#b22">(23)</ref> on the SAT-UNSAT problem set. Upper and lower confidence limits. Right column: Performance of GambleTA compared to the oracle, on all problems and for all runs. 50 × 1, 899/2 = 47, 475 points per plot. c First half of the sequence. d Second half. The diagonal (not marked) is the performance of Oracle. The continuous line above the diagonal is the performance of Uniform. Note that this line is crossed by many runs, especially for runtimes around 10 6 . The biggest improvements in the second part of the sequence can be seen on very easy and very hard problems. See also Fig. <ref type="figure" target="#fig_1">3</ref>, and Table <ref type="table" target="#tab_0">1</ref> overhead of about 14%. Note that this figure includes the performance at the beginning of the sequence, when the model is still poorly trained.</p><p>Examining a single run, it can be observed that most of the allocators quickly learn to start solving each problem using the local search algorithm, and later switch to Satz-Rand if no solution is found by G2-WSAT.</p><p>As there are only two algorithms in the set, we can easily visualize the time allocators (see <ref type="bibr">Section 4)</ref>. Using the same data from Fig. <ref type="figure">1a</ref>, in Fig. <ref type="figure">1b</ref>, we plot the survival probability S A,s (t u ) (vertical axis) at a time contract t u , for different values of the share s 1 assigned to Satz-Rand (horizontal axis), and different values of the time contract t u (different lines). Figure <ref type="figure">1c</ref> displays an analogous plot for the quantile Fig. <ref type="figure" target="#fig_1">3</ref> SAT-UNSAT problems. Performance of GambleTA compared to the oracle, on all problems and for all runs, separated for SAT (left column: 50 × 1, 000/2 = 25, 000 points per plot) and UNSAT (right column: 50 × 899/2 = 22, 475 points per plot) problems. Top: first half of the sequence. Bottom: second half. Note that this distinction is unavailable to the algorithm: the data was filtered a posteriori from the data of Fig. <ref type="figure" target="#fig_0">2c,</ref><ref type="figure">d</ref>, and refers to the same experiment, with SAT and UNSAT instances randomly mixed. The order of problem instances is different for every run, so the same instance might be met at different stages of the learning process. The diagonal (not marked) is the performance of Oracle. The continuous line above the diagonal is the performance of Uniform. Note that this line is crossed by many runs, especially for SAT instances, for runtimes above 10 6 minimization method: this time the ordinates report the logarithm of the quantile t A,s (α) for the portfolio, and different lines correspond to different values of the required solution probability α.</p><p>You can notice that the optimum of s varies according to the parameter of the time allocator (see Section 4): for low values of the contract t u , and the quantile α, the optimum is at s 1 = 0, which means that only G2-WSAT is run, notwithstanding the 0.5 survival probability at ∞.</p><p>If both algorithms are run in parallel, for 10 7 loops in total, without solving the problem, we get the situation depicted in the right column of Fig. <ref type="figure">1</ref>. The RTD of the two algorithms have been shifted and scaled, as in <ref type="bibr" target="#b8">(9)</ref>, and the one of G2-WSAT has almost disappeared. Given the time already spent, there is only a very small probability that G2-WSAT will solve the problem. This situation is reflected in the plots of the contract (Fig. <ref type="figure">1e</ref>) and quantile (Fig. <ref type="figure">1f</ref>) allocators: now the optimum of the lines is at s 1 = 1 for all values of the parameters, except the smallest, which means that most allocators would only run Satz-Rand.</p><p>During the course of a run, Exp4 gradually selects a mixture of three quantile allocators, with small values for α (0.2, 0.3, 0.4). Note that the predictions of the WW model, and thus the decisions of the time allocators, are solely based on previously observed runs. The view of the time allocators is similar to the one in Fig. <ref type="figure">1</ref>: only, there 200 samples for each algorithm are available, for the same covariate (n = 250), and this results in a much smoother model than the one typically available during the initial part of the task sequence. The surfaces (in this case lines) optimised by the time allocators look smooth anyway, especially for low values of the parameters, but the contract allocator tends to look flat for large intervals of s 1 values.</p><p>The simple tactic found by GambleTA is not always effective, and can actually result in a performance much worse than the uniform share, on a single instance. We show this in Fig. <ref type="figure" target="#fig_0">2c,</ref><ref type="figure">d</ref>, where the runtimes of GambleTA are scatter-plotted against the one of the oracle, for all the 1, 899 instances, and all the 50 runs. The two plots only distinguish among instances met during the first half of the sequence, and the second: all other order information is lost. Note that, as the order of instances is picked randomly for each run, a same instance can figure in both plots: but it would represent two different runs, with different random seeds for the a k , and would likely map to different points. We did not plot the diagonal, which would be the performance of the oracle, as it would interfere with the data. The continuous line above the diagonal represents the performance of the uniform share t U = Kt O . There are many points above this line, which indicates a performance worse than uniform (WTU). The biggest improvement, from the first half (Fig. <ref type="figure" target="#fig_0">2c</ref>) to the second (Fig. <ref type="figure" target="#fig_0">2d</ref>), seems to be on really easy and really hard instances, with low and high runtimes respectively.</p><p>In order to further analyze this situation, in Fig. <ref type="figure" target="#fig_1">3</ref> we repeat the same scatter-plots using the same data, but distinguishing among satisfiable and unsatisfiable instances. It is now clear that the cloud of poor performance still visible in Fig. <ref type="figure" target="#fig_0">2d</ref> is entirely represented by satisfiable instances, on which the runtime of the fastest algorithm (probably G2-WSAT) is between 10 6 and 10 7 loops. We can now make an hypothesis: looking back at Fig. <ref type="figure">1a,</ref><ref type="figure">d</ref>, we see that this is the time range on which the runtime distributions of the two algorithms overlap (at least for n = 250 variables). In other words, the longest successful runs of G2-WSAT and the shortest ones of Satz-Rand are in this range. The surfaces of the time allocators will be similar to the ones in Fig. <ref type="figure">1e,</ref><ref type="figure">f</ref>.</p><p>In Table <ref type="table" target="#tab_0">1</ref> we display a few performance statistics, separately for the two halves of the task sequence. GTA labels the cumulative time of GambleTA, OR the one of the oracle. OVH represents the cumulative overhead <ref type="bibr" target="#b22">(23)</ref>, evaluated only on the respective half. WTU stands for "worse than uniform." It measures the fraction of task instances on which the performance is worse than the uniform t U = Kt O .</p><p>The first block in the table (SU) refers to the full set of instances, as solved by GambleTA. The second (S) and third (U) respectively refer to the satisfiable and unsatisfiable instances alone. We can see that, in terms of the number of instances, only on 11% of satisfiable instances a WTU performance is observed, but this is enough to give a very high overhead value: the overhead is actually slightly worse in the second half of the sequence. But we have to bear in mind that this situation results from a 6% of the total number of problems, on which the runtime of G2-WSAT is unusually long. GambleTA is willing to pay this price, in order to avoid running G2-WSAT for too long on a potentially unsatisfiable instance.</p><p>The performance is much better on the unsatisfiable instances, as they are characterized by much longer runtime values, and the overhead of trying G2-WSAT first is low. Here the WTU instances go down to less than one on a thousand, and the overhead at less than 9%. On the whole set, the performance for the second half is a 13% overhead, and less than 7% WTU. Due to the difficulty of the task, we do not expect more than a marginal improvement in the performance from the use of more sophisticated modeling techniques, or more features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Winner determination problem</head><p>The Auction Winner Determination Problem (WDP) <ref type="bibr" target="#b46">[45]</ref> is an interesting combinatorial optimisation problem, where a set of agents allocate money on n bids over m goods, and the winning subset of bids, that maximizes the sum of the amounts bidden, must be determined. The agents have limited amounts of money, and are allowed to specify XOR constraints over the bidden goods, and the selected winning subset has also to satisfy these constraints. The problem is NP-hard.</p><p>In <ref type="bibr" target="#b46">[45]</ref>, to which we refer for more details and references, the hardness of randomly generated WDP instances is modeled, describing the performance of a Linear Programming software (CPLEX), and an ad-hoc solver (CASS). The runtime of these solvers is related to 28 instance features, including the size (n,m), and serves as an input for a regression routine aimed at learning a predictive model of runtime value, conditioned on instance features. The performance of the models is assessed using mean squared error on the logarithm of predicted values, which suggests a parametric assumption of the run-time distribution being log-normal. Censored runtimes ("capped" runs in the terminology of the paper) are treated as the uncensored, and it is argued that the impact of this approximation on model precision is low. The resulting models are actually quite precise in terms of the proposed error measure. The performance of CPLEX dominates CASS, but on about 1/4 of the instances this situation is inverted. In such a case, a per set selection technique would always select CPLEX. As an interesting example application of these models, the authors propose a per instance algorithm selection technique, in which the expected fastest algorithm is picked based on the model's predictions. In the original paper, the model is trained on runtime data obtained by solving a large number of instances, censoring runs that exceed a predetermined threshold of 12 h for CASS. On a test set of unseen instances, the model performs efficient selection, detecting the instances on which CASS is faster, and allowing the portfolio to improve on the performance of CPLEX alone. The overhead <ref type="bibr" target="#b22">(23)</ref>, compared to the performance of the oracle, is reported to be 8%, excluding a small additional factor due to the cost of computing features.</p><p>The runtime data for the two algorithms were obtained online. <ref type="foot" target="#foot_11">13</ref> The data consists of various small fixed size problem sets, and one large variable size set. After discarding a few instances, for which the time values were censored for both algorithms, the variable size set has 7, 145 instances, and the fixed size sets sum to 3, 519, for a total of 10, 664 problems. On these, CASS dominates on 2, 278, while CPLEX is faster on the remaining 8, 386. None of the two algorithms could solve all the problems before capping. The runtimes of the whole data set sum to almost nine years.</p><p>We repeated the experiment with GambleTA, solving the whole set of instances. As the solvers are not randomized, here the only difference among runs is the random ordering of problem instances. The runtimes in the data set are reported in seconds. Some runs were indicated with a 0 runtime, which means that they were too fast for the granularity of the clock (0.01). In these cases, we replaced the 0 value with 0.001. We then set t min to 0.001, and left t max at 10 10 , which is oversized in this case, as the maximum runtime value in the set is 5 × 10 5 . The initial time interval was set as t 0 = 0.01. The model was allowed only two covariate values, the number of bids and the number of goods, representing the size of the problems.</p><p>Figure <ref type="figure" target="#fig_2">4a</ref>,b report the cumulative time during the task sequence, and the cumulative overhead, again comparing with the ideal performance of the oracle <ref type="bibr" target="#b22">(23)</ref>. The last block of Table <ref type="table" target="#tab_0">1</ref> reports the same performance indicators described in the  <ref type="formula" target="#formula_43">23</ref>) on the WDP problem set. Upper and lower confidence bounds. The overall final performance is 4%: in the second part only, the cumulative overhead is less than 3% (see Table <ref type="table" target="#tab_0">1</ref>). Right column: Performance of GambleTA compared to the oracle, on all problems and for all runs. 50 × 10, 664/2 = 266, 600 points per plot. c First half of the sequence. d Second half. The vertical lines reflect the fact that the algorithms are deterministic: runs differ only in the random order of the instances. The diagonal (not marked) would be the performance of Oracle. The continuous line above the diagonal would be the performance of Uniform. Note that this line is crossed by many runs. See also Table <ref type="table" target="#tab_0">1</ref> previous subsection. The cumulative overhead during the second part of the problem sequence was less than 3%, while WTU performance was observed for about 15% of the problem instances. Figure <ref type="figure" target="#fig_2">4c</ref>,d display a scatter-plot of the runtime of GambleTA against the one of the oracle, on all runs, again distinguishing among the first and second half of the problem sequence. Examining the latter, one can notice that the instances for which the runtime of GambleTA was worse than Uniform (represented by points above the line) can mostly be solved in less than 10 s. In other words, GambleTA is less precise for instances that have a minor impact on the cumulative runtime, which in this case is very close to the one of the Oracle. For this benchmark, Exp4 favored a mixture of two quantile allocators (α = 0.2, 0.3), and the greedy contract allocator, which was discarded on the previous benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Discussion</head><p>The experiments gave quite impressive results. In the first case, the dynamic time allocator GambleTA managed to solve an algorithm selection problem that cannot be solved in a similar way by any static technique. In the second case, performance was competitive with the one of a static offline selection technique, built based on advanced knowledge of the problem domain, including dozens of problem-specific features, and which required quite a long training time. On this latter point we have to remark that in <ref type="bibr" target="#b46">[45]</ref> no attempt was made at reducing the training cost, the interest of the authors being more focused on the precision of the estimated models.</p><p>The idea of performing algorithm selection based on runtime interaction with the algorithms is not at all new (see Section 2). Most fully dynamic methods are oblivious, i. e., with no knowledge transfer from one problem to the next; in most non-oblivious methods, the model is trained off-line, at a prohibitively high computational cost, as there is no principled method to decide when to stop the training phase. GambleTA takes the best of both worlds: the model allows to retain knowledge from past experiments, but is trained online, with a negligible overhead. The bandit problem solver Exp4 guarantees the optimal amount of exploration: the model is exploited as soon as it allows to improve on the uniform share. At this stage, the model is visibly rough, but can already serve the purpose of algorithm selection. Time allocation is fully dynamic, and shares can be updated an arbitrary number of times. To our knowledge, the most closely related approaches are <ref type="bibr" target="#b45">[44,</ref><ref type="bibr" target="#b60">59]</ref>. In the former, reinforcement learning, which can be seen as a generalization of bandit problems, is used, but at the algorithm level. The resulting method shares many of the positive features of GambleTA, as it is also online, and dynamic. In the dynamic method described in <ref type="bibr" target="#b59">[58,</ref><ref type="bibr" target="#b60">59]</ref>, the algorithm priorities are updated repeatedly, but the dynamic sharing schedule is decided per set, and offline. In <ref type="bibr" target="#b40">[40]</ref>, the dynamic selection is only based on the initial evolution of the state, and the probability distributions are assumed to belong to a finite set, known a priori: also in this case the model is learned offline. In <ref type="bibr" target="#b9">[10]</ref>, an oblivious technique is presented, based on a contract on execution time, but with no knowledge transfer across problem instances. In <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b74">73]</ref>, a bandit problem solver is used, but at a lower level, to perform oblivious per-instance algorithm selection. Compared to our previous work <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>, this article replaced the heuristic aspects, both in mapping model predictions to time allocation shares (Section 4), and in controlling the exploration-exploitation balance (Section 6).</p><p>At its upper level, the method is practically parameter-less. The bandit problem solver can set its only parameter optimally, based on the length of the task sequence. If the latter is not known, an initial estimate can be used, and periodically updated <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. In this case the optimal regret (20) is guaranteed with respect to the actual cumulative reward of the best expert. This modification was already tested, with analogous results. Different values of t 0 can only affect the performance with a logarithmic factor. The use of a logarithm for rewarding the algorithms allows to set t min and t max , respectively, to a very small and a very large value, such that only the knowledge of a very loose bound on execution time is required. Design decisions, including the choice of the time allocators, and model(s) to use, as well as the relative parameters, can be taken with a redundant approach, and their refinement can be left to Exp4. In the presented experiments we used a non-parametric model, which is slower to converge than a parametric one, but can converge to an arbitrary distribution, so it does not require any a priori hypothesis about the runtime distributions of the algorithms. If such hypothesis are available, but unsure, an additional copy of each time allocator, based on the parametric model, can be added, and Exp4 will decide which model to use, with a √ ln 2 impact on its regret. At the lowest level, the choice of the algorithms composing A, as well as the relative parameters, is still left to the user.</p><p>The amount of prior knowledge required by the experiments was quite low: the only inputs used for the model where one or two features, representing the size of the problems, and time. GambleTA has a black-box view of the algorithms, and can be applied to any decision problem solver. Optimisation problems can be treated, if a target on performance can be set in advance.</p><p>With respect to the previous parametric model <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>, the nonparametric method used here also allows to greatly reduce the modeling overhead, which is now negligible. According to <ref type="bibr" target="#b78">[77]</ref>, WW suffers from the curse of dimensionality, so it should be replaced in order to profit from a larger set of features. Including timevarying covariates, to condition the prediction also on the dynamic state of the algorithms, will also require more advanced models <ref type="bibr" target="#b43">[43,</ref><ref type="bibr" target="#b50">49,</ref><ref type="bibr" target="#b56">55]</ref>: the approximation used in <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref> was abandoned. The regret of Exp4 will scale well with the number of algorithms K, and the number of time allocators N, with order O( √ K ln N). The time allocators perform an optimisation in [0, 1] K , constrained to a space of size K -1, as s has to sum to one. As there are no guarantees of unimodality, they will all suffer from the curse of dimensionality, so, for much larger algorithm sets, some approximations should be introduced.</p><p>GambleTA is highly modular. On the higher level, different bandit problem solvers could be compared, possibly starting from the variations described in <ref type="bibr" target="#b1">[2]</ref>. On a level below, the model based time allocators could be replaced, or combined, with any other algorithm selection technique. It would be enough to express its decision as a share vector s. In the simplest case, one could add an additional fixed allocator for each algorithm in the set, to quickly detect situations in which a single algorithm dominates the others. Also oblivious techniques, as the ones in <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b20">21]</ref>, could be easily integrated.</p><p>Section 4 is based on a single machine. In future research we plan to address a more realistic scenario, in which a cluster of machines has to be allocated, one algorithm per machine. Another alternative implementation could be based on setting the priorities of the algorithms through the operating system.</p><p>If we go back to the initial section, and look at the list of issues of a typical modelbased algorithm selection technique, we realize that at least two of them do not hold for GambleTA. It never solves the same problem twice. And the simple fact of looking at the runtime of the algorithms allows it to improve its initial time allocation decisions. The first problem remains open: one feature that is still lacking is that the method cannot react to a misprediction of the model during a single task, which could be caused by an "outlier" problem instance, on which the behavior of the algorithms is radically different from what seen so far in the problem sequence. We will focus on this issue in our future research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>) Algorithm 2</head><label>2</label><figDesc>Exp4(K, N, M) by Auer et al. [1] 1: K arms, N experts, M trials 2: set γ := min 1, K ln N (e-1)M 3: initialize w n := 1 for n = 1, ..., K; 4: for each trial do 5: get advice vectors s (n) ∈ [0, 1] K from experts n = 1, ..., N 6: set p n := w n / N i=1 w i for n = 1, ..., N 7:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 3 GambleTA</head><label>3</label><figDesc>Gambling time allocator 1: Algorithm set A with K algorithms 2: N time allocators, including s U = (1/K, ..., 1/K) 3: M problem instances 4: initialize Exp4(K, N, M) 5: let Exp4 initialize p ∈ [0, 1] N 6: initialized model M 7: for each problem b 1 , b 2 , ..., b M do</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 WDP problems. a Cumulative time on the problem set. Upper 95% confidence bounds on 50 runs, with random reordering of the problems. GambleTA is our time allocator. Oracle is the lower bound on performance. Uniform is the (0.5,0.5) share. b Cumulative overhead (23) on the WDP problem set. Upper and lower confidence bounds. The overall final performance is 4%: in the second part only, the cumulative overhead is less than 3% (see Table1). Right column: Performance of GambleTA compared to the oracle, on all problems and for all runs. 50 × 10, 664/2 = 266, 600 points per plot. c First half of the sequence. d Second half. The vertical lines reflect the fact that the algorithms are deterministic: runs differ only in the random order of the instances. The diagonal (not marked) would be the performance of Oracle. The continuous line above the diagonal would be the performance of Uniform. Note that this line is crossed by many runs. See also Table1</figDesc><graphic coords="28,223.61,56.23,168.63,296.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>1 .</head><label>1</label><figDesc>Expected time. The expected runtime value E A,s (t) =</figDesc><table><row><cell>∞ 0 t f A,s (t)dt can be ob-</cell></row><row><cell>tained, and minimized with respect to s:</cell></row><row><cell>s = arg min</cell></row></table><note><p>s E A,s (t). (15) 2. Contract. If an upper bound, or contract, t u on execution time is imposed, one can instead use (13) to pick the s that maximizes the probability of solution within the contract F A,s (t u ) = Pr{T A,s ≤ t u } (or, equivalently, maximizes H A,s (t u ), or minimizes S A,s (t u )):</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>Various performance indicators for GambleTA, evaluated over the first and second halves of each problem sequence, averaging over 50 runs UNSAT instances, filtered from SU. Note that these two do not refer to separate experiments, but are extracted from the results on the SAT-UNSAT problem sequence. WDP: Winner Determination Problem. Indicators: GTA: cumulative performance of GambleTA. OR: cumulative performance of the Oracle. OVH: cumulative overhead of GambleTA, with respect to the Oracle<ref type="bibr" target="#b22">(23)</ref>. WTU: fraction of problems on which GambleTA is worse than Uniform (t U = Kt O )</figDesc><table><row><cell></cell><cell></cell><cell>First half</cell><cell>Second half</cell></row><row><cell>SU</cell><cell>GTA</cell><cell>1.46 × 10 10 ± 2.14 × 10 8</cell><cell>1.42 × 10 10 ± 2.11 × 10 8</cell></row><row><cell></cell><cell>OR</cell><cell>1.27 × 10 10 ± 2.06 × 10 8</cell><cell>1.26 × 10 10 ± 1.92 × 10 8</cell></row><row><cell></cell><cell>OVH</cell><cell>0.153 ± 0.0058</cell><cell>0.124 ± 0.0034</cell></row><row><cell></cell><cell>WTU</cell><cell>0.0739 ± 0.00296</cell><cell>0.0576 ± 0.00269</cell></row><row><cell>S</cell><cell>GTA</cell><cell>8.07 × 10 8 ± 4.64 × 10 7</cell><cell>8.47 × 10 8 ± 4.58 × 10 7</cell></row><row><cell></cell><cell>OR</cell><cell>3.05 × 10 8 ± 1.47 × 10 7</cell><cell>2.99 × 10 8 ± 1.32 × 10 7</cell></row><row><cell></cell><cell>OVH</cell><cell>1.66 ± 0.127</cell><cell>1.86 ± 0.143</cell></row><row><cell></cell><cell>WTU</cell><cell>0.119 ± 0.0044</cell><cell>0.109 ± 0.0050</cell></row><row><cell>U</cell><cell>GTA</cell><cell>1.37 × 10 10 ± 2.01 × 10 8</cell><cell>1.35 × 10 10 ± 2.15 × 10 8</cell></row><row><cell></cell><cell>OR</cell><cell>1.23 × 10 10 ± 2.01 × 10 8</cell><cell>1.24 × 10 10 ± 1.88 × 10 8</cell></row><row><cell></cell><cell>OVH</cell><cell>0.117 ± 0.00481</cell><cell>0.0822 ± 0.0029</cell></row><row><cell></cell><cell>WTU</cell><cell>0.024 ± 0.0037</cell><cell>0.0003 ± 0.0002</cell></row><row><cell>WDP</cell><cell>GTA</cell><cell>5.72 × 10 7 ± 6.48 × 10 5</cell><cell>5.51 × 10 7 ± 6.57 × 10 5</cell></row><row><cell></cell><cell>OR</cell><cell>5.45 × 10 7 ± 6.44 × 10 5</cell><cell>5.37 × 10 7 ± 6.44 × 10 5</cell></row><row><cell></cell><cell>OVH</cell><cell>0.0502 ± 0.0022</cell><cell>0.026 ± 0.0016</cell></row><row><cell></cell><cell>WTU</cell><cell>0.176 ± 0.0014</cell><cell>0.148 ± 0.0025</cell></row><row><cell cols="4">Ninety-five percent confidence intervals. SU: SAT-UNSAT benchmark. S: SAT instances, filtered</cell></row><row><cell>from SU. U:</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In previous works[17,  </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>21], the terms "offline" and "online" were used to distinguish among static and dynamic approaches, but we found this nomenclature to be misleading, especially for the machine learning community.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>With the term algorithm portfolio, we always refer to the parallel execution of (a subset of) the members of the portfolio. In other works ( e. g.,<ref type="bibr" target="#b46">[45]</ref>), the term is also referred to the algorithm set from which single algorithm selection is performed.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>This is the most widely used term, in medicine, biostatistics, biology, but different application fields use other terms. Engineers modeling the duration of a device speak of failure analysis, or reliability theory. Actuaries setting premiums for insurance companies use the term actuarial science.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>Here and in the following we assume an "ideal" machine, with no task switching overhead.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5"><p>Apart form the terms s k , (14) is the method used by engineers to evaluate the failure distribution of a series system, which stops working as soon as one of the components fail, based on the failure distribution for each single component.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6"><p>If we wait for just one algorithm to terminate, and t I is the performance of the fastest, the resulting training cost will be Kt I : another uncensored sample t I I would cost an additional (K -1)(t I It I ), and so on.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_7"><p>Oblivious per instance techniques could be based on different reward attributions, as in<ref type="bibr" target="#b9">[10]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_8"><p>Unfortunately, doing research on an online method does not have the benefits of just using one, as comparing with the performance of an oracle requires the knowledge of all runtimes, which means that, for the first experiments, we also had to solve all satisfiable problems with Satz-Rand.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_9"><p>Including the overhead of the quantile evaluations, the model update, etc., would not be fair, as all these operations are implemented in unoptimized, and rather bloated, Matlab code, while the a k are written in C. WW, as other nonparametric methods, has a very cheap learning phase, which consists in sorting independently the event times and the d dimensions of the covariates x ∈ R d . The cost of prediction is d searches on the sorted covariate data, and the cost of<ref type="bibr" target="#b21">(22)</ref>. Quantiles can also be evaluated just by searching a value on a sorted list. To give a rough idea, we report the profile of a single run on the SAT-UNSAT benchmark: on 1, 899 problems, two WW models were updated once per problem, for a total of 4.6 s. The hazard generating function<ref type="bibr" target="#b21">(22)</ref> was called about 280, 000 times in total, as each of the allocators uses it in the optimisation process (see note 9) : the cost was 88 s. An additional 3 min was spent in merging and re-sorting hazard vectors, to evaluate the hazard of the portfolio. The total runtime of the portfolio alone on the problem sequence would have been about 24 min. These figures would obviously change passing to a C implementation. Simple optimizations, like preserving order when merging two hazard vectors, would further improve the situation. The fact that the data is sorted would allow for more advanced optimizations, based for example on balanced trees, with a cost O(log n), n being the number of samples, both for search and insertion. Regarding memory requirements, the model would collect K samples for each solved task. On a modern machine, this amount of data would not cause any problem, even with long task sequences, but once there is enough data one can start to reduce the number of stored samples, for example merging neighboring hazards.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_10"><p>This odd number is due to the fact that instance uuf-200-860 number 100 is missing in the online archive. Note also that the smallest n for the unsatisfiable instances is 50, so there are 1, 000 SAT and</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_11"><p>http://www.cs.ubc.ca/~kevinlb/downloads/db-data.zip.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Faustino Gomez, for his invaluable support during writing; Alexey Chernov and Jan Poland, for the always useful brainstorming; Yannet Interian, and Laura Spierdijk, for their expert advice; and Kevin Leyton-Brown, for kind assistance with the WDP data.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by SNF grant 200020-107590/1.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Gambling in a rigged casino: the adversarial multi-armed bandit problem</title>
		<author>
			<persName><forename type="first">P</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual Symposium on Foundations of Computer Science</title>
		<meeting>the 36th Annual Symposium on Foundations of Computer Science<address><addrLine>Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="322" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The nonstochastic multiarmed bandit problem</title>
		<author>
			<persName><forename type="first">P</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="48" to="77" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Reactive search, a history-sensitive heuristic for max-sat</title>
		<author>
			<persName><forename type="first">R</forename><surname>Battiti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Protasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM J. Exp. Algorithms</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Integration of AI and OR Techniques in Constraint Programming for Combinatorial Optimization Problems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Freuder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First International Conference</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Régin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Rueher</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="volume">3011</biblScope>
			<biblScope unit="page" from="50" to="64" />
		</imprint>
	</monogr>
	<note>Simple rules for low-knowledge algorithm selection</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Nonparametric regression with randomly censored survival data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Beran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<pubPlace>Berkeley</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of California</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Bandit Problems: Sequential Allocation of Experiments</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fristedt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Chapman &amp; Hall</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A racing algorithm for configuring metaheuristics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Birattari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stützle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Paquete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Varrentrapp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GECCO 2002: Proceedings of the Genetic and Evolutionary Computation Conference</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Langdon</surname></persName>
		</editor>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deliberation scheduling for problem solving in time-constrained environments</title>
		<author>
			<persName><forename type="first">M</forename><surname>Boddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="245" to="285" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adaptive constraint satisfaction: The quickest first principle</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Borrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P K</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Walsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th European Conference on Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Wahlster</surname></persName>
		</editor>
		<meeting>the 12th European Conference on Artificial Intelligence<address><addrLine>Chichester; UK</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="160" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Applying machine learning to low knowledge control of optimization algorithms</title>
		<author>
			<persName><forename type="first">T</forename><surname>Carchrae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Beck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Intell</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="373" to="387" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Heuristic selection for stochastic search optimization: Modeling solution quality by extreme value theory</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Cicirello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Wallace</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3258</biblScope>
			<biblScope unit="page" from="197" to="211" />
			<date type="published" when="2004">2004</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg New York</pubPlace>
		</imprint>
	</monogr>
	<note>Principles and Practice of Constraint Programming -CP 2004</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The max k-armed bandit: A new model of exploration applied to search heuristic selection</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Cicirello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings, The Twentieth National Conference on Artificial Intelligence and the Seventeenth Innovative Applications of Artificial Intelligence Conference</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Veloso</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Kambhampati</surname></persName>
		</editor>
		<meeting>The Twentieth National Conference on Artificial Intelligence and the Seventeenth Innovative Applications of Artificial Intelligence Conference<address><addrLine>Pittsburgh, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">July 9-13, 2005. 2005</date>
			<biblScope unit="page" from="1355" to="1361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A representation for the adaptive generation of simple sequential programs</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Cramer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of an International Conference on Genetic Algorithms and Their Applications</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Grefenstette</surname></persName>
		</editor>
		<meeting>an International Conference on Genetic Algorithms and Their Applications<address><addrLine>Hillsdale NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<date type="published" when="1985">July 24-26, 1985. 1985</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie-Mellon University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Embedding decision-analytic control in a learning architecture</title>
		<author>
			<persName><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="129" to="159" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On-line bibliography on meta-learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fürnkranz</surname></persName>
		</author>
		<ptr target="Http://faculty.cs.byu.edu/~cgc/Research/MetalearningBiblio/metal-bib.html" />
	</analytic>
	<monogr>
		<title level="m">A Meta-learning Assistant for Providing User Support in Machine Learning Mining</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
	<note>EU ESPRIT METAL Project</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Gambling in a computationally expensive casino: Algorithm selection as a bandit problem. NIPS 2006 Workshop on Online Trading of Exploration and Exploitation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gagliolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006-12-08">8 December 2006</date>
			<pubPlace>Whistler Canada</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A neural network model for inter-problem adaptive online time allocation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gagliolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks: Formal Models and Their Applications -Proceedings ICANN 2005. Part 2</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Duch</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3697</biblScope>
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dynamic algorithm portfolios</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gagliolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ninth international symposium on artificial intelligence and mathematics</title>
		<meeting><address><addrLine>Fort Lauderdale FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-01">January 2006</date>
			<biblScope unit="page" from="4" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Impact of censored sampling on the performance of restart strategies</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gagliolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Benhamou</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">4204</biblScope>
			<biblScope unit="page" from="167" to="181" />
			<date type="published" when="2006">2006</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg New York</pubPlace>
		</imprint>
	</monogr>
	<note>Principles and Practice of Constraint Programming -CP 2006</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning restart strategies</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gagliolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI 2007 -Twentieth International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adaptive online time allocation to search algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gagliolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zhumatiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<ptr target="http://www.idsia.ch/idsiareport/IDSIA-23-04.ps.gz" />
	</analytic>
	<monogr>
		<title level="m">Machine Learning: ECML 2004. Proceedings of the 15th European Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Boulicaut</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="134" to="143" />
		</imprint>
	</monogr>
	<note>Extended tech. report available at</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">The search for satisfaction</title>
		<author>
			<persName><forename type="first">I</forename><surname>Gent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Walsh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Strathclyde</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Introduction to the special issue on meta-learning</title>
		<author>
			<persName><forename type="first">Giraud-Carrier</forename></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vilalta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Brazdil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="187" to="193" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Algorithm portfolios</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Selman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="43" to="62" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Heavy-tailed phenomena in satisfiability and constraint satisfaction problems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Selman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Crato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Autom. Reason</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="67" to="100" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Monitoring and control of anytime algorithms: A dynamic programming approach</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zilberstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="139" to="157" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A parameter-less genetic algorithm</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Harick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">G</forename><surname>Lobo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Banzhaf</surname></persName>
		</editor>
		<meeting>the Genetic and Evolutionary Computation Conference<address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1867" to="1875" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Adaptation in Natural and Artificial Systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Holland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>University of Michigan Press</publisher>
			<pubPlace>Ann Arbor, MI</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Stochastic Local Search: Foundations and Applications</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stützle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">SATLIB: An Online Resource for Research on SAT</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stützle</surname></persName>
		</author>
		<ptr target="http://www.satlib.org" />
	</analytic>
	<monogr>
		<title level="m">SAT 2000</title>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">W I P</forename><surname>Gent</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Maaren</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="283" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A bayesian approach to tackling hard computational problems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Selman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI &apos;01: Proceedings of the 17th Conference in Uncertainty in Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Breese</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</editor>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="235" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Computational tradeoffs under bounded resources (editorial)</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zilberstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="1" to="4" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note>Special Issue</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An economic approach to hard computational problems</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Huberman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Lukose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hogg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">275</biblScope>
			<biblScope unit="page" from="51" to="54" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Parameter adjustment based on performance prediction: Towards an instance-aware problem solver</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hamadi</surname></persName>
		</author>
		<idno>. MSR-TR-2005-125</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Microsoft Research</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Performance prediction and automated tuning of randomized and parametric algorithms</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hamadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Leyton-Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Benhamou</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">4204</biblScope>
			<biblScope unit="page" from="213" to="228" />
		</imprint>
	</monogr>
	<note>Principles and Practice of Constraint Programming -CP 2006</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<pubPlace>Berlin Heidelberg New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sinha</surname></persName>
		</author>
		<title level="m">Bayesian Survival Analysis</title>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Applied Survival Analysis: Regression Modeling of Time to Event Data</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W H</forename><surname>Jr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lemeshow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Reinforcement learning: a survey</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kaelbling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="237" to="285" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Nonparametric estimation from incomplete samples</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="457" to="481" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Dynamic restart policies</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Selman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth National Conference on Artificial Intelligence and Fourteenth Conference on Innovative Applications of Artificial Intelligence (AAAI/IAAI)</title>
		<meeting>the Eighteenth National Conference on Artificial Intelligence and Fourteenth Conference on Innovative Applications of Artificial Intelligence (AAAI/IAAI)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="674" to="681" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Estimation of the conditional distribution in regression with censored data : a comparative study</title>
		<author>
			<persName><forename type="first">I</forename><surname>Van Keilegom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Akritas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Veraverbeke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="487" to="500" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">ECML 2000 workshop on meta-learning: building automatic advice strategies for model selection and method combination</title>
		<author>
			<persName><forename type="first">J</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Giraud-Carrier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eleventh European Conference on Machine Learning (ECML-2000)</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-06-02">30 May-2 June. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Unified Methods for Censored Longitudinal Data and Causality</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Van Der Laan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Robins</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Berlin Heidelberg New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Algorithm selection using reinforcement learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Lagoudakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth International Conference on Machine Learning (ICML 2000)</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Langley</surname></persName>
		</editor>
		<meeting>the Seventeenth International Conference on Machine Learning (ICML 2000)<address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="511" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning the empirical hardness of optimization problems: The case of combinatorial auctions</title>
		<author>
			<persName><forename type="first">K</forename><surname>Leyton-Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nudelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shoham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">V</forename><surname>Hentenryck</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">2470</biblScope>
			<date type="published" when="2002">2002</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg New York</pubPlace>
		</imprint>
	</monogr>
	<note>Principles and Practice of Constraint Programming -CP 2002</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Empirical hardness models: Methodology and a case study on combinatorial auctions</title>
		<author>
			<persName><forename type="first">K</forename><surname>Leyton-Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nudelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shoham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint/>
	</monogr>
	<note>submitted</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Heuristics based on unit propagation for satisfiability problems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Anbulagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Fifteenth International Joint Conference on Artificial Intelligence<address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="366" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Diversification and determinism in local search for satisfiability</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory and Applications of Satisfiability Testing, 8th International Conference, SAT 2005</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Bacchus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Walsh</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3569</biblScope>
			<biblScope unit="page" from="158" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">An approach to nonparametric regression for life history data using local linear fitting</title>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Doss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="787" to="823" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Censored data regression in high dimension and low sample size settings for genomic applications</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Optimal speedup of las vegas algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sinclair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zuckerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Process. Lett</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="173" to="180" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Hard and easy distributions of sat problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Selman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Levesque</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 10th National Conf. on Artificial Intelligence</title>
		<meeting>10th National Conf. on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="459" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Efficient algorithms for minimizing cross validation error</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference (ICML)</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Hirsh</surname></persName>
		</editor>
		<meeting>the Eleventh International Conference (ICML)<address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="190" to="198" />
		</imprint>
	</monogr>
	<note>Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Applied Life Data Analysis</title>
		<author>
			<persName><forename type="first">W</forename><surname>Nelson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Kernel estimation in a nonparametric marker dependent hazard model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Linton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1735" to="1748" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Empirical approach to the complexity of hard problems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nudelman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Understanding random sat: Beyond the clauses-to-variables ratio</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nudelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Leyton-Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Devkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shoham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Wallace</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3258</biblScope>
			<biblScope unit="page" from="438" to="452" />
			<date type="published" when="2004">2004</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg New York</pubPlace>
		</imprint>
	</monogr>
	<note>Principles and Practice of Constraint Programming -CP 2004</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Learning parallel portfolios of algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Petrik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Comenius University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Statistically optimal combination of algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Petrik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SOFSEM 2005 -31st Annual Conference on Current Trends in Theory and Practice of Informatics</title>
		<meeting><address><addrLine>Slovak Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-01">January, 2005</date>
			<biblScope unit="page" from="22" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Learning static parallel portfolios of algorithms. Ninth international symposium on artificial intelligence and mathematics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Petrik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zilberstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006-01">January 2006</date>
			<biblScope unit="page" from="4" to="6" />
			<pubPlace>Fort Lauderdale FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Meta-learning by landmarking various learning algorithms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bensusan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Giraud-Carrier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth International Conference on Machine Learning (ICML 2000)</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Langley</surname></persName>
		</editor>
		<meeting>the Seventeenth International Conference on Machine Learning (ICML 2000)<address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="743" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Guest editors&apos; introduction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Pratt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note>Special Issue on Inductive Transfer</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">The algorithm selection problem</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Rice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Computers</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Rubinoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Yovits</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic</publisher>
			<date type="published" when="1976">1976</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="65" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Some aspects of the sequential design of experiments</title>
		<author>
			<persName><forename type="first">H</forename><surname>Robbins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bull. Am. Math. Soc</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="527" to="535" />
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Principles of metareasoning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Wefald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="361" to="395" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Anytime sensing, planning, and action: A practical model for robot control</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zilberstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Artificial Intelligence (IJCAI-93)</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Bajcsy</surname></persName>
		</editor>
		<meeting>the International Conference on Artificial Intelligence (IJCAI-93)<address><addrLine>Chambéry, France; San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="1402" to="1407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Probabilistic incremental program evolution</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Sałustowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="141" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Optimal ordered problem solver</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Short version in NIPS 15</title>
		<imprint>
			<date type="published" when="2003">2004. 2003</date>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="1571" to="1578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Shifting inductive bias with success-story algorithm, adaptive Levin search, and incremental self-improvement</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wiering</surname></persName>
		</author>
		<idno>TR IDSIA-69-96</idno>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="105" to="130" />
			<date type="published" when="1996">1997. 1996</date>
		</imprint>
	</monogr>
	<note>Based on: Simple principles of metalearning</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A meta-learning method to select the kernel width in support vector regression</title>
		<author>
			<persName><forename type="first">C</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Brazdil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kuba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="195" to="209" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Progress in incremental machine learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Solomonoff</surname></persName>
		</author>
		<idno>. IDSIA-16-03</idno>
	</analytic>
	<monogr>
		<title level="j">IDSIA</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Nonparametric conditional hazard rate estimation: a local linear approach</title>
		<author>
			<persName><forename type="first">L</forename><surname>Spierdijk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>TW Memorandum, University of Twente</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">An asymptotically optimal algorithm for the max k-armed bandit problem</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Streeter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings, The Twenty-First National Conference on Artificial Intelligence and the Eighteenth Innovative Applications of Artificial Intelligence Conference (AAAI/IAAI)</title>
		<meeting>The Twenty-First National Conference on Artificial Intelligence and the Eighteenth Innovative Applications of Artificial Intelligence Conference (AAAI/IAAI)<address><addrLine>Menlo Park, CA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">The Nature of Statistical Learning Theory</title>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A perspective view and survey of meta-learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Vilalta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Drissi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Rev</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="77" to="95" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Smoothing hazard rate</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of Biostatistics, 2nd Edition</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Armitage</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="4986" to="4997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Application of a simple nonparametric conditional quantile function estimator in unemployment duration analysis</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wichert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Wilke</surname></persName>
		</author>
		<idno>. ZEW Discussion Paper No. 05-67</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Centre for European Economic Research</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
