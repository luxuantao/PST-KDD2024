<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A novel hybrid KPCA and SVM with GA model for intrusion detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-01-30">30 January 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Fangjun</forename><surname>Kuang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Nanjing University of Science and Technology</orgName>
								<address>
									<postCode>210018</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Electronic and Information Engineering</orgName>
								<orgName type="institution">Hunan Vocational Institute of Safety &amp; Technology</orgName>
								<address>
									<postCode>410151</postCode>
									<settlement>Changsha</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Weihong</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Nanjing University of Science and Technology</orgName>
								<address>
									<postCode>210018</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">College of Computer and Communications Engineering</orgName>
								<orgName type="institution">Changsha University of Science and Technology</orgName>
								<address>
									<postCode>410077</postCode>
									<settlement>Changsha</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Siyang</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Electronic and Information Engineering</orgName>
								<orgName type="institution">Hunan Vocational Institute of Safety &amp; Technology</orgName>
								<address>
									<postCode>410151</postCode>
									<settlement>Changsha</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Nanjing University of Science and Technology</orgName>
								<address>
									<postCode>210018</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A novel hybrid KPCA and SVM with GA model for intrusion detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-01-30">30 January 2014</date>
						</imprint>
					</monogr>
					<idno type="MD5">32BB610835951589D5E11225D087CB74</idno>
					<idno type="DOI">10.1016/j.asoc.2014.01.028</idno>
					<note type="submission">Received 11 October 2012 Received in revised form 17 November 2013 Accepted 15 January 2014</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Intrusion detection Kernel principal component analysis Kernel function Support vector machines Genetic algorithm</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A novel support vector machine (SVM) model combining kernel principal component analysis (KPCA) with genetic algorithm (GA) is proposed for intrusion detection. In the proposed model, a multi-layer SVM classifier is adopted to estimate whether the action is an attack, KPCA is used as a preprocessor of SVM to reduce the dimension of feature vectors and shorten training time. In order to reduce the noise caused by feature differences and improve the performance of SVM, an improved kernel function (N-RBF) is proposed by embedding the mean value and the mean square difference values of feature attributes in RBF kernel function. GA is employed to optimize the punishment factor C, kernel parameters and the tube size Îµ of SVM. By comparison with other detection algorithms, the experimental results show that the proposed model performs higher predictive accuracy, faster convergence speed and better generalization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Intrusion detection is one of the most essential things for security infrastructures in network environments, and it is widely used in detecting, identifying and tracking the intruders <ref type="bibr" target="#b0">[1]</ref>. Capabilities of intrusion detection technologies have great importance with the performance of intrusion detection system (IDS). Researches always want to find an intrusion detection technology with better detection accuracy and less training time.</p><p>However, there are many problems in the traditional IDS, such as the low detection capability against the unknown network attack, high false alarm rate, and insufficient analysis capability and so on. In nature, intrusion detection can be seen as classification problem, to distinguish between the normal activities and the malicious activities. The concerned problems of machine learning are how the systems automatically improve the performance with the increase of experience, which is consistent with that of the IDS. Therefore, various machine learning methods are developed for intrusion detection, such as decision tree <ref type="bibr" target="#b0">[1]</ref>, genetic algorithm (GA) <ref type="bibr" target="#b1">[2]</ref>, neural network <ref type="bibr" target="#b2">[3]</ref>, principal component analysis (PCA) <ref type="bibr" target="#b3">[4]</ref>, fuzzy logic <ref type="bibr" target="#b4">[5]</ref>, K-nearest neighbor <ref type="bibr" target="#b5">[6]</ref>, rough set theory <ref type="bibr" target="#b6">[7]</ref> and support vector machine (SVM) <ref type="bibr" target="#b7">[8]</ref>.</p><p>Among the methods mentioned above, SVM is an effective one, the main reason is that the distribution of different types of attacks is imbalanced, where the learning sample size of the low-frequent attacks is too small compared to the high-frequent attack. SVM is a margin-based classifier based on small sample learning with good generalization capabilities, which is frequently used in real world applications of classification <ref type="bibr" target="#b8">[9]</ref>. It realizes the theory of VC dimension and principle of structural risk minimum, thus it does not have the over-fitting problem that artificial neural network cannot overcome. SVM has manifested its robustness and efficiency in the network action classification, and it is widely used in IDS as a popular method <ref type="bibr" target="#b9">[10]</ref>. Eskin <ref type="bibr" target="#b10">[11]</ref> addressed an unsupervised anomaly detection framework, and applied it in three unsupervised learning algorithms, including clustering method, K-nearest neighbor and SVM. Shon et al. <ref type="bibr" target="#b11">[12]</ref> employed genetic algorithm (GA) for feature selection, and used SVM for intrusion detection. Srinoy <ref type="bibr" target="#b12">[13]</ref> proposed an intrusion detection model using SVM and particle swarm optimization (PSO) which used PSO to extract intrusion features and SVM to classify. Fei et al. <ref type="bibr" target="#b13">[14]</ref> proposed an incremental clustering method based on the density. Horng et al. <ref type="bibr" target="#b14">[15]</ref> used the hierarchical clustering algorithm to provide the SVM with fewer, abstracted, and higher qualified training instances. To overcome the problem of uncertainty in IDS, Kavitha et al. <ref type="bibr" target="#b15">[16]</ref> adopted a new technique known as neutrosophic logic (NL). Wu and Banzhaf <ref type="bibr" target="#b16">[17]</ref> referred to the review of computational intelligence in intrusion detection and applied numerical evaluation measures to quantify the performance of IDS. Kolias and Kambourakis <ref type="bibr" target="#b17">[18]</ref> gave the survey of swarm intelligence in intrusion detection. Kuang et al. <ref type="bibr" target="#b18">[19]</ref> proposed a SVM model based on kernel principal component analysis (KPCA) and GA, which used KPCA to extract intrusion features, and GA to optimize the parameter of SVM. Li et al. <ref type="bibr" target="#b19">[20]</ref> put forward pipeline of data preprocess and data mining in IDS, and used gradually feature removal method to feature reduction and SVM to classify.</p><p>However, standard SVM still has some limitations, the performance depends on its parameters selection, and when the differences between the attributes of the sample are very big, using RBF in the training process will produce a large number of support vectors and the training time will be longer too. And two main parts should be conducted which are detection model set-up and intrusion feature extraction to get better performance.</p><p>To solve the above mentioned problems, we present a novel intrusion detection approach combining SVM and KPCA to enhance the detection precision for low-frequent attacks and detection stability. In the proposed method, KPCA maps the high dimension features in the input space to a new lower dimension eigenspace and extracts the principal features of the normalized data, and multi-layer SVM classifier is employed to estimate whether the action is an attack. In order to shorten the training time and improve the performance of SVM classification model, an improved radial basis kernel function (N-RBF) based on Gaussian kernel function is developed, and GA is used to optimize the parameters of SVM.</p><p>The rest of this paper is organized as follows. In Section 2, the proposed SVM classification model is described in detail. The classification procedure is presented to illustrate how to use the proposed SVM model for intrusion detection in Section 3.The experimental results are discussed in Section 4. Section 5 presents conclusion and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Novel KPCA SVM classification model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Kernel principal component analysis</head><p>Principal component analysis (PCA) <ref type="bibr" target="#b20">[21]</ref> is a common method applied to dimensionality reduction and feature extraction. PCA method can only extract the linear structure information in the data set, however, it cannot extract this nonlinear structure information. KPCA is an improved PCA, which extracts the principal components by adopting a nonlinear kernel method <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>. A key insight behind KPCA is to transform the input data into a high dimensional feature space F in which PCA is carried out, and in implementation, the implicit feature vector in F does not need to be computed explicitly, while it is just done by computing the inner product of two vectors in F with a kernel function.</p><p>Let x 1 , x 2 , . . ., x n â R d be the n training samples for KPCA learning <ref type="bibr" target="#b18">[19]</ref>. The ith KPCA-transformed feature t i can be obtained by</p><formula xml:id="formula_0">t i = 1 i i T [k(x 1 , x new ), k(x 2 , x new ), . . ., k(x n , x new )] T , i = 1, 2, . . ., p<label>(1)</label></formula><p>Here, Column vectors i (i = 1, 2, . . ., p ; 0 &lt; p â¤ n) is the orthonormal eigenvectors to the p largest positive eigenvalues 1 â¥ 2 â¥ . . . â¥ p , k(x i , x j ) is the calculation of the inner product of two vectors in the hyper-dimensional feature space F with a kernel function.</p><p>By using Eq. ( <ref type="formula" target="#formula_0">1</ref>), the KPCA-transformed feature vector of a new sample vector can be obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">SVM classification model</head><p>After feature extraction using KPCA, the training data points can be expressed as (t 1 , y 1 ), (t 2 , y 2 ), . . ., (t p , y p ), t i â R k (k &lt; d) is the transformed input vector, y i is the target value <ref type="bibr" target="#b18">[19]</ref>. In the Îµ-SVM classification <ref type="bibr" target="#b23">[24]</ref>, the goal is to find a function f(t) that has at most Îµ deviation from the actually obtained targets y i for all the training data, and at the same time, is as flat as possible. The Îµ-insensitive loss function denotes as follows:</p><formula xml:id="formula_1">e(f (t) -y) = 0, f (t) -y â¤ Îµ f (t) -y -Îµ, otherwise<label>(2)</label></formula><p>Formally the optimization problem by requiring the follows:</p><formula xml:id="formula_2">minimize 1 2 w 2 + C p i=1 ( i + i * ) subject to y i -(w Ë(t i ) + b) â¤ Îµ -i (w Ë(t i ) + b) -y i â¤ Îµ -i * i , i * â¥0, i = 1, 2, . . ., p; C &gt; 0<label>(3)</label></formula><p>where i and i * are slack variables, the punishment factor C is regularization constant, Îµ denotes the tube size of SVM. C and Îµ are both determined by users empirically, the constant C determines the trade-off between the flatness of f(t) and the amount up to which deviations large than Îµ are tolerated.</p><p>At the optimal solution, the decision function takes the following form:</p><formula xml:id="formula_3">f (t) = sgn p i=1 (Ëi -Ëi * )K(t i , t j ) + b<label>(4)</label></formula><p>where Ëi and Ëi* are the Lagrange multiplier coefficients for the ith training sample, and obtained by solving the dual optimization problem in support vector learning <ref type="bibr" target="#b23">[24]</ref>. The training sample for which Ëi / = Ëi * is corresponded to the support vectors, K(k i , k j ) is a kernel function, b is found by the Karush-Kuhn-Tucker conditions at optimality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">N-RBF kernel function for SVM model</head><p>In the SVM, there are some common kernels, shown as follows, and any of those can be chosen to achieve the boundary function. Their detailed usages and descriptions, including parameters definitions, can be found in <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref>.</p><p>(1) Gaussian RBF kernel:</p><formula xml:id="formula_4">K(t i , t j ) = exp -t i -t j 2 2 , â R (2) Polynomial kernel: K(t i , t j ) = (a(t i â¢ t j ) + b) d , a â R, b â R, d â N (3) Sigmoid kernel: K(t i , t j ) = tanh(a(t i â¢ t j ) + b), a â R, b â R (4) Inverse multi-quadric kernel: K(t i , t j ) = 1 t i -t j 2 + 2</formula><p>, â R SVM always has good performance in classification when using RBF, which is an effective kernel function for fewer parameters set and an excellent overall performance. A network record contains dozens of attributes, and there may be significant differences between them. Therefore, when the differences between the attributes are very big, using RBF in the training process will produce a larger number of support vectors and the training time will be longer too.</p><p>In order to shorten the training time and improve the performance of SVM, an improved kernel function N-RBF is developed by embedding the mean value and the mean square difference values of feature attributes in Gaussian RBF kernel function to normalize the attribute values. The N-RBF is defined as follows:</p><formula xml:id="formula_5">K(t i , t j ) = exp( -(t i -m)/s -(t j -m)/s 2 2 )<label>(5)</label></formula><p>where m = (m 1 , m 2 , . . ., m j , . . ., m k ) and s = (s 1 , s 2 , . . ., s j , . . ., s k ) are the mean value and the mean square deviation of attributes, respectively, k is the dimension of sample vectors, m j and s j is denoted as follows:</p><formula xml:id="formula_6">m j = 1 n n i=1 L ij , j = 1, 2, . . ., k<label>(6)</label></formula><formula xml:id="formula_7">s j = 1 n -1 n i=1 (L ij -m j ) 2 , j = 1, 2, . . ., k<label>(7)</label></formula><p>where L ij is the jth attribute of the ith sample and n is the number of training samples.</p><p>According to the functional theory, as long as the function K satisfies Mercer's condition, it can be denoted as an inner product, and it should be a positive definite kernel. Obviously, N-RBF is a positive definite kernel, and is a kernel function.</p><p>Consequently, the three positive parameters , Îµ and C are userdetermined parameters in SVM classification model, the selection of the parameters plays an important role in the performance of SVM model. A better approach is to apply cross validation to select the best choices among some candidate parameters. Based on the idea, several disciplined approaches can be used to obtain the optimal parameters for SVM classification model, out of which, evolutionary method such as genetic algorithm (GA), simulated annealing algorithm and PSO algorithm, is one of the most widely used approaches. In this paper, GA is employed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Optimizing the SVM model parameters with GA</head><p>GA is a search technique used in computing to find exact or approximate solutions to optimization and search problems. Genetic algorithms, as global search heuristics, are a particular class of evolutionary algorithms (EA) that use techniques inspired by evolutionary biology such as inheritance, mutation, selection, and crossover. GAs have been considered with increasing interest in a wide variety of applications <ref type="bibr" target="#b26">[27]</ref>. These algorithms are used to search the solution space through simulated evolution of "survival of the fittest". These are also used to solve linear and nonlinear problems by exploring all regions of state space and exploiting potential areas through mutation, crossover and selection operations applied to individuals in the population.</p><p>Therefore, in this paper, genetic algorithms are used to optimize the parameters , Îµ and C of SVM. And a negative mean absolute percentage error (MAPE) is used as the fitness function for evaluating fitness <ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref>:</p><formula xml:id="formula_8">MAPE = 1 N N i=1 a i -d i a i Ã 100%<label>(8)</label></formula><p>where a i and d i represent the actual and forecast values, respectively. N is the number of classification periods. GA is used to yield a smaller MAPE by searching for better combinations of three parameters in SVM. The process of optimizing the SVM parameters with GA is shown in Fig. <ref type="figure">1</ref>, which is described below.</p><p>Step 1: Encode SVM parameters and initialization of population. The three free parameters , Îµ and C are encoded in binary numbers and represented by a chromosome. Each bit of the chromosome represents whether the corresponding feature is selected or not. '1' in each bit means the corresponding feature is selected, whereas '0' means it is not selected. Randomly generate an initial population of chromosomes which represent the values of parameters in SVM model.</p><p>Step 2: Calculate the fitness function of each chromosome according to Eq. ( <ref type="formula" target="#formula_8">8</ref>). It is evaluated by the cross-validated predictive accuracy of the SVM model.</p><p>Step 3: GA operators, which are selection, crossover and mutation. Selection is performed to select excellent chromosomes to reproduce. Based on fitness functions, chromosomes with higher fitness values are more likely to yield offspring in the next generation by means of the roulette wheel. The single-point crossover principle is employed. Segments of paired chromosomes between two determined break-points are swapped. Mutations are performed randomly by converting a '1' bit into a '0' bit or a '0' bit in to a '1' bit. The rates of crossover and mutation are probabilistically determined. In this study, the probabilities of crossover and mutation are set to 0.8 and 0.05, respectively.</p><p>Step 4: Generate a new population for the next generation. Offspring replaces the old population and forms a new population in the next generation by the three operations.</p><p>Step 5: Obtain the parameters of SVM model. If one of the stopping criteria (Generally, a sufficiently good fitness or a given number of generations) is satisfied, then the best chromosomes are presented as a solution, else go to step 2.</p><p>After these steps, the optimal parameters , Îµ and C of the KPCA SVM model are obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed SVM model for intrusion detection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Intrusion detection types and normalized</head><p>This paper takes the KDD CUP99 <ref type="bibr" target="#b27">[28]</ref> as the datasets of the experiments. The datasets can be divided into five categories which are normal, denial of service (DoS), unauthorized access from a remote machine (Remote to Local, R2L), unauthorized access to local supervisor privileges (User to Root, U2R) and Probe. Each network record contains 41 attributes, of which 34 attributes are continuous and 7 attributes are discrete. Before the experiments, we need to deal with the discrete attributes by counting the frequency of their values and converting them to numerical attributes, and transform all attributes into the normalized format.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Intrusion detection based on proposed SVM model</head><p>Multi-SVM classifiers are applied to intrusion detection because of multi-types existing in network. 'One-against-one', 'Oneagainst-all' and 'Binary tree' are the popular methods in SVM multi-class classification <ref type="bibr" target="#b23">[24]</ref>. 'Binary tree' SVM classification algorithm needs only k -1 two-class SVM classifiers for a case of k classes, while 'One-against-all' SVM classification algorithm needs k two-class SVM classifiers where each one is trained with all the samples and 'One-against-one' SVM classification algorithm needs k (k -1)/2 two-class SVM classifiers where each one is trained on data from two classes <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref>. Obviously less two-class classifiers help to expedite the rate of training and recognition. Thus, 'Binary tree' SVM classification algorithm is adopted to construct detection model for intrusion detection.</p><p>Based on the characteristics of different intrusion detection types, four SVM classifiers are developed to identify the five states: normal state (Nc) and the four intrusion state (DoS, R2L, U2R, and Probing). With all the training samples of the five states, SVM1 is trained to separate the normal state from the intrusion state. When input of SVM1 is a sample representing the normal state, output of SVM1 is set to +1; otherwise -1. SVM2 is trained to separate the DoS from the other intrusion states. When the input of SVM2 is a sample representing DoS, the output of SVM2 is set to +1; otherwise -1.</p><p>SVM3 is trained to separate R2L from U2R and Probing. When the input of SVM3 is a sample representing the R2L, the output of SVM3 is set to +1; otherwise -1. SVM4 is trained to separate Probing from U2R. When the input of SVM4 is a sample representing Probing, the output of SVM4 is set to +1; otherwise -1. Thus, the multilayer SVM classifier is obtained. The basic principle of intrusion detection model based on improved SVM classifiers by combining KPCA and GA is shown in Fig. <ref type="figure">2</ref>. All the four SVMs adopt N-RBF function as their kernel function, and the parameters , Îµ and C are optimized with GA. The adjusted parameters with maximal classification accuracy are selected as the most appropriate parameters. Then, the optimal parameters are utilized to train the SVM model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Proposed intrusion detection model implementation</head><p>Intrusion detection belongs to classification problems in essence, it distinguishes between the abnormal data and the normal data, and the intrusion data is of a high dimension and contains many noise attributes. Therefore, KPCA is used to extract the principal components, SVM classifiers are applied to intrusion detection. The proposed hybrid approach is composed of two stages: In the first stage, the principal components are achieved based on KPCA theory, which find an optimal subset of all attributes and delete irrelevant and redundant attributes. The second stage is to use this attribute subset as the training dataset and testing dataset of SVM to perform the classification, and N-RBF kernels are used for KPCA and N-RBF kernels are also adopted for SVM, GA is used to select the optimal parameter of SVM. Fig. <ref type="figure" target="#fig_1">3</ref> shows the procedures of the proposed SVM classification model for intrusion detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental results and discussions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental description</head><p>In this section, we selected samples from the subset of KDD to form the training and testing set. There are some performance indicators for the intrusion detection system as follows: TP, FP, TN and FN, where TP represents that the normal behavior is correctly forecasted, FP indicates that the abnormal behavior is judged as normal, FN denotes that the normal behavior is wrongly thought as abnormal, and TN represents the abnormal behavior is correctly detected <ref type="bibr" target="#b16">[17]</ref>.</p><p>( where DR denotes the detection rate and FAR denotes the false alarm rate. They are important to evaluate the performance of the intrusion detection system. In addition, we consider another indicator cc, which denotes the correlation between the forecast result and the actual situation. It ranges from -1 to 1, where 1 implies the forecast result is fully consistent with the actual situation and -1 is on behalf of a random prediction.</p><p>The experiment was processed within a MATLAB R2009b environment, which was running on a PC powered by Pentium IV 3.0 GHz CPU and 3.0 GB RAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Effectiveness of N-RBF</head><p>In this section, we selected samples from the subset of KDD to form the training and testing set. There were five data sets in Table <ref type="table" target="#tab_0">1</ref>. In order to verify the effectiveness of N-RBF, the percentage of the normal samples in each set was different. Adopt the SVM as the classifier. Because the choice of parameters would impact algorithms' performance directly, we used the python in Libsvm as a supplementary tool. The parameter of RBF and N-RBF is set to be 0.00028.The parameters a, d and b of POLY are set to be 0.00028, 3 and 1, respectively. The penalty parameter C of SVM is set to be 1024. The experiment results are shown in Table <ref type="table" target="#tab_1">2</ref>.</p><p>As shown in Table <ref type="table" target="#tab_1">2</ref>, the detection rates of N-RBF and POLY are higher, especially N-RBF. Due to the introduction of normalization, it reduces the noise among attributes, so the detection rate of N-RBF is higher than RBF. Secondly, the training time of RBF is dozens or even hundreds of times of N-RBF, while the training time of POLY is several or dozens of times of N-RBF, which indicate N-RBF has good performance in reducing the training time and only costs a few seconds; and the test time POLY and N-RBF cost is significantly less than RBF. In general, although the detection effect of N-RBF is not The above experiments have not considered the attacks of different kinds, respectively. In order to further analyze the detection performance of N-RBF on unknown attacks, we gave the following experiments. First, regenerated a test set, containing more than 90% attacks of new categories. Then we compared SVM with N-RBF, SVM with RBF, and SVM with POLY in the experiments, and counted the detection rates of these methods on the attacks of all categories, the comparisons of experimental results in 30 simulation experiments are given in Table <ref type="table" target="#tab_2">3</ref>.</p><p>As shown in Table <ref type="table" target="#tab_2">3</ref>, we can see that the three methods show high detection rates on forecasting normal behaviors, and SVM with N-RBF has the highest detection rates on predicting the attacks of Probe and DoS. However, the results for detecting attacks of U2R and R2L are all unsatisfactory. In general, the detection rate of SVM with N-RBF on attacks of all categories is better than the other two methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Experiments of novel KPCA-GA-SVM</head><p>The following experiments were done to verify the effectiveness of the novel KPCA-GA-SVM (N-KPCA-GA-SVM). In this section, firstly, the subset we obtained in Section 4.2 was randomly divided into two subsets, each subset contains both the data of normal and abnormal class, one was as the training set, and the other was as the test set. Secondly, randomly select 10 datasets from the training subset, named from F1 to F10, as the training set, and any two training sample sets did not intersect. Thirdly, from the test subset, selected the normal and attack records with the same number to form the test set. Now, we evaluated N-KPCA-GA-SVM by comparing it with KPCA-GA-SVM <ref type="bibr" target="#b18">[19]</ref>, PCA-GA-SVM, Single-SVM and radical basis function neural networks (RBFNN) on the detection rate (DR), false alarm rate (FAR), correlation coefficient (cc), and training time (TrD) and test time (TeD). We employed four SVMs for the 5-class classification problem including Section 3.2, and partitioned the data into the two classes of "Normal" and "Rest" (DoS, R2L, U2R, Probe) patterns, where the rest was the collection of four classes of attack instances in the dataset. The objective was to separate normal and attack patterns. Repeat this process for all classes. In this paper, we chose p eigenvectors by trial and error, which corresponded to the first p biggest eigenvalues, to form the sub-eigenspace, satisfying:</p><formula xml:id="formula_10">p i=1 i n i=1 i â¥90%<label>(9)</label></formula><p>In N-KPCA-GA-SVM model, N-RBF kernels were used for KPCA and N-RBF kernels were also adopted for SVM, GA method was used to select the optimal parameter of SVM and KPCA. KPCA was applied to feature extraction, this method aimed to map the high dimensional original input data to a lower dimensional eigensapce, which held the principal features and abandoned the subordinate and noise data. In N-KPCA-GA-SVM model, by many experiments, the parameters of the models were chosen as follows: population size: 50, maximal iteration: 200, the probabilities of crossover and mutation were set to 0.8 and 0.05, respectively. Through 20 simulation experiments, parameters (C, , Îµ) = (83.5191, 0.0907, 0.0008) of SVM were obtained. In the other SVM model, all SVMs adopted RBF as their kernel function, and the parameters , Îµ and C were randomly selected. In RBFNN model, RBFNN had four-layer ANN, with 5 input neurons, with two hidden layers with 20 and 30 neurons each, and 5 output neurons. The experiment results among different algorithms are listed in Table <ref type="table" target="#tab_3">4</ref>.</p><p>As shown in Table <ref type="table" target="#tab_3">4</ref>, the classification accuracies of the proposed SVM model are superior to those of SVM classifiers whose parameters are randomly selected, SVM classifier for intrusion detection by using PCA, KPCA to extract feature has a good performance in accuracy and runtime than that without feature extraction. The experimental results demonstrate that the features extracted by KPCA can provide more additional discriminatory information for improving classification performance than PCA. And dimension reduction can improve the generalization performance and running time of SVM classifier. Furthermore, results also show that KPCA is better than PCA. The reason lies in the fact that KPCA can explore higher order information of the original inputs than PCA. By using the kernel method to generalize PCA into nonlinear, KPCA implicitly takes into account higher order information of the original inputs.</p><p>More number of principal components can also be extracted in KPCA, eventually resulting in better generalization performance. We can also see from Table <ref type="table" target="#tab_3">4</ref> that the stabilities of the learning of N-KPCA-GA-SVM and KPCA-GA-SVM are better than Single-SVM. Compared to KPCA-GA-SVM, N-KPCA-GA-SVM is more effective in detecting, because DR and cc of N-KPCA-GA-SVM are higher than that of KPCA-GA-SVM. We can also see that Single-SVM needed longer training time, because it has to do cross-judging and more training, and the training time of KPCA-GA-SVM and PCA-GA-SVM is in the acceptable range. And N-KPCA-GA-SVM has obvious advantages in training time over KPCA-GA-SVM. It is apparent that N-KPCA-GA-SVM needed less test time than another three algorithms. RBFNN also obtains good classification accuracy, but RBFNN requires large amounts of training data, and needs to adjust the parameters of the hidden activation function, the parameters are determined by experience or by using the optimum method to tune the network parameters and connecting weights such as Genetic algorithm. In addition, this table can also see that the overall performance of N-KPCA-GA-SVM model is better than other four methods for intrusion detection.</p><p>The above results show that N-RBF and KPCA play some role in saving the training and test time. N-KPCA-GA-SVM is more reliable, compared to KPCA-GA-SVM, PCA-GA-SVM, Single-SVM and RBFNN. And it does not cause large fluctuations in detection performance. Moreover, it can improve the detection performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, a Novel hybrid KPCA SVM with GAs model is proposed for intrusion detection. In N-KPCA-GA-SVM model, KPCA is adopted to extract the principal features of intrusion detection data, and multi-layer SVM classifier is employed to estimate whether the action is an attack. N-RBF kernel function based on Gaussian kernel function is developed to shorten the training time and improve the performance of SVM classification model, GA is used to select suitable parameters for SVM classifier, which avoids over-fitting or under-fitting of the SVM model occurring because of the improper determination of these parameters. The experimental results show that the classification accuracies of the proposed KPCA SVM model are superior to those of SVM classifiers whose parameters are randomly selected, and SVM classifier by feature extraction using PCA, KPCA can achieve better generalization performance than that without feature extraction. Furthermore, the experimental results also show that on intrusion detection data, KPCA perform is better than PCA. The reason lies in the fact that KPCA can explore higher order information of the original inputs than PCA. By using the kernel method to generalize PCA into nonlinear, KPCA also implicitly takes into account higher order information of the original inputs. More number of principal components can also be extracted in KPCA, eventually resulting in better generalization performance.</p><p>For future work, we want to develop more algorithms of combining kernel methods with some other classification methods for pattern analysis and online intrusion detection, and research some other optimization algorithm for SVM parameters optimization.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .Fig. 2 .</head><label>12</label><figDesc>Fig. 1. Optimizing the parameters of improved KPCA SVM model with GA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The procedures of the proposed SVM model for intrusion detection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>( 2 )FN+TP( 3 )</head><label>23</label><figDesc>) Detection rate: DR = TN TN+FP False alarm rate: FAR = FN Correlation coefficient: cc = TPÃTN-FPÃFN â (TP+FN)(TP+FP)(TN+FP)(TN+FN)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Five training and test sets.</figDesc><table><row><cell cols="2">No. Training set</cell><cell></cell><cell></cell><cell>Test set</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Normal (%) Abnormal</cell><cell>Total</cell><cell cols="2">Normal (%) Abnormal</cell><cell>Total</cell></row><row><cell></cell><cell></cell><cell>(%)</cell><cell></cell><cell></cell><cell>(%)</cell><cell></cell></row><row><cell>D1</cell><cell>83.5</cell><cell>16.5</cell><cell>12560</cell><cell>72.5</cell><cell>17.5</cell><cell>11040</cell></row><row><cell>D2</cell><cell>90.5</cell><cell>9.5</cell><cell>11050</cell><cell>35.0</cell><cell>65.0</cell><cell>11428</cell></row><row><cell>D3</cell><cell>55.3</cell><cell>44.7</cell><cell>9040</cell><cell>57.9</cell><cell>42.1</cell><cell>13818</cell></row><row><cell>D4</cell><cell>93.9</cell><cell>6.1</cell><cell>10640</cell><cell>85.8</cell><cell>14.2</cell><cell>11650</cell></row><row><cell>D5</cell><cell>76.5</cell><cell>23.5</cell><cell>6540</cell><cell>64.9</cell><cell>35.1</cell><cell>12318</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Comparison of the performance of the three kernel functions.</figDesc><table><row><cell>No.</cell><cell>SVM (Kernels)</cell><cell>DR (%)</cell><cell>FAR (%)</cell><cell>cc</cell><cell>TrD (s)</cell><cell>TeD (s)</cell></row><row><cell>D1</cell><cell>POLY</cell><cell>92.892</cell><cell>0.12</cell><cell>0.926</cell><cell>28.693</cell><cell>1.528</cell></row><row><cell></cell><cell>RBF</cell><cell>89.256</cell><cell>0.06</cell><cell>0.912</cell><cell>456.062</cell><cell>158.67</cell></row><row><cell></cell><cell>N-RBF</cell><cell>93.867</cell><cell>0.0825</cell><cell>0.968</cell><cell>3.896</cell><cell>1.821</cell></row><row><cell>D2</cell><cell>POLY</cell><cell>92.259</cell><cell>0.10</cell><cell>0.897</cell><cell>21.266</cell><cell>1.484</cell></row><row><cell></cell><cell>RBF</cell><cell>93.551</cell><cell>0.025</cell><cell>0.914</cell><cell>489.625</cell><cell>158.63</cell></row><row><cell></cell><cell>N-RBF</cell><cell>95.907</cell><cell>0.10</cell><cell>0.943</cell><cell>3.359</cell><cell>1.828</cell></row><row><cell>D3</cell><cell>POLY</cell><cell>97.731</cell><cell>0.188</cell><cell>0.978</cell><cell>33.75</cell><cell>1.797</cell></row><row><cell></cell><cell>RBF</cell><cell>94.259</cell><cell>0.0375</cell><cell>0.951</cell><cell>174.375</cell><cell>116.625</cell></row><row><cell></cell><cell>N-RBF</cell><cell>95.669</cell><cell>0.0625</cell><cell>0.962</cell><cell>4.734</cell><cell>3.11</cell></row><row><cell>D4</cell><cell>POLY</cell><cell>93.333</cell><cell>0.08</cell><cell>0.958</cell><cell>25.219</cell><cell>1.516</cell></row><row><cell></cell><cell>RBF</cell><cell>84.909</cell><cell>0.04</cell><cell>0.908</cell><cell>431.062</cell><cell>155.67</cell></row><row><cell></cell><cell>N-RBF</cell><cell>95.879</cell><cell>0.29</cell><cell>0.966</cell><cell>3.547</cell><cell>1.844</cell></row><row><cell>D5</cell><cell>POLY</cell><cell>93.122</cell><cell>0.625</cell><cell>0.938</cell><cell>16.016</cell><cell>1.531</cell></row><row><cell></cell><cell>RBF</cell><cell>91.894</cell><cell>0.0375</cell><cell>0.937</cell><cell>61.172</cell><cell>103.937</cell></row><row><cell></cell><cell>N-RBF</cell><cell>93.330</cell><cell>0.187</cell><cell>0.946</cell><cell>2.188</cell><cell>1.844</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>Comparison of the detection rates of various categories.</figDesc><table><row><cell>Method/category</cell><cell>Normal</cell><cell>Probe</cell><cell>Dos</cell><cell>U2R</cell><cell>R2L</cell></row><row><cell>SVM (N-RBF)</cell><cell>0.9973</cell><cell>0.9862</cell><cell>0.8869</cell><cell>0.68</cell><cell>0.2484</cell></row><row><cell>SVM (RBF)</cell><cell>0.9980</cell><cell>0.1598</cell><cell>0.3628</cell><cell>0.04</cell><cell>0.0069</cell></row><row><cell>SVM (POLY)</cell><cell>0.9965</cell><cell>0.9532</cell><cell>0.5563</cell><cell>0.07</cell><cell>0.2391</cell></row><row><cell cols="6">greatly improved in comparison to the other two kernel functions,</cell></row><row><cell cols="6">it has saved lots of time in the training process, which lays the</cell></row><row><cell cols="5">foundation for the following experiments of the SVM.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc>Experimental results among different algorithms.</figDesc><table><row><cell>Methods</cell><cell>Dataset</cell><cell>F1</cell><cell>F2</cell><cell>F3</cell><cell>F4</cell><cell>F5</cell><cell>F6</cell><cell>F7</cell><cell>F8</cell><cell>F9</cell><cell>F10</cell></row><row><cell>N-KPCA-GA-SVM</cell><cell>DR (%)</cell><cell>94.226</cell><cell>95.302</cell><cell>95.188</cell><cell>94.264</cell><cell>96.302</cell><cell>96.377</cell><cell>95.302</cell><cell>95.302</cell><cell>94.280</cell><cell>96.032</cell></row><row><cell></cell><cell>FAR (%)</cell><cell>1.025</cell><cell>1.025</cell><cell>1.0</cell><cell>1.35</cell><cell>1.0</cell><cell>0.956</cell><cell>1.025</cell><cell>1.0</cell><cell>0.975</cell><cell>0.984</cell></row><row><cell></cell><cell>cc</cell><cell>0.955</cell><cell>0.966</cell><cell>0.935</cell><cell>0.931</cell><cell>0.946</cell><cell>0.968</cell><cell>0.956</cell><cell>0.956</cell><cell>0.949</cell><cell>0.963</cell></row><row><cell></cell><cell>TrD (s)</cell><cell>0.718</cell><cell>1.719</cell><cell>1.328</cell><cell>1.015</cell><cell>0.438</cell><cell>0.553</cell><cell>0.984</cell><cell>0.453</cell><cell>0.438</cell><cell>0.672</cell></row><row><cell></cell><cell>TeD (s)</cell><cell>1.985</cell><cell>5.546</cell><cell>3.391</cell><cell>2.719</cell><cell>1.105</cell><cell>1.11</cell><cell>1</cell><cell>1.11</cell><cell>1.469</cell><cell>1.286</cell></row><row><cell>KPCA-GA-SVM</cell><cell>DR (%)</cell><cell>92.065</cell><cell>93.033</cell><cell>92.617</cell><cell>93.936</cell><cell>94.017</cell><cell>95.175</cell><cell>93.828</cell><cell>92.093</cell><cell>90.615</cell><cell>93.092</cell></row><row><cell></cell><cell>FAR (%)</cell><cell>4.25</cell><cell>4.2</cell><cell>4.3</cell><cell>4.475</cell><cell>4.2</cell><cell>4.9</cell><cell>4.15</cell><cell>4.15</cell><cell>4.425</cell><cell>4.452</cell></row><row><cell></cell><cell>cc</cell><cell>0.814</cell><cell>0.831</cell><cell>0.826</cell><cell>0.818</cell><cell>0.839</cell><cell>0.848</cell><cell>0.838</cell><cell>0.84</cell><cell>0.767</cell><cell>0.869</cell></row><row><cell></cell><cell>TrD (s)</cell><cell>2.078</cell><cell>6.781</cell><cell>5.797</cell><cell>3.156</cell><cell>8.609</cell><cell>13.812</cell><cell>8.156</cell><cell>10.485</cell><cell>1.094</cell><cell>6.678</cell></row><row><cell></cell><cell>TeD (s)</cell><cell>6.218</cell><cell>13.641</cell><cell>11.719</cell><cell>9.266</cell><cell>16.938</cell><cell>21.328</cell><cell>15.532</cell><cell>18.969</cell><cell>4.656</cell><cell>18.254</cell></row><row><cell>PCA-GA-SVM</cell><cell>DR (%)</cell><cell>87.403</cell><cell>86.567</cell><cell>87.529</cell><cell>82.475</cell><cell>85.995</cell><cell>86.45</cell><cell>88.166</cell><cell>83.346</cell><cell>88.615</cell><cell>86.658</cell></row><row><cell></cell><cell>FAR (%)</cell><cell>3.675</cell><cell>4.4</cell><cell>5.3</cell><cell>5.125</cell><cell>4.075</cell><cell>4.175</cell><cell>4.375</cell><cell>4.05</cell><cell>4.425</cell><cell>4.478</cell></row><row><cell></cell><cell>cc</cell><cell>0.867</cell><cell>0.891</cell><cell>0.879</cell><cell>0.789</cell><cell>0.832</cell><cell>0.835</cell><cell>0.880</cell><cell>0.810</cell><cell>0.867</cell><cell>0.852</cell></row><row><cell></cell><cell>TrD (s)</cell><cell>7.547</cell><cell>13.3</cell><cell>18.44</cell><cell>6.85</cell><cell>9.164</cell><cell>15.27</cell><cell>48.69</cell><cell>83.2</cell><cell>1.105</cell><cell>14.264</cell></row><row><cell></cell><cell>TeD (s)</cell><cell>16.203</cell><cell>14.297</cell><cell>19.656</cell><cell>13.984</cell><cell>14.563</cell><cell>36.047</cell><cell>30.547</cell><cell>30.016</cell><cell>5.688</cell><cell>24.689</cell></row><row><cell>Single-SVM</cell><cell>DR (%)</cell><cell>86.752</cell><cell>77.139</cell><cell>76.571</cell><cell>81.302</cell><cell>75.095</cell><cell>79.637</cell><cell>76.95</cell><cell>75.007</cell><cell>78.615</cell><cell>80.765</cell></row><row><cell></cell><cell>FAR (%)</cell><cell>10.95</cell><cell>6.275</cell><cell>5.875</cell><cell>5.8</cell><cell>6.3</cell><cell>6.475</cell><cell>5.625</cell><cell>3.125</cell><cell>4.425</cell><cell>6.8</cell></row><row><cell></cell><cell>cc</cell><cell>0.754</cell><cell>0.729</cell><cell>0.73</cell><cell>0.771</cell><cell>0.712</cell><cell>0.748</cell><cell>0.737</cell><cell>0.724</cell><cell>0.767</cell><cell>0.762</cell></row><row><cell></cell><cell>TrD (s)</cell><cell>13.844</cell><cell>18.864</cell><cell>19.093</cell><cell>5.625</cell><cell>22.672</cell><cell>28.146</cell><cell>18.047</cell><cell>33.094</cell><cell>1.016</cell><cell>16.251</cell></row><row><cell></cell><cell>TeD (s)</cell><cell>14.813</cell><cell>26.656</cell><cell>23.922</cell><cell>20.562</cell><cell>42.094</cell><cell>43.813</cell><cell>35.047</cell><cell>47.969</cell><cell>5.64</cell><cell>32.682</cell></row><row><cell>RBFNN</cell><cell>DR (%)</cell><cell>87.063</cell><cell>79.236</cell><cell>77.139</cell><cell>82.265</cell><cell>73.265</cell><cell>80.983</cell><cell>77.654</cell><cell>78.278</cell><cell>80.142</cell><cell>82.247</cell></row><row><cell></cell><cell>FAR (%)</cell><cell>8.68</cell><cell>5.62</cell><cell>5.854</cell><cell>6.26</cell><cell>6.85</cell><cell>9.475</cell><cell>6.487</cell><cell>6.128</cell><cell>5.825</cell><cell>5.41</cell></row><row><cell></cell><cell>cc</cell><cell>0.812</cell><cell>0.789</cell><cell>0.768</cell><cell>0.798</cell><cell>0.708</cell><cell>0.804</cell><cell>0.826</cell><cell>0.804</cell><cell>0.828</cell><cell>0.8141</cell></row><row><cell></cell><cell>TrD (s)</cell><cell>18.345</cell><cell>20.662</cell><cell>15.216</cell><cell>13.245</cell><cell>24.132</cell><cell>26.254</cell><cell>19.452</cell><cell>31.421</cell><cell>2.345</cell><cell>15.564</cell></row><row><cell></cell><cell>TeD (s)</cell><cell>16.952</cell><cell>28.346</cell><cell>30.983</cell><cell>24.652</cell><cell>45.584</cell><cell>44.987</cell><cell>26.253</cell><cell>46.874</cell><cell>8.986</cell><cell>30.248</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work is supported by the National Natural Science Foundation of China (No. 61373063), the Science and Technology Department of Hunan Province of China (No. 2012SK4046, 2012FJ3005, and 2013FJ4217), the Research Foundation of Education Bureau of Hunan Province of China (No. 13C086, 12C0983). And the authors are grateful to the anonymous reviewers for valuable suggestions and comments, which are very helpful for improvement of this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Effective value of decision tree with KDD 99 intrusion detection datasets for intrusion detection system</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th International Conference on Advanced Communication Technology (ICACT&apos;08)</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1170" to="1175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An adaptive genetic based signature learning system for intrusion detection</title>
		<author>
			<persName><forename type="first">K</forename><surname>Shafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Abbass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="12036" to="12043" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A new approach to intrusion detection using artificial neural networks and fuzzy clustering</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="6225" to="6232" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Identifying intrusions in computer networks with principal component analysis</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Battiti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Conference on Availability Reliability and Security (ARES&apos;06)</title>
		<meeting>the First International Conference on Availability Reliability and Security (ARES&apos;06)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="270" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Anomalybased intrusion detection using fuzzy rough clustering</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chimphlee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Addullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Srinoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chimphlee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Paper Presented at the International Conference on Hybrid Information Technology (ICHIT&apos;06)</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="329" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A triangle area based nearest neighbors approach to intrusion detection</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="222" to="229" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Finding key attribute subset in dataset for outlier detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">S</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl. Syst</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="269" to="274" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A new intrusion detection system using support vector machines and hierarchical clustering</title>
		<author>
			<persName><forename type="first">L</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Awad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thuraisingham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Very Data Bases</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="507" to="521" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Combining support vector machines using genetic programming</title>
		<author>
			<persName><forename type="first">A</forename><surname>Majid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Mirza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Hybrid Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="125" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Intrusion detection by machine learning: a review</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">F</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="11994" to="12000" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Anomaly detection over noisy data using learned probability distributions</title>
		<author>
			<persName><forename type="first">E</forename><surname>Eskin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="255" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A machine learning framework for network anomaly detection using SVM and GA</title>
		<author>
			<persName><forename type="first">T</forename><surname>Shon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Moon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 3rd IEEE International Workshop on Information Assurance and Security</title>
		<meeting>3rd IEEE International Workshop on Information Assurance and Security<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="176" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Intrusion detection model based on particle swarm optimization and support vector machine</title>
		<author>
			<persName><forename type="first">S</forename><surname>Srinoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 IEEE Symposium on Computational Intelligence in Security and Defense Applications (CISDA&apos;07)</title>
		<meeting>the 2007 IEEE Symposium on Computational Intelligence in Security and Defense Applications (CISDA&apos;07)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="186" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Using density-based incremental clustering for anomaly detection</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 International Conference on Computer Science and Software Engineering</title>
		<meeting>the 2008 International Conference on Computer Science and Software Engineering</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="986" to="989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A novel intrusion detection system based on hierarchical clustering and support vector machines</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Horng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Kao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="306" to="313" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An ensemble design of intrusion detection system for handling uncertainty using neutrosophic logic classifier</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kavitha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Karthikeyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Maybell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl. Syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="88" to="96" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Use of computational intelligence in intrusion detection systems: a review</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Banzhaf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Swarm intelligence in intrusion detection: a survey</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kolias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kambourakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maragoudakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Security</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="625" to="642" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A novel approach of KPCA and SVM for intrusion detection</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3237" to="3244" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An efficient intrusion detection system based on support vector machines and gradually feature removal method</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="424" to="430" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">T</forename><surname>Jolliffe</surname></persName>
		</author>
		<title level="m">Principle Component Analysis</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Minimax probability machine classifier with feature extraction by kernel PCA for intrusion detection</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">J</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wireless Communications, Netw. Mobile Comput</title>
		<imprint>
			<biblScope unit="page" from="1" to="4" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Adaptive kernel principal analysis for online feature extraction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. World Acad. Sci. Eng. Technol</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="288" to="293" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Data classification using support vector machine</title>
		<author>
			<persName><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bhambhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Theoret. Appl. Inf. Technol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A Practical Guide to Support Vector Classification [EB/OL</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/â¼cjlin/papers/guide/guide.pdf" />
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A novel engine identification model based on support vector machine and analysis of precision-influencing factors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">B</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cent. South Univ. Technol</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1391" to="1397" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<title level="m">Genetic Algorithms in Search Optimization Machine Learning</title>
		<meeting><address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Stolfo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Prodromidis</surname></persName>
		</author>
		<ptr target="http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html" />
	</analytic>
	<monogr>
		<title level="j">KDD Cup</title>
		<imprint>
			<date type="published" when="1999">1999. 2011</date>
		</imprint>
	</monogr>
	<note>EB/OL</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
