<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BiRank: Towards Ranking on Bipartite Graphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
							<email>xiangnanhe@gmail.com</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Ming</forename><surname>Gao</surname></persName>
							<email>mgao@sei.ecnu.edu.cn</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dingxian</forename><surname>Wang</surname></persName>
							<email>diwang@ebay.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Web IR/NLP group</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">• M. Gao is with Software Engineering Institute</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Computing</orgName>
								<orgName type="laboratory">• M-Y. Kan is with Web IR/NLP group</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Search Science Department</orgName>
								<orgName type="institution">eBay Inc</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">BiRank: Towards Ranking on Bipartite Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">81E0D5FCD37A4603FCB247037E5BCBE9</idno>
					<idno type="DOI">10.1109/TKDE.2016.2611584</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Bipartite graph ranking</term>
					<term>graph regularization</term>
					<term>n-partite graphs</term>
					<term>popularity prediction</term>
					<term>personalized recommendation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The bipartite graph is a ubiquitous data structure that can model the relationship between two entity types: for instance, users and items, queries and webpages. In this paper, we study the problem of ranking vertices of bipartite graph, based on the graph's link structure as well as prior information about vertices (termed as query vector ). We present a new solution, BiRank, which iteratively assigns scores to vertices and finally converges to a unique stationary ranking. In contrast to the traditional random walk-based methods, BiRank iterates towards optimizing a regularization function, which smooths the graph under the guidance of the query vector; moreover, we establish the bridge with a Bayesian method, enabling the future extension in a probabilistic way. To show the rationale and extendability of the ranking methodology, we further extend it to rank for the more generic n-partite graphs. BiRank is generic and as such, its modeling of both the structure of graph and the features of vertices makes it flexible to encode various ranking hypotheses. To illustrate it, we apply the BiRank and TriRank (ranking for tripartite graphs) algorithms to two real-world applications: a general ranking scenario that predicts the future popularity of items, and a personalized ranking scenario that recommends interesting items to users. Extensive experiments on both synthetic and real-world datasets demonstrate BiRank's soundness (fast convergence), efficiency (linear in the number of graph edges) and effectiveness (achieving state-of-the-art in the two real-world tasks).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>G Raphs provide a universal language to represent rela- tionships between entities. In real-world applications, not only are the relationships between entities of the same type considered, but the relationships between different types of entities should also be considered. Such relationships naturally form a bipartite graph, containing rich information to be mined from. For example, in YouTube, the videos and users form a bipartite relationship where edges indicate a viewing action; in Web search, the relationship between queries and search engine result page entries are user actions ("clicks") and provide relevance judgements from the perspective of the users.</p><p>A fundamental task in the mining of bipartite graphs is to rank vertices against a specific criterion. Depending on the setting, assigning each vertex a ranking score can be used for many tasks, including the estimation of vertex importance (popularity prediction) and the inference of similar vertices to a target vertex (similarity search), and edge suggestion for connecting a target vertex (link prediction and recommendation). Existing work on graph ranking have largely focused on unipartite graphs, including PageRank <ref type="bibr" target="#b1">[2]</ref>, HITS <ref type="bibr" target="#b2">[3]</ref> 1 , and many of their variants <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>. Although several works <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref> have considered ranking on bipartite graphs, they have either focused on a specific application or adapted existing algorithms to handle the bipartite case. In our opinion, the work up to the current time, lacks a thorough theoretical analysis.</p><p>We focus on the problem of ranking vertices of bipartite graphs. We formulate the ranking problem in a generic manner -accounting for both the graph's structural information and the proper incorporation of any prior information for vertices, where such vertex priors can be used to encode any features of vertices. The main contributions of this paper are summarized as follows:</p><p>• We develop a new algorithm -BiRank -for addressing the ranking problem on bipartite graphs, and show its convergence to a unique stationary point; • We analyze BiRank through the formalism of graph regularization, and present a complementary Bayesian view. These two views enable future extensions to be grounded and compelling from a more theoretically sound way (either algebraically or probabilistically); • We deploy BiRank to the general ranking scenario of item popularity prediction, demonstrating how to specify it to encode several ranking hypotheses; • We extend the methodology to rank on the more generic n-partite graphs, and employ it for a personalized ranking scenario by mining tripartite graphs. • We conduct extensive experiments to justify our methods for the two real-world ranking scenarios, popularity prediction and personalized recommendation.</p><p>The paper is organized as follows. After reviewing related works in Section 2, we formalize the problem in Section 3. Then we describe the BiRank algorithm in Section 4, and interpret it from two views in Section 5. In Section 6, we discuss how to apply BiRank to the real-world applications of popularity prediction and personalized recommendation. We conduct experiments on both synthetic and real-world datasets to study the properties and efficiency of BiRank in Section 7, before concluding the whole paper in Section 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>BiRank, which ranks vertices of a bipartite graph, can be categorized as a link-based object ranking method under the paradigm of link mining <ref type="bibr" target="#b10">[11]</ref>. In this section, we focus on related work that contribute in the ranking method, and leave out the discussion of other relevant issues such as efficiency and evolving graphs. We then review some works that can benefit from such bipartite graph ranking, forming the potential downstream applications of our BiRank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Graph Ranking Methods</head><p>In the context of web graph ranking, the PageRank <ref type="bibr" target="#b1">[2]</ref> and HITS <ref type="bibr" target="#b2">[3]</ref> algorithms are the most prominent methods. PageRank estimates the importance score of vertices as the stationary distribution of a random walk process -starting from a vertex, the surfer randomly jumps to a neighbor according to the edge weight. HITS assumes each vertex has two roles: hub and authority, transforming the web graph to a bipartite graph. A vertex has high authority score if it is linked by many vertices with hub score, and a vertex has a high hub score if it links to many authoritative vertices.</p><p>Based on the basic themes of PageRank and HITS, many variants have been proposed. Ng et al. <ref type="bibr" target="#b11">[12]</ref> studied the stability of the two algorithms, finding HITS more sensitive to small perturbations in the graph structure under certain situations. They proposed two variants -Randomized HITS and Subspace HITS -to yield more stable rankings. Similarly, Lempel et al. <ref type="bibr" target="#b4">[5]</ref> found that applying HITS on graphs with TKCs (tightly knit communities, i.e., small but highly interconnected set of vertices) fails to identify meaningful authority vertices. They devised SALSA as a stochastic variant of HITS, for alleviating the TKC effect. Haveliwala <ref type="bibr" target="#b3">[4]</ref> proposed topic-sensitive PageRank (also known as personalized PageRank) by replacing the uniform teleportation vector with a non-uniform vector that encodes each vertex's topic score (cf. query vector in our BiRank context). Later on, Ding et al. <ref type="bibr" target="#b12">[13]</ref> unified HITS and PageRank under a normalized ranking framework. Inspired by the discrete-time Markov process explanation of PageRank, Liu et al. <ref type="bibr" target="#b5">[6]</ref> also proposed BrowseRank based on continuous time Markov process, exploiting user behavior data for page importance ranking. To incorporate side information on nodes and edges into ranking, Gao et al. <ref type="bibr" target="#b6">[7]</ref> extended PageRank in a semisupervised way by learning the transition matrix based on the features on nodes and edges.</p><p>Along a separate line of work -ranking on graphs based on regularization theory <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref> -has gained popularity within the machine learning community. These works mainly consider the problem of labeling vertices of a graph from partially known labels, also termed semisupervised learning or manifold learning on graph. Smola et al. <ref type="bibr" target="#b14">[15]</ref> summarized early works on graph kernels (e.g., Diffusion kernels), and formulated a family of regularization operators on graphs to encompass such kernels. Inspired by it, Zhou et al. <ref type="bibr" target="#b13">[14]</ref> developed a regularization framework consisting of two constraints: smoothness and fitting, and proposed an iterative algorithm <ref type="bibr" target="#b16">[17]</ref> for optimizing the regularization function. Later on, Zhou et al. supplemented the regularization framework by developing a discrete analytic theory of graphs <ref type="bibr" target="#b17">[18]</ref> and extending it to cover directed graphs <ref type="bibr" target="#b18">[19]</ref>. Agarwal <ref type="bibr" target="#b15">[16]</ref> further extended Zhou's regularization framework by replacing the fitting term (i.e., sum of squared errors) to the hinge ranking loss, proposing an algorithm with similarities to solving support vector machine to optimize the regularization function.</p><p>The above discussed works have all focused on ranking for homogeneous graphs, where vertices are of the same type. Our proposed BiRank targets the task of ranking for bipartite graphs, where vertices are of two different types. Separately handling the two vertex types is very important for ranking in bipartite graphs for many applications, which we will demonstrate through our experiments later. Inspired by Zhou's graph regularization framework <ref type="bibr" target="#b17">[18]</ref>, we develop the BiRank algorithm, which can be seen an extension of the manifold ranking algorithm <ref type="bibr" target="#b16">[17]</ref> on bipartite graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Ranking on Bipartite Graphs</head><p>There are other algorithms developed for bipartite graph ranking that target specific applications. As a natural way to represent relationship between two types of entities, bipartite graphs have been widely used across domains. As a consequence, ranking on bipartite graph data have been explored to address many applications. For example, in Web search, Deng et al. <ref type="bibr" target="#b7">[8]</ref> modeled queries and URLs for query suggestion, Cao et al. <ref type="bibr" target="#b19">[20]</ref> considered the cooccurrence between entities and queries for entity ranking, Li et al. <ref type="bibr" target="#b9">[10]</ref> modeled users and their search sessions for detecting click spam, and Rui et al. <ref type="bibr" target="#b20">[21]</ref> mined visual features and the surrounding texts for Web image annotation. In practical recommender systems, bipartite graphs methods have been used for Twitter user recommendation <ref type="bibr" target="#b21">[22]</ref> and YouTube video recommendation <ref type="bibr" target="#b22">[23]</ref>. In the domain of natural language processing, Parveen et al. <ref type="bibr" target="#b23">[24]</ref> generated multi-document summarization based on the relationship of sentences and lexical entities.</p><p>In terms of the ranking technique, these works share the same cornerstone -they all rank by iteratively propagating scores on the graph; either through a PageRank-like random walk or a HITS-like iterative process -which is adjusted for use on bipartite graphs. The prominent advantage of such propagation-based methods is that the global structure of the graph can be implicitly considered, which is an effective way to deal with the data sparsity and make use of the graph structure. Similar to their ranking algorithms, our proposed BiRank is also a propagation-based method; however, the main difference lies in the normalization strategy used in the iterative process. The symmetric normalization used in BiRank normalizes an edge weight by its both vertex ends, which accords a smoothing on the graph that can be explained by the regularization theory <ref type="bibr" target="#b17">[18]</ref>. As a result, extensions to the algorithm, such as incorporating more features about vertices and edges, can be achieved in a more theoretically sound way. More importantly, we believe such a bridge with the graph regularization theory and Bayesian framework allows BiRank a broader algorithmic extensions that are difficult to achieve by PageRank, HITS and their variants. For example, we can adjust the score propagation process to use a different ranking-based objective (Section 5.1.2), and learn the combination parameters in an automatic way (Section 5.2). We will study these algorithmic extensions of BiRank in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROBLEM FORMULATION</head><p>We first present the bipartite graph model and then give the notation convention used. We then formalize the ranking problem that we address in this paper. Notations. Let G = (U ∪ P, E) be a bipartite graph, where U and P represent the vertex sets of the two entity types respectively, and E represents the edge set (n.b., bipartite graphs have edges only between vertices of the two different types). Figure <ref type="figure" target="#fig_0">1</ref> shows an example of the bipartite structure. For each vertex u i , we denote its weighted degree (i.e., sum of connected edges' weights) as d i , and use a diagonal matrix D u to denote the weighted degrees of all vertices in U such that (D u ) ii = d i ; and similarly, for d j and D p . Note that in this paper, we deal with undirected bipartite graphs, i.e., we do not model any directionality in the edges. Problem Definition. In a nutshell, the general graph ranking problem is to assign each vertex a score s.t. a given expectation is satisfied. For example, PageRank <ref type="bibr" target="#b1">[2]</ref> infers an importance score for each vertex to capture the intuition that an important vertex should be linked by many other important vertices. As in many applications, a ranking simply based on the graph structure is insufficient; often, there also exists some prior information (or features) on the vertices. For example, in webpage ranking, we already know some webpages are important (e.g., official sites), and wish to incorporate this knowledge into the ranking process; in the application of recommendation, we need to consider a user's historical actions as the prior knowledge of the user's preference. We term such prior knowledge as a query vector, which encodes the prior belief of the score of vertices with respect to the ranking criterion. In this paper, we study the bipartite graph ranking problem where a query vector is given, formally defined as: Input: A bipartite graph G = (U ∪ P, E) with its weight matrix W . A query vector u 0 , p 0 encodes the prior belief concerning the vertices in U and P , respectively, with respect to the ranking criterion. Output: A function f : P ∪U → R, which maps each vertex in G to a real number. The function value f (u i ) and f (p j ) form the ranking score of vertex u i and p j , respectively. To keep the notation simple, we also use u i and p j to denote the ranking score, and represent the final ranking score of all vertices as two ranking vectors u = [u i ] and p = [p j ].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ITERATIVE BIRANK ALGORITHM</head><p>In this section, we detail the iterative paradigm of the BiRank algorithm. We first describe how we design the ranking algorithm, analyzing its time complexity. Then we study its convergence properties in theory. Finally we discuss the connection of BiRank with other similar-style iterative bipartite graph ranking algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Design of BiRank Algorithm</head><p>To rank vertices based on the graph structure, seminal algorithms like PageRank and HITS have been proposed. Motivated from their design, our intuition for bipartite graph ranking is that the scores of vertices should follow a smoothness convention, namely that: a vertex (from one side) should be ranked high if it is connected to higher-ranked vertices (from the other side). This rule defines a mutually-reinforcing relationship, which is naturally implemented as an iterative process that refines each vertex's score as the sum of the contribution from its connected vertices:</p><formula xml:id="formula_0">p j = |U | i=1 w ij u i ; u i = |P | j=1 w ij p j .</formula><p>As it is an additive update rule, normalization is necessary to ensure the convergence and stability. Two strategies have been widely adopted in previous work: 1) a PageRank-style that normalizes W (and W T ) to stochastic matrix, leading to a probabilistic random walk explanation; and 2) a HITSstyle method that normalizes the ranking scores of vertices after each iteration. In our BiRank method, we adopt the symmetric normalization scheme, which is inspired from Zhou's work <ref type="bibr" target="#b13">[14]</ref> of semi-supervised learning on graphs. The idea is to smooth an edge weight by the degree of its two connected vertices simultaneously:</p><formula xml:id="formula_1">p j = |U | i=1 w ij √ d i d j u i ; u i = |P | j=1 w ij √ d i d j p j ,<label>(1)</label></formula><p>where d i and d j are the weighted degrees of vertices u i and p j , respectively. The use of symmetric normalization is a key characteristic of BiRank, allowing edges connected to a high-degree vertex to be suppressed through normalization, lessening the contribution of high-degree vertices. This has the beneficial effect of toning down the dependence of top rankings on high-degree vertices, a known defect of the random walk-based diffusion methods <ref type="bibr" target="#b22">[23]</ref>. This gives rise to better quality results.</p><p>To account for the query vector p 0 and u 0 that encode the prior belief on the importance of the vertices, one can either opt for 1) incorporating the graph ranking results for combination in post-processing (a.k.a late fusion), or 2) factoring the query vector directly into the ranking process. The first way of post-processing yields a ranking that is a compromise between two rankings; for scenarios that the query vector defines a full ranking of vertices, this ensemble approach might be suitable. However, when the query vector only provides partial information -i.e., only a small proportion of vertices have a prior score while most other vertices have no prior information -this method fails to identify an optimal ranking. For example, in the application of personalized recommendation (see Section 6.2), the aim is to rank unconsumed items for a user; the query vector encodes the user's known preference, which is a sparse vector with the consumed items as non-zeros. In this case, simply combining the ranking from graph structure and query vector via post processing does not work, since the ranking of unconsumed items will solely depend on the graph structure. As such, in BiRank we opt for the second way that factors the query vector directly into the ranking process, which has the advantage of using the query vector to guide the ranking process:</p><formula xml:id="formula_2">p j = α |U | i=1 w ij √ d i d j u i + (1 -α)p 0 j ; u i = β |P | j=1 w ij √ d i d j p j + (1 -β)u 0 i ,<label>(2)</label></formula><p>where α and β are hyper-parameters to weight the importance of the graph structure and the prior query vector, to be set between [0, 1]. To keep notation simple, we can also express the iteration in its equivalent matrix form:</p><formula xml:id="formula_3">p = αS T u + (1 -α) p 0 ; u = βSp + (1 -β) u 0 ,<label>(3)</label></formula><p>where</p><formula xml:id="formula_4">S = D -1 2 u W D -1 2</formula><p>p , the symmetric normalization of weight matrix W . We call this set of update rules the BiRank iteration, which forms the core of the iterative BiRank algorithm. In a nutshell, BiRank first randomly initializes the ranking vector, and then iteratively execute the BiRank iteration until convergence (summarized in Algorithm 1).</p><p>For convergence, one can either monitor the change of ranking vectors p, u across iterations, or rely on a hold-out validation data to prevent overfitting. Moreover, the numerical convergence of BiRank is theoretically guaranteed, discussed later in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Time Complexity Analysis</head><p>It is easy to show that a direct implementation of BiRank iteration in Eq. (3) has a time complexity of O(|P | • |U |), mainly due to the multiplication of S T u and S p. However, note that in real-world applications, the matrix S is typically very sparse; for example in recommender systems, the useritem matrix to model is always over 99% sparse (e.g., Netflix challenge dataset). In this case, a representation of sparse matrix only needs to account for non-zero entries (which correspond to the edges of the bipartite graph), instead of all |P | • |U | entries. As such, the real-time cost needed for BiRank is O(c|E|), where c denotes the number of iterations executed to converge, and |E| denotes number of edges in the graph. Thus, BiRank is linear with respect to number of edges, ensuring good scalability to large-scale graphs. Moreover, our empirical experience show that BiRank has a very fast convergence rate -10 iterations are usually enough for convergence. One reason is that it can be seen as optimizing a convex function effectively using alternating optimization, which we will discuss later in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Convergence Analysis of BiRank</head><p>We show that BiRank can converge to a stationary and unique solution regardless of the initialization, followed by a theoretical analysis of the convergence speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Proof of Convergence</head><p>It is clear that the behavior of BiRank depends on the hyper-parameters α and β, which are in the range [0, 1]. To make a through analysis, we need to carefully consider the boundary conditions. Considering the two boundaries 0 and 1, we divide the proof into the following three cases:</p><p>Proof. 1. α = 0 or β = 0. When α = 0, the vector p = p 0 is unchanged across iterations. Thus u, which depends on p and u 0 , will also be unchanged after the first iteration. Similarly for the case of β = 0.</p><p>2. α = 1 and β = 1. In this case, the query vectors do not have any impact on the ranking, and the ranking is solely determined by the graph structure. The iterative update rule then reduces to Eq. ( <ref type="formula" target="#formula_1">1</ref>), whose matrix form is p = S T u, u = S p . By further reducing this, we obtain:</p><formula xml:id="formula_5">p (k) = (S T S)p (k-1) = ... = (S T S) k p (0) , u (k) = (SS T )u (k-1) = ... = (SS T ) k u (0) ,<label>(4)</label></formula><p>where k denotes the number of iterations, and p (0) , u (0) denote the initial ranking scores for vertices. Note that matrix S T S and SS T are both symmetric matrices. According to a lemma in standard linear algebra <ref type="bibr" target="#b24">[25]</ref>: Lemma 1. If M is a symmetric matrix, and v is a vector not orthogonal to the principle eigenvector of M , then the limit of M k v (after converting to unit vector) converges to the principle eigenvector of M with k increasing without bound.</p><p>By the lemma, we can see that with reasonable initialization, the iterative process will converge to a stationary solution p * and u * , which are the principle eigenvector of matrix S T S and SS T , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Normal cases.</head><p>We now consider the normal ranking scenarios that α and β are in the range of (0,1), meaning that both the graph structure and query vectors can affect the ranking process. Without loss of generality, we prove the convergence of p.</p><p>First, we eliminate u in p's update rule:</p><formula xml:id="formula_6">p = αβ(S T S) p +α(1 -β)S T u 0 +(1 -α) p 0 .<label>(5)</label></formula><p>Let matrix M be αβ(S T S) and vector z 0 be α(1β)S T u 0 +(1 -α) p 0 , which are both invariant across iterations. Then, we have: (6)   where k denotes the number of iterations, and p (0) denotes the initial ranking vector of p. Assuming M 's eigenvalues are in the range of (-1, 1), we can obtain:</p><formula xml:id="formula_7">p (k) = M p (k-1) + z 0 = ... = M k p (0) + k-1 t=0 M t z 0 ,</formula><formula xml:id="formula_8">lim k→∞ M k p (0) = 0, and lim k→∞ k-1 t=0 M t = (I -M ) -1 .</formula><p>where I denotes the identity matrix. In this case, we can derive the stationary solution of p as:</p><formula xml:id="formula_9">p * = (I -M ) -1 z 0 .<label>(7)</label></formula><p>However, the above stationary solution is derived based on the assumption that M 's eigenvalues are in the range (-1,1). Next, we prove the correctness of this assumption. Proof. Recall that M is defined as:</p><formula xml:id="formula_10">M = αβ(S T S) = αβ(D -1 2 u W D -1 2 p ) T (D -1 2 u W D -1 2 p ) = αβ(D -1 2 p W T D -1 u W D -1<label>2</label></formula><p>p ). To see M 's eigenvalues are bounded by αβ, we first construct a variant M v that has the same eigenvalues 2 as M :</p><formula xml:id="formula_11">M v = D 1 2 p M D -1 2 p = αβ(W T D -1 u W D -1 p ). Note that matrix W T D -1 u W D -1</formula><p>p is a stochastic matrix in which the entries of each column sum to 1. By standard linear algebra <ref type="bibr" target="#b24">[25]</ref>, for a stochastic matrix, its largest absolute value of the eigenvalues is always 1. Thus, the eigenvalues of M v are in the range [-αβ, αβ], and same must hold for M as they have exactly the same eigenvalues. The proof of M s eigenvalues is finished. As M 's eigenvalues are theoretically guaranteed in the range [-αβ, αβ] and in the normal cases α, β are in the range (0, 1), the assumption that M 's eigenvalues are in the range (-1, 1) holds. Therefore, we conclude that Eq. ( <ref type="formula" target="#formula_9">7</ref>) indeed forms the stationary solution of p. To round out the proof, we give the stationary solution of BiRank as follows:</p><formula xml:id="formula_12">p * = (I -αβS T S) -1 [α(1 -β)S T u 0 +(1 -α) p 0 ], u * = (I -αβSS T ) -1 [β(1 -α)S p 0 +(1 -β) u 0 ].<label>(8)</label></formula><p>The convergence proof of BiRank is finished.</p><p>This convergence proof gives an elegant closed-form solution -for any non-trivial initializations, the iterative algorithm of BiRank will converge to Eq. ( <ref type="formula" target="#formula_12">8</ref>). As such, an alternative method to our iterative BiRank is to direct calculate the closed-form stationary solution. Even so, we suggest the practitioners following the iterative procedure for two reasons. First, in real-world practice, when there is a large number of vertices to rank, the matrix inversion operation is very expensive, making the calculation of the closed-form solution inefficient. More specifically, matrix inversion is 2. The equality of the eigenvalues is easily shown by using determinants, denoted as | • |. Let the eigenvalues of Mv be λv, then we have</p><formula xml:id="formula_13">|Mv -λvI| = |D 1 2 p (M -λvI)D -1 2 p | = |D 1 2 p | • |M -λvI| • |D -1 2 p | = |M -λvI| = 0, meaning that λv are also M 's eigenvalues.</formula><p>usually assumed a O(N 3 ) time complexity <ref type="bibr" target="#b25">[26]</ref>; thus the time complexity of directly calculating the stationary solution is O(|P | 3 + |U | 3 ), which can be much higher than the upper bound of the iterative solution O(c|P | • |U |). Second, the iterative process emphasizes the underlying motivation that reinforcing a vertex's importance from its neighbors and the query vector. As such, one does not have to run the iterations until convergence; instead, one can compute the scores by starting from any initialization and performing a fixed number of iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Speed of Convergence</head><p>Since the behavior of BiRank depends on the graph structure, query vector and hyper-parameters α, β, we analyze how do these factors impact BiRank's convergence speed.</p><p>In each BiRank iteration, the score of a vertex comes from both its neighbors and the query vector. Since the query vector is static that remains unchanged across iterations, it will not cause the divergence of ranking scores, and the main uncertainty for convergence stems from the neighbors diffusion part. As such, the number of iterations required to converge will increase as α and β increase (the empirical evidence in Figure <ref type="figure" target="#fig_8">6</ref> also verifies this property). Clearly, the "slowest" convergence is when α and β are set to 1, where the effect of query vector is eliminated. Next, we analyze this upper bound case of convergence.</p><p>When both α and β are set to 1, the update of p at the iteration k can be written as: p (k) = (S T S)p (k-1) , which essentially can be seen as the power method for the symmetric eigenvalue problem (Chapter 8.2 of <ref type="bibr" target="#b24">[25]</ref>). It is known that the convergence of power method is determined by the second dominant eigenvalue of the transition matrix. In spite of the slight difference that the power iteration requires an additional L 2 normalization on the ranking vector (while our BiRank does not), we point out that BiRank shares the same property of convergence speed.</p><p>Theorem 2. The convergence rate of BiRank depends on |λ 2 |, where λ 2 is the second largest eigenvalue of the matrix S T S in magnitude.</p><p>Proof. As S T S is a symmetric matrix, it is guaranteed to have n eigenvalues which are real numbers (n = |P |). Let its eigenvalues be λ 1 , λ 2 , ..., λ n , where</p><formula xml:id="formula_14">|λ 1 | ≥ |λ 2 | ≥ ... ≥ |λ n |,</formula><p>and vectors x 1 , x 2 , ..., x n be the corresponding eigenvectors. Then, the starting vector p (0) can be expressed as:</p><formula xml:id="formula_15">p (0) = n i=1 c i x i ,</formula><p>where {c i } are constant coefficients. Then the update of p (k) can be written as:</p><formula xml:id="formula_16">p (k) = c 1 (S T S) k x 1 + c 2 (S T S) k x 2 + ... + c n (S T S) k x n = c 1 λ k 1 (x 1 + n i=2 c i (λ i /λ 1 ) k x i ).<label>(9)</label></formula><p>Here we use the fact that (S T S)x i = λ i x i . Hence, we see that the non-essential quantities decay at a rate of approximately |λ 2 /λ 1 |. As we have shown in Theorem 1, S T S has the same eigenvalues with a variant stochastic matrix, thus we have</p><formula xml:id="formula_17">|λ 1 | = 1.</formula><p>The proof is finished.</p><p>To summarize, the convergence rate of BiRank depends on the normalized adjacency matrix S and parameters α, β. Analytically, larger α and β will lead to slower convergence; theoretically, smaller magnitude of the second dominant eigenvalue of S T S will result in faster convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Connection with Other Algorithms</head><p>There are some bipartite graph ranking algorithms <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b19">[20]</ref>, though developed for specific applications with varying ranking targets, they share the similar spirit with our BiRank. Specifically, in terms of the iterative ranking process, they have the same update rule form as Eq. ( <ref type="formula" target="#formula_3">3</ref>); the main difference is in how to generate the transition matrices (S and S T for updating u and p, respectively). It is instructive to study the difference with these algorithms. TABLE 1: Transition matrices (i.e., S and S T in Eq. ( <ref type="formula" target="#formula_3">3</ref>)) of different bipartite graph ranking algorithms. Note that S T here denotes a matrix, rather than just the transpose of S.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Definition of Transition Matrices HITS (Kleinberg <ref type="bibr" target="#b2">[3]</ref>)</p><formula xml:id="formula_18">S = W ; S T = W T Co-HITS (Deng et al.[8]) S = W D -1 p ; S T = W T D -1 u BGER (Cao et al.[20]) S = D -1 u W ; S T = D -1 p W T BGRM (Rui et al.[21]) S = D -1 u W D -1 p ; S T = D -1 p W T D -1 u BiRank (our proposal) S = D -1 2 u W D -1 2 p ; S T = D -1 2 p W T D -1 2 u</formula><p>Table <ref type="table">1</ref> summarizes the ways of constructing transition matrices using our symbol notations. From a high-level view, these algorithms differ in how they utilize the vertex degree to normalize each edge weight (except that HITS does not account for the query vector). HITS, the earliest proposed algorithm, uses the original weight matrix W asis; although the convergence can be guaranteed in theory, HITS is sensitive to outliers in graph <ref type="bibr" target="#b11">[12]</ref> and suffers from the tightly knit communities <ref type="bibr" target="#b4">[5]</ref>. Co-HITS <ref type="bibr" target="#b7">[8]</ref> normalizes each column of W (and W T ) stochastically, having an explanation of simulating random walks on the graph. However, random walk methods can be biased towards the highdegree vertices <ref type="bibr" target="#b22">[23]</ref>. While BGER <ref type="bibr" target="#b19">[20]</ref> avoids this defect by normalizing each row of W (and W T ) stochastically, yielding an effect of suppressing the scores of high-degree vertices. However, the one-side normalization of BGER does not account the degrees of p vertices when updating u, allowing high-degree p vertices to exert a stronger impact in the diffusion process; and vice versa. Similar with our proposed BiRank, BGRM also applies a symmetric normalization on W , while the level of normalization differs (the sum of normalization exponents is -2 and -1 for BGRM and BiRank, respectively). Although it is difficult to tell which way between them is more advantageous, we point out that BiRank employs the matrix S T S in a similar fashion to a stochastic matrix (the same eigenvalues, see Theorem 1) and corresponds to a regularization framework, both of which are nice properties that BGRM lacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">FOUNDATIONS OF BIRANK</head><p>In contrast to the traditional graph ranking algorithms (e.g., PageRank and HITS), BiRank iterations are implicitly optimizing an objective function. This is analogous to the manifold ranking algorithm on graphs <ref type="bibr" target="#b13">[14]</ref>. In what follows, we investigate the regularization framework for BiRank and present a Bayesian explanation of the ranking algorithm. These two views shed important insight into the basis of BiRank, allowing future extensions in a theoretically sound way. To show its extendability, we finally generalize the methodology to rank for the more general n-partite graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Regularization Framework</head><p>Inspired from the discrete graph theory <ref type="bibr" target="#b17">[18]</ref>, we construct the regularization function as follows:</p><formula xml:id="formula_19">R(u, p) = |P | j=1 |U | i=1 w ij ( p j d j - u i √ d i ) 2 + γ |P | j=1 (p j -p 0 j ) 2 + η |U | i=1 (u i -u 0 i ) 2 ,<label>(10)</label></formula><p>where γ and η are the regularization parameters to combine different components (they are constants corresponding to α and β in BiRank). Next, we first show that optimizing Eq. ( <ref type="formula" target="#formula_19">10</ref>) leads to the iterative BiRank algorithm, and then interpret the meaning of the regularization function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Relationship with BiRank</head><p>Eq. ( <ref type="formula" target="#formula_19">10</ref>) defines an objective function with the ranking scores as model parameters. To optimize the objective function, let us first calculate its first-order derivatives:</p><formula xml:id="formula_20">∂R ∂p j = (2 + 2γ)p j -2γp 0 j -2 |U | i=1 w ij u i √ d i d j ∂R ∂u i = (2 + 2η)u i -2ηu 0 i -2 |P | j=1 w ij p j √ d i d j .<label>(11)</label></formula><p>Adopting alternating optimization, we obtain the update rule by setting the gradients to 0:</p><formula xml:id="formula_21">pj = 1 1 + γ |U | i=1 wij √ di dj ui + γ 1 + γ p 0 j , ui = 1 1 + η |P | j=1 wij √ di dj pj + η 1 + η u 0 i ,<label>(12)</label></formula><p>which exactly recovers the BiRank iteration Eq. ( <ref type="formula" target="#formula_2">2</ref>) by plugging γ = 1-α α , η = 1-β β into the equation. As such, we see that BiRank is actually iterating towards optimizing the regularization function Eq. ( <ref type="formula" target="#formula_19">10</ref>).</p><p>As we have shown BiRank converges to a stationary solution in Section 4.2.1. Now a question arises: does the solution found by BiRank lead to the regularization function's global optimum? In fact it does, as the regularization function is strictly convex in both p j and u i . Theorem 3. The regularization function R(u, p) defined by Eq.( <ref type="formula" target="#formula_19">10</ref>) is strictly convex and only one global minimum exists.</p><p>Proof. According to the convex optimization theory, a continuous, twice differentiable function is strictly convex if and only if its Hessian matrix is positive definite. As R(u, p) is a continuous function, we now prove it is twice differentiable and that its Hessian matrix is positive definite.</p><p>The second order derivative of R(u, p) is:</p><formula xml:id="formula_22">∂ 2 R ∂p j ∂p j = 2 + 2γ; ∂ 2 R ∂u i ∂u i = 2 + 2η; ∂ 2 R ∂p j ∂u i = 2 -w ij √ d i d j .</formula><p>We can see R(u, p) is twice differentiable. Let matrix A be the</p><formula xml:id="formula_23">(|U | + |P |) × (|U | + |P |</formula><p>) weighted adjacency matrix of the bipartite graph. Then the Hessian of R(u, p) can be written as:</p><formula xml:id="formula_24">2(I -D -1 2 AD -1 2 ) + 2B</formula><p>, where D is a diagonal matrix where each entry D kk denotes the weighted degree of k-th vertex (can be of either side); B is a diagonal matrix that each entry B kk is γ or η, dependant on the choice of origin (side) for the k-th vertex.</p><p>Note that the matrix (I -D -1 2 AD -1 2 ) is the normalized Laplacian matrix of the graph. By spectral graph theory <ref type="bibr" target="#b26">[27]</ref>, the normalized Laplacian matrix of a graph is positive semidefinite. Meanwhile, B is also positive definite because its eigenvalues are all positive (eigenvalues of a diagonal matrix are its diagonal values). Finally, according to the standard linear algebra, the addition of a positive semidefinite matrix and positive definite matrix is also positive definite. Thus, we reach the conclusion that the Hessian matrix must be positive definite. The proof is finished.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Interpretation of Regularization</head><p>It is instructive to interpret the meaning of the regularization function and see how it is constructed. First, it can be seen as enforcing two constraints in assigning the ranking scores on the vertices: A smoothness constraint that implies structural consistency -that nearby vertices should not vary much in their ranking scores; and a fitting constraint which encodes the query vector -that the ranking should not overly deviate from prior belief. Smoothness. The first term of Eq. 10 implements the smoothness constraint, which constrains a vertex's normalized score to be similar to the normalized scores of its connected neighbors. Minimizing it leads to the simplified BiRank algorithm devised in Eq. ( <ref type="formula" target="#formula_1">1</ref>). Moreover, it can be seen as the squared sum (L 2 distance) of edge derivatives on the graph, as introduced in graph regularization theory <ref type="bibr" target="#b17">[18]</ref>:</p><formula xml:id="formula_25">∂f ∂e eij = w ij d i u i - w ij d j p j ,</formula><p>which measures the variation (or energy drop) of the ranking function on edge e ij . I.e., if two vertices are strongly connected but exhibit a large difference in their scores, then the magnitude of the variation will be large. Variants of our vanilla BiRank can be derived by employing other methods to combine the edge derivatives, e.g., the L 1 distance, which can yield and model different effects for smoothness.</p><p>Fitting. The second and third term of the regularization function gives the fitting constraint for the query vectors p 0 and u 0 , respectively:</p><formula xml:id="formula_26">R f (p) = |P | j=1 (p j -p 0 j ) 2 , R f (u) = |U | i=1 (u i -u 0 i ) 2 , (<label>13</label></formula><formula xml:id="formula_27">)</formula><p>This fitting term is easy to understand: it regularizes the value of each vertex's score to be similar with its prior score, i.e., its value in the query vector.</p><p>In our formulation of BiRank, we have chosen a MSE (mean squared error) loss function form; other ranking-oriented loss functions, such as the BPR-OPT <ref type="bibr" target="#b27">[28]</ref>, may be more suited if one seeks to maintain the vertices' relative ordering in the query vector during the ranking process. We leave this possibility for future work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Bayesian Explanation</head><p>On the basis of the above regularization framework, we now present a Bayesian explanation for BiRank.</p><p>Figure <ref type="figure" target="#fig_3">2</ref> shows the graphical model representation of the ranking method. We model the query vectors p 0 and u 0 as observations, which are generated by the latent factors p and u (distributions), serving as the importance scores of the vertices; the weight matrix W forms the prior for generating the latent factors. The goal is to infer the latent factors p and u that generate the observations p 0 and u 0 .</p><p>The MAP (maximum a posteriori) estimation is given by:</p><formula xml:id="formula_28">arg max u,p p(u, p | u 0 , p 0 , W ).</formula><p>By Bayes' rule and the conditional independence indicated in the graphical model, we have:</p><formula xml:id="formula_29">p(u, p | u 0 , p 0 , W ) = p(u 0 , p 0 | u, p) • p(u, p |W ) p(u 0 , p 0 ) ∝ p(u 0 , p 0 | u, p) • p(u, p |W ) ∝ p(u 0 | u) • p(p 0 | p) • p(u, p |W ).</formula><p>Note that p and u are not conditionally independent with each other given the prior W , as a vertex's score is also influenced by its neighbors' scores. Taking the logarithm, MAP estimation is then equivalent to: We then devise the conditional probabilities as follows:</p><formula xml:id="formula_30">p(u, p |W ) = 1 Z up e -Rs(u,p) , p(p 0 | p) = 1 Z p e -γR f (p) , p(u 0 | u) = 1 Z u e -ηR f (u) ,</formula><p>where Z up , Z p and Z u are normalization constants, and where R s (u, p) is the smoothness term, and R f (p) and R f (u) are the fitting terms defined in Eq. ( <ref type="formula" target="#formula_26">13</ref>). From this formalization, we can see that minimizing the regularization function is equivalent to maximizing the posteriori probability of generating the query vector. This shows the equivalence between BiRank's ranking process and a Bayesian network. We map the ranking problem to probabilistic graphical modeling, allowing the extension of BiRank in a probabilistic way, which is more flexible and adaptable for different applications. For example, if there is additional prior knowledge or context for the vertices, we can model them as priors of p, u and use the desired distributions; moreover, aside from MAP, other inference techniques can also be applied to infer the ranking scores, such as the variational inference and MCMC sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Generalization to n-partite Graph Ranking</head><p>Our proposed BiRank methodology is general and versatile.</p><p>Here, we generalize it to rank vertices of the more general n-partite graphs.</p><p>A n-partite graph is a graph whose vertices can be partitioned into n different independent sets. We represent it as G({P t }; {E tl }), where P represents vertices, E represents edges, t and l represent the indices of the independent vertex sets, satisfying 1 ≤ t, l ≤ n. Let the weight matrix of edges E tl be W tl , which is a |P t | × |P l | matrix. If the graph is undirected, we have W lt = W T tl . The symmetrically normalized matrix is defined as</p><formula xml:id="formula_31">S tl = √ D t W tl √ D l</formula><p>, where D t and D l represent the diagonal degree matrix of vertices P t and P l , respectively. Let the ranking vector and query vector of vertices in P t be p t and p 0 t , respectively. Then, the objective function for vertex ranking is defined by smoothing the connected vertices (of pairwise vertex types) and fitting the query vectors (of each vertex type):</p><formula xml:id="formula_32">R = t η t ||p t -p t 0 || 2 + l =t γ tl i,j (W tl ) ij ( (p t ) i D t ii - (p l ) j D l jj ) 2 ,</formula><p>where γ tl and η t are hyper-parameters that control the importance of the corresponding component. Similar to BiRank, this regularization function is strictly convex for all model parameters. Thereby, the global minimum can be achieved by alternating optimization, which leads to the iterative update solution as:</p><formula xml:id="formula_33">p 1 = l =1 α 1l S 1l p l + (1 - l =1 α 1l )p 0 1 , ...... p t = l =t α tl S tl p l + (1 - l =t α tl )p 0 t ,<label>(14)</label></formula><p>where the hyper-parameters α tl are associated with γ tl and η t , indicating the weight of graph substructure E tl in contributing to the final ranking. Iteratively executing the above update rule until convergence, we obtain the ranking. We call this algorithm n-partiteRank, as an extension of BiRank for the n-partite graph; it is easy to see when n = 2, the algorithm exactly recovers the BiRank. Also, the time complexity of the algorithm is linear to number of edges in the n-partite graph, which is very efficient for large-scale heterogeneous graphs in real-world applications. In Section 6.2, we demonstrate how to utilize this generic algorithm to model user reviews (n = 3, i.e., TriRank) for the application of personalized recommendation <ref type="bibr" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">APPLICATIONS</head><p>In this section, we demonstrate how to apply the BiRank method to two real-world applications; namely, 1) predicting the future popularity of items, and 2) recommending items of interest to users. We choose to model user comment data for addressing the relevant task, since it is a form of explicit feedback that is easily accessible to both content providers and external observers<ref type="foot" target="#foot_0">3</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Popularity Prediction</head><p>Predicting the popularity of web content has a wide range of applications, such as online marketing <ref type="bibr" target="#b29">[30]</ref> and recommender system <ref type="bibr" target="#b25">[26]</ref>. In what follows, we first briefly introduce the task, and then show how to customize BiRank to address the problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Task Introduction</head><p>A direct and objective metric to measure an item's popularity is the view count, which evaluates users' attention on the item. Thereby, previous works have primarily focused on modeling the view histories of items <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b29">[30]</ref> and casted the prediction as a regression task. However, for some external services (which are not the content providers themselves), items' view histories are not easily accessible. Specifically, most websites do not explicitly provide the view history for an item. Even in the cases where a website like YouTube and Flickr provides the current number of views, one will have to repeatedly and periodically crawl the item pages to build view histories, potentially very bandwidth intensive for practitioners.</p><p>To assist external observers in predicting items' popularity, we are more interested in an alternative and more viable solution -modeling the affiliated user comments of items. In contrast to view count, the advantage of comments is the exposure of users' commenting activities up to the current time -crawling once, one can get the previous history and perform the prediction directly. However, the key deficiency is that the comment history can be much sparser than view history, since a user viewing an item may not comment on it. For example, it is common that two items have no comments during the time interval, while they attract views at a different rate. As such, existing view-based solutions <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b31">[32]</ref> (which are mostly regression-based methods) can fail to leverage comment series to predict popularity accurately.</p><p>To tackle the sparsity issue in user comments for quality prediction, we need to account for more popularity signals in addition to the comment count. Here, we propose three ranking hypotheses observed from user comments that we wish to incorporate into our popularity prediction solution:</p><p>H1. Temporal Factor: If an item has received many comments recently, it is more likely to be popular in the near future. More recent comments are a salient signal that more users focused on the item recently.</p><p>H2. User Social Influence: If the users commenting on an item are more influential, the item is more likely to receive more views in the future. This is enabled by the Web 2.0 social interfaces that propagate a user's comments to friends and followers.</p><p>H3. Item Current Popularity: If an item has already been popular, it is likely to garner more views in the future. This is partially effected by the existing visual interfaces of Web 2.0 systems: the more views an item has, the more likely it will be promoted to users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">BiRank Customization</head><p>To customize BiRank for a certain ranking purpose, we need to construct the weighted bipartite graph model and devise the query vectors. Bipartite Graph Construction. As we deal with users' commenting behaviors on items, we model their relationship as a bipartite graph -users and items form the two sides of vertices U and P , respectively, and edges E represent comments. If and only if a user has commented on an item, there is an edge between them. We use the edge weight to model the respective comment's contribution towards the item's future popularity. As the hypothesis H1 shows a strong near-term correlation, we assign w based on temporal considerations. Specifically, recent (older) comments should contribute more (less) to an item's future popularity. To achieve this, we choose a monotonically decreasing exponential decay function:</p><formula xml:id="formula_34">wij = δ a(t 0 -t ij )+b , (<label>15</label></formula><formula xml:id="formula_35">)</formula><p>where δ is the decay parameter that controls the decay rate, t 0 is the ranking time and t ij is the commenting time; a and b are constants, to be tuned for the particular media and site. Time units are arbitrary; they can be assigned as minutes, hours, days, weeks or other units, depending on the temporal resolution and the domain of the items to rank.</p><p>If no edge exists between u i and p j , then w ij is zero. In our empirical study, we find a setting of δ = 0.85, a = 1, b = 0 leads to good performance, and thus use this setting across datasets. As we focus on short-term popularity prediction, we set the time unit as 1 day. Query Vectors Setup. We devise the user query vector u 0 and item query vector p 0 to account for the hypotheses H2 and H3, respectively. Intuitively, if a user has more friends, his behavior is likely to influence more users. Thus we set a user's prior score in the query vector proportional to the log value of his number of friends:</p><formula xml:id="formula_36">u 0 i = log(1 + g i ) |U | k=1 log(1 + g k )</formula><p>,</p><p>where g i is user u i 's number of friends at the ranking time.</p><p>Note that we use add-1 smoothing to address the case where a user has no friends. H3 models the current popularity factor on items. As such, the item query vector should encode our prior belief on each item's popularity prior to examining its recent comments. We capture this potential "rich-get-rich" effect by defining an item's score in the query vector as:</p><formula xml:id="formula_37">p 0 j = log v j |P | k=1 log v k</formula><p>, where v j denotes the view count of item p j at ranking time.</p><p>After finalizing the edge weights and query vectors, the rationale in our design can be more clearly seen by looking into the BiRank iteration in Eq. ( <ref type="formula" target="#formula_3">3</ref>). First, it captures the mutual reinforcement between users and items -the more recent the comments are by a user on an item, the higher the popularity score the item will receive; and in return, the popularity of the target item increases the user's influence. Second, the score of items and users is partially determined by the original setting of the query vector. To sum up, BiRank determines a user's social influence based on two source of evidence: his level of activity and his number of friends. Analogously, BiRank determines an item's future popularity based on four aspects: the frequency and recency of comments on it, the influence of the users commenting on it, and its current accumulated popularity. Thus, from a qualitative point of view, we see that the formulation of BiRank can encode our hypotheses on the ranking function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Personalized Recommendation</head><p>In this subsection, we apply the generalized, n-partiteRank to the application of personalized recommendation. This is a more challenging task than popularity prediction, since it needs to generate a personalized ranking of items for each user. In what follows, we first show how to employ BiRank to encode the well-known collaborative filtering effect for recommendation. Then we use the TripartiteRank (short for TriRank) to additionally model aspects (extracted from comments' texts) for enhanced recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Collaborative Filtering with BiRank</head><p>In recommendation systems, collaborative filtering (CF) is the most successful and widely-used technique for personalization. It exploits user-item interactions (e.g., ratings, click histories) by assuming that users with similar interest consume similar items. The core of a CF algorithm lies in how it models the similarity among users and items. For example, neighbor-based CF <ref type="bibr" target="#b32">[33]</ref> directly estimates the similarity by adopting statistical measure on the user-item matrix, while latent factor-based CF <ref type="bibr" target="#b25">[26]</ref> estimates the similarity by projecting items/users into a latent space. Under our BiRank paradigm, similarity is estimated by means of smoothing the user-item graph with the target user's known preference, embodied as a query vector. We use an example in Figure <ref type="figure" target="#fig_5">3</ref> to illustrate how the smoothness works. Users and items represent the two types of vertices, and edge weights denote the rating scores (here, a zero score means the user did not rate the item; a missing value). Assume we want to recommend items to the target user u 1 , who has rated p 1 with a score of 5. We construct the query vector by setting the prior of p 1 to 5 and other vertices to 0. Now, we consider how the BiRank predicts u 1 's preference (i.e., the similarity to other items) with this setting. As p 1 is connected more strongly to u 2 than u 3 , by the smoothness constraint, u 2 will be given a higher score than u 3 . This indicates that BiRank treats u 2 more similar with u 1 than u 3 . Finally, since the edge weights of &lt; u 2 ,p 2 &gt; and &lt; u 3 ,p 3 &gt; are identical, BiRank will assign p 2 a higher score than p 3 , meaning that p 2 is a more suitable candidate to recommend for u 1 than p 3 . From this qualitative analysis, we see that by properly setting the query vector's values, smoothing the user-item relation leads to the collaborative filtering </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yelp</head><p>bar, salad, menu, chicken, sauce, restaurant, rice, cheese, fries, bread, sandwich, drinks Amazon camera, quality, sound, price, battery, pictures, screen, size, memory, lens effect. More specifically, by setting the query vector as the rated items of the target user, BiRank functions similar to item-based CF <ref type="bibr" target="#b32">[33]</ref> which represents a user by his historical actions for personalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Modelling Aspects with TriRank</head><p>Aside from ratings, which form the basis for collaborative filtering, most Web 2.0 systems also encourage users to pen reviews. These reviews justify a user's ratings, offering the underlying reasons for the rating by discussing the specific properties of the item. We term these specific properties as aspects, which are nouns or noun phrases that represent the features of items (see Table <ref type="table" target="#tab_1">2</ref> as examples). Aspects are well-suited as a complementary data source for CF, since a mention of an aspect implies the user's interest in the aspect, which in turn reveals the user's preference. In this subsection, we model the aspects with TriRank to improve the CF-based recommendation. Similar to the application of BiRank to popularity prediction, we first show how to construct the tripartite graph, and then design the query vectors to implement the personalized ranking. Tripartite Graph Construction. After extracting aspects from user reviews, we construct a tripartite graph with users, items and aspects as the three types of vertices. We formalize the input as a list of triples, where each triple &lt; u i , p j , a k &gt; denotes that user u i has rated item p j with a review mentioning aspect a k and is represented as a triangle with edges e ij , e ik and e jk in the graph. Figure <ref type="figure" target="#fig_6">4</ref> shows an example of the tripartite graph. Each edge carries a weight, which is crucial to determine the meaning of smoothness and the behaviors of TriRank. The setting of user-item edge weights should encode the collaborative filtering effect: in cases with explicit feedback, it can be the rating score (as have illustrated in Section 6.2.1); for implicit feedback, it can denote whether the user has interacted with or browsed the item (measured as either a binary yes/no, or an integer view count). Our datasets provide explicit user ratings, so we use these ratings asis. The setting of aspect connected edges should reflect the aspect filtering effect: if a user is interested in an aspect, then the system should rank the items that are good at this aspect high. Thus, we set the edge weights of useraspect relation and item-aspect relation to connote the degree of user interest (item specialty) with respect to the aspect.</p><p>Once aspects are identified in reviews, we use the review frequency (i.e., number of reviews that mention the aspect) within all a user's (item's) reviews as the edge weight. As is done in general information retrieval, we take the logarithm of the review frequency, to dampen the effect of aspects that appear very frequently.</p><p>Query Vectors Setup. The query vectors should encode the target user's prior preference on the vertices, which serve as the gateway for personalization. Here we discuss how to set the query vectors for target user u i .</p><p>For the item query vector p 0 , an element takes a positive value if the target user has interacted with the item; otherwise, 0. Thus we adopt the i th row vector of the user-item matrix as the p 0 for the target user u i . Similarly, the aspect query vector a 0 is set as the respective row vector of the user-aspect matrix, denoting the target user's prior preference on aspects. The user preference vector u 0 should denote the target user's similarity with other users. When user's social network is available, we can use her friends information to initialize u 0 . Here due to the lack of social information in our dataset, we adopt a basic approach, simply setting the target user herself as 1, and all other users as 0. Considering that the weight matrix is symmetrically normalized, we also apply the L 1 norm on p 0 , a 0 and u 0 respectively, for a meaningful combination.</p><p>Our final recommendation solution works as follows. After constructing the tripartite graph, we preform TriRank with the personalized query vectors for each target user. The ranking process follows the iteration defined in Eq. ( <ref type="formula" target="#formula_33">14</ref>). After convergence (usually in 10 iterations), items with the highest scores serve as the recommendations for the user, and the aspect vertices with the highest scores can be used as explanatory factors for the recommendations <ref type="bibr" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">EXPERIMENTS</head><p>In this section, we empirically examine BiRank's properties and effectiveness. We first conduct experiments on synthetic data to study BiRank's convergence and time efficiency. Then we perform experiments on real-world datasets to evaluate BiRank performance for the two applications of popularity prediction and personalized recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Experiments on Synthetic Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.1">Datasets</head><p>We concern ourselves with two forms of generated graphs: 1. Synthetic Random Graphs. These random graphs are generated by sampling edges from a uniform distribution. We control the density of the generated bipartite graph to simulate real-world graph sparsity. Given the expected density of the graph, we visit each potential edge and generate a uniformly random number in the range (0, 1); if the number is less (or equal) than the density value, we add the edge into the graph. 2. Synthetic Power-law Graphs. Considering that many real-world graphs follow power-law in degree distribution, such as document-word and user-item graphs, we also generate the power-law bipartite graphs. We adopt the power-law graph generation algorithm in <ref type="bibr" target="#b33">[34]</ref>: starting from an empty graph, it follows two main steps: first it assigns a degree x to each vertex v from the distribution p(d v = x) ∝ x -λ where λ &gt; 1; then, it sorts the vertices by degree in decreasing order, and assigns neighbors to each vertex according to the degree. We adjust the second step for generating bipartite graph -sampling neighbors of a vertex only from the vertices of the other side.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.2">Convergence Study</head><p>There are two natural questions need to be answered empirically regarding BiRank's convergence<ref type="foot" target="#foot_2">4</ref> : 1) Will BiRank iterations converge to the optimal solution of the regularization function as analyzed theoretically? 2) How does the algorithm hyper-parameters (i.e., α and β) influence BiRank's convergence rate? Since our findings were consistent across many settings, we only report results with a set of representative settings. shows the difference (i.e., squared sum) of the ranking vector before and after the update of each iteration. As we can see, BiRank successfully finds the optima of the regularization function in all four cases. Our further examination (not shown) validates that the ranking vector obtained by BiRank iterations is actually same with the stationary solution. This demonstrates BiRank's ability in converging to the unique and optimal solution of the regularization function, regardless of the graph structure. Moreover, the convergence rate is rather fast for these simulated problems -usually within 10 iterations. Another finding is that the deepest descents are in the early iterations, which impose the most influence to the ranking. 2. Convergence rate w.r.t. algorithm parameters. In BiRank, α and β are the hyper-parameters to combine the score calculated from the graph structure and query vector. They act like the damping factor in PageRank, and are crucial to the ranking results and convergence. We study the impact of the two parameters on the convergence rate. The convergence threshold is set as 0.0001 for Vector Diff, a strict condition that guarantees a sufficient convergence. Figure <ref type="figure" target="#fig_8">6</ref> plots the number of iterations to converge on two graphs of size 10K × 20K. Both graphs show the same trend that BiRank needs more iterations to converge with a larger α (and β). This verifies our qualitative analysis in Section 4.2.2 that smaller value of α (and β) leads to a larger effect of the static query vectors, helpful to quick convergence. Figure <ref type="figure">7</ref> shows the average time per iteration for graphs of different settings. First, from each single line, we see that the actual running time per iteration exhibits linearity w.r.t. to number of edges in the graph. More specifically, each iteration takes about 0.9 seconds for graphs with 2M edges, steadily increasing to 9 seconds for graphs with 20M edges. This is rather efficient, given that we only run the algorithm in a single thread; for large-scale graphs, one can easily scale up the algorithm by parallelizing the matrix operations in multiple threads. Comparing across lines, we find that graphs of larger size take more time but still within the same magnitude. As the edge count is the same, the additional time is caused by traversing additional vertices in such larger graphs when performing matrix operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Evaluation of Popularity Prediction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">Experimental Settings</head><p>Datasets and metrics. Table <ref type="table" target="#tab_3">3</ref> shows the demographics of the three real-world datasets used in our experiments in this section. Each dataset is constructed by the search results of some seed queries. More details about the dataset are given in <ref type="bibr" target="#b0">[1]</ref>. The evaluation ground-truth (GT) is the number of views (note, not the number of comments) received in the future three days after the original crawl date (i.e., ranking date t 0 ).  Given a set of items, BiRank outputs a ranking list of the items, indicating their predicted popularity. To assess the quality of the predicted ranking with the GT ranking globally, we adopt the Spearman coefficient, which measures the agreement between two rankings.</p><p>Baselines. We compare with the following six baselines: 1. View Count (VC): Rank based on the current view count of items, corresponding to our Hypothesis H3 alone. 2. Comment Count in the Past (CCP): Rank based on the number of comments received in the 3-day period prior to t 0 , corresponding to our Hypothesis H1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Multivariate Linear model (ML) [31]:</head><p>A state-of-the-art regression method for popularity prediction. We apply this method on the comment series with the time unit as 3 days. This baseline is to test the traditional view-based methods when applied to modeling comments. 4. PageRank [2]: This is the most widely used graph ranking method. Since the bipartite nature can cause the random walk to be non-stationary, we employ the standard method to set a uniform self-transition weight w ii = 1 for all nodes before converting to a stochastic matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Co-HITS [8]:</head><p>This algorithm is devised for ranking on bipartite graphs by interleaving two random walks. To make a fair algorithmic comparison with BiRank, we apply the same query vectors to Co-HITS and tune the parameters in the same way. 6. BGER [20]: This is another algorithm designed for ranking on bipartite graphs. Instead of simulating a random walk, it normalizes the edge weights in a different way and is analogously explained as heat diffusion. We apply the same query vectors and parameter search for this method.</p><p>To expedite parameter tuning, we randomly held out 10% of the dataset as the development set, and employ grid search to find the optimal parameters. Then the performance is evaluated on the remaining 90% as the testing items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2">Performance Comparison</head><p>Table <ref type="table" target="#tab_4">4</ref> shows the performance of the methods on the three datasets. First, we can see that the three bipartite graph ranking methods (lines 5 -7) significantly outperform other methods. This is because these methods model all the three ranking hypotheses we proposed, while other methods only partially model the hypotheses. Among the three bipartite ranking methods, BiRank achieves the best performance in general (best on two datasets YouTube and Flickr), followed by Co-HITS (best on Last.fm) and BGER. Further experimentation of 10-fold cross validation shows that the improvements of BiRank over Co-HITS and BGER on YouTube and Flickr datasets are consistent and statistically significant (p &lt; 0.01, via one-sample paired t-test). Moreover, Co-HITS outperforms BGER consistently, although the random walk treatments of Co-HITS are suspicious to bias the high-degree vertices while BGER does not have this issue. We suspect the reason of Co-HITS's strong performance might be that the bias effect is diluted by the setting of query vectors, which can regulate the random walks effectively. Focusing on the result of PageRank (line 4), we see that it performs very poorly for Flickr and Last.fm. This indicates that just the centrality of an item in the user-item temporal graph is insufficient for accurate popularity prediction. In addition, the performance discrepancy between PageRank and CoHITS (also a random walk-based method) highlights the importance of separately handling the two vertex types within the bipartite graph.</p><p>It is surprising that the regression approach ML underperforms CCP, as ML leverages more information: comments in the recent 30 days compared with CCP's access to only three days. There are two reasons for this: 1) short-term prediction, 2) sparsity of comments. As the prediction task is a short-term one, the most recent data carries the most signal -"What happened yesterday will happen tomorrow"; the performance score of CCP verifies this point. Secondly, the sparsity in comment series (e.g., some time units have zero count) can negatively affect the regression process in an unexpected manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Evaluation of Personalized Recommendation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.1">Experimental Settings</head><p>Datasets. We experiment with two public review datasets: Yelp 5 and Amazon Electronics 6 . We follow the common practice in evaluating recommendation algorithms <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b25">[26]</ref> that filters out users and items with fewer than 10 reviews. We used the sentiment analysis tool developed by <ref type="bibr" target="#b34">[35]</ref> for extracting aspects from review texts. Table <ref type="table" target="#tab_6">5</ref> summarizes the statistics of the filtered datasets and Table <ref type="table" target="#tab_1">2</ref> shows examples of the top aspects extracted. Baselines. We compare with the following methods that are commonly used in top-K recommendation: 1. Popularity (ItemPop). Items are ranked by their popularity judged by number of ratings. This non-personalized method benchmarks the performance of the top-K task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">ItemKNN [33]</head><p>. This is standard item-based CF. We tested the method with different number of neighbors, finding that using all neighbors works best. 3. PureSVD <ref type="bibr" target="#b35">[36]</ref>. A state-of-the-art model-based CF method for top-K recommendation, which performs SVD on the whole matrix. We tuned the number of latent factors.   . This graph method has been widely used for top-K recommendation, such as by <ref type="bibr" target="#b36">[37]</ref>. For a fair comparison, we set the personalized vector the same with TriRank's query vectors and tuned the damping factor. 5. TagRW <ref type="bibr" target="#b37">[38]</ref>. A state-of-the-art tag-based recommendation solution, which performs random walks on the user-user and item-item similarity graph. Since tags have a similar form with aspects, we feed aspect as tags into the method.</p><p>For each user, we sort her reviews in chronological order. The first 80% are used for training, followed by 10% as validation (for parameter tuning) and 10% as test set (for evaluation). Given a test user, we assess the ranked list of top-K items with Hit Ratio <ref type="bibr" target="#b27">[28]</ref> and NDCG <ref type="bibr" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.2">Performance Comparison</head><p>Figure <ref type="figure" target="#fig_10">8</ref> plots the performance of top-K recommendation methods evaluated by NDCG from position 10 to 50. Performance of hit ratio shows the similar trend with NDCG thus is omitted due to the space limitation. ItemPop performed very weakly on the Amazon dataset, thus it was entirely omitted in Figure <ref type="figure" target="#fig_10">8b</ref> to better highlight the performance of the other methods. As can be seen, our TriRank consistently outperforms the baselines with a large margin, and the onesample paired t-test verifies that the improvements over all baselines are statistically significant with p &lt; 0.01. For a more detailed discussion, we further show the concrete scores obtained at the position 50 Table <ref type="table" target="#tab_8">6</ref>.</p><p>Focusing on Lines 1-4 that are all CF methods that only model the user-item relationship, we see that our BiRank achieves the best performance on both datasets; specifically, it improves over the competitive recommendation methods ItemKNN and PureSVD with a relative improvement about 8.3%. This is very encouraging, and gives evidence of the merit of our specification of BiRank (in Section 6.2.1) for collaborative filtering. ItemKNN performs very well on the Yelp dataset (better than PureSVD), but poorly on the Amazon one. One possible reason comes from data sparsity: as in Table <ref type="table" target="#tab_6">5</ref>, each item of the Amazon dataset only has 3.9 reviews on average. In such cases, the statistical similarity measure may fail in neighbor-based CF. In contrast, modelbased methods are more robust to sparse data by projecting users and items to the latent space. Lastly, we see Item Popularity performs the worst, indicating the importance of modeling users personalized preferences, rather than just recommending popular items.</p><p>Moving to Lines 5-7 of review-based methods, we see that they generally improve over the methods that use CF only, indicating the utility of reviews (more specifically, item aspects) for uncovering users' preference and complementing with user ratings. Second, TriRank achieves the best performance, further improving over BiRank with over a 10% relative improvement and outperforming PageRank and TagRW significantly. This verifies the effectiveness of our TriRank in incorporating the aspects for enhanced recommendation. Lastly, TagRW is inferior to PageRank in utilizing the same aspect source. We believe the main reason comes from TagRW's transformation of the user-itemaspect graph to user-user and item-item graphs, which can cause some signal loss especially when the original relationships are sparse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>In this paper, we focus on the problem of ranking vertices of bipartite graphs. We devise a new, generic algorithm -BiRank -which ranks vertices by accounting for both the graph structure and prior knowledge. BiRank is theoretically guaranteed to converge to a stationary solution, and can be explained as by both a regularization view and a Bayesian view. This appealing feature allows future extensions to BiRank to be grounded in a theoretically principled way. As a case in point, to show its extendability, we further generalize the BiRank method to rank vertices in the generalized n-partite graph case. To demonstrate the efficacy of our proposal, we examine two ranking scenarios: a general ranking scenario of item popularity prediction and a personalized ranking scenario of user preference prediction. By properly setting the graph's edge weights and query vectors, BiRank can be customized to encode various ranking hypotheses. Extensive experiments on both synthetic and real datasets demonstrate the efficacy of our method.</p><p>In the future, we will study how to optimally learn the hyper-parameters of BiRank. Owing to the regularization and Bayesian view of BiRank, two solutions can be explored -by adapting the parameters based on the validation set , or by integrating over the parameters via MCMC under the Bayesian network formalism. In addition, we will explore the use of ranking-based loss <ref type="bibr" target="#b27">[28]</ref> for guiding the ranking with a different objective.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Bipartite User-Item Structure. We use u i to denote the i-th vertex in U , and p j to denote the j-th vertex in P , where 1 ≤ i ≤ |U | and 1 ≤ j ≤ |P |; set cardinality |U | denotes number of elements in U . Edges carry weights non-negative w ij , modeling the relationship strength between the connected vertices u i and p j . As such, we can represent all edge weights of the graph as a |U | × |P | matrix W = [w ij ].For each vertex u i , we denote its weighted degree (i.e., sum of connected edges' weights) as d i , and use a diagonal matrix D u to denote the weighted degrees of all vertices in U such that (D u ) ii = d i ; and similarly, for d j and D p . Note that in this paper, we deal with undirected bipartite graphs, i.e., we do not model any directionality in the edges. Problem Definition. In a nutshell, the general graph ranking problem is to assign each vertex a score s.t. a given expectation is satisfied. For example, PageRank<ref type="bibr" target="#b1">[2]</ref> infers an importance score for each vertex to capture the intuition that an important vertex should be linked by many other important vertices. As in many applications, a ranking simply based on the graph structure is insufficient; often, there also exists some prior information (or features) on the vertices. For example, in webpage ranking, we already know some webpages are important (e.g., official sites), and wish to incorporate this knowledge into the ranking process; in the application of recommendation, we need to consider a user's historical actions as the prior knowledge of the user's preference. We term such prior knowledge as a query vector, which encodes the prior belief of the score of vertices with respect to the ranking criterion. In this paper, we study the bipartite graph ranking problem where a query vector is given, formally defined as: Input: A bipartite graph G = (U ∪ P, E) with its weight matrix W . A query vector u 0 , p 0 encodes the prior belief concerning the vertices in U and P , respectively, with respect to the ranking criterion. Output: A function f : P ∪U → R, which maps each vertex in G to a real number. The function value f (u i ) and f (p j ) form the ranking score of vertex u i and p j , respectively. To keep the notation simple, we also use u i and p j to denote the ranking score, and represent the final ranking score of all vertices as two ranking vectors u = [u i ] and p = [p j ].</figDesc><graphic coords="3,96.60,165.75,154.80,67.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1 :1 2 4 p 5 u</head><label>1245</label><figDesc>Iterative BiRank AlgorithmInput: Weight matrix W , query vector p 0 , u 0 , and hyper-parameters α, β; Output: Ranking vectors p, u; Symmetrically normalize W : S = D Randomly initialize p and u; 3 while Stopping criteria is not met do ← αS T u +(1 -α) p 0 ; ← βS p +(1 -β) u 0 ; 6 end 7 return p and u</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Theorem 1 .</head><label>1</label><figDesc>M 's eigenvalues are in the range [-αβ, αβ].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Graphical model representation of BiRank.</figDesc><graphic coords="7,372.17,43.70,129.00,98.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>ln p(u, p |W ) + ln p(u 0 | u) + ln p(p 0 | p) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: A toy example of using BiRank to model the collaborative filtering effect. The target user u 1 has previously rated item p 1 with a rating score 5 (in tail).Users and items represent the two types of vertices, and edge weights denote the rating scores (here, a zero score means the user did not rate the item; a missing value). Assume we want to recommend items to the target user u 1 , who has rated p 1 with a score of 5. We construct the query vector by setting the prior of p 1 to 5 and other vertices to 0. Now, we consider how the BiRank predicts u 1 's preference (i.e., the similarity to other items) with this setting. As p 1 is connected more strongly to u 2 than u 3 , by the smoothness constraint, u 2 will be given a higher score than u 3 . This indicates that BiRank treats u 2 more similar with u 1 than u 3 . Finally, since the edge weights of &lt; u 2 ,p 2 &gt; and &lt; u 3 ,p 3 &gt; are identical, BiRank will assign p 2 a higher score than p 3 , meaning that p 2 is a more suitable candidate to recommend for u 1 than p 3 . From this qualitative analysis, we see that by properly setting the query vector's values, smoothing the user-item relation leads to the collaborative filtering</figDesc><graphic coords="9,421.00,434.37,103.20,80.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: An example of the tripartite graph (the dashed line illustrates the additional input &lt; u 1 , p 3 , a 2 &gt;).</figDesc><graphic coords="10,76.06,462.45,51.60,74.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 : 1 .</head><label>51</label><figDesc>Fig. 5: Convergence status of two generated graphs.1. Convergence to optimum. Figure5plots the convergence status of each iteration on two representative synthetic graphs (the random setting has a density of 1%; the powerlaw graph sets λ = 2). The black line (Stationary) benchmarks the optimal solution from the direct calculation of the stationary solution Eq. (8). The blue line (Iterative) shows the regularization function's value after the update of each iteration; the red line (Vector Diff, y-axis scale of the right) shows the difference (i.e., squared sum) of the ranking vector before and after the update of each iteration. As we can see, BiRank successfully finds the optima of the regularization function in all four cases. Our further examination (not shown) validates that the ranking vector obtained by BiRank iterations is actually same with the stationary solution. This demonstrates BiRank's ability in converging to the unique and optimal solution of the regularization function, regardless of the graph structure. Moreover, the convergence rate is rather fast for these simulated problems -usually within 10 iterations. Another finding is that the deepest descents are in the early iterations, which impose the most influence to the ranking. 2. Convergence rate w.r.t. algorithm parameters. In BiRank, α and β are the hyper-parameters to combine the score calculated from the graph structure and query vector. They act like the damping factor in PageRank, and are crucial to the ranking results and convergence. We study the impact of the two parameters on the convergence rate. The convergence threshold is set as 0.0001 for Vector Diff, a strict condition that guarantees a sufficient convergence. Figure6plots the</figDesc><graphic coords="11,48.83,246.15,123.84,88.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: Convergence rate w.r.t. α and β.</figDesc><graphic coords="11,325.83,43.70,103.20,83.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>7. 1 . 3 Fig. 7 :</head><label>137</label><figDesc>Fig. 7: Running time per iteration w.r.t. number of edges.</figDesc><graphic coords="11,327.16,325.98,103.20,81.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 8 :</head><label>8</label><figDesc>Fig. 8: Performance comparison of top-K recommendation evaluated by NDCG from position 10 to 50 (i.e., K).</figDesc><graphic coords="13,51.81,43.70,123.84,99.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>4 .</head><label>4</label><figDesc>PageRank<ref type="bibr" target="#b3">[4]</ref></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2016.2611584, IEEE Transactions on Knowledge and Data Engineering IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2016</figDesc><table /><note><p>1041-4347 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 2 : Top automatically extracted aspects.</head><label>2</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>1041-4347 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2016.2611584, IEEE Transactions on Knowledge and Data Engineering IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2016</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 3 : Demographics of the three Web 2.0 datasets.</head><label>3</label><figDesc></figDesc><table><row><cell>Dataset</cell><cell>Item#</cell><cell>User#</cell><cell>Comment#</cell><cell>Avg C/I</cell><cell>Crawled Date</cell></row><row><cell>YouTube</cell><cell>21,653</cell><cell>3,620,487</cell><cell>7,246,287</cell><cell>334.7</cell><cell>2012/8/9</cell></row><row><cell>Flickr</cell><cell>26,815</cell><cell>37,690</cell><cell>169,150</cell><cell>6.3</cell><cell>2012/9/3</cell></row><row><cell>Last.fm</cell><cell>16,284</cell><cell>77,996</cell><cell>530,237</cell><cell>32.6</cell><cell>2012/10/24</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 4 : Popularity prediction evaluated by Spearman coefficient (%). "*" denotes the statistical significance for</head><label>4</label><figDesc>p &lt; 0.01 judged</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>by the one-sample paired t-test.</head><label></label><figDesc></figDesc><table><row><cell>Method</cell><cell>YouTube</cell><cell>Flickr</cell><cell>Last.fm</cell></row><row><cell>1. VC</cell><cell>73.39</cell><cell>58.42</cell><cell>67.31</cell></row><row><cell>2. CCP</cell><cell>83.35</cell><cell>59.43</cell><cell>67.21</cell></row><row><cell>3. ML</cell><cell>78.24</cell><cell>58.00</cell><cell>38.09</cell></row><row><cell>4. PageRank</cell><cell>80.72</cell><cell>28.15</cell><cell>10.24</cell></row><row><cell>5. Co-HITS</cell><cell>85.21</cell><cell>63.81</cell><cell>72.71  *</cell></row><row><cell>6. BGER</cell><cell>84.10</cell><cell>63.17</cell><cell>68.94</cell></row><row><cell>7. BiRank (ours)</cell><cell>88.21  *</cell><cell>64.76  *</cell><cell>70.93</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 5 : Statistics of datasets in evaluation.</head><label>5</label><figDesc></figDesc><table><row><cell>Dataset</cell><cell cols="4">Review# Item# User# Aspect#</cell></row><row><cell>Yelp</cell><cell>114,316</cell><cell>4,043</cell><cell>3,835</cell><cell>6,025</cell></row><row><cell>Amazon</cell><cell>55,677</cell><cell>14,370</cell><cell>2,933</cell><cell>1,617</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE 6 : Recommendation performance (%) evaluated at Rank 50. BiRank outperforms CF-based methods (Lines 1-3) and TriRank outperforms all other methods.</head><label>6</label><figDesc></figDesc><table><row><cell>Dataset</cell><cell></cell><cell>Yelp</cell><cell cols="2">Amazon</cell></row><row><cell>Metric(%)</cell><cell>HR</cell><cell>NDCG</cell><cell>HR</cell><cell>NDCG</cell></row><row><cell>1. ItemPop</cell><cell>10.61</cell><cell>4.08</cell><cell>6.13</cell><cell>2.37</cell></row><row><cell>2. ItemKNN</cell><cell>15.72</cell><cell>6.37</cell><cell>12.69</cell><cell>10.15</cell></row><row><cell>3. PureSVD</cell><cell>14.94</cell><cell>6.16</cell><cell>14.94</cell><cell>10.55</cell></row><row><cell cols="2">4. BiRank (ours) 17.00  5. PageRank 15.90</cell><cell>6.52</cell><cell>17.49</cell><cell>11.78</cell></row><row><cell>6. TagRW</cell><cell>15.25</cell><cell>6.02</cell><cell>17.47</cell><cell>10.65</cell></row><row><cell>7. TriRank (ours)</cell><cell>18.58</cell><cell></cell><cell></cell><cell></cell></row></table><note><p>* 6.90 * 15.97 * 11.16 * * 7.69 * 18.44 * 12.36 *</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>In contrast, implicit feedback -such as users' clicks on webpages and views on items -is only obtainable for the internal content providers. For external observers, such as the third-party services, implicit feedback is usually difficult to access.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2016</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>Note that due to the difficulty of controlling the eigenvalues of generated graphs, we do not empirically study the impact of the second dominant eigenvalue on convergence rate. While the impact has been theoretically proved in Theorem 2.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank the anonymous reviewers for their valuable comments, and acknowledge the additional discussion and help from Jun-Ping Ng, Tao Chen, Yiqun Liu and Kazunari Sugiyama. NExT research is supported by the National Research Foundation, Prime Minister's Office, Singapore under its IRC@SG Funding Initiative.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Xiangnan He is currently a post-doc research fellow of the School of Computing at the National University of Singapore. His research interests include information retrieval, text mining, recommender systems and machine learning. His works have appeared in several major international conferences such as SIGIR, WWW, CIKM and AAAI. He has served as program committee member of international conferences such as SIGIR, WWW and EMNLP.</p><p>Ming Gao is an associate professor of Software Engineering Institute with the East China Normal University, China. He received his doctorate from the School of Computer Science, Fudan University. His research interests include uncertain data management, streaming data processing, social network analysis and data mining. His work appears in major international conferences including ICDE, ICDM, DASFAA and WebSci.</p><p>Min-Yen Kan is an associate professor at the National University of Singapore. He is a member of the executive committee of the Association of Computational Linguistics (ACL) and maintains the ACL Anthology, the community's largest archive of published research. He is an associate editor for the Springer "Information Retrieval" journal. His research interests include digital libraries and applied natural language processing and information retrieval. Specific projects include work in the areas of scientific discourse analysis, full-text literature mining, machine translation, lexical semantics and applied text summarization.</p><p>Dingxian Wang is a Research Engineer with the Search Science Department in eBay. He is specifically working on the project of product classification for improving search ranking. His research interests mainly include information retrieval, software engineering, natural language processing and applied machine learning. His works have appeared in international conferences including WISE, CSE and ICSSP.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Predicting the popularity of web 2.0 items based on user comments</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-Y</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR &apos;14</title>
		<meeting>of SIGIR &apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The PageRank citation ranking: Bringing order to the Web</title>
		<author>
			<persName><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Stanford InfoLab</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Authoritative sources in a hyperlinked environment</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="604" to="632" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Topic-sensitive PageRank</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Haveliwala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW &apos;02</title>
		<meeting>of WWW &apos;02</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="517" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The stochastic approach for linkstructure analysis (salsa) and the tkc effect</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lempel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Networks</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="387" to="401" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Browserank: letting web users vote for page importance</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR &apos;08</title>
		<meeting>of SIGIR &apos;08</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="451" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semi-supervised ranking on very large graphs with rich metadata</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of KDD &apos;11</title>
		<meeting>of KDD &apos;11</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="96" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A generalized Co-HITS algorithm and its application to bipartite graphs</title>
		<author>
			<persName><forename type="first">H</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of KDD &apos;09</title>
		<meeting>of KDD &apos;09</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="239" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Relevance search and anomaly detection in bipartite graphs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGKDD Explor. Newsl</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="48" to="55" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Search engine click spam detection based on bipartite graph propagation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WSDM &apos;14</title>
		<meeting>of WSDM &apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="93" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Link mining: A survey</title>
		<author>
			<persName><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Diehl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGKDD Explor. Newsl</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="3" to="12" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Stable algorithms for link analysis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR &apos;01</title>
		<meeting>of SIGIR &apos;01</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="258" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pagerank, hits and a unified framework for link analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Husbands</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR &apos;02</title>
		<meeting>of SIGIR &apos;02</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="353" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning with local and global consistency</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Lal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="321" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Kernels and regularization on graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning Theory and Kernel Machines, ser. LNCS</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2777</biblScope>
			<biblScope unit="page" from="144" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Ranking on graph data</title>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML &apos;06</title>
		<meeting>of ICML &apos;06</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Ranking on data manifolds</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schlkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Regularization on discrete spaces</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="361" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning from labeled and unlabeled data on a directed graph</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML &apos;05</title>
		<meeting>of ICML &apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1036" to="1043" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bipartite graph based entity ranking for related entity finding</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WI-IAT &apos;11</title>
		<meeting>of WI-IAT &apos;11</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Bipartite graph reinforcement model for web image annotation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of MM</title>
		<meeting>of MM</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="585" to="594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Wtf: The who to follow service at twitter</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW &apos;13</title>
		<meeting>of WWW &apos;13</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="505" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Video suggestion and discovery for youtube: Taking random walks through the view graph</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baluja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Seth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sivakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yagnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW &apos;08</title>
		<meeting>of WWW &apos;08</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="895" to="904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Multi-document summarization using bipartite graphs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Parveen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Strube</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="15" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Van Loan</surname></persName>
		</author>
		<title level="m">Matrix computations</title>
		<imprint>
			<publisher>JHU Press</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fast matrix factorization for online recommendation with implicit feedback</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-Y</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR &apos;16</title>
		<meeting>of SIGIR &apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Chung</surname></persName>
		</author>
		<title level="m">Spectral Graph Theory</title>
		<imprint>
			<publisher>American Mathematical Society</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">92</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Bpr: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of UAI &apos;09</title>
		<meeting>of UAI &apos;09</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Trirank: Review-aware explainable recommendation by modeling aspects</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-Y</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CIKM &apos;15</title>
		<meeting>of CIKM &apos;15</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1661" to="1670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Predicting the popularity of online content</title>
		<author>
			<persName><forename type="first">G</forename><surname>Szabo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Huberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="80" to="88" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Using early view patterns to predict the popularity of youtube videos</title>
		<author>
			<persName><forename type="first">H</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WSDM &apos;13</title>
		<meeting>of WSDM &apos;13</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="365" to="374" />
		</imprint>
	</monogr>
	<note>Gonc ¸alves</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Modeling and predicting behavioral dynamics on the web</title>
		<author>
			<persName><forename type="first">K</forename><surname>Radinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Svore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Teevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bocharov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW &apos;12</title>
		<meeting>of WWW &apos;12</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="599" to="608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Item-based collaborative filtering recommendation algorithms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW &apos;01</title>
		<meeting>of WWW &apos;01</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Generating network topologies that obey power laws</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Steffan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of GLOBECOM &apos;00</title>
		<meeting>of GLOBECOM &apos;00</meeting>
		<imprint>
			<biblScope unit="page" from="434" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Do users rate or review?: Boost phrase-level sentiment labeling with review-level sentiment classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR &apos;14</title>
		<meeting>of SIGIR &apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1027" to="1030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Performance of recommender algorithms on top-n recommendation tasks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cremonesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Turrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of RecSys &apos;10</title>
		<meeting>of RecSys &apos;10</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="39" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Random walk based entity ranking on graph for multidimensional recommendation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-I</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-G</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of RecSys &apos;11</title>
		<meeting>of RecSys &apos;11</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="93" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A random walk model for item recommendation in social tagging systems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abbasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TMIS</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
