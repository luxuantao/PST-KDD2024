<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ViPER: Augmenting Automatic Information Extraction with Visual Perceptions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kai</forename><surname>Simon</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institut für Informatik</orgName>
								<orgName type="institution">Universität Freiburg Georges-Köhler-Allee</orgName>
								<address>
									<postCode>51 79110</postCode>
									<settlement>Gebäude, Freiburg i.Br</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Georg</forename><surname>Lausen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institut für Informatik</orgName>
								<orgName type="institution">Universität Freiburg Georges-Köhler-Allee</orgName>
								<address>
									<postCode>51 79110</postCode>
									<settlement>Gebäude, Freiburg i.Br</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ViPER: Augmenting Automatic Information Extraction with Visual Perceptions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">ACC8C039C263555EC28F61A4DBA24F50</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.m [Information Storage and Retrieval]: Miscellaneous-Data Extraction</term>
					<term>Wrapper Generation</term>
					<term>Web Algorithms</term>
					<term>Experimentation</term>
					<term>Performance Data extraction</term>
					<term>data record alignment</term>
					<term>visual features</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we address the problem of unsupervised Web data extraction. We show that unsupervised Web data extraction becomes feasible when supposing pages that are made up of repetitive patterns, as it is the case, e.g., for search engine result pages. Hereby the extraction rules are generated automatically without any training or human interaction, by means of operating on the DOM tree respectively the flat tag token sequence of a single page.</p><p>Our contribution to automatic data extraction through this paper is twofold. First, we identify and rank potential repetitive patterns with respect to the user's visual perception of the Web page, well aware that location and size of matching elements within a Web page constitute important criteria for defining relevance. Second, matching subsequences of the pattern with the highest weightiness are aligned with global multiple sequence alignment techniques. Experimental results show that our system is able to achieve high accuracy in distilling and aligning regularly structured objects inside complex Web pages.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>tured HTML pages. According to the process of their generation they could be divided into static and dynamic pages. Static pages, bearing stable or rarely changing content, can easily be crawled and indexed by common search engines. Dynamic pages, on the other hand, consist of rapidly changing content, e.g., news sites or pages changing their content based on user requests. Typically these sites are filled with information from back-end databases and generated by predefined templates or server-sided scripts. Although they have a unique URL address, crawling and indexing becomes otiose by virtue of their volatile nature. Hence there arises the need for new information services that can help users locate information in the Hidden Web. Possible solutions might be high dimensional meta-search engines with hundreds of thousands of subordinate information resources or Web agents scanning the Web for hidden information. Hereby both approaches have to be equipped with mechanisms which distill the relevant information and subsequently align the extracted data in order to provide more suitable data representation.</p><p>Under the aspect of extracting information from thousands of information resources manual or semi-automatic approaches become infeasible, therefore this paper presents a new fully-automatic information extraction tool named ViPER (Visual Perception-based Extraction of Records). The principle assumption made is that a Web page contains at least two multiple spatially consecutive data records building a data region which exhibits some kind of structural and visible similarity. ViPER is then able to extract and discriminate the relevance of different repetitive information contents with respect to the user's visual perception of the Web page. Having identified the most relevant data region the tool aligns these records utilizing a fast and robust multiple sequence alignment (MSA) technique. In our opinion global alignment techniques, which have not yet been applied, bear most flexible opportunities in this context. To show the efficiency and accuracy of the extraction and alignment process we used an available third-party test bed with manually extracted and labeled data. Additionally we compared ViPER with existing state-of-the-art wrapping tools resulting in encouraging results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Wrapper tools for extracting information from HTML pages started attracting major research interest during the midnineties. One significant characteristic is their degree of au-tomation, reaching from specially designed standalone wrapper programming languages, for manual wrapper generation, over machine learning, and interactive approaches with more or less human interaction to fully-automatic wrapper tools. We refer the interested reader to <ref type="bibr" target="#b12">[12]</ref> for a brief survey of different wrapping techniques. Whereas the majority of the approaches rely on user interaction to generate extraction rules, more recently, interest in automatically generate wrappers without human involvement has grown substantially. Most relevant to our approach are IEPAD <ref type="bibr" target="#b4">[4]</ref>, DeLa <ref type="bibr" target="#b16">[16]</ref>, MDR <ref type="bibr" target="#b13">[13]</ref> and recently ViNTs <ref type="bibr" target="#b14">[14]</ref>, and DEPTA <ref type="bibr" target="#b19">[19]</ref> which fall into the category of fully-automatic wrapper tools.</p><p>IEPAD generates extraction rules utilizing a decoded binary string of the HTML tag sequence and tries to find maximal repeated patterns using a PAT tree, which is rather similar to a suffix tree. The extracted pattern becomes generalized using multiple string alignment techniques. Finally the user has to choose one of these generalized patterns as an extraction rule. The approach is fairly simple and fast but tests in <ref type="bibr" target="#b13">[13]</ref> have shown that it provides poor results when the data records have a complex, nested structure. In our system we also search for maximal repeats but instead of trying to find data records with this technique we use it in the context of data record alignment.</p><p>DeLa tries to overcome the problem of nested-structured data records recognition by multi-level continuous repeat (crepeat) detection using suffix trees. The drawback of this approach is that repetitive structures are not that obvious contained in a data record because of optional tag elements. Finally heuristics are needed to prune the number of different patterns discovered. Inspired by this work we integrated a tandem repeat (c-repeats) identification instance into our approximate pattern search to cope with additional repetitive tag elements which often discards possible matches.</p><p>ViNTs <ref type="bibr" target="#b14">[14]</ref> fully-automatically generates SRR (search result record ) extraction rules using visual context features and tag structure information. Therefore it first utilizes the visual content without considering the tag structure to identify content regularities denoted as content lines and then combines them with the HTML tag structure regularities to generate wrappers. To weight the relevance of different extraction rules visual and non-visual features have been used. ViNTs builds a wrapper for a search engine using several result pages and one no-result page. The resulting wrapper is represented by a regular expression of alternative horizontal separators tags, i.e., &lt;HR&gt; or &lt;BR&gt;&lt;BR&gt;, which segment descendants into SRRs. Due to the fact that the ViNTs system only supplies horizontal separators, which is sufficient when considering document result pages, it could not separate horizontally arranged data records which will require vertical separators. Additionally at least four data records have to be present in a Web page for wrapper building and in case the data records are distributed over multiple sections only the major section is reported.</p><p>MDR <ref type="bibr" target="#b13">[13]</ref> identifies data regions by searching for multiple generalize-nodes using edit-distance similarity where generalize-nodes are a fix combination of multiple child nodes and their corresponding subtrees. MDR does not identify the most relevant data records but rather reports each repetitive sub-region contained in a Web page. Recently the authors proposed an improvement of their system named DEPTA <ref type="bibr" target="#b19">[19]</ref> (MDR-2) operating on a tag tree built according to visual rendering information. Additionally they men-tion that gap information is incorporated to eliminate false node combinations but nothing is said about the realization. Finally they proposed an approach for data record alignment by progressively growing a seed tag tree. The alignment is partial because only these nodes of a data record become aligned whose position for inserting into the seed tree can be uniquely determined. They tested their MDR system on a collection of handpicked sample pages with near perfect results (precision 100% and recall 99.8%) compared to (56%,39%) OMINI <ref type="bibr" target="#b2">[2]</ref> and (67%,39%) IEPAD. Test result reported in <ref type="bibr" target="#b14">[14]</ref> indicated that the performance on thirdparty test beds yield to worse results. In <ref type="bibr" target="#b19">[19]</ref> they showed the improvements of their new system DEPTA and reported encouraging results for the alignment process.</p><p>Our objective in this paper is to enhance the extraction technique realized in the MDR by identifying tandem repeats and visual context information for record segmentation which has not yet been proposed. Additionally we only report the relevant data records according to the visual perception of a Web page in contrast to MDR and DEPTA. We do not extract data records according to separator tags like ViNTs does, rather we consider the tag structure that data records consist of. Thus we could also manage Web pages containing at least two consecutive data records, extract similar data records distributed over multiple sections, and extract horizontally arranged data records. The visual relevance weighting mechanism is similar to ViNTs but we computed it in a different way because our data records may range over multiple sections. Our data record alignment method is totally different to the method proposed for DEPTA because of global matching mechanisms and incorporated text content information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DATA EXTRACTION</head><p>In this section we will describe in detail our contributions made to improve the extraction power. First, we carry out a pre-processing step to enhance the recognition robustness. Next, we adapt the edit-distance metric to cope with typical HTML structures. Based on the observation in <ref type="bibr" target="#b13">[13]</ref> that a data record is either formed by a single coherent subtree (subtree pattern) or ranges over multiple adjacent sibling nodes (forest tree pattern) the pattern search is restricted to child subtrees belonging to the same parent node. This search technique has already successfully been implemented in the MDR system. We improve this technique by variable rather than fix node combinations, and finally incorporate visual information to separate and weight the identified data regions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Definition</head><p>Semi-structured data can be described as data which is neither raw nor very strictly typed as in traditional database systems. In case of HTML, predefined markup tags could be used to control the appearance of untyped text. Therefore we could formalize HTML documents as a class of labeled unordered trees. A labeled unordered tree is a directed acyclic graph T = (V, E, r, δ) where V denotes a set of nodes with a distinguished node r called the root, E ⊆ V×V a set of edges between two different nodes and a label function δ : V × L where L is a string. If (u, v) ∈ E we call u parent node of v, and v child node of u. Each node v ∈ V \ {r} has exactly one parent node in the graph. If node u is an inner node then Cu = {v |(u, v) ∈ E } denotes the set of child nodes belonging to u. For a node v, we define Tv as the subtree of T rooted at v, where the subgraph of Tv is induced by the set of all descendants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Pre-Processing</head><p>To enhance the pattern extraction accuracy in HTML documents pre-processing has to be performed. For instance, numerous Web pages are not even well-formed with respect to their HTML syntax. We used the Open Source Mozilla Browser and its underlying rendering engine Gecko to convert HTML documents into valid XHTML. The reason is that most HTML authors verify their pages with standard browsers before publishing their sites. We controlled Gecko over the XPCOM interface via the Java Framework JREX (http://jrex.mozdev.org/) which enables us to use the correction power of Gecko within Java. Furthermore, we have the ability to access the parsed document tree T * with additional rendering information whereas every tag element is augmented with bounding box information by the upperleft corner's (x,y) pixel coordinates along with width and height. Furthermore, we compute the matching bounding box of text elements. To analyze T * we work on an abstract representation where each HTML tag is restricted to its tag name ignoring attributes. Moreover, trimmed text between two tag elements is represented by a new abstract element denoted as &lt;TEXT&gt; element tag. Additionally, &lt;TABLE&gt; related tags with colspan or rowspan attributes are regulated. Due to the fact that matching parts of a query string are often highlighted in search results, and the corresponding style tags are often spread very inhomogeneously over a document, we additionally ignore HTML style tags. These transformations are done by the function σ : T * → T . Finally the pre-processed document is represented by its restricted tag tree T and the plain tag sequence structure S of T where each element in the tree representation has a link to the corresponding element in the sequence representation and vice versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Pattern Search Strategy</head><p>One common technique to measure the similarity between two plain sequences Si, Sj with length n, m, respectively, is the edit-distance <ref type="bibr" target="#b9">[9]</ref>, which computes the minimal cost to transform one sequence into the other, utilizing uniform cost operations insert, delete and rename. Using Dynamic Programming techniques we can compute an n×m edit-distance matrix D in O(nm) time. A typical characteristic of data records is that single data record instances vary in optional or repetitive subparts. For instance, optional or multiple authors in the description of a book data record. An obvious disadvantage of the edit-distance computation is that repetitive and optional subparts inside the sequences Si, Sj could increase the edit cost, therefore causing possible matches to be discarded. Optional subparts are usually handled with an approximate similarity threshold value θ by defining two sequences similar if their accumulated edit-distance is less or equal to a threshold value e D * (Si, Sj) = e Dn,m ≤ θ. This approach has already successfully been implemented in the MDR system. To overcome the problem of accumulated edit costs according to repetitive subparts it is suggested that two sequences are similar if they have at least a similarity of 60%. By virtue of the low similarity threshold it is very likely that sequences match each other although they belong to different contexts. Moreover, many situations could be generated where actually matching sequences are discarded because of repetitive subparts. For instance, when comparing the following data records Si = &lt;P&gt;&lt;B&gt;Title&lt;/B&gt;&lt;A&gt;Author1&lt;/A&gt;&lt;A&gt;Author2&lt;/A&gt; &lt;A&gt;Author3&lt;/A&gt;&lt;/P&gt; and Sj = &lt;P&gt;&lt;B&gt;Title&lt;/B&gt; &lt;A&gt;Author1&lt;/A&gt;&lt;/P&gt; the repetitive authors make the sequences be considered as dissimilar despite of the low similarity threshold. Therefore we identify so called tandem repeats present in both sequences and allow zero cost for delete and insert operations inside additional repetitive instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Primitive Tandem Repeats</head><p>A tandem repeat contained in a sequence S is a subpart of the form α k with k ≥ 2 where α is a non-empty sequence of elements. For instance, the character sequences Si=ABCBCBCDD and Sj=ABCDDDD contain the following tandem repeats in Pj becomes rejected. In the context of HTML tags we only consider primitive tandem repeats with |α| ≥ 3. For the running example we disregard this condition owing to space constraints. We implemented the algorithm described in <ref type="bibr" target="#b10">[10]</ref> based on suffix trees to identify all z primitive tandem repeats in a sequence of length n in O(n + z) time before computing the edit-distance. Next we mark each extra repetitive instance with different marker elements. If, e.g., α k i ,k j 1 ∈ P and Si contains fewer consecutive repeats of α1 than Sj, then each element in the m = kj -ki extra repeats of α1 in Sj becomes marked. Additionally we mark the last element in the array of the consecutive repeated elements of α1 contained in Si with the same marker. Moreover, for each primitive tandem repeat α ∈ P l \ P with l ∈ {i, j}, if α at most occurs once in the other sequence the elements become marked in the same way. According to these marked tag elements the recursive computation of a single matrix entry of D is adapted as follows:</p><formula xml:id="formula_0">Pi = {α 3 i,1 = BC, α 2 i,2 = CB, α 2 i,3 = D} and Pj = {α 4 j,1 = D, α<label>2</label></formula><formula xml:id="formula_1">D k,l = min V X D k-1,l + f(a k , b l ) D k,l-1 + f(a k , b l ) D k-1,l-1 + c(a k , b l ) for 1 ≤ k ≤ n, 1 ≤ l ≤ m with f(a k , b l ) = &amp; 0 if marker(a k ) ∩ marker(b l ) = ∅ 1 else and c(a k , b l ) = &amp; 1 if a k = b l 0 else .</formula><p>Consequently f(a k , b l ) = 0 if the set of markers assigned to a k and b l have at least one marker in common. This assures that additional repetitive subparts contained in both sequences do not unduly increase the edit-distance. The cost function c(a k , b l ) equals zero if both elements belong to the same tag type which we denote as shallow equal.</p><formula xml:id="formula_2">marker x x x x o Sj A B C B C B C D D Si 0 1 2 3 4 5 6 7 8 9 A 1 0 1 2 B 2 1 0 1 2 x C 3 2 1 0 0 0 0 0 1 D 4 2 1 1 1 1 1 0 1 D 5 2 2 2 2 2 1 0 o D 6 2 0 o D 7 0</formula><p>The table shows the resulting edit-distance matrix of the two sequences and the different markers assigned to additional repetitive elements. With respect to the modified edit-distance computation the two sequences can be mapped with zero edit cost D * (Si, Sj) = 0 despite of optional repetitive sub-elements. For instance, the first mismatch in the diagonal occurs at position (4, 4) in the matrix. Due to the fact that element C in sequence Si shares the same marker as the second B in sequence Sj zero edit cost are mapped to matrix entry <ref type="bibr" target="#b3">(3,</ref><ref type="bibr" target="#b4">4)</ref>. To speed up the computation of the matrix Dn,m we eliminate all path hypotheses exceeding the threshold value θ = 0.25 • max (|Si|, |Sj|). In most cases this simple strategy reduces the computation workload to almost linear time and only best matching elements are compared with each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Identifying Data Regions and Records</head><p>According to the observations made in <ref type="bibr" target="#b13">[13]</ref> we have to find similar subtrees Tv i of child nodes vi ∈ Cu of all inner nodes u ∈ T . This can be done by computing the pairwise similarity of each subtree Tv i , Tv j , respectively, their corresponding sequences Sv i , Sv j with 1 ≤ i &lt; j ≤ |Cu|. Despite of comparing fix pairs of subtree combinations we generalize the search process to variable subtree combinations. Therefore single data records inside a data region could consists of variable numbers of subtrees.</p><p>When we compute the pairwise similarity between all subtree sequences we obtain an upper triangular subtree similarity matrix M s u for each inner node u. To simplify the pattern discovery we do not store the edit-distance values inside the matrix. Instead, a cell entry M s u (i, j) becomes 1 if the edit-distance between two sequences Sv i , Sv j satisfies the condition D * (Sv i , Sv j ) ≤ θv i,j with θv i,j := 0.25</p><formula xml:id="formula_3">• max |Sv i |, |Sv j | ¡ .</formula><p>Next we try to identify sets of adjacent sibling nodes having the highest matching frequency. The following example illustrates the problem:</p><p>Let u be an inner node in T and v1, . . . , vn ∈ Cu its n children. The corresponding subtree similarity matrix M s u is given as follows:</p><formula xml:id="formula_4">v1 v2 v3 v4 v5 v6 v7 v8 v9 v10 v11 . v1 - 0 0 0 0 0 0 0 0 0 0 . v2 - 0 0 1 0 1 1 0 0 1 . v3 - 0 0 1 0 0 1 0 0 . v4 - 0 0 1 0 0 1 0 . v5 - 0 0 1 0 0 1 . v6 - 0 0 1 0 0 . v7 - 0 0 1 0 . v8 - 0 1 0 . . - 0 0 .</formula><p>Interpreting the matrix entries we notice that the first node v1 has no approximative match with its sibling nodes. Scanning the matrix from left to right and top-down, the first matching sequences are found at position M s u (2, 5) = 1. Focusing on the diagonal entries starting at this position we recognize that several matches follow after node v5. The fact that several consecutive sibling nodes are similar to each other indicates a potential repetitive matching region. Hereby we could weight the region by counting all consecutive matches found inside the diagonal, starting at the corresponding position. In our case the matching diagonal starts at position M s u (2, 5) and ends at position M s u (7, 10). Thus, the diagonal weight w(diag matches (2,5) ) = 6. Next we have to split the data region into blocks forming the potential single data records. To this end, we scan the matrix horizontally starting at position M s u (2, 5) for nearest matches within the range defined by w(diag matches ) = 4 and the last match within the range is M s u (2, 11) with w(diag matches (2,11) ) = 1. By comparing the diagonal weight starting at these positions we are able to measure the splitting possibility for the current data region, which is the likeliest for position M s u (2, 8) in our running example. If no match exists inside the range then the data record block divides the data region evenly. Applying these steps iteratively to every pair of matching sequences we are able to identify potential data regions and their corresponding likeliest data block segmentations. In our example we obtain one main data region which is built by the nodes v2, .., v10 where every third node matches each other. Consequently we get a forest tree pattern where a single data record inside the data region consists of three nodes and their corresponding subtrees. Finally a data region R k is represented by the data record, denoted as pattern Sp k , with the minimal pairwise distance to each remaining data.</p><p>Knowing that the matrix is symmetric we only have to compute values for the upper triangular entries. To further reduce the computation of the matrix we consider an editdistance dependent, transitive similarity relation. Hereby, the matrix is computed line-by-line, where each match with edit-distance D(Sv i , Sv j ) ≤ 1 is stored in an array Ai corresponding to the row i. After completing the computation of a row we set each pair (l, k) ∈ 2 A i , which is part of the power set, to one, M s u (l, k) = 1. Additionally, if</p><formula xml:id="formula_5">|Sv i | -|Sv j |</formula><p>&gt; θv i,j and in the case the sequences share no tandem repeats, we do not compute the edit-distance and set M s u (i, j) = 0. Therefore we have to compute n matrix entries in the best case (subtree pattern) and n 2 2 matrix entries in the worst case (no transitive similarity).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Visual Data Segmentation</head><p>To enhance the data record separation process we incorporate visual cues which bears advantages for both vertical and horizontal segmentation of data region. When a data region R k has been identified we additionally analyze the corresponding image representation defined by R k . Thus the bounding boxes of &lt;TEXT&gt; elements contained in R k are used, to compute the vertical and horizontal projection profiles. This is realized by summing the width and respectively the height of all boxes with respect to their x/ycoordinates. Figure <ref type="figure" target="#fig_3">1</ref> shows the x/y-projection profiles of a data region. To demonstrate the correlation between text information as normally viewed on the Web site and bounding box information we represented the data region in both views. Additionally the projection profiles, exclusively computed according to the bounding box information, surround the data region in the figure. With respect to these pro-  files we analyze the probability of a potential segmentation according to characteristic valleys between peaks. Valleys between peaks corresponds to blank between text lines and the distance between two significant valleys corresponds to a potential separation of the data region into smaller data records. We establish a relationship between the valleys found in the profiles and the corresponding tag elements by a containment check. For this purpose each child element vi ∈ Cu, respectively the corresponding bounding box, in the data region R k which is totally or partially contained in an interval, described by a valley, becomes a potential separation tag. Next we test the splitting probability with respect to the computed similarity matrix for these tag elements as described above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Visual Data Region Weighting</head><p>After the pattern extraction process took place we compute the relevance of each pattern Sp 1 , Sp 2 , ...Sp k respectively their result sets R l 1 p 1 , R l 2 p 2 , . . . R l k p k which contain all matching sub-sequences R l i p i := {Sp i , Sp i ,1, . . . , S p i ,l i } of a pattern Sp i with 1 ≤ i ≤ k contained in the complete Web page. To accomplish this task several heuristics could be used for measuring the individual weight of a region. In case of dynamically generated HTML sites, we might reward data regions which partially contain the requested keywords according to some given user request. Moreover, it is possible to compute the textual coverage of the data region with respect to the pattern size. This heuristic often fails if the target pattern primarily consists of images and links or if a data region inside the menu bar has a higher textual coverage. Inspired by the work of Deng <ref type="bibr" target="#b3">[3]</ref> who described a vision-based page segmentation, we introduce a ranking technique based on visual location. Hereby a significant feature for a potential target pattern is determined by its visual location inside the page. Generally, Web pages are divided into different information regions, so-called slots, filled with navigation bars, banners, adds and the proper query result. In most cases these slots reside in appropriate locations. Actually it can be observed that the slot filled with the target information has often a centered location and covers a large part of the total page. Consequently a heuristic which measures the coverage and the deviation of the result set R l i p i from the page center is used to weight pattern Sp i . Given the bounding box information we ascertain the rectangle ζ R l i p i spanned by the result set R l i p i computing the extremum coordinates over all single rectangles represented by each match and define its total area A tot</p><formula xml:id="formula_6">R l i p i := p∈R l i p i</formula><p>Ap by the sum of each single rectangle area. Whereas the area of a matching instance Sp i,j ∈ R l i p i is defined as the area of the rectangle spanned by the parent node, in case Sp i,j is a subtree pattern, or by the sum of the area of all sibling nodes if it is a forest tree pattern. Computing the total area as sum of each matching rectangle area, we could handle the case having a small matching instance in the upper part and a second instance at the bottom of the page which results in a rectangle spanning over the complete page but effectively occupying only a small area. Finally the weight wS p i of the pattern Sp i is computed as follows:</p><formula xml:id="formula_7">wS p i = 1 1 + log(1 + d(cpage, cR p i )) A tot R l i p i</formula><p>, where cpage denotes the page center coordinate, cR p i defines the center of the result set rectangle ζ R l i p i</p><p>, and d(u, v) is the Euclidian distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">DATA ALIGNMENT</head><p>Having extracted the most relevant pattern and its corresponding approximate matches we try to align the multiple data records next. Hereby corresponding information elements (data items) should be arranged in adequate columns belonging to the same attribute, making it easy to label and store the data records in a database, export them as XML or synchronize them with data records extracted from other Web pages. Especially in case of schema matching, i.e., discovering semantically attributes in different schemas, which is fundamental for enabling query mediation and data exchange across multiple information sources, accurate data alignment plays an important role.</p><p>Typical properties of similar extracted data records are optional or multi-valued attributes or even several attributes encoded inside one single text element. These attributes often lead to non-trivial alignment scenarios. To motivate the complexity of multiple data record alignment we depicted a small example scenario in Figure <ref type="figure" target="#fig_6">2a</ref>). Here three similar data records and their appropriate abstract tag sequences are represented. Please note that &lt;TEXT&gt; elements, which abstract from the original content information contained in the Web site, have been abbreviated by the letter T to enable a compact representation. Due to the fact that each sequence has optional sub-sequences, the alignment process becomes already difficult for such a small example. Before we start to explain our alignment technique we give a short introduction into existing multiple sequence alignment techniques and motivate our approach.</p><p>In the domain of bioinformatics multiple (protein) sequence (genome) alignment (MSA) is a fundamental task and also one among the most studied and difficult problems in computational biology. Although the notion of multiple alignment could be easily extended from two sequences to many sequences, the score or quality of a multiple alignment cannot be simply generalized. One very intuitive candidate is the well known sum-of-pairs (SP) score function which is given by the sum of the induced pairwise alignment scores of each pair in the alignment. An optimal solution of n se-    quences, each of length k, can be computed in Θ(k n time by dynamic programming <ref type="bibr" target="#b15">[15]</ref>. However, such an approach is not practical for more than a few sequences. Moreover, the optimal SP alignment problem has been proven to be NP-complete <ref type="bibr" target="#b1">[1]</ref>. It should be mentioned that in the domain of data record alignment the quantifier optimal is not always definite, making it difficult to express the quality of the alignment by an objective score function. To decrease the computational costs, a large body of research exists for the design of efficient heuristics with sub-optimal solutions. For instance, in <ref type="bibr" target="#b8">[8]</ref> an alignment heuristic with guaranteed error bounds, less than twice the score of the optimal SP problem, and polynomial worst-case time have been proposed based on pairwise sequence alignment utilizing the edit-distance computation. The key idea in this approach is based on a center-star tree alignment algorithm which first tries to find a sequence (center sequence) minimizing the overall edit cost to each remaining sequence. According to this center sequence each remaining sequence is iteratively aligned to construct the final multiple alignment. Such an edit-distance based approach has already been ported into the information extraction domain, e.g., in <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b5">5]</ref>. In <ref type="bibr" target="#b4">[4]</ref> Chang et al. proposed IEPAD which generalizes the discovered exact repeated patterns to allow approximate matching by adopting the center-star multiple string alignment technique. Furthermore, in <ref type="bibr" target="#b5">[5]</ref> Chang et al. proposed a semisupervised information extraction tool called OLERA where the user could interactively generate extraction rules according to a set of training pages. OLERA is able to automatically discover other records similar to the enclosed examples and present the data in form of a spreadsheet by aligning the data records with the center-star alignment technique. Hereby, a string comparator function is incorporated into the alignment process to improve the alignment result. We implemented the second alignment proposal and identified several drawbacks of the center-star technique in the context of data record alignment. First, if the center sequence does not contain all optional sub-sequences, which is pretty often the case for complex data records, the multiple sequence alignment is fairly poor for these missing sub-sequences. Additionally, the alignment process lacks any global control instance to resolve alignment mismatches due to the fact that unaligned sequences are not considered when aligning new sequences to the growing multiple center sequence. Furthermore, the performance of the alignment process becomes very slow when the number of data records increases. And finally, tree structure and HTML structure information, which provides in our opinion valuable clues, should not be ignored during the alignment process.</p><p>Therefore we utilized a new method inspired by the algorithms in <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b11">11,</ref><ref type="bibr">7]</ref> based on global sequence alignment using general suffix trees as an alternative to edit-distance algorithms. The main idea is to find global matches which reduce the multiple alignment problem in a Divide and Conquer fashion. Thus, we are able to dramatically speed up the alignment process and extend it by a global control instance. Next we briefly describe the main stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Global Data Record Alignment</head><p>First we try to find maximal unique matches (MUMs) contained in all data records. Whereas maximal denotes that we cannot simultaneously extend the given match to the left or to the right in every sequence and unique means that the matches occur only once in each of the n sequences. For instance, in Figure <ref type="figure" target="#fig_6">2a</ref>) five such like MUMs are contained in the sequences, respectively, MUM1=T&lt;A&gt;T&lt;/A&gt;T, MUM2=&lt;TABLE&gt;&lt;TR&gt;&lt;TD&gt;T&lt;BR&gt;, MUM3=&lt;NOBR&gt;, MUM4=&lt;/NOBR&gt;, and MUM5=&lt;/TD&gt;&lt;/TR&gt;&lt;/TABLE&gt;. To visualize the MUM arrangement we can represent the MUMs by intervals corresponding to the starting position and number of elements on horizontal lines. Figure <ref type="figure" target="#fig_6">2b</ref>) shows the resulting 3-level MUM diagram with the corresponding MUM chains. The objective is to select a MUM-sequence of nonoverlapping MUMs that has maximal weight, where the weight of a MUM-sequence is defined by the sum of the weights of its members, respectively, the number of elements they consist of. Solving this optimization problem could be done with algorithms from computational geometry in O(k 2 ) time, for details see <ref type="bibr">[7]</ref>, where k denotes the number of MUMs identified. When we align the data records according to the MUM-sequence of length l with optimal weight, the problem decomposes into l + 1 smaller unaligned sub-regions. Figure <ref type="figure" target="#fig_6">2c</ref>) shows the result of the computed optimal non-overlapping MUMs-sequence MUM opt seq = [MUM1, MUM2, MUM5]. In the next stage we iteratively align each unaligned sub-region between global matches separately. To reflect the characteristics of optional and repetitive elements we attenuate our definition by searching for MUMs -appearing in most of the sequences and maximal multiple exact matches (multiMEMs) which may appear multiple times in a sequence. In Figure <ref type="figure" target="#fig_6">2c</ref>) sub-region 0 contains one MUM - 0.1 =&lt;P&gt; which occurs in the first and the third sequence. The matching closing tags are located in sub-region 3 labeled 3.1. Moreover, sub-region 2 contains MUM - 2.1 =T&lt;BR&gt; and MUM - 2.2 =&lt;A&gt;T&lt;/A&gt;T&lt;A&gt;T&lt;/A&gt;, which do not intersect and therefore build an optimal nonoverlapping MUMs-sequence. The algorithm to find all mul-tiMEMs, respectively, MUMs takes O(zn + k) time utilizing a general suffix tree, where z is the length of the concatenated n sequences and k is the total number of multiMEMs and MUMs. We refer the interested reader to <ref type="bibr" target="#b9">[9]</ref> for more details. Finally, remaining gaps are closed by mapping unaligned sub-sequences to the largest sub-sequence inside a sub-region with respect to their tree structure using a standard tree mapping function. Figure <ref type="figure" target="#fig_6">2d</ref>) visualizes the tree structure of the data records. And Figure <ref type="figure" target="#fig_6">2e</ref>) shows the result of the global alignment with the text content. In the end we assign to each group of aligned text, link and image elements a separate column. This course of action guarantees that we have a global control instance over the alignment process and we are also able to reduce the computational cost significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Aligning Text Content</head><p>So far, we defined two elements shallow equal if they belong to the same tag type. Due to the fact that the content of &lt;TEXT&gt; elements establish a good indication for global correspondences we modify the comparison function of &lt;TEXT&gt; elements when we build the general suffix tree to find regularities contained in all sequences. Therefore we define two abstract &lt;TEXT&gt; elements A and B content similar if fsim(σ -1 (A), σ -1 (B)) &gt; θstring, i.e., if they are similar with respect to their original trimmed text content given a string comparator function fsim and a threshold value θstring. For instance when a new suffix Si = α&lt;TEXT&gt;β have to be inserted into the general suffix tree we have to compute the content similarity to each &lt;TEXT&gt; element leaving a node v. In case no content similarity is given a new edge has to be created, otherwise the suffix &lt;TEXT&gt;β is assigned to the edge having the highest content similarity value. Therefore each edge leaving a node v and starting with a &lt;TEXT&gt; element stands for an equivalence class of a text content where the representative is the first &lt;TEXT&gt; content which generated a new edge. This special treatment of abstract &lt;TEXT&gt; elements is necessary because during the alignment process we need to guarantee that only similar text content becomes aligned in the global matching stages. Best alignment results have been achieved with the Jaro-Winkler <ref type="bibr" target="#b17">[17]</ref> string metric and θstring = 0.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EXPERIMENTS</head><p>In this section we compare our wrapper prototype system with the two most relevant existing fully-automatic state-ofthe-art information extraction systems, ViNTs and MDR. We do not compare our tool with DEPTA because at the time of this writing neither the test bed, experiments were performed on, nor the system was available. Instead we took the accessible datasets 2 and 3 generated within the ViNTs prototype for testing and comparing. Furthermore, we conducted experiments on the manually labeled Testbed for Information Extraction from Deep Web TBDW <ref type="bibr" target="#b18">[18]</ref> Ver. 1.02 available at (http://daisen.cc.kyushu-u.ac.jp/TBDW/) to additionally measure the performance of the alignment process. The performance was measured with the standard metrics recall = E correct N total and precision = E correct E total . Where N total defines the number of data records contained in all dynamic pages, Ecorrect is the total number of correctly extracted data records and E total denotes the total number of data records extracted by the wrapper. Due to the fact that the number of data records represented inside different Web pages varies from just a few up to hundreds of records, the final performance metrics are basically dominated by pages which consists of many data records. Therefore only the first 25 data records are used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Results</head><p>To test the performance of our system ViPER, we used dataset 2 from the ViNTs Web page featuring sample pages from 100 different search engines with 10 (5 test/5 training) result pages and one additional no-result page per engine. Due to the fact that our wrapper only works on a single Web page we randomly took 1 result page per search engine resulting in 100 pages and operated on these pages independently. As we can see from Table <ref type="table" target="#tab_1">1</ref>, the performance of our system on dataset 2 tends to result in high quality precision and recall values. We use the abbreviation SRRs search result records as introduced in <ref type="bibr" target="#b14">[14]</ref>, which is equivalent to our definition of data records to conform with the different notions. The ViNTs results, reported in <ref type="bibr" target="#b14">[14]</ref>, were obtained during building the wrapper on 5 sample pages per search engine using one no-result page and finally extracting SRRs according to these 5 pages. Despite of the different extracting approaches, DOM tree-based vs. identifying visual separators, both techniques yield high quality results. The reason is that data records in document result pages could be easily separated by horizontal separators and the relevant data records often cover a large slice of the result page.</p><p>Next, we compare our system according to dataset 3 from the ViNTs system with the results published in <ref type="bibr" target="#b14">[14]</ref> obtained by using MDR and ViNTs. The authors of <ref type="bibr" target="#b14">[14]</ref> took this dataset to compare their ViNTs system with the available MDR tool, calibrating the similarity threshold value at 60%. While MDR reports all identified data regions, only the major region is considered if it is contained inside the reported data regions. In the middle of Table <ref type="table" target="#tab_1">1</ref> the reported extraction results of the two different extraction tools ViNTs and MDR are provided, along with the results of our system ViPER. First of all it could be recognized that the performance of ViNTs and ViPER is considerably better than that of MDR on this dataset. This indicates that despite of the same underlying technique, used for MDR, the improvements made by incorporating tandem repeats, visual segmentation, and visual relevance selection the final result of the extraction could be enhanced enormously. Comparing the performance of ViNTs with ViPER's, ViNTs performs slightly better than our system. One reason is that in <ref type="bibr" target="#b14">[14]</ref> only the number of SRRs contained in a consecutive data region are count as correct result. If, e.g., the relevant data region is split into 2 subparts, by an advertisement for instance, ViNTs only reports and counts results from the larger part as correct. This is for example the case for the result page lycos.html. Here our system additionally reported the 4 data records which we had to count as false records. Finally, we performed extraction tests on data set TBDW Ver. 1.02 which have not been used in <ref type="bibr" target="#b14">[14]</ref>. Here our system performed better than ViNTs, due to the fact that some data records have a more complex structure. Additionally, we tested the alignment quality with respect to the manually labeled field information. Where label information is provided in the data set for the first data record of each Web page. The number of data items contained in the set of labeled data records add up to 367, resulting in 4,846 data items overall. With respect to the 676 correctly extracted data records by ViPER only 11 data items could not be aligned correctly. Hereby the execution time for the alignment was always less than 150msec on a P4 2.4GHz with 768MB RAM for every page.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION</head><p>In this paper, we presented a fully-automatic information extraction tool called ViPER. The tool is able to extract and separate data exhibiting recurring structures out of a single Web page with high accuracy by identifying tandem repeats and using visual context information. Additionally, we proposed a new fast and robust data record alignment technique based on global matching information and text content information. Tests performed on several third-party data sets finally underpin the high accuracy of the our system. In the future we plan to release a plugin of ViPER for the Firefox Web browser with additional interactive functionalities to extract non-repetitive data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>j, 2 = 1 =</head><label>21</label><figDesc>DD} and have the following repeats in common P = Pi ∩ Pj = {α 2,4 D}. Consequently tandem repeats build an array of consecutive repeats. If we additionally claim that the repeats have to be primitive then α may not contain shorter repeats. As a result α 2 j,2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>(2, 5 )) = 6 .</head><label>56</label><figDesc>In our example the nearest match in row 2 occurs at position M s u (2, 7) with w(diag matches (2,7) ) = 1, M s u (2, 8) with w(diag matches (2,8)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Visual data record segmentation utilizing x/y-profile information of text element bounding boxes.</figDesc><graphic coords="5,248.62,128.25,52.58,69.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>&lt;P&gt;&lt;A&gt;T&lt;/A&gt;&lt;BR&gt; T&lt;A&gt;T&lt;/A&gt;T &lt;TABLE&gt;&lt;TR&gt;&lt;TD&gt;T&lt;BR&gt; T&lt;BR&gt;T &lt;NOBR&gt; &lt;A&gt;T&lt;/A&gt;T&lt;A&gt;T&lt;/A&gt; &lt;/NOBR&gt; &lt;/TD&gt;&lt;/TR&gt;&lt;/TABLE&gt; &lt;/P&gt; &lt;BLOCKQ&gt; T&lt;A&gt;T&lt;/A&gt;T&lt;BR&gt; &lt;NOBR&gt; T&lt;A&gt;T&lt;/A&gt; &lt;/NOBR&gt; &lt;TABLE&gt;&lt;TR&gt;&lt;TD&gt;T&lt;BR&gt; T&lt;BR&gt;T&lt;A&gt;T&lt;/A&gt;T&lt;A&gt;T&lt;/A&gt; &lt;/TD&gt;&lt;/TR&gt;&lt;/TABLE&gt; &lt;/BLOCKQ&gt; &lt;P&gt; T&lt;A&gt;T&lt;/A&gt;T &lt;TABLE&gt;&lt;TR&gt;&lt;TD&gt;T&lt;BR&gt; T &lt;/TD&gt;&lt;/TR&gt;&lt;/TABLE&gt; &lt;NOBR&gt; T &lt;/NOBR&gt; &lt;/</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The data record alignment process is divided into different stages.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Datasets used within the ViNTs system Extraction performance achieved on 3 different third-party test beds.</figDesc><table><row><cell>Testbed for IE</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The complexity of multiple sequence alignment with SP-score that is a metric</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bonizzoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Vedova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TCS</title>
		<imprint>
			<biblScope unit="volume">259</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="63" to="79" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Fully Automated Object Extraction System for the World Wide Web</title>
		<author>
			<persName><forename type="first">D</forename><surname>Buttler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDCS&apos;01</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page">361</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Extracting content structure for web pages based on visual representation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">APWEB&apos;03</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="406" to="417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automatic information extraction from semi-structured web pages by pattern discovery</title>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-N</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Lui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Special Issue on Web Retrieval and Mining</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="129" to="147" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>SCI expanded</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">OLERA: A semi-supervised approach for web data extraction with visual support</title>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Kuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intelligent Systems (SCI, EI)</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="56" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Alignment of whole genomes</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Delcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kasif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Fleischmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Salzberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NAR</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2369" to="2376" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">EMAGEN: An efficient approach to multiple whole genome alignment</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deogun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ma</surname></persName>
		</author>
		<editor>Y.-P. P. Chen</editor>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>ACS</publisher>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="113" to="122" />
			<pubPlace>Dunedin, New Zealand</pubPlace>
		</imprint>
		<respStmt>
			<orgName>CRPIT</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficient methods for multiple sequence alignments with guaranteed error bounds</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gusfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin of Mathematical Biology</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="141" to="154" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Algorithms on Strings, Trees, and Sequences</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gusfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CUP</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Linear-Time algorithms for finding and representing all tandem repeats in a string</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gusfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stoye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JCSS</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="525" to="546" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Efficient multiple genome alignment</title>
		<author>
			<persName><forename type="first">M</forename><surname>Höhl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kurtz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ohlebusch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>Suppl. 1):S312-S320</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A brief survey of web data extraction tools</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H F</forename><surname>Laender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S D</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Teixeira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="84" to="93" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Mining data records in web pages</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD&apos;03</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Fully automatic wrapper generation for search engines</title>
		<author>
			<persName><forename type="first">W</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005-05">May 2005</date>
			<biblScope unit="volume">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Minimal mutation trees of sequences</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sankoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="35" to="42" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Data extraction and label assignment for web databases</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Lochovsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>ACM Press</publisher>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="187" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The state of record linkage and current research problems</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Winkler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Statistical Research Division</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<pubPlace>U.S. Census Bureau, Washington, DC</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Testbed for information extraction from deep web</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nakatoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hirokawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW Alt. &apos;04</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="346" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Web data extraction based on partial tree alignment</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005-05">May 2005</date>
			<biblScope unit="volume">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
