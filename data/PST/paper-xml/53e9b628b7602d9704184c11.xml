<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">supporting mutual awareness</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="1997">MARCH 1997</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Elin</forename><forename type="middle">Ranby</forename><surname>Pedersen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Computer Science</orgName>
								<orgName type="department" key="dep2">Communication and Educational Research</orgName>
								<orgName type="institution">Roskilde University</orgName>
								<address>
									<postBox>P. O. Box 260</postBox>
									<postCode>DK-4000</postCode>
									<settlement>Roskilde</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Tomas</forename><surname>Sokoler</surname></persName>
							<email>tomasok@ruc.dk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Computer Science</orgName>
								<orgName type="department" key="dep2">Communication and Educational Research</orgName>
								<orgName type="institution">Roskilde University</orgName>
								<address>
									<postBox>P. O. Box 260</postBox>
									<postCode>DK-4000</postCode>
									<settlement>Roskilde</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">supporting mutual awareness</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="1997">MARCH 1997</date>
						</imprint>
					</monogr>
					<idno type="MD5">610C83BA4FE817708A20B840FFB4469C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The AROMA project is exploring the kind of awareness that people effortless are able to maintain about other beings who are located physically close. We are designing technology that attempts to mediate a similar kind of awareness among people who are geographically dispersed but want to stay better in touch. AROMA technology can be thought of as a stand-alone communication device or -more likely --an augmentation of existing technologies such as the telephone or full-blown media spaces. Our approach differs from other recent designs for awareness (a) by choosing pure abstract representations on the display site, (b) by possibly remapping the signal across media between capture and display, and, finally, (c) by explicitly extending the application domain to include more than the working life, to embrace social interaction in general.</p><p>We are building a series of prototypes to learn if abstract representation of activity data does indeed convey a sense of remote presence and does so in a sutTiciently subdued manner to allow the user to concentrate on his or her main activity. We have done some initial testing of the technical feasibility of our designs. What still remains is an extensive effort of designing a symbolic language of remote presence, done in parallel with studies of how people will connect and communicate through such a language as they live with the AROMA system. Keywords Awareness, sense of presence; ubiquitous computing; CSCW, media spaces; non-work application; interaction 10 republish, kJ post on suvem or to redistribute 10 Iisk. requires specitic permission andlor !tc CH[ 97, ,AllamJ ( iA I ISA Copyright 1997 .\C!V1 O-8979 I -802-()/97/03</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>After a decade of experience with emerging media space technology we are still at odds as to how they benefit their users. Subjective accounts point mostly to the enhanced so-Permiwion to makedigihlhrd copies of all or pmt ot'this n)ateriol for perxonnl or clwsroom uw is graokd wilhout {W provided Ihot the copies are INN nmdc or di.stributcd for proli[ or conmwrc ial ;Idvantage, the copyrighl noliw. [he lilk ol'llw pt!ldica(!o!) and IIS dak appww. find notice is given that copyright is hy permission ol'(hc :\Chl. inc. To copy otherwise, cial interaction that seems to be afforded though, for a while, this was seen as a kind of by-product to the primary affordance of the shared work space. <ref type="bibr">Bly et al [2]</ref> observed that "Although seemingly the most invisible, the use of the media space for peripheral awareness was perhaps its most powerful use", Social affordance of media spaces soon became a focal point of its own, leading to designs that aimed at seamless integration of work space and personal space <ref type="bibr">[3,</ref><ref type="bibr">5,</ref><ref type="bibr">6,</ref><ref type="bibr" target="#b8">13,</ref><ref type="bibr" target="#b13">20]</ref>.</p><p>Having shifted the focus away from work, we are also ready to broaden our prospective usage domain beyond the work place: enhancement of social awareness over geographical distances is certainly a theme of interest to people outside the working life. One can easily think of very useful situations in relation to care of elder relatives or situations where you are traveling and want to be closer in touch with your loved ones than current telephone technology allows. By extending the usage domains we are faced with hard questions such as balancing privacy and availability interests and choosing capture and display techniques that fit into and work in settings that are likely to be more heterogeneous than the traditional office environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PERIPHERAL AWARENESS</head><p>The kind of awareness we are after is our ability to maintain and constantly update a sense of our social and physical context. We do so in an apparently effortless manner and without being aware that we do so, -at least until something happens that is out of order and makes us raise our level of consciousness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Phenomenon of Peripheral Awareness</head><p>Awareness, like attention, is one of the tricky and dangerous terms in psychology, easily leading to circular argumentation. We have tried to steer clear of such threats by sticking to a phenomenological reading of the word.</p><p>The phenomenon we are after may be the "preattentive processes" described in the Oxford Companion to The Mind under the entry Vision: early warning: "a preattentive (process) for the almost instantaneous detection of textual changes in our environment that indicates the occurrence of objects, and an attentive (serial) one that can shift focal attention to any of the objects detected by the preattentive process". The phenomenon is related to that of subliminal perception and intuitive conduct, and further studies of more theoretical nature may prove useful in our design.</p><p>People have an amazing ability to make sense of even very few and scattered snippets of information -just think of the hunter who is reading the ground for traces of animals passing by. At the same time, the skill of reading is an acquired competence. For most of us who are not hunters, the ground would tell us absolutely nothing about the passage of a deer some hours ago.</p><p>Most people have developed skills in reading the environment; perhaps not the set of skills used by the hunter in the forest, but others more appropriate for the everyday needs of the individual, as for instance the awareness of the neighbors maintained by the urban citizen by the lively soundscape of the apartment building and the neighborhood. Those of us who work in oftices with visual and auditory closeness to our colleagues know the efficiency of peripheral awareness: most of the time we have a pretty good idea about who is around, who is having a meeting with someone from outside, and who is fhmtically trying to get a paper out in half an hour and therefore should not be disturbed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>An Ecology of Awareness</head><p>Our ability and practice of reading our environment has its own economy and ecology, making the balance between affordances and costs crucial. This has been noticed also by <ref type="bibr">Smith&amp;Hudson [15]</ref>. "This dual tradeoff is between privacy and awareness, and between awareness and disturbance", and by GutWin&amp;Greenberg <ref type="bibr" target="#b0">[9]</ref> "a trade-off between being well informed about other's activities but being distracted by the information."</p><p>For the "reader" there is a balance between learning too much about the environment at the expense of whatever is one's primary activity. Examples of the affordances for the reader, and their price tags are: + being prepared when approached (please note that reading most likely takes place as a peripheral process) + a sense of when others maybe approached -fa sense of having company, not being alone risk of interruption if the events feeding the peripheral awareness slide into focus One example: it would sometimes be nice to have a better sense of what is going on at the callee's site before the telephone cal I is made, e.g., whether the time is appropriate for an idle chat or a serious conversation.</p><p>For the people being "read" by other users there is a balance between making oneself available and preserving one's privacy and personal integrity. Examples of the affordances for the one being read, and their price tags are + being able to "announce" one's availability risk of accidental revelation of personal/private information if events not meant to be public are "overheard" sense of violation of personal integrity when "too much" is available to others to hear, see, ..</p><p>One example: it would sometimes be nice if people wouldn't call us when we are busy doing something important. Usually our body language would be very easy to read, provided it could be communicated to those who might think of calling us.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>THE AROMA APPROACH</head><p>In the AROMA project we are exploring what kind of data to capture and display to convey a sense of remote presence for the purpose of peripheral awareness, i.e., images that put a low demand on attention while conveying "enough" (whatever that is) information about changes at the remote site. More specifically we are exploring the use of abstract representations as presence indicators. We are seeking a better understanding of the mental or intellectual cost of abstract representation and of their overall usefulness compared with more traditional media space approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>What is Abstract Representation? A Scenario</head><p>An example of the kind of abstract representation we are thinking of --and the situation in which it may be used --is the following:</p><p>Two people who know each other well and work closely together have become geographically separated for a longer period of time. They are trying to stay in touch by the usual technology such as telephone and email, and in addition they have established a kind of media space to share. The media space is organized as a pair of windows on their worltstatiom, each displaying abstract visual and auditory effects all together reflecting the state of affairs at the remote site.</p><p>The visual effect could look like an abstract, dynamic painting in which the dynamics reflect the changes in the combined auditory and visual state of the remote site (as it would be picked up by, say, a microphone and an ultrasound sensor); the auditory effects could be created as the sound landscape of a forest: audio events and processes could be structurally analyzed and processed or they could just be mapped directly into waterfali sounds, bird song, the sound of a chain saw against fir trees, etc.</p><p>The display of presence data may be characterized by its absnwctness with respect to the fullness of the original source of the signals. By "abstract" we mean the amount of PAPERS data removed from the original signal; the more we throw away, the more abstract our display become.</p><p>However, another kind of abstractness is at play too: upon processing and transforming the original signal we may need increasingly more interpretation to "read" the display properly. The abstractness is here in relation to the immediateness of the reading.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Designing for Abstract Representation</head><p>We have developed a prototype architecture that makes up the technical framework for further use studies. The prototype encompasses capture of audito~and visual data, abstraction of such data into compact streams, synthesizing of auditory, visual and haptic imagery from streams of abstract data, and finally disp/qv at the receiving end (please note that we are using "display" as opposed to "capture", i.e., using it in its widest sense, including visual, auditory, and tactile effects).</p><p>The display representation can be enriched semantically by more extensive processing on the capture site, through raognition of certain high level objects in the captured data, as well as through identification of patterns in series of events. We see these as different approaches which may be used alone or in combination. The object recognition approach lend itself to retreat ion of the original scenery, whereas the other --which is our current preference --is more directed towards crest ion of symbolic representations of the scenery. When combined, high level objects would be used to enhance the recognition of patterns in the event data. However, the area of such complex capture site processing is still uncovered by our initial prototyping.</p><p>The prototype also provides facilities for experimenting with remapping across media: for example, what was originally captured as an auditory input (for instance by a microphone) can be processed/abstracted through a number of pipelined media manipulation modules resulting in streams of abstract "activity data". These abstract data are no longer linked to any specific media and can be used to control many different display types.</p><p>In a (much too) simplistic form we may think of a simple binding of auditory change to color and visual changes to speed of a slowly evolving display scene. Slightly more complex is a setup where audio is remapped into simple state data which in turn may be used as parameters to a visual display mechanism: an audio signal is picked up by a microphone and used to determine the number of people in a location, but no detailed audio information is transmitted to the remote location(s); on the display site the data is used to select the number of animated cartoon characters.</p><p>We have found it useful to differentiate between the intentional awareness of others one may seek for the purpose of deciding if they can be approached, versus the unintentional awareness that one may maintain about others in the sur- rounding for no direct purpose at all. A particular system may provide support for intentional awareness while being useless with respect to the unintentional variation. An example of such a system would be a media space where you would have to keep a button pressed to see and hear the remote site; such system could be usefid for determining whether someone looks like he or she is available for an intemuption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Why Abstract Representation?</head><p>So why is it that we want this abstraction in the first place? Why not work to get the best, the richest, the most "naturallike" signal sent across? Well, we are exploring an assumption about the benefits of abstract representation over direct media transfers: we are proposing (1) that abstract representations will provide a kind of "shielding" for privacy of the people in the spaces, (2) that abstractions may be preferable to more media-rich representations by providing a better peripheral, non-attention demanding awareness, and (3) it is a painless accommodation to our perpetual bandwidth shortage (there will always be more items to transport over the net than we have capacity for). Furthermore, we find the abstract representations particularly interesting because (4) they lend themselves directly to media remapping, allowing each user to choose the display medium that is most effective, and in general accommodate individual preferences (some people hate visual cues and like auditory ones, while other have the opposite preference).</p><p>These assumed advantages of abstract representation need to be assessed in the context of long-term use, including the effort it may take to get them internalized initially.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INSPIRATION AND RELATED WORK</head><p>AROMA is deeply indebted to a large body of work in areas such as ubiquitous computing, active objects, augmented environments, and CSCW. We are combining ideas from such areas w M experience from media space research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conceptual Design space</head><p>The ideas explored in this project were inspired from many sources, including artists' installations as well as "classical" media space theory, encompassing an abundance of prototype systems and actual products. We have tried to chart this design space of scenarios, systems and installations in Figure <ref type="figure" target="#fig_2">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Active Objects and Remapping</head><p>Inspiration to go beyond the computer and include objects from the environment comes from the general discussion of ubiquitous computing and computer augmented environments (e.g., the special CACM issue [4]).</p><p>The Sal scenario from Weiser's paper on Ubiquitous Computing <ref type="bibr">[18]</ref> in which a window pane is used to display the recent traffic in the neighborhood, points to several key aspects of our design: use of non-computer screens, use of history and abstract representations of people's movements, the social, non-work purpose of the (imagined) installation.</p><p>Hiroshi lshii and Natalie Jeremflenko led us to play with the concept of free remapping across media, i.e., what was captured as an audio signal may be abstracted into a mediaindependent activity measure and later synthesized into a different media. In his visionary video from 1994 <ref type="bibr">[11 ]</ref>, Ishii shows us a painter and a flute player performing together with music and paint: the music is audible but also mapped into an active painting that evolves and intertwines with the painter's more traditional paint strokes. Natalie Jeremijenko was an artist in the Xerox PARC PAIR program (PARC artist in residence); she created the installation: "Dangling string", which is a short piece of ethernet cable hanging suspended tlom the ceiling; the piece of cable will move, wave calmly or shake violently, relative to the traffic load on the local computer network (see also description in <ref type="bibr">[19]</ref>).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Representation of Remote Presence</head><p>During the years we have seen numerous suggestions for representation of remote presence. Some are based on the full audio and video streams, possibly augmented or slightly tuned to support a wider sense of presence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Direct Representations</head><p>Early designs for awareness have focused on providing contextual information along with the information needed in a direct interaction. In the Porthole system [5] video is captured and transmitted with very low frame rate (typically a frame every other minute); the Porthole idea can be found in many instantiations, e.g., the NYNEX Portholes and the "When did Keith leave?" sub-system <ref type="bibr">[15]</ref>. Slightly more elaborate representations provide contextual information as fisheye perspective <ref type="bibr">[8,</ref><ref type="bibr" target="#b0">9]</ref>, or through layer model <ref type="bibr">[1O]</ref>. Use of auditory cues to help the user make sense of the remote environment has also been suggested <ref type="bibr">[7]</ref>.</p><p>As the design for awareness evolved it became clear that the contextual awareness provided by fill media representations might lead to unwanted revelations, and many experiments have been done on controlled muffling or distortion of the signal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract Representation</head><p>We use the term "abstract" representation to denote that something has been removed from the original signal, which also imply that more or less interpretive efforts are required by the "reader" of the abstraction. The removal may be a simple, evenly applied degradation, or itmay involve more complex processing and possibly feature extraction or silhouetting, as we call it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simple Degradation</head><p>Common degradation techniques in the visual domain are pixelation and thresholding. As it turns out such techniques can be quite powerful. Examples of pixelation can be found in the Shadow-Views by Smith&amp;Hudson <ref type="bibr">[15]</ref>. Thresholding techniques will typically enhance the contrasts of an image and as such direct attention to shapes and edges. In direct continuation hereof are graphical edgedetection techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature Extraction, Silhouetting</head><p>Edge-detection is a low-level feature extraction. Higher level features might include skin color, body forms and eye or mouth shapes in the visual domain, and individual voice patterns in the auditory domain.</p><p>An interesting extraction technique for audio was described by <ref type="bibr">Smith&amp;Hudson [16]</ref> as "Low Disturbance Audio For Awareness and Privacy in Media Space Applications". What they do is to process a speech signal into non-speech audio resulting in a sound that "(...) allows one to determine who is speaking, but not what they are saying, and which is not demanding of attention and hence can fall into PAPERS background noise". Something similar to what Smith&amp;-Hudson did to audio signals can of course be done to video too. We can analyse the video signal of a scene and select some characteristic visual features to preserve while others are abstracted out. We prefer to call these abstraction techniques "silhouetting" because they have certain parallels to that old art of portraiture.</p><p>Having extracted certain high-level features it is also possible to use this information at the display site, for instance to control the behaviors of avatar-like characters <ref type="bibr">[1,</ref><ref type="bibr">12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Radical Abstraction</head><p>Our current approach has many similarities to the silhouetting approach of Smith&amp;Hudson insofar we are also concerned about the subtle balances between privacy and accessibility, and between peripheral and focused attention. We also share the approach of applying signal processing to the data, resulting in very abstract representations. But we seem to differ significantly in what we are striving to obtain: they are trying to preserve significant portions of the original signal, while making the signal sufficiently muffled, anonymous or subdued, whereas our approach is minimalistic: we try to abstract the original information into a few essential bits of information, in order to, during the synthesis, add whatever is necessary for people to make sense of the bits and pieces. Hence, we talk about our approach as radical abstraction.</p><p>The two approaches clearly taps into different sides of human perception. Silhouetting is relying on the human perceptual faculties to "fill out" a few missing elements, where as we are tapping in to our symbolic abilities. Our approach is more risky: when symbolic and abstract representations really work, they are immensely powerful and efficient, but when they fail, we are left with something entirely unintelligible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AROMA PROTOTYPING</head><p>We have built a prototype version of the AROMA system, based on sketches of usage scenarios and two main design principles: "radical abstraction" as described above, and "non-intentionality", by which we mean that no specific actions should be required by the user, neither the "reader" of the information, nor the one being "read".</p><p>In the first round we mostly aimed at understanding the technical feasibility of our ideas. However, we have had some preliminary usage experience with the prototype which is installed between an oflice and a home.</p><p>In this section we will describe an architecture for a generic "awareness system". Finally, we describe the components and main processing of our current prototype within this generic architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generic System Architecture</head><p>The AROMA prototype is implemented within a general system architecture for capture, abstraction, synthesizing and displaying presence data. The purpose of the generic architecture is to provide a platform for design and exploration of different capture and display functional ities. Below is a description of the components and processing parts of the generic system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Capture Site</head><p>The capture site is characterised by its repertoire of input devices, and its capture andabstractor objects (see lefthand side of Figure <ref type="figure" target="#fig_3">2</ref>). Its architecture is hierarchical and object oriented, reflecting the idea that the system should enable viewing of the same raw data at different levels of abstraction.</p><p>The input devices can be microphones, video cameras, or more singular sensors of various kinds. Sample sensors are pressure sensors, ultrasonic sensors and simple binary on/off sensors (switches).</p><p>Each input device is tied to a timer controlled object, called a capture object; the timer operates at a sampling rate appropriate for the specific device. Each capture object interfaces with the rest of the system through a circular buffer used to store the most recently captured data.</p><p>These buffers of the capture objects are available to socalled abstracter objects, doing basic signal processing, accumulations, and comparative analyses (such as history processing). An abstracter object is defined by a specific process performed on one or more (capture or abstracter) objects and possibly the recent history of the abstracter. This recent history is represented by a circular buffer of recent processing results. The data contained in this buffer can be shipped "as is" to the remote sites or used as input to other abstracters.</p><p>An abstracter can make use of data from more than one (capture or abstracter) object and more abstracters can make use of the same (capture or abstracter) object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Communication between Capture and Display</head><p>The data shipped to the remote sites are collected from the abstracters and stored into message objects. The message structure identifies the type of presence data: compound activity measure, visual activity measure, speaker id, location data, and high-level events (somebody is getting up, somebody hasn't moved for x minutes).</p><p>The rates at which data are shipped are chosen to fit the characteristic time of the abstracters balanced with the available bandwidth. An exception to this rule is those abstracters that analyze history to identi~complex events: they ship their results whenever ready.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Display Site</head><p>The display site is characterised by its repertoire of ou@t devices, which are fed by a series of synthesizer objects (see righthand side of Figure <ref type="figure" target="#fig_3">2</ref>).</p><p>Possible output devices are speakers, displays/projectors, and a whole range of transducers that produce elements of haptic and kinetic response, etc. A sample transducer could be an electromechanical vibrator in the seat or back of a chair or a thermoelectric device to control the heat on parts of a work surface.</p><p>Incoming messages are dispatched using the message type to a set of synthesizer objects. Each synthesizer object is responsible for a particular abstract representation, i.e., a mapping from presence data to some display method. Typical synthesizer tasks are transformation of the incoming data to fit the dynamic range of the specific display device. Each synthesizer can make use of several different types of data from the remote site and the same data can be delivered to a number of synthesizers.</p><p>An important class of synthesizer objects are what we call abstract animations. Our initial intuitions, which were confirmed in our experimentation, suggest that (a) discrete signals are pu~ing higher demands on attention than continuos signals, and (b) that although monotonousness may be low on attention demand it may also be too low and thereby making the signal too easy to ignore. That made us focus on visual display of animated objects, whose dynamic characteristics include moving around in certain patterns and changing appearance in shape, color and size. By tying some dynamic characteristics to presence data and others to simple timers, we are able to create a not-too-monotonous and not-too-abrupt imagery. We are aware that adding dynamics that is unrelated to remote activity may add to the difficulty of interpreting the abstract representations, and we need to study this issue further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The virtual "inner off ice window" prototype</head><p>The generic architecture was developed in parallel with actual prototyping. A large number of specific prototypes have been built and tried out.</p><p>The most recent setup is inspired by "inner oflice windows" which allow the office inhabitant to stay aware of activities in the immediate surroundings <ref type="bibr">[18]</ref>. The mediated sur- roundings could be the offices of close colleagues and/or the living rooms of close friends and family members. This is also the prototype we have used most extensively in experiments. It demonstrates crucial elements of patiicular abstract representations and media remapping. Figure <ref type="figure" target="#fig_3">2</ref> illustrates the configuration of this prototype.</p><p>The hardware in this prototype consists of two Power Macintosh 8 100av with built-in speakers and greyscale Connectix Quickcams attached, and a National Instruments multifunction interface card with a set of a/d and &amp;a converters; this device controls the temperature of a handrest (keeping it within the range of 15-45 C using Peltier elements), and a electromechanical merry-go-round ( 15cm diameter). The code is written in C++, using Apple Quicktime and Apple gamesprockets libraries.</p><p>The capture site consists of two capture objects, one for each device, and three abstracter objects: one calculates the fiarne differences in consecutive video fi-ames, another calculate the difference between consecutive samples of sound input level. A third abstracter combines the data generated by the other two abstracters and creates a compound value, the "bustle" factor.</p><p>We use the "bustle" factor as input to four different synthesizer objects on the display site: it determines the rotation speed of a merry-go-round, it sets the current sound level in a sea shore soundscape, it is mapped into temperature of a surface used as a handrest, and finally, it sets the speed of drifting clouds on a display. The display is also controlled by the sound level differences which determines the shades of gray used when painting the clouds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results, initial prototyping</head><p>It seems to work: Our initial and very informal use of the prototype looks promising: it was indeed possible to make sense of the remote activity even with very primitive activity displays. After initial learning one of the users was ~~s"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D-O-F</head><p>'3 'actor Learning curves: Our users encountered problems in learning how to decipher the abstract representations, in particular when the user had not designed the particular mapping from capture data to display data herself. One of our users liked to have a full video representation next to the AROMA display, though she suggested it might be only a need during the initial training.</p><p>Histoty and memoty: Since we are trying to support peripheral awareness we cannot expect people to constantly monitor the various display elements. While using our first prototype, it soon became clear that our activity representations were too volatile for occasional gaze: representations of events that would be important to know of disappeared and left no trace behind. Some kind of memow as needed to sustain the display of activity bursts. We looked around for ways to somehow "stretch time" to facilitate a view into the most recent past, rather than just providing a snapshot. We discovered that the active objects we used for displays offered a natural or inherent inertia: the surface temperature changed only slowly, allowing the user to feel the recent activity, the motor controlling the merry-go-round did not stop immediately when the activity level dropped to zero. In general, we are often able to utilize the inherent relaxation time of mechanical, hydrodynamic or thermoelectric systemsh-ansducers as the vehicle for display of history. We also found that abstract representations in general (i.e., not only the active objects, but also the various visual representations) seem to lend themselves readily to history representations (as exemplified by color fading mechanism and ghostly outlines of earlier states).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Art and aes[hefics:</head><p>Finally, we found that a lot needs to be done on the aesthetics: We experienced how we (the designers) soon grew tired of the abstract displays we had chosen, and rather than "blaming" the very idea of using abstract representations we suggest that we could benefit immensely from having the appropriate artistic and communicative expertise involved in our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FUTURE WORK</head><p>During the following months we will be evaluating and refining our prototypes. in the process we \\ ill be using a combination of ethnographically-based techniques and automatic Ioggings within the system. One of the purposes wil I be to look for correlations between patterns of events in the capture data and 'behavioral' events that are meaningful and important to the users.</p><p>We are aware that we are reporting some very early findings, and we have to allow for serious problems to be uncovered in the practical use of abstract representations. Perhaps even more important, we need to incorporate a wide range of skills and knowledge in designing and evaluating what may be thought of as an abstract symbolic language of presence, proximity, and reticence.</p><p>The entire research field of social awareness in work and non-work settings seems so wide open and rich on fascinating opportunities for design and invention. We would like to see collaborations in areas such as basic research into human perception and socializing patterns, design work on interaction and integration of awareness systems with other media space components, and, finally, technical work on signal processing, networking, etc.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Charting our design space according to the relative concreteness/abstractness of the representation of captured signals (x-axis). and the location of the display device with respect to the traditional computing system(y-axis)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Current AROMA prototype. virtual "inner office windows"</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank the participants in the Oksnaen Symposium 96 and members of the Design Study Group at Xerox PARC for comments and discussions of earlier AROMA ideas and concepts. Awareness in Real-time Desktop Conferences. In Proc.</p><p>of The Second New Zealand Computer Science Research Students' Conference, Hamilton, New Zealand. 1995.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">User Embodiment in Collaborative Virtual Environments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Benford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bowers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fahlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Greenhalgh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Snowdon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CHI&apos;95 ACM Conference on Human Factors in Computing System</title>
		<meeting>of CHI&apos;95 ACM Conference on Human Factors in Computing System</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1995">1995. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Media Space: Bringing People Together in a Video, Audio, and Computing Environment</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Irwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="28" to="47" />
			<date type="published" when="1993-01">1993. January 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Integrating the Periphery and Context: A New Taxonomy of Telematics</title>
		<author>
			<persName><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GI&apos;95. Graphics Interface Conference</title>
		<meeting>GI&apos;95. Graphics Interface Conference</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1993">1995. July 1993</date>
			<biblScope unit="page">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Portholes: Supporting Awareness in a Distributed Work Group</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dourish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;92 Conf. on Human Factors in Computing Systems</title>
		<meeting>CHI&apos;92 Conf. on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="541" to="547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Evaluating Video as a Technology for Informal Communication</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kraut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Root</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CHI&apos;92 ACM Conference on Human Factors in Computing System</title>
		<meeting>of CHI&apos;92 ACM Conference on Human Factors in Computing System</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The Affordances of Media Spaces for Collaboration</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Gaver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CSCW &apos;92</title>
		<meeting>of CSCW &apos;92</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Using Distortion-Oriented Displays to Support Workspace Awareness</title>
		<author>
			<persName><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gutwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cockbum</surname></persName>
		</author>
		<idno>96/58 1/0 1</idno>
		<imprint>
			<date type="published" when="1996-11">1996. November</date>
			<pubPlace>Calgary, Canada</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Calgary</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Research report</note>
	<note>See also video proceedings of CSCW&apos;96</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Support for Group 10</title>
		<author>
			<persName><forename type="first">Gutwin</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Transparent Layered User Interfaces: An Evaluation of a Display Design to Enhance Focused and Divided Attention</title>
		<author>
			<persName><forename type="first">B</forename></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Vicente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CHI&apos;95. ACM Conference on Human Factors in Computing System</title>
		<meeting>of CHI&apos;95. ACM Conference on Human Factors in Computing System</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="317" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
		<title level="m">Seamless Media Design. SigGraph ,. Video review. CSCW &apos;94</title>
		<imprint>
			<date type="published" when="1994">1994. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Transcontinental Collaborative Virtual Environments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Leigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Graphics and Applications</title>
		<meeting>Graphics and Applications</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1996">1996. 1996</date>
			<biblScope unit="volume">106</biblScope>
		</imprint>
	</monogr>
	<note>Supporting Work in Persistent of IEEE Computer</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Experiences in the use of a media space</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mantei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Baecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sellen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Milligan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wellman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CH1&apos;91. ACM Conference on Human Factors in Computing Systems</title>
		<meeting>of CH1&apos;91. ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="203" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Providing Awareness in Support of Transitions in Remote Computer Mediated Collaborations</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Mcdaniel</surname></persName>
		</author>
		<idno>16. 17. 18. 19</idno>
	</analytic>
	<monogr>
		<title level="m">Conference Companion of CHI&apos;96 ACM Conference on Human Factors in Computing System</title>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="57" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Techniques for Addressing Fundamental Privacy and Disruption Tradeoffs in Awareness Support Systems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CSCW96</title>
		<meeting>of CSCW96</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1996">1996. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Low Disturbance Audio For Awareness and Privacy in Media Space Applications</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><surname>Hudson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM Multimedia &apos;95</title>
		<meeting>of ACM Multimedia &apos;95</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="91" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Supporting Social Awareness@Work: Design and Experience</title>
		<author>
			<persName><forename type="first">K</forename><surname>Tollmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Sandor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schemer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CSCW&apos;96</title>
		<meeting>of CSCW&apos;96</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1996">1996. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">(199 I ) The Computer of the Twenty-First Century</title>
		<author>
			<persName><forename type="first">M</forename><surname>Weiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scientific American</title>
		<imprint>
			<date type="published" when="1991-09">September 1991</date>
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Designing Calm Technology</title>
		<author>
			<persName><forename type="first">M</forename><surname>Weiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
		<ptr target="http://powergrid.electriciti.com/l.01" />
	</analytic>
	<monogr>
		<title level="j">PowerGrid Journal</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="1996-07">1996. July 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Informal Workspace Communication: What Is It Like And How Might We Support It</title>
		<author>
			<persName><forename type="first">S</forename><surname>Whittaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Frohlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Daly-Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CHI&apos;94. ACM Conference on Human Factors in Computing System</title>
		<meeting>of CHI&apos;94. ACM Conference on Human Factors in Computing System</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="13" to="14" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
