<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Early Active Learning with Pairwise Constraint for Person Re-identification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Wenhe</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">LTI</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ling</forename><surname>Chen</surname></persName>
							<email>ling.chen@uts.edu.au</email>
							<affiliation key="aff1">
								<orgName type="laboratory">LTI</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yi</forename><surname>Yang</surname></persName>
							<email>yeeiyang@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">LTI</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CAI</orgName>
								<orgName type="institution" key="instit2">University of Technology Sydney</orgName>
								<address>
									<settlement>Sydney</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Early Active Learning with Pairwise Constraint for Person Re-identification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Early active learning, Person re-identification</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Research on person re-identification (re-id) has attached much attention in the machine learning field in recent years. With sufficient labeled training data, supervised re-id algorithm can obtain promising performance. However, producing labeled data for training supervised reid models is an extremely challenging and time-consuming task because it requires every pair of images across no-overlapping camera views to be labeled. Moreover, in the early stage of experiments, when labor resources are limited, only a small number of data can be labeled. Thus, it is essential to design an effective algorithm to select the most representative samples. This is referred as early active learning or early stage experimental design problem. The pairwise relationship plays a vital role in the re-id problem, but most of the existing early active learning algorithms fail to consider this relationship. To overcome this limitation, we propose a novel and efficient early active learning algorithm with a pairwise constraint for person re-identification in this paper. By introducing the pairwise constraint, the closeness of similar representations of instances is enforced in active learning. This benefits the performance of active learning for re-id. Extensive experimental results on four benchmark datasets confirm the superiority of the proposed algorithm.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The primary target of person re-identification (re-id) is to identify a person from camera shots across pairs of non-overlapping camera views, and research on this topic has attracted considerable attention in recent years <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b28">29]</ref>. In the field of computer vision, re-id can be formed as an image retrieval task. Given a probe image of a person from one camera view, the difficulty is to identify images of the same person from a gallery of images taken by other nonoverlapping camera views. Despite the encouraging results reported in previous works, re-id remains a challenge in several respects. The accuracy of identification is often degrades as a result of the uncontrollable and/or unpredictable variation of appearance changes across camera views, such as body pose, view angle, occlusion and illumination conditions <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b22">23]</ref>.</p><p>Supervised re-id methods can achieve promising results if there are sufficient labeled training data. Unfortunately, the human labor necessary for labeling training data is sometimes inadequate. This problem becomes extremely severe in the re-id scenario, since labeling for re-id is difficult to achieve. Unlike other recognition tasks which only requires each image to be labeled, re-id requires all pairs of images across camera views to be labeled. It is a tough task even for humans to identify the same person in different camera views among a potentially huge number of imposters <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b19">20]</ref>. At the same time, pairwise labeled data is required for each pair of camera views in the camera network in re-id, thus the labeling cost will become prohibitively high numbers of cameras in today's world. For example, there might be more than over a hundred in one underground train station <ref type="bibr" target="#b19">[20]</ref>.</p><p>To save labor costs, it is essential to design an effective algorithm that can select a subset of samples that are the most representative and/or informative for training. Active learning is widely studied to solve this kind of sample selection problem. As discussed in <ref type="bibr" target="#b17">[18]</ref>, active learning methods can be divided into two categories. The first category of algorithms select the most informative samples for labeling when there are already some labeled samples. They include uncertainty sampling methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b21">22]</ref> query by committee methods <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b2">3]</ref>. Most of these active learning methods prefer to select uncertainty data, or data that is difficult to analyze. They thus require a certain number of labeled samples to evaluate the uncertainty of the unlabeled data or sampling bias <ref type="bibr" target="#b17">[18]</ref> will result. It is therefore recommended that such methods are only applied in the mid-stage of experiments when there are sufficient labeled data. For the purpose of distinguishing between the two categories, we refer to the first category of active learning methods as traditional active learning. The second category of active learning methods is considered for application in the early stage of experiments, when there are limited resources for labeling data. In this case, there are no labeled samples, thus labeling a small number of representative data is desirable for training reliable supervised models. In the category of early active learning, there are clustering-based methods <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b15">16]</ref> and transductive experimental design methods <ref type="bibr" target="#b26">[27]</ref>. These kinds of active learning algorithms are referred to as early active learning or early stage experimental design <ref type="bibr" target="#b17">[18]</ref>. We illustrate the procedures of and example of the traditional active learning algorithm, QUIRE <ref type="bibr" target="#b5">[6]</ref>, and our early active learning algorithm with pairwise constraint (abbreviated as EALPC) in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>In the rest of this paper, we focus on the early active learning methods for person re-identification applications. As mentioned, labeling re-id data is extremely labor-consuming and time-consuming. It is therefore highly desirable to enhance the learning performance in re-id applications by early active learning. Unfortunately, early active learning methods currently merely consider analyzing representative samples with pairwise relationships. Therefore, directly applying them for re-id may be not appropriate.</p><p>To overcome the limitations described above, we propose a novel algorithm for person re-identification, Early Active Learning with Pairwise Constraint, abbreviated as EALPC. The main contributions of our work are as follows:</p><p>1. We propose a novel Early Active Learning with Pairwise Constraint algorithm for person re-identification. To the best of our knowledge, this is the first method considers to consider both (a) applying early active learning for the re-id application, and (b) extending early active learning schema with pairwise constraint. 2. We introduce the 2,1 -norm to our objective function, which improves the robustness of our methods and suppresses the effects of outliers. 3. We propose an efficient algorithm to optimize the proposed problem. Our optimization algorithm also provides a closed form solution and guarantees to reach the global optimum in the convergence. In QUIRE, pre-labeled samples X l are used for the uncertainty evaluation on the unlabeled samples Xu. Then, it selects a subset samples V ⊂ Xu for labeling. At last, both Xu and V along with their labels are used for supervised learning. In EALPC, unlabeled data X is analyzed without pre-labeled data. Meanwhile, pairwise constraint Ψ is introduced to enhance the performance of early active learning for re-id. More details are in Section. 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Proposed Framework</head><p>In this section, we first revisit the early active learning algorithm and then propose our early active learning with pairwise constraint for re-id.</p><p>Notation. Let the superscript T denote the transpose of a vector/matrix, 0 be a vector/matrix with all zeros, I be an identity matrix. Let Tr(A) be the trace of matrix A. Let a i and a j be the i-th column vector and j-th row vector of matrix A respectively. Let A, B = Tr(AB T ) be the inner product of A and B, and v p be the p -norm of a vector v. Then, the Frobenius norm of an arbitrary matrix A is defined as A F = A, A . The 2 -norm of a vector a is denoted as a 2 = √ a T a and the 2,1 -norm of matrix A ∈ R n×m is denoted as</p><formula xml:id="formula_0">A 2,1 = n i=1 m j=1 a 2 ij = n i=1 a i 2</formula><p>, where a ij is the (i, j)-th element of A and a i is the i-th row vector of A. For analytical consistency, the 2,0 -norm of a matrix A is denoted as the number of the nonzero rows of A. For any convex function f (A), let ∂f (A)/∂A denote its subdifferential at A.We denote G as a weighted graph with a vertex set X and an affinity matrix S ∈ R n×n constructed on X . The (unnormalized) Laplacian matrix associated with G is defined as L = D − S, where D is a degree matrix with D(i, i) = j S(i, j).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Early Active Learning</head><p>We first revisit the early active learning algorithm. Given a set of unlabeled samples X ∈ R d×n , the task of active learning is to select a subset of m &lt; n most representative samples V ∈ R d×m . Then, the selected samples are queried labeling for supervised learning. The labeled subset of data is expected to maximize the potential performance of the supervised learning in the early stage of experiment, when the available resource for labeling data is limited, i.e. only a small number of data can be labeled for supervised learning. Generally, we can define the optimization problem of early active learning as follows:</p><formula xml:id="formula_1">min V,A R(X, V, A) + αΩ(A), s.t. V ⊂ X, |V| = m. (<label>1</label></formula><formula xml:id="formula_2">)</formula><p>where V is a subset of X, A is a transformation matrix. In Eq. ( <ref type="formula" target="#formula_1">1</ref>), the first term R(•) is the reconstruction loss, the second term Ω(•) is the regularization term and α &gt; 0 is a leverage parameter.The major purpose of early active learning is to select a subset V ⊂ X with size m &lt; n that can best represent the whole data X through the linear transformation matrix A. The selected samples are therefore considered to be the most representative.</p><p>In <ref type="bibr" target="#b26">[27]</ref>, an early active learning via a Transduction Experimental Design algorithm (TED) is proposed with the aim of finding the subset V ⊂ X and a project matrix A that minimizes the least squared reconstruction error: min</p><formula xml:id="formula_3">V,A n i=1 ( x i − Va i 2 2 + α a i 2 2 ) s.t. A = [a 1 , • • • , a n ] ∈ R m×n , V ⊂ X, |V| = m. (2)</formula><p>where Va i is the representation item of x i . However, Eq. ( <ref type="formula">2</ref>) is an NP-hard problem to solve, thus an approximate solution by a sequential optimization problem is proposed in <ref type="bibr" target="#b26">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Early Active Learning with Pairwise Constraint</head><p>In this work, we focus on early active learning in the person re-id problem. As mentioned previously, person re-id is formed as an image retrieval task which aims to re-identify the same person across non-overlapping camera views given a probe image of the person. The analysis of pairwise relationships of images in different camera views is therefore required. For this purpose, we introduce a pairwise constraint to early active learning:</p><formula xml:id="formula_4">Ψ V (A) = n i,j=1 Va i − Va j 2 2 S V (i, j), (<label>3</label></formula><formula xml:id="formula_5">)</formula><p>where Va i is the representation item of x i and S V (i, j) is the (i, j)-th element of similarity matrix S. It is the similarity between the i-th and the j-th representations. In this work we define S V (i, j) as a Gaussian similarity:</p><formula xml:id="formula_6">S V (i, j)= exp(− Vai−Vaj 2 σ 2 ), if Va i ∈ N k (Va j ) and Va j ∈ N k (Va i ) 0 , otherwise,<label>(4)</label></formula><p>where N k (x) denotes the set of k-nearest neighbors of x. We can then reformulate the pairwise constraint in Eq. ( <ref type="formula" target="#formula_4">3</ref>) by inducing a Laplacian matrix:</p><formula xml:id="formula_7">Ψ V (A) = n i,j=1 Va i − Va j 2 2 S V (i, j) = Tr((VA)L V (VA) T ),<label>(5)</label></formula><p>where L V = D − S V is the Laplacian matrix and D is the degree matrix with each element D ii = j S V (i, j). As discussed in <ref type="bibr" target="#b8">[9]</ref>, minimizing the pairwise constraint will force the similar representations to be close to each other. Following the assumption that visually similar images of a person have a high probability of sharing the similar representation features in re-id <ref type="bibr" target="#b8">[9]</ref>, this will make early active learning schema more suitable for re-id applications.</p><p>After introducing the pairwise constraint, the early active learning for person re-identification can be formulated as:</p><formula xml:id="formula_8">min V,A R(X, V, A) + αΩ(A) + βΨ V (A) s.t. A = [a 1 , • • • , a n ] ∈ R m×n , V ⊂ X, |V| = m. (<label>6</label></formula><formula xml:id="formula_9">)</formula><p>where α &gt; 0 and β &gt; 0 are leverage parameters of regularization terms. After substituting Eq. ( <ref type="formula">2</ref>) and Eq. ( <ref type="formula" target="#formula_7">5</ref>) into Eq. ( <ref type="formula" target="#formula_8">6</ref>) we obtain: min</p><formula xml:id="formula_10">V,A n i=1 ( x i − Va i 2 2 + α a i 2 2 ) + βTr((VA)L V (VA) T ) s.t. A = [a 1 , • • • , a n ] ∈ R m×n , V ⊂ X, |V| = m. (7)</formula><p>Finding the optimal subset V ⊂ X in Eq. ( <ref type="formula">7</ref>) is NP-hard. Inspired by <ref type="bibr" target="#b17">[18]</ref>, we relax the problem to the following problem by introducing the 2,0 -norm for structure sparsity:</p><formula xml:id="formula_11">min A n i=1 x i − Xa i 2 2 + α A 2,0 + βTr((XA)L X (XA) T ) s.t. A = [a 1 , • • • , a n ] ∈ R n×n , A 2,0 = m. (8)</formula><p>However, the 2,0 -norm makes Eq. ( <ref type="formula">8</ref>) a non-convex problem. At the same time, the least squared loss used in Eq. ( <ref type="formula">8</ref>) is sensitive to the outliers <ref type="bibr" target="#b17">[18]</ref>, which makes the algorithm not robust.</p><p>We note that in previous researches <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b25">26]</ref>, the 2,1 -norm is used instead of the 2,0 -norm. It is shown in <ref type="bibr" target="#b17">[18]</ref> that the 2,1 -norm is the minimum convex hull of the 2,0 -norm when row-sparsity is required. In other words, minimization of A 2,1 will achieve the same result as A 2,0 when A is row-sparse. As analyzed in <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b29">30]</ref>, the 2,1 -norm can suppress the effect of outlying samples. We therefore reformulate Eq. ( <ref type="formula">8</ref>) as a relaxed convex optimization problem:</p><formula xml:id="formula_12">min A n i=1 x i − Xa i 2,1 + α A 2,1 + βTr((XA)L X (XA) T ).<label>(9)</label></formula><p>In Eq. ( <ref type="formula" target="#formula_12">9</ref>), we adopt the 2,1 -norm instead of both the least square reconstruction loss term and the 2,0 -norm structure sparsity term for robustness and suppression of outliers. By inducing the matrix formulation, Eq. ( <ref type="formula" target="#formula_12">9</ref>) is rewritten as follows:</p><p>min</p><formula xml:id="formula_13">A (X − XA) T 2,1 + α A 2,1 + βTr((XA)L X (XA) T ). (<label>10</label></formula><formula xml:id="formula_14">)</formula><p>After obtaining the optimal solution of A, the importances of samples can be ranked by sorting the absolute row-sum values of A in the decreasing order. A subset of the representative samples then can be selected corresponding to the top m largest values and query labeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Kernelization</head><p>The proposed algorithm can be extended to the kernel version for non-linear high dimensional space. We define Φ : R d → H as a mapping from the Euclidian space to a Reproducing Kernel Hilbert Space (RKHS) as H. It can be induced by a kernel function K(x, y) = Φ(x) T Φ(y). Then we can project</p><formula xml:id="formula_15">X to RKHS space as Φ(X) = [Φ(x 1 ), • • • , Φ(x n )].</formula><p>The proposed problem thus becomes:</p><p>min</p><formula xml:id="formula_16">A (Φ(X) − Φ(X)A) T 2,1 + α A 2,1 + βTr((Φ(X)A)L X (Φ(X)A) T ). (<label>11</label></formula><formula xml:id="formula_17">)</formula><p>We denote our Early Active Learning with Pairwise Constraint algorithm in Eq. <ref type="bibr" target="#b9">(10)</ref> as EALPC and the kenerlized version of our algorithm in Eq. ( <ref type="formula" target="#formula_16">11</ref>) as EALPC_K.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Optimization</head><p>We provide an efficient algorithm for optimizing the proposed objective function.</p><p>Taking the derivative w.r.t. A in Eq. <ref type="bibr" target="#b9">(10)</ref> and setting it to zero, we obtain 1 :</p><formula xml:id="formula_18">X T XAP − X T XP + αQA + βX T XAL X = 0, (<label>12</label></formula><formula xml:id="formula_19">)</formula><p>where P is a diagonal matrix and its i-th diagonal element is</p><formula xml:id="formula_20">p ii = 1 2 xi−Xai 2 . Q is a diagonal matrix and its i-th diagonal element is q ii = 1 2 a i 2</formula><p>. Then by setting the derivative of Eq. ( <ref type="formula" target="#formula_18">12</ref>) w.r.t. a i to zero for each i, we obtain:</p><formula xml:id="formula_21">p ii X T Xa i − p ii X T x i + αQa i + βX T XAL i = 0,<label>(13)</label></formula><p>where L i is the i-th column vector of L X . It is sample to verify that AL i = l ii a i + k =i l ki a k , where l ii and l ki are the (i, i)-th and (k, i)-th element of L X respectively and a k is the k-th column vector of A. Therefore, the optimal solution a * i can be calculated by the closed form solution:</p><formula xml:id="formula_22">a * i = (p ii X T X + αQ + βX T Xl ii ) −1 (p ii X T x i − βX T X k =i a k l ki ).<label>(14)</label></formula><p>In Eq. ( <ref type="formula" target="#formula_18">12</ref>), P and Q are dependent on A, thus they also need to be determined in each iteration. We propose an iterative algorithm to solve this problem. The detailed algorithm is described in Algorithm 1. In the next section, we will prove that Algorithm 1 converges to the global optimal solution of Eq. ( <ref type="formula" target="#formula_13">10</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Convergence Analysis</head><p>We first introduce a lemma proposed in <ref type="bibr" target="#b16">[17]</ref>:</p><p>Lemma 1. For any arbitrary vector m and n there is</p><formula xml:id="formula_23">m 2 − m 2 2 2 n 2 ≤ n 2 − n 2 2 2 n 2 . (<label>15</label></formula><formula xml:id="formula_24">)</formula><p>Next, in the following theorem we prove the convergence of our algorithm:</p><p>Theorem 1. Algorithm 1 monotonically decreases the objective function value of Eq. <ref type="bibr" target="#b9">(10)</ref> in each iteration. 1 In practice, when xi − Xai = 0, pii can be regularized as pii = 1 2</p><formula xml:id="formula_25">√ x i −Xa i 2 2 +η</formula><p>.</p><p>Similarly when ai = 0, we set qii =</p><formula xml:id="formula_26">1 2 √ a i 2 2 +η</formula><p>. η is a very small constant. It can be verified that when η → 0 the problem with η reduces to the original problem in Eq. <ref type="bibr" target="#b11">(12)</ref>.</p><p>Algorithm 1: Algorithm for solving problem in Eq. <ref type="bibr" target="#b9">(10)</ref> Input: The data matrix X ∈ R d×n , parameters α and β. 1 Initialize A ∈ R n×n . 2 while not converge do 3 Compute the diagonal matrix P, where the i-th diagonal element is pii =</p><formula xml:id="formula_27">1 2 x i −Xa i 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4</head><p>Compute the diagonal matrix Q, where the i-th diagonal element is qii = 1 2 a i 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5</head><p>Update A by each column ai as in Eq. ( <ref type="formula" target="#formula_22">14</ref>):</p><formula xml:id="formula_28">a * i = (piiX T X + αQ + βX T Xlii) −1 (piiX T xi − βX T X k =i a k l ki ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">end Output:</head><p>The matrix A ∈ R n×n .</p><p>Proof. Suppose in an iteration the updated A is A + . According to Step 5 in Algorithm 1 we know that:</p><formula xml:id="formula_29">A + = arg min F f (F),<label>(16)</label></formula><p>where we denote the function</p><formula xml:id="formula_30">f (F) = Tr((X − XF)P(X − XF) T ) + αTr(FQF T ) + βTr((XF)L X (XF) T ).</formula><p>Thus, in each iteration when updating A to A + we have </p><p>According to the definition of P and Q, we thus obtain:</p><formula xml:id="formula_32">n i=1 xi − Xa + i 2 2 2 xi − Xai 2 + α a i + 2 2 2 a i 2 + βTr((XA + )LX(XA + ) T ) ≤ n i=1 xi − Xai 2 2 2 xi − Xai 2 + α a i 2 2 2 a i 2 + βTr((XA)LX(XA) T ).<label>(18)</label></formula><p>Meanwhile, according to Lemma 1, we can induce the following inequalities:</p><formula xml:id="formula_33">n i=1 xi − Xa + i 2 − xi − Xa + i 2 2 2 xi − Xai 2 ≤ n i=1 xi − Xai 2 − xi − Xai 2 2 2 xi − Xai 2 , (<label>19</label></formula><formula xml:id="formula_34">)</formula><p>and</p><formula xml:id="formula_35">n i=1 a i + 2 − a + i 2 2 2 ai 2 ≤ n i=1 a i 2 − a i 2 2 2 a i 2 . (<label>20</label></formula><formula xml:id="formula_36">)</formula><p>After summing Eq. ( <ref type="formula" target="#formula_33">19</ref>)and Eq. ( <ref type="formula" target="#formula_35">20</ref>) in the both sides of Eq. ( <ref type="formula" target="#formula_32">18</ref>), we conclude that:</p><formula xml:id="formula_37">n i=1 ( xi − Xa + i 2 + α a i + 2) + βTr((XA + )LX(XA + ) T ) ≤ n i=1 xi − Xai 2 + α a i 2 + βTr((XA)LX(XA) T ).<label>(21)</label></formula><p>The above inequality indicates that the objective function value of Eq. ( <ref type="formula" target="#formula_13">10</ref>) monotonically decreases in Algorithm 1.</p><p>Meanwhile, let ∂f (A)/∂A = 0 is equal to solving Eq. ( <ref type="formula" target="#formula_18">12</ref>), thus in convergence, A will satisfy Eq. ( <ref type="formula" target="#formula_13">10</ref>). As Eq. ( <ref type="formula" target="#formula_13">10</ref>) is a convex problem, A is the global optimum solution to our problem. Overall, Algorithm 1 will converge to the global optimum solution of Eq. ( <ref type="formula" target="#formula_13">10</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Study</head><p>In the experiments, we compare our proposed EALPC algorithm with five stateof-the-art and classic active learning algorithms. After determining and labeling the most representative samples, we train the re-id models with these samples using five popular re-id algorithms. All experiments are operated on four widely referenced re-id benchmark datasets. We report the average performance of 10 trials of independent experiments on each dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets and Settings</head><p>Datasets We analyze performance of active learning for re-id on four widely referred benchmark datasets for person re-identification.</p><p>1. VIPeR <ref type="bibr" target="#b3">[4]</ref> The VIPeR dataset contains 1,264 images of 632 persons from two non-overlapping camera views. Two images are taken for each person, each from a different camera. Variations in viewpoint and illumination conditions occur frequently in VIPeR. 2. PRID <ref type="bibr" target="#b4">[5]</ref> The PRID dataset contains images of 385 individuals from two distinct cameras. Camera B records 749 persons and Camera A records 385 persons, 200 of whom are same persons. 3. i-LID <ref type="bibr" target="#b29">[30]</ref> The i-LID dataset records 119 individuals captured by three different cameras in an airport terminal. It contains 476 images with large occlusions caused by luggage and viewpoint changes. 4. CAVIAR <ref type="bibr" target="#b1">[2]</ref> The CAVIAR dataset contains 72 individuals captured by two cameras in a shopping mall. The number of the images is 1,220, with 10 to 20 images for each individual. The size of the images in the CAVIAR dataset varies significantly from 39 × 17 to 141 × 72.</p><p>In the experiments, we use the recently proposed Local Maximal Occurrence (LOMO) features for person image representation <ref type="bibr" target="#b11">[12]</ref>. As in <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b19">20]</ref>, all person images are scaled to 128 × 48 pixels. We then use the default setting in <ref type="bibr" target="#b11">[12]</ref> to produce a 29,960 dimension feature for each image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Active Learning Algorithms</head><p>We choose five active learning algorithms and compare them with our proposed algorithm.</p><p>1. Random As a baseline algorithm, we randomly select samples and query labeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">K-means</head><p>We use the K-means algorithm as another baseline algorithm as in <ref type="bibr" target="#b17">[18]</ref>. In each experiment, samples are ranked by their distances from the K cluster centers in ascending order. 3. QUIRE <ref type="bibr" target="#b5">[6]</ref> Active learning by Querying Informative and Representative</p><p>Examples is an algorithm which queries the most informative and representative examples for labeling using the min-max margin-based approach. 4. TED <ref type="bibr" target="#b26">[27]</ref> Active learning via Transduction Experimental Design is an algorithm that selects a subset of informative samples from a candidate dataset. It formulates a regularized linear regression problem which minimizes reconstruction error. 5. RRSS <ref type="bibr" target="#b17">[18]</ref> Early active learning via Robust Representation and Structured Sparsity is a early active learning algorithm. It uses the 2,1 -norm to introduce structured sparsity for sample selection and robustness. However, RRSS does not consider the pairwise relations in re-id. We also introduce the kernelized RRSS denoted as RRSS_K. 6. EALPC Our proposed early active learning with pairwise constraint algorithm is denoted as EALPC. We also use a kernelized version of our algorithm denoted as EALPC_K. For kernelization, we construct a Gaussian kernel for the candidate dataset, i.e. K(</p><formula xml:id="formula_38">x i , x j ) = exp(−α x i − x j 2 ).</formula><p>To seek the optimal parameters (if any), we apply a grid search in a region of {10 −4 , 10</p><formula xml:id="formula_39">−3 , • • • , 1, • • • , 10 3 , 10 4</formula><p>} with a five-fold cross validation strategy to determine the best parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Re-identification Algorithms</head><p>Five state-of-the-art supervised re-id algorithms are chosen for the performance analysis of the proposed early active learning algorithms on person re-id.</p><p>1. NFST <ref type="bibr" target="#b27">[28]</ref> Null Foley-Sammon Transform space learning is a re-id algorithm for learning a discriminative subspace where the training data points of each of the classes are collapsed to a single point. 2. KCCA <ref type="bibr" target="#b13">[14]</ref> Kernel Canonical Correlation Analysis algorithm seeks a common subspace between the proposed images extracted from disjoint cameras and projects them into a new space. 3. XQDA <ref type="bibr" target="#b11">[12]</ref> Cross-view Quadratic Discriminant Analysis learns a discriminant low dimensional subspace by cross-view quadratic discriminant analysis for metric learning. 4. kLFDA <ref type="bibr" target="#b23">[24]</ref> Kernelized Local Fisher Discriminant Classifier is a closed form method that uses a kernelized method to handle large dimensional feature vectors while maximizing a Fischer optimization criterion. 5. MFA <ref type="bibr" target="#b24">[25]</ref> Marginal Fisher Analysis method is introduced for dimensionality reduction by designing two graphs that characterize the intra-class compactness and interclass separability.</p><p>Settings We report the average performance of 10 independent trials. In each trial, we divide each dataset into two equal-sized subsets as training and test sets, with no overlapping of person identities. Following the setting in <ref type="bibr" target="#b19">[20]</ref>, we divide the probe and gallery sets for re-id as follows: for datasets recording two camera views, e.g. VIPeR and PRID, images of one view are randomly selected for the probe sets, and images from the other view are chosen for the gallery sets. For a multi-view dataset, e.g. i-LID, images of one view are randomly selected as gallery sets and others are chosen as probe images. For the training set, we apply active learning methods to select a subset of training samples and query human labeling. The supervised re-id algorithms are then trained with the labeled samples. For evaluation measurement, we evaluate the performance of re-id by Cumulative Matching Characteristic (CMC) curve, which is the most commonly used performance measure for person re-id algorithms <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b11">12]</ref>. CMC calculates the probability that there exists a candidate image in the rank k gallery set that appears to match the prob image. In the experimental study, we also report the Rank One Matching Accuracy from CMC for simplicity.  <ref type="table">1</ref>. Rank One Matching Accuracy(%) on four benchmarks. Percentage of selected instances for labeling is 20% of all samples. Each column is an active learning algorithm and each row is a re-id algorithm. The best result of each re-id algorithm is marked in bold numbers. The best result of the algorithms overall is marked with an asterisk( * ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Result Analysis</head><p>Performance of Re-id We illustrate the performance of the active learning algorithms for re-id application in Table <ref type="table">1</ref>. In Table <ref type="table">1</ref>, each row corresponds to an active learning algorithm, and each column corresponds to a supervised re-id method. On each benchmark dataset, we select 20% of training samples via active learning algorithms and query labeling. The labeled subsets of samples are then adopted by supervised re-id algorithms for training models. We report the rank one matching accuracy in Table <ref type="table">1</ref>.</p><p>As shown in Table <ref type="table">1</ref>, we observe that: 1) All active learning algorithms perform better than Random selection. This indicates that active learning algorithms can select the performance of re-id. 2) Our algorithms consistently outperform the other active learning algorithms. The table also confirms that our algorithms are better than the RRSS and TED method by around 5% on rank one matching accuracy. RRSS and TED have a similar optimization target to our algorithm but without pairwise constraint. This implies that our method is much suitable for re-id applications as a result of introducing the pairwise constraint. 3) The performance of the kernelized meth- ods is better than the performance of the linear methods with our algorithm. This is consistent with the mathematical analysis in <ref type="bibr" target="#b17">[18]</ref> that kernelization produces more discriminative representation by mapping data into high-dimensional feature space. 4) The active learning algorithms with XQDA method for report better rank one matching accuracy than those with LOMO features.</p><p>In Figure <ref type="figure" target="#fig_2">2</ref>, we illustrate the performance via CMC curves of active learning methods with XQDA as the re-id algorithm. The percentage of the labeled training sample is set to only 10% to present a more challenging task. We choose XQDA as it returned the best re-id results in the previous experiments. As shown in Fig. <ref type="figure" target="#fig_2">2</ref>, we can observe that: 1) Our algorithms outperforms other algorithms consistently on all four benchmark datasets. 2) Compared to the results in Table 1, all algorithms suffer a decrease in the rank one matching accuracy when the percentage of labeled samples is halved from 20% to 10%. However, our algo-rithm only decreases around by 5% on rank one matching accuracy whereas the accuracy of others, e.g. Random and K-means, reduces approximately 10%. This indicates that our algorithm is more robust. 3) The matching accuracy of our algorithm is the only one to reach 90% with rank 15 on CAVIAR and VIPeR, and the only one to reach 90% on rank 20 on PRID and i-LID. This implies that our algorithm is more effective on re-id. Effects on the Number of Selected Instances Figure <ref type="figure" target="#fig_3">3</ref> illustrates the performance of re-id when the number of instances that selected by active learning methods varies. As displayed in Fig. <ref type="figure" target="#fig_3">3</ref>, we observe that: 1) Generally, rank one matching accuracy of all re-id algorithms increases gradually when the number of selected instances increases. 2) All active learning methods report better performances than Random selection. This indicates that active learning algorithms can improve the performance of re-id applications. 3) Our algorithm consistently performs better than the other active learning algorithms when the number of selected instance increases. More specifically, for our algorithm, kernelized methods is better than the linear methods.</p><p>Convergence In Figure <ref type="figure" target="#fig_4">4</ref>, we draw the objective value of the first 50 iterations of our algorithm on benchmark datasets. In the experiments, we fix the leverage parameters as α = 0.1 and β = 1 and set the percentage of selected samples to 20%. As shown in Fig. <ref type="figure" target="#fig_4">4</ref>, the object values of our algorithm decrease dramatically and barely change after the first five iterations on all the benchmark datasets. This indicates that our algorithm converges very rapidly on all the datasets, which is consistent with our theoretical analysis of convergence. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we have proposed a novel early active learning algorithm with a pairwise constraint for person re-identification. The proposed method is designed for the early stage of supervised re-id experiments when there are limited labor resources for labeling data. Our algorithm introduces a pairwise constant for analyzing graph structures specifically for re-identification. A closed form solution is provided to efficiently weight and select the candidate samples. Extensive experimental studies on four benchmark datasets validate the effectiveness of the proposed algorithm. The experimental results demonstrate that our methods achieve encouraging performance against the state-of-the art algorithms in the filed of early active learning for person re-identification. In future work, our algorithm can be applied to other applications that consider the pairwise relatedness, such as in social network analysis, etc.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Procedures of QUIRE<ref type="bibr" target="#b5">[6]</ref> (upper) and our Early Active Learning with Pairwise Constraint (EALPC) (lower). In QUIRE, pre-labeled samples X l are used for the uncertainty evaluation on the unlabeled samples Xu. Then, it selects a subset samples V ⊂ Xu for labeling. At last, both Xu and V along with their labels are used for supervised learning. In EALPC, unlabeled data X is analyzed without pre-labeled data. Meanwhile, pairwise constraint Ψ is introduced to enhance the performance of early active learning for re-id. More details are in Section. 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Tr((X − XA + )P(X − XA + ) T ) + αTr((A + )Q(A + ) T ) + βTr((XA + )LX(XA + ) T ) ≤ Tr((X − XA)P(X − XA) T ) + αTr(AQA T ) + βTr((XA)LX(XA) T ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. CMC Performance Comparison of Active Learning algorithms. XQDA is chosen as the re-id algorithm. The percentage of selected samples is set to 10% of all samples.</figDesc><graphic url="image-3.png" coords="12,139.33,357.68,80.62,82.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Rank One Matching Accuracy(%) w.r.t. Number of Selected Instances. We use XQDA as the re-id algorithm and train it with varying numbers of samples selected by the active learning methods.</figDesc><graphic url="image-10.png" coords="13,312.29,360.98,165.99,118.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Convergence Analysis of EALPC on Benchmark Datasets. The parameters are set as α = 0.1 and β = 1. The percentage of selected samples is 20%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>00 35.20 38.75 * 33.29 31.91 33.66 30.44 34.29 * 29.18 30.03</head><label></label><figDesc></figDesc><table><row><cell>Dataset</cell><cell></cell><cell>CAVIAR</cell><cell>VIPeR</cell></row><row><cell cols="4">Algorithm NFST KCCA XQDA kLFDA MFA NFST KCCA XQDA kLFDA MFA</cell></row><row><cell cols="4">Random 23.65 23.47 21.38 27.55 25.87 26.65 23.01 27.23 22.78 23.64</cell></row><row><cell cols="4">K-means 26.90 25.99 22.05 27.74 27.40 27.59 26.16 27.59 23.15 24.39</cell></row><row><cell>TED</cell><cell cols="3">29.78 28.70 29,42 27.94 28.08 27.45 28.53 28.43 25.75 26.09</cell></row><row><cell cols="4">QUIRE 30.66 30.87 31.56 28.18 26.16 28.39 27.43 28.54 26.25 25.13</cell></row><row><cell>RRSS</cell><cell cols="3">31.87 30.69 33.57 30.95 29.01 31.56 28.54 30.71 27.34 28.04</cell></row><row><cell cols="4">RRSS_K 31.69 33.03 35.56 31.41 31.13 31.61 28.73 31.46 28.51 29.40</cell></row><row><cell cols="4">EALPC 34.12 33.57 37.45 33.09 31.16 32.61 29.45 31.82 28.54 29.56</cell></row><row><cell cols="2">EALPC_K 35.Dataset</cell><cell>PRID</cell><cell>iLIDS</cell></row><row><cell cols="4">Algorithm NFST KCCA XQDA kLFDA MFA NFST KCCA XQDA kLFDA MFA</cell></row><row><cell cols="4">Random 24.49 25.47 24.00 23.50 20.00 25.96 23.40 25.00 23.35 25.00</cell></row><row><cell cols="4">K-means 26.16 27.54 27.01 24.70 21.20 27.02 23.94 27.00 25.57 25.20</cell></row><row><cell>TED</cell><cell cols="3">27.72 27.71 29.32 24.33 22.11 29.15 25.33 28.13 27.33 29.20</cell></row><row><cell cols="4">QUIRE 27.24 26.90 29.33 24.40 22.50 28.72 25.74 28.03 29.48 30.20</cell></row><row><cell>RRSS</cell><cell cols="3">29.21 28.44 30.00 25.09 23.97 28.11 27.66 30.82 30.08 30.55</cell></row><row><cell cols="4">RRSS_K 30.33 29.03 31.05 25.30 24.10 29.17 27.37 32.00 30.30 31.10</cell></row><row><cell cols="4">EALPC 32.22 30.63 31.03 25.90 25.60 29.26 27.66 32.34 30.43 31.60</cell></row><row><cell cols="2">EALPC_K 32.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>70 31.50 33.40 * 26.06 25.70 31.19 28.72 34.00 * 31.60 32.47 Table</head><label></label><figDesc></figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was partially supported by the Data to Decisions Cooperative Research Centre www.d2dcrc.com.au and partially supported by the National Science Foundation under Grant No. IIS-1638429.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Margin based active learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Balcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Broder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computational Learning Theory</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="35" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Custom pictorial structures for re-identification</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stoppa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bazzani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC)</title>
				<meeting>the British Machine Vision Conference (BMVC)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Selective sampling using the query by committee algorithm</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="133" to="168" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Evaluating appearance models for recognition, reacquisition, and tracking</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Workshop on Performance Evaluation for Tracking and Surveillance (PETS)</title>
				<meeting>IEEE International Workshop on Performance Evaluation for Tracking and Surveillance (PETS)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Person re-identification by descriptive and discriminative classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hirzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Beleznai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scandinavian conference on Image analysis</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="91" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Active learning by querying informative and representative examples</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="892" to="900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Person re-identification with discriminatively trained viewpoint invariant dictionaries</title>
		<author>
			<persName><forename type="first">S</forename><surname>Karanam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Radke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
				<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="4516" to="4524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Sparse re-id: Block sparsity for person reidentification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Karanam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Radke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Person re-identification by unsupervised l 1 graph learning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kodirov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="178" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dictionary learning with iterative laplacian regularisation for unsupervised person re-identification</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kodirov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC)</title>
				<meeting>the British Machine Vision Conference (BMVC)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Heterogeneous uncertainty sampling for supervised learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Catlett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Machine Learning</title>
				<meeting>the Eleventh International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="148" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Person re-identification by local maximal occurrence representation and metric learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2197" to="2206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Person re-identification by iterative re-weighted sparse ranking</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lisanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Masi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Bagdanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Del Bimbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1629" to="1642" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Matching people across camera views using kernel canonical correlation analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lisanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Masi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Del Bimbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Distributed Smart Cameras</title>
				<meeting>the International Conference on Distributed Smart Cameras</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semi-supervised ranking for re-identification with few labeled image pairs</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="598" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Active learning using pre-clustering</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smeulders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-first International Conference on Machine Learning</title>
				<meeting>the Twenty-first International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient and robust feature selection via joint l2, 1-norms minimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1813" to="1821" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Early active learning via robust representation and structured sparsity</title>
		<author>
			<persName><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI)</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Initialization independent clustering with actively selftraining method</title>
		<author>
			<persName><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="27" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>Part B (Cybernetics)</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unsupervised cross-dataset transfer learning for person re-identification</title>
		<author>
			<persName><forename type="first">P</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1306" to="1315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Query by committee</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Opper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sompolinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Annual Workshop on Computational Learning Theory</title>
				<meeting>the Fifth Annual Workshop on Computational Learning Theory</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="287" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bayesian active learning with evidence-based instance selection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Twomey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Diethe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Flach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Learning over Multiple Contexts, European Conference on Machine Learning (ECMLâĂŹ15)</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning deep feature representations with domain guided dropout for person re-identification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1249" to="1258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Person re-identification using kernelbased metric learning methods</title>
		<author>
			<persName><forename type="first">F</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Camps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sznaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Graph embedding and extensions: A general framework for dimensionality reduction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">l2, 1-norm regularized discriminative feature selection for unsupervised learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Joint Conference on Artificial Intelligence (IJCAI</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Active learning via transductive experimental design</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on Machine learning</title>
				<meeting>the 23rd international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1081" to="1088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning a discriminative null space for person re-identification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1239" to="1248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02984</idno>
		<title level="m">Person re-identification: Past, present and future</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Graph regularized sparse coding for image representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1327" to="1336" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
