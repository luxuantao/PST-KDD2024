<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Single Image Interpolation via Adaptive Nonlocal Sparsity-Based Modeling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-06-11">June 11, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yaniv</forename><surname>Romano</surname></persName>
							<email>yromano@tx.technion.ac.il</email>
						</author>
						<author>
							<persName><forename type="first">Matan</forename><surname>Protter</surname></persName>
							<email>matanpr@cs.technion.ac.il</email>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Michael</forename><surname>Elad</surname></persName>
							<email>elad@cs.technion.ac.il</email>
						</author>
						<author>
							<persName><forename type="first">Charles</forename><forename type="middle">Y</forename><surname>Creusere</surname></persName>
						</author>
						<author>
							<persName><surname>Romano</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Intel Collaborative Research Institute for Computational Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">Technion-Israel Institute of Technology</orgName>
								<address>
									<postCode>32000</postCode>
									<settlement>Technion City, Haifa</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Technion-Israel Institute of Technology</orgName>
								<address>
									<postCode>32000</postCode>
									<settlement>Technion City, Haifa</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Single Image Interpolation via Adaptive Nonlocal Sparsity-Based Modeling</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-06-11">June 11, 2014</date>
						</imprint>
					</monogr>
					<idno type="MD5">3A3652C3DC8761929F6819707ECA2D6C</idno>
					<idno type="DOI">10.1109/TIP.2014.2325774</idno>
					<note type="submission">received October 31, 2013; revised February 11, 2014; accepted May 6, 2014. Date of publication May 20, 2014</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Image restoration</term>
					<term>super resolution</term>
					<term>interpolation</term>
					<term>nonlocal similarity</term>
					<term>sparse representation</term>
					<term>K-SVD</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Single image interpolation is a central and extensively studied problem in image processing. A common approach toward the treatment of this problem in recent years is to divide the given image into overlapping patches and process each of them based on a model for natural image patches. Adaptive sparse representation modeling is one such promising image prior, which has been shown to be powerful in filling-in missing pixels in an image. Another force that such algorithms may use is the self-similarity that exists within natural images. Processing groups of related patches together exploits their correspondence, leading often times to improved results. In this paper, we propose a novel image interpolation method, which combines these two forces-nonlocal self-similarities and sparse representation modeling. The proposed method is contrasted with competitive and related algorithms, and demonstrated to achieve state-of-the-art results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>S INGLE<ref type="foot" target="#foot_0">1</ref> image super resolution is the process of reconstructing a High-Resolution (HR) image from an observed Low-Resolution (LR) one. Typical applications include zoom-in of still images in digital cameras, scalingup an image before printing, interpolating images to adapt their size to high resolution screens and conversion from low-definition to high-definition video. The image interpolation problem, which is the focus of this paper, is a special case of single image super resolution, where the LR image is assumed to be a decimated version (without blurring) of the HR image. This is an inverse problem associated with the linear degradation model</p><formula xml:id="formula_0">y = U L x,<label>(1)</label></formula><p>where y ∈ R r×c is the observed LR input image, x ∈ R rL×cL is the unknown HR image, and U L is a linear down-sampling operator of size rc × L 2 rc, decimating the image by a factor of L along the horizontal and vertical dimensions. Note that x and y are held in the above equation as column vectors after lexicographic ordering. A solution to this interpolation problem is an approximation x of the unknown HR image x, that coincides with the values of y on the coarse grid.</p><p>The extensive work of single image super resolution divides by the assumptions made on the data creation model -which blur, if at all, is assumed as part of data creation, and whether these measurements are contaminated by noise, and if so, which noise is it. Often times, an algorithm developed for super-resolving an image with one set of assumptions is found less effective or even non-relevant when turning to a different data model assumption. This is especially so when dealing with the image interpolation problem -the case of no blur and no noise. Algorithms tailored for this problem are typically very different from general-purpose super-resolution methods. As said above, our focus is the interpolation problem, and thus this paper will concentrate on the existing and relevant literature in this domain.</p><p>Why should one work on the interpolation problem? After all, it seems to be an extremely easy version of the single image super-resolution problem. There are several possible reasons to study this problem, which may explain its popularity in the literature:</p><p>1) It comes up in reality: There are situations where the given image is deeply aliased (i.e., no blur) as a measure of preserving its sharpness. If this is the case and the image quality is high (i.e., no noise), dealing with super-resolving such an image calls for an interpolation scheme. 2) Relation to Single-Image-Super-Resolution: Even if the image to be scaled-up is blurred, one can always cast the super-resolution task as a two stage process: interpolate the missing pixels, and then deblur. In such a case, interpolation algorithms address the first stage. 3) Performance bounds: From a theoretical standpoint, the interpolation problem poses a guiding bound on the achievable recovery of missing pixels in an image. 4) Relation to classical interpolators: The foundations (theoretical and practical) of interpolation are well known in the numerical analysis literature. Extending bi-linear, bi-cubic, bi-splines, and other methods to be content adaptive is a fascinating subject, as it sheds light on non-linear extensions of known methods.</p><p>The simplest techniques to reconstruct x are linear interpolators, e.g. bi-linear, bi-cubic, and cubic-spline interpolators <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>. These methods utilize a polynomial approximation to compute each missing pixel from a small local neighborhood of known pixels around it, often generating blurry results and stair-case shaped edges due to their inability to adapt to varying pixel structures in the image. These techniques can be attributed to l 2 -based regularization schemes that force some sort of spatial smoothness in an attempt to regularize the inherently ill-posed problem defined in Equation <ref type="bibr" target="#b0">(1)</ref>.</p><p>More complex algorithms use more advanced and more effective priors on the image in order to gain a stabilization of the solution. Two such powerful priors that have widespread use in recent years are (i) non-local proximity and (ii) Sparse-Land modeling. The first assumes that a given patch may find similar patches within its spatial surroundings, and these could be used to help the recovery process. Several works leverage this assumption to solve various image restoration problems, e.g. denoising <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b7">[8]</ref>, deblurring <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref> and super-resolution <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>. On the other hand, the Sparse-Land model, as introduced in <ref type="bibr" target="#b12">[13]</ref> and <ref type="bibr" target="#b13">[14]</ref> assumes that each patch from the image can be well represented using a linear combination of a few elements (called "atoms") from a basis set (called "dictionary"). Put differently, each patch x i in the original image is considered to be generated by x i = Dα i , where D ∈ R n×m is a dictionary composed of (possibly m ≥ n) atoms, where α i ∈ R m is a sparse (mostly zero) vector of coefficients. Therefore, sparsity-based restoration algorithms seek a dictionary and sparse representations that bring the corrupted\degraded patch to be as close as possible to the original one. In other words, the first force seeks to exploit relations between different patches while the second concentrates on the redundancy that exists within the treated patch.</p><p>Recent papers, e.g. NARM <ref type="bibr" target="#b14">[15]</ref> and LSSC <ref type="bibr" target="#b15">[16]</ref>, combine a sparsity-based model with the non-local similarity of natural image patches and achieve impressive restoration results. NARM is an image interpolation method that embeds a nonlocal autoregressive model (i.e. connecting a missing pixel with its nonlocal neighbors) into the data fidelity term, combined with a conventional sparse representation minimization term. Their method also exploits the nonlocal redundancy in order to further regularize the overall problem. NARM divides the image to clusters of patches and uses a local PCA dictionary learning per each cluster, in order to adaptively and sparsely represent the patches. LSSC achieves state-ofthe-art results in image denoising and demosaicing by jointly decomposing groups of similar patches with a learned dictionary. Their method uses a simultaneous sparse coding <ref type="bibr" target="#b16">[17]</ref> to impose the use of the same dictionary atoms in the sparse decomposition of similar patches.</p><p>Inspired by the promising results of the above-mentioned contributions ( <ref type="bibr" target="#b14">[15]</ref> and <ref type="bibr" target="#b15">[16]</ref>), we propose a two-stage image interpolation scheme based on an adaptive non-local sparsity prior. The proposed method starts with an initial cubicspline interpolation of the HR image. In the first stage we aim at recovering regions that fit with the non-local self-similarity assumption. We iteratively produce a rough approximation of the HR image, accompanied by a learned dictionary. In the second stage we obtain the final interpolated result by refining the previous HR approximation using the first-stage's adapted dictionary and a non-local sparsity model. In order to ensure that the influence of known pixels will be more pronounced compared to the approximated (actually unknown) ones, in both stages of the algorithm we use an element-wise weighted variant of the Simultaneous Orthogonal Matching Pursuit <ref type="bibr" target="#b16">[17]</ref> and the K-SVD <ref type="bibr" target="#b17">[18]</ref> algorithms. Note that the algorithm we introduce in this paper can be easily extended to cope with the case of interpolation under noise, i.e. when Equation ( <ref type="formula" target="#formula_0">1</ref>) is replaced by y = U L x + v, where v is white additive Gaussian noise. However, in order to remain consistent with the work in <ref type="bibr" target="#b14">[15]</ref> and <ref type="bibr" target="#b18">[19]</ref>- <ref type="bibr" target="#b20">[21]</ref>, we will discuss the noiseless case only.</p><p>The current state-of-the-art is the recently published NARM method <ref type="bibr" target="#b14">[15]</ref>, showing impressive results. However, based on 18 test images, our proposed method outperforms NARM by 0.11dB and 0.23dB on average for interpolation by factors of 2 and 3, respectively. Similarly to NARM, we rely on the sparsity model and the self-similarity assumption, but unlike NARM:</p><p>1) We do not assume that each patch can be represented as a linear combination of its similar patches. NARM requires that the representation of each patch shall be close (in terms of l 2 norm) to a linear combination of its similar patches representations. When this assumption holds -the recovery is indeed impressive, but there are patches that do not align with this assumption and forcing them to fit this requirement becomes harmful. 2) We suggest training a redundant dictionary, exploiting the benefit of the large number of examples, while NARM divides the image patches into 60 clusters and trains a PCA dictionary per each of these clusters. Besides the fact that the clustering is computationally "expensive" and very difficult to parallelize, NARM assumes that each cluster would contain enough examples (which are crucial for obtaining a good subdictionary), with the risks that (i) patches may accidentally be assigned to an inappropriate cluster (e.g. due to aliasing), and (ii) there is no suitable cluster per each patch. To conclude, the proposed method achieves competitive and even better results than NARM without limiting the algorithm to strictly fit the non-local proximity assumption. This is attributed to the proposed stable sparse-coding and the effective K-SVD dictionary learning.</p><p>This paper is organized as follows: In Section II we provide brief background material on sparse representation and dictionary learning, for the sake of completeness of the discussion. In Section III we introduce our novel image interpolation algorithm and discuss its relation to previous works. Experiments are brought in Section IV, showing that the proposed method outperforms the state-of-the-art algorithms for the single-image interpolation task. Conclusions and future research directions are drawn in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND: SPARSE REPRESENTATIONS AND DICTIONARY LEARNING</head><p>The idea behind sparse and redundant representation modeling is the introduction of a new transform of a signal x i ∈ R n to a representation α i ∈ R m where m &gt; n (thus leading to redundancy), such that the obtained representation is the sparsest possible. This semi-linear transform assumes that a signal x i can be described as x i = Dα i , thus implying that the inverse transform from the representation to the signal is indeed linear. On the other hand, the forward transform, i.e., the recovery of α i from x i (called "sparse-coding"), is obtained by</p><formula xml:id="formula_1">αi = min α i α i 0 s.t. Dα i -x i 2 2 ≤ 2 , (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where the notation α 0 stands for the count of the nonzero entries in α, and is an a-priori error threshold. For pure transformation, should be zero, implying that Dα i = x i . When x i is believed to be noisy, the very same expression above serves as a denoising process, since D αi could be interpreted as the cleaned version of x i , and in such a case, is set as the noise level. Since Equation ( <ref type="formula" target="#formula_1">2</ref>) is an NP-hard problem, the representation is approximated by a pursuit algorithm, e.g. MP <ref type="bibr" target="#b21">[22]</ref>, OMP <ref type="bibr" target="#b22">[23]</ref>, SOMP <ref type="bibr" target="#b16">[17]</ref>, basis pursuit <ref type="bibr" target="#b23">[24]</ref>, and others <ref type="bibr" target="#b13">[14]</ref>. Naturally, adapting the dictionary D to a set of signals</p><formula xml:id="formula_3">{x i } N</formula><p>i=1 results in a sparser representation than the one which would be based on a pre-chosen dictionary. For example, given the representations of these signals, {α i } N i=1 , obtained using a dictionary D 0 , the MOD and K-SVD dictionary learning algorithms <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref> adapt D to the signals by approximating the solution of the minimization problem min</p><formula xml:id="formula_4">D,{α i } N i=1 i Dα i -x i 2 2 s.t. ∀i Supp{α i } = Supp{ αi },<label>(3)</label></formula><p>where Supp{ αi } are the supports (the indices of the non-zero rows in αi ). This process is typically iterated several times, performing pursuit to update the representations, followed by updating the dictionary (and the non-zero values in the representations). Once D and αi are computed, each signal is approximated by xi = D αi . Since dictionary learning is limited in handling lowdimensional signals, a treatment of an image is typically done by breaking it into small overlapping patches, forcing each to comply with the sparse representation model. In this paper we rely on the ideas of the K-SVD denoising algorithm <ref type="bibr" target="#b26">[27]</ref>, which divides the noisy image into √ n × √ n overlapping patches. Then the algorithm performs iterations of: (i) sparsecoding using OMP on all these patches, followed by (ii) a dictionary-update applied as a sequence of a rank-1 approximation problems that update each dictionary atom and the representation coefficients using it. Finally, the denoised image is obtained by averaging the cleaned patches and the noisy image. All this process is essentially a numerical scheme for approximating the solution of the problem</p><formula xml:id="formula_5">x, D, { αi } N i=1 = min x,D,{α i } N i=1 1 2 x -y 2 2 + λ N i=1 α i 0 s.t. Dα i -R i x 2 2 ≤ 2 , (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>where N is the number of image patches, x is the denoised image, D is the trained overcomplete dictionary and R i is a matrix that extracts the i -th patch from the image. The first term of Equation ( <ref type="formula" target="#formula_5">4</ref>) demands a proximity between the noisy image y and its denoised version x. The second and third terms demand that every patch R i x = x i is represented sparsely up to a bounded error, with respect to a dictionary D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. THE PROPOSED ALGORITHM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The General Objective Function</head><p>The single-image interpolation problem can be viewed as the need to fill-in a regular pattern of missing pixels in a desired HR image. In terms of a sparsity-based approach, the HR patches are characterized by having sparse representations with respect to a learned dictionary, and this should be assessed while relying (mainly) on the known pixels. In the spirit of the K-SVD denoising formulation for images, as described in Equation ( <ref type="formula" target="#formula_5">4</ref>), the interpolation solution can be cast as the outcome of the minimization problem</p><formula xml:id="formula_7">x, D, {α sp i } N i=1 = min x,D,{α i } N i=1 N i=1 α i 0 s.t. y = U L x and ∀i Dα i -R i x 2 Wi ≤ 2 i , (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>where x is an approximation of the HR image and the constraint y = U L x is simply the relation to the measurements as given in Equation (1). Wi ∈ R n×n is a diagonal weighting matrix, which sets high weights for known pixels in R i x = x i , and low ones for the missing\approximated pixels.<ref type="foot" target="#foot_1">2</ref> i = c Wi 2 2 are error thresholds, where c is some constant. The essence of Wi is to ensure that the influence of known pixels will be more pronounced compared to the approximated ones. 2 In practice, the representations {α</p><formula xml:id="formula_9">sp i } N i=1</formula><p>are approximated by a weighted variant of the Orthogonal Matching Pursuit (OMP), the dictionary D is updated using a weighted variant of the K-SVD <ref type="bibr" target="#b17">[18]</ref>, and once D and</p><formula xml:id="formula_10">{α sp i } N i=1</formula><p>are fixed, the output HR image x is computed by solving the constrained minimization problem</p><formula xml:id="formula_11">min x N i=1 Dα sp i -R i x 2 Wi s.t. y = U L x.<label>(6)</label></formula><p>This optimization problem leads to a simple solution, in which the approximated HR patches are averaged followed by a simple projection of the known pixels in x on the outcome. Appendix A describes the closed-form solution for this problem via the Lagrange multipliers method.</p><p>Intuitively, if we could improve the sparse-coding step in Equation ( <ref type="formula" target="#formula_7">5</ref>), this may lead to better results. The OMP processes each of the patches separately and disregards interrelations that may exist between them. As consequence, the recovery of similar patches may be different despite their similar content. Grouping similar patches together and applying joint sparse-coding is a powerful technique which leverages the assumption that there are several appearances of the same image content and those could help each other somehow. In the case of denoising (as suggested by LSSC <ref type="bibr" target="#b15">[16]</ref>), similar patches contain similar image content but with different noise realization. In the case of interpolation, the aliasing can be considered as structured noise <ref type="bibr" target="#b27">[28]</ref>, and it varies between similar patches extracted from different locations, thus enriching our set.</p><p>The proposed algorithm is based on the observation that the more known pixels within a patch, the better its reconstruction. Performing group decomposition serves this goal; each patch in the group contributes its known pixels in finding the atoms decomposition for the whole group. Following the LSSC algorithm <ref type="bibr" target="#b15">[16]</ref>, we apply the simultaneous sparsecoding (SOMP) method, which forces similar patches to have similar decompositions in terms of the chosen atoms in the pursuit. SOMP is a variant of the OMP; it is an iterative greedy algorithm that finds one atom at a time for the representation of the group signals. Given a group of similar patches and a dictionary, in the first iteration SOMP finds the atom that best fits the group of weighted patches. In the next iterations, given the previously found atoms, it finds the next one that minimizes the sum of weighted l 2 norm of the residuals. Note that per iteration, the coefficients that correspond to the chosen atoms are evaluated by solving weighted least-squares.</p><p>To summarize, inspired by LSSC we suggest a strengthened version of Equation ( <ref type="formula" target="#formula_7">5</ref>):</p><formula xml:id="formula_12">x, D, {A sp i } N i=1 = min x,D,{A i } N i=1 N i=1 A i 0,∞ s.t. y = U L x and ∀i j ∈S i D(A i ) j -R j x 2 W i, j ≤ T i ,<label>(7)</label></formula><p>where S i = { j |1 ≤ j ≤ N, and x ix j 1 ≤ c d } is a set of the similar patches to x i , where c d is a fixed threshold. W i, j = W j exp x ix j 1 /c w ensures that the closer x j patch to x i , the higher the influence of it. A i ∈ R m×|S i | is a matrix, where the j -th column (A i ) j is the representation of the j -th patch in S i . The notation A i 0,∞ counts the number of non-zero rows in A i , and</p><formula xml:id="formula_13">T i = j ∈S i c W i, j<label>2</label></formula><p>2 are the error thresholds. Similar to Equation ( <ref type="formula" target="#formula_11">6</ref>), the reconstruction of the HR image is obtained by solving</p><formula xml:id="formula_14">min x N i=1 j ∈S i D(A sp i ) j -R j x 2 W i, j s.t. y = U L x. (<label>8</label></formula><formula xml:id="formula_15">)</formula><p>Although the non-local approach strengthens the sparsity model, there are still some potential instabilities in the sparse coding stage. These are the result of the ratio between the overall number of pixels in the HR image and the known ones. This ratio equals 1 L 2 , where L is the up-scaling factor along the horizontal and vertical dimensions. For example, when L = 3, the number of known pixels within a 7 × 7 patch varies from Fig. <ref type="figure" target="#fig_0">1</ref>. Demonstration of a "strong" patch (solid line) and "weak" patches (dash line) for L = 2 and 3× 3 patch size. The number of known pixels (dark points) within a "strong" patch is 4, and within a "weak" patch is 1 or 2.</p><p>4 to 9 out of 49 pixels. Fig. <ref type="figure" target="#fig_0">1</ref> demonstrates this for L = 2 and 3 × 3 patch size. Assigning a low weight to unknown and approximated pixels (e.g. 0.01 in our experiments) raises the instability of the joint weighted sparse coding. Thus, in order to further stabilize the sparse-coding step we suggest modifying the formulation in Equation ( <ref type="formula" target="#formula_12">7</ref>) to min</p><formula xml:id="formula_16">x,{α r i } N i=1 {A sp i } N i=1 N i=1 [α r i A sp i ] 0,∞<label>(9)</label></formula><formula xml:id="formula_17">s.t. y = U L x ∀i Dα r i -R i xest 2 2 + j ∈S i D(A sp i ) j -R j x 2 W i, j ≤ T i ,</formula><p>where xest is an initial estimation of the HR image (e.g. a cubic-spline approximation), α r i ∈ R m are the representations of patches xi that are computed without discrimination between known and unknown pixels, [α r i A sp i ] 0,∞ counts the number of non-zero rows in the matrix [α r i A sp i ], and T i = c n + j ∈S i c W i, j 2 2 are the error thresholds. In general, sparse coding based on the l 2 norm (i.e. a non-weighted patch) is more stable than the weighted l 2 norm since it finds the atoms according to higher number of pixels. Following this observation, the essence of α r i is to stabilize the sparsecoding step (due to the non-weighted l 2 norm), and promote their preferred set of atoms to the group they serve. <ref type="foot" target="#foot_2">3</ref> These representations are ignored in the reconstruction step, i.e., reconstruction of x remains as described in Equation ( <ref type="formula" target="#formula_14">8</ref>). Note that α r i is not included in A sp i ; given the joint support, α r i is the outcome of a least-squares while each column in</p><formula xml:id="formula_18">A sp i is the outcome of a weighted least-squares. Once {[α r i A sp i ]} N i=1</formula><p>are computed, we update the dictionary by a weighted variant of the K-SVD that approximates the solution to the problem min The above framework is the basis of the proposed two-stage image interpolation algorithm; our proposed scheme starts with an initial cubic-spline approximation of the HR image. In the first stage we iteratively produce a rough approximation of the HR image accompanied by a learned dictionary. In the second stage, based on the first-stage's HR result, we apply a joint weighted sparse-coding to represent the HR image using the first-stage's dictionary. A detailed description of these steps now follows.</p><formula xml:id="formula_19">D,{α i } N i=1 ,{A i } N i=1 N i=1 Dα i -R i x 2 2 + N i=1 j ∈S i D(A i ) j -R j x 2 W i, j s.t. ∀i Supp{[α i A i ]} = Supp{[α r i A sp i ]},<label>(10</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The First Stage of the Proposed Algorithm</head><p>The essence of the first-stage of our algorithm is to efficiently recover regions that fit the non-local self-similarity assumption, such as flat or smooth regions (e.g. sky, sand, walls, etc.), and repetitive or continues edges or textures (e.g. stockades, columns, bricks, etc.). This is achieved by utilizing the self-similarities between the patches within the image. Recall that grouping similar patches together in order to find their joint decomposition has a major advantage in fillingin missing pixels. The main contribution of each patch in finding the joint support comes from its small number of known pixels. Joining similar patches together increases the number of known pixels which are crucial for the success of the sparse-coding step.</p><p>Within an HR patch, the number of known pixels and their locations varies according to its location in the image; there are "strong" patches, i.e. patches that contain the maximal number of known pixels, and "weak" ones, i.e. patches that contain a lower number of known pixels, see Fig. <ref type="figure" target="#fig_0">1</ref> for a visual demonstration of these types of patches. It is natural to expect that the restoration of "strong" patches would be more accurate than the "weak" ones, since they have more known pixels. Motivated by this assumption, we define per each patch of xest ("strong" or "weak") a set S strong i that contains the indices of up to K most similar "strong" patches to xest i , sorted according to their l 1 distance (from low to high), requiring this distance to be at most c d .</p><p>Once</p><formula xml:id="formula_20">{S strong i</formula><p>} N i=1 are computed, in the first stage we solve the minimization problems defined in ( <ref type="formula" target="#formula_16">9</ref>) and <ref type="bibr" target="#b9">(10)</ref>  </p><formula xml:id="formula_21">D(A sp i ) 1 -R i x 2 W i,1 s.t. y = U L x,<label>(11)</label></formula><p>where (A sp i ) 1 is the representation that corresponds to the first index in S strong i set, i.e. the representation of the most similar "strong" patch to xest i . We draw the reader's attention to the resemblance and the differences between this and the equation given in ( <ref type="formula" target="#formula_14">8</ref>) -here we use only one representation -the one corresponding to the closest strong patch, while in <ref type="bibr" target="#b7">(8)</ref> we recover the image based on all the representations together.</p><p>Notice that when xest i is a "weak" patch, S strong i</p><p>does not contain its index, i.e., A sp i does not include the representation of the weighted "weak" i -th patch at all (as opposed to the case where xest i is a "strong" one). It is important to emphasize that the approach taken here is very different from a "simple" replacement of a "weak" patch with its most similar "strong" one. The non-weighted term Dα r i -R i xest 2 2 in Equation ( <ref type="formula" target="#formula_16">9</ref>) has a significant influence on deciding which atoms will be chosen to represent the {S strong i } N i=1 patches. Thereby the properties of the "weak" patch leak into the "strong" one owing to the joint decomposition and the fact that there are infinitely many ways to fill-in the missing pixels within a patch. 4 Referring to Equation ( <ref type="formula" target="#formula_21">11</ref>), we found that using the conventional l 2 norm instead of the weighted one performs slightly better.</p><p>Notice that we suggest reconstructing the HR image based on (A sp i ) 1 although α r i is available due to the following: 5 1) The restoration of a "weak" reference patch based on α r i cancels the explicit exploitation of the self-similarity assumption.</p><p>2) When the reference patch is a "strong" one, (A sp i ) 1 leads to a patch reconstruction that is close to the known pixels, while the unknown ones are naturally interpolated. The interpolation is done by a linear combination of the chosen HR dictionary atoms, which in turn are updated iteratively to obtain better and better estimation of these unknown pixels. On the other hand, α r i is the representation of the non-weighted patch; therefore it leads to a patch reconstruction that is close to the whole previously interpolated patch. While the joint element-wise weighted sparse-coding leads to an effective reconstruction, we found it to be computationally demanding mostly due to the inability to use a batch implementation <ref type="bibr" target="#b28">[29]</ref>. This batch method reduces the sparse-coding complexity by relying on the fact that large number of (non-weighted) signals are coded over the same dictionary. In this work we propose a technique that leverages the batch SOMP results and approximates the joint weighted sparse-coding representations. This technique is composed of two stages: (i) compute the joint supports {Supp{A batch i }} N i=1 5 In terms of PSNR and based on the test images, reconstructing the image based on α r i instead of (A sp i ) 1 degrades the restoration performance. The average differences between the original proposed two-stage algorithm and reconstructing the image based on α r i are 0.28 dB and 0.31 dB for interpolation by factor 2 and 3, respectively.  </p><formula xml:id="formula_22">( Âsp i ) j = min z D s i z -R j xest 2 W i, j ,<label>(12)</label></formula><p>where ( Âsp i ) j are the approximated representations, and D s i is a matrix where its columns are atoms from D that correspond to the nonzero entries of A batch i . To conclude, the first-stage is composed of three steps which are repeated iteratively: joint weighted sparse-coding, weighted dictionary learning and aggregation of the approximated HR patches by exploiting the "strong" patches. A pseudo-code description of the proposed iterative first-stage is given in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. The Second Stage of the Proposed Algorithm</head><p>The goal of the second stage is to generate a robust and reliable HR image by refining xest (the first-stage approximation) using again the non-local sparsity model, but with some important differences:</p><p>1) As apposed to the previous stage, we no longer restrict the sets to use strong patches, and use all kinds equally. 2) In the second stage, we can assign higher weights to the approximated pixels, as they are already of better quality after the first stage. 3) Forcing the self-similarity property on patches that are not similar to others can be harmful. In order to obtain a reliable estimation, the use of self-similarities in the second stage is made more conservative than in the firststage by reducing c d . 4) In the second stage there is no patch replacement in the reconstruction step. In practice, given xest and D, we represent xest patches as described in ( <ref type="formula" target="#formula_16">9</ref>) and finally we reconstruct the HR image as described in <ref type="bibr" target="#b7">(8)</ref>. <ref type="foot" target="#foot_3">6</ref>To summarize, in this stage we exploit the first-stage effective recovery of regions that fit the non-local self-similarity prior, and the ability of the sparsity model to fill-in missing pixels within the patches. A pseudo-code description of the proposed second-stage is given in Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS</head><p>In this section, detailed results of the proposed algorithm are presented for the images Bears, Boat, Butterfly, Cameraman, Elk, Fence, Flowers, Foreman, Girl, House, Koala, Leaves, Lena, Parthenon, Parrot, Starfish, Stream and Texture (see Fig. <ref type="figure" target="#fig_1">2</ref>). All these are commonly used in other related publications, which enables a fair comparison of results. All the tests in this section are generated by decimating the input HR image by factor of L in each axis We tested the proposed algorithm for two scaling factors, L = 2 and L = 3. The interpolation flow for a color image is: (i) first, convert the image to YCbCr color space, (ii) interpolate the luminance channel (i.e. Y) using the proposed algorithm and interpolate the chromatic channels (i.e. Cb and Cr) using the bi-cubic method, and (iii) finalize by converting the interpolated channels back to the RGB color space. We evaluate the interpolation performance using the Peak Signal to Noise Ratio (PSNR), defined as 20 log 10 ( 255</p><formula xml:id="formula_23">√ MSE</formula><p>), where MSE is the meansquared-error between the luminance channel of the original HR image and the recovered one.</p><p>We ran many tests to tune the various parameters of the proposed algorithm. These tests have resulted in a selection of a single set of parameters per each scaling factor and stage, which are given in Table <ref type="table" target="#tab_1">I</ref>. Note that we limit the number of atoms which represent the HR patches for at most 7 atoms.</p><p>Before comparing the proposed algorithm with the stateof-the-art methods, we demonstrate the differences between the general objective function (Section III-A) and the final algorithm (Sections III-B, III-C) in terms of PSNR. We implemented the general objective function by repeating iteratively (i) joint weighted sparse-coding as described in Equation ( <ref type="formula" target="#formula_16">9</ref>), (ii) dictionary learning as described in Equation <ref type="bibr" target="#b9">(10)</ref>, and (iii) image reconstruction as described in Equation <ref type="bibr" target="#b7">(8)</ref>. Table <ref type="table" target="#tab_2">II</ref> lists the PSNR of the general objective function, the first-stage, and the second-stage (i.e. the final result) of the proposed algorithm. It is clear that the restoration of the proposed algorithm is much better than the general one. In terms of PSNR, the average differences between them for interpolation by factors of L = 2 and L = 3 are 0.74dB and 0.76dB, respectively. The first stage of the proposed algorithm offers a PSNR improvement of 0.19dB (for L = 2) and 0.68dB (for L = 3) over the general algorithm, while the second stage offers a further improvement of 0.55dB (for L = 2) and 0.08dB (for L = 3) over the first stage. To summarize, the performance of the proposed two-stage algorithm is much better than the general non-local sparsity objective function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Up-Scaling by a Factor of 2</head><p>In Table <ref type="table" target="#tab_2">III</ref> we compare the proposed algorithm with the current stage-of-the-art methods. The competitive methods for interpolation by factor of L = 2 are (i) bicubic, (ii) Decision and Adaptive Interpolator (SAI) <ref type="bibr" target="#b18">[19]</ref>, (iii) Sparse Mixing Estimation (SME) <ref type="bibr" target="#b19">[20]</ref>, (iv) Piecewise Linear Estimation (PLE) <ref type="bibr" target="#b20">[21]</ref> and (v) Nonlocal Auto-Regressive Modeling (NARM) <ref type="bibr" target="#b14">[15]</ref>. 7 SAI is an adaptive edge-directed interpolator which exploits the image directional regularity, SME is a zooming algorithm that exploits directional structured sparsity 7 We do not compare the proposed algorithm with LSSC <ref type="bibr" target="#b15">[16]</ref> since it was not designed\tested for image interpolation. in wavelet representations, PLE is a general framework for solving inverse problems based on Gaussian mixture model, and NARM combines the non-local self-similarities and the sparsity prior as described in the Section I. The results are generated by the original authors' software. Note that PLE has a special treatment for color images while in the following simulations we interpolate and measure the PSNR on the luminance channel only. From Table <ref type="table" target="#tab_2">III</ref> we can see that our algorithm is competitive with the current state-of-theart NARM interpolator with an average gain of 0.11dB. The proposed algorithm outperforms the bicubic, SAI, SME and PLE methods with an average gain of 1.11dB, 0.58dB, 0.47dB and 0.47dB, respectively.</p><p>Figs. <ref type="figure" target="#fig_2">3</ref> and<ref type="figure" target="#fig_3">4</ref> demonstrate a visual comparison between the above algorithms for interpolation by factor of 2. According to these figures, the proposed method results in less ringing and aliasing artifacts than the others. Visually, the results are comparable to NARM, showing pleasant outcome with hardly any artifacts. Fig. <ref type="figure" target="#fig_4">5</ref> shows the reconstruction error images of PLE, NARM, and the proposed method. These error images show the absolute difference between the original and the interpolated results, with a proper common magnification. As can be seen, the proposed method succeeds in recovering the house's roof and the left portion of the fence better than PLE and NARM, while performing roughly equivalent on the right portion of the fence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Up-Scaling by a Factor of 3</head><p>For interpolation by factor of L = 3 we compare the proposed algorithm with the bicubic, SAI, SME, PLE and NARM methods. Since the available implementations for SAI and SME do not support upscaling of factors other than 2, we have tested these algorithms by upscaling twice by a factor of 2 and then reducing the result back by a factor of 3  4 using the bicubic interpolation. According to Table <ref type="table" target="#tab_2">III</ref>, the proposed algorithm outperforms the bicubic, SAI, SME, PLE and NARM interpolators with an average gap of 0.92dB, 0.61dB, 0.49dB, 0.36dB and 0.23dB, respectively.</p><p>A visual comparison between the above algorithms and the proposed method can be found in Figs. <ref type="figure" target="#fig_5">6</ref> and<ref type="figure" target="#fig_6">7</ref>. The ability of the proposed algorithm to recover continues edges and fine details (e.g. the parrot's eye) despite the large magnification is demonstrated in Fig. <ref type="figure" target="#fig_5">6</ref>, and the ability to handle severe aliasing is demonstrated in Fig. <ref type="figure" target="#fig_6">7</ref>. A comparison between the reconstruction error images of PLE, NARM, and the proposed method is given in Fig. <ref type="figure" target="#fig_7">8</ref>, supporting the quantified results and showing improved recovery for the proposed algorithm over PLE and NARM.</p><p>Note that for some images, PLE and NARM perform slightly better than the proposed algorithm. NARM may outperform the proposed algorithm for images with large regions that fit the self-similarity assumption (e.g. Foreman and Leaves) due to the implicit way that NARM relies on the image self-similarities. On the other hand, the initialization of PLE is very effective and leads to visually very pleasant results with a low computational complexity. Learning an HR dictionary based on the LR image is challenging in general, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>THE BEST RESULTS IN EACH LINE ARE HIGHLIGHTED</head><p>especially for images that suffer from very strong aliasing artifacts (e.g. Fence and Parthenon). PLE may handle these type of images in a better way than the proposed method thanks to its special initial dictionary, which represent the image very well even without any dictionary update steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Weighting the Unknown Pixels</head><p>Assigning a high weight to known pixels and a low one for the interpolated pixels is necessary and highly influential for the success in the overall interpolation task. Fig. <ref type="figure" target="#fig_8">9</ref> plots the average PSNR over the test images as a function of the weight for the unknown pixels, ranging from 0.005 up to 1. Note that differently from the proposed algorithm, here we use the same weight for both stages in order to measure its impact. As can be seen, the sensitivity of the algorithm to varying weights between 0.005 to 0.1 is small. The best restorations are achieved around the weights 0.01 and 0.05 for interpolation by factor of 2 and 3, respectively. In the context of interpolation by a factor of 3, there is a slight advantage for the weight 0.05 over 0.005 since higher weight results in more stable sparse-coding.</p><p>Another related test we present here studies the impact of increasing this weight as a function of the iterations. Clearly, there are many strategies for increasing the weight, and we explored several options. For example, we linearly increased the weights of the unknown pixels from the initial first stage value up to the second stage value, i.e. from 0.01 up to 0.05 and from 0.01 up to 0.1 for interpolation by factor of 2 and 3, respectively. In terms of the resulting PSNR, a constant weight per-stage performs slightly better than increasing weights, with an average difference of 0.003 dB and 0.01 dB for interpolation by factor of 2 and 3, respectively.  Returning to Fig. <ref type="figure" target="#fig_8">9</ref>, the worst performance is obtained for a weight that is equal to 1 (i.e. using the conventional l 2 norm instead of the weighted l 2 norm). This result is not surprising. As a reminder, each (pixel-weighted) group is represented subject to a low error threshold (c = 0.01 according to Table <ref type="table" target="#tab_1">I</ref>). Using the weighted l 2 norm with this threshold leads to a patch reconstruction that is close to the known pixels, while the unknown ones are naturally interpolated. The interpolation is done by a linear combination of the chosen HR dictionary atoms, which in turn are updated iteratively to obtain better and better estimation of these unknown pixels.</p><p>Using the same strategy but via the conventional l 2 norm leads to a patch reconstruction that is close to the whole interpolated patch. The joint sparse coding algorithm in this case chooses atoms that better fit the interpolated pixels, rather than the known ones, since the number of known pixels within a patch is relatively small. This resembles a computation of a rough approximation of the HR image by replacing every "weak" patch with its most similar "strong" one over and over again (see Equation ( <ref type="formula" target="#formula_21">11</ref>)).</p><p>Another explanation for the above degradation emerges from <ref type="bibr" target="#b14">[15]</ref>, which claims that the conventional sparsity-based methods (see <ref type="bibr" target="#b29">[30]</ref>) are less effective because the data fidelity term fails to impose structural constraint on the missing pixels. The authors of <ref type="bibr" target="#b14">[15]</ref> suggest exploiting the selfsimilarity assumption in order to connect a missing pixel with its non-local neighbors. Our algorithm exploits the nonlocal self-similarity assumption too, but somewhat differently. We (i) use a joint weighted sparse coding, and (ii) replace the representation of each "weak" patch (whose central pixel is missing) with its most similar "strong" patch (whose central pixel is known) representation, all this in the first stage of the algorithm. However, using the conventional l 2 norm instead of the weighted l 2 norm cancels the discrimination between the known pixels and the unknown ones, and this results in inferior interpolation performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Similarity Function</head><p>Many recent papers on subspace clustering (see <ref type="bibr" target="#b30">[31]</ref>) indicate that joint sparse-coding should group patches that belong to the same subspace, and this in turn means that the grouped patches are not necessarily expected to be close-by in l 2 (or l 1 ). Therefore, grouping similar patches according to their l 2 or l 1 norm is not the best choice. However, the popularity, simplicity and low-computational cost of these norms, together with an impressive restoration performance, make them very attractive. In our work, we have chosen the l 1 norm over the l 2 because it is more robust to outliers. In terms of the resulting PSNR, we found that the l 1 norm is slightly better than the l 2 norm, with an average difference of 0.1 dB and 0.07 dB for interpolations by factor of 2 and 3, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Computational Complexity</head><p>The complexity of the proposed algorithm is composed of three main parts: (i) computing K-Nearest Neighbors (K-NN) per each patch within a window of size h × h pixels, (ii) sparse coding using an element-wise weighted variant of the SOMP, and (iii) dictionary learning using an elementwise weighted variant of the K-SVD. The complexity of computing the K-NN per-patch is O(n</p><formula xml:id="formula_24">• h 2 + h 2 • log h 2 ).</formula><p>A detailed complexity analysis of the OMP, its batch implementation, and the K-SVD are given in <ref type="bibr" target="#b28">[29]</ref>. Note that we approximate the solution of the weighted SOMP by applying its batch implementation without weights followed by a weighted least-squares. The complexity of the batch-SOMP per-patch is O K • (n • m + s 2 • n + s 3 ) , where s is the average number of atoms that participate in the representation of the HR patches. Adding now the weights costs additional   the HR image is N and each patch has K similar patches). The overall complexity of the proposed algorithm under the assumptions that s</p><formula xml:id="formula_25">n &lt; m ≈ h 2 is O I • n • m 3 + I • K • N • (n • m + s 2 • n) , (<label>13</label></formula><formula xml:id="formula_26">)</formula><p>where I is the number of iterations. The chosen parameters effect the complexity, which can be reduced by choosing sub-optimal parameters with a minor impact on the overall interpolation performance. We compared the complexity of the proposed algorithm with SME <ref type="bibr" target="#b19">[20]</ref>, PLE <ref type="bibr" target="#b20">[21]</ref> and NARM <ref type="bibr" target="#b14">[15]</ref>. Unfortunately SAI <ref type="bibr" target="#b18">[19]</ref> does not provide a complexity analysis; therefore we do not include it in this comparison. It is worth mentioning, though, that the runtime of the published implementation of SAI is faster than the others. Note that in order to obtain a comparable complexity terms we made several assumptions about the variables dimensions. 8  We test the runtime of an un-optimized Matlab implementation on an Intel Core i7 3 GHz processor. The runtime for interpolating a 128×128 LR image to a 256×256 HR image is about 1 minute per iteration; therefore it takes 10-15 minutes to obtain our best interpolation performance. The algorithm could be optimized by replacing the exhaustive K-NN search with a fast patch matching (see <ref type="bibr" target="#b31">[32]</ref>), reducing the number of examples for the dictionary update (e.g. by choosing mostly active\textured patches), applying the dictionary update every several iterations, etc. However, we did not take this route, and this is left for future work.</p><p>To conclude, we demonstrated the efficiency of the proposed technique to recover an HR image from an observed LR one. We presented the advantages of the proposed two-stage algorithm over the general objective function. Furthermore, the experimental results indicate that the proposed method outperforms the state-of-the-art algorithms for interpolation by factors of L = 2 and L = 3. We illustrated the influence of the weights on the final result, discussed the similarity function and provided a complexity analysis along with a comparison to the competitive algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>The interpolation problem is a special case of the superresolution task, where pure decimation is applied on the original high-resolution image, leading to a subset of known pixels and void values around them in a regular pattern. The problem of filling-in these missing values has drawn a considerable attention in the past several years, and various techniques that rely on image statistics have been proposed. Inspired by the work reported in <ref type="bibr" target="#b14">[15]</ref> and <ref type="bibr" target="#b15">[16]</ref>, we proposed in this paper a novel image interpolation scheme that is composed of two phases. In both, the main forces exploited are sparse representation of the high-resolution image patches with a 8 Regarding the complexity analysis of NARM and their notations, we set T = I , N L = N/L 2 , and assume that q ≈ N/K , t 1 &lt; u ≈ p ≈ n ≈ K q and κ ≈ √ n. The complexity of the proposed algorithm is obtained under the assumptions that</p><formula xml:id="formula_27">K ≈ s ≈ √ n, n &lt; m ≈ h 2 , m ≈ n 1.5 .</formula><p>trained dictionary, and non-local relations that exist between image patches. The obtained results are encouraging, and our hope is to leverage this approach to treat more complicated scenarios such as single image super-resolution with assumed blur and noise, or fusion of several images. APPENDIX A closed-form solution for Equation <ref type="bibr" target="#b5">(6)</ref> via the Lagrange multipliers method: This problem could be described more concisely as</p><formula xml:id="formula_28">x = min x 1 2</formula><p>Axb 2 2 s.t. y = Bx, <ref type="bibr" target="#b13">(14)</ref> where B is the down-sampling operator U L , the matrix </p><formula xml:id="formula_29">A = W1 R 1 ; W2 R 2 ; • • • ; WN R N ,</formula><p>2) Null the derivative w.r.t. x,</p><formula xml:id="formula_31">∂L ∂x = 0 ⇒ x = A T A -1 A T b -B T z . (<label>16</label></formula><formula xml:id="formula_32">)</formula><p>where A T A is a diagonal matrix, which counts the number of representations per each element. 3) Find z by forcing the constraint y = Bx:</p><formula xml:id="formula_33">y = B A T A -1 A T b -B T z ,<label>(17)</label></formula><p>leading to a closed-form solution for z by</p><formula xml:id="formula_34">z = B A T A -1 B T -1 B A T A -1 A T b -y . (<label>18</label></formula><formula xml:id="formula_35">)</formula><p>Notice that the matrix to invert here is positive definite if A T A is positive definite, and B has full row-rank. In our case, these two requirements are met. 4) Finally, obtain a closed-form solution for x by substituting z into Equation <ref type="bibr" target="#b15">(16)</ref>.</p><formula xml:id="formula_36">x = A T A -1 A T b -A T A -1 B T z (19) = A T A -1 A T b -A T A -1 B T B A T A -1 B T -1 B A T A -1 A T b + A T A -1 B T B A T A -1 B T -1 y.</formula><p>Notice that this expression is misleadingly complex and long, and in fact it has a simple interpretation and easy computation. This can be exposed by separating the pixels in x to two kinds -the ones that were known in the low-resolution image, and the others. First, by multiplying x by B we isolate the known pixels, and using Equation <ref type="bibr" target="#b18">(19)</ref> this leads to Bx = (20)</p><formula xml:id="formula_37">B A T A -1 A T b -B A T A -1 B T B A T A -1 B T -1 B A T A -1 A T b +B A T A -1 B T B A T A -1 B T -1 y = B A T A -1 A T b -B A T A -1 A T b + y = y,</formula><p>where we have used the self-cancellation of the term B A T A -1 B T with its inverse. The outcome should not be surprising, as it is exactly the constraint posed in <ref type="bibr" target="#b13">(14)</ref>.</p><p>As to the interpolated pixels, define the operator B as a decimation that removes the known pixels, leaving only the others. As above, we multiply x by B in order to see who those pixels are in the solution obtained in Equation <ref type="bibr" target="#b18">(19)</ref>. Observe that since A T A is diagonal, then the term B(A T A) -1 B T is zero. This is because B T interpolates an image by zero filling, the multiplication by (A T A) -1 scales every pixel in the outcome, and eventually B chooses only the zero pixels. Therefore, in Equation ( <ref type="formula">19</ref>), the second and third terms are nulled, leading to Bx = B(A T A) -1 A T b, <ref type="bibr" target="#b20">(21)</ref> which means that we put each reconstructed patch in its location, average them all, and normalize by the number of contributions per each pixel along with their weights. So, to summarize, the solution of the problem posed in Equation ( <ref type="formula">14</ref>) is given by x = (A T A) -1 A T b if this is an interpolated pixel y if this is a known pixel. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>) Algorithm 1</head><label>1</label><figDesc>Description of the First Stage of the Image Interpolation Algorithm where Supp{[α r i A sp i ]} are the supports of the indices of the non-zero rows in [α r i A sp i ] (the joint support) that were computed in Equation (9).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Test images from left to right and top to bottom: Bears, Butterfly, Elk, Fence, Flowers, Girl, Koala, Parthenon, Starfish, Boat, Cameraman, Foreman, House, Leaves, Lena, Parrot, Stream and Texture.</figDesc><graphic coords="7,57.95,115.37,56.78,56.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Visual comparison of crop from Elk, magnified by factor of 2. (a) LR. (b) Original. (c) Bicubic. (d) SAI. (e) SME .(f) PLE. (g) NARM. (h) Proposed.TABLE III SUMMARY OF THE INTERPOLATION RESULTS [PSNR] FOR UP-SCALING BY FACTOR OF L = 2 AND L = 3.</figDesc><graphic coords="9,61.43,165.05,112.58,84.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Visual comparison of crop from Fence, magnified by factor of 2. (a) LR. (b) Original. (c) Bicubic. (d) SAI. (e) SME. (f) PLE. (g) NARM. (h) Proposed.</figDesc><graphic coords="10,53.39,442.01,57.14,108.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Visual comparison of the absolute difference between portions from the original and the interpolated Fence image, magnified by factor of 2. (a) Original. (b) PLE Err. (c) NARM Err. (d) Proposed Err.</figDesc><graphic coords="10,114.95,442.01,57.14,108.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Visual comparison of crop from Parrot, magnified by factor of 3. (a) LR. (b) Original. (c) Bicubic. (d) SAI. (e) SME. (f) PLE. (g) NARM. (h) Proposed.</figDesc><graphic coords="11,76.19,429.00,70.55,105.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Visual comparison of crop from House, magnified by factor of 3. (a) LR. (b) Original. (c) SAI. (d) SME. (e) PLE. (f) NARM. (g) Proposed. O K • (s 2 • n + s 3 ) . The complexity of one dictionary-update step is approximately O n • (m 3 + s 2 • K • N) , where K • N is the number of examples (since the number of patches of</figDesc><graphic coords="11,54.95,555.96,75.80,105.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Visual comparison of the absolute difference between portions from the original and the interpolated House image, magnified by factor of 3. (a) Original. (b) PLE Err. (c) NARM Err. (d) Proposed Err.</figDesc><graphic coords="11,222.87,429.00,75.87,105.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9.The average PSNR [dB] over the test images as a function of the weight assigned to unknown pixels, ranging from 0.005 up to 1. Weight assigned to unknown pixels.For an image of size N pixels, the complexity of SME isO (N • log N), PLE costs O(I • B • n 2 • N),where I is the number of iterations and B is the number of PCA bases (typically B = 19), NARM costs O(I • n • N 2 ), where n is the patch-size. The proposed algorithm costs O(I •n 3 •(n 2.5 + N)).Note that in order to obtain a comparable complexity terms we made several assumptions about the variables dimensions.8  We test the runtime of an un-optimized Matlab implementation on an Intel Core i7 3 GHz processor. The runtime for interpolating a 128×128 LR image to a 256×256 HR image is about 1 minute per iteration; therefore it takes 10-15 minutes to obtain our best interpolation performance. The algorithm could be optimized by replacing the exhaustive K-NN search with a fast patch matching (see<ref type="bibr" target="#b31">[32]</ref>), reducing the number of examples for the dictionary update (e.g. by choosing mostly active\textured patches), applying the dictionary update every several iterations, etc. However, we did not take this route, and this is left for future work.To conclude, we demonstrated the efficiency of the proposed technique to recover an HR image from an observed LR one. We presented the advantages of the proposed two-stage algorithm over the general objective function. Furthermore, the experimental results indicate that the proposed method outperforms the state-of-the-art algorithms for interpolation by factors of L = 2 and L = 3. We illustrated the influence of the weights on the final result, discussed the similarity function and provided a complexity analysis along with a comparison to the competitive algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>and the vector b = W1 Dα sp 1 ; W2 Dα sp 2 ;</head><label>12</label><figDesc>• • • ; WN Dα sp N . Using Lagrange multipliers, the solution is obtained by the following steps: 1) Form the Lagrangian with Lagrange multiplier vector z by L(x, z) = 1 2 Axb 2 2 + z T (Bxy).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Matan</head><label></label><figDesc>Protter received his B.Sc. (2003) in Physics, Mathematics and Computer Science from the Hebrew University and his M.Sc. (2008) and Ph.D. (2011) from the Computer Science Department at the Technion, Israel. Matan worked for 6 years as a senior researcher in the image processing group in RAFAEL. He has founded two startups and consulted to various hitech companies in the field of computer vision. Michael Elad (F'12) received his B.Sc. (1986), M.Sc. (1988) and D.Sc. (1997) from the department of Electrical engineering at the Technion, Israel. Since 2003 he is a faculty member at the Computer-Science department at the Technion, and since 2010 he holds a full-professorship position. Michael Elad works in the field of signal and image processing, specializing in particular on inverse problems, sparse representations and superresolution. Michael received the Technion's best lecturer award six times, he is the recipient of the 2007 Solomon Simon Mani award for excellence in teaching, the 2008 Henri Taub Prize for academic excellence, and the 2010 Hershel-Rich prize for innovation. Michael is an IEEE Fellow since 2012. He is serving as an associate editor for SIAM SIIMS, and ACHA. Michael is also serving as a senior editor for IEEE SPL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Description of the Second Stage of the Image Interpolation Algorithm</figDesc><table><row><cell cols="2">Algorithm 2 Armed with D and {A image is obtained by 4</cell><cell>sp i } N i=1 , the reconstruction of the HR</cell></row><row><cell></cell><cell>N</cell></row><row><cell>min x</cell><cell>i=1</cell></row><row><cell></cell><cell></cell><cell>strong i</cell><cell>} N i=1 .</cell></row></table><note><p>with one major difference -replace {S i } N i=1 sets with {S</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I PARAMETERS</head><label>I</label><figDesc>USED PER EACH SCALING FACTOR AND STAGE using the non-weighted batch SOMP implementation, and (ii) given the supports, approximate {A</figDesc><table><row><cell>sp i } N i=1 representations by</cell></row><row><cell>solving the weighted least-squares problem</cell></row><row><cell>strong i ∀i, j ∈ S</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II INTERPOLATION</head><label>II</label><figDesc>RESULTS [PSNR] FOR UP-SCALING BY FACTOR OF L = 2 AND L = 3. WE COMPARE BETWEEN THE GENERAL OBJECTIVE FUNCTION (SECTION III-A), THE FIRST-STAGE (SECTION III-B) AND THE SECOND-STAGE (SECTION III-C) OF THE PROPOSED ALGORITHM. NOTICE THAT IN ALL CASES THE PERFORMANCE OF SECOND-STAGE IS EQUAL OR BETTER THAN THE FIRST-STAGE, AND OVERCOMES</figDesc><table /><note><p><p>THE GENERAL OBJECTIVE FUNCTION. THE BEST RESULTS</p>IN EACH LINE ARE HIGHLIGHTED</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>This paper concentrates on the single image interpolation problem, which is substantially different from the classical super-resolution task, where a group of images are fused to form a higher resolution result<ref type="bibr" target="#b0">[1]</ref>-<ref type="bibr" target="#b2">[3]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>In Section IV-C we provide an experiment along with a brief discussion regarding the need for these weights.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>In terms of PSNR and based on the test images, excluding α r i from the penalty function degrades the restoration performance. The average differences between the original proposed two-stage algorithm and excluding α r i from it are 0.39 dB and 0.38 dB for interpolation by factor of 2 and 3, respectively.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3"><p>Notice that the only difference between the general objective function and the second stage is the existence of the dictionary update.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors thank the anonymous reviewers for their helpful comments.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>. This work was supported in part by the European Research Council through the European Union 7th Framework Program, in part by the European Research Council under Grant 320649, and in part by the</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Generalizing the nonlocal-means to super-resolution reconstruction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Protter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Takeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="36" to="51" />
			<date type="published" when="2009-01">Jan. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast and robust multiframe super resolution</title>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1327" to="1344" />
			<date type="published" when="2004-10">Oct. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Image and video super-resolution via spatially adaptive block-matching filtering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Danielyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Workshop Local Non-Local Approx. Image Process</title>
		<meeting>Int. Workshop Local Non-Local Approx. Image ess</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cubic convolution interpolation for digital image processing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Keys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust., Speech Signal Process</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1153" to="1160" />
			<date type="published" when="1981-12">Dec. 1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cubic splines for image interpolation and digital filtering</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Andrews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoustics, Speech Signal Process</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="508" to="517" />
			<date type="published" when="1978-12">Dec. 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Image denoising by sparse 3-D transform-domain collaborative filtering</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2080" to="2095" />
			<date type="published" when="2007-08">Aug. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Implementation of the &apos;non-local Bayes&apos; (NL-Bayes) image denoising algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lebrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Process. Line</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="42" />
			<date type="published" when="2013-06">Jun. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A review of image denoising algorithms, with a new one</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multiscale Model., Simul</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="490" to="530" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">BM3D frames and variational image deblurring</title>
		<author>
			<persName><forename type="first">A</forename><surname>Danielyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1715" to="1728" />
			<date type="published" when="2012-08">Aug. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deblurring and denoising of images by nonlocal functionals</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kindermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multiscale Model., Simul</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1091" to="1115" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Super-resolution from a single image</title>
		<author>
			<persName><forename type="first">D</forename><surname>Glasner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bagon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 12th IEEE Int. Conf. Comput. Vis</title>
		<meeting>12th IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2009-10">Sep./Oct. 2009</date>
			<biblScope unit="page" from="349" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Image and video upscaling from local self-examples</title>
		<author>
			<persName><forename type="first">G</forename><surname>Freedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">From sparse solutions of systems of equations to sparse modeling of signals and images</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Bruckstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="34" to="81" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<title level="m">Sparse and Redundant Representations: From Theory to Applications in Signal and Image Processing</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sparse representation based image interpolation with nonlocal autoregressive modeling</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lukac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1382" to="1394" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Non-local sparse models for image restoration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 12th Int. Conf. Comput. Vis</title>
		<meeting>IEEE 12th Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2009-10">Sep./Oct. 2009</date>
			<biblScope unit="page" from="2272" to="2279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Algorithms for simultaneous sparse approximation. Part I: Greedy pursuit</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Tropp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Strauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="572" to="588" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">K -SVD: An algorithm for designing overcomplete dictionaries for sparse representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bruckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4311" to="4322" />
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Image interpolation by adaptive 2-D autoregressive modeling and soft-decision estimation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="887" to="896" />
			<date type="published" when="2008-06">Jun. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Super-resolution with sparse mixing estimators</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2889" to="2900" />
			<date type="published" when="2010-11">Nov. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Solving inverse problems with piecewise linear estimators: From Gaussian mixture models to structured sparsity</title>
		<author>
			<persName><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2481" to="2499" />
			<date type="published" when="2012-05">May 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Matching pursuits with time-frequency dictionaries</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3397" to="3415" />
			<date type="published" when="1993-12">Dec. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sparse solution of underdetermined systems of linear equations by stagewise orthogonal matching pursuit</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tsaig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Drori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Starck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1094" to="1121" />
			<date type="published" when="2012-02">Feb. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Atomic decomposition by basis pursuit</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Saunders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="61" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Method of optimal directions for frame design</title>
		<author>
			<persName><forename type="first">K</forename><surname>Engan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">O</forename><surname>Aase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Hakon</forename><surname>Husoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="2443" to="2446" />
			<date type="published" when="1999-03">Mar. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Improving dictionary learning: Multiple dictionary updates and coefficient reuse</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">N</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="82" />
			<date type="published" when="2013-01">Jan. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Image denoising via sparse and redundant representations over learned dictionaries</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3736" to="3745" />
			<date type="published" when="2006-12">Dec. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Aliasing as noise: A quantitative and qualitative assessment</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hazra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="1993-08">Aug. 1993</date>
			<biblScope unit="volume">1961</biblScope>
			<biblScope unit="page" from="2" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Efficient implementation of the K-SVD algorithm using batch orthogonal matching pursuit</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zibulevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Sci</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<pubPlace>Technion, Haifa, Israel</pubPlace>
		</imprint>
	</monogr>
	<note>Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Image deblurring and super-resolution by adaptive sparse domain selection and adaptive regularization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1838" to="1857" />
			<date type="published" when="2011-07">Jul. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Probabilistic subspace clustering via sparse representations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hel-Or</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="66" />
			<date type="published" when="2013-01">Jan. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Yaniv Romano received his B.Sc. (2012) from the department of Electrical engineering at the Technion, Israel, and he is currently a Ph.D. candidate in the same department. In parallel, Yaniv has been working in the industry since 2011 as an image processing algorithm developer. His research interests include sparse and redundant representations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Goldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">24</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>PatchMatch: A randomized correspondence algorithm for structural image editing. inverse problems and superresolution</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
