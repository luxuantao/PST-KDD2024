<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Scheduling Algorithms and Operating Systems Support for Real-Time Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>MEMBER, IEEE</roleName><forename type="first">Krithi</forename><surname>Ramamritham</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<postCode>01003</postCode>
									<settlement>Amherst</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>AND</roleName><forename type="first">John</forename><forename type="middle">A</forename><surname>Stankovic</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<postCode>01003</postCode>
									<settlement>Amherst</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Scheduling Algorithms and Operating Systems Support for Real-Time Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A13B94E725AD9DC7A9BC9926BB3341E7</idno>
					<note type="submission">received July 13, 1993.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper summarizes the state of the real-time field in the areas of scheduling and operating system kernels. Given the vast amount of work that has been done by both the operations research and computer science communities in the scheduling area, we discuss four paradigms underlying the scheduling approaches and present several exemplars of each. The four paradigms are: static tabledriven scheduling, static priority preemptive scheduling, dynamic planning-based scheduling, and dynamic best efSort scheduling. In the operating system context, we argue that most of the proprietary commercial kernels as well as real-time extensions to time-sharing operating system kernels do not fit the needs of predictable realtime systems. We discuss several research kernels that are currently being built to explicitly meet the needs of real-time applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Real-time systems are defined as those systems in which the correctness of the system depends not only on the logical result of computation, but also on the time at which the results are produced. Examples of this type of real-time system are command and control systems, process control systems, flight control systems, the Space Shuttle avionics system, future systems such as the space station, spacebased defense systems such as SDI, and large command and control systems. A majority of today's systems assume that much of this knowledge is available a priori, and hence are based on static designs which contribute to their high cost and inflexibility. The next generation hard real-time systems must be designed to be dynamic, predictable, and flexible.</p><p>When activities have timing constraints, as is typical of real-time computing systems, scheduling these activities to meet their timing constraints is one major problem that comes to mind. However, as we show in Section I1 of this paper, in spite of an extensive literature on Manuscript</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>scheduling, scheduling algorithms that are of practical value for real-time computing, ones that take real-world considerations into account, have only begun to appear. Given the vast amount of work that has been done by both the operations research and computer science communities in the scheduling area, it is impossible to do an exhaustive survey of the field. Instead, we discuss four paradigms underlying the scheduling approaches and discuss several exemplars of each. The four paradigms are: static tabledriven scheduling, static priority preemptive scheduling, dynamic planning-based scheduling, and dynamic best effort scheduling. Because of their increasing importance we also discuss the impact of quality-timeliness tradeoffs, fault-tolerance constraints, and resource reclaiming on scheduling.</p><p>Clearly, a real-time operating system must be able to perform integrated CPU scheduling and resource allocation so that collections of cooperating tasks can obtain the resources they need, at the right time, in order to meet timing constraints. In addition to proper scheduling algorithms, predictability requires bounded operating system primitives. Using the current operating system paradigm of allowing arbitrary waits for resources or events, or treating a task as a random process will not be feasible in the future to meet the more complicated set of requirements. It is also important to avoid having to rewrite the operating system for each application area. In Section 111 we elaborate on these issues and discuss operating systems under three broad categories: proprietary commercial kernels, real-time extensions to time-sharing operating system kernels, and research kernels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">REAL-TIME SCHEDULING</head><p>Scheduling involves the allocation of resources and time to tasks in such a way that certain performance requirements are met. Scheduling has been perhaps the most widely researched topic within real-time systems. This is due to the belief that the basic problem in real-time systems is to make sure that tasks meet their time constraints. Scheduling is also a well-structured and conceptually demanding problem. Given the resulting enormous amount of literature available on scheduling, any survey paper can only scratch the surface. On the other hand, just giving a list of algorithms is not useful. Hence, we have categorized the state of the art into a set of paradigmatic approaches to scheduling and present instances of the algorithms that fit the different paradigms.</p><p>This section is structured as follows. Since a scheduling algorithm is typically geared to meet a certain performance requirement, we first discuss, in Section 11-A, the different metrics that have been used in real-time systems, Based on these metrics and also on whether an algorithm is used on-line or off-line, different approaches or paradigms for scheduling have been used in the literature. Four main paradigms are introduced in Section 11-B. Section 11-C discusses different examples of scheduling algorithms that conform to these four paradigms. In Section 11-D we discuss three additional important scheduling topics: scheduling with quality-timeliness tradeoffs, scheduling with faulttolerance constraints, and resource reclaiming.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Performance Metrics in Real-Time Systems</head><p>The metrics that guide scheduling decisions depend on the application areas. The need to minimize the schedule length pervades static non-real-time systems and minimizing response times and increasing the throughput are the primary metrics in dynamic non-real-time systems. However, in both static and dynamic real-time systems, the main goal is to achieve timeliness. This introduces quite different metrics for the real-time case.</p><p>The variety of metrics that have been suggested for realtime systems is indicative of the different types of real-time systems that exist in the real world as well as the types of requirements imposed on them. This sometimes makes it hard to compare different scheduling algorithms. Another difficulty arises from the fact that different types of task characteristics occur in practice. Tasks can be associated with computation times, resource requirements, importance levels (sometimes also called priorities or criticalness), precedence relationships, communication requirements, and of course, timing constraints. If a task is periodic, its period becomes important; if it is aperiodic, its deadline becomes important. A periodic task may have a deadline by which it must be completed. This deadline may or may not be equal to the period. Both periodic and aperiodic tasks may have start time constraints.</p><p>Let us consider some of the performance metrics. In the static case, an off-line schedule is to be found that meets all deadlines. If many such schedules exist, a secondary metric, such as maximizing the average earliness is used to choose one among them. If no such schedule exists, one which minimizes the average tardiness may be chosen. In dynamic real-time systems, since, in general, it cannot be a priori guaranteed that all deadlines will be met, maximizing the number of arrivals that meet their deadlines is often used as a metric.</p><p>An issue related to metrics is the level of predictability afforded by a particular scheduling approach. That is, using a particular approach how well can we predict that the tasks will meet their deadlines? We will comment on this as we examine the different scheduling paradigms in the next subsection.</p><p>It should be mentioned that two different research communities have examined scheduling problems from their own perspectives. Scheduling in the Operations Research (OR) community has focussed on job-shop and flow-shop problems, with and without deadlines. For instance, manpower scheduling, project scheduling, and scheduling of machines are some of the topics studied in OR. The types of resources assumed by OR researchers (machines, factory cells, etc.) and how jobs use those resources (e.g., a job may be required to use every machine in some specified order) are quite different from those assumed by Computer Science researchers (CPU cycles, memory, etc., and where jobs typically use only a single machine). Also, activities on a factory floor typically have larger time granularities than those studied by computer scientists. Some of the metrics of interest to the OR community are: minimizing maximum cost, minimizing the sum of completion times, minimizing schedule length, minimizing tardiness, and minimizing the number of tardy jobs. Also, OR techniques are geared towards static (off-line) techniques whereas those developed in computer science focus more on dynamic techniques. In spite of these differences, the abstract problems studied by the two communities have a large commonality. In this paper, however, we examine scheduling problems mainly from the perspective of computer science. For an OR view of the problem we refer the reader to [7], [12], <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b28">[29]</ref>,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>W1.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Scheduling Paradigms</head><p>As was mentioned in the previous section, predictability is one of the primary issues in real-time systems. Schedulability analysis or feasibility checking of the tasks of a real-time system has to be done to predict whether the tasks will meet their timing constraints. Several scheduling paradigms emerge, depending on a) whether a system performs schedulability analysis, b) if it does, whether it is done statically or dynamically, and c) whether the result of the analysis itself produces a schedule or plan according to which tasks are dispatched at run-time. Based on this we can . . identify the following classes of algorithms: Static table-driven approaches: These perform static schedulability analysis and the resulting schedule (or table, as it is usually called) is used at run time to decide when a task must begin execution. Static prioritydriven preemptive approaches: These perform static schedulability analysis but unlike in the previous approach, no explicit schedule is constructed. At run time, tasks are executed "highest priority first." Dynamic planning-based approaches: Unlike the previous two approaches, feasibility is checked at run time, i.e., a dynamically arriving task is accepted for execution only if it found feasible. (Such a task is said to be guaranteed to meet its time constraints.) One of the results of the feasibility analysis is a schedule or plan that is used to decide when a task can begin execution. Dynamic best effort approaches: Here no feasibility checking is done. The system tries to do its best to meet deadlines. But since no guarantees are provided, a task may be aborted during its execution. It must be pointed out that even though we have identified these four categories for ease of discussion, some scheduling techniques possess characteristics that span multiple paradigms. Now we briefly elaborate on each of these categories.</p><p>Static tahle-dri\&gt;en approaches are applicable to tasks that are periodic (or have been transformed into periodic tasks by well-known techniques). Given task characteristics, a table is constructed, using one of many possible techniques (e.g., using various search heuristics), that identifies the start and completion times of each task and tasks are dispatched according to this table. This is a highly predictable approach but is highly inflexible since any change to the tasks and their characteristics may require a complete overhaul of the table.</p><p>The approach traditionally used in non-real-time systems is the priority-based preemptive scheduling approach. Here, tasks have priorities that may be statically or dynamically assigned and at any time, the task with the highest priority executes. It is the latter requirement that necessitates preemption: if a low-priority task is in execution and a higher priority task arrives, the former is preempted and the processor is given to the new arrival. If priorities are assigned systematically in such a way that timing constraints can be taken into account, then the resulting scheduler can also be used for real-time systems. For example, using the ratemonotonic approach <ref type="bibr" target="#b35">[36]</ref>, utilization bounds can be derived such that if a set of tasks do not exceed the bound, they can be scheduled without missing any deadlines using such a static priority-driven preemptive scheduler.</p><p>Cyclic scheduling, used in many large-scale dynamic real-time systems [SI is a combination of both table-driven scheduling and priority scheduling. Here, tasks are assigned one of a set of harmonic periods. Within each period, tasks are dispatched according to a table that just lists the order in which the tasks execute. It is slightly more flexible than the table-driven approach because no start times are specified and it is amenable to U priori bound analysis-if maximum requirements of tasks in each cycle are known beforehand. However, pessimistic assumptions are necessary for determining these requirements. In many actual applications, rather than making worse case assumptions, confidence in a cyclic schedule is obtained by very elaborate and extensive simulations of typical scenarios. This approach is both error-prone and expensive <ref type="bibr" target="#b39">[40]</ref>.</p><p>The dynumic planning-based approaches provide the flexibility of dynamic approaches with some of the predictability of approaches that check for feasibility. Here, after a task arrives, but before its execution begins, an attempt is made to create a schedule that contains the previously guaranteed tasks as well as the new arrival. If the attempt fails and if the attempt is made sufficiently ahead of the deadline, time is available to take altemative actions. This approach provides for predictability with respect to individual arrivals and for achieving admission control.</p><p>In contrast, if a purely priority-driven preemptive approach is used, say, by using task deadlines as priorities, and without any planning, a task could be preempted any time during its execution. In this case, until the deadline arrives, or until the task finishes, whichever comes first, we do not know whether a timing constraint will be met. This is the major disadvantage of the dynamic. best effort approaches. If, however, we can analyze the worst case performance characteristics of such a scheduler, then perhaps it can be recognized and avoided. Such worst case analyses are in their infancy, being applicable to tasks with very simple characteristics [4].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Scheduling Algorithms for These Paradigms</head><p>The variety of performance metrics, scheduling approaches, and types of processing resources used by tasks imply a wide variety of scheduling algorithms. Before we delve into the algorithms, we note that most instances of the scheduling problem for hard real-time systems are computationally intractable. Here is a summary of the results discussed in <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>. The problem of scheduling tasks with unit computation times and arbitrary precedence relationships on two processors and one resource is NPcomplete; a polynomial time algorithm exists when the precedence relation is empty but arbitrary numbers of resources are present. But, for three processors and one resource, even with an empty precedence relationship, the problem is NP-complete. The generalized versions of the above problem are NP-complete even though for a limited number of cases polynomial time solutions exist. In summary, resource-constrained scheduling is an NP-complete problem, and the presence of precedence constraints exacerbates the problem. Hence, as we shall see in the rest of this section, many authors have examined the use of heuristics and approximation algorithms to deal with tasks that have complex requirements, including resource requirements and precedence constraints.</p><p>1 ) Static Table-Driven Scheduling: These approaches are motivated by the fact that resources needed to meet the deadlines of safety-critical tasks must be preallocated so that they can be guaranteed a priori. These tasks are usually statically scheduled such that their deadlines will be met even under worst case conditions. For obvious reasons, these tasks are assumed to be periodic. (If they are not, assuming worst case interarrival times, they can be converted into periodic arrivals.) For periodic tasks, there exists a feasible schedule if and only if there exists a feasible schedule for the LCM (the least common multiple) of the periods <ref type="bibr" target="#b29">[30]</ref>. Given a set of periodic tasks, a typical algorithm that deals with multiprocessors or a distributed system attempts to assign subtasks of the tasks to processors or sites in the system and to construct a schedule of length LCM of the the task periods. At run time, the set of tasks is repeatedly executed according to this schedule every LCM units of time.</p><p>If the tasks have simple characteristics, then a table can be constructed using the earliest-deadline-first (EDF), or the shortest-period-first technique. However, besides periodicity constraints, tasks may have resource requirements and can possess precedence, exclusion, communication, as well as replication constraints. In these cases, given the NP-completeness of the resulting scheduling problem, heuristics are resorted to <ref type="bibr" target="#b32">[33]</ref>. Most of the algorithms adopt aspects from the branch-and-bound discipline in searching for a feasible schedule.</p><p>For instance, Xu and Parnas <ref type="bibr" target="#b72">[73]</ref> have examined this scheduling problem for a task model where tasks are divided into subtasks and exclusion and precedence relations are specified among subtasks. It is applicable to multiprocessor systems. If an exclusion relation exists between two subtasks s1 and s g then S I ' S execution cannot be interrupted by s g and vice versa. Exclusion relations can be used to model resource access conflicts. The algorithm uses a branch-and-bound technique where an initial schedule that is based on ordering the tasks according to their deadlines is modified at each step to reduce the maximum lateness of the tasks. If a schedule is found with a maximum lateness that is zero or negative, then the schedule meets all the deadlines.</p><p>If a feasible schedule is not found then the algorithm at least derives a schedule with the smallest maximum lateness.</p><p>The algorithm described in <ref type="bibr" target="#b46">[47]</ref> considers communication and replication constraints and is applicable to distributed systems. It clusters subtasks of tasks based on the amount of communication involved between a pair of communicating subtasks and the computation time of the subtasks. Clustered subtasks are assigned to the same site, thereby eliminating the communication costs involved. A feasible schedule is determined by using a heuristic search technique that takes into account the various task characteristics, in particular, subtask computation times, communication costs, deadlines, and precedence constraints. Communication (between subtasks) on the communication channels in the system is also scheduled. This algorithm is designed for tasks whose subtasks may have to be executed on different sites, to cater, for example, to subtasks of a task having replication requirements. Further, the total computational requirements of subtasks of a task may be such that a single site may not be able to execute all of them within the period of the task. However, by distributing the subtasks, in particular, by exploiting the parallelism within a task, it may be possible to meet the periodicity requirements. Also, all resources needed by all the subtasks may not be available on any one site. The work described in <ref type="bibr" target="#b42">[43]</ref> is also applicable to tasks with precedence and communication constraints and is a pure branch-and-bound search. Unlike in <ref type="bibr" target="#b46">[47]</ref>, all the subtasks of a task are scheduled to execute on the same site.</p><p>The primary criterion in the static scheduling of periodic tasks is predictability, i.e., determining a feasible schedule wherein all tasks meet their timing requirements, precedence constraints, etc. Under static allocation and scheduling, exactly when and where instances of a task will execute are fixed. But, if both periodic tasks as well as nonperiodic tasks exist in a system, it will be advantageous to make some provision, during static scheduling, to cater to the needs of dynamic arrivals. For instance, some leeway could be provided such that the static schedules can be dynamically modified for better nonperiodic task schedulability while retaining the feasibility of the critical task set. A scheme to achieve this is discussed in <ref type="bibr" target="#b50">[51]</ref>.</p><p>2) Priority-Driven Preemptive Scheduling: Prioritydriven preemptive scheduling is the one used in most time-sharing systems. In non-real-time systems, the priority of a job changes depending on whether it is CPU-bound or I/O-bound. In real-time systems, priority assignment is related to the time constraints associated with a job or task and this assignment can be either static or dynamic.</p><p>Liu and Layland <ref type="bibr" target="#b35">[36]</ref> were perhaps the first to formally study priority-driven algorithms. They focussed on the problem of scheduling periodic tasks on a single processor and proposed two preemptive algorithms. The first algorithm, called the Rate-Monotonic (RM) algorithm assigns static priorities to tasks based on their periods. It assigns higher priorities to tasks with shorter periods. They showed that this scheme is optimal among static-priority schemes. This assignment is intuitively easy to understand. Liu and Layland also analyzed Earliest-Deadline-First (EDF), a dynamic priority-assignment algorithm: The closer a task's deadline, the higher its priority. This again is an intuitive priority assignment policy.</p><p>Static priorities are attractive because a task's priority is assigned once it arrives and does not have to be reevaluated as time progresses. The RM priority-assignment policy is applicable to periodic tasks. A dynamic priorityassignment policy, however, can be applied to both periodic and aperiodic tasks. In contrast with static priorities, a task's dynamic priority may change when a new task, say with an earlier deadline, arrives. This makes the use of dynamic priorities more expensive in terms of run-time overheads.</p><p>The advantage of either of these two priority-assignment policies is that, for periodic tasks, schedulability bounds on resource utilization by the tasks exist. In the case of the RM policy, a set of n tasks can be scheduled to meet its periodicity constraints on a uniprocessor provided the processor's utilization is no greater than In2 for large n. Better bounds based on more exact characterization of the RM policy can be found in <ref type="bibr" target="#b31">[32]</ref>. If the periods are harmonics of the smallest period, the bound is 1.00. In the case of EDF, the bound is always 1.00.</p><p>In addition to EDF, a task's laxity (given by the amount of time one can wait and still meet its deadline) can be used as its dynamic priority. This leads to the Least-Laxity-First algorithm. In fact, any function of the task's parameters can be used to assign priorities. We will see examples of these in Section 11-C3.</p><p>Even though the RM policy has been in use by NASA in its software for the Apollo space missions, <ref type="bibr" target="#b35">[36]</ref> is the first publication that gave a formal characterization and analysis of the RM policy. Then, after a long hiatus, it was picked up again by Sha, Lehoczky, and their colleagues, as well as Baker, among others, and extended in a variety of ways to deal with shared resources, aperiodic tasks, tasks with different importance levels, and mode changes. These are discussed in detail in <ref type="bibr" target="#b55">[56]</ref>.</p><p>Although feasibility checking or schedulability analysis is made easier by preemptive scheduling (in terms of theoretical optimality and complexity), the checking generally either ignores the dispatching cost, or assumes it is a negligibly small constant. However, in an actual system, dispatching is more complicated involving preemption, context switching, and readying the preempted task for future resumption. The dispatcher must also incorporate timer interrupts. The complexity of the dispatching process under nonpreemptive scheduling depends on whether the tasks are independent and whether there are resource constraints. The planning-based scheduling algorithms discussed next typically use nonpreemptive scheduling, partly motivated by the goal of reducing unnecessary preemptions.</p><p>3) Dynamic Planning-Based Scheduling: Dynamic planning-based schedulers focus on dynamically performing feasibility checks. A task is guaranteed by constructing a plan for task execution whereby all guaranteed tasks meet their timing constraints. A task is guaranteed subject to a set of assumptions, for example, about its worst case execution time and resource needs, and the nature of faults in the system. If these assumptions hold, once a task is guaranteed it will meet its timing requirements. A guarantee algorithm must consider many issues including worst case execution times, resource requirements, timing constraints, the presence of periodic tasks, preemptable tasks, precedence constraints (which is used to handle task groups), multiple importance levels for tasks, and faulttolerance requirements. In a distributed system, when a task arrives at a site, the scheduler at that site attempts to guarantee that the task will complete execution before its deadline, on that site. If the attempt fails, the scheduling components on individual sites cooperate to determine which other site in the system has sufficient resource surplus to guarantee the task.</p><p>An algorithm to guarantee nonpreemptable tasks arriving at a site given their arrival time, deadline or period, worst case computation time, and resource requirements is described in <ref type="bibr" target="#b48">[49]</ref>. A task uses a resource either in shared mode or in exclusive mode and holds a requested resource as long as it executes. Using heuristics, a full feasible schedule for a set of tasks is constructed in the following way. Starting at the root of the search tree which is an empty schedule the algorithm tries to extend the schedule (with one more task) by moving to one of the vertices at the next level in the search tree until a full feasible schedule is derived. To this end, a heuristic function H which synthesizes various characteristics of tasks affecting real-time scheduling decisions is used to actively direct the scheduling to a plausible path. H is applied to at most k tasks that remain to be scheduled at each level of search.</p><p>The task with the smallest value of function H is selected to extend the current partial schedule. If a partial schedule is found to be infeasible, it is possible to backtrack and then continue the search. If the value of IC is constant (and in practice, IC will be small when compared to the task set size n), the complexity is linearly proportional to n, the size of the task set <ref type="bibr" target="#b48">[49]</ref>. While the complexity is proportional to n, the algorithm is programmed so that it incurs a fixed worst case cost by limiting the number of H function evaluations permitted in any one invocation of the algorithm. The paper also discusses how to choose IC.</p><p>Dynamic algorithms that do not a priori know the arrival times of tasks cannot guarantee optimal performance <ref type="bibr" target="#b14">[15]</ref>. But one dynamic algorithm can be considered better than another, if given a number of task sets for which feasible schedules exists, the former is able to find feasible schedules for more task sets than the latter. Extensive simulation studies of the algorithm show that a heuristic that combines deadline and resource requirement information works very well (see also <ref type="bibr" target="#b73">[74]</ref>, <ref type="bibr" target="#b74">[75]</ref>) according to this performance criterion. Hence this algorithm has been implemented as part of the Spring kemel <ref type="bibr" target="#b62">[63]</ref>. In <ref type="bibr" target="#b71">[72]</ref>, another dimension of the heuristic algorithm, namely, the bound on the length of the schedule compared to an algorithm that minimizes schedule length is derived.</p><p>With regard to cooperation between processing elements, several schemes have been reported in the literature <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b49">[50]</ref>. We now discuss details of the four algorithms evaluated in <ref type="bibr" target="#b49">[50]</ref>. They differ in the way a site treats a task that cannot be guaranteed locally: In the randomscheduling algorithm, the task is sent to a randomly selected site; in the focussed-addressing algorithm, the task is sent to a site that is estimated to have sufficient surplus resources and time to complete the task before its deadline; in the bidding algorithm, the task is sent to a site based on the bids received for the task from sites in the system; and in thejexible algorithm, the task is sent to a site based on a technique that combines bidding and focussed addressing. These algorithms are compared, via simulations, relative to each other as well as with respect to two baselines. The first baseline is the noncooperative algorithm where a task that cannot be guaranteed locally is not sent to any other site. The second is an (ideal) algorithm that behaves exactly like the bidding algorithm, but incurs no communication overheads. The fact that distributed scheduling improves the performance of a hard real-time system is attested by the better performance of the flexible algorithm compared to the noncooperative baseline under all load distributions. The performance of the flexible algorithm is better than both the focussed-addressing and bidding algorithms. However, the performance difference between the bidding algorithm and the flexible algorithm under small communication delays is negligible. The same can be said about the performance difference between the focussed addressing algorithm and the flexible algorithm under large communication delays. The random algorithm performs quite well compared to the flexible algorithm, especially when system load is low as well as when system load is high and the load is unevenly distributed. Under moderate loads, its performance falls short by a few percentage points which may be significant in a hard real-time system. Overall, the studies show that no algorithm outperforms all others in all system states. Though the flexible algorithm performs better than the rest in most cases, it is more complex than the other algorithms. Other details of the distributed scheduling algorithms can be found in <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b49">[50]</ref>, <ref type="bibr" target="#b63">[64]</ref>. The stability of these algorithms is discussed in <ref type="bibr" target="#b58">[59]</ref>.</p><p>4 ) Dynamic Best Effort Scheduling: Best effort scheduling is the approach used by many real-time systems deployed today. In such systems, a priority value is computed for each task based on the task's characteristics and the system schedules tasks according to their priority. Confidence is gained in the system via extensive simulations, in conjunction with recoding the tasks and priority adjustment.</p><p>Often used real-time scheduling algorithms, such as, earliest deadline first and least laxity first have optimal behavior as long as no overloads occur. However, experiments reported in <ref type="bibr" target="#b38">[39]</ref> show that extreme performance degradation is encountered under overloads. But, since dynamic algorithms must perform well under varying loading conditions, the next task to execute or to discard in the case of an overload must be chosen carefully. The best effort approach proposed in <ref type="bibr" target="#b38">[39]</ref> tries to maximize the sum of the values of the tasks completed under overload condition where a task's value to the system depends on when it completes execution. Priority-driven preemptive scheduling is employed. Many different types of value functions are examined in <ref type="bibr" target="#b38">[39]</ref>, including shortest processing time first, earliest deadline first, least laxity first, first come first served, an algorithm that randomly chooses the next task to execute, as well as one that fixes a task's priority to be its highest possible value. In addition to the standard highest-priority-first scheduling algorithm, an algorithm which discards tasks with low value density, i.e., value per unit computation time, when an overload is considered likely, is also evaluated. As expected, the new algorithm improves performance under overloads. Dealing with overheads, in general, is a complex problem and solutions are still in their infancy <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr">[51.</ref> Clearly, the biggest disadvantage of dynamic best effort algorithms lie in their lack of predictability and their suboptimality. A dynamic scheduling algorithm is said to be optimal if it always produces a feasible schedule whenever a clairvoyant algorithm, i.e., a static scheduling algorithm with complete prior knowledge of the tasks, can do so. For most real-world circumstances, optimal dynamic algorithms do not exist <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b41">[42]</ref>. However, recognizing that it will be useful to quantify the worst case behavior of the dynamic algorithms, recently, there has been a surge of activity in this area. The results of this work can be useful in handling overloads effectively.</p><p>For example, <ref type="bibr" target="#b3">[4]</ref> analyzes such bounds for the problem of preemptively scheduling sporadic task requests in both uniprocessor and multiprocessor environments. In the model considered, if a task is successfully scheduled to completion, a value equal to the task's execution time is imparted to the system; otherwise, no value is obtained.</p><p>It is proved that no dynamic scheduling algorithm can guarantee a cumulative value greater than a fourth of the value obtainable by a clairvoyant algorithm. (In fact, for the algorithm in <ref type="bibr" target="#b38">[39]</ref>, this ratio can be as low as zero.) Furthermore, the paper presents a dynamic scheduling algorithm TD1 with this behavior, thus showing the bound to be tight. The paper also quantifies the relationship between the amount of overloading permitted and the bound. Generalization of these results to two processors gives an upper bound of 112 which is tight in some very special cases. These results are just the beginning and have to be elaborated to apply to more interesting and useful situations in order for dynamic best effort approaches to be employed by real-time systems that must be predictable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Other Important Scheduling Issues</head><p>In this section we discuss two issues that are important in any real real-time system. They are: supporting fault tolerance, and improving performance by utilizing time left unused when tasks do not use all the time earmarked for them. A third issue concerns scheduling imprecise computations, computations in which a tradeoff between the solution quality and timeliness can be achieved. Since a detailed discussion of imprecise computations appears in <ref type="bibr" target="#b37">[38]</ref> we do not discuss it here. 1 ) Scheduling with Fault-Tolerance Constraints: In this section, we examine some of the scheduling algorithms that explicitly take fault tolerance into account.</p><p>In <ref type="bibr" target="#b34">[35]</ref>, Liestman and Campbell propose a deadline mechanism that can guarantee that a primary task will make its deadline if there is no failure, and that an altemative task (of less precision) will run by the deadline if there is a failure. If the primary task executes then it is not necessary to run the altemative task and the time set aside for the alternative is reused. The paper deals with periodic tasks only and allows all tasks to be preempted. It is possible to precompute a tree of schedules (and backup schedules) where the tree can be encoded within an efficient tabledriven scheduler.</p><p>Krishna and Shin continue with this theme in <ref type="bibr" target="#b27">[28]</ref>. Specifically, they want to be able to quickly switch to a new task schedule upon failure, where that new schedule has been precomputed. Off-line they use a dynamic programming algorithm to compute contingency schedules which are embedded within the primary schedule. In this approach they are able to ensure that hard deadlines are met in the face of some maximum number of failures. The embedded contingency schedules are not used unless there is a failure. However, the contingency schedules do represent a latent demand for processing time, thereby lowering the efficiency of the primary schedules to some extent. This is the price paid for having very little on-line processing time available to respond to failures. This paper also assumes that there is a need to conserve memory so that at most one contingency schedule per processor can be stored. In many of today's real-time systems memory constraints are still bottlenecks and therefore need to be accounted for. This paper also considers periodic tasks, but in contrast with <ref type="bibr" target="#b34">[35]</ref> it does not suggest running some restricted and less accurate version of the task.</p><p>Approaches for fault tolerance, such as these two papers represent, are valuable for static, embedded computer systems where fault tolerance is extremely important and deadlines are very tight. In such cases, processor utilization is not important, rather guaranteeing the primary and contingency schedules are important. However, these static approaches are not suitable for many next-generation real-time systems which must provide for predictability while reacting to the dynamics of the environment. Also, techniques are required that can trade off fault tolerance for timeliness, if an application allows such tradeoffs, to handle overloads. For example, it is possible to combine the use of dynamic-planning-based schedulers, to provide predictability, with the notion of imprecise computations, to effect the tradeoffs. This brings to bear the power of the two complementary approaches to provide adaptive fault tolerance by focusing on the specific interaction between fault tolerance and scheduling. It allows the system to dynamically adapt the fault-tolerance requirements of processes. Planning permits the forecasting of timing errors, supports graceful degradation, and allows dynamic tradeoff analysis involving levels of redundancy and value accrued to the system.</p><p>2 ) Scheduling with Resource Reclaiming: The variance in tasks' execution times may result in some tasks completing earlier than expected by the scheduler. The task dispatcher can try to reclaim the time left by such early completion and utilize that to execute other tasks. Clearly, non-real-time tasks can be executed in the idle time slots. But, more valuable will be an approach that improves the guaranteeability of tasks that have time constraints. Several issues must be considered to achieve this. When the actual computation time of a task differs from its worst case computation time in a nonpreemptive multiprocessor schedule with resource constraints, run-time anomalies [ 191 may occur. These anomalies may cause some of the scheduled tasks to miss their deadlines. In particular, one cannot simply use any greedy or work-conserving dispatcher, one that will never leave a processor idle if there is a dispatchable task. For tasks with precedence constraints, Manacher <ref type="bibr">[4 11</ref> proposed an algorithm to avoid these anomalies by imposing additional precedence constraints on tasks to preserve the order of tasks which can run in parallel. Manacher's work was motivated by a need to make sure that the processors that execute task replicas (for fault tolerance) follow a consistent schedule even when tasks finish early. This is termed the stabilization problem.</p><p>Reclaiming unused time to improve the schedulability of dynamically arriving tasks is the motivation behind the work in <ref type="bibr" target="#b56">[57]</ref>. Resource reclaiming algorithms used in systems that do dynamic planning-based scheduling must be correct, i.e., must maintain the feasibility of guaranteed tasks; must be inexpensive, i.e., the overhead cost of a resource reclaiming algorithm should be very low compared to tasks' computation times since a resource reclaiming algorithm is invoked whenever a task finishes; must have bounded complexity, in particular, it should be independent of the number of tasks in the schedule, so that its cost can be incorporated into the worst case computation time of a task; and must be effective, i.e, it should improve the performance of the system.</p><p>In <ref type="bibr" target="#b56">[57]</ref> two resource reclaiming algorithms, are presented: Basic Reclaiming and Reclaiming with Early Start. These two algorithms employ strategies that are a form of dynamic local optimization of a feasible multiprocessor schedule. Both of these algorithms have bounded time complexity although Reclaiming with Early Start is more expensive to run than Basic Reclaiming. Simulation results demonstrate that these simple local optimizations can be very effective in improving the system performance in a dynamic realtime system and that resource reclaiming can compensate for the performance loss due to the worst case assumptions about the computation times of real-time tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">REAL-TIME OPERATING SYSTEMS</head><p>Real-time operating systems are an integral part of realtime systems. Not surprisingly, four main functional areas that they support are process management and synchronization, memory management, interprocess communication, and I/O. However, the manner in which they support these areas differs from conventional operating systems as will be discussed in this section. In particular, real-time operating systems stress predictability and include features to support real-time constraints. Three general categories of real-time operating systems exist: small, proprietary kernels (commercially available as well as homegrown kernels), real-time extensions to commercial timesharing operating systems such as UNIX, and research kernels. In this section we will survey these three main categories of real-time operating systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Small, Fast, Proprietary Kernels</head><p>The small, fast, proprietary kernels come in two varieties: homegrown' and commercial offerings'. Both varieties are often used for small embedded systems when very fast and highly predictable execution must be guaranteed. The homegrown kernels are usually highly specialized to the application. The cost of uniquely developing and maintaining a homegrown kernel, as well as the increasing quality of the commercial offerings is significantly reducing the practice of generating homegrown kernels. For both varieties of proprietary kernels, to achieve speed and predictability, the kernels are stripped down and optimized versions of time-sharing operating systems. To reduce the run-time overheads incurred by the kernel and to make the system fast, the kernel has a fast context switch, has a small size (with its associated minimal functionality),</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>'Examples include [l], [22].</head><p>' Examples of commercials kernels include QNX, PDOS, pSOS, VCOS, VRTX32, and VxWorks.</p><p>responds to extemal interrupts quickly (sometimes with a guaranteed maximum latency to post an event but, generally, no guarantee is given as to when processing of the event will be completed; this later guarantee can sometimes be computed if priorities are chosen correctly), minimizes intervals during which interrupts are disabled, provides fixed or variable sized partitions for memory management (i.e., no virtual memory) as well as the ability to lock code and data in memory, and provides special sequential files that can accumulate data at a fast rate. To deal with timing requirements, the kernel provides bounded execution time for most primitives, maintains a real-time clock, provides a priority scheduling mechanism, provides for special alarms and timeouts, supports real-time queuing disciplines such as earliest deadline first and primitives for jamming a message into the front of a queue, and provides primitives to delay processing by a fixed amount of time and to suspend/resume execution. In general, the kemels also perform multitasking and intertask communication and synchronization via standard, well-known primitives such as mailboxes, events, signals, and semaphores. While all these latter features are designed to be fast, fast is a relative term and not sufficient when dealing with real-time constraints. Nevertheless, many realtime system designers use these features as a basis upon which to build real-time systems. This has been effective in small embedded applications such as instrumentation, communication front ends, intelligent peripherals, and many areas of process control. Since these applications are simple it is relatively easy to show that all timing constraints are met. Consequently, the kernels provide exactly what is needed. However, as applications become more complex it becomes more and more difficult to craft a solution based on priority-driven scheduling where all timing, computation time, resource, precedence, and value requirements are mapped to a single priority for each task. In these situations demonstrating predictability becomes very difficult. For example, a task may block when it attempts to access a semaphore, new tasks may be dynamically invoked at higher priorities, messages may not be available when a task begins execution, events may be posted very quickly but there may be no guarantee that the processing required to respond to the event will execute in time, etc. Given this large amount of asynchrony, concurrency, and blocking, the unfortunate implementor is required to assign the proper priorities that ensures the system always meets all of its deadlines. Because of these reasons, some researchers believe that current kernel features provide almost no direct support for solving the difficult timing problems, and would rather see more sophisticated kernels that directly address timing and faulttolerance constraints.</p><p>Recently, there have been efforts to produce seamless real-time kernels that scale from the small, proprietary kemels to large kemels that support the full POSIXKJNIX interfaces. The idea is to let the user make tradeoffs in size, performance and functionality depending on the application. The lowest level of support is being called a nanokemel or alternatively a microkemel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Real-Time Extensions to Commercial Operating Systems</head><p>A second approach to real-time operating systems is the extension of commercial products, e.g., extending UNIX to RT-UNIX <ref type="bibr" target="#b15">[16]</ref>, or POSIX to RT-POSIX, or MACH to RT-MACH <ref type="bibr" target="#b68">[69]</ref>, or CHORUS to a real-time version <ref type="bibr">[lo]</ref>. The real-time version of commercial operating systems are generally slower and less predictable than the proprietary kernels, but have greater functionality and better software development environments-very important considerations in many applications. Another significant advantage is that they are based on a set of familiar interfaces (standards) that facilitate portability. For UNIX, since many variations of UNIX have evolved, a new standards effort, called POSIX, has defined a common set of user level interfaces for operating systems. In particular, the POSIX P. 1003.4 subcommittee is defining standards for real-time operating systems. To date, the effort has focused on eleven important real-time-related functions: timers, priority scheduling, shared memory, real-time files, semaphores, interprocess communication, asynchronous event notification, process memory locking, asynchronous I/O, synchronous I/O, and threads.</p><p>Various problems exist when attempting to convert a nonreal-time operating system to a real-time version. These problems can exist both at the system interface as well as in the implementation. For example, in UNIX interface problems exist in process scheduling due to the nice and setpriority primitives and its round robin scheduling policy. In addition, the timer facilities are too coarse, memory management (of some versions) contains no method for locking pages into memory, and interprocess communication facilities do not support fast and predictable communication. The implementation problems include intolerable overhead, excessive latency in responding to interrupts, partly but very importantly, due to the nonpreemptability of the kernel, and intemal queues are FIFO. These and other problems can and have been solved to result in a real-time operating system that is used for both realtime and non-real-time processing. However, because the underlying paradigm of time-sharing systems still exists users must be careful not to use certain non-real-time features that might insidiously impact the real-time tasks.</p><p>For example, in <ref type="bibr" target="#b15">[16]</ref> they list over 60 RT-UNIX system calls that are not recommended to be used when running a real-time application. This is very disturbing because in converting from UNIX to RT-UNIX the following aspects were changed: scheduling, interrupt handling, IPC, the file system, I/O support, how the user controls resource use, timer facilities, memory management, and the basic syn-chronization assumptions of the kemel. The juxtaposition of changing almost everything and then ending up with over 60 system calls that should still not be used, should lead us to question whether extending a commercial time-sharing OS is the correct approach. We believe that it is not the correct approach because too many basic and inappropriate underlying assumptions still exist. This includes: optimizing for the average case (rather than worst assigning resources on demand, ignoring most if not all semantic information about independent CPU scheduling and resource allocation</p><p>On the other hand, the trend to begin with a completely new implementation of UNIX based on microkemels may reduce or eliminate some of the above problems. Consider several more detailed examples from MACH. MACH is heavily based on lazy evaluation, meaning that you never do anything until it is really needed. One example of this strategy is copy-on-write. Here either a message or part of an address space is not actually copied at the message send time or at address space create time, respectively, but delayed until that message (memory) is actually accessed. On the average this provides excellent performance. The problem is that large amounts of execution time may be required at the wrong time to finally perform the copy, causing a task to miss a deadline. Basically, it cannot be predicted as to when slowdowns will occur. Can all forms of lazy evaluation be eliminated to push MACH towards predictability? Yes, but it is difficult because of the overpowering integration of this philosophy in the kemel. Virtual memory is another problem. It is possible to lock pages in memory to remove some of the unpredictability (except, it is nontrivial to decide when to lock and unlock, accounting for the cost of the lock and unlock, and ensuring that the pages are locked in time). Does locking pages, by itself, make the virtual memory part of the system predictable? What about unpredictabilities due to the memory map tables (lookup and maintenance), the MMU TLB entries (present or not), hash table entries used for quick lookup (access time in the table), and indirect problems such as how by locking many pages we might affect the performance of both real-time and nonreal-time threads needing pages now being drawn from a smaller pool? Valuable real-time features that were added to MACH include real-time threads, real-time synchronization primitives, support for priority inheritance, and real-time scheduling, but all of these are still embedded in a timesharing paradigm.</p><p>Another fundamental problem with the time-sharing paradigm is that these operating systems want to remove control over resources from the application. Such operating systems consider it their prerogative to decide who should get resources for the best average case performance. For example, a multilevel feedback queue will modify the userspecified priorities to balance 1/0 and CPU performance. case), the application, and possibly causing unbounded blocking.</p><p>After a real-time application designer goes through torture to map all the complexities of his application into a set of priorities, if the system adjusts these priorities, then the analysis and evaluation were for naught. Allowing fixed priorities or another real-time scheduling algorithm helps, but insidious interactions from the non-real-time threads, through their resource use and scheduling policy, might slow down the real-time tasks (in some unanticipated Given all these problems for RT-UNIX or RT-MACH can they be used in real-time applications? Yes, certainly for real-time applications where missing a deadline has no severe consequences, they can be used. If deadlines must be guaranteed to be met, these operating systems can still be used if the designers can hand craft a set of priorities that will always work. For example, given five independent periodic tasks with certain periods and deadlines, running only these at fixed priorities on these operating systems can easily be shown to work (however, it would be just as easy to use the proprietary kernels). As we add aperiodics, interrupts from the environment, shared data structures, precedence constraints between tasks, nonreal-time background processing, etc., assigning priorities such that it will always work becomes difficult and the designer is still not certain that lurking problems do not exist due to the underlying time-sharing design. Such an approach typically has very high cost and is very difficult to maintain. way).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C . Research Operating Systems</head><p>While many real-time applications will continue to be constructed with proprietary real-time kernels and with extensions to commercial time-sharing operating systems, as discussed above, significant problems still exist. In particular, the proprietary kernels have difficulty when scaling to large applications, and the time-sharing extensions emphasize speed rather than predictability, thereby perpetuating the myth that real-time computing is fast computing <ref type="bibr" target="#b60">[61]</ref>. strongly emphasizing predictability not only of the kemel but also providing good support for application level predictability, retaining significant amounts of application semantics at run time, developing support for fault tolerance, investigating object-oriented approaches, providing support for multiprocessor and distributed real-time systems including end-to-end timing constraints, and attempting to define a real-time micro-kemel. In the remainder of this section we will briefly survey several research projects to provide a brief idea about the scope and type of research that is ongoing. The projects chosen here are representative of a much wider set of work in the field.</p><p>1 ) MARS: The MARS kemel [13], <ref type="bibr" target="#b26">[27]</ref> offers support for controlling a distributed application based entirely on time events (rather than asynchronous events) from the environment. Emphasis is placed on an a priori static analysis to demonstrate that all the timing requirements are met. An important feature of this system is that flow control on the maximum number of events that the system handles is automatic and this fact contributes to the predictability analysis. This system is based on a paradigm, i.e., the timedriven model, that is different than what is found in timesharing systems. The scheduling approach is static tabledriven. Support for distributed real-time systems includes a hardware-based clock synchronization algorithm and a TDMA-like protocol to guarantee timely message delivery.</p><p>2) Spring: The Spring kemel <ref type="bibr" target="#b62">[63]</ref> contains real-time support for multiprocessors and distributed systems. A novel aspect of the kernel is the dynamic-planning-based scheduling of tasks that arrive dynamically. This takes tasks' time and resource constraints into account and avoids the need to a priori compute worst case blocking times. Safety-critical tasks are dealt with via static table-driven scheduling. The kernel also embodies a reflective architecture that retains a significant amount of application semantics at run time. This approach provides a high degree of flexibility and graceful degradation. These planning and application semantic features are integrated to provide direct support for achieving both application and system level predictability. The kemel also uses global replicated memory to achieve predictable distributed communication. The abstractions provided by the kemel include guarantee, reservation, planning, and end-to-end timing support. Spring, like MARS, presents a new paradigm for real-time operating systems, but unlike MARS (to date), it strives for a more flexible combination of off-line and on-line techniques.</p><p>3) MARUTI: The MARUTI system [21] focuses on support for dynamic on-line guarantees that tasks will make their deadlines and on fault tolerance. It is object based and supports distributed systems. Each object has service access points which are the operations (services) that the object provides. Information about objects such as their computation times and deadlines are retained with the ob-jects to be used by the dynamic-planning-based scheduler. When an object is invoked the scheduler determines if the object can be guaranteed to meet its timing constraint. If so, the schedule for it is added to a calendar that represents the deterministic manner in which the object will execute and all resources the object will require are reserved. MARUTI has been designed in a top-down fashion with a goal of demonstrating principles. As such, the actual implementation is high-level and runs on top of UNIX. An implementation in native mode is underway.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4)ARTS:</head><p>The ARTS kernel <ref type="bibr" target="#b67">[68]</ref> provides a distributed real-time computing environment that works in conjunction with the static priority-driven preemptive scheduling paradigm. The kemel supports the notion of real-time objects and real-time threads. Each real-time object is timeencapsulated. This is enforced by a time fence mechanism which provides a run-time check that ensures that the slack time is greater than the worst case execution time for an object invocation about to be performed. If it is, the operation proceeds, else it is aborted. Each real-time thread can have a value function, timing constraints, worst case execution time, phase, and delay value associated with it. Communication (object invocation) proceeds in a request-accept-reply fashion, but does not address deadlines for messages. A real-time transport protocol has been developed, but is not yet included in the ARTS kemel. The ARTS kernel is also tied to various tools that a priori analyze the system-wide schedulability of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) CHAOS:</head><p>The CHAOS system <ref type="bibr" target="#b52">[53]</ref> represents an object-based approach to real-time kernels. This approach allows easy creation of a family of kemels, each tailored to a specific hardware or application. This is important because real-time applications vary widely in their requirements and it would be beneficial to have one basic paradigm for a wide range of applications. The family of kemels is based on a core that supports a realtime threads package. This core is the machine-dependent part. Virtual memory regions, synchronization primitives, classes, objects, and invocations all comprise additional support provided in each kemel. One of the investigated scheduling approaches is guarantee-oriented, employing a variation of the preemptive deadline-first scheduling algorithm for its feasibility checking <ref type="bibr" target="#b5">[6]</ref>. Unlike the scheduling approach used in Spring in which both timing and functionality of a task are guaranteed, here, it is verified that a set of tasks can meet their deadline requirements based on optimistic assumptions about resource availability, for instance. Thus depending on blocking for resources, a task may not achieve its desired functionality, even though it will meet its timing constraint.</p><p>6) HARTOS: The Hexagonal Architecture for Real-Time Systems (HARTS) consists of multiple sites connected by a hexagonal mesh network. Each site may be a uniprocessor or multiprocessor and contains an intelligent network processor. The intelligent network processor handles much of the low-level communication functions. An experimental operating system called HARTOS <ref type="bibr" target="#b25">[26]</ref> is a distributed realtime kemel running on HARTS. On each site HARTOS runs in conjunction with the commercial uniprocessor OS, pSOS, so, by itself, is not a full operating system. Rather, HARTOS focuses on interprocess communication, thereby providing some support for distributed real-time systems. In particular, HARTOS supports message send and receive, nonqueued-event signals, reliable streams, and message scheduling that provides a best effort approach in delivering a message by its deadline. Support for fault-tolerant routing, clock synchronization, and for replicated processes are planned for the future. 7) DARK: Ada is mandated to be used in embedded real-time systems for many DoD projects. The Distributed Ada Real-Time Kemel (DARK) [71] has been developed to provide support for execution of Ada applications in a distributed real-time environment. The kemel supports both Ada tasks and kemel processes which are outside of the Ada run-time environment. For real-time control, the application programmer, writing in Ada, deals directly with kemel processes and the kemel's scheduler by appropriate declarations. The scheduler is based on the dynamic best effort paradigm, where a simple highest priority first scheduler is used. DARK also implements layers 2 through 4 of the standard I S 0 reference model to support distributed communication, There are no special time-related services provided in the interprocess communication implementation. The goal of DARK was to provide a near-term option of how to use Ada in a distributed real-time system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. SUMMARY</head><p>This paper presents a categorized summary of work in the areas of scheduling and operating systems for real-time applications. In particular, four scheduling paradigms were identified: static table-driven scheduling, static priority preemptive scheduling, dynamic planning-based scheduling, and dynamic best effort scheduling. Real-time operating systems were categorized into three classes: small, proprietary kemels, real-time extensions to commercial operating systems, and research kemels. Rather than being exhaustive, we have provided specific examples from each of the categories. Exciting developments and serious limitations of the current work both in scheduling and operating systems was also noted. Important interactions between scheduling algorithm development and operating systems exist. For example, whereas scheduling is an integral part of any real-time operating system, barring a few exceptions, most scheduling work has ignored the overheads involved in scheduling. As we saw, for predictability, it is essential to account for all the overheads involved. This is another area where there are new challenges.</p><p>It is also important to point out that in several real-world applications, there exists end-to-end timing constraints with respect to computations that span many processing sites. Allocation and scheduling the communication as well as processing resources in an integrated fashion still remains a problem awaiting efficient and flexible solutions. Furthermore, many applications with end-to-end constrains have prababilistic requirements. For example, in telephone switching, it is required to establish z percentage of the connections within y amount of time. Schemes to meet such performance requirements and methodical approaches for showing that the requirements will be met are also worthy of further exploration.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="0" xml:id="foot_0"><p> </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>19/94$04.00 0 1994 IEEE PROCEEDINGS OF THE IEEE, VOL. 82. NO. I , JANUARY 1994 5.5</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>RAMAMRITHAM AND STANKOVIC. ALGORITHMS AND SUPPORT FOR REAL-TIME SYSTEMSSI</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>RAMAMRITHAM AND STANKOVIC: ALGORITHMS AND SUPPORT FOR REAL-TIME SYSTEMS</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This material is. based upon work supported by the National Science Foundation under Grants CDA-8922572 and IRI-9208920, and by the Office of Naval Research under Grant N00014-92-J-1048.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PROCEEDINGS OF THE</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Real-time operating system for a nuclear power plant computer</title>
		<author>
			<persName><forename type="first">L</forename><surname>Alger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Real-Time Systems Symp</title>
		<meeting>Real-Time Systems Symp</meeting>
		<imprint>
			<date type="published" when="1986-12">Dec. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Stack-based scheduling of real-time processes</title>
		<author>
			<persName><forename type="first">T</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Real-Time Syst</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="100" />
			<date type="published" when="1991-03">March 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Task allocation in faulttolerant distributed systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Bannister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Informatica</title>
		<imprint>
			<biblScope unit="page" from="261" to="281" />
			<date type="published" when="1983">1983</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On the competitiveness of online real-time scheduling</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baruah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rosier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shasha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proc Real-Time Systems Symp.</title>
		<imprint>
			<date type="published" when="1991-12">Dec. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The integration of deadline and criticalness in hard real-time scheduling</title>
		<author>
			<persName><forename type="first">Si</forename><forename type="middle">S</forename><surname>Biyabani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stankovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamritham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Real-Time Systems Symp</title>
		<meeting>Real-Time Systems Symp</meeting>
		<imprint>
			<date type="published" when="1988-12">Dec. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Experimental evaluation of a real-time scheduler for a multiprocessor system</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schwan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1991-01">Jan. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Scheduling under resource constraints-deterministic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Blazewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cellary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Slowinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weglarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annals of Operations Research</title>
		<imprint>
			<publisher>Baltzer AG Scientific Pub. Company</publisher>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Architecture of the Space Shuttle primary avionics software system</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Carlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="1984-09">Sept. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Some results of the earliest deadline scheduling algorithm</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chetto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="1989-10">Oct. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Chorus Kernel 1,3 r4.0 Programmer&apos;s Reference Manual</title>
		<imprint>
			<date type="published" when="1991-09">Sept. 1991</date>
		</imprint>
		<respStmt>
			<orgName>Chorus Systems</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep. CSDR-91-71</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Task allocation and precedence relations for distributed real-time systems</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">lEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="1987-06">June 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Coffman</surname></persName>
		</author>
		<title level="m">Computer and JohlShop Scheduling Theory</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The real-time operating system of Mars</title>
		<author>
			<persName><forename type="first">A</forename><surname>Damm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reisinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Schnakel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kopetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operating Syst. Rev</title>
		<imprint>
			<biblScope unit="page" from="141" to="157" />
			<date type="published" when="1989-07">July 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An on line algorithm for real-time tasks allocation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Davari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Dhall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Real-Time Systems Symp.. Washington</title>
		<meeting>Real-Time Systems Symp.. Washington</meeting>
		<imprint>
			<publisher>DC: Computer Soc. Press</publisher>
			<date type="published" when="1986-12">Dec. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multiprocessor on-line scheduling of hard-real-time tasks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Dertouzos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K L</forename><surname>Mok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="1989-12">Dec. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Real-Time Unix Systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Furht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grostick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gluch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rabbat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Roberts</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Kluwer</publisher>
			<pubPlace>Norwell, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Complexity results for multiprocessor scheduling under resource constraints</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Garey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM . I . Comput</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Computers and Intractability: A Guide to the Theory of NP-Completeness</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bounds on multiprocessing timing anomalies</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J . Appl. Math</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1969-03">Mar. 1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Optimization and approximation in deterministic sequencing and scheduling: A survey</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Lawler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Lenstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H G R</forename><surname>Kan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals Discrete Math</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">MARUTI, An environment for hard real-time applications</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gudmundsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agrawala</surname></persName>
		</author>
		<author>
			<persName><surname>Tripathi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mission Critical Operating Systems</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Agrawala</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Gordon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Hwang</surname></persName>
		</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Hawk: An operating system kemel for a real-time embedded multiprocessor</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">P</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Piorkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Davidson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sandia Nat. Labs., Rep</title>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On-line scheduling of real-time tasks</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Y-T</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Real-Time Systems Symp</title>
		<meeting>Real-Time Systems Symp</meeting>
		<imprint>
			<date type="published" when="1988-12">Dec. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Load sharing with considerations of future arrivals in heterogeneous distributed real-time systems</title>
		<author>
			<persName><forename type="first">C-J</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Real-Time Systems Symp</title>
		<meeting>Real-Time Systems Symp</meeting>
		<imprint>
			<date type="published" when="1991-12">Dec. 1991</date>
			<biblScope unit="page" from="94" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The kernel computational model of the alpha real-time distributed operating system</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mission Critical Operating Systems</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Agrawala</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Gordon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Hwang</surname></persName>
		</editor>
		<imprint>
			<publisher>10s Press</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A real-time operating system for HARTS</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kandlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kiskis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mission Critical Operating Systems</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Agrawala</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Gordon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Hwang</surname></persName>
		</editor>
		<imprint>
			<publisher>Eds. 10s Press</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Distributed fault tolerant real-time systems: The Mars approach</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kopetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Demm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mulozzani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>IEEE Micro</publisher>
			<biblScope unit="page" from="25" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On scheduling tasks with a quick recovery from failure</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="448" to="455" />
			<date type="published" when="1986-05">May 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Recent results in the theory of machine scheduling</title>
		<author>
			<persName><forename type="first">E</forename><surname>Lawler</surname></persName>
		</author>
		<editor>A. Bachem et al.</editor>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Marhematical Programming: The State of the Art</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Scheduling periodically occurring tasks on multiple processors</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Lawler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">U</forename><surname>Martel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing Lett</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1981-02">Feb. 1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Enhancing aperiodic responsiveness in a hard real-time environment</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Lehoczky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Strosnider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Real-Time Systems Symp</title>
		<meeting>Real-Time Systems Symp</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The rate monotone scheduling algorithm: exact characterization and average case behavior</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Lehoczky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Real-Time Systems Symp</title>
		<meeting>IEEE Real-Time Systems Symp</meeting>
		<imprint>
			<date type="published" when="1989-12">Dec. 1989</date>
			<biblScope unit="page">166171</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Guaranteed response time in a hard realtime environment</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Leinbaugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="1980-01">Jan. 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Complexity of machine scheduling problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lenstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H G R</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bruchker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977">1977</date>
			<publisher>North-Holland</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>in Annals of Discrete Mathematics</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A fault tolerant scheduling problem</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Liestman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1089" to="1095" />
			<date type="published" when="1986-11">Nov. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Scheduling algorithms for multiprogramming in a hard real-time environment</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Layland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J . Amer. Compt. Mach</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="5" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Algorithms for scheduling imprecise calculations</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">5848</biblScope>
			<date type="published" when="1991-05">May 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Imprecise computations</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W S</forename><surname>Liu</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Best-effort decision making for real-time scheduling</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Locke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985-05">May 1985</date>
			<pubPlace>Pittsburgh, PA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon Univ.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Software architecture for hard real-time applications: Cyclic executives vs. fixed priority executives</title>
	</analytic>
	<monogr>
		<title level="j">Real-Time Systems</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Production and stabilization of real-time task schedules</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Manacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J . Assoc. Ccomput. Mach</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Fundamental design problems of distributed systems for the hard real-time environment</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Mok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dep. Elec. Engi. Comput. Sci., Mass. Inst. Techno</title>
		<imprint>
			<date type="published" when="1983-05">May 1983</date>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
	<note>Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Static allocation of periodic tasks with precedence constraints in distributed real-time systems</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Distributed Computing</title>
		<meeting>Int. Conf. on Distributed Computing</meeting>
		<imprint>
			<date type="published" when="1989-06">June 1989</date>
			<biblScope unit="page" from="190" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Real-time synchronization protocols for multiprocessors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rajkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lehoczky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Real-Time Systems Symp</title>
		<meeting>Real-Time Systems Symp</meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">R</forename><surname>Rajkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Lehoczky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamritham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Principles of Real-Time Systems</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Son</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ed</forename></persName>
		</editor>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Dynamic task scheduling in distributed hard real-time systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamritham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stankovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Software</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="65" to="75" />
			<date type="published" when="1984-07">July 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Allocation and scheduling of complex periodic tasks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamritham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th Int. Conf. on Distributed Computing Systems</title>
		<meeting><address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990-06">June 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Scheduling strategies adopted in Spring: An overview</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamritham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stankovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of Real-Time Computing: Scheduling and Resource Management</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Van Tilborg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Koob</surname></persName>
		</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Efficient scheduling algorithms for real-time multiprocessor systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamritham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stankovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shiah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Parallel Distributed Syst</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="184" to="194" />
			<date type="published" when="1990-04">Apr. 1990. Mar. 1992</date>
			<publisher>Kluwer</publisher>
			<pubPlace>Norwell, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Distributed scheduling of tasks with deadlines and resource requirements</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamritham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stankovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="11" to="21" />
			<date type="published" when="1989-08">Aug. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Issues in the static allocation and scheduling of complex periodic tasks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamritham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fohler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Adan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th IEEE Workshop on Real-Time Operating Systems and Software</title>
		<imprint>
			<date type="published" when="1993-05">May 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">VRTX: A real-time operating system for embedded microprocessor applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ready</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986-08">Aug. 1986</date>
			<publisher>IEEE Micro</publisher>
			<biblScope unit="page" from="8" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">From Chaos&quot;&quot;&quot;&apos; to Chaos&quot;&apos; : A family of real-time kernels</title>
		<author>
			<persName><forename type="first">K</forename><surname>Schwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Geith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Real-Time Systems Symp</title>
		<meeting>Real-Time Systems Symp</meeting>
		<imprint>
			<date type="published" when="1990-12">Dec. 1990</date>
			<biblScope unit="page" from="82" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Priority inheritance protocols: An approach to real-time synchronization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rajkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lehoczky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">185</biblScope>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Mode change protocols for priority-driven preemptive scheduling</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rajkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lehoczky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamritham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Real-Time Syst</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="243" to="264" />
			<date type="published" when="1989-12">Dec. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Generalized rate-monotonic scheduling theory: A framework for developing real-time systems</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sha</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>this issue</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Resource reclaiming in multiprocessor real-time systems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamritham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stankovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Parallel Distributed Syst</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="382" to="397" />
			<date type="published" when="1993-04">Apr. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Aperiodic task scheduling for hard real-time systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sprunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lehoczky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Real-Time Syst</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2740</biblScope>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">stability and distributed scheduling algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stankovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Decentralized decision making for task allocation in a hard real-time system</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stankovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<date type="published" when="1989-03">Mar. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Misconceptions about real-time computing</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="1988-10">Oct. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">The Spring kemel: A new paradigm for real-time operating systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stankovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamritham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Operating Syst. Rev</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="54" to="71" />
			<date type="published" when="1989-07">July 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">The Spring kernel: A new paradigm for hard real-time operating systems</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Software</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="62" to="72" />
			<date type="published" when="1991-05">May 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Evaluation of a flexible task scheduling algorithm for distributed hard realtime systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stankovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamritham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">11361143</biblScope>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">SpringNet: A scalable architecture for high performance, predictable, distributed, real-time computing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stankovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Univ. of Massachusetts, Tech. Rep</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">74</biblScope>
			<date type="published" when="1991-10">Oct. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Dynamic scheduling to support adaptive fault tolerance in real-time systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stankovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamritham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992-12">Dec. 1992</date>
		</imprint>
	</monogr>
	<note>submitted for publication</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Scramnet Network Reference Manual, Dayton</title>
		<author>
			<persName><surname>Systran Corp</surname></persName>
		</author>
		<imprint>
			<publisher>OH</publisher>
			<biblScope unit="page">45432</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">ARTS: A distributed real-time kerne1</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tokuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Operating Systems Rev</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1989-07">July 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Real-time Mach: Towards a predictable real-time system</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tokuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nakajima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Usenix Mach Workshop</title>
		<meeting>Usenix Mach Workshop</meeting>
		<imprint>
			<date type="published" when="1990-10">Oct. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Implementation of a time driven scheduler for real-time operating systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tokuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wendorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Real-Time Systems Symp</title>
		<meeting>Real-Time Systems Symp<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<publisher>Computer Soc. Press</publisher>
			<date type="published" when="1987-12">Dec. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">An overview of DARK</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van Scoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bamberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Firth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mission Critical Operating Systems</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Agrawala</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Gordon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Hwang</surname></persName>
		</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Bounds on the schedule length for some heuristic scheduling algorithms for hard real-time systems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamritham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stankovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Real-Time Systems Symp</title>
		<meeting>Real-Time Systems Symp</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Scheduling processes with release times, deadlines, precedence, and exclusion relations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Parnas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="page">366369</biblScope>
			<date type="published" when="1990-03">Mar. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Simple and integrated heuristic algorithms for scheduling tasks with time and resource constraints</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamritham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J . Syst. Software</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="195" to="205" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Scheduling tasks with resource requirements in hard real-time systems</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamritham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stankovic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985. 10s Press, 1992</date>
			<biblScope unit="volume">152</biblScope>
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
