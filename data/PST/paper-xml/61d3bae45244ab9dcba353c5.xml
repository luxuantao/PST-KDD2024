<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CAUSALMTA: Eliminating the User Confounding Bias for Causal Multi-touch Attribution</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Di</forename><surname>Yao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chang</forename><surname>Gong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lei</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Alibaba Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sheng</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Alibaba Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jingping</forename><surname>Bi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">CAUSALMTA: Eliminating the User Confounding Bias for Causal Multi-touch Attribution</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multi-touch attribution (MTA), aiming to estimate the contribution of each advertisement touchpoint in conversion journeys, is essential for budget allocation and automatically advertising. Existing methods first train a model to predict the conversion probability of the advertisement journeys with historical data and calculate the attribution of each touchpoint using counterfactual predictions. An assumption of these works is the conversion prediction model is unbiased, i.e., it can give accurate predictions on any randomly assigned journey, including both the factual and counterfactual ones. Nevertheless, this assumption does not always hold as the exposed advertisements are recommended according to user preferences. This confounding bias of users would lead to an out-of-distribution (OOD) problem in the counterfactual prediction and cause concept drift in attribution. In this paper, we define the causal MTA task and propose CAUSALMTA to eliminate the influence of user preferences. It systemically eliminates the confounding bias from both static and dynamic preferences to learn the conversion prediction model using historical data. We also provide a theoretical analysis to prove CAUSALMTA can learn an unbiased prediction model with sufficient data. Extensive experiments on both public datasets and the impression data in an e-commerce company show that CAUSALMTA not only achieves better prediction performance than the state-of-the-art method but also generates meaningful attribution credits across different advertising channels.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Online advertising platforms have been widely deployed to help advertisers launch their advertisements (ads) across multiple marketing channels, such as social media, feed stream, and paid search. During the usage, the ad exposure sequences and conversion feedbacks of all customers are collected. Multi-touch attribution, short for MTA, aims to estimate each ad touchpoint's relative contribution in user conversion journeys. The attribution results will shed light on the budget allocation and automatically advertising.</p><p>Nowadays, instead of attributing the ad touchpoints by heuristic rules <ref type="bibr" target="#b5">(Berman 2018)</ref>, data-driven methods (Shao and Li 2011; <ref type="bibr">Dalessandro et al. 2012;</ref><ref type="bibr" target="#b12">Ji and Wang 2017;</ref><ref type="bibr" target="#b14">Ren and etc. 2018;</ref><ref type="bibr" target="#b2">Arava et al. 2018;</ref><ref type="bibr" target="#b20">Yang, Dyer, and Wang</ref>  2020) which estimate the attribution credits according to the historical data have become the mainstream techniques. These methods learn a conversion prediction model with all observed historical data and then generate the counterfactual ad journeys by removing or replacing some touchpoints. Basing on some criteria, e.g., Shapley value (Shapley 1953), the attribution credits can be estimated by using the prediction results of these counterfactual journeys. One essential assumption of these methods is the conversion prediction model should be unbiased, which means the model can give fair predictions on any randomly assigned journeys, including the factual and counterfactual ones. Unfortunately, this assumption does not hold in online advertising. The ad exposures are recommended according to the user preferences, leading the learned conversion prediction model to be biased. The discrepancy between observed training data and counterfactual data causes an out-of-distribution (OOD) problem in counterfactual prediction, which would harm the fairness of attribution. We define the attribution of the ad journeys with an unbiased prediction model as causal MTA. Nevertheless, it is no trivial to eliminate the confounding bias of user preferences in MTA. The reasons are two folds: (1) Multiple confounders. The confounders in ad exposure generation consist of the static user attributes, such as genders, ages and education background, and dynamic features, e.g., previously viewed ads and favorite items. Both the static and dynamic features should be taken into account for unbiased causal MTA. Existing works either focus on the static settings <ref type="bibr" target="#b3">(Austin 2011;</ref><ref type="bibr" target="#b12">Johansson, Shalit, and Sontag 2016;</ref><ref type="bibr" target="#b12">Johansson et al. 2018;</ref><ref type="bibr" target="#b23">Zou et al. 2020)</ref>  propensity score matching method for deconfounding, or are dedicated to the dynamic confounders <ref type="bibr">(Lim 2018;</ref><ref type="bibr" target="#b6">Bica et al. 2020</ref>) learning an unbiased representation for prediction at each time step. All these works rely on the strong ignorability assumption <ref type="bibr" target="#b14">(Pearl 2009)</ref>, i.e., no hidden confounders. In their settings, the static and dynamic features are hidden confounders mutually that disable the usage. (2) Delay feedback. The conversion results are observed at the end of the journey. Moreover, there is no explicit feedback available at each touchpoint. Existing sequential deconfounding methods <ref type="bibr" target="#b19">(Xu, Xu, and Saria 2016;</ref><ref type="bibr" target="#b15">Roy, Lum, and Daniels 2017;</ref><ref type="bibr">Lim 2018;</ref><ref type="bibr" target="#b6">Bica et al. 2020</ref>) are designed for instant feedbacks, e.g., the blood pressure, which can be observed immediately after taking the hypotensor. CAMTA <ref type="bibr" target="#b12">(Kumar et al. 2020)</ref> is the most related method of our work. However, it takes the click action as the "pseudo" feedback at each touchpoint, which would involve other confounders. Above all, due to the peculiarities of advertising, there are no existed methods that can be used for unbiased causal MTA.</p><p>In this paper, we propose a novel method, namely CAUSALMTA, to mitigate the effect of user preferencesrelated confoundedness and achieve causal MTA. It learns an unbiased counterfactual prediction model which systemically eliminates the confounding bias from both static user attributes and dynamic features. One fundamental assumption of CAUSALMTA is that the influence of static user attributes and dynamic features are independent. This assumption is reasonable in online advertising because user attributes usually determine their item interests, and dynamic features determine how likely the users want to buy. As shown in Figure1, twenty years old students tend to be attracted by fancy phones and cosmetics, whereas the middle age guys usually like high cost-performance phones and anti-bald goods. Dynamic features, such as previously visited ads and staying time, reflect the purchase intention. The main contributions can be summarized as follows:</p><p>• We decomposed the confounding bias of user preferences into static user attributes and dynamic features, and defined the causal MTA problem.</p><p>• We propose the first method CAUSALMTA for causal MTA, which is provable for eliminating the confounding bias of user preferences in counterfactual prediction.</p><p>• Experiments on both opensource datasets and real-world impressing data of mobile phones shops from an ecommerce company show the superior of CAUSALMTA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>Data-driven multi-touch attribution. Previously, marketers have applied simple rules, e.g., the last touch, to attribute the influence of touched ads <ref type="bibr" target="#b5">(Berman 2018)</ref>, which either ignore the effects of other channels or neglect the channel difference. To overcome these drawbacks, researchers proposed data-driven attribution methods. The data-driven MTA model was first proposed in (Shao and Li 2011), and has been combined with survival analysis <ref type="bibr" target="#b22">(Zhang, Wei, and Ren 2014)</ref> and hazard rate <ref type="bibr" target="#b12">(Ji and Wang 2017)</ref> to reflect the influence of ad exposure. However, the data-driven methods mentioned above neglect the customers' features and cannot directly allocate personalized attribution. Besides, the temporal dependency and dynamic interaction between channels need to be modeled. Recently, many DNN-based data-driven MTA methods have been proposed to address the issues, such as channel interaction, time dependency, user characteristics. Some literature <ref type="bibr" target="#b2">(Arava et al. 2018;</ref><ref type="bibr" target="#b14">Ren and etc. 2018;</ref><ref type="bibr">Du and etc. 2019;</ref><ref type="bibr" target="#b12">Kumar et al. 2020;</ref><ref type="bibr" target="#b20">Yang, Dyer, and Wang 2020)</ref>   <ref type="bibr">(Dalessandro et al. 2012)</ref>, the calculation of attribution credits is actually based on counterfactual estimation <ref type="bibr" target="#b22">(Zhang, Wei, and Ren 2014;</ref><ref type="bibr">Du and etc. 2019;</ref><ref type="bibr" target="#b18">Singal and etc. 2019;</ref><ref type="bibr" target="#b17">Shender et al. 2020)</ref>. A limitation of the models mentioned above is the lack of exogenous variation in user exposure to advertising, which hazards the reliability of the attribution results as the training data of the counterfactual predictor is biased by confounders. Albeit extant papers <ref type="bibr" target="#b16">(Sahni 2015;</ref><ref type="bibr" target="#b4">Barajas et al. 2016;</ref><ref type="bibr" target="#b13">Nair et al. 2017;</ref><ref type="bibr" target="#b21">Zantedeschi, Feit, and Bradlow 2017)</ref> mitigate the issue with full or quasi-randomization, the cost and complexity of such randomization restrict the number of users and ad-types. The idea of calibrating the conversion prediction model in MTA by removing confounding bias is inspired by works in counterfactual prediction. There is a large number of methods for counterfactual prediction using observational data in the static setting, involving utilizing propensity score matching <ref type="bibr" target="#b3">(Austin 2011)</ref>, learning unbiased representation for prediction <ref type="bibr" target="#b12">(Johansson, Shalit, and Sontag 2016;</ref><ref type="bibr" target="#b12">Johansson et al. 2018;</ref><ref type="bibr" target="#b23">Zou et al. 2020)</ref>, conducting propensity-aware hyperparameter tuning <ref type="bibr">(Alaa and</ref><ref type="bibr">van der Schaar 2017, 2018)</ref>. For estimating the effects of time-varying treatments in the area such as epidemiology where the treatments have instant feedback, many approaches <ref type="bibr" target="#b19">(Xu, Xu, and Saria 2016;</ref><ref type="bibr" target="#b15">Roy, Lum, and Daniels 2017;</ref><ref type="bibr">Lim 2018;</ref><ref type="bibr" target="#b6">Bica et al. 2020</ref>) addressing the longitudinal setting are proposed. Because of the gap between the longitudinal data in epidemiology and ad journeys in MTA, those methods cannot be directly used in our task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preliminary</head><p>Problem Definition. We consider an ad exposure dataset D which consists of N conversion journeys of U users. Each journey can be formulated as a triplet, i.e., (u i , J i , y i ). u i stands for the static user attributes, which is unlikely to be changed during the user conversion journey. J i is a sequence of touchpoints, i.e., {p i t } T i t=1 . Each touchpoint p i t = (c i t , f i t ) contains a channel index c i t and a feature vector z i t . Specifically, c i t ∈ {c 1 , ..., c k , ..., c K } indicates the exposed channels, where K is the number of ad channels. The feature vector f i t includes the dynamic side information of this touch-   </p><formula xml:id="formula_0">Encoder Decoder &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " d F 4 O z J J M n M p u I B r D V G 3 O V b p D z 1 A = " &gt; A A A B 6 n i c b V D L S g N B E O y N r x h f U Y 9 e B o O Q U 9 i V o B 4 D X j x G N A 9 I l j A 7 m U 2 G z M w u 8 x D C k k / w 4 k E R r 3 6 R N / / G S b I H T S x o K K q 6 6 e 6 K U s 6 0 8 f 1 v r 7 C x u b W 9 U 9 w t 7 e 0 f H B 6 V j 0 / a O r G K 0 B Z J e K K 6 E d a U M 0 l b h h l O u 6 m i W E S c d q L J 7 d z v P F G l W S I f z T S l o c A j y W J G s H H S Q 1 / Y Q b n i 1 / w F 0 D o J c l K B H M 1 B + a s / T I g V V B r C s d a 9 w E 9 N m G F l G O F 0 V u p b T V N M J n h E e 4 5 K L K g O s 8 W p M 3 T h l C G K E + V K G r R Q f 0 9 k W G g 9 F Z H r F N i M 9 a o 3 F / / z e t b E N 2 H G Z G o N l W S 5 K L Y c m Q T N / 0 Z D p i g x f O o I J o q 5 W x E Z Y 4 W J c e m U X A j B 6 s v r p H 1 Z C 6 5 q 9 f t 6 p V H N 4 y j C G Z x D F Q K 4 h g b c Q R N a Q G A E z / A K b x 7 3 X</formula><formula xml:id="formula_1">I 6 V C I Q j K K V 7 r v I H 9 E P 0 q d p v 1 h y K + 4 c Z J V 4 G S l B h n q / + N U d R C w J u U I m q T E d z 4 2 x l 1 K N g k k + L X Q T w 2 P K x n T I O 5 Y q G n L T S + c X T 8 m Z V Q Y k i L Q t h W S u / p 5 I a W j M J P R t Z 0 h x Z J a 9 m f i f 1 0 k w u O q l Q s U J c s U W i 4 J E E o z I 7 H 0 y E J o z l B N L K N P C 3 k r Y i G r K 0 I Z U s C F 4 y y + v k u Z 5 x b u o V G + r p V o 5 i y M P J 3 A K Z f D g E m p w A 3 V o A A M F z / A</formula><formula xml:id="formula_2">U i I Q j K K V H n r I n 9 A P 0 v p s U C y 5 F X c B s k 6 8 j J Q g Q 2 N Q / O o N I 5 a E X C G T 1 J i u 5 8 b Y T 6 l G w S S f F X q J 4 T F l E z r i X U s V D b n p p 4 u L Z + T C K k M S R N q W Q r J Q f 0 + k N D R m G v q 2 M 6 Q 4 N q v e X P z P 6 y Y Y 3 P R T o e I E u W L L R U E i C U Z k / j 4 Z C s 0 Z y q k l l G l h b y V s T D V l a E M q 2 B C 8 1 Z f X S e u y 4 l 1 V q n f V U q 2 c x Z G H M z i H M n h w D T W 4 h Q Y 0 g Y G C Z 3 i F N</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domain Classifier</head><p>User Static Attributes &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W m 9 9 h l E q J q 8 S i B j K 7 F Z M + Y P E / 6 4 = " &gt; A A A B 8 X i c b V B N S 8 N A E N 3 U r 1 q / q h 6 9 L B a h p 5 K I q M e C F 4 8 V 7 A e 2 o W y 2 k 3 b p Z h N 2 J 2 I J / R d e P C j i 1 X / j z X / j t s 1 B W x 8 </p><formula xml:id="formula_3">M P N 6 b Y W Z e k E h h 0 H W / n c L a + s b m V n G 7 t L O 7 t 3 9 Q P j x q m T j V H J o 8 l r H u B M y A F A q a K F B C J 9 H A o k B C O x j f z P z 2 I 2 g j Y n W P k w T 8 i A 2 V C A V n a K W H H s I T B m G W T v v l i l t z 5 6 C r x M t J h e R o 9 M t f v U H M 0 w g U c s m M 6 X p u g n 7 G N A o u Y V r q p Q Y S x s d s C F 1 L F Y v A + N n 8 4 i k 9 s 8 q A h r G 2 p Z D O 1 d 8 T G Y u M m U S B</formula><formula xml:id="formula_4">L f + Y + Q 1 t z j F 0 b h m + V P x f S H w = " &gt; A A A C D H i c b V D L S s N A F J 3 U V 6 2 v q k s 3 g 0 W o I C W R o i 4 L b l x J B f u A J p T J d N I O n T y Y u R F L y A e 4 8 V f c u F D E r R / g z r 9 x 0 k b Q 1 g M D h 3 P O Z e 4 9 b i S 4 A t P 8 M g p L y y u r a 8 X 1 0 s b m 1 v Z O e X e v r c J Y U t a i o Q h l 1 y W K C R 6 w F n A Q r B t J R n x X s I 4 7 v s z 8 z h 2 T i o f B L U w i 5 v h k G H C P U w J a 6 p c r t k 9 g R I l I r t O q D e w e X C 8 x 0 x P 8 w 6 3 0 W K f M m j k F X i R W T i o o R 7 N f / r Q H I Y 1 9 F g A V R K m e Z U b g J E Q C p 4 K l J T t W L C J 0 T I a s p 2 l A f K a c Z H p M i o + 0 M s B e K P U L A E / V 3 x M J 8 Z W a + K 5 O Z q u r e S 8 T / / N 6 M X g X T s K D K A Y W 0 N l H X i w w h D h r B g + 4 Z B T E R B N C J d e 7 Y j o i k l D Q / Z V 0 C d b 8 y Y u k f V q z z m r 1 m 3 q l U c 3 r K K I D d I i q y E L n q I G u U B O 1 E E U P 6 A m 9 o F f j 0 X g 2 3 o z 3 W b R g 5 D P 7 6 A + M j 2 + H g J s 0 &lt; / l a t e x i t &gt; N (0, 1)</formula><p>Density Ratio Estimation weights &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " R n j j f p H </p><formula xml:id="formula_5">/ T O R k b W b P j i x 4 K 3 B U j / Q = " &gt; A A A C B 3 i c b V D L S s N A F J 3 4 r P V V d S n I Y B G 6 K o k U d S M U 3 L i S C v Y B T Q 2 T 6 a Q d O n k w c 6 O W I T s 3 / o o b F 4 q 4 9 R f c + T c m b R b a e u D C 4 Z x 7 u f c e N x J c g W l + G w u L S 8 s r q 4 W 1 4 v r G 5 t Z 2 a W e 3 p c J Y U t a k o Q h l x y W K C R 6 w J n A Q r B N J R n x X s L Y 7 u s j 8 9 h 2 T i o f B D Y w j 1 v P J I O A e p w R S y S k d 2 F r b w B 7 A 9 f R 9 k j g c 2 4 m j + b m V 3 O q r p O i U y m b V n A D P E y s n Z Z S j 4 Z S + 7 H 5 I Y 5 8 F Q A V R q m u Z E f Q 0 k c C p Y E n R j h W L C B 2 R A e u m N C A + U z 0 9 + S P B R 6 n S x 1 4 o 0 w o A T 9 T f E 5 r 4 S o 1 9 N + 3 0 C Q z V r J e J / 3 n d G L y z n u Z B F A M L 6 H S R F w s M I c 5 C w X 0 u G Q U x T g m h k q e 3 Y j o k k l B I o 8 t C s G Z f n i e t 4 6 p 1 U q 1 d 1 8 r 1 S h 5 H A e 2 j Q 1 R B F j p F d X S J G q i J K H p E z + g V v R l P x o v x b n x M W x e M f G Y P / Y H x + Q N g 8 p m K &lt; / l a t e x i t &gt; {w i } N i=1 Ad Journey &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " l C Z 1 J r p n y l / b 2 0 6 y f 4 x 5 Q c n m F W 0 = " &gt; A A A B 8 X i c b V D L S g N B E J y N r x h f U Y 9 e B o O Q U 9 i V o B 4 D X s R T B P P A J I T Z S W 8 y Z H Z 2 m e k V w 5 K / 8 O J B E a / + j T f / x k m y B 0 0 s a C i q u u n u 8 m M p D L r u t 5 N b W 9 / Y 3 M p v F 3 Z 2 9 / Y P i o d H T R M l m k O D R z L S b Z 8 Z k E J B A w V K a M c a W O h L a P n j 6 5 n f e g R t R K T u c R J D L 2 R D J Q L B G V r p o Y v w h H 6 Q 3 k 7 7 x Z J b c e e g q 8 T L S I l k q P e L X 9 1 B x J M Q F H L J j O l 4 b o y 9 l G k U X M K 0 0 E 0 M x I y P 2 R A 6 l i o W g u m l 8 4 u n 9 M w q A x p E 2 p Z C O l d / T 6 Q s N G Y S + r Y z Z D g y y 9 5 M / M / r J B h c 9 V K h 4 g R B 8 c W i I J E U I z p 7 n w 6 E B o 5 y Y g n j W t h b K R 8 x z T j a k A o 2 B G / 5 5 V X S P K 9 4 F 5 X q X b V U K 2 d x 5 M k J O S V l 4 p F L U i M 3 p E 4 a h B N F n s k r e X O M 8 + K 8 O x + L 1 p y T z R y T P 3 A + f w D c A 5 D 4 &lt; / l a t e x i t &gt; J … &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " t U B K n D D F v A t / Z 3 Q Q + / N e d I d Y T R 4 = " &gt; A A A B 8 3 i c b V B N S 8 N A E N 3 U r 1 q / q h 6 9 L B a h p 5 J I U Y 8 F L x 4 r 2 A 9 o S t l s J + 3 S z S b s T s Q S + j e 8 e F D E q 3 / G m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S N n G q O b R 4 L G P d D Z g B K R S 0 U K C E b q K B R Y G E T j C 5 n f u d R 9 B G x O o B p w n 0 I z Z S I h S c o Z V 8 H + E J g z D j s 4 E 7 K F f c m r s A X S d e T i o k R 3 N Q / v K H M U 8 j U M g l M 6 b n u Q n 2 M 6 Z R c A m z k p 8 a S B i f s B H 0 L F U s A t P P F j f P 6 I V V h j S M t S 2 F d K H + n s h Y Z M w 0 C m x n x H B s V r 2 5 + J / X S z G 8 6 W d C J S m C 4 s t F Y S o p x n Q e A B 0 K D R z l 1 B L G t b C 3 U j 5 m m n G 0 M Z V s C N 7 q y + u k f V n z r m r 1 + 3 q l U c 3 j K J I z c k 6 q x C P X p E H u S J O 0 C C c J e S a v 5 M 1 J n R f n 3 f l Y t h a c f O a U / I H z + Q M t r 5 G 0 &lt; / l a t e x i t &gt;</formula><formula xml:id="formula_6">C o f H z S N n G q O b R 4 L G P d D Z g B K R S 0 U K C E b q K B R Y G E T j C 5 n f u d R 9 B G x O o B p w n 0 I z Z S I h S c o Z V 8 H + E J g z A L Z w N v U K 6 4 N X c B u k 6 8 n F R I j u a g / O U P Y 5 5 G o J B L Z k z P c x P s Z 0 y j 4 B J m J T 8 1 k D A + Y S P o W a p Y B K a f L W 6 e 0 Q u r D G k Y a 1 s K 6 U L 9 P Z G x y J h p F N j O i O H Y r H p z 8 T + v l 2 J 4 0 8 + E S l I E x Z e L w l R S j O k 8 A D o U G j j K q S W M a 2 F v p X z M N O N o Y y r Z E L z V l 9 d J + 7 L m X d X q 9 / V K o 5 r H U S R n 5 J x U i U e u S Y P c k S Z p E U 4 S 8 k x e y Z u T O i / O u / O x b C 0 4 + c w p + Q P n 8 w c z y J G 4 &lt; / l a t e x i t &gt; f 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P I N w g L 0 Q o p Z 1 h G O q B t y C R h j I N G Q = " &gt; A A A B 8 3 i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S L 0 V J J S 1 G P B i 8 c K 9 g O a U j b b T b t 0 s w m 7 E 7 G E / g 0 v H h T x 6 p / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K Q w 6 L r f z s b m 1 v b O b m G v u H 9 w e H R c O j l t m z j V j L d Y L G P d D a j h U i j e Q o G S d x P N a R R I 3 g k m t 3 O / 8 8 i 1 E b F 6 w G n C + x E d K R E K R t F K v o / 8 C Y M w C 2 e D 2 q B U d q v u A m S d e D k p Q 4 7 m o P T l D 2 O W R l w h k 9 S Y n u c m 2 M + o R s E k n x X 9 1 P C E s g k d 8 Z 6 l i k b c 9 L P F z T N y a Z U h C W N t S y F Z q L 8 n M h o Z M 4 0 C 2 x l R H J t V b y 7 + 5 / V S D G / 6 m V B J i l y x 5 a I w l Q R j M g + A D I X m D O X U E s q 0 s L c S N q a a M r Q x F W 0 I 3 u r L 6 6 R d q 3 p X 1 f p 9 v d y o 5 H E U 4 B w u o A I e X E M D 7 q A J L W C Q w D O 8 w p u T O i / O u / O x b N 1 w 8 p k z + A P n 8 w c 1 T J G 5 &lt; / l a t e x i t &gt; f 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 1 R X t + k M X p O w W 8 5 l F a 1 k a 8 h p c Z 1 E = " &gt; A A A B 8 3 i c b V B N S 8 N A E N 3 U r 1 q / q h 6 9 L B a h p 5 J I U Y 8 F L x 4 r 2 A 9 o S t l s J + 3 S z S b s T s Q S + j e 8 e F D E q 3 / G m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S N n G q O b R 4 L G P d D Z g B K R S 0 U K C E b q K B R Y G E T j C 5 n f u d R 9 B G x O o B p w n 0 I z Z S I h S c o Z V 8 H + E J g z D j s 4 E 3 K F f c m r s A X S d e T i o k R 3 N Q / v K H M U 8 j U M g l M 6 b n u Q n 2 M 6 Z R c A m z k p 8 a S B i f s B H 0 L F U s A t P P F j f P 6 I V V h j S M t S 2 F d K H + n s h Y Z M w 0 C m x n x H B s V r 2 5 + J / X S z G 8 6 W d C J S m C 4 s t F Y S o p x n Q e A B 0 K D R z l 1 B L G t b C 3 U j 5 m m n G 0 M Z V s C N 7 q y + u k f V n z r m r 1 + 3 q l U c 3 j K J I z c k 6 q x C P X p E H u S J O 0 C C c J e S a v 5 M 1 J n R f n 3 f l Y t h a c f O a U / I H z + Q M v M 5 G 1 &lt; / l a t e x i t &gt; c 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y K Y p q 7 0 o k r c S f H I r L J F J W R s R 5 M = " &gt; A A A B + X i c b V B N S 8 N A E N 3 4 W e t X 1 K O X x S L 0 Y k m k q M e C F 4 8 V + g V t C J v t p l 2 6 2 Y T d S b G E / B M v H h T x 6 j / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X 4 D j f 1 s b m 1 v b O b m m v v H 9 w e H R s n 5 x 2 d J w q y t o 0 F r H q B U Q z w S V r A w f B e o l i J A o E 6 w a T + 7 n f n T K l e S x b M E u Y F 5 G R 5 C G n B I z k 2 / Y A 2 B M E Y U Z z P 2 t d u b l v V 5 y a s w B e J 2 5 B K q h A 0 7 e / B s O Y p h G T Q A X R u u 8 6 C X g Z U c C p Y H l 5 k G q W E D o h I 9 Y 3 V J K I a S 9 b X J 7 j S 6 M M c R g r U x L w Q v 0 9 k Z F I 6 1 k U m M 6 I w F i v e n P x P 6 + f Q n j n Z V w m K T B J l 4 v C V G C I 8 T w G P O S K U R A z Q w h V 3 N y K 6 Z g o Q s G E V T Y h u K s v r 5 P O d c 2 9 q d U f 6 5 V G t Y i j h M 7 R B a o i F 9 2 i B n p A T d R G F E 3 R M 3 p F b 1 Z m v V j v 1 s e y d c M q Z s 7 Q H 1 i f P 4 y L k 4 c = &lt; / l a t e x i t &gt; c T 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " o q A g x L 6 H r v 8 x 7 K s n M K W Z S s 2 S E 5 Y = " &gt; A A A B 9 X i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 B I v Q U 0 l E 1 G P B i w c P F e w H t L F s t p t 2 6 W Y T d i d q C f k f X j w o 4 t X / 4 s 1 / 4 7 b N Q V s f D D z e m 2 F m n h 8 L r t F x v q 3 C y u r a + k Z x s 7 S 1 v b O 7 V 9 4 / a O k o U Z Q 1 a S Q i 1 f G J Z o J L 1 k S O g n V i x U j o C 9 b 2 x 1 d T v / 3 A l O a R v M N J z L y Q D C U P O C V o p P s e s i f 0 g z T I + u l N 1 i 9 X n J o z g 7 1 M 3 J x U I E e j X / 7 q D S K a h E w i F U T r r u v E 6 K V E I a e C Z a V e o l l M 6 J g M W d d Q S U K m v X R 2 d W a f G G V g B 5 E y J d G e q b 8 n U h J q P Q l 9 0 x k S H O l F b y r + 5 3 U T D C 6 9 l M s 4 Q S b p f F G Q C B s j e x q B P e C K U R Q T Q w h V 3 N x q 0 x F R h K I J q m R C c B d f X i a t 0 5 p 7 X j u 7 P a v U q 3 k c R T i C Y 6 i C C x d Q h 2 t o Q B M o K H i G V 3 i z H q 0 X 6 9 3 6 m L c W r H z m E P 7 A + v w B K T a S 3 w = = &lt; / l a t e x i t &gt; f L Causal RNN Predictor Gradient Reverse Gradient Reverse</formula><p>Gradient Reverse</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MLP MLP MLP</head><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " a i u L K c B t f 9 h G O 0 p j v I P P V z m i h q 0 = "  </p><formula xml:id="formula_7">&gt; A A A B / X i c b V D J S g N B E O 1 x j X E b l 5 u X w S D k F G Y k q M e A F 4 8 R z A L J O P R 0 a p I m P Q v d N c E 4 D P 6 K F w + K e P U / v P k 3 d p a D J j 4 o e L x X R V U 9 P x F c o W 1 / G y u r a + s b m 4 W t 4 v b O 7 t 6 + e X D Y V H E q G T R Y L G L Z 9 q k C w S N o I E c B 7 U Q C D X 0 B L X 9 4 P f F b I 5 C K x 9 E d j h N w Q 9 q P e M A Z R S 1 5 5 n E X 4 Q H 9 I G O 5 l z n 5 f S Z h l H t m y a 7 Y U 1 j L x J m T E p m j 7 p l f 3 V 7 M 0 h A i Z I I q 1 X H s B N 2 M S u R M Q F 7 s p g o S y o a 0 D x 1 N I x q C c r P p 9 b l 1 p p W e F c R S V 4 T W V P 0 9 k d F Q q X H o 6 8 6 Q 4 k A t e h P x P 6 + T Y n D l Z j x K U o S I z R Y F q b A w t i Z R W D 0 u g a E Y a 0 K Z 5 P p W i w 2 o p A x 1 Y E U d</formula><formula xml:id="formula_8">W + N U m G B J E S o = " &gt; A A A B / X i c b V D J S g N B E O 2 J W 4 x b X G 5 e B o O Q U 5 g J Q T 0 G v H i M Y B Z I x q G n U 5 M 0 6 V n o r g n G Y f B X v H h Q x K v / 4 c 2 / s b M c N P F B w e O 9 K q r q e b H g C i 3 r 2 8 i t r W 9 s b u W 3 C z u 7 e / s H x c O j l o o S y a D J I h H J j k c V C B 5 C E z k K 6 M Q S a O A J a H u j 6 6 n f H o N U P A r v c B K D E 9 B B y H 3 O K G r J L Z 7 0 E B 7 Q 8 1 O W u W k 1 u 0 8 l j D O 3 W L I q 1 g z m K r E X p E Q W a L j F r 1 4 / Y k k A I T J B l e r a V o x O S i V y J i A r 9 B I F M W U j O o C u p i E N Q D n p 7 P r M P N d K 3 / Q j q S t E c 6 b + n k h p o N Q k 8 H R n Q H G o l r 2 p + J / X T d C / c l I e x g l C y O a L / E S Y G J n T K M w + l 8 B Q T D S h T H J 9 q 8 m G V F K G O r C C D s F e f n m V t K o V + 6 J S u 6 2 V 6 u V F H H l y S s 5 I m d j k k t T J D W m Q J m H k k T y T V / J m P B k v x r v x M W / N G Y u Z Y / I H x u c P e / i V 0 g = = &lt; / l a t e x i t &gt; c rev 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " y 5 d Y z Z f u J d Y C o k E q O a w u n + V e s g E = " &gt; A A A B / X i c b V D J S g N B E O 2 J W 4 x b X G 5 e B o O Q U 5 i R o B 4 D X j x G y A b J O P R 0 a p I m P Q v d N c E 4 D P 6 K F w + K e P U / v P k 3 d p a D J j 4 o e L x X R V U 9 L x Z c o W V 9 G 7 m 1 9 Y 3 N r f x 2 Y W d 3 b / + g e H j U U l E i G T R Z J C L Z 8 a g C w U N o I k c B n V g C D T w B b W 9 0 M / X b Y 5 C K R 2 E D J z E 4 A R 2 E 3 O e M o p b c 4 k k P 4 Q E 9 P 2 W Z m z a y + 1 T C O H O L J a t i z W C u E n t B S m S B u l v 8 6 v U j l g Q Q I h N U q a 5 t x e i k V C J n A r J C L 1 E Q U z a i A + h q G t I A l J P O r s / M c 6 3 0 T T + S u k I 0 Z + r v i Z Q G S k 0 C T 3 c G F I d q 2 Z u K / 3 n d B P 1 r J + V h n C C E b L 7 I T 4 S J k T m N w u x z C Q z F R B P K J N e 3 m m x I J W W o A y v o E O z l l 1 d J 6 6 J i X 1 a q d 9 V S</formula><formula xml:id="formula_9">g J 4 n d g F q a E C b d f 8 G v o x T U M W A R V E q Y F t J e B k R A K n g u W V Y a p Y Q u i E j N h A 0 4 i E T D n Z 4 v Q c n 2 v F x 0 E s 9 Y s A L 9 T f i Y y E S s 1 C T 0 + G B M Z q 1 Z u L / 3 m D F I J r J + N R k g K L 6 H J R k A o M M Z 7 3 g H 0 u G Q U x 0 4 R Q y f W t m I 6 J J B R 0 W x V d g r 3 6 5 X X S v W j Y l 4 3 m X b P W q h d 1 l N E p O k N 1 Z K M r 1 E K 3 q I 0 6 i K I H 9 I x e 0 Z v x Z L w Y 7 8 b H c r R k F J k T 9 A f G 5 w 9 Q b Z S d &lt; / l a t e x i t &gt; v pred</formula><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 6 A i q y Y J P Q O J X 3 S + e S + 4 h c W N 1 1 A o = " &gt; A A A B 8 X i c b V B N S 8 N A E N 3 U r 1 q / q h 6 9 L B a h p 5 K I q M e C F 4 8 V 7 A e 2 o W y 2 k 3 b p Z h N 2 J 2 I J / R d e P C j i 1 X / j z X / j t s 1 B W x 8     point, e.g., advertising form and staying time. y i is a binary indicator that records whether the journey leads to a conversion event or not. The goal of MTA is to model the sequential pattern and assign the attribution credits to all the touchpoints p i t according to the whole information in D. Nevertheless, historical data in D often exhibits confounding bias due to user preferences, which could be a fatal challenge for estimating the attribution credits. The choice of the channel at a touch-point is likely to be influenced by multiple factors like user attributes and previously visited goods. Causal multi-touch attribution aims to estimate trustworthy attribution credits {p i t } T i t=1 of all touchpoints in J i . Method Overview. As shown in Figure <ref type="figure" target="#fig_13">2</ref>, CAUSALMTA is a novel model-agnostic framework consisting of two key modules, i.e., journey reweighting and causal conversion prediction, which mitigate the confounding bias of user static attributes and dynamic features respectively. In journey reweighting, we employ the Variational Recurrent Auto-encoders (VRAE) to learn the generation probabilities of pure channels journeys, and conduct user demographic-based density estimation to calculate the likelihoods of the channels being randomly assigned that is used for weights computation. For causal conversion prediction, CAUSALMTA utilizes RNNs to model the dynamic features of journeys. A gradient reverse layer is building upon the outputs of each time step to ensure the model is unable to predict the next ad channel. It derives balancing representation, which removes the association between dynamic features and the ad exposure. Basing on the learned weights of journey reweighting, the last hidden output is trained to estimate the conversion probability. After that, we can obtain an unbiased prediction model. Lastly, with the constructed counterfactual journeys, the attribution credits can be estimated under Shapley value measure.</p><formula xml:id="formula_10">M P N 6 b Y W Z e k E h h 0 H W / n c L a + s b m V n G 7 t L O 7 t 3 9 Q P j x q m T j V H J o 8 l r H u B M y A F A q a K F B C J 9 H A o k B C O x j f z P z 2 I 2 g j Y n W P k w T 8 i A 2 V C A V n a K W H H s I T B m E 2 m f b L F b f m z k F X i Z e T C</formula><formula xml:id="formula_11">U i I Q j K K V H n r I n 9 A P 0 v p s U C y 5 F X c B s k 6 8 j J Q g Q 2 N Q / O o N I 5 a E X C G T 1 J i u 5 8 b Y T 6 l G w S S f F X q J 4 T F l E z r i X U s V D b n p p 4 u L Z + T C K k M S R N q W Q r J Q f 0 + k N D R m G v q 2 M 6 Q 4 N q v e X P z P 6 y Y Y 3 P R T o e I E u W L L R U E i C U Z k / j 4 Z C s 0 Z y q k l l G l h b y V s T D V l a E M q 2 B C 8 1 Z f X S e u y 4 l 1 V q n f V U q 2 c x Z G H M z i H M n h w D T W 4 h Q Y 0 g Y G C Z 3 i F N</formula><formula xml:id="formula_12">m V v / + D w q H p 8 0 j U q 1 Z R 1 q B J K 9 0 N i m O C S d Y C D Y P 1 E M x K H g v X C 6 W 3 u 9 5 6 Y N l z J R 5 g l L I j J W P K I U w J W 8 g c x g Q k l I r u f D 6 s 1 t + E u g N e J V 5 A a K t A e V r 8 G I 0 X T m E m g g h j j e 2 4 C Q U Y 0 c C r Y v D J I D U s I n Z I x 8 y 2 V J G Y m y B a R 5 / j C K i M c K W 2 f B L x Q f 2 9 k J D Z m F o d 2 M o 9 o V r 1 c / M / z U 4 h u g o z L J A U m 6 f K j K B U Y F M 7 v x y O u G Q U x s 4 R Q z W 1 W T C d E E w q 2 p Y o t w V</formula><formula xml:id="formula_13">m V v / + D w q H p 8 0 j U q 1 Z R 1 q B J K 9 0 N i m O C S d Y C D Y P 1 E M x K H g v X C 6 W 3 u 9 5 6 Y N l z J R 5 g l L I j J W P K I U w J W 8 g c x g Q k l I r u f D 6 s 1 t + E u g N e J V 5 A a K t A e V r 8 G I 0 X T m E m g g h j j e 2 4 C Q U Y 0 c C r Y v D J I D U s I n Z I x 8 y 2 V J G Y m y B a R 5 / j C K i M c K W 2 f B L x Q f 2 9 k J D Z m F o d 2 M o 9 o V r 1 c / M / z U 4 h u g o z L J A U m 6 f K j K B U Y F M 7 v x y O u G Q U x s 4 R Q z W 1 W T C d E E w q 2 p Y o t w V</formula><formula xml:id="formula_14">V v L Q f E j O m R O C H e W l Q r j g 1 Z w G 8 T t y c V C B H c 1 D + 6 g 8 j m o R M G i q I 1 j 3 X i Y 2 X E m U 4 F W x e 6 i e a x Y R O y I j 1 L J U k Z N p L F 6 H n + M I q Q x x E y j 5 p 8 E L 9 v Z G S U O t Z 6 N v J L K N e 9 T L x P 6 + X m O D G S 7 m M E 8 M k X R 4 K E o F N h L M G 8 J A r R o 2 Y W U K o 4 j Y r p m O i C D W 2 p 6 w E d / X L 6 6 R 9 W X O v a v X 7 e q V R z e s o w h m c Q x V c u I Y G 3 E E T W k D h C Z 7 h F d 7 Q F L 2 g d / S x H C 2 g f O c U / g B 9 / g A Z o Z G W &lt; / l a t e x i t &gt; S Counterfactual Predictions &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " o v B Q R M + 1 e l a Q y O X k 6 C q v x L v y n d w = " &gt; A A A C B X i c b V D L S s N A F J 3 U V 6 2 v q E t d B I v Q V U m k q B u h 4 M Z l h b 6 g q W E y n b R D J w 9 m b s Q y Z O P G X 3 H j Q h G</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methodology</head><p>In this section, we first specify the journey reweighting and causal conversion prediction respectively. After that, the calculation of attribution credits is detailed. In the end, we pro-vide the theoretical analysis of CAUSALMTA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Journey Reweighting</head><p>To mitigate the bias of static user attributes, the journey reweighting module takes pure channel sequences in D as the input and estimates the sample weights of the prediction model according to how likely the journey be generated randomly. It consists of two procedures, i.e., generation model for channel sequences and weights estimation of journeys.</p><p>Generation Model for Channel Sequences. We utilize VRAE (Variational Recurrent Auto-encoders) <ref type="bibr" target="#b10">(Fabius, van Amersfoort, and Kingma 2015)</ref> to model the generation of channel sequences. When training data is large enough, the distribution of pure channel sequences tends to be random without considering user preferences. In this setting, the learned VRAE is capable of generating unbiased predictions of observed channel sequences.</p><p>For each ad journey (u, J, y) in D, we only concern with the channel information in this procedure and extract the pure channel sequence C = {c t } T t=1 . Taking C as the input, CAUSALMTA employs the channel embedding affiliated with LSTM as the encoder and utilizes the final hidden state to generate the distribution over latent representation:</p><formula xml:id="formula_15">{h t } T t=1 = LSTM enc (C, h 0 ) µ z = W µ h T + b µ log(σ z ) = W σ h T + b σ</formula><p>where h 0 is the initial hidden state of the encoder. Leveraging the reparametrization trick, we sample a vector z from the distribution to initialize the hidden state of the decoder:</p><formula xml:id="formula_16">h 0 = tanh(W T z z + b z ) {h t } T t=1 = LSTM dec (C out , h 0 ) c t = sof tmax(W o h t + b o )</formula><p>where h 0 is the initial hidden state of the decoder; C out is the feed previous input which takes the output of previous step as the input; c t is the decoded channel sequence.</p><p>The loss function is composed of two parts: 1) the reconstruction loss which is defined as the cross-entropy between c t and c t . 2) the KL divergence between the posterior and prior distribution over the latent variable:</p><formula xml:id="formula_17">L w = α N i=1 T i t=1 CE(c t , c t ) + βD KL (q φ (z)||p θ (z)) (1)</formula><p>where p θ (z) is the prior distribution usually assumed to be a standard normal distribution N (0, I); q φ (z|c i ) is the posterior approximation (N (µ i , (σ i ) 2 ); α and β are hyperparameters that control the importance each parts.</p><p>Weights Estimation for Ad Journeys. To eliminate the bias of user static features, we estimate the weights of observed journeys. The journeys approximating to randomly assigned have higher weights in conversion prediction training than those are severely affected by user preferences. Formally, the learned weights W T (u, C) should be subject to W T (u, C) = p(C)/p(C|u) <ref type="bibr" target="#b11">(Fong et al. 2018;</ref><ref type="bibr" target="#b23">Zou et al. 2020)</ref>. When we learn a variational distribution q φ (z|c), the variational sample weights can be computed as follows:</p><formula xml:id="formula_18">w i = W T (u i , c i ) = {E z∼q φ (z|c i ) [ 1 W z (u i , z) ]} −1 (2)</formula><p>where W z (u, z) can be viewed as the density ratio estimation to decorrelate u and z for points in space × Z. The detailed proof can be found in the appendix.</p><p>In CAUSALMTA, we design a binary domain classifier to help estimate W Z (u, z). Training data of the classifier is generated cooperating with the encoder of VRAE. We label static user attributes with real latent representation {(u i , z)} 1≤i≤N , z ∼ q φ (z|c i ) as positive ones, whereas samples with latent representationt sampled from standard normal distribution {(u i , z)} 1≤i≤N , z ∼ p θ (z) as negative ones. We first embed the user attributes into latent vectors and train a domain classifier to fit these samples:</p><formula xml:id="formula_19">e u = Embedding(u) x = concat(e u , z) p θ d (L|u, z) = sigmoid(MLP(x))</formula><p>Now that we have p(L = 0) = p(L = 1), the density ratio estimation W z (u, z) can be conducted as follows:</p><formula xml:id="formula_20">W z (u, z) = p(u, z|L = 0) p(u, z|L = 1) = p(L = 0|u, z) p(L = 1|u, z)<label>(3)</label></formula><p>Using this formula, we can obtain the weights of all journeys, i.e., {w i } N i=1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Causal Conversion Prediction</head><p>After the generation of sample weights, CAUSALMTA utilizes them to train a trustworthy conversion prediction model. Besides the static attributes, the biases of prediction are also caused by dynamic user features. To mitigate them, we borrow the idea from CRN <ref type="bibr" target="#b6">(Bica et al. 2020</ref>) and involve a gradient reverse layer to learn balancing representation. Due to the delay feedback problem, we refine the structure of CRN to make it suitable for MTA.</p><p>Formally, we first reorganize the dataset. For each journey (u, J, y), we adopt one step offset on the channel sequence and fill the blank position with a unified placeholder, i.e., C + = {c 0 , c t } T −1 t=1 . CAUSALMTA takes C + along with other dynamic features F = {f t } T t=1 as the input and employs LSTM with the attention mechanism to obtain the trustworthy prediction:</p><formula xml:id="formula_21">e u , e C+ , e F = Embedding(u, C + , F) v in = concat(e C+ , e F ) {out t } T t=1 = LSTM pred (v in , h 0</formula><p>) where e C+ , e F , v in are the sequences of latent vectors. Once the output vectors are generated, we adopt them for two parallel processes. One for eliminating the bias of dynamic features, and the other for conversion prediction.</p><formula xml:id="formula_22">{v rev t } T t=1 = MLP(GRL({out t } T t=1 )) {c rev t } T t=1 = sof tmax({v rev t } T t=1 ) v attn = Attention(out T , {out t } T t=1 ) v pred = sof tmax(MLP(v attn ))</formula><p>where GRL is the gradient reverse layer that ensures out t can not predict c t . The loss function of causal conversion prediction consists of two parts, i.e., reverse channel prediction and conversion prediction:</p><formula xml:id="formula_23">L p = γ N i=1 T i t=1 CE(c rev t , c t ) + δ N i=1 w i • CE(v i pred , y i ) (4)</formula><p>where CE is the cross-entropy loss; γ and δ are hyperparameters; w i is the learned journey weights. With the welltrained conversion prediction model, we can calculate the attribution credits of each touchpoint by constructing some counterfactual journeys.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attribution Credits Calculation</head><p>CAUSALMTA computes Shapley values (Shapley 1953) for ad credits allocation. Based on assessing the marginal contribution of each player in the game, the Shapley value method is a general credit distribution method, and it has been widely used in MTA <ref type="bibr" target="#b18">(Singal and etc. 2019;</ref><ref type="bibr" target="#b20">Yang, Dyer, and Wang 2020)</ref> due to its advantage of having an axiomatic foundation and catering to fairness consideration.</p><p>Formally, let J i \{p i t } denote the counterfactual ad journey by removing touchpoint p i t . S can be viewed as a subsequence of the counterfactual ad journey J i \{p i t }. If we denote the result of causal conversion prediction for channel sequence J i as p(J i ), the Shapley values for ad exposure {c i t } can be defined as</p><formula xml:id="formula_24">SV i t = S⊆J i \{p i t } |S|!(|J i |−|S|−1)! |J i |! [p(S ∪ {p i t }) − p(S)</formula><p>] where |C i |, |S| are the cardinalities of these sets. If SV i t is negative, we set it zero. Then we normalize all incremental scores for each ad exposure as follows,</p><formula xml:id="formula_25">a i t = σ(SV i t )/ T i t=1 σ(SV i t )<label>(5)</label></formula><p>Algorithm 1: Learning procedure of CAUSALMTA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input:</head><p>The ad exposure dataset D, i.e., {(u i , J i , y i )} N i=1 ; Output:</p><p>Attribution credits {α i t } Ti t=1 for touchpoints {a i t } T i t=1 . 1: # Generation model for channel sequences 2: for each journey (u i , J i , y i ) in D do 3:</p><p>Evaluate L w according to Eq.( <ref type="formula">1</ref>) and update the parameters of VRAE model. 4: end for 5: # Weights estimation for ad journeys 6: for each ad journey (u i , J i , y i ) in D do 7:</p><p>Generate latent representation for positive and negative samples respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8:</head><p>Optimize the parameters of domain classifier. 9: end for 10: Conduct density ratio estimation and calculate sample weights w i according to Eq.( <ref type="formula">2</ref>) and Eq.( <ref type="formula" target="#formula_20">3</ref>). 11: # Causal conversion prediction 12: for each ad journey (u i , J i , y i ) in D do 13:</p><p>Evaluate L p according to Eq.( <ref type="formula">4</ref>) and update the parameters of conversion prediction model. 14: end for 15: # Calculation of Attribution Credits 16: for each ad journey (u i , J i , y i ) in D do 17:</p><p>for each touchpoint c i t in channel sequence C i do 18:</p><p>Compute SV i t according to its definition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>19:</head><p>Calculate attribution credits a i t according to Eq.( <ref type="formula" target="#formula_25">5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>20:</head><p>end for 21: end for 22:</p><formula xml:id="formula_26">return {{a i t } Ti t=1 } N i=1</formula><p>where σ(x) = max(0, x) and a i t are the attribution credits of the corresponding ad exposures. The pseudo-code of CAUSALMTA is shown in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theoretical Analysis of CAUSALMTA</head><p>Under the assumption of independence, we can decompose the overall confounding bias B into the bias introduced by user static attributes B u and the bias introduced by dynamic user features B F , i.e., B = B u + B F . CAUSALMTA aims to obtain an unbiased prediction model and achieve B = 0.</p><p>We prove that the confounding bias from static user attributes B u can be mitigated by estimating sample weights w i for ad journeys. Formally, let E cf denote the counterfactual prediction error, which is the target to be minimized. Unfortunately, E cf can not be directly measured on the observational dataset. We can derive the upper bound of E cf , which is given by B</p><formula xml:id="formula_27">u = E cf − E w f ≤ IP M G (W T (u, C)p(u, C), p(u)p(C))</formula><p>where E w f is the prediction error on the re-weighted data and IP M denotes Integral Probability Metric. When W T (u, C) = p(C) p(C|u) , the equation E cf = E w f can be proved. More details of the proof are available in the appendix.</p><p>In dynamic settings, B F equals zero if we can prove that the learned representation removes the association between dynamic features and the ad exposure. We build </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment</head><p>In this section, we evaluate the performance of CAUSALMTA and answer the following questions:</p><p>• Q1: Does CAUSALMTA perform better than the stateof-the-art MTA methods on conversion prediction? • Q2: What are the capabilities of the journey reweighting module and the causal conversion prediction module? • Q3: Does CAUSALMTA work well on real ad impression dataset?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Settings</head><p>A conversion prediction task is employed to examine the performance of CAUSALMTA. In this section, we briefly introduce the data description, evaluation metrics, compared baselines, and hyperparameter settings. More details of this part can be found in the appendix. Data Descriptions. The performance of CAUSALMTA is evaluated on two datasets, i.e., Criteo and Ad Impression of an E-commerce company. Criteo<ref type="foot" target="#foot_0">1</ref> is a public dataset on ad bidding and be widely used in MTA <ref type="bibr" target="#b9">(Diemert et al. 2017;</ref><ref type="bibr" target="#b14">Ren and etc. 2018;</ref><ref type="bibr" target="#b12">Kumar et al. 2020)</ref>. Following the same experimental setting of CAMTA(Kumar et al. 2020), we choose top-10 highly exposed channels and journeys containing more than 3 touchpoints. Ad Impression of an E-commerce Company contains the ad impression data of mobile phone shops in 30 days. These touchpoints are categorized into 40 channels, including interact, feed, display, search, live show, etc.</p><p>Evaluation Metrics. For conversion prediction, we evaluate the performance in terms of log-loss, AUC. For fairness, the log-loss only contains the conversion prediction additional confounding bias. Moreover, CAMTA does not consider the difference between static and dynamic confounders, which would also harm the performance. One interesting phenomenon is CAUSALMTA has a more stable confidence interval compared to other baselines. It indicates that the parameters in CAUSALMTA tend to converge to similar values with different initialization. To a certain extent, CAUSALMTA is more robust than other baselines.</p><p>Comparing the performance of different categories of methods, we can observe that SL methods are inferior to the other two categories. SL methods either use statistical laws or employ logistic regression to predict the conversion probability, which can not well model the conversion process. DL methods perform better than the SL methods but are also inferior to the CL methods. It proves that the deep learning techniques are more suitable for conversion prediction due to their large parameter space and high ability to model complex tasks. However, these methods have poor performance compared to the CL methods. It is because deep learning methods directly use the observed data to train the prediction models, which are incapable of handling confounding bias and would suffer from the out-of-distribution problem. CL methods outperform other baselines with a large margin, which demonstrates the prediction performance highly increased by eliminating the confounding bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Studies</head><p>To explore the effectiveness of the journey reweighting and causal conversion prediction, we compare CAUSALMTA with two ablation methods, i.e., CM-RW and CM-CAUSAL, which remove the reweighting procedure and the gradient reverse layer respectively. We first show the intermediate results of journey reweighting. The reconstruction accuracy of VRAE and the classification accuracy of the domain classifier directly influence the performance of CAUSALMTA. As shown in Figure <ref type="figure" target="#fig_14">3</ref>, the reconstruction accuracy is approximate to 98%, and the classification accuracy is approximate to 82%, which indicates that the VRAE and domain classifier are well trained, and the results of journey reweighting are significant. We also witness the reconstruction accuracy fluctuates at a high level as KL divergence dominates the training loss when the cross-entropy loss is small enough. We summarize the metrics of ablations in Table <ref type="table">2</ref> and illustrate the training procedure in Figure <ref type="figure">5</ref>. As shown, the AUCs of CM-RW and CM-CAUSAL are inferior to CAUSALMTA, which proves that both the journey reweighting and causal conversion prediction help improve the performance. By removing the journey reweighting model, the performance of CAUSALMTA decreases from 0.9659 to 0.9539. By removing the gradient reverse layer, the performance of CAUSALMTA decreases from 0.9659 to 0.9617. We can observe the improvement of gradient reverse layer(causal prediction) is more significant than journey reweighting, which indicates the confounding bias of dynamic feature are more obvious than the static user attributes. This result is consistent with our cognition. Moreover, as illustrated in Figure <ref type="figure">5</ref>, the convergence speed of CAUSALMTA is faster than CM-RW and CM-CAUSAL, which shows the superiority of CAUSALMTA in eliminating the confounding bias of user preferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Empirical Applications in an E-commerce Company</head><p>We evaluate the performance of CAUSALMTA on real applications in this section. In application, channel attributions of each shop are more meaningful to guide the budget allocation. We train the attribution models in the first 15 days and use the last data for testing. We choose all of its converted journeys in the test set for one specific shop and compute the mean credits of 40 channels. After that, we employ two experiments, i.e., attribution improvement and offline data replay, to evaluate the performance of CAUSALMTA.</p><p>Attribution Improvement. We compute the attribution credits of two representative cellphone shops utilizing CAUSALMTA and compare them with the credits calculated by an LSTM-based conversion prediction model. The comparison results are illustrated in Figure <ref type="figure">5</ref>. As shown, the credits of search channels on both shops are decreased, indicating that the estimated contribution of search ads is reduced after eliminating the confounding bias of user preferences. This is because user tends to search the goods before paying. The attributions of the search channel are usually overestimated, and CAUSALMTA can mitigate this kind of bias. For different shops, the improvements are consistent with its budget allocation. After examining the total budget on each channel, we found Shop 1 spent more money on Live and Shop 2 spent more money on Display, which coincides with our attribution result.  Offline Data Replay. In this experiment, we employ the attribution credits to guide the budget allocation. Based on the attribution credits, we first compute the return-oninvestment (ROI) of each channel and utilize the normalized weights of ROI as budget proportion (Ren and etc. 2018). Assuming that the total cost of the test set is cost t , we set the evaluation budgets as 1/2, 1/4, 1/8, 1/16 of cost t and replay the historical data to select journeys satisfying evaluation budgets. Table <ref type="table" target="#tab_3">3</ref> shows the comparison results of the profit in each evaluation budget. We can observe that the profit CAUSALMTA consistently outperforms the LSTM-based predictor on all evaluation budgets, which indicates that the attribution credits of CAUSALMTA reflect the causal relationships in advertising. It can be used to guide budget allocation and achieve better profit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this paper, we define the problem of causal MTA, which eliminates the confounding bias introduced by user preferences and assigns the attribution credits fairly over all touchpoints. To this end, we propose CAUSALMTA, which composes the confounding bias of user preferences into two independent parts, i.e., the static user attributes and the dynamic features. CAUSALMTA employs journey reweighting and causal conversion prediction to solve these two kinds of confounding bias respectively. We prove that CAUSALMTA is capable of generating unbiased conversion predictions of ad journey. Extensive experiments on the public dataset and real commercial data from an e-commerce company show that CAUSALMTA outperforms all the compared baselines and works well in the real-world application.</p><p>The target of the counterfactual prediction error to be minimized is</p><formula xml:id="formula_28">E cf = E U∼p(U) [E(U)].</formula><p>But in the observational dataset, the touch-points are assigned based on confounders, i.e., C ∼ p(C|U). Instead of directly using supervised learning, optimizing the prediction error on the re-weighted data</p><formula xml:id="formula_29">E w f = E U,C∼p(U,C) L f θp (U, C), y(U, C) W T (U, C)</formula><p>can lead to a more accuracy counterfactual prediction.</p><p>Assuming a family G of functions g : U × C → R, and we have L(f (U, C), y(U, C)) = l(U, C) ∈ G . We can therefore bridge the gap between the counterfactual loss and the re-weighted loss under observational data. where KL(•||•) is the KL divergence and JSD(•, ..., •) is the Jensen-Shannon Divergence <ref type="bibr" target="#b12">(Li et al. 2018;</ref><ref type="bibr" target="#b6">Bica et al. 2020)</ref> in the multi-distribution form. Because JSD(•, ..., •) is non-negative and equals zero when all distirbutions are equal and K logK is a constant, we have that p(v rev t |c 1 ) = ... = p(v rev t |c K ) by minimizing L rev .</p><formula xml:id="formula_30">E cf − E w f = U C p(U)p(C) − W T (U, C)p(U, C) • L f (U, C), y(U, C) dUdC ≤ U C p(U)p(C) − W T (U, C)p(U, C) • L f (U, C), y(U, C) dUdC ≤ sup g∈G U C p(U)p(C) − W T (U, C)p(U, C) • g(U, C)dUdC =IP M G W T (U, C)p(U, C), p(U)p(C) When W T (U, C) = p(C) p(C|U) , we have: IP M G (W T (U, C)p(U, C), p(U)p(C)) = 0 E w f = E cf Proof of</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>Details of data preprocessing. The attribution modeling for bidding dataset published by Criteo company is widely deployed in the research of modeling user behavior and ad attribution <ref type="bibr" target="#b9">(Diemert et al. 2017;</ref><ref type="bibr" target="#b14">Ren and etc. 2018;</ref><ref type="bibr" target="#b12">Kumar et al. 2020)</ref>. As a sample of 30 days of Criteo live traffic data, this dataset has more than 16 million ad impression records and 45 thousand conversions over 700 ad campaigns. Each ad impression record contains items such as timestamp, user id, ad campaign, and side information. There is also a label denotes whether a click action has occurred, and the corresponding conversion ID if this sequence of ad impressions finally leads to a conversion. We preprocess the raw Criteo dataset in the following procedures: (i) we count the top 10 campaigns with the largest number of ad impression records and filter out the ad impression records corresponding to other campaigns; (ii) we group the ad impression entries, which have the same user id and conversion id, into the same sequence and sort each sequence by timestamp; (iii) for a conversion id of -1, i.e., for a specific user, a group of ad impression records that did not cause the user to convert, the original group is divided at a time interval of 3 days based on timestamp; (iv) we filter out ad sequences that are less than 3 in length; (v) we divide it into the train set and the test set, and ensure the set of user id in the test set is a subset of user id in the train set. We also compare CAUSALMTA with its two ablations:</p><p>• CM-RW removes the journey reweighting module and treats all journeys equally. It only employs the proposed causal conversion prediction model for MTA. • CM-CAUSAL replaces the causal RNN predictor with traditional RNN and only utilize the reweighting mechanism to eliminate the confounding bias of static user attributes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The influence of user preferences for MTA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>using IPW and arXiv:2201.00689v1 [cs.IR] 21 Dec 2021</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>r x 3 7 2 P Z W v D y m V P 4 A + / z B 1 h 6 j c U = &lt; / l a t e x i t &gt; µ &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y X 7 b h t 8t R a 5 m c Y L F r q k m C T u o M i 8 = " &gt; A A A B 7 n i c b V D L S g N B E O y N r x h f U Y 9 e B o O Q U 9 i V o B 4 D X j x G M I m Q L G F 2 M p s M m c c y M y u E J R / h x Y M i X v 0 e b / 6 N s 8 k e N L G g o a j q p r s r S j g z 1 v e / v d L G 5 t b 2 T n m 3 s r d / c H h U P T 7 p G p V q Q j t E c a U f I 2 w o Z 5 J 2 L L O c P i a a Y h F x 2 o u m t 7 n f e 6 L a M C U f 7 C y h o c B j y W J G s H V S b 2 D Y W O D K s F r z G / 4 C a J 0 E B a l B g f a w + j U Y K Z I K K i 3 h 2 J h + 4 C c 2 z L C 2 j H A 6 r w x S Q x N M p n h M + 4 5 K L K g J s 8 W 5 c 3 T h l B G K l X Y l L V q o vy c y L I y Z i c h 1 C m w n Z t X L x f + 8 f m r j m z B j M k k t l W S 5 K E 4 5 s g r l v 6 M R 0 5 R Y P n M E E 8 3 c r Y h M s M b E u o T y E I L V l 9 d J 9 7 I R X D W a 9 8 1 a q 1 7 E U Y Y z O I c 6 B H A N L b i D N n S A w B S e 4 R X e v M R 7 8 d 6 9 j 2 V r y S t m T u E P v M 8 f z f 6 P J g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " x e Q g + X z S 1 r j E Q j / v Z T 0 r 3 2 R u f 6 8 = " &gt; A A A B 8 X i c b V D L T g J B E O z F F + I L 9 e h l I j H h R H Y N U Y 8 k X j x i I o 8 I h M w O s z B h d n Y z 0 2 v E D X / h x Y P G e P V v v P k 3 D r A H B S v p p F L V n e 4 u P 5 b C o O t + O 7 m 1 9 Y 3 N r f x 2 Y W d 3 b / + g e H j U N F G i G W + w S E a 6 7 V P D p V C 8 g Q I l b 8 e a 0 9 C X v O W P r 2 d + 6 4 F r I y J 1 h 5 O Y 9 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>K b 4 5 x X p x 3 5 2 P R m n O y m W P 4 A + f z B y U C k S g = &lt; / l a t e x i t &gt; z sample &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G f N m m 1 r q T C 6 T C 6 W V 3 u w / p U Y K U 0 E = " &gt; A A A B 8 X i c b V D L T g J B E O z F F + I L 9 e h l I j H h R H Y N U Y 8 k X D x i I o 8 I h M w O s z B h d n Y z 0 2 s k G / 7 C i w e N 8 e r f e P N v H G A P C l b S S a W q O 9 1 d f i y F Q d f 9 d n I b m 1 v b O / n d w t 7 + w e F R 8 f i k Z a J E M 9 5 k k Y x 0 x 6 e G S 6 F 4 E w V K 3 o k 1 p 6 E v e d u f 1 O d + + 5 F r I y J 1 j 9 O Y 9 0 M 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>8 c 4 L 8 6 7 8 7 F s z T n Z z C n 8 g f P 5 A 9 F g k P E = &lt; / l a t e x i t &gt; C Channel sequence</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>7 Y w Y j s y y N x P / 8 7 o p h t d + J l S S I i i + W B S m k m J M Z + / T g d D A U U 4 s Y V w L e y v l I 6 Y Z R x t S y Y b g L b + 8 S l r n N e + y d n F 3 U a l X 8 z i K 5 I S c k i r x y B W p k 1 v S I E 3 C i S L P 5 J W 8 O c Z 5 c d 6 d j 0 V r w c l n j s k f O J 8 / H W m R I w = = &lt; / l a t e x i t &gt; u concat sampled from &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " + 7 8 z</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " t D J 4 4 o I M O K D e K + 9 l Z 4 L G I + 0 H R U A = " &gt; A A A B 8 3 i c b V B N S 8 N A E N 3 U r 1 q / q h 6 9 L B a h p 5 J I U Y 8 F L x 4 r 2 A 9 o S t l s J + 3 S z S b s T s Q S + j e 8 e F D E q 3 / G m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>g r P 4 8 j J p n l e c i 0 r 1 t l q q l e d x F M g J O S V l 4 p B L U i M 3 p E 4 a h J F H 8 k x e y Z v x Z L w Y 7 8 b H r H X F m M 8 c k T 8 w P n 8 A e m 2 V 0 Q = = &lt; / l a t e x i t &gt; c rev 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 4 x 9 d 7 u p d x k L d g C l 7</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>r b y I I 0 9 O y R k p E 5 t c k R q 5 J X X S J I w 8 k m f y S t 6 M J + P F e D c + 5 q 0 5 Y z F z T P 7 A + P w B s G 6 V 9 A = = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = "1 M f o G U 5 O 2 d B 9 + Z s 1 H G 9 7 h g u O s z I = " &gt; A A A B + n i c b V D L S s N A F J 3 U V 6 2 v V J d u B o v Q V U m k q M u C G 5 c V7 A P a E C a T S T t 0 8 m D m p l p i P s W N C 0 X c + i X u / B u n b R b a e m D g c M 4 9 3 D v H S w R X Y F n f R m l j c 2 t 7 p 7 x b 2 d s / O D w y q 8 d d F a e S s g 6 N R S z 7 H l F M 8 I h 1 g I N g / U Q y E n q C 9 b z J z d z v T Z l U P I 7 u Y Z Y w J y S j i A e c E t C S a 1 a H w B 7 B C 7 J p 7 m Y 6 6 e e u W b M a 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>s n R 6 J e / e o O Y p x E o 5 J I Z 0 / X c B P 2 M a R R c w r T U S w 0 k j I / Z E L q W K h a B 8 b P 5 x V N 6 Z p U B D W N t S y G d q 7 8 n M h Y Z M 4 k C 2 x k x H J l l b y b + 5 3 V T D K / 9 T K g k R V B 8 s S h M J c W Y z t 6 n A 6 G B o 5 x Y w r g W 9 l b K R 0 w z j j a k k g 3 B W 3 5 5 l b T O a 9 5 l 7 e L u o l K v 5 n E U y Q k 5 J V X i k S t S J 7 e k Q Z q E E 0 W e y S t 5 c 4 z z 4 r w 7 H 4 v W g p P P H J M / c D 5 / A C N 9 k S c = &lt; / l a t e x i t &gt; y &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G f N m m 1 r q T C 6 T C 6 W V 3 u w / p U Y K U 0 E = " &gt; A A A B 8 X i c b V D L T g J B E O z F F + I L 9 e h l I j H h R H Y N U Y 8 k X D x i I o 8 I h M w O s z B h d n Y z 0 2 s k G / 7 C i w e N 8 e r f e P N v H G A P C l b S S a W q O 9 1 d f i y F Q d f 9 d n I b m 1 v b O / n d w t 7 + w e F R 8 f i k Z a J E M 9 5 k k Y x 0 x 6 e G S 6 F 4 E w V K 3 o k 1 p 6 E v e d u f 1 O d + + 5 F r I y J 1 j 9 O Y 9 0 M 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>8 c 4 L 8 6 7 8 7 F s z T n Z z C n 8 g f P 5 A 9 F g k P E = &lt; / l a t e x i t &gt; C &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W 4 H 9 K y 7 Y K P h Z I 1 S S 8 5 A Z g h J v r K g = " &gt; A A A B 8 n i c b V D L S g M x F M 3 U V 6 2 v q k s 3 w S J 0 V W a k q M u C G x c u K t g H T I e S S T N t a C Y Z k j t C G f o Z b l w o 4 t a v c e f f m G l n o a 0 H A o d z 7 i X n n j A R 3 I D r f j u l j c 2 t 7 Z 3 y b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>s 9 e Z 1 0 L x v e V a P 5 0 K y 1 6 k U d Z X S G z l E d e e g a t d A d a q M O o k i h Z / S K 3 h x w X p x 3 5 2 M 5 W n K K n V P 0 B 8 7 n D 3 w h k V E = &lt; / l a t e x i t &gt; L &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W 4 H 9 K y 7 Y K P h Z I 1 S S 8 5 A Z g h J v r K g = " &gt; A A A B 8 n i c b V D L S g M x F M 3 U V 6 2 v q k s 3 w S J 0 V W a k q M u C G x c u K t g H T I e S S T N t a C Y Z k j t C G f o Z b l w o 4 t a v c e f f m G l n o a 0 H A o d z 7 i X n n j A R 3 I D r f j u l j c 2 t 7 Z 3 y b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>s 9 e Z 1 0 L x v e V a P 5 0 K y 1 6 k U d Z X S G z l E d e e g a t d A d a q M O o k i h Z / S K 3 h x w X p x 3 5 2 M 5 W n K K n V P 0 B 8 7 n D 3 w h k V E = &lt; / l a t e x i t &gt; L Ad Journey &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " l C Z 1 J r p n y l / b 2 0 6 y f 4x 5 Q c n m F W 0 = " &gt; A A A B 8 X i c b V D L S g N B E J y N r x h f U Y 9 e B o O Q U 9 i V o B 4 D X s R T B P P A J I T Z S W 8 y Z H Z 2 m e k V w 5 K / 8 O J B E a / + j T f / x k m y B 0 0 s a C i q u u n u 8 m M p D L r u t 5 N b W 9 / Y 3 M p v F 3 Z 2 9 / Y P i o d H T R M l m k O D R z L S b Z 8 Z k E J B A w V K a M c a W O h L a P n j 6 5 n f e g R t R K T u c R J D L 2 R D J Q L B G V r p o Y v w h H 6 Q 3 k 7 7 x Z J b c e e g q 8 T L S I l k q P e L X 9 1 B x J M Q F H L J j O l 4 b o y 9 l G k U X M K 0 0 E 0 M x I y P 2 R A 6 l i o W g u m l 8 4 u n 9 M w q A x p E 2 p Z C O l d / T 6 Q s N G Y S + r Y z Z D g y y 9 5 M / M / r J B h c 9 V K h 4 g R B 8 c W i I J E U I z p 7 n w 6 E B o 5 y Y g n j W t h b K R 8 x z T j a k A o 2 B G / 5 5 V X S P K 9 4 F 5 X q X b V U K 2 d x 5 M k J O S V l 4 p F L U i M 3 p E 4 a h B N F n s kr e X O M 8 + K 8 O x + L 1 p y T z R y T P 3 A + f w D c A 5 D 4 &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " N R B H Y c p Z z n G h W N F G v G t R F t e 6 8 r 8 = " &gt; A A A B 9 H i c b V D L S g M x F L 2 p r 1 p f V Z d u g k X o q s x I U Z c F N y 4 r 2 g e 0 Q 8 m k m T Y 0 k x m T T K E M / Q 4 3 L h R x 6 8 e 4 8 2 / M t L P Q 1 g O B w z n 3 c k + O H w u u j e N 8 o 8 L G 5 t b 2 T n G 3 t L d / c H h U P j 5 p 6 y h R l L V o J C L V 9 Y l m g k v W M t w I 1 o 0 V I 6 E v W M e f 3 G Z + Z 8 q U 5 p F 8 N L O Y e S E Z S R 5 w S o y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Architecture of CAUSALMTA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Learning curves and sample weight distribution on Criteo dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Performance comparison of ablation methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>=EE</head><label></label><figDesc>the causal prediction module. The optimal prediction probabilities of ad exposure are given byc rev * = arg max c rev K k=1 v rev p(v rev |c k )log (c rev k ) dv revBy maximizing value function and leveraging Lagrange multiplies, we can derive c rev * by the following form − p(v rev |c k ) χ = p(v rev |c k ) K m=1 p(v rev |c m ) by setting the above derivative to zero and solving c rev * .Therefore, the objective min v rev L rev for the learned representation v rev becomes minv rev K k=1 E v rev ∼p(v rev |c k ) log p(v rev |c k ) K m=1 p(v rev |c m ) We can derive that K k=1 E v rev ∼p(v rev |c k ) log p(v rev |c k ) v rev ∼p(v rev |c k ) log p(v rev |c k ) v rev ∼p(v rev |c k ) log p(v rev |c k ) rev |c m )= K • JSD p(v rev |c 1 ), ..., p(v rev |c K )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>( 1 −</head><label>1</label><figDesc>kinds of baselines, i.e., statistical learning-based methods(SL), deep learning-based methods(DL), causal learning-based methods(CL) and ablations.The statistical learning-based methods consist of three works:• LR(Logistic Regression) model for ad attribution is proposed by<ref type="bibr" target="#b16">Shao and Li(Shao and Li 2011)</ref>, in which channel's attribution values are calculated as the learned coefficients. • SP(Simple Probabilistic) model calculates the conversion rate taking into the conversion probability from the observed data into account. As in(Dalessandro et al.  2012), the conversion rate isp(y = 1|{c j } mi j=1 ) = 1 − mi j Pr(y = 1|c j = k))• AH(Additive Hazard) proposed by Zhang et al. (Zhang, Wei, and Ren 2014) is the first user conversion estimation model based on survival analysis and additive hazard function. The deep learning-based methods also consist of three works: • DNAMTA is the Deep Neural Net with Attention Multitouch Attribution model proposed by Arava et al. (Arava et al. 2018). It leverages LSTM and attention mechanism to model the dynamic interaction between ad channels, and incorporates user-context information to reduce estimation bias. • DARNN is the Dual-Attention Recurrent Neural Network proposed in (Ren and etc. 2018) which uses dualattention RNNs to combine both post-view and post-click attribution patterns together for the user conversion estimation. • DeepMTA is a phased-LSTM based model (Yang, Dyer, and Wang 2020) which combines deep neural networks and additive feature explanation model for interpretable online multi-touch attribution. For fair comparison, we replace the phased-LSTM with vinilla LSTM. The causal learning-based methods consist of two works: • JDMTA is a causal-inspired model (Du and etc. 2019) which employs Shapley Value to compute the attribution credits for touchpoints. • CAMTA is the Causal Attention Model for Multi-touch Attribution proposed by Kumar et al. (Kumar et al. 2020). This model leverages counterfactual recurrent network to minimize selection bias in channel assignment while conducting conversion estimation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>The overview of the Criteo dataset , c t ) in Eq.(4). We can prove thatL rev = K • JSD(p(v revt |c 1 ), ..., p(v rev t |c K )) − K logK where KlogK is a constant, and JSD(•, ..., •) denotes the multi-distribution Jensen-Shannon Divergence (Li et al. 2018), which is non-negative and 0 if and only if all distributions are equal. To minimize L rev , we derive p(v rev t |c 1 ) = ... = p(v rev t |c K ), where v rev t is the learned representation invariant across different ad channels. For details, see the appendix.</figDesc><table><row><cell>Statistics</cell><cell></cell><cell>Raw</cell><cell>Processed</cell></row><row><cell>No. of users</cell><cell></cell><cell>6,142,256</cell><cell>157,331</cell></row><row><cell cols="2">No. of campaigns</cell><cell>675</cell><cell>10</cell></row><row><cell>No. of journeys</cell><cell></cell><cell>6,514,319</cell><cell>196,560</cell></row><row><cell cols="2">No. of convert journeys</cell><cell>435,810</cell><cell>19,890</cell></row><row><cell cols="2">No. of touchpoints</cell><cell>16,468,027</cell><cell>787,483</cell></row><row><cell>the representation v rev t</cell><cell cols="3">invariant across different ad chan-</cell></row><row><cell cols="4">nels to eliminate biases caused by dynamic user fea-</cell></row><row><cell cols="4">tures. We achieve this by minimizing the formula L rev = N i=1 T i t=1 CE(c rev t</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Profit comparison of data replay.</figDesc><table><row><cell>Method</cell><cell>1/2</cell><cell>1/4</cell><cell>1/8</cell><cell>1/16</cell></row><row><cell></cell><cell></cell><cell>Shop 1</cell><cell></cell><cell></cell></row><row><cell>LSTM</cell><cell>69.8</cell><cell>63.7</cell><cell>56.2</cell><cell>58.3</cell></row><row><cell>CAUSALMTA</cell><cell>72.3</cell><cell>70.2</cell><cell>57.1</cell><cell>59.2</cell></row><row><cell cols="5">Improvement +3.58% +10.20% +1.60% +1.54%</cell></row><row><cell></cell><cell></cell><cell>Shop 2</cell><cell></cell><cell></cell></row><row><cell>LSTM</cell><cell>20.9</cell><cell>18.3</cell><cell>17.5</cell><cell>15.2</cell></row><row><cell>CAUSALMTA</cell><cell>21.1</cell><cell>19.1</cell><cell>17.8</cell><cell>15.8</cell></row><row><cell cols="5">Improvement +0.96% +4.37% +1.71% +3.95%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">http://ailab.criteo.com/criteo-attribution-modeling-biddingdataset/</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="formula">4</ref><p>. It can be reckoned as a standard measurement to estimate the classification performance. AUC can be a metric reflecting the pairwise ranking performance of the estimation between converted and non-converted ad impression sequences.</p><p>Compared Methods. In our experiments, CAUSALMTA is compared with 8 baseline methods which can be divided into three categories, i.  <ref type="bibr">2020)</ref>. Besides, we also compare CAUSALMTA with two ablation methods, i.e., CM-RW and CM-CAUSAL. Detailed descriptions of these methods are available in the appendix.</p><p>Parameter Settings. For LSTMs in CAUSALMTA, we stack three 3 layer LSTMs as the encoder, decoder, and the predictor respectively. MLP models in CAUSALMTA are composed of 4 fully connected layers with ELU as the activate function. CAUSALMTA has 4 hyperparameters i.e., α, β, γ and δ, we empirically set α = β = 0.5, and γ = δ = 0.5. All the experiments are conducted on a highend server with 2× NVIDIA GTX3090 GPUs. All the compared baselines are trained in 30 epochs and the best model is chosen to report.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance Comparison</head><p>The detailed evaluation results on different baselines are presented in Table <ref type="table">2</ref>. As shown, CAUSALMTA continuously outperforms all the compared baselines, which proves the validity of eliminating the confounding bias on static user attributes and dynamic features. CAMTA is the strongest baseline but also inferior to CAUSALMTA. It utilizes click labels as the auxiliary information, which probably involves </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>Theoretical Analysis of CAUSALMTA Proof of weights calculation. In order to create a pseudo-population which debiases by means of sample re-weighting, the weights should cater to the equation W T (U, C) = p(C)/p(C|U) <ref type="bibr" target="#b11">(Fong et al. 2018;</ref><ref type="bibr" target="#b23">Zou et al. 2020</ref>). When we learn a variational distribution q φ (z|c) of the original channel assignment of touch-points, the variational sample weights can be computed as follows:</p><p>Where W Z (U, Z) can be viewed as the density ratio estimation to decorrelate U and Z for points in space U × Z.</p><p>Proof of the journal reweighting module. In the task of multi-touch attribution, provided with observational data, we hope to learn a hypothesis f θp : U × C → R with model parameters θ p , which predicts the conversion rate based on the confounders and touch-points. In this setting, the concept of counterfactual is to guarantee the learned hypothesis to predict accurate outcome when the assignment of touchpoint (e.g., the channel preference) is random. For the individual U, when L() denotes the error function and y() denotes the ground-truth outcome, the prediction error can be formed as:</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bayesian Inference of Individualized Treatment Effects using Multi-task Gaussian Processes</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Alaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Der Schaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Von Luxburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017</title>
				<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-04">2017. December 4-9, 2017</date>
			<biblScope unit="page" from="3424" to="3432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Limits of Estimating Heterogeneous Treatment Effects: Guidelines for Practical Algorithm Design</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Alaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Der Schaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning, ICML 2018</title>
				<editor>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Dy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Krause</surname></persName>
		</editor>
		<meeting>the 35th International Conference on Machine Learning, ICML 2018<address><addrLine>Stockholmsmässan, Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018-07-10">2018. July 10-15. 2018</date>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="129" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Deep neural net with attention for multi-channel multi-touch attribution</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Arava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.02230</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An introduction to propensity score methods for reducing the effects of confounding in observational studies</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Austin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate behavioral research</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="399" to="424" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Experimental designs and estimation for online display advertising attribution in marketplaces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Barajas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Akella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Holtan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Flores</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Science</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="465" to="483" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Beyond the last touch: Attribution in online advertising</title>
		<author>
			<persName><forename type="first">R</forename><surname>Berman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Science</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="771" to="792" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Estimating counterfactual treatment outcomes over time through adversarially balanced representations</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Alaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Der Schaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
				<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26">2020. April 26-30, 2020</date>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">B</forename><surname>Dalessandro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Perlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Stitelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Provost</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Causally motivated attribution for online advertising</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth international workshop on data mining for online advertising and internet economy</title>
				<meeting>the sixth international workshop on data mining for online advertising and internet economy</meeting>
		<imprint>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Attribution Modeling Increases Efficiency of Bidding in Display Advertising</title>
		<author>
			<persName><forename type="first">E</forename><surname>Diemert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Meynet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Galland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lefortier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.00215</idno>
	</analytic>
	<monogr>
		<title level="m">Causally driven incremental multi touch attribution using a recurrent neural network</title>
				<editor>
			<persName><forename type="first">.</forename><forename type="middle">Acm</forename><surname>Du</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename></persName>
		</editor>
		<meeting><address><addrLine>Halifax, NS, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-08-13">2017. August 13 -17, 2017. 2019</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
	<note>Proceedings of the ADKDD&apos;17</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Variational Recurrent Auto-Encoders</title>
		<author>
			<persName><forename type="first">O</forename><surname>Fabius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Van Amersfoort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations, ICLR 2015</title>
				<editor>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07">2015. May 7-9, 2015</date>
		</imprint>
	</monogr>
	<note>Workshop Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Covariate balancing propensity score for a continuous treatment: application to the efficacy of political advertisements</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hazlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Imai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Applied Statistics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="156" to="177" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Forecasting Treatment Responses Over Time Using Recurrent Marginal Structural Networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pmlr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kallus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shroff</surname></persName>
		</author>
		<author>
			<persName><surname>Ieee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.08598</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<meeting><address><addrLine>Sorrento, Italy; Munich, Germany; Lim, B; NeurIPS; Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2017. 2016. 2018. 2020. November 17-20, 2020. 2018. September 8-14. 2018. 2018. 2018. 2018. December 3-8, 2018</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="7494" to="7504" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>20th International Conference on Data Mining Workshops, ICDM Workshops 2020</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Big data and marketing analytics in gaming: Combining empirical models and field experimentation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename><surname>Hornbuckle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Science</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="699" to="725" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning Multi-touch Conversion Attribution with Dual-attention Mechanisms for Online Advertising</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM 2018</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009. 2018</date>
			<biblScope unit="page" from="1433" to="1442" />
		</imprint>
	</monogr>
	<note>Causality</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Bayesian nonparametric approach to marginal structural models for point treatments and a continuous or survival outcome</title>
		<author>
			<persName><forename type="first">J</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Lum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Daniels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="47" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Data-driven multi-touch attribution models</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Sahni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Effect of temporal spacing between advertising exposures: Evidence from online field experiments. Quantitative Marketing and Economics</title>
				<editor>
			<persName><forename type="first">C</forename><surname>Apté</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Ghosh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Smyth</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011-08-21">2015. 2011. August 21-24, 2011</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="307" to="317" />
		</imprint>
	</monogr>
	<note>Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. Shapley, L. S. 1953. A value for n-person games. Contributions to the Theory of Games</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Shender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dikmen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.08432</idno>
		<title level="m">A Time To Event Framework For Multi-touch Attribution</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Shapley meets uniform: An axiomatic framework for attribution in online advertising</title>
		<author>
			<persName><forename type="first">R</forename><surname>Singal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1713" to="1723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Bayesian nonparametric approach for estimating individualized treatmentresponse curves</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning for Healthcare Conference</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="282" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.00384</idno>
		<title level="m">Interpretable Deep Learning Model for Online Multi-touch Attribution</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Measuring multichannel advertising response</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zantedeschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Feit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Bradlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2706" to="2728" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multi-touch attribution in online advertising with survival theory</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE International Conference on Data Mining</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="687" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Counterfactual Prediction for Bundle Treatment</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
