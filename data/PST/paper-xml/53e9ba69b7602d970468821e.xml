<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Declarative Tracepoints: A Programmable and Application Independent Debugging System for Wireless Sensor Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Qing</forename><surname>Cao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tarek</forename><surname>Abdelzaher</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">John</forename><surname>Stankovic</surname></persName>
							<email>stankovic@cs.virginia.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Virginia</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kamin</forename><surname>Whitehouse</surname></persName>
							<email>whitehouse@cs.virginia.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Virginia</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Liqian</forename><surname>Luo</surname></persName>
							<email>liqian@microsoft.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Declarative Tracepoints: A Programmable and Application Independent Debugging System for Wireless Sensor Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">54BF522BEF9E9CE80189744E3FAF415E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>D.2.5 [Software Engineering]: Testing and Debugging-Debugging aids and Tracing Design</term>
					<term>Experimentation</term>
					<term>Performance Declarative Tracepoints</term>
					<term>Embedded Debugging</term>
					<term>Wireless Sensor Networks TraceSQL Language Overview Statement types Keywords Comments Configuration statements Variable declaration statements @</term>
					<term>INTEGER</term>
					<term>LONG</term>
					<term>STRUCT</term>
					<term>ARRAY Declare TraceSQL variables. Each statement must start with @</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Effective debugging usually involves watching program state to diagnose bugs. When debugging sensor network applications, this approach is often time-consuming and errorprone, not only because of the lack of visibility into system state, but also because of the difficulty to watch the right variables at the right time. In this paper, we present declarative tracepoints, a debugging system that allows the user to insert a group of action-associated checkpoints, or tracepoints, to applications being debugged at runtime. Tracepoints do not require modifying application source code. Instead, they are written in a declarative, SQL-like language called TraceSQL independently. By triggering the associated actions when these checkpoints are reached, this system automates the debugging process by removing the human from the loop. We show that declarative tracepoints are able to express the core functionality of a range of previously isolated debugging techniques, such as EnviroLog, NodeMD, Sympathy, and StackGuard. We describe the design and implementation of the declarative tracepoints system, evaluate its overhead in terms of CPU slowdown, illustrate its expressiveness through the aforementioned debugging techniques, and finally demonstrate that it can be used to detect real bugs using case studies of three bugs based on the development of the LiteOS operating system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Effective debugging usually involves watching program state to diagnose abnormal behavior. When debugging sensor networks, observing state is challenging in that it requires watching the right set of variables at the right time. That set is hard to know in advance. Meanwhile, watching everything is not feasible due to severe resource limitations at individual sensor nodes. Often, a node could crash and restart before useful information is collected, in which case all state is lost. Therefore, the debugging process for sensor network applications remains time-consuming, error-prone, and difficult.</p><p>To simplify the debugging process, we present the declarative tracepoints (DT) system, which allows the developer to insert a group of action-associated checkpoints at runtime. We refer to these action-associated checkpoints as tracepoints, or probes, analogous to the way test probes are used in electronic hardware to debug circuits. These tracepoints are programmed in an SQL-like declarative language, called TraceSQL. By triggering the associated actions when tracepoints are reached, DT removes the human from the loop, and makes the debugging process programmable.</p><p>DT has two key advantages. First, DT does not require modifying application source code. Based on dynamic instrumentation, it enables programmers to add and remove tracepoints at runtime, without requiring application reboots. Such flexibility allows programmers to try out multiple rounds of modifications without the need to re-deploy applications. This is particularly attractive in sensor networks, where recompilation and re-deployment of applications is usually a lengthy, error-prone process. Second, to implement associated actions, DT introduces the TraceSQL language to program the debugging actions. Being programmable, DT can express a wide range of debugging techniques that were previously hardwired for unique application needs. In this sense, DT acts like the thin waist of a systematic framework where multiple debugging techniques co-exist. To the best of our knowledge, DT is the first debugging system to simultaneously provide both a declarative programming language and independence from application source code for wireless sensor networks.</p><p>The usage model of DT is as follows. First, a user application is deployed into multiple nodes. After observing abnormal behavior, the developer writes DT scripts in TraceSQL, compiles the scripts into Tracepoint Engines (TEs), and installs the TEs to debug the application. A TE inserts tracepoints into application binaries, triggers associated actions when such tracepoints are reached, and exposes information in the form of messages or traces for online or off-line diagnosis. In this sense, the TE is an agent in lieu of the developer, streamlining the debugging process because it no longer involves user interaction. Finally, the developer can uninstall the current TEs and install new ones if the bug has not been resolved. The on-demand deployment of TEs keeps the debugging code base small, thus minimizing the resource consumption of the debugging process.</p><p>The design of DT is partially inspired by features offered by Aspect Oriented Programming (AOP) <ref type="bibr" target="#b12">[13]</ref>. The design motivation of AOP is to achieve separation of concerns and to avoid tangling code by identifying cross-cutting aspects that cut across the system's basic components at join points, where additional advice is applied. The aspects and components in AOP are usually developed using different languages, and are later weaved together either at compile time or at runtime. For complicated systems, such an approach is promising to improve the isolation, composition, and reuse of software modules.</p><p>DT and the TraceSQL language can be viewed as one aspect of sensor network development, the debugging aspect. Just like AOP, TraceSQL programs are developed independently of the debugged applications. TraceSQL programs cut across functional components, in the form of Tracepoint Engines (TEs). The associated actions are essentially a form of advice for debugging purposes.</p><p>We have implemented a prototype of DT on top of the LiteOS operating system, a recent thread-based operating system developed at the University of Illinois <ref type="bibr" target="#b5">[6]</ref>. We chose LiteOS mostly because of its support for interactive control of network behavior through its Unix-like shell, such as the file copy command for easy retrieval of data. Therefore, we do not address trace retrieval separately in the DT system. The prototype we implemented supports instrumentation of both user applications and the LiteOS kernel. We also selected four representative debugging techniques, namely EnviroLog <ref type="bibr" target="#b16">[17]</ref>, NodeMD <ref type="bibr" target="#b13">[14]</ref>, Sympathy <ref type="bibr" target="#b19">[20]</ref>, and StackGuard <ref type="bibr" target="#b7">[8]</ref>, to demonstrate that they can be expressed with TraceSQL. Finally, we also used DT to retroactively debug the documented bugs in the development version of LiteOS and its applications from October 2007 to March 2008, as well as to solve a problem in the communication stack development based on LiteOS. We present these bugs as representative case studies.</p><p>Note that, DT can also be implemented on other sensor network operating systems, as long as the following two features are supported. First, the operating system should support dynamic loading of new modules, so that the compiled TE can be installed incrementally in addition to the deployed user applications. Second, the operating system should support access to non-volatile storage, such as flash. Several existing operating systems meet such requirements, including TinyOS <ref type="bibr" target="#b10">[11]</ref> (with TinyThreads <ref type="bibr" target="#b18">[19]</ref>, Deluge <ref type="bibr" target="#b11">[12]</ref>, and the Matchbox file system <ref type="bibr" target="#b1">[2]</ref> installed), Contiki <ref type="bibr" target="#b8">[9]</ref>, and Mantis <ref type="bibr" target="#b3">[4]</ref>. Porting declarative tracepoints to these operating systems is therefore possible. Also note that while DT is designed for wireless sensor networks, it applies to more generic embedded system debugging as well. Porting DT for these needs is outside the scope of this paper.</p><p>The remainder of this paper is organized as follows. Section 2 summarizes the related work. In Section 3, we give an overview of DT. Section 4 presents the details of the TraceSQL language, illustrating the core features using examples. In Section 5, we discuss the implementation of declarative tracepoints. Section 6 presents performance evaluation focusing on overhead. In Section 7, we explore and evaluate the expressiveness of DT using a series of debugging techniques from the literature. Section 8 presents three real bugs based on the LiteOS operating system as case studies to demonstrate the effectiveness of DT. Section 9 concludes the paper and presents directions for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Debugging has been an active topic probably ever since software has been written. In the area of sensor networks, many debugging techniques have been proposed. In this paper, we use TraceSQL to express three such techniques; namely, EnviroLog <ref type="bibr" target="#b16">[17]</ref>, NodeMD <ref type="bibr" target="#b13">[14]</ref>, and Sympathy <ref type="bibr" target="#b19">[20]</ref>. We also use TraceSQL to express a more general technique called StackGuard <ref type="bibr" target="#b7">[8]</ref>. Below, we describe them in more detail.</p><p>The first tool that we use TraceSQL to express is En-viroLog. It aims to improve repeatability of experimental testing of distributed event-driven applications, based on the observation that the system state can change depending on the event sequence and timing. Hence, debugging such applications is complicated by non-repeatable event sequences caused by the dynamic environmental inputs. To address this challenge, EnviroLog provides an event recording and replay service that captures and replays events with the help of the non-volatile flash. Its compiler modifies the application source code such that every time an instrumented function is called, its invoked time and parameters are stored into flash. Later, EnviroLog replays this sequence of events by executing the same sequence of functions with the same parameters. After the code is installed, EnviroLog allows the user to issue START_RECORD and START_REPLAY commands to record and replay events on demand.</p><p>The second tool expressed, NodeMD, is designed to diagnose node-level faults in sensor network applications. It focuses on catching software faults before they completely disable the remote sensor node, so that the user can be provided with diagnostic information to troubleshoot the root cause. It tries to catch three types of bugs: stack overflows, livelocks, and deadlocks, in addition to application-specific faults. It also provides remote retrieval of the logged information stored in a circular buffer, so that the probable root of the bug can be traced.</p><p>The third tool, Sympathy, detects and debugs failures by collecting metrics and performing an analysis procedure at the sink to localize the most likely failure source. The key assumption made by Sympathy is that for a broad class of data gathering applications, it is possible to diagnose failures by analyzing a minimal set of metrics at a centralized sink. It traces the failure source to one of the three possibilities: the node itself, the communication path, or the sink.</p><p>The last tool we express is StackGuard, a more generic tool for detecting stack corruption caused by buffer overruns (e.g., when the return address of a function is over-written). This problem is also known as the buffer overrun security exploit. Having received intensive attention, this problem is addressed in multiple ways, and StackGuard is one of the better-known techniques in that it virtually eliminates all buffer overflows with the help of the canary word. More specifically, StackGuard modifies the generated prologue and epilogue code for functions to insert canary words.</p><p>The assumption held by StackGuard is that if some code in a function modifies the return address, it must have modified the canary word as well, assuming that the application does not know the value and size of the canary word. By checking the integrity of the canary word, StackGuard can detect malfunctioning code.</p><p>Besides the four representative debugging techniques, many other tools have been proposed for different debugging purposes in the sensor network community. Clairvoyant <ref type="bibr" target="#b23">[24]</ref>, JTAG <ref type="bibr" target="#b0">[1]</ref>, and the LiteOS shell <ref type="bibr" target="#b5">[6]</ref> provide interactive sourcelevel debugging commands such as break, step, and watch to access program state. TOSSIM <ref type="bibr" target="#b15">[16]</ref>, EmStar <ref type="bibr" target="#b9">[10]</ref>, and Avrora <ref type="bibr" target="#b20">[21]</ref> provide simulation environments for sensor network applications. SNMS <ref type="bibr" target="#b21">[22]</ref> provides logging and retrieval of runtime state for fault diagnosis. Some tools recognize visibility as the one of main obstacles for debugging, hence propose to improve visibility in various ways <ref type="bibr" target="#b22">[23]</ref>. Tools for improving memory safety also exist <ref type="bibr" target="#b6">[7]</ref>. Various virtual machines <ref type="bibr" target="#b14">[15]</ref> developed for sensor networks can also be modified to provide robustness and error checking on the nodes. However, none of these tools implement languages specialized for debugging that can express existing techniques. Hence, we believe that DT is complementary to these previous techniques.</p><p>Outside the area of sensor networks, one tool that has used dynamic instrumentation for debugging is DTrace <ref type="bibr" target="#b2">[3]</ref>, a comprehensive dynamic tracing framework developed by Sun Microsystems on Solaris 10. DTrace allows the user to write scripts using the D programming language to perform runtime instrumentation and trace collection. Compared to DTrace, our work is novel in the following two respects. First, DTrace is tightly integrated with the underlying operating system and only supports PCs with sufficient system resources. The design and implementation of our DT system, on the other hand, consists of design choices specific to sensor nodes to fit into their stringent resource limitations. Second, the debugging needs addressed in this paper are very different from those addressed by DTrace scripts. While DTrace primarily addresses problems more specific to its own environment, such as CPU scheduling tracing and I/O activities, our DT system targets debugging tasks of more interest to sensor networks, such as stack overflows and the special need to replay sensor readings. These significant differences in goals and approaches distinguish DT from DTrace.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DESIGN</head><p>The DT system aims to provide a programmable and application-independent debugging architecture. Figure <ref type="figure" target="#fig_0">1</ref> shows its overall architecture. Below, we identify the major design goals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Application Independence</head><p>Our first goal is to achieve application independence. More specifically, we hope that DT programs should be developed independently of applications, and should not require source level modifications to the applications under debugging. While this approach may sometimes prevent the compiler from performing better global optimizations, it achieves separation of concerns by isolating debugging code from application code. Hence, debugging can be performed without requiring re-compilations and re-deployments of applications.</p><p>DT works as follows. As shown in Figure <ref type="figure" target="#fig_0">1</ref>,TraceSQL programs are compiled into TE executables. Once installed, TE inserts tracepoints into applications by instrumenting their binaries. The instruction flow jumps to an action handler whenever a tracepoint is reached. The action handler is carefully designed such that its existence is transparent to user applications except in timing<ref type="foot" target="#foot_0">1</ref> . Indeed, the number of CPU cycles for running a user application is changed inevitably if new functionality is added. However, this is usually not a big concern in that it can be viewed that the application reached a mini context switch at each tracepoint, although the kernel is oblivious. Given that DT is designed for multi-threaded operating systems (each TE is executed as a separate thread), it is reasonable to assume that additional context switches should not lead to extra application bugs in most cases<ref type="foot" target="#foot_1">2</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Ease of Programming</head><p>Our second goal is to allow easy DT programming. To this end, we adopt a declarative language syntax similar to SQL. Declarative languages are well known for their ability to express complicated operations with short programs. The customized language we developed, TraceSQL, focuses on expressing the locations of tracepoints and the associated actions. Below, we show an example that records every context switch caused by applications. In LiteOS, each context switch invokes the yield() function in the syscall.c file. Therefore, we simply add a tracepoint at the beginning of this function to track context switches, shown as follows. The syntax of TraceSQL is described in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TRACE yield() FROM syscall.c EXECUTE {</head><p>RECORD yield(); }</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Runtime Efficiency</head><p>Our third goal is to control the overhead introduced by DT. To this end, we directly compile DT programs into  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">THE TRACESQL LANGUAGE</head><p>In this section, we systematically describe the syntax of TraceSQL. Table <ref type="table" target="#tab_0">1</ref> shows an overview of TraceSQL keywords. We first present a complete TraceSQL example, followed by describing its syntax details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">TraceSQL Program Example</head><p>In this example, we present the TraceSQL implementation of the StackGuard tool. As described in Section 2, StackGuard addresses the stack corruption problem through canary words, as illustrated in Figure <ref type="figure" target="#fig_1">2</ref>. This problem is usually not caused by security attacks in sensor networks. Instead, it is more common for a node to crash for accidentally overwriting the return address of its functions, causing a function to return to unpredictable addresses. Therefore, using StackGuard is very much needed. While StackGuard is implemented as a patch for GCC, to our knowledge, it does not support AVR-GCC, and hence does not work with sensor networks.</p><p>Our implementation of StackGuard is illustrated in Table 2. This example demonstrates the use of integers, tracepoints declarations, and their associated actions. It consists of two probes for each instrumented function, which, in this </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2: TraceSQL Example for StackGuard</head><p>example, is the crashNode() function from the file app.c. One probe is located before the prologue, and the other after the epilogue. When a procedure is invoked, the first triggered tracepoint pushes a randomly generated canary word onto the stack. Just before this function returns, the second tracepoint is triggered, which checks if the canary word is still intact. If not, an error is detected and the thread is suspended.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Program Structure Overview</head><p>Formally, a TraceSQL program consists of three types of statements: configuration statements, variable declaration statements, and tracepoint declaration statements. The example in Table <ref type="table">2</ref> shows the latter two types of statements.</p><p>Configuration statements: These statements specify TE parameters. For example, if a program writes to a file, it specifies the name of the file with a configuration statement. Starting with a pre-defined @, the following sample shows how to set the file output and the internal buffer size. @fileoutput = "trace.log"; @buffersize = 64;</p><p>Variable declaration statements: These statements specify the types and names of variables. Integers are most commonly used, as shown in lines 1 and 2 of the StackGuard example (Table <ref type="table">2</ref>).</p><p>Tracepoint declaration statements: Tracepoint declaration statements are the key components of a program.</p><p>Each statement consists of three parts, tracepoint addresses, tracepoint actions, and optional condition predicates. One or more tracepoints can be specified within a single statement, and they can also be nested to perform complicated tasks. The declaration part starts with a TRACE keyword, the action part starts with an EXECUTE keyword, and the predicate starts with a WHERE keyword. Hence, a tracepoint declaration looks as follows. Two examples of this declaration are shown in lines 3 and 8 of the StackGuard example (Table <ref type="table">2</ref>).</p><formula xml:id="formula_0">TRACE {...} FROM {...} EXECUTE {...} WHERE {...}</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Tracepoint Declarations</head><p>TraceSQL supports three types of tracepoints: function tracepoints, statement tracepoints, and virtual tracepoints.</p><p>Function tracepoints: The first type of tracepoints inserts probes into functions. In TraceSQL programs, the probe is addressed by a pair consisting of a function name and a file name. By default, the probe is located before the first instruction generated by the function. Additional keywords, such as BEFORE_PROLOGUE and AFTER_PROLOGUE, can be used to specify the exact address of inserted probes (for these two keywords, they specify that the probe is located before and after the prologue code generated by the GCC compiler).</p><p>Function tracepoints can express a variety of events of interest, such as receiving a packet (by adding a probe to the packet receiving function), or reading ADC sensors (by adding a probe to the ADC reading function). To simplify adding a group of tracepoints, the TraceSQL compiler supports regular expressions. For example, the following code inserts probes to all functions starting with device in files with names starting with hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTEGER @counter; TRACE [device\w*]() FROM [hardware\w*] EXECUTE {</head><p>@counter++; RECORD "Device driver called"+ counter + "\n" ; } As illustrated in this example, regular expressions make inserting a group of tracepoints much faster than manually instrumenting the source code.</p><p>Statement tracepoints: The second type of tracepoints inserts probes into specific source code statements. It is defined by a pair consisting of a line number and a file name. An example is shown as follows:</p><p>TRACE 236 FROM app.c EXECUTE { RECORD "Line 236 reached"; } In this example, the probe is inserted before the first instruction generated by code line 236 in the user file app.c. Compared to function tracepoints, statement tracepoints provide more flexible positioning.</p><p>Virtual tracepoints: The third type of tracepoints does not insert explicit probes. Instead, they are triggered by timers, either once or periodically, to perform specific actions. In the following example, we show how to record the value of a counter 100 times at a period of 100 seconds. Observe that TRACE is followed by a variable counter, instead of a function. No confusion will be introduced because unlike functions, variables are not followed with parentheses.</p><p>TRACE counter FROM app.c PERIOD 100s FOR 100 EXECUTE { RECORD counter; }</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Condition Predicates</head><p>The TraceSQL compiler also supports condition predicates with the WHERE keyword. A condition predicate can be constructed by logical operators such as AND, OR, and NOT. To illustrate their uses, we present an example that records all context switches triggered by radio transmissions. Here, the msend mutex variable in the library file radio.c is a flag that shows whether or not there is ongoing radio operation (if there is, the msend mutex is locked). We use the READ keyword to access memory variable values.</p><formula xml:id="formula_1">TRACE yield() FROM syscall.c EXECUTE { RECORD yield() ; } WHERE { READ msend-&gt;lock FROM radio.c == 1 }</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Tracepoint Actions</head><p>In this section, we describe the associated actions when tracepoints are reached. The RECORD keyword used in previous examples represents a logging action. Formally, TraceSQL supports the following three action categories: actions on declared variables, on memory variables, and on function invocations.</p><p>First, a tracepoint action may operate on declared variables. Consider that a user application does not keep track of the number of received packets and hence provides no visibility on network activity statistics. Without modifying the source code, we can write a TraceSQL program to gather such information by declaring additional variables. In the following example, we define such a variable, numOfPacket-sReceived, for this purpose. This variable is shared by two tracepoints, but no race conditions will be introduced because action statements are implicitly protected by atomic operators.</p><p>INTEGER @numOfPacketsReceived = 0; TRACE packetreceived() FROM user.c EXECUTE { @numOfPacketsReceived ++ ; } TRACE PERIOD 100s FOR REPEAT EXECUTE { RECORD @numOfPacketsReceived; @numOfPacketsReceived = 0; } Second, a tracepoint action may directly read/write RAM variables using keywords READ and SET. The values of these variables can be combined with other statements to perform complex actions. This has been illustrated in previous examples.</p><p>Finally, a tracepoint action may directly invoke functions provided by the operating system or user applications. In TraceSQL, these actions start with the keyword INVOKE. The following example shows how to blink the LED every time a packet is received. The greentogglefunction() is located in the syscall.c file that toggles the green LED.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">IMPLEMENTATION</head><p>We implement DT on the LiteOS operating system for the MicaZ platform running the Atmega128 processor. In this section, we first describe the execution model of LiteOS, then we describe the details of tracepoint instrumentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Execution Model of LiteOS</head><p>LiteOS supports separate compilation of the kernel and user applications. Initially, only the LiteOS kernel is installed. It then loads more applications into memory according to users' needs. The kernel and user applications are bridged by system calls, a special type of function pointers. Multiple user applications can be loaded simultaneously, running as individual threads. As AVR processors provide separate program space (flash) from the data space (RAM), each thread in LiteOS owns a non-overlapping chunk of both the flash memory and the RAM.</p><p>Figure <ref type="figure" target="#fig_2">3</ref> shows how we implemented the DT system in the LiteOS environment. Each tracepoint engine (TE) is implemented as a stand-alone thread in LiteOS. It is loaded by the user using the interactive shell, where individual threads can be started or stopped separately. Hence, multiple TEs can be loaded concurrently or sequentially. When one TE terminates, it restores the applications it has instrumented to their original state, so that the normal execution of user applications will not be interrupted.</p><p>A tracepoint engine is compiled by the TraceSQL compiler. Implemented in Python, the compiler translates user programs from TraceSQL into C with equivalent semantics. To optimize memory variable operations, the compiler must be provided with memory addresses of the applications. Such information is provided by the .lss files generated from user applications.</p><p>As output, the TraceSQL compiler generates translated C programs that are ready to be compiled. We use GCC 4.1.1 in our experiments. If the RECORD command is used, the compiler also generates a customized trace interpreter for translating the collected traces into readable output.</p><p>Note that, our implementation description assumes that traces can be easily obtained at the end of the experiments using the file copy command supported by the LiteOS shell. This assumption is operating-system-dependent. On other operating systems where this command is not available, DT must also implement its own trace retrieval module. Such discussions are out of the scope of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">The Tracepoint Engine (TE)</head><p>This section describes the details of the Tracepoint Engine. As shown in Figure <ref type="figure" target="#fig_2">3</ref>, it consists of three modules: the configuration controller for setting up the environment, the tracepoint controller for instrumenting tracepoints, and the action handler for triggered actions.</p><p>The first module, the configuration controller, sets up the operating environment. In this part, it opens files for trace output in the LiteOS file system (LiteFS). LiteFS is a hierarchial file system that provides Unix-like operations on the external flash available on the motes. For MicaZ, the size of the flash is 512K bytes. To reduce writing operations, TE also keeps an internal buffer to temporarily store traces. The remaining two modules are more complicated, and we describe them separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Tracepoint Instrumentation</head><p>Tracepoint instrumentation is based on dynamic instrumentation, a technique that modifies application binary code at runtime. On MicaZ, DT relies on the binary rewriting capability of the Atmega128 processor to modify application binaries. It inserts branch instructions into specified locations of original user application binaries as tracepoint portals. The displaced user application instructions are mirrored in the action handlers. Note that, the displaced instructions cannot contain destinations of other branch instructions in the original application. Otherwise, the correct execution of the original application can no longer be enforced (another branch instruction could jump to the middle of the tracepoint portal, causing unexpected errors). This limitation is typically not a problem, because the probability that one instruction being the destination of another branch instruction is measured to be very low. In our benchmark application used later, for instance, the probability is 0.76% (38 instructions are branch destinations in around 5000 instructions). Such destinations of branch instructions are identified and avoided by the TraceSQL compiler.</p><p>We next describe the implementation of different types of tracepoints.</p><p>Function and Statement Tracepoints Figure <ref type="figure" target="#fig_3">4</ref> shows an example of inserting a tracepoint into a sequence of instructions. For clarity, we organize the whole instrumented code into 14 parts. They are described in detail as follows.</p><p>Part 1 is the original binary code (in assembly form), taken from the greenToggle() function. After binary instrumentation, these instructions are replaced with a tracepoint portal, shown in part 2. These new instructions first save registers in part 2, then branch to the system call gate in part 3. Parts 3 through 5 check if a tracepoint handler is present, and lead to its handler. Part 6 through part 13 are the core parts of the tracepoint handler, where mixed C and assembly code is used to explain its logic.</p><p>At the beginning of part 6, observe that the TE has executed several branch instructions in parts 2, 3, and 5. Each branch instruction pushes a return address onto the stack. Also, the contents of several registers have been modified after they are saved onto the stack. To enforce the correct semantics of the original program, both the stack contents and the register values have to be restored. Parts 6 and part 7 perform these actions, modifying the stack pointer, restoring registers, and saving the program counter to a variable regsource.  This variable regsource is useful in two ways. First, regsource differentiates between tracepoint origins. This is needed because TE uses one single handler for all function and statement tracepoints. To map each origin to the right action, TE relies on the value of regsource, which has been set as the program counter before the first icall instruction in part 2. Second, regsource allows the instruction flow to return to the original after the action handler, as shown in parts 12 and 13.</p><p>At the end of part 7, the modified registers and the stack pointer have been restored. The mirrored instructions can therefore be safely executed in part 8.</p><p>Parts 9, 10, and 11 perform the handler actions. Here TE optionally uses a macro SWAP_STACK_PTR() to switch the stack pointer back and forth between the kernel stack and the thread stack. If the original tracepoint is located in a thread, the macro is activated, as is illustrated here. The reason is that the thread stack of user applications in LiteOS is typically compact, and directly executing the action handler may cause stack overflows, especially if complicated actions are involved. Switching to the kernel stack helps solve this problem.</p><p>Note that, even with SWAP_STACK_PTR(), TE still pushes more variables onto the stack in part 2 through 6 than the unmodified application. In general, TE requires 12 bytes of extra data space to work well. Therefore, if a thread has consumed almost all of its stack space, stack overflow may occur. In our experiments, however, we did not observe this problem because by default, LiteOS allocates more stack than minimum for user applications.</p><p>One note on TE is that the mirrored instructions in part 8 can swap with parts 9, 10, and 11, so that the action can also be performed before the mirrored instructions. This feature is useful for implementing the BEFORE_PROLOGUE keyword, where the actions have to be executed before the displaced prologue section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System Call Gate and Virtual Tracepoints</head><p>DT allows tracepoints to be positioned in system call gates of LiteOS. The system call gates are a table of function pointers through which applications access kernel functionalities. Each system call gate strictly uses 4 bytes. Because of this limitation, the approach described in Figure <ref type="figure" target="#fig_3">4</ref> cannot be applied, as it requires 7 instructions to be modified at the tracepoint portal.</p><p>We follow a different approach for system call instrumentation, based on the observation that the total number of system calls in LiteOS is fewer than 80, and their implementation is known. Here, we implemented an instrumented set of system call gates that resides entirely in the TE. We then rewrite the original system call gates by only modifying the call instructions to point to the instrumented version, so that the system calls are diverted to tracepoint handlers. A different implementation is needed for virtual tracepoints. Such tracepoints are triggered by timers instead of user applications. Instead of binary instrumentation, for every virtual tracepoint, we set up a callback function that invokes action handlers when the timer fires. The timer can be either one-time or periodic depending on the TraceSQL program.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Action Handlers</head><p>We next describe two techniques to implement more complicated actions: stack shuffling and loop compression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stack Shuffling Techniques</head><p>As illustrated in Table <ref type="table" target="#tab_0">1</ref>, TraceSQL provides two functions: push_integer() and pop_integer(). Operating directly on the stack, they are unusual in that they explicitly modify the stack content, hence breaking the transparency of the tracepoint handler. So what is the whole point of their existence?</p><p>We find two occasions when pushing and popping operations are useful: before prologues and after epilogues. For example, the StackGuard debugging tool checks the return address of functions at these two locations. TraceSQL provides two GCC-dependent keywords, BEFORE_PROLOGUE and AFTER_EPILOGUE for these needs.</p><p>However, supporting the push and pop functions is not trivial. After the stack content is changed, all registers must be restored to their original values. Otherwise, the application logic will be broken. To this end, we developed a technique called stack shuffling. The details of stack shuffling are shown in Figure <ref type="figure" target="#fig_4">5</ref>.</p><p>The implementation of the push_integer() function consists of four steps. First, it pushes registers that are used later onto the stack. Notice it pushes R31 and R30 twice, so that there is extra stack space reserved for the integer VAR (assumed to be two bytes). Then, the parameter VAR is saved to this reserved space with the help of a pointer. Finally, the registers are restored except for the space occupied by VAR, then the push_integer() operation finishes.</p><p>The implementation of the pop_integer() function is similar, except that it reads the VAR variable rather than saves it. After VAR is read, the stack is shuffled by moving stored registers by two bytes while preserving their relative order. Finally, registers are restored and the pop_integer() function finishes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loop Compression</head><p>Loop compression optimizes the RECORD operation. In one extreme case, if an event A is logged for 100 times, it should be written as "A for 100 times" instead of writing 100 As repeatedly. The loop compression technique extends this observation by compressing the data stored in the buffer periodically before they are written into an external file. This technique works best for large internal buffers, such as 256 bytes or 512 bytes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Implementation Notes</head><p>In our implementation of tracepoints, we made several tradeoffs. To ensure that the implementation of TE is generic instead of compiler-dependent, we focus on global variable operations in tracepoint actions. The addresses of these variables are obtained by parsing the generated assembly code. For local variables, on the other hand, it is still possible to obtain their values through a pair of pop and push stack operations. However, TE does not automate this process because in that case, extensive and compiler-dependent analysis on the contents of the stack is required. Such an analysis cannot be ported across compilers easily, in contrast to the way TE handles global variables. For the same reason, TE does not address complexities introduced by compilerspecific optimizations. For instance, it is possible to read out-of-date values for variables that have been temporarily cached by registers. This problem, however, can usually be prevented by carefully selecting tracepoint locations (e.g., at the beginning of functions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EVALUATION OF DT OVERHEAD</head><p>In this section, we evaluate the overhead of DT. We focus on three metrics: slowdown in CPU cycles, memory overhead, and flash lifetime. The details of our experiment settings are shown in Table <ref type="table" target="#tab_5">3</ref>, where we carry out all experiments on the LiteOS operating system with MicaZ nodes.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">CPU Slowdown</head><p>In DT, new binary code is dynamically weaved into application code at runtime. By analyzing the generated assembly code, we identify that each blank tracepoint (i.e., one without any triggered actions) adds 282 CPU cycles. On MicaZ, this consumes 36 microseconds. The overhead of adding multiple tracepoints is usually tolerable. In one of our later examples where 10 tracepoints are added, each triggered 20 times per second, theoretically, an aggregate overhead of around 0.7% of CPU time is introduced, without considering the effect of their associated actions.</p><p>To profile the slowdown impact of tracepoints, we use a simple timer-driven radio message generator as the benchmark application in this evaluation. This application sends out radio messages at a frequency of 20 messages per second. The complete experimental settings are shown in Table <ref type="table" target="#tab_5">3</ref>.</p><p>To measure the slowdown effect, we designed a CPU idleness parameter (CIP) metric as follows. We modified the LiteOS kernel by adding a loop counter in its main (idle) loop that runs when no tasks or threads are scheduled. When the loop is executed, the counter is increased monotonically while the CPU is idle. Its value is periodically collected through the USART port. The difference in counter readings between two collection instants (i.e., the difference within a period) reflects the amount of idle time of the CPU within one period. The percentage of reduction for this value can be used to estimate CPU overhead.</p><p>In the first experiment, we added 1 to 15 tracepoints to the message generator application. We set the size of the file output buffer to 256 bytes. We used the CIP value when no applications are running as the baseline. We then started the application under evaluation, instrumented it with tracepoints, and measured the new CIP value. We plotted the percent of decrease compared to the baseline in Figure <ref type="figure" target="#fig_5">6</ref>.</p><p>Observe that the message generator consumes around 10% of CIP when no tracepoint is inserted (denoted as 0 on the X axis). As more tracepoints are added, CIP decreases. The average progressive decrease of the CIP counter with each blank tracepoint is 0.0852%, slightly higher than the theoretical 0.072% value based on our earlier analysis. This is expected, because (due to other computations such as the kernel timer) the baseline value of the CIP counter represents less than a 100% idle CPU.  To evaluate the slowdown of tracepoints when actions are performed, we measured three cases: when the tracepoint handler reads a 16-bit memory variable, when it writes a 16-bit memory variable, and when it logs a 16-bit variable into an external file. The performance in the former two scenarios is similar to that of blank tracepoints, which is reflected by Figure <ref type="figure" target="#fig_5">6</ref>. The performance in the last case is significantly different, and is shown separately in Figure <ref type="figure">7</ref>. The reason is that file operations consume many more CPU cycles compared to reading/writing memory variables. For file operations, because of the internal buffer, the measured CIP fluctuates. Hence we plot 95% confidence intervals in Figure <ref type="figure">7</ref>. Observe that in the extreme case, when each of the fifteen tracepoints writes one variable to the file (encoded to 6 bytes), the number of idle CPU cycles drops by almost 70%. For practical applications, however, we rarely log so many variables at once, hence the performance impact is smaller.</p><p>In the second experiment, we evaluated the impact of kernel tracepoints. We inserted tracepoints to all system calls, as well as to the radio-sending function in the kernel. The same message generator application is used as the benchmark. As tracepoints are triggered, TE logs either the system call, or the radio sending function. We chose different sizes of file buffers, including 128 bytes, 256 bytes, and 512 bytes. Figure <ref type="figure" target="#fig_6">8</ref> shows the impact of tracepoints with 95% confidence intervals. Observe that, as the buffer size increases, the impact on CPU decreases because file I/O operations are better aggregated. At the end of the experiment, we retrieved the files generated and obtained a complete trace of system calls and radio operations. Table <ref type="table">4</ref> shows one loop in the translated traces, revealing the interactions between the kernel and the user application. Such information provides us with rich details on the behavior of the software stack for debugging purposes. For example, one step in our analysis of the third bug in Section 8.3 is based on such captured details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Memory Overhead</head><p>In this section, we evaluate the memory overhead of tracepoints. This includes both program flash consumption and RAM consumption. We measured both metrics with the benchmark application. In this experiment, we turned on the -O3 level of optimization, and enabled full program optimization in the GCC compiler. Regardless of how many tracepoints are inserted, the RAM overhead remains constant, because we only use one tracepoint handler for each TE. The RAM usage for blank tracepoints is measured to  be 42 bytes, and for file logging tracepoints 332 bytes, both of which under 10% of the available RAM of MicaZ. Therefore, we consider this overhead to be usually tolerable. For flash usage, we plot our measurement results in Figure <ref type="figure" target="#fig_8">9</ref>.</p><p>As illustrated in this figure, the overhead of compiled code size increases with the number of tracepoints inserted, but is consistently less than 4K bytes, or 3% of the flash available on MicaZ nodes. Therefore, we conclude that the overhead introduced by tracepoints is generally acceptable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Flash Lifetime</head><p>There are two types of flash lifetime. The first is related to the serial flash used as the file system. Each MicaZ node has 512K bytes of flash memory. Hence, if too much data are written, the flash will be exhausted. In the previous file logging example, each variable is encoded into 6 bytes. Therefore, one tracepoint generates 0.12K bytes of data per second at the chosen frequency. If 15 tracepoints are added, the serial flash will be exhausted in about 280 seconds. In reality, developers should either limit the amount of logging activities, or attach a larger flash to the node <ref type="bibr" target="#b17">[18]</ref>.</p><p>Another flash lifetime parameter is related to the flash memory. On MicaZ, the reprogrammable flash has a lifetime of 10,000 write/erase cycles. Therefore, the total number of debugging rounds for the same application is limited. This is usually not a problem, and in extreme cases, the developer may change memory settings of the compiled programs to balance program flash operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">TRACESQL EXPRESSIVENESS</head><p>To highlight the expressiveness of DT and TraceSQL, we show that they can provide the core functionality of several previous debugging techniques. The details of these  techniques are introduced in Section 2. However, these techniques are by no means an exhaustive coverage of the potential of DT/TraceSQL. For EnviroLog, NodeMD, and Stack-Guard, we implement their core functionality while leaving out less relevant details. For Sympathy, because it is designed in the context of a larger project (ESS), we only briefly outline how it can be expressed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">EnviroLog</head><p>We implemented the core functionality of EnviroLog with TraceSQL. Specifically, we selected the OscilloscopeRF application in the EnviroLog 1.0 distribution as the benchmark application (EnviroLog 1.0 contains two examples, the other one is the relatively simple application Blink). We implemented and instrumented this application in LiteOS, and our main program is named OscilloscopeRF.c. This file invokes the read_sensor() function to get readings. It is located on line 61, shown as follows. reading = read sensor();</p><p>In EnviroLog, the return value of the function should be captured so that it can be replayed later. We use a statement tracepoint on the following line to implement the record and replay service of EnviroLog as follows. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5: EnviroLog Implementation Comparison</head><p>Table <ref type="table">5</ref> shows the comparison results of the TraceSQL version of EnviroLog and the original version in terms of compiled code size. Note that, because of the programming paradigm differences between TinyOS (for EnviroLog) and LiteOS (for TraceSQL), the compiled applications have very different sizes. TinyOS compiles applications together with its kernel into a monolithic binary image, whereas LiteOS compiles applications independently of its kernel. Another difference is that EnviroLog supports Mica2. In contrast, TraceSQL currently only supports MicaZ.</p><p>We chose two less platform-dependent metrics to make meaningful comparisons, the lines of code written by the user, and the increase in the number of code bytes because of EnviroLog. Arguably, these two metrics should be less platform-dependent (because EnviroLog does not directly implement drivers) and less operating-system-dependent (because we are only considering the increase in bytes).</p><p>For this particular example, the user of original EnviroLog needs to write one line of code, whereas in TraceSQL, a total of 14 lines of code is needed. Note that the TraceSQL version requires less memory in part because it leverages the file system abstraction provided by LiteOS, while the original En-viroLog implementation has to address EEPROM and serial flash operations at a lower level. Another reason is that the TraceSQL version does not need to implement interactive actions, as they are already provided through the LiteOS Original Implementation of NodeMD (published in Table <ref type="table">2</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">NodeMD</head><p>NodeMD detects stack overflows and potential livelocks or deadlocks. The stack overflow problem occurs when the stack collides with the allocated variables (i.e., the .bss section). While stack estimation tools exist, they are not always accurate, and hence runtime stack overflow protection is still needed. When a procedure is called, the stack pointer is modified because of three components: the call overhead such as the return address, the passed parameters, and the local data for the function being called. Because the GCC compiler first modifies the stack pointer before using stack memory, NodeMD detects stack overflows by inserting a check code at the start of a function, reading the pre-incremented SP pointer, and comparing this pointer to the stack top (i.e., the end of the .bss section). If the SP pointer collides with the latter, a stack overflow is detected.</p><p>In our implementation of NodeMD with DT/TraceSQL, we focus on its ability to detect stack overflows and livelock/deadlocks. For its remaining features, its remote retrieval module can be provided by the data copy command in the LiteOS shell. Its application specific fault detection module is based on the ASSERT macro, and is supported by the LiteOS programming environment. Therefore, we do not address these two modules in our expressiveness study.</p><p>DT follows a runtime modification approach to implement the stack overflow detection of NodeMD, where it inserts a probe immediately before the first line of a function, but after the prologue generated by GCC, so that the stack pointer has been pre-incremented. When the probe is triggered, TE checks whether the SP pointer has reached the stack top. For example, for a function foo() from the file app.c, we develop the following code.</p><p>INTEGER @currentsp; //The stack top for a thread is a known constant INTEGER @stacktop = ...; TRACE foo() AFTER PROLOGUE FROM app.c EXECUTE { @currentsp = getsp(); IF @currentsp &lt;= @stacktop BREAK; }</p><p>The second problem that NodeMD addresses, livelocks and deadlocks, is solved by adding source code checkpoints that registers with the kernel regularly if the thread is alive. NodeMD argues that for most threads, a timeout value can be estimated. The thread is expected to reach its checkpoint during each timeout period. Hence, if the thread fails to reach the checkpoint for much longer than timeout, the kernel assumes that this thread has reached a deadlock or livelock state.</p><p>In TraceSQL, the NodeMD approach to check deadlocks or livelocks can be appropriately implemented using virtual tracepoints. In the following example, TE adds a checkpoint to the foo() function in the file app.c (which is already running) as shown below. Note that, the BREAK keyword can optionally take the name of the thread, assumed to be app, as its parameter.</p><p>INTEGER @checkpointreached; //The timeout is known for this thread. LONG @timeout = ...; TRACE foo() FROM app.c EXECUTE { @checkpointreached = 1; } TRACE PERIOD @timeout*3 FOR REPEAT { IF (@checkpointreached == 1) @checkpointreached = 0; ELSE BREAK app; } Similar to EnviroLog, we use the lines of code written by the user and the memory footprint as metrics to evaluate our implementation of NodeMD with TraceSQL. Because NodeMD source code is currently not publicly available, we refer to the data reported in its original paper. We also use its examples, where two applications are measured. One is blink_led, which uses a single thread to periodically toggle an LED, and the other is FireWxNet, a multi-tiered monitoring application. We only implemented the first one, and instrumented the blink_led application with the TraceSQL version of NodeMD. As illustrated by the comparison results in Table <ref type="table" target="#tab_9">6</ref>, the overhead introduced by TraceSQL is measured to be lower than that of NodeMD. This is probably due to that we only implemented the core features of NodeMD, while leaving out several functionalities that are already implemented in LiteOS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">StackGuard</head><p>We introduced the mechanism of StackGuard in Section 2. The implementation of StackGuard in TraceSQL takes 15 lines of code, as shown in Table <ref type="table">2</ref>. The evaluation results of StackGuard are shown in Table <ref type="table" target="#tab_11">7</ref>, where the memory footprint with 1, 5, 10, 20, and 50 functions instrumented is presented. Because the original version of StackGuard does not support the AVR-GCC compiler used for MicaZ, no comparison between the TraceSQL version of StackGuard and the original version is made.</p><p>We also designed one improvement over StackGuard without using the canary word. Observe that any return address cannot be zero. Hence, our improved method also checks the return address in each probe for such invalid numbers that will crash the node. This approach turns out to be very useful in one of our case studies to locate a bug in the LiteOS kernel, as shown in Section 8.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Sympathy</head><p>Because Sympathy is designed for ESS, we have not implemented its functionality. Instead, we only present a brief overview on how the metric collection subsystem of Sympathy could be expressed with TraceSQL. Table <ref type="table" target="#tab_12">8</ref> shows the types of metrics that are collected by Sympathy. To   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">CASE STUDIES</head><p>One of the most convincing ways to evaluate the effectiveness of a debugging system is to use it to find real bugs. In this section, we present three case studies. In the first two cases, we use the DT to retroactively test existing applications with documented bugs. In the third case, we describe our experiences using DT to debug a routing protocol that we developed for the communication stack of LiteOS.</p><p>The motivating question we want to answer in the first two case studies is, could DT have detected any documented old bugs if it were available? We obtained the full documented bug list of the LiteOS operating system from October 2007 to March 2008, when it evolved from version 0.2 to 0.3, and used them to test DT software. Note that, all these bugs had been fixed by the time we tested them with DT. Therefore, we knew the causes of the bug in advance when we did the following tests. This, however, does not prevent us from gaining insight into the strength and limitations of the DT system as a debugging tool.</p><p>We focus on a subset of difficult bugs that are related to memory. They share the commonality that while the symptom is obvious, it is unclear what variables to watch or where breakpoints should be set. It would be great if the DT system could identify the source of these bugs with less time and effort.</p><p>Among the nine difficult memory bugs documented (difficulty measured by the time to fix them), we identified two bugs that could have been solved using DT/TraceSQL. This relatively low coverage ratio is primarily caused by the diversity of the bugs, ranging from erroneous pointer dereferences to stack overflows, most of which simply fall outside the scope of DT. For those bugs not caught by DT, they can be found by more conventional methods such as the built-in interactive debugger of LiteOS. For the two bugs that are caught, each took more than one day to solve originally without DT. In contrast, it took less than two hours to develop, debug, and identify the root cause using TraceSQL scripts. This improvement demonstrates the benefits and effectiveness of the DT system.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Bug I: Node reboot after changing the compiler optimization level</head><p>The first bug has the following symptom. When the LiteOS kernel is compiled with -Os (optimization for size) instead of -O0 (no optimization), the node repeatedly reboots itself. Since the kernel invokes many functions in its startup stage, it took a considerable effort to pinpoint the exact buggy function.</p><p>To use DT to analyze this bug, our guess is that reboots are usually caused by stack corruptions. Using StackGuard is therefore promising. However, the original version of StackGuard fails to catch this bug. We then tried our improvement that only checks the return address. This time, the bug is caught. The function lite_switch_to_user_thread, shown in the following table, is identified as trying to return to a zero address. Technically, this function performs context switches. In this sense, it does not return to its caller. When -O0 is used, the assembly code generated for this function first pushes registers R28 and R29 into the stack. When -Os is used, however, the compiler detects that such two pushes are not necessary, and removes them to generate compact code. However, as shown in lines 7, 8, and 9 of the program, the number of registers to be popped when the context switch occurs is pre-calculated. When two pop instructions are removed, when the context switch occurs for the first time, the stack of the user thread is of the wrong size. Hence, the return instruction at line 11 leads to address 0x00, and reboots the node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Bug II: User applications put into MEM-ORY_CORRUPTED state once executed</head><p>The second bug appeared when during one LiteOS kernel update. The symptom was that after this update, any application, once loaded by the kernel, was quickly put into MEMORY_CORRUPTED state. Further investigation shows that the kernel puts threads into this state only if the thread appears to be occupying an incorrect chunk of RAM or program flash. This checking procedure is based on reading the thread control block. If the allocation has conflicts with the kernel or other threads, the thread is immediately put into error state. Consequently, the problem is, what caused every thread to have incorrect control block values?</p><p>This bug is difficult to solve because the user application appears to be doing nothing wrong. Analysis of the source code does not lead to anything. The bug was later detected with assembly-level analysis.</p><p>This bug could have been solved faster with the DT system. In our experiments, we instrumented each function of the user application with a tracepoint that checks whether the thread control block in question has been illegally modified. We used a simple Blink application as the test case, and the instrumented code still triggered the same bug. Hopefully, this approach allows us to localize the problem to the function level so that the search scope is reduced significantly. To accurately pinpoint the function, the tracepoints were inserted after the epilogue section of each function.</p><p>With DT deployed, the bug was found immediately. It turned out the control block of threads is modified by the following function, which is intended to put the current thread into sleep mode. Further investigations reveal that the unintended modification is caused by a mismatch between the thread control block declaration in the kernel and in user applications. During the kernel update, the thread control block in the kernel is updated with additional member variables. On the application side, however, an old, inconsistent version of the thread control block structure is used. When the statement 4 in the above function changes the structure member variable state of the control block, it mistakenly modifies the variables that represent the RAM allocation information, because it calculates the offsets incorrectly. Therefore, the thread is blocked and put into the MEMORY_CORRUPTED state as soon as the kernel takes over.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Bug III: Unexpected corruption of communication protocol neighbor table</head><p>The third bug is related to our development of routing layer protocols in the LiteOS environment. Here, communication protocols are developed as stand-alone files that are running as individual threads. In our development phase, we attempted to evaluate the performance of multiple protocols by comparing their delivery ratio. However, when nodes switch from the first protocol (geographic forwarding) to the second (logical coordinate based routing, or LCR <ref type="bibr" target="#b4">[5]</ref>), the neighbor table of the second protocol sometimes gets corrupted with incorrect values. This symptom is relatively rare, making it hard to pinpoint the exact source of the bug.</p><p>We first used the interactive debugger of the LiteOS shell to monitor the neighbor table contents. This approach was not successful, because we can only detect the bug after the neighbor table has been incorrectly modified. Once this happens, the LCR protocol fails to operate correctly. We later decide to automate the bug capture process with TraceSQL. Specifically, we check whether the neighbor table has been corrupted at the end of several functions that we consider might have introduced the bug, by reading neighbor table contents and checking their validness in TraceSQL. To correlate the incorrect modifications with their origins, we also use TraceSQL to capture the traces of system calls, a technique we introduced earlier in Section 6.1.</p><p>By analyzing the traces we collected, we identified that the bug symptom is closely correlated with the event of receiving neighbor beacon packets sent by a node running the geographic forwarding protocol. This is normal because nodes do not switch from the first protocol to the second simultaneously. As such a packet arrives, the TE running on the node that has switched to LCR immediately detects that its own neighbor table is incorrectly modified. This insight allows us to pinpoint the exact location of the bug, and solves the problem.</p><p>Technically, this bug is introduced by the fact that different communication protocols in LiteOS are differentiated through their port numbers, which are registered by each protocol with the kernel. A callback function is associated with the unique port number of each protocol to perform tasks such as updating the neighbor table. In the failed experiments, after the geographic forwarding protocol process is terminated, its registered callback function is not properly removed as the protocol neglects to de-register itself with the kernel. This problem causes the bug. When a neighbor beacon arrives for the geographic forwarding port, the registered callback function for this port is still invoked. As the two protocols are compiled in such a way that only their RAM allocation overlaps, the binary code of the previous protocol still resides in the program flash, whose execution modifies the RAM locations that are currently occupied by the new protocol. Thus, the neighbor table contents of the latter are incorrectly modified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">CONCLUSIONS AND FUTURE WORK</head><p>This paper proposes the declarative tracepoint debugging system, the first comprehensive system that allows applicationindependent and programmable tracepoints to be inserted and removed at application runtime for wireless sensor networks. We demonstrate that its programming language, TraceSQL, is expressive enough to implement the core func-tionality of a variety of debugging techniques in the literature, such as EnviroLog, NodeMD, Sympathy, and Stack-Guard. We also demonstrate the effectiveness of the DT system through a series of case studies based on the LiteOS operating system, and demonstrate that it is feasible to use TraceSQL to detect these otherwise difficult bugs.</p><p>In future work, we plan to investigate implementing distributed tracepoints, and use the DT system to diagnose new bugs. Such explorations will help us obtain better understanding on the strength and limitations of the DT debugging system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overall System Architecture of Declarative Tracepoints</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The Use of Canary Words in StackGuard</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: System Architecture for Declarative Tracepoints on LiteOS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Implementation for Dynamic Tracepoint Instrumentation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Implementation of Push and Pop Functions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Tracepoints Slowdown by Memory Operations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Tracepoints Slowdown with Different Buffer Sizes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Partial output from the trace interpreter (one complete loop): The kernel or app thread has event:\ RADIO SEND OPERATION KERNEL Thread 2 has event: RESTORE RADIO STATE Thread 2 has event: MUTEX UNLOCK FUNCTION Thread 2 has event: GET CURRENT THREAD ADDRESS Thread 2 has event: YIELD FUNCTION Thread 2 has event: GET RADIO MUTEX ADDRESS Thread 2 has event: GET CURRENT THREAD ADDRESS Thread 2 has event: GET CURRENT RADIO INFO ADDR Thread 2 has event: GET CURRENT THREAD ADDRESS Thread 2 has event: GET CURRENT THREAD INDEX Thread 2 has event: SOCKET RADIO SEND FUNCTION Thread 2 has event: GET CURRENT THREAD ADDRESS Thread 2 has event: YIELD FUNCTION The kernel or app thread has event:\ RADIO SEND OPERATION KERNEL</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Memory Overhead</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 : Overview of TraceSQL Language Keywords</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">General</cell><cell></cell><cell>TRACE, FROM, EXECUTE, WHERE, EXIT</cell><cell>The basic format is TRACE { } FROM { } EXECUTE {} WHERE {.}.</cell></row><row><cell>Tracepoint</cell><cell>Tracepoint type declarations</cell><cell cols="2">Function tracepoints Statement tracepoints Virtual tracepoints</cell><cell>BEFORE_PROLOGUE, AFTER_PROLOGUE, BEFORE_EPILOGUE, AFTER_EPILOGUE, regular expressions N/A PERIOD, FOR, REPEAT</cell><cell>BEFORE_PROLOGUE inserts the probe before the prologue section of a f unction generated by GCC, AFTER_PROLOGUE the opposite, etc. N/A Set up the virtual timer period and the number of times it will be triggered.</cell></row><row><cell>declaration</cell><cell cols="3">Condition predicates</cell><cell>AND, OR , NOT</cell><cell>Define complicated predicates.</cell></row><row><cell>statements</cell><cell></cell><cell cols="2">Generic</cell><cell>RECORD, LOAD, INTO, AS</cell><cell>Operate files in the LiteFS file system.</cell></row><row><cell></cell><cell>Tracepoint</cell><cell cols="2">On memory variables</cell><cell>READ, SET</cell><cell>Read and write memory variables.</cell></row><row><cell></cell><cell>actions</cell><cell cols="2">On invoking functions</cell><cell>INVOKE</cell><cell>Invoke a function.</cell></row><row><cell></cell><cell></cell><cell cols="2">On thread operations</cell><cell>TERMINATE, BREAK</cell><cell>Control threads.</cell></row><row><cell></cell><cell cols="2">Stack operations</cell><cell></cell><cell>pushinteger(), popinteger(), getsp()</cell><cell>Push and pop integers to and from the stack, and read the stack pointer.</cell></row><row><cell>Built-in functions</cell><cell cols="3">Number operations</cell><cell>getRand()</cell><cell>Return a random number.</cell></row><row><cell></cell><cell cols="3">Memory operations</cell><cell>readMem(), writeMem()</cell><cell>Read and write memory locations directly.</cell></row><row><cell cols="3">Caller Stack Context</cell><cell cols="2">The canary word is checked every time</cell></row><row><cell>Stack</cell><cell>Ret Address</cell><cell></cell><cell cols="2">the function returns</cell></row><row><cell>growth</cell><cell>Canary Word</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Old Stack Pointer</cell><cell cols="2">The local variables may overwrite the return address</cell></row><row><cell cols="2">Local Variables,</cell><cell></cell><cell cols="2">and the canary word.</cell></row><row><cell cols="2">Buffer, etc.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>TraceSQL also provides several built-in functions, as illustrated in Table1, including stack operations, number operations, and memory operations. The detailed descriptions are skipped because they are self-explanatory.</figDesc><table><row><cell></cell><cell cols="2">Base Station PC</cell><cell></cell><cell></cell></row><row><cell>a.tsql b.tsql</cell><cell cols="2">LiteOS Shell State TraceSQL Compiler Processor Tracepoint Engine Binary Session Data Cache Command</cell><cell>Network</cell><cell>LiteOS Kernel Declarative Tracepoint Engine Apps User Configuration Controller Tracepoint Controller Sensor Node Action Handler Environment Add Tracepoints Settings Tracepoints Triggered</cell><cell>File System Other nodes</cell></row><row><cell></cell><cell cols="2">User Environment</cell><cell></cell><cell>System calls</cell></row><row><cell>Output</cell><cell>Trace Interpreter</cell><cell>Traces</cell><cell></cell><cell>Node Side Software</cell></row><row><cell cols="3">User Side Interactions</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>TRACE packetreceived() FROM user.c EXECUTE {</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>INVOKE greentogglefunction() FROM syscall.c;</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>}</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 : Tracepoint Evaluation Settings</head><label>3</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Tracepoints Slowdown by File Operations</head><label></label><figDesc></figDesc><table><row><cell>unter Decrease CIP Cou</cell><cell>30 00% 40.00% 50.00% 60.00% 70.00% 80.00% 10.00% 20.00% 30.00%</cell><cell cols="3">Tracepoint/Write Memory Variable to File</cell></row><row><cell></cell><cell>0.00%</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Number of Inserted Tracepoints</cell></row><row><cell>35.00% 40.00% Figure 7: 0.00% 5.00% 10.00% 15.00% 20.00% 25.00% 30.00% CIP Counter Decrease</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">No Tracepoint Tracepoint/No</cell><cell>Tracepoint/File</cell><cell>Tracepoint/File</cell><cell>Tracepoint/File</cell></row><row><cell></cell><cell></cell><cell>Action</cell><cell>Logging with</cell><cell>Logging with</cell><cell>Logging with</cell></row><row><cell></cell><cell></cell><cell></cell><cell>128 Bytes</cell><cell>256 Bytes</cell><cell>512 Bytes</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Buffer</cell><cell>Buffer</cell><cell>Buffer</cell></row><row><cell></cell><cell></cell><cell cols="3">Experiment Scenario</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>NodeMD Implementation Comparisonshell. The original EnviroLog implementation, in contrast, provides additional commands such as START_RECORD and START_REPLAY, thus requiring a larger memory footprint.</figDesc><table><row><cell>of [14])</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 : Implementation of StackGuard</head><label>7</label><figDesc></figDesc><table><row><cell>Types</cell><cell>Metric Details</cell></row><row><cell>Connectivity Metrics</cell><cell>Routing Table Neighbor List</cell></row><row><cell></cell><cell>Packets Transmitted</cell></row><row><cell></cell><cell>Packets Received</cell></row><row><cell>Flow Metrics</cell><cell>Sink Packets Transmitted</cell></row><row><cell></cell><cell>Sink Packets Received</cell></row><row><cell></cell><cell>Sink Last Timestamp</cell></row><row><cell></cell><cell>Node Uptime</cell></row><row><cell>Node Metrics</cell><cell>Bad Packets Received</cell></row><row><cell></cell><cell>Good Packets Received</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>Sympathy Metricsdemonstrate how they can be implemented in TraceSQL, we summarize their potential implementation in Table9.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 9 : Expressing Sympathy Metrics with TraceSQL</head><label>9</label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>TraceSQL also provides function APIs to modify the application stack under special scenarios, as described in Section 5.2.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>.<ref type="bibr" target="#b1">2</ref> The dynamic instrumentation may still cause heisenbugs, which change or disappear once the debugger is deployed. We attempt to minimize such effect by reducing the memory footprint of the DT system.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We gratefully acknowledge the anonymous reviewers and our shepherd, Kay Rmer, for their insightful comments. This paper is supported in part by NSF grants CNS 05-54759, CNS 06-15318, CNS 06-26342, and CNS 06-26825, and a fellowship from Vodafone Foundation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="http://www.atmel.com/dyn/products/tools-card.asp?tool-id=2737" />
		<title level="m">Mature AVR JTAG ICE</title>
		<imprint/>
		<respStmt>
			<orgName>Atmel Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Design of matchbox, The simple filing system for motes</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gay</surname></persName>
		</author>
		<ptr target="http://www.tinyos.net/tinyos-1.x/doc/matchbox-design.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<ptr target="http://www.sun.com/bigadmin/content/dtrace" />
		<title level="m">The DTrace Homepage on Sun Microsystems</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Mantis OS: An embedded multithreaded operating system for wireless micro sensor platforms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bhatti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM/Kluwer Mobile Networks and Applications (MONET)</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>Special Issue on Wireless Sensor Networks</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Scalable logical coordinates framework for routing in wireless sensor networks</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Abdelzaher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Sensor Networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The LiteOS operating system: Towards Unix-like abstractions for wireless sensor networks</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Abdelzaher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stankovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IPSN</title>
		<meeting>IPSN</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Efficient memory safety for TinyOS</title>
		<author>
			<persName><forename type="first">N</forename><surname>Cooprider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Archer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Eide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Regehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SenSys</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">StackGuard: Automatic adaptive detection and prevention of buffer-overflow attacks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Walpole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bakke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Beattie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Grier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wagle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th USENIX Security Conference</title>
		<meeting>7th USENIX Security Conference<address><addrLine>San Antonio, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-01">Jan 1998</date>
			<biblScope unit="page" from="63" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Contiki -A lightweight and flexible operating system for tiny networked sensors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dunkels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gronvall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Voigt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Emnets-I</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">EmStar: A software environment for developing and deploying wireless sensor networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Girod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Elson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cerpa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stathopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Estrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Annual Technical Conference</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="283" to="296" />
		</imprint>
	</monogr>
	<note>General Track</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">System architecture directions for network sensors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szewczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hollar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Culler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ASPLOS-IX</title>
		<meeting>ASPLOS-IX</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The dynamic behavior of a data dissemination protocol for network programming at scale</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Culler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SenSys</title>
		<imprint>
			<date type="published" when="2004-11">November 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Aspect-oriented programming</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kiczales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lamping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mendhekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Loingtier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Irwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Confernece on Object-Oriented Porgramming</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">1241</biblScope>
			<biblScope unit="page" from="220" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">NodeMD: Diagnosing node-level faults in remote wireless sensor systems</title>
		<author>
			<persName><forename type="first">V</forename><surname>Krunic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Trumpler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MobiSys</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="43" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mate: A tiny virtual machine for sensor networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Levis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Culler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ASPLOS</title>
		<meeting>ASPLOS</meeting>
		<imprint>
			<date type="published" when="2002-12">December 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">TOSSIM: Accurate and scalable simulation of entire TinyOS applications</title>
		<author>
			<persName><forename type="first">P</forename><surname>Levis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Culler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SenSys</title>
		<imprint>
			<date type="published" when="2003-11">November 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Achieving repeatability of asynchronous events in wireless sensor networks with EnviroLog</title>
		<author>
			<persName><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Abdelzaher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stankovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE INFOCOM</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Capsule: An energy-optimized object storage system for memory-constrained sensor devices</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mathur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Desnoyers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ganesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Shenoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SenSys</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="195" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Abstractions for safe concurrent programming in networked embedded systems</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Mccartney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sridhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SenSys</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sympathy for the sensor network debugger</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kapur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Girod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Estrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SenSys</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="255" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Avrora: Scalable sensor network simulation with precise timing</title>
		<author>
			<persName><forename type="first">B</forename><surname>Titzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Palsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IPSN</title>
		<meeting>IPSN</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="477" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Design of an application-cooperative management system for wireless sensor networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tolle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Culler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeedings of EWSN</title>
		<meeting>eeedings of EWSN</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Visibility: A new metric for protocol design</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wachs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Levis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SenSys</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Clairvoyant: A comprehensive source-level debugger for wireless sensor networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Soffa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Selavo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Whitehouse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SenSys</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
