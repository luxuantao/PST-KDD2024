<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sub-sampled Newton methods</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Farbod</forename><surname>Roosta-Khorasani</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematics and Physics</orgName>
								<orgName type="institution">University of Queensland</orgName>
								<address>
									<settlement>St Lucia</settlement>
									<region>QLD</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Mahoney</surname></persName>
							<email>mmahoney@stat.berkeley.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution" key="instit1">ICSI</orgName>
								<orgName type="institution" key="instit2">UC Berkeley</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Sub-sampled Newton methods</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6A594E3AFCE310A29F5435D2EC750501</idno>
					<idno type="DOI">10.1007/s10107-018-1346-5</idno>
					<note type="submission">Received: 14 March 2017 / Accepted: 27 October 2018</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T05:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Newton-type methods</term>
					<term>Local and global convergence</term>
					<term>Sub-sampling Mathematics Subject Classification 49M15</term>
					<term>65K05</term>
					<term>90C25</term>
					<term>90C06</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For large-scale finite-sum minimization problems, we study non-asymptotic and highprobability global as well as local convergence properties of variants of Newton's method where the Hessian and/or gradients are randomly sub-sampled. For Hessian sub-sampling, using random matrix concentration inequalities, one can sub-sample in a way that second-order information, i.e., curvature, is suitably preserved. For gradient sub-sampling, approximate matrix multiplication results from randomized numerical linear algebra provide a way to construct the sub-sampled gradient which contains as much of the first-order information as possible. While sample sizes all depend on problem specific constants, e.g., condition number, we demonstrate that local convergence rates are problem-independent.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Consider the convex optimization problem</p><formula xml:id="formula_0">min x∈D∩C F(x) = 1 n n i=1 f i (x),<label>(1)</label></formula><p>where C ⊆ R p is a convex constraint set and D = n i=1 dom( f i ) is a convex and open domain of the strongly convex objective F. Many data fitting applications can be expressed as <ref type="bibr" target="#b0">(1)</ref> where each f i corresponds to an observation (or a measurement) which models the loss (or misfit) given a particular choice of the underlying parameter x, e.g., empirical risk minimization in machine learning including softmax classification, support vector machines, and graphical models, among many others. Many optimization algorithms have been developed to solve <ref type="bibr" target="#b0">(1)</ref>, <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b31">32]</ref>. Here, we consider the regime where n, p</p><p>1. In such high dimensional settings, the mere evaluation of the gradient or the Hessian of F can be computationally prohibitive. As a result, many of the classical deterministic optimization algorithms might prove to be inefficient, if applicable at all. In this light, faced with modern "big data" problems, there has been a great deal of effort to design stochastic variants which are efficient and inherit much of the "nice" convergence behavior of the original deterministic counterparts.</p><p>Many of these stochastic algorithms employ sub-sampling to speed up the computations. Within the class of first order methods, i.e., those which only use gradient information, there are many such algorithms with various kinds of theoretical guarantees. However, for second order methods, i.e., those that employ both the gradient and the Hessian information, studying the theoretical properties of such sub-sampled algorithms lags behind. In this paper, we provide a detailed analysis of sub-sampling as a way to leverage the "magic of randomness" in the classical Newton's method and study variants that are more suited for modern large-scale problems.</p><p>The common occurring theme in our approach is the high-probability and nonasymptotic convergence analysis. This is so since high-probability analysis allows for a small, yet non-zero, probability of occurrence of "bad events" in each iteration. Hence, the accumulative probability of occurrence of "good events" at all times becomes smaller with increasing iterations, and in fact is asymptotically zero for an infinite sequence of iterates. As a result, although the term "convergence" typically implies the asymptotic limit of an infinite sequence, here we consider non-asymptotic behavior of a finite number of random iterates and provide high-probability results on their properties. For example, we study whether, with high-probability, a finite set of random iterates generated by an algorithm approaches the solution of (1) and, if so, at what rate. Henceforth, we use the term "convergence" loosely in this sense.</p><p>Under such an analytic framework, our theoretical results are delivered in two stages. At first, we take a "coarse-grained" approach and provide a variety of conditions under which the convergence is global, i.e., random iterations are guaranteed to converge, with high-probability, to the solution of (1) starting from any initial point. In the second stage, we zoom-in and employ a "finer-grained" approach to study nonasymptotic local convergence of these sub-sampled methods, i.e., when the initial iterate is chosen in a neighborhood "close enough" to the solution of (1). This is so since the theoretical appeal of many second-order methods mainly lies in their local convergence behaviors, e.g., local quadratic convergence of the classical Newton's method. Indeed, any method claiming to be second-order must be accompanied by similar superior local convergence properties. In this light, the "big-picture" contribution of this paper is to map the lay of the land for the non-asymptotic local and global convergence properties of variants of Newton's method in which the Hessian and/or gradient are randomly sub-sampled.</p><p>The rest of the paper is organized as follows. In Sect. 1.1, we first give a brief overview of the general framework for the iterative schemes considered in our anal-ysis. In Sect. 1.2, we briefly survey the related works, and in their light, discuss our contributions in Sect. 1.3. The notation and the assumptions used in this paper are given in Sects. 1.4 and 1.5, respectively. Section 2 addresses sampling strategies for approximating the Hessian and gradient. The non-asymptotic and high-probability convergence results for sub-sampled Newton's methods are given in Sect. <ref type="bibr" target="#b2">3</ref>. In particular, global and local convergence properties are treated in Sects. 3.1and 3.2, respectively, followed by some unifying results in Sect. 3.3. Worst-case computational complexities involving various parts of these algorithms are gathered in Sect. 3.4. Conclusions and further thoughts are gathered in Sect. <ref type="bibr" target="#b3">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Framework</head><p>The iterative framework under which we study the sub-sampled Newton-type variants is what is best known as scaled gradient projection formulation <ref type="bibr" target="#b2">[3]</ref>. More specifically, given the current iterate, x (k) ∈ D ∩ C , consider the following iterative scheme, (k) )(xx (k) ) , (2a)</p><formula xml:id="formula_1">x (k) = arg min x∈D∩C (x -x (k) ) T g(x (k) ) + 1 2 (x -x (k) ) T H (x</formula><formula xml:id="formula_2">x (k+1) = x (k) + α k x (k) -x (k) ,<label>(2b)</label></formula><p>where g(x (k) ) and H (x (k) ) are some approximations to (in our case, sub-samples of) the actual gradient and the Hessian at the k th iteration, respectively, and α k is the step-size. A variety of first and second order methods can be written in this form. For example, classical Newton's method is obtained by setting g(x (k) ) = ∇ F(x (k) ) and H (x (k) ) = ∇ 2 F(x (k) ), the (projected) gradient descent is with g(x (k) ) = ∇ F(x (k) ) and H (x (k) ) = I, and the pair</p><formula xml:id="formula_3">g(x (k) ) = ∇F(x (k) ), H (x (k) ) = 1 |S H | j∈S H ∇ 2 f j (x (k) ), or g(x (k) ) = 1 |S g | j∈S g ∇ f j (x (k) ), H (x (k) ) = 1 |S H | j∈S H ∇ 2 f j (x (k) ),</formula><p>for some index sets S g , S H ⊆ [n] gives rise to sub-sampled Newton methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b41">42]</ref>, henceforth referred to as SSN, which are the focus of this paper. Depending on the method, the step-size α k is sometimes set to a predefined value, or alternatively is chosen adaptively, e.g., using line-search techniques.</p><p>Our primary objective in this paper is to study conditions under which variants of SSN are not only efficient for large-scale problems, but also preserve, at least locally, as much of the superior convergence properties of the classical Newton's method as possible while maintaining a reasonable global convergence behavior. In doing so, we need to simultaneously ensure the following requirements.</p><p>(R.1) Our sampling strategy needs to provide a sample size which is independent of n, or at least smaller, e.g, grows slowly with n.</p><p>(R.2) To re-scale the gradient direction appropriately, the sub-sampled matrix must preserve the spectrum of the full Hessian as much as possible. At the very least, it should be able to generate descent directions, e.g., when D = C = R p , if the original matrix is uniformly positive definite (PD), so should be the subsampled approximation (preferably without any additional regularization to the Hessian). Approximation to the gradient should also contain as much of the first order information as possible. (R.3) Such algorithms need to be globally convergent and approach the optimum starting from any initial guess. More importantly, for any variant of SSN to be considered "Newton-like", it must enjoy a reasonably fast convergence rate which is, at least locally, similar to that of the classical Newton's method. (R.4) In high-dimensional regimes where p 1, solving (2a) exactly at each iteration can pose a significant computational challenge. In such settings, allowing for (2a) to be solved inexactly is indispensable.</p><p>In this paper, we strive to, at least partially, address challenges (R.1)-(R.4). More precisely, by using random matrix concentration inequalities and results from approximate matrix multiplication of randomized numerical linear algebra (RandNLA) <ref type="bibr" target="#b27">[28]</ref>, we aim to ensure (R.1) and (R.2). For (R.3), we give variants of SSN which are globally convergent and whose local convergence rates can be made close to that of the classical Newton's method. Finally, to satisfy (R.4), for both global and local convergence, we give inexactness requirements, which are less strict than prior works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Related work</head><p>Randomized approximation of the full Hessian matrix has been previously considered in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b41">42]</ref>.Within the context of deep learning, <ref type="bibr" target="#b28">[29]</ref> is the first to suggest a heuristic sub-sampled Newton-type algorithm and study its empirical performance. The pioneering work in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref> establishes, for the first time, the convergence of variants of Newton's method with the sub-sampled Hessian. However, the results are asymptotic and no quantitative convergence rate is given. In addition, convergence is established for the case where each f i is assumed to be strongly convex. Under the same setting, some modifications and improvements are given in <ref type="bibr" target="#b39">[40]</ref>. The work in <ref type="bibr" target="#b34">[35]</ref> is the first to use "sketching" within the context of Newton-like methods, specialized to the cases where some square root of the Hessian matrix is readily available. Under the same setting, non-uniform sampling strategies are proposed in <ref type="bibr" target="#b41">[42]</ref>. Non-asymptotic local convergence rates for the uniform sub-sampling of the Hessian is first established in <ref type="bibr" target="#b17">[18]</ref>. The authors suggest an algorithm where, at each iteration, the spectrum of the uniformly sub-sampled Hessian is modified as a form of regularization. In <ref type="bibr" target="#b0">[1]</ref> a Hessian sub-sampling algorithm is proposed that employs unbiased estimator of the inverse of the Hessian. This is followed by an improved and simplified convergence analysis in <ref type="bibr" target="#b30">[31]</ref>. Arguably, the closest results to those of the present paper are given in <ref type="bibr" target="#b4">[5]</ref>. However, the convergence results in <ref type="bibr" target="#b4">[5]</ref> are given in expectation whereas, here, we give high probability results. In addition, <ref type="bibr" target="#b4">[5]</ref> assumes that each f i in (1) is strongly convex, while here, we only make such an assumption for the objective function, F, and each f i need only be (weakly) convex.</p><p>Within the context of second order methods, gradient sub-sampling has been successfully applied in large scale machine learning, e.g., <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>, as well as nonlinear inverse problems, e.g., <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b35">36]</ref>. By carefully increasing the sample size across iterations, the hybrid methods of <ref type="bibr" target="#b18">[19]</ref> combine the inexpensive iterations of incremental gradient algorithms and the convergence of full gradient methods. Such careful increase of the sample size is one of the main ingredients of our analysis.</p><p>Finally, inexact updates have been used in many second-order optimization algorithms; see <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b25">26]</ref> and references therein.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Contributions</head><p>In light of the related work, the main contributions of this paper are summarized as follows; see Table <ref type="table">1</ref>. We first consider the unconstrained version of (1) where D = C = R p , and under certain assumptions, study non-asymptotic and high-probability global convergence of SSN with Armijo line search. Specifically, we consider the variants of SSN depicted in Algorithms 1 and 2. Theorems 1 and 3 give global convergence results for the case where the linear system arising from (2a) is solved exactly, Theorems 2 and 4 give similar results for inexact updates. For all these results, we only require that the objective F in (1) is strongly convex, while each component function, f i , is allowed to be only (weakly) convex. This is a relaxation over all previous work where strong convexity is assumed for all f i 's.</p><p>We then zoom in, and in full generality, i.e., omitting the assumption D = C = R p , study non-asymptotic and high-probability local convergence behavior of SSN using the natural step size of the classical Newton's method, i.e., α k = 1 in (2b). Specifically, for Algorithms 3, 4, and 5, we establish non-asymptotic equivalents of Q-linear, Qsuperlinear, and R-linear convergence results in Theorem 6, 7, 8, and 11. Though the sample size depends on the condition number of the problem, we show that the local rates for the (super)linear convergence phase are, in fact, problem-independent, a property common to most Newton-type methods. Fast and problem-independent local convergence rates using the inexact solution of (2a) (in unconstrained case) are studied in Theorems 9 and 12.</p><p>Compared to similar results, e.g., <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b41">42]</ref>, our inexactness tolerance is a significant improvement. More specifically, in prior works, the inexactness tolerance depends Table <ref type="table">1</ref> Summary of the main results. "Lin" and "SupLin", respectively, are short for "Linear" and "Superlinear". "Exact" and "Inexact", refer to the exact and approximate solution of (2a), respectively on the inverse of the condition number, where as here, our tolerance depends on the square root of this inverse (Theorems 2, 4, 9, and 12).</p><p>We finally combine these global and local analysis and obtain unifying results (Theorems 13 and 14), which ensure that SSN with Armijo line search is globally convergent with problem-independent local rate. Further, after certain number of iterations, the line-search automatically adopts the natural step size of the classical Newton's method, i.e., α k = 1, for all subsequent iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Notation</head><p>Throughout this paper, vectors are denoted by bold lowercase letters, e.g., v, and matrices or random variables are denoted by regular upper case letters, e.g., V , which is clear from the context. For a vector v, and a matrix V , v , V and V F , respectively, denote the vector 2 norm, the matrix spectral norm, and the matrix Frobenius norm. ∇ f (x) and ∇ 2 f (x) are the gradient and the Hessian of f at x, respectively. For a set X and two symmetric matrices A and B, A X B indicates that x T (B -A)x ≥ 0 for all x ∈ X . The superscript, e.g., x (k) , denotes iteration counter and ln(x) denotes the natural logarithm of x. Throughout the paper, S denotes a collection of indices from [n] := {1, 2, . . . , n}, with potentially repeated items and |S | denote its cardinality. The cone of feasible directions at the optimum x is denoted by</p><formula xml:id="formula_4">K := p ∈ R p ; ∃t &gt; 0 s.t. x + tp ∈ D ∩ C . (<label>3</label></formula><formula xml:id="formula_5">)</formula><p>If x lies in the relative interior of D ∩ C , then, as a consequence of Prolongation Lemma <ref type="bibr" target="#b3">[4,</ref><ref type="bibr">Lemma 1.3.3]</ref>, it is easy to show that K is a subspace. For a vector v and a matrix A, using K , we can define their K -restricted seminorms, respectively, as</p><formula xml:id="formula_6">v K := sup p∈K \{0}</formula><p>|p T v| p , and</p><formula xml:id="formula_7">A K := sup p,q∈K \{0} |p T Aq| p q . (<label>4</label></formula><formula xml:id="formula_8">)</formula><p>Similarly, one can define the K -restricted maximum and the minimum eigenvalues of a symmetric matrix A as</p><formula xml:id="formula_9">λ K min (A) := inf p∈K \{0} p T Ap p 2 , and λ K max (A) := sup p∈K \{0} p T Ap p 2 . (<label>5</label></formula><formula xml:id="formula_10">)</formula><p>Alternatively, let U be an orthonormal basis for the subspace K . The definitions above are equivalent to v K = U T v , A K = U T AU . Also, this representation allows us to define any K -restricted eigenvalue of A as λ K i (A) = λ i (U T AU ), where λ i (A) is the usual i th eigenvalue of A, i.e., computed with respect to all vectors in R p .</p><p>For the non-asymptotic high-probability analysis in this paper, we use the following adaptations of the classical notions of convergence, which are typically applied asymptotically. Recall that we use the term "convergence" loosely for a finite sequence. To evaluate convergence, one typically uses an appropriate distance measure, d : R p × R p → [0, ∞), such that d(z, z) = 0. Here, we consider d(x, y) = xy and d(x, y) = |F(x) -F(y)|. Let z (k) denote the iterate generated by an iterative algorithm at the k th iteration. An algorithm's iterations are said to converge Q-linearly to a limiting value z if ∃ρ ∈ [0, 1) such that ∀k 0 ∈ N = {1, 2, . . .}, the iterates generated by k 0 iterations of the algorithm starting from z (0) satisfy d(z (k+1) , z ) ≤ ρd(z (k) , z ), k = 0, 1, . . . , k 0 -1. Q-superlinear convergence is defined similarly by requiring that ∃ρ : N → [0, 1), ρ(k) ↓ 0, s.t. ∀k 0 ∈ N, d(z (k+1) , z ) ≤ ρ(k)d(z (k) , z ), k = 0, 1, . . . , k 0 -1. The notion of R-convergence rate is an extension which captures sequences which still converge reasonably fast, but whose "speed" is variable. An algorithm's iterations are said to converge R-linearly to</p><formula xml:id="formula_11">z if ∃ρ ∈ [0, 1), ∃R &gt; 0 such that ∀k 0 ∈ N, d(z (k) , z ) ≤ Rρ k , k = 1, 2, . . . , k 0 .</formula><p>Clearly, for k 0 = ∞, these notions imply the typical asymptotic definitions. For randomized algorithms considered in this paper, we study conditions under which these algorithms, with high-probability, generate iterates that satisfy the corresponding convergence criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5">Assumptions</head><p>We assume that each f i is twice-differentiable, smooth and convex with respect to the cone K , i.e., we have</p><formula xml:id="formula_12">0 ≤ inf x∈D∩C λ K min ∇ 2 f i (x) ≤ sup x∈D∩C λ K max ∇ 2 f i (x) K i &lt; ∞, i ∈ [n],<label>(6a)</label></formula><p>where λ K min (A) and λ K max (A) are defined in <ref type="bibr" target="#b4">(5)</ref>. We further assume that F is smooth and strongly convex, i.e., we have</p><formula xml:id="formula_13">0 &lt; γ inf x∈D∩C λ K min ∇ 2 F(x) ≤ sup x∈D∩C λ K max ∇ 2 F(x) K &lt; ∞,<label>(6b)</label></formula><p>and it has a Lipschitz continuous Hessian with respect to K , i.e., sup</p><formula xml:id="formula_14">x-y∈K x =y ∇ 2 F(x) -∇ 2 F y) K x -y L &lt; ∞,<label>(7)</label></formula><p>where A K is defined in (4). Since D ∩ C is convex, Assumption (6b) implies the uniqueness of the optimum, x . We further assume that x lies in the relative interior of D ∩ C . The quantity</p><formula xml:id="formula_15">κ K /γ , (<label>8</label></formula><formula xml:id="formula_16">)</formula><p>is known as the condition number of the problem, restricted to vectors in K . Note that, depending on K , (8) might be significantly smaller than the usual condition number, which is usually defined using all vectors in R p . For example, consider the case where D = R p and C = {x ∈ R p ; Ax = b} for some matrix A ∈ R m× p with m &lt; p that has full row-rank . Then K is the null space of A, i.e., K = {p ∈ R p ; Ap = 0}, and rank(K ) = pm. As a result, one can compute K and γ using Rayleigh quotients of ∇ 2 f i (x) and ∇ 2 F(x) for all x ∈ D ∩ C , respectively, but restricted to vectors in this pm dimensional sub-space. Depending on A, these values can be much smaller than the minimum and maximum of such Rayleigh quotients over the entire R p . Of course, in an unconstrained problem, κ coincides with the usual condition number. For an integer 1 ≤ q ≤ n, let Q be the set of indices corresponding to q largest K i 's and define the "sub-sampling" condition number as</p><formula xml:id="formula_17">κ q K q /γ , (<label>9a</label></formula><formula xml:id="formula_18">)</formula><p>where</p><formula xml:id="formula_19">K q 1 q j∈Q K j . (<label>9b</label></formula><formula xml:id="formula_20">)</formula><p>It is easy to see that K ≤ K n and for any two integers q and r such that 1 ≤ q ≤ r ≤ n, we have κ ≤ κ r ≤ κ q . Finally, define</p><formula xml:id="formula_21">κ κ 1 , If sample S is drawn with replacement κ |S | , If sample S is drawn without replacement , (<label>9c</label></formula><formula xml:id="formula_22">)</formula><p>where κ 1 and κ |S | are as in (9a).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Sub-sampling</head><p>We now study various sampling strategies for appropriately approximating the Hessian and the gradient. We note that all the following sampling results provide worst-case sample sizes which are useful in regimes where n 1. More generally, however, the prescribed sample sizes should be mostly regarded as a qualitative guide to practice, as opposed to verbatim.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Sub-sampling Hessian</head><p>For the optimization problem (1), at each iteration, consider picking S , uniformly at random with or without replacement. Let</p><formula xml:id="formula_23">H (x) 1 |S | j∈S ∇ 2 f j (x), (<label>10</label></formula><formula xml:id="formula_24">)</formula><p>be the sub-sampled Hessian. As mentioned before in Sect. 1.1, in order for such subsampling to be useful, we need the sample size |S | to satisfy (R.1). In addition, as mentioned in (R.2), we need to at least ensure that H (x) is K -restricted PD similar to the original Hessian, e.g., for D = C = R p , H (x) should be uniformly PD. In this case, the direction given by H (x), indeed, yields a descent direction with respect to K . It is important to emphasize that, ideally, we'd like to ensure such K -restricted PD property without any additional regularization to the Hessian, e.g., Levenberg-Marquardt type. This is because such added regularization perturbs the spectrum corresponding to small eigenvalues of the Hessian, which in turn destroys the curvature information. Recall that the most "informative" part of the curvature information is contained in the spectrum corresponding to small eigenvalues. Levenberg-Marquardt type regularization, for example, easily diminishes the contributions of the directions corresponding to small eigenvalues. This could make the algorithm behave more like gradient descent, which defeats the purpose of using second order information! Lemma 1 shows that we can indeed probabilistically guarantee such PD property.</p><p>Lemma 1 (K -restricted positive definiteness) Given any 0 &lt; ε, δ &lt; 1, and <ref type="bibr" target="#b9">(10)</ref>, we have</p><formula xml:id="formula_25">x ∈ D ∩ C , if |S | ≥ 2κ 1 ln( p/δ)/ε 2 , then for H (x) defined in</formula><formula xml:id="formula_26">Pr (1 -ε)γ ≤ λ K min (H (x)) ≥ 1 -δ,</formula><p>where γ and κ 1 are defined in (6b) and (9a), respectively.</p><p>Proof Let U be an orthonormal basis for the subspace </p><formula xml:id="formula_27">K in (3). For x ∈ D ∩ C , consider |S | random matrices X j (x), j = 1, 2, . . . , |S | such that Pr(X j (x) = ∇ 2 f i (x)) = 1/n; ∀i ∈ [n]. Define H (x) j∈S X j (x)/|S | and also X (x) j∈S U T X j (x)U = |S |U T H (x)U . Note that we have E(X j (x)) = ∇ 2 F(x), X j (x) K 0, λ K max (X j (x)) ≤ K 1 ,</formula><formula xml:id="formula_28">(X (x)) ≤ (1 -ε)|S |λ K min (∇ 2 F(x))) ≤ p e -ε (1 -ε) (ε-1) |S |γ / K 1 . The result follows by noticing that e -ε (1 -ε) (ε-1) ≤ e -ε 2 /2 , and requiring that exp{-ε 2 |S |/(2κ 1 )} ≤ δ.</formula><p>If, instead, we require that the sub-sampled Hessian preserves the spectrum of the full Hessian, we will need larger sample than that of Lemma 1. <ref type="bibr" target="#b9">(10)</ref>, we have</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 2 (K -restricted spectrum preserving) Given any</head><formula xml:id="formula_29">0 &lt; ε, δ &lt; 1 and x ∈ D ∩C , if |S | ≥ 16κ 2 1 ln(2 p/δ)/ε 2 , then for H (x) defined in</formula><formula xml:id="formula_30">Pr H (x) -∇ 2 F(x) K ≤ εγ ≥ 1 -δ,</formula><p>where γ and κ 1 are defined in (6b) and (9a), respectively.</p><p>Proof Let U be an orthonormal basis for the subspace</p><formula xml:id="formula_31">K in (3). Consider |S | random matrices X j (x), j = 1, 2, . . . , |S | as in the proof of Lemma 1. Define Y j (x) U T X j (x) -∇ 2 F(x) U and Y (x) j∈S Y j (x) = |S |U T H (x) -∇ 2 F(x) U , where H (x) j∈S X j (x)/|S |. Note that E(Y j (x)) = 0 and for X j (x) = ∇ 2 f 1 (x), Y 2 j (x) = Y j (x) 2 = U T ( n-1 n ∇ 2 f 1 (x) -n i=2 1 n ∇ 2 f i (x))U 2 ≤ 4( n-1 n ) 2 K 2 1 ≤ 4 K 2 1</formula><p>, where K 1 is defined in (9b). Operator-Bernstein inequality [21, Theorem 1], for both sampling with and without replacement, gives Pr(</p><formula xml:id="formula_32">H (x) -∇ 2 F(x) K ≥ εγ ) = Pr( Y (x) ≥ ε|S |γ ) ≤ 2 p exp{-ε 2 |S |γ 2 /(16K 2 )}. The requirement on |S | gives the result.</formula><p>As a consequence of Lemma 2, we have the spectral approximation property of the sub-sampled matrix H (x), with respect to the cone K i.e., Pr (1</p><formula xml:id="formula_33">-ε)∇ 2 F(x) K H (x) K (1 + ε)∇ 2 F(x) ≥ 1 -δ, where A K B is defined in Sect. 1.4. This follows from H -∇ 2 F(x) K ≤ εγ , which gives (1 -ε)U T ∇ 2 F(x)U U T ∇ 2 F(x)U -εγ I U T H (x)U U T ∇ 2 F(x)U + εγ I (1 + ε)U T ∇ 2 F(x)U .</formula><p>This ensures that the sub-sampled Hessian, to ε accuracy, preserves the spectrum of the full Hessian.</p><p>In Lemma 1, the sufficient sample size, |S |, grows only linearly in κ 1 , i.e., Ω(κ 1 ), as opposed to quadratically, i.e., Ω(κ 2 1 ), in Lemma 2. This difference, in fact, boils down to the difference between the requirements for global and local convergence in (R.2). For example, for D = C = R p , in order to guarantee global convergence, we only require that the sub-sampled Hessian is uniformly PD. In contrast, to obtain fast local convergence, we need a much stronger guarantee to preserve the spectrum of the true Hessian. Consequently, Lemma 1 requires a smaller sample size, i.e., in the order of κ 1 versus κ 2  1 for Lemma 2, while delivering a much weaker guarantee. Depending on κ 1 and for n 1, in Lemmas 1 and 2, we can have |S | n. However, since both bounds on |S | in Lemmas 1 and 2 are too conservative, the required sample size can be unnecessarily large. Unfortunately, for uniform sampling, this is unavoidable as the prescribed sample size protects against the worst-case scenario of extreme non-uniformity among ∇ 2 f i (x)'s <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b41">42]</ref>. In some extreme cases, uniform sampling might even require Ω(n) samples to capture the Hessian appropriately. In such cases, if possible, non-uniform sampling schemes result in sample sizes that are independent of n and are resilient to such non-uniformity <ref type="bibr" target="#b41">[42]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Sub-sampling gradients</head><p>For sub-sampling the gradient, consider picking the indices in S uniformly at random with replacement, and let</p><formula xml:id="formula_34">g(x) 1 |S | j∈S ∇ f j (x), (<label>11</label></formula><formula xml:id="formula_35">)</formula><p>be the sub-sampled gradient. By (R.2), we require that the sub-sampled gradient contains as much of the first order information from the full gradient as possible. For this, we write the gradient ∇ F(x) in a matrix-matrix product from as ∇ F(x) = AB where</p><formula xml:id="formula_36">A ∇ f 1 (x) ∇ f 2 (x) • • • ∇ f n (x) ∈ R p×n , B 1/n 1/n . . . 1/n T ∈ R n×1 . (<label>12</label></formula><formula xml:id="formula_37">) Table 2 Uniform estimates for G(x) in GLMs, F(x) = n -1 n i=1 Φ(a T i x) -b i a T i x , over the sparsity inducing constraint set C = {x ∈ R p ; x 1 ≤ 1}.</formula><p>The infinity norm of a vector a is denoted by a ∞</p><p>We then use approximate matrix multiplication results from RandNLA <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b27">28]</ref>, to probabilistically control the error in the approximation of ∇ F(x) by g(x), through uniform sampling of the columns and rows A, B.</p><formula xml:id="formula_38">Lemma 3 (Gradient sub-sampling) For a given x ∈ D ∩C , let ∇ f i (x) K ≤ G(x) &lt; ∞, i = 1, 2, . . . , n. For any 0 &lt; ε, δ &lt; 1, if |S | ≥ G(x) 2 1 + √ 8 ln(1/δ) 2 /ε 2 ,</formula><p>then for g(x) as in <ref type="bibr" target="#b10">(11)</ref>, we have</p><formula xml:id="formula_39">Pr ∇ F(x) -g(x) K ≤ ε ≥ 1 -δ,</formula><p>where . K is defined as in <ref type="bibr" target="#b3">(4)</ref>.</p><p>Proof Let U be an orthonormal basis for K . By the assumption and the definition (4), we have that at a given By the assumption on G(x), we can use <ref type="bibr" target="#b14">[15,</ref><ref type="bibr">Lemma 11]</ref> to get, with probability 1 -δ,</p><formula xml:id="formula_40">x ∈ D ∩ C , U T ∇ f i (x) ≤ G(x), i = 1,</formula><formula xml:id="formula_41">U T AB -U T A B F = ∇ F(x) -g(x) K ≤ G(x)(1 + √ 8 ln(1/δ))/ √ |S |. The result follows by requiring G(x)(1 + √ 8 ln(1/δ)) ≤ ε √ |S |.</formula><p>Note that the gradient sampling in Lemma 3 is done with replacement; for gradient sampling without replacement see <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b18">19]</ref>. Further, the sample size from Lemma 3 is given with respect to the current iterate, x (k) . As a result, we need to be able to efficiently estimate G(x (k) ) at every iteration or, a priori, have a uniform upper bound for G(x) for all x ∈ D ∩ C . Fortunately, in many different problems, it is possible to efficiently estimate G(x). For example, consider GLM objective function</p><formula xml:id="formula_42">F(x) = n -1 n i=1 Φ(a T i x) -b i a T i x , over a sparsity inducing constraint set, e.g., C = {x ∈ R p ; x 1 ≤ 1}.</formula><p>Here, (a i , b i ), i = 1, 2, . . . , n, form response and covariate pairs where a i ∈ R p , and the domain of b i depends on the GLM. The cumulant generating function, Φ, determines the type of GLM; see the book <ref type="bibr" target="#b29">[30]</ref> for further details and applications. For illustration purposes only, Table <ref type="table">2</ref> gives some very rough uniform estimates of the constant G(x) with respect to C for some popular GLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Convergence results</head><p>We will now leverage the sampling strategies described in Sect. 2 to study the convergence properties of SSN. We consider the global convergence behaviour in Sect. 3.1, followed by the local convergence properties in Sect. 3.2. We then combine these to give unifying results in Sect. 3.3. Finally, worst-case computational complexities involving various parts of these algorithms are gathered in Sect. 3.4.</p><p>The following results rely on the high-probability occurrence of the events <ref type="figure"></ref>and<ref type="figure" target="#fig_1">3</ref>, for one or several iterations. In what follows, the convergence probabilities, which can be controlled a priori, are explicitly given in all theorem statements. However, for simplicity, the respective proofs are given by implicitly conditioning on the occurrence of the corresponding events.</p><formula xml:id="formula_43">{(1 - ε)γ ≤ λ K min (H (x))}, { H (x) -∇ 2 F(x) K ≤ εγ } and/or { ∇ F(x) -g(x) K ≤ ε} from Lemmas 1, 2,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Global convergence</head><p>In this section, we study the global convergence of SSN using Armijo line search and only in the unconstrained case where D = C = R p . Our choice in considering unconstrained optimization lies in the unfortunate fact that defining "inexactness" for the solution of constrained variant of (2a) in a computationally feasible way is non-trivial, if possible at all. In unconstrained case, the solution to (2a) boils down to a linear system [cf. (13a) and (15a)], where the notion of inexactness naturally arises.</p><p>Similar algorithms with asymptotic convergence guarantees are given in the pioneering work of <ref type="bibr" target="#b6">[7]</ref>, while <ref type="bibr" target="#b4">[5]</ref> gives quantitative convergence rates in expectation. However, for both sets of these results, it is assumed that each f i in (1) is strongly convex. Using Lemma 1, we study such globally-convergent algorithms under a milder assumption (6b), where strong convexity is only assumed for F, while each f i is allowed to be only (weakly) convex as in (6a). Many optimization problems can be of this form, e.g., f i (x) = g(a T i x), with g : R → R, a i ∈ R p and Range({a i } n i=1 ) = R p , i.e., the matrix whose rows are formed by a i is full column rank. If the real valued function g(t) is strongly convex, then we have ∇ 2 f i (x) = g (a T i x)a i a T i , which is clearly rank one and not positive definite, but F(x) is indeed strongly convex. A simple example is when g(t) = t 2 which gives rise to ordinary linear least squares.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Global convergence: sub-sampled Hessian and full gradient</head><p>In this section, we consider iterations (2) using the sub-sampled Hessian, H (x (k) ) and the full gradient, ∇ F(x (k) ). We first present an iterative algorithm in which, at every iteration, the linear system in (2a) is solved exactly, followed by an inexact variant.</p><p>Exact update In the unconstrained case where D = C = R p , the iterations (2) using Armijo-type line-search to select α k , can be re-written as x (k+1) = x (k) + α k p k , where</p><formula xml:id="formula_44">p k = -[H (x (k) )] -1 ∇ F(x (k) ), (<label>13a</label></formula><formula xml:id="formula_45">)</formula><p>and α k is the largest α ≤ 1 such that</p><formula xml:id="formula_46">F(x (k) + αp k ) ≤ F(x (k) ) + αβp T k ∇ F(x (k) ),<label>(13b)</label></formula><p>for some β ∈ (0, 1). Recall that (13b) can be approximately solved using various methods such as backtracking line search <ref type="bibr" target="#b5">[6]</ref>.</p><p>Algorithm 1 Globally Convergent SSN with Hessian Sub-Sampling</p><formula xml:id="formula_47">1: Input: x (0) , 0 &lt; δ &lt; 1, 0 &lt; ε &lt; 1, 0 &lt; β &lt; 1 2:</formula><p>-Set the sample size, |S |, with ε and δ as in Lemma 1 3:</p><formula xml:id="formula_48">for k = 0, 1, 2, • • • until termination do 4:</formula><p>-Select a sample set, S , of size |S | and form H (x (k) ) as in (10) 5:</p><p>-Update x (k+1) as in <ref type="bibr" target="#b12">(13)</ref> with H (x (k) ) 6: end for Theorem 1 (Global convergence of Algorithm 1) Let Assumptions (6) hold. Using Algorithm 1 with any x (k) ∈ R p , with probability 1 -δ, we have</p><formula xml:id="formula_49">F(x (k+1) ) -F(x ) ≤ (1 -ρ k ) F(x (k) ) -F(x ) , (<label>14</label></formula><formula xml:id="formula_50">)</formula><p>where ρ k = 2α k β/ κ, and κ is defined as in (9c). Moreover, the step size is at least</p><formula xml:id="formula_51">α k ≥ 2(1 -β)(1 -ε)/κ</formula><p>, where κ is defined as in <ref type="bibr" target="#b7">(8)</ref>.</p><formula xml:id="formula_52">Proof Since p T k H (x (k) )p k ≥ λ min (H (x)) p 2 , by Lemma 1, we have p T k H (x (k) )p k ≥ (1 -ε)γ p k 2 . By p T k ∇ F(x (k) ) = -p T k H (x (k) )p k , this implies that p T k ∇ F(x (k)</formula><p>) &lt; 0 and we can indeed obtain decrease in the objective function. Now, it suffices to show that there exists an iteration-independent α &gt; 0, such that (13b) holds for any 0 ≤ α ≤ α. For any 0 ≤ α, define</p><formula xml:id="formula_53">x α = x (k) +αp k . Assumption (6b) implies F(x α )-F(x (k) ) ≤ (x α -x (k) ) T ∇ F(x (k) ) + K x α -x (k) 2 /2 = αp T k ∇ F(x (k) ) + α 2 K p k 2 /2. Now in</formula><p>order to pass the Armijo rule, we search for α such that 2αp</p><formula xml:id="formula_54">T k ∇ F(x (k) )+α 2 K p k 2 ≤ 2αβp T k ∇ F(x (k) ), which gives α K p k 2 ≤ -2(1-β)p T k ∇ F(x (k) ). This latter inequal- ity is satisfied if we require that α K p k 2 ≤ 2(1-β)p T k H (x (k) )p k . As a result, having α ≤ 2(1 -β)(1 -ε)/κ,</formula><p>satisfies the Armijo rule. So in particular, we can always find an iteration-independent α = 2(1 -β)(1 -ε)/κ such that (13b) holds for all α ≤ α. Now, for sampling without replacement and by</p><formula xml:id="formula_55">H (x (k) )p k = -∇ F(x (k) ) we get p T k H (x (k) )p k = ∇F(x (k) ) T [H (x (k) )] -1 ∇ F(x (k) ) ≥ ∇F(x (k) ) 2 / K |S | . Simi- larly for sampling with replacement, we have p T k H (x (k) )p k ≥ 1/ K 1 ∇ F(x (k) ) 2 . By p T k ∇ F(x (k) ) = -p T k H (x (k) )p k , (13b) gives F(x (k+1) ) ≤ F(x (k) )-α k βp T k H (x (k) )p k .</formula><p>The result follows by subtracting F(x ) from both sides and noting that Assumption (6b) gives</p><formula xml:id="formula_56">F(x (k) ) -F(x ) ≤ ∇F(x (k) ) 2 /(2γ ); see [32, Theorem 2.1.10].</formula><p>The role of ε in Theorem 1, which appears explicitly in the worst-case step-size, is rather interesting. As it can be seen, the better we approximate the Hessian, the larger our "bottom-line" step-size would be, which in turn implies a faster worst-case convergence speed. In fact, this is rather intuitive: inaccurate estimation of the curvature implies that the local quadratic approximation of F at x (k) in (2a) is unreliable, i.e, the local approximation error between the true function and the second-order model increases. Hence, the resulting method would tend to take more conservative, i.e., shorter, steps, to account for such increased local inaccuracy.</p><p>Theorem 1 states that the iterates generated by Algorithm 1, with high-probability, approach x , starting from any x (0) . However, in the worst case, the global linear rate is with ρ k ∈ Ω(1/(κ κ)) which is seemingly unsatisfying, and indeed worse than that of simple gradient descent. This is due to the application of Armijo line search and appears as a by-product of the analysis. In fact, such unsatisfying global rate appears throughout the literature for similar Newton-type methods, e.g. Theorem 2.1 in <ref type="bibr" target="#b4">[5]</ref>, as well as in some classical and widely cited textbooks such as Sect. 9.3.5 in <ref type="bibr" target="#b5">[6]</ref>. This has indeed been pointed out in <ref type="bibr" target="#b32">[33]</ref> where a cubic regularization is employed to circumvent this issue. Examples have also been constructed for which, in the worst case, steepestdescent and Newton's method are equally slow for unconstrained optimization <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>. Despite these worst-case scenarios, efficient variants of Newton-type methods have been shown to outperform first order alternatives in many practical settings, e.g., see the numerical examples in <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42]</ref>.</p><p>Inexact update In high dimensional settings where p 1, finding the exact update, p k , in (13a) is computationally expensive. Hence, it is imperative to be able to calculate the update direction only approximately. Such inexact updates have been used in many second-order optimization algorithms, e.g. <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b25">26]</ref>.</p><p>Our results are inspired by <ref type="bibr" target="#b8">[9]</ref>. More specifically, instead of (13a), we approximately solve the underlying linear system such that for some 0 ≤ θ 1 , θ 2 &lt; 1, we have</p><formula xml:id="formula_57">H (x (k) )p k + ∇ F(x (k) ) ≤ θ 1 ∇ F(x (k) ) , (15a) p T k ∇ F(x (k) ) ≤ -(1 -θ 2 )p T k H (x (k) )p k . (<label>15b</label></formula><formula xml:id="formula_58">)</formula><p>The condition (15a) is the usual relative residual of the approximate solution, while condition (15b) ensures that such a p k is always a descent direction. Note that given any 0 ≤ θ 1 , θ 2 &lt; 1, one can always find a p k satisfying ( <ref type="formula" target="#formula_57">15</ref>), e.g., the exact solution.</p><p>Assume that to find p k in (15), the linear system H (x (k) )p k = -∇ F(x (k) ) is solved approximately using an iterative method, in which the iterates, p (t)  k , are generated by successive minimization of the function g k (p) p T ∇ F(x (k) ) + p T H (x (k) )p/2 over progressively expanding linear manifolds M t , i.e., p (t) k = arg min p∈M t g k (p). One such method, which is suitable for our setting here, is the celebrated conjugate gradient (CG). Now since over any such space M t , g k (0) = 0, we always have g k (p (t)  k ) ≤ 0, ∀t. As a result, for θ 2 = 1/2, any such p (t)  k always satisfies (15b). Although for θ 2 = 1/2, (15b) can be simply dropped from <ref type="bibr" target="#b14">(15)</ref>, in the following results, we will treat θ 2 as a hyper-parameter to discuss its effect on convergence.</p><p>Recall that by Lemma 1, with high probability, we have (1 -ε)γ ≤ λ min (H (x (k) )); hence Cond(H (x (k) )) ≤ κ/(1 -ε) where κ is as in (9c). If CG is used to obtain a solution for (15a), then by its worst case convergence <ref type="bibr" target="#b23">[24]</ref>, we get</p><formula xml:id="formula_59">p (t) k -p k H (x (k) ) ≤ 2 κ/(1 -ε) -1 κ/(1 -ε) + 1 t p (0) -p k H (x (k) ) ,</formula><p>where p A = p T Ap. If p (0) = 0, it follows that</p><formula xml:id="formula_60">H (x (k) )p (t) k + ∇ F(x (k) ) ≤ 2 κ (1 -ε) κ/(1 -ε) -1 κ/(1 -ε) + 1 t ∇ F(x (k) ) .</formula><p>Hence, after</p><formula xml:id="formula_61">t ≥ ln ⎛ ⎝ 2 θ 1 κ (1 -ε) ⎞ ⎠ / ln κ/(1 -ε) + 1 κ/(1 -ε) -1 , (<label>16</label></formula><formula xml:id="formula_62">)</formula><p>iterations, we get (15a). Theorem 2 prescribes a sufficient condition on θ 1 , which is less strict than similar prior works, and yet ensures a desirable convergence property.</p><p>As shown above, for θ 2 = 1/2 and any θ 1 &lt; 1, the complexity of checking ( <ref type="formula" target="#formula_57">15</ref>) is directly related to the computational cost involved in solving the underlying linear system. For θ 2 &lt; 1/2, however, we are not aware of a way to quantify the cost required to ensure (15b). Overall computational complexities of Algorithms involving <ref type="bibr" target="#b14">(15)</ref> are discussed in Sect. 3.4.</p><p>Theorem 2 (Global convergence of Algorithm 1: inexact update) Let Assumptions (6) hold, and 0 ≤ θ 1 , θ 2 &lt; 1 be given. Using Algorithm 1 with any x (k) ∈ R p , and the "inexact" update (15) instead of (13a), with probability 1 -δ, we have <ref type="bibr" target="#b13">(14)</ref> with ρ k as follows: (i) if</p><formula xml:id="formula_63">θ 1 ≤ (1 -ε)/(4 κ), then ρ k = α k β/ κ, (ii) otherwise, ρ k = 2(1 -θ 2 )(1 -θ 1 ) 2 (1 -ε)α k β/ κ2</formula><p>, with κ, θ 1 and θ 2 as in (9c) for (15a), and (15b), respectively. Moreover, for both cases, the step size is</p><formula xml:id="formula_64">α k ≥ 2(1 -θ 2 )(1 -β)(1 -ε)/κ,</formula><p>where κ is as in <ref type="bibr" target="#b7">(8)</ref>.</p><p>Proof We give the proof for sampling without replacement. The proof for sampling with replacement is obtained similarly. First, we note that Lemma 1 and (15b) imply</p><formula xml:id="formula_65">p T k ∇ F(x (k) ) ≤ -(1 -θ 2 )(1 -ε)γ p k 2 . (<label>17</label></formula><formula xml:id="formula_66">)</formula><p>So, p T k ∇ F(x (k) ) &lt; 0 and we can indeed obtain decrease in the objective function. As in the proof of Theorem (1), we get</p><formula xml:id="formula_67">F(x α ) -F(x (k) ) ≤ αp T k ∇ F(x (k) ) + α 2 K p k 2 /2.</formula><p>In order to pass the Armijo rule, we search for α such that</p><formula xml:id="formula_68">α K p k 2 ≤ -2(1 - β)p T k ∇ F(x (k) ). Hence, α ≤ 2(1 -θ 2 )(1 -β)(1 -ε)/κ, satisfies the Armijo rule.</formula><p>For part (i), we notice that by self-duality of the vector 2 norm, i.e.,</p><formula xml:id="formula_69">v 2 = sup{w T v; w 2 = 1}, (15a) implies p T k ∇ F(x (k) ) + ∇ F(x (k) ) T [H (x (k) )] -1 ∇ F(x (k) ) ≤ θ 1 ∇ F(x (k) ) [H (x (k) )] -1 ∇ F(x (k) ) . From Lemma 1 we have that [H (x (k) )] -1 1/((1 -ε)γ )I, which, in turn, gives [H (x (k) )] -1 ∇ F(x (k) ) ≤ ∇ F(x (k) ) T [H (x (k) )] -1 ∇ F(x (k) )/((1 -ε)γ ).</formula><p>Hence,</p><formula xml:id="formula_70">p T k ∇ F(x (k) ) ≤ q θ 1 ∇ F(x (k) ) / √ (1 -ε)γ -q , where q ∇ F(x (k) ) T [H (x (k) )] -1 ∇ F(x (k) ). Since q ≥ ∇F(x (k) ) / K |S | , if θ 1 ≤ (1 -ε)/(4 κ), then we get θ 1 ∇ F(x (k) ) ≤ q √ (1 -ε)γ /2.</formula><p>For part (ii), we have</p><formula xml:id="formula_71">θ 1 ∇ F(x (k) ) ≥ H (x (k) )p k + ∇ F(x (k) ) ≥ ∇ F(x (k) ) - H (x (k) )p k , which gives (1 -θ 1 ) ∇ F(x (k) ) ≤ H (x (k) )p k ≤ H (x (k) ) p k ≤ K |S | p k . (<label>17</label></formula><formula xml:id="formula_72">) implies p T k ∇ F(x (k) ) ≤ -(1-θ 2 )(1-ε)γ (1-θ 1 ) 2 ∇ F(x (k) ) 2 / K 2 |S |</formula><p>. By Assumption (6b), the results follow as in the end of the proof of Theorem 1.</p><p>By Theorem 2, in order to guarantee similar worst-case global convergence rate as that with exact update in Theorem 1, i.e., ρ k ∈ Ω(1/(κ κ)), it is sufficient to solve the linear system to a "small-enough" accuracy, i.e., Ω( 1/ κ). This requirement on relative accuracy is less strict than with what is found in similar literature. Clearly, this improvement merely manifests itself as a constant in the worst-case analysis of the number of CG iterations. However, in practice, the difference between the actual amount of work by CG to achieve a relative residual of O(1/ κ) versus O( 1/ κ), given the non-monotonic behavior of CG in terms of residuals, can be significant. By Theorem 2, large ill-conditioning, i.e., κ 1, or inaccurate Hessian estimation, i.e., large ε, both can necessitate small θ 1 , and if the linear system is not solved accurately enough, then the convergence rate can degrade, i.e., ρ k ∈ Ω(1/(κ κ2 )).</p><p>From Theorem 2, we see that the minimum amount of decrease in the objective function is mainly dependent on θ 1 , i.e., the accuracy of the linear system solve. On the other hand, the dependence of the step size, α k , on θ 2 indicates that the algorithm can take larger steps along a search direction, p k , that points more accurately towards the direction of the largest rate of decrease.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Global convergence: sub-sampled Hessian and gradient</head><p>We now consider SSN-type algorithms which are fully stochastic, in which, both the gradient and the Hessian are approximated. As before, we first study the iterations with exact solution of (2a), and then turn to inexact variants.</p><p>Exact update For the sub-sampled gradient and the Hessian, g(x (k) ), H (x (k) ), respectively, consider rewriting the update (2) for as x (k+1) = x (k) + α k p k , where</p><formula xml:id="formula_73">p k = -[H (x (k) )] -1 g(x (k) ), (<label>18a</label></formula><formula xml:id="formula_74">)</formula><p>and α k is the largest α ≤ 1 such that, for some β ∈ (0, 1), we have</p><formula xml:id="formula_75">F(x (k) + αp k ) ≤ F(x (k) ) + αβp T k g(x (k) ). (<label>18b</label></formula><formula xml:id="formula_76">)</formula><p>Algorithm 2 Globally Convergent SSN with Hessian and Gradient Sub-Sampling -Set the sample size, |S g |, with ε 2 , δ and x (k) as in Lemma 3 6:</p><formula xml:id="formula_77">1: Input: x (0) , 0 &lt; δ &lt; 1, 0 &lt; ε 1 &lt; 1, 0 &lt; ε 2 &lt; 1, 0 &lt; β &lt; 1,</formula><p>-Select a sample set, S g of size |S g | and form g(x (k) ) as in (11) 7:</p><p>if g(x (k) ) &lt; σε 2 then 8:</p><p>-STOP 9:</p><p>end if 10:</p><p>-Update x (k+1) as in <ref type="bibr" target="#b17">(18)</ref> with H (x (k) ) and g(x (k) ) 11: end for Theorem 3 (Global convergence of Algorithm 2) Let Assumptions (6) hold. For any x (k) ∈ R p , using Algorithm 2 with ε 1 ≤ 1/2 and σ ≥ 4 κ/(1 -β), we have the following with probability (1 -δ) 2 : if "STOP", then</p><formula xml:id="formula_78">∇ F(x (k) ) &lt; (1 + σ ) ε 2 ,</formula><p>otherwise, <ref type="bibr" target="#b13">(14)</ref> holds with ρ k = 8α k β/(9 κ) and α k ≥ (1 -β)(1 -ε 1 )/κ, where κ and κ are defined in <ref type="bibr" target="#b7">(8)</ref> and (9c), respectively. Proof We give the proof for the sampling without replacement as sampling with replacement is obtained similarly. By Lemma 1 and (13a), we have</p><formula xml:id="formula_79">p T k g(x (k) ) = -p T k H (x (k) )p k ≥ -(1 -ε 1 )γ p k 2 .</formula><p>Hence, since p T k g(x (k) ) &lt; 0, we can obtain decrease in the objective function. As in the proof of Theorem 1, we first need to show that there exists an iteration-independent step-size, α &gt; 0, such that (18b) holds for any 0 ≤ α ≤ α. For any 0 ≤ α, define x α = x (k) + αp k . By Assumption (6b), we have</p><formula xml:id="formula_80">F(x α ) -F(x (k) ) ≤ αp T k ∇ F(x (k) ) + α 2 K 2 p k 2 ≤ αp T k g(x (k) ) + α ∇ F(x (k) ) -g(x (k) ) p k + α 2 K 2 p k 2 ≤ -αp T k H (x (k) )p k + αε 2 p k + α 2 K 2 p k 2 .</formula><p>As a result, we need to find α such that</p><formula xml:id="formula_81">-αp T k H (x (k) )p k + ε 2 α p k + α 2 K p k 2 /2 ≤ -αβp T k H (x (k) )p k , which follows if ε 2 + α K p k /2 ≤ (1 -β)(1 -ε 1 )γ p k . This latter inequality holds if α = (1 -β)(1 -ε 1 )γ /K and ε 2 = (1-β)(1-ε 1 )γ p k /2. From H (x (k) )p k = -g(x (k) )</formula><p>, it is implied that to guarantee an iteration-independent lower bound for α as above, we need</p><formula xml:id="formula_82">ε 2 ≤ (1 -β)(1 -ε 1 )γ g(x (k) ) /(2 K |S | ),</formula><p>which, by the choice of σ and ε 1 , is imposed by the algorithm. If the stopping criterion succeeds, then by g(x (k) </p><formula xml:id="formula_83">) ≥ ∇ F(x (k) ) -ε 2 , we have ∇ F(x (k) ) &lt; (1 + σ ) ε 2 . Otherwise, by g(x (k) ) ≤ ∇ F(x (k) ) + ε 2 , we get (σ -1)ε 2 ≤ ∇ F(x (k) ) . Since σ ≥ 4, the latter inequality implies that 2 ∇ F(x (k) ) /3 ≤ (σ -2) ∇ F(x (k) ) /(σ -1) ≤ ∇ F(x (k) ) -ε 2 . From H (x (k) )p k = -g(x (k) ), it follows that 123 p T k H (x (k) )p k = g(x (k) ) T [H (x (k) )] -1 g(x (k) ) ≥ g(x (k) ) 2 / K |S | ≥ ( ∇ F(x (k) ) -ε 2 ) 2 / K |S | ≥ 4 ∇ F(x (k) ) 2 /(9 K |S | ).</formula><p>By Assumption (6b), the result follows as in the end of the proof of Theorem 1.</p><p>Theorem 3 only guarantees approximate optimality, where ∇ F(x (k) ) is small, and no iterate from Algorithm 2 is ensured to be exactly optimal, where ∇ F(x (k) ) vanishes. However, by (6b), in order to obtain sub-optimality in objective function as F(x (k) ) -F(x ) ≤ ς for some ς ≤ 1, it is sufficient to require that upon termination ∇ F(x (k) ) 2 &lt; 2ςγ , which, in turn, requires ε 2 ≤ √ 2ςγ /(1 + σ ); further related complexities are given in Table <ref type="table">3</ref>. It has been also well-established, e.g., <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b18">19]</ref>, that without increasing sample sizes for gradient estimation, one can, at best, hope for convergence to a neighborhood of the solution. This is indeed inline with Theorem 3; see also <ref type="bibr">Theorems 11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b13">and 14.</ref> Inexact update For some 0 ≤ θ 1 , θ 2 &lt; 1, consider the inexact version of (18a), as a solution of</p><formula xml:id="formula_84">H (x (k) )p k + g(x (k) ) ≤ θ 1 g(x (k) ) , (19a) p T k g(x (k) ) ≤ -(1 -θ 2 )p T k H (x (k) )p k . (<label>19b</label></formula><formula xml:id="formula_85">)</formula><p>Theorem 4 gives the global convergence of Algorithm 2 with update <ref type="bibr" target="#b18">(19)</ref>. The proof is given by combining the arguments used to prove Theorems 2 and 3, and hence, is omitted here. Theorem 4 (Global convergence of Algorithm 2: inexact update) Let Assumptions (6) hold, and 0 &lt; θ 1 , θ 2 &lt; 1 be given. For any x (k) ∈ R p , using Algorithm 2 with ε 1 ≤ 1/2, the "inexact" update <ref type="bibr" target="#b18">(19)</ref> instead of (18a), and σ ≥ 4 κ/ (1-θ 1 )(1-θ 2 )(1β) , the following holds with probability (1 -δ) 2 . If "STOP", then ∇ F(x (k) ) &lt; (1 + σ ) ε 2 . Otherwise <ref type="bibr" target="#b13">(14)</ref> </p><formula xml:id="formula_86">holds in which case if θ 1 ≤ (1 -ε 1 )/(4 κ), then ρ k = 4α k β/9 κ, else ρ k = 8α k β(1 -θ 2 )(1 -θ 1 ) 2 (1 -ε 1 )/9 κ2 , with κ defined as in (9c). Moreover, for both cases, α k ≥ (1 -θ 2 )(1 -β)(1 -ε 1 )/κ, with κ as in (8).</formula><p>Although Algorithm 2 employs sub-sampled gradients, the step-size α k , at each iteration, is chosen using exact evaluations of F in (18b). For most problems, the cost of evaluating a gradient is of the same order as that of the corresponding function. In this light, gradient sub-sampling in Algorithm 2 might, in fact, not contribute much in reducing the overall computational costs. However, in many problems, this can be remedied. Indeed, from the proof of Theorems 3, and 4, it is clear that we can simply, but conservatively, replace (18b) with α ≤ 2((β -1)p T k g(x (k) ) -ε 2 p k )/(K p k 2 ), and Theorems 3, and 4 would stay the same. In this case, at each iteration, the step size can be readily chosen, although potentially smaller than what we could obtain from (18b), without having to resort to any functional evaluations. However, this requires the knowledge of K , which might not be available for all problems. Fortunately, there are many important instances, in particular in machine learning, in which an estimate of K can easily be obtained, e.g., most popular generalized linear models (GLMs) such as ridge regression, logistic regression, and Poisson regression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Local convergence</head><p>While the classical Newton's method has seen great practical success in many application areas, the theoretical appeal mainly lies in its local convergence behavior. The folklore notion that "Newton method converges quadratically" is, in fact, a statement about its local theoretical guarantee. Indeed, any method striving to be Newton-type must enjoy similar superior local convergence properties. In this section, we set out to do that by showing that, locally, variants of SSN with Newton's method's "natural" step size, i.e., α k = 1, can achieve linear or superlinear convergence rates. Moreover, we show that such rates are problem-independent, i.e., the rates are prescribed by the user and are not affected by the problem under consideration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Local convergence: sub-sampled Hessian and full gradient</head><p>We now consider the framework (2) with α k = 1, where, for a given x (k) ∈ D ∩ C , we set g(x (k) ) = ∇ F(x (k) ) and H (x (k) ) is sub-sampled as in <ref type="bibr" target="#b9">(10)</ref>.</p><p>Exact update We first study the case where, at every iteration, (2a) is solved exactly. Lemma 4 which will be the foundation of our main results for this Section. Lemma 4 (Structural Lemma A) Let Assumption (7) hold. Also, for H (x (k) ) as in <ref type="bibr" target="#b9">(10)</ref>, assume that</p><formula xml:id="formula_87">p T H (x (k) )p &gt; 0, ∀ p ∈ K \{0}. (<label>20</label></formula><formula xml:id="formula_88">)</formula><p>For the update (2) with α k = 1, g(x (k) ) = ∇ F(x (k) ) and H (x (k) ), we have x (k+1)x ≤ ρ 0 x (k)x + ξ x (k)x 2 , where ξ 0.5L/λ K min (H (x (k) )), and</p><formula xml:id="formula_89">ρ 0 H (x (k) ) -∇ 2 F(x (k) ) K /λ K min (H (x (k) )).</formula><p>Proof Define Δ k x (k)x . From (2), since α k = 1, we get x (k+1) = x (k) . By optimality of x (k+1) in (2a), we have for any</p><formula xml:id="formula_90">x ∈ D ∩ C , (x -x (k+1) ) T ∇ F(x (k) ) + (x -x (k+1) ) T H (x (k) )(x (k+1) -x (k) ) ≥ 0.</formula><p>In particular, setting x = x , and noting that x (k+1) -</p><formula xml:id="formula_91">x (k) = Δ k+1 -Δ k , we get Δ T k+1 H (x (k) )Δ k+1 ≤ Δ T k+1 H (x (k) )Δ k - Δ T k+1 ∇ F(x (k) ). Optimality of x gives ∇ F(x ) T (x (k+1) -x ) ≥ 0, which implies Δ T k+1 H (x (k) )Δ k+1 ≤ Δ T k+1 H (x (k) )Δ k -Δ T k+1 ∇ F(x (k) ) + Δ T k+1 ∇ F(x ). Now, by the mean value theorem ∇ F(x (k) ) -∇ F(x ) = 1 0 ∇ 2 F x + t(x (k) -x ) dt (x (k) -x ),</formula><p>we have</p><formula xml:id="formula_92">Δ T k+1 H (x (k) )Δ k+1 ≤Δ T k+1 H (x (k) )Δ k -Δ T k+1 1 0 ∇ 2 F x + t(x (k) -x ) dt Δ k = Δ T k+1 H (x (k) )Δ k -Δ T k+1 ∇ 2 F(x (k) )Δ k + Δ T k+1 ∇ 2 F(x (k) )Δ k -Δ T k+1 1 0 ∇ 2 F x + t(x (k) -x ) dt Δ k ≤ H (x (k) ) -∇ 2 F(x (k) ) K Δ k Δ k+1 + 1 0 ∇ 2 F(x (k) ) -∇ 2 F x + t(x (k) -x ) K dt Δ k Δ k+1 ≤ H (x (k) ) -∇ 2 F(x (k) ) K Δ k Δ k+1 + L 2 Δ k 2 Δ k+1 ,</formula><p>where A K is as in <ref type="bibr" target="#b3">(4)</ref>. We also have</p><formula xml:id="formula_93">Δ T k+1 H (x (k) )Δ k+1 ≥ λ K min H (x (k) ) Δ k+1 2 .</formula><p>Assumption <ref type="bibr" target="#b19">(20)</ref> implies λ K min H (x (k) ) &gt; 0, and the result follows.</p><p>Note that for the case of -Select a sample set, S , of size |S | and H (x (k) ) as in (10) 5:</p><formula xml:id="formula_94">H (x (k) ) = ∇ 2 F(x (k) ),</formula><p>-Update x (k+1) as in (2) with g(x (k) ) = ∇ F(x (k) ), H (x (k) ), and α k = 1 6: end for Theorem 5 (Error recursion of (2) with ∇ F(x (k) ) and H (x (k) )) Let Assumptions <ref type="bibr" target="#b5">(6)</ref> and <ref type="bibr" target="#b6">(7)</ref> hold and let 0 &lt; δ &lt; 1 and 0 &lt; ε &lt; 1 be given. Set |S | as in Lemma 2, and let H (x (k) ) be as in <ref type="bibr" target="#b9">(10)</ref>. Then, for the update (2) with g(x (k) ) = ∇ F(x (k) ), H(x (k) ), and α k = 1 , with probability 1 -δ, we have</p><formula xml:id="formula_95">x (k+1) -x ≤ ρ 0 x (k) -x + ξ x (k) -x 2 , (<label>21a</label></formula><formula xml:id="formula_96">)</formula><p>where</p><formula xml:id="formula_97">ρ 0 = ε (1 -ε)</formula><p>,</p><formula xml:id="formula_98">and ξ = L 2(1 -ε)γ . (<label>21b</label></formula><formula xml:id="formula_99">)</formula><p>Proof By Lemma 2, we get</p><formula xml:id="formula_100">H (x) -∇ 2 F(x) K /λ K min (H (x)) ≤ ε/(1 -ε)</formula><p>. Now the results follow immediately by applying Lemma 4.</p><p>Bounds given here exhibit a composite behavior where the error recursion, when far from the optimum, is first dominated by a quadratic term and then by a linear term near the optimum. Notably, the coefficient of the linear term, ρ 0 , is indeed independent of any problem-related quantities, and only depends on the sub-sampling accuracy, ε. Of course, such problem dependent quantities indeed appear in the lower bound for the sample size, in the form of p and κ 1 ; see Lemma 2. Now we establish sufficient conditions for Q-linear convergence of Algorithm 3.</p><p>Theorem 6 (Q-linear convergence of Algorithm 3) Let Assumptions ( <ref type="formula" target="#formula_12">6</ref>) and (7) hold and consider any 0 &lt; ρ 0 &lt; ρ &lt; 1. Using Algorithm 3 with ε ≤ ρ 0 /(1 + ρ 0 ), if</p><formula xml:id="formula_101">x (0) -x ≤ ρ -ρ 0 ξ , (<label>22</label></formula><formula xml:id="formula_102">)</formula><p>with ξ as in Theorem 5, we get Q-linear convergence</p><formula xml:id="formula_103">x (k) -x ≤ ρ x (k-1) -x , k = 1, . . . , k 0 (<label>23</label></formula><formula xml:id="formula_104">)</formula><p>with probability (1 -δ) k 0 .</p><p>Proof Using this particular choice of ε, Theorem 5, for every k, yields</p><formula xml:id="formula_105">x (k+1) -x ≤ ρ 0 x (k) -x + ξ x (k) -x 2 .</formula><p>The result follows by requiring that ρ 0 x (0)x + ξ x (0)x 2 ≤ ρ x (0)x . Finally, let A k denote the event that x (k)x ≤ ρ x (k-1)x . The overall success probability is</p><formula xml:id="formula_106">Pr ⎛ ⎝ k 0 k=1 A k ⎞ ⎠ = Pr ⎛ ⎝ A k 0 | k 0 -1 k=1 A k ⎞ ⎠ Pr ⎛ ⎝ k 0 -1 k=1 A k ⎞ ⎠ = • • • = k 0 k=1 Pr ⎛ ⎝ A k | k-1 i=1 A i ⎞ ⎠ = (1 -δ) k 0 ,</formula><p>since for every k, the conditional probability of a successful update x (k+1) , given the past successful iterations</p><formula xml:id="formula_107">{x i } k i=1 , is 1 -δ.</formula><p>If the Hessian approximation accuracy increases as the iterations progress, we can also obtain Q-superlinear rate. In fact, it seems reasonable to expect that the rate at which the Hessian estimation accuracy increases, determines the actual rate of Q-superlinear convergence. To verify this, Theorems 7 and 8 consider, respectively, geometric and logarithmic increase in the Hessian approximation accuracy. These, in turn, give rise to Q-superlinearly convergent iterates where the actual speed of convergence from one iteration to the next increases, respectively, at geometric and logarithmic rates; cf. ρ(k) in the definition of Q-superlinear convergence in Sect. 1.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 4</head><p>Locally Superlinearly Convergent SSN with Hessian Sub-Sampling</p><formula xml:id="formula_108">1: Input: x (0) , 0 &lt; δ &lt; 1, 0 &lt; ε &lt; 1, 0 &lt; ρ &lt; 1 2: for k = 0, 1, 2, • • • until termination do 3:</formula><p>-Set ε (k) , for example as in Theorems 7 or 8 4:</p><p>-Set the sample size, |S (k) |, with ε (k) and δ as in Lemma 2 5:</p><p>-Select a sample set, S (k) , of size |S (k) | and H (x (k) ) as in (10) 6:</p><p>-Update x (k+1) as in (2) with g(x (k) ) = ∇ F(x (k) ), H (x (k) ), and α k = 1 7: end for Theorem 7 (Q-superlinear convergence of Algorithm 4: geometric growth) Let the assumptions of Theorem 6 hold. Using Algorithm 4, with ε (k) = ρ k ε, k = 0, 1, . . . , k 0 , if x (0) satisfies <ref type="bibr" target="#b21">(22)</ref> with ρ, ρ 0 , and ξ (0) , we get Q-superlinear convergence</p><formula xml:id="formula_109">x (k) x ≤ ρ k x (k-1) -x , k = 1, . . . , k 0 , (<label>24</label></formula><formula xml:id="formula_110">)</formula><p>with probability (1 -δ) k 0 , where ξ (0) is as in (21b) with ε (0) . Proof Theorem 5, for each k, gives x (k+1) -x ≤ ρ (k) 0</p><p>x (k) -x +ξ (k) x (k) -x 2 , where ρ (k) 0 and ξ (k) are as in (21b) using ε (k) . Note that, by ε (k) = ρ k ε and ε set as in Theorem 6, it follows that ρ (0)</p><formula xml:id="formula_111">0 ≤ ρ 0 , ρ (k)</formula><p>0 ≤ ρ k ρ 0 , and ξ (k) ≤ ξ (k-1) . We prove the result by induction on k. Define Δ k x (k) -x . For k = 0, by assumptions on ρ, ρ 0 , and ξ (0) , we have</p><formula xml:id="formula_112">Δ 1 ≤ ρ (0) 0 Δ 0 +ξ (0) Δ 0 2 ≤ ρ 0 Δ 0 +ξ (0) Δ 0 2 ≤ ρ Δ 0 . Now</formula><p>assume that ( <ref type="formula" target="#formula_109">24</ref>) holds up to the iteration k. For k + 1, we get</p><formula xml:id="formula_113">Δ k+1 ≤ ρ (k) 0 Δ k + ξ (k) Δ k 2 ≤ ρ k ρ 0 Δ k + ξ (k) Δ k 2 ≤ ρ k ρ 0 Δ k + ξ (0) Δ k 2 .</formula><p>By induction hypothesis, we have Δ k-1 ≤ Δ 0 , and</p><formula xml:id="formula_114">Δ k ≤ ρ k Δ k-1 &lt; ρ k (ρ -ρ 0 )/ξ (0) , hence it follows that Δ k+1 ≤ ρ k+1 Δ k .</formula><p>Theorem 8 (Q-superlinear convergence of Algorithm 4: logarithmic growth) Let Assumptions ( <ref type="formula" target="#formula_12">6</ref>) and (7) hold. Using Algorithm 4 with ε</p><formula xml:id="formula_115">(k) = 1/(1 + 2 ln(4 + k)), k = 0, 1, . . . , k 0 , if x (0) satisfies x (0) -x ≤ 2γ /((1 + 4 ln(2)) L), we get Q-superlinear convergence x (k) -x ≤ 1 ln(3 + k) x (k-1) -x , k = 1, . . . , k 0 , (<label>25</label></formula><formula xml:id="formula_116">)</formula><formula xml:id="formula_117">with probability (1 -δ) k 0 .</formula><p>Proof By the choice of ε (k) in (21b), we have ρ (k) 0 = 1/(2 ln(4 + k)), and as before ρ (k)  0 &lt; ρ (k-1) 0 and ξ (k) ≤ ξ (k-1) . We again prove the result by induction on k. For k = 0, by assumptions on x (0) and the choice of ε (0) , we have <ref type="bibr" target="#b3">(4)</ref>. Now assume that (25) holds up to the iteration k. For k + 1, we get</p><formula xml:id="formula_118">Δ 1 ≤ ρ (0) 0 Δ 0 + ξ (0) Δ 0 2 = Δ 0 /(2 ln(4)) + ξ (0) Δ 0 2 ≤ Δ 0 / ln</formula><formula xml:id="formula_119">Δ k+1 ≤ ρ (k) 0 Δ k + ξ (k) Δ k 2 ≤ Δ k /(2 ln(4 + k)) + ξ (k) Δ k 2 . (<label>26</label></formula><formula xml:id="formula_120">)</formula><p>Now consider φ(x) = ln(4 + x)/ln(3 + x). Since φ(0) &lt; 2 ln(2) and dφ(x)/dx &lt; 0, ∀x ≥ 0, i.e., φ(x) is decreasing, it follows that ln(4</p><formula xml:id="formula_121">+ k) ≤ 2 ln(2) ln(3 + k), ∀k ≥ 0. Since ln(3 + k) ≥ 1, we get (1 + 2 ln(4 + k)) ≤ ln(3 + k) (1 + 4 ln(2))</formula><p>. By induction hypothesis, we have Δ k-1 ≤ Δ 0 , and so</p><formula xml:id="formula_122">Δ k ≤ Δ k-1 / ln(3 + k) &lt; 2γ /(ln(3 + k) (1 + 2 ln(4)) L), which by above implies that Δ k ≤ 2γ /((1 + 2 ln(4 + k)) L) = 1/(2 ln(4 + k)ξ (k)</formula><p>). As a result, from (26), we get</p><formula xml:id="formula_123">Δ k+1 ≤ Δ k /(ln(4 + k)).</formula><p>Theorems 7 and 8 require that the sample-sizes increase across iterations at some prescribed rates. Consequently, sooner or later, one will require sample sizes that are of the same order as n. In this light, the results of Theorems 7 and 8 are more applicable in early stages of the algorithms where the samples sizes are small (relative to n). However, sub-sampling, even if done at intermediary steps and prior to switching to a full algorithm, can still valuable computational savings, e.g., see <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37]</ref> and references therein for hybrid approaches to solve large-scale inverse problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inexact update</head><p>We now consider the unconstrained case, where D = C = R p , and study iterations generated by inexact solutions to (2a) with α = 1, i.e., x (k+1) = x (k) + p k , where p k is as in (15a). In Theorem 2, we showed that a reasonably mild inexactness condition on θ 1 still gives a globally convergent method with convergence rate similar to that of the method with exact update (13a). We now show that similar inexactness condition is, indeed, sufficient to also guarantee a problem-independent local Q-linear convergence rate.</p><p>Theorem 9 (Q-Linear convergence of Algorithm 3: inexact update) Let Assumptions ( <ref type="formula" target="#formula_12">6</ref>) and <ref type="bibr" target="#b6">(7)</ref> hold and D = C = R p . Consider any 0 &lt; ρ 0 &lt; ρ &lt; 1 and</p><formula xml:id="formula_124">θ 1 ≤ ρ 0 (1 -ε)/4 κ.</formula><p>Consider Algorithm 3 with inexact update (15a) in place of (13a), and ε ≤ ρ 0 /(2 + ρ 0 ). Further assume that, to solve (15a), we use CG initialized at zero. Then if <ref type="bibr" target="#b21">(22)</ref> holds, we get Q-linear convergence as in <ref type="bibr" target="#b22">(23)</ref>, with probability</p><formula xml:id="formula_125">(1 -δ) k 0 . Proof For such inexact iteration we have x (k+1) -x = x (k) +p k -p k +p k -x ≤ p k -p k + Δ k+1 ≤ p k -p k +ρ 0 x (k) -x +ξ x (k) -x 2 ,</formula><p>where Δ k+1 , ρ 0 , and ξ are as in Lemma 4 and p k is the exact solution, i.e.,</p><formula xml:id="formula_126">p k = -[H (x (k) )] -1 ∇ F(x (k) ).</formula><p>Recall that by Lemma 2, with high probability, we have</p><formula xml:id="formula_127">v T H (x (k) )v ≥ (1 -ε)γ v 2 . Now, CG with p (0) k = 0, gives p (t) k -p k ≤ 2 √ (1 -ε)γ κ/(1 -ε) -1 κ/(1 -ε) + 1 t p k H (x (k) ) ,</formula><p>where p</p><formula xml:id="formula_128">(t)</formula><p>k is the t th iterate of CG, κ is as in (9c), and p A = p T Ap. We have</p><formula xml:id="formula_129">p k H (x (k) ) = ∇ F(x (k) ) T [H (x (k) )] -1 ∇ F(x (k) ) ≤ ∇F(x (k) ) / √ (1 -ε)γ . By (6b), ∇ F(x (k) ) = ∇ F(x (k) ) -∇ F(x ) ≤ K x (k) -x . Hence, p (t) k -p k ≤ 2 (1 -ε) κ κ/(1 -ε) -1 κ/(1 -ε) + 1 t x (k) -x ,</formula><p>where κ is as in <ref type="bibr" target="#b7">(8)</ref>. Now t as in <ref type="bibr" target="#b15">(16)</ref> gives</p><formula xml:id="formula_130">p (t) k -p k ≤ θ 1 κ x (k) -x /( (1 -ε) κ).</formula><p>The assumption on θ 1 , and noting κ ≤ κ, implies p (t)  kp k ≤ ρ 0 x (k)x /2. The rest of the proof follows by assumption on ε and similar to Theorem 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Local convergence: sub-sampled Hessian and gradient</head><p>We now study <ref type="bibr" target="#b1">(2)</ref> with both Hessian and gradient sub-sampling. We consider the setting where the gradient and Hessian are sub-sampled independently of each other.</p><p>The alternative is to use the same collection of indices perform simultaneous sub-sampling for both. This latter case is not considered here, as in our opinion and experience, it does not seem to offer any practical and theoretical advantages.</p><p>We now present Lemma 5, as a structural lemma, followed by our main theorems.</p><p>Lemma 5 (Structural Lemma B) Let Assumptions <ref type="bibr" target="#b6">(7)</ref> and ( <ref type="formula" target="#formula_87">20</ref>) hold. For the update <ref type="bibr" target="#b1">(2)</ref> with α k = 1, H(x (k) ) and g(x (k) ) as in <ref type="bibr" target="#b9">(10)</ref> and <ref type="bibr" target="#b10">(11)</ref>, respectively, we have</p><formula xml:id="formula_131">x (k+1) - x ≤ η + ρ 0 x (k) -x + ξ x (k) -x 2</formula><p>, where ρ 0 , ξ are as in Lemma 4 and</p><formula xml:id="formula_132">η = ∇ F(x (k) ) -g(x (k) ) K /λ K min (H (x (k)</formula><p>)), with v K as in <ref type="bibr" target="#b3">(4)</ref>. Proof The result follows as in the proof of Lemma 4, and using the identity g(x</p><formula xml:id="formula_133">(k) ) = g(x (k) ) -∇ F(x (k) ) + ∇ F(x (k) ), and noting that |Δ T k+1 (g(x (k) ) -∇ F(x (k) ))| ≤ g(x (k) ) -∇ F(x (k) ) K Δ k+1</formula><p>, simply follows from the definition of . K in (4).</p><p>Theorem 10 (Error recursion of (2) with g(x (k) ) and H (x (k) )) Let Assumptions ( <ref type="formula" target="#formula_12">6</ref>) and ( <ref type="formula" target="#formula_14">7</ref>) hold, and let 0 &lt; δ, ε 1 , ε 2 &lt; 1 be given. Set |S H | as in Lemma 2 with (ε 1 , δ) and |S g | as in Lemma 3 with (ε 2 , δ) and G(x (k) ). Independently, choose S H and S g , and let H (x (k) ) and g(x (k) ) be as in <ref type="bibr" target="#b9">(10)</ref> and <ref type="bibr" target="#b10">(11)</ref>, respectively. For the update <ref type="bibr" target="#b1">(2)</ref> with</p><formula xml:id="formula_134">α k = 1, with probability (1 -δ) 2 we have x (k+1) -x ≤ η + ρ 0 x (k) -x + ξ x (k) -x 2 , where η = ε 2 /((1 -ε 1 )γ ), ρ 0 = ε 1 /(1 -ε 1 ), and ξ = L/(2(1 -ε 1 )γ ).</formula><p>Similar to Theorem 5, the bounds given here exhibit a composite behavior where the error is, at first, dominated by a quadratic term, which transitions to a linear term, and finally is dominated by the approximation error in the gradient. R-linear convergence of Algorithms 5 is given in Theorem 11.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 5</head><p>Locally Linearly Convergent SSN with Hessian and Gradient Sub-Sampling 1: Input: x (0) , 0 &lt; δ &lt; 1, 0 &lt; ε 1 &lt; 1, 0 &lt; ε 2 &lt; 1 and 0 &lt; ρ &lt; 1 2: -Set the sample size, |S H |, with ε 1 and δ as in Lemma 2 3:</p><formula xml:id="formula_135">for k = 0, 1, 2, • • • until termination do 4:</formula><p>-Select a sample set, S H , of size |S H | and form H (x (k) ) as in (10) 5:</p><p>-Set</p><formula xml:id="formula_136">ε (k) 2 = ρ k ε 2 6:</formula><p>-Set the sample size, |S</p><formula xml:id="formula_137">(k) g |, with ε (k)</formula><p>2 , δ and x (k) as in Lemma 3 with G(x (k) ) 7:</p><p>-Select a sample set, S (k)</p><formula xml:id="formula_138">g of size |S (k)</formula><p>g | and form g(x (k) ) as in (11) 8:</p><p>-Update x (k+1) as in (2) with H (x (k) ), g(x (k) ) and α k = 1 9: end for Theorem 11 (R-linear convergence of Algorithm 5) Let Assumptions (6) and <ref type="bibr" target="#b6">(7)</ref> </p><formula xml:id="formula_139">hold. Consider any 0 &lt; ρ, ρ 0 , ρ 1 &lt; 1 such that ρ 0 + ρ 1 &lt; ρ. Let ε 1 ≤ ρ 0 /(1 + ρ 0 ), and define c 2 ρ -(ρ 0 + ρ 1 ) (1 -ε 1 )γ /L. Using Algorithm 5 with ε 2 ≤ (1-ε 1 )γρ 1 c, if the initial iterate, x (0) , satisfies x (0) -x ≤ c, we get R-linear convergence x (k) -x ≤ cρ k , (<label>27</label></formula><formula xml:id="formula_140">)</formula><p>with probability (1 -δ) 2k .</p><p>Proof Using Theorem 10, the particular choice of ε 1 and ε (k) 2 , where η (k) = ρη (k-1)  and η (0) ≤ ρ 1 c. We prove the result by induction on k. Define Δ k x (k)x . For k = 0, by the assumption on x (0) and the definition of c = ρ -(ρ 0 + ρ 1 ) /ξ , we have</p><formula xml:id="formula_141">2 ρ k ε 2 , for each k, gives x (k+1) -x ≤ η (k) + ρ 0 x (k) -x + ξ x (k) -x</formula><formula xml:id="formula_142">Δ 1 ≤ η (0) + ρ 0 Δ 0 + ξ Δ 0 2 ≤ ρ 1 c + ρ 0 c + ξ c 2 = ρc. Now assume that (27) holds for k. For k + 1, we get Δ k+1 ≤ η (k) + ρ 0 Δ k + ξ Δ k 2 = ρ k η (0) + ρ 0 Δ k + ξ Δ k 2 ≤ ρ k ρ 1 c + ρ 0 ρ k c + ξρ 2k c 2 ≤ ρ k ρ 1 c + ρ 0 c + ξ c 2 = ρ k+1 c</formula><p>, where the first and the second inequalities follow, respectively, from the induction hypothesis and ρ &lt; 1, and the final equality is by definition of c.</p><p>Theorem 11 implies that, to get linear convergence rate, estimation of the gradient must be done, progressively, more accurately, whereas the sample size for the Hessian can remain unchanged across iterations. This is in line with the common knowledge where, as the iterations get closer to the optimal solution, the accuracy of the gradient estimation is more important than that of the Hessian.</p><p>Similar to Theorem 9, it is possible to obtain results for a variant of Algorithm 5 with inexact updates. We simply state the following result and we omit the proof.</p><p>Theorem 12 (R-linear convergence of Algorithm 5: inexact update) Let Assumptions (6) and <ref type="bibr" target="#b6">(7)</ref> </p><formula xml:id="formula_143">hold and D = C = R p . Consider any 0 &lt; ρ, ρ 0 , ρ 1 &lt; 1 such that ρ 0 + ρ 1 &lt; ρ and θ 1 ≤ ρ 0 (1 -ε)/4 κ. Let ε 1 ≤ ρ 0 /(2 + ρ 0 ), define c 2 ρ -(ρ 0 + ρ 1 ) (1 -ε 1 )γ /L and set ε 2 ≤ (1 - ε 1</formula><p>)γρ 1 c. Consider Algorithm 5 with inexact update <ref type="bibr" target="#b18">(19)</ref> in place of (18a) and, assume that, to solve <ref type="bibr" target="#b18">(19)</ref>, we use CG initialized at zero. If x (0)x ≤ c, we get locally R-linear convergence as in <ref type="bibr" target="#b26">(27)</ref>, with probability (1 -δ) 2k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Putting it all together</head><p>Theorem 1 guarantees the global convergence of Algorithm 1 with a linear rate that depends on the problem specific quantities i.e., κ and κ. However, by Theorem 6, the locally linear convergence rate of such SSN variant with α k = 1 is indeed problemindependent. In fact, it is possible to combine both results to show that Algorithm 1 is globally convergent with a (super)linear and problem-independent local rate. We also show that after certain number of iterations, Armijo line search automatically adopts the natural step size of the classical Newton's method, i.e., α k = 1, for all subsequent iterations. We note that here, we give unifying results for the case of exact update. Since the extensions to inexact updates is done similarly, we omit the details.</p><p>Theorem 13 (Global convergence of Algorithm 1 with problem-independent local rate) Let Assumptions (6) and (7) hold, and consider any 0 &lt; ρ 0 &lt; ρ &lt; 1. Using Algorithm 1 with any x (0) ∈ R p ,</p><formula xml:id="formula_144">ε ≤ min (1 -2β)/(2(1 -β)), ρ 0 /(4(1 + ρ 0 ) √ κ 1 ) ,</formula><p>and 0 &lt; β &lt; 1/2, after at most k ∈ O(κ κ/(1-ε)) iterations, with probability (1-δ) k we get problem-independent Q-linear convergence, i.e., x -x ≤ ρ x (k-1) -x , where κ, κ 1 and κ are defined in <ref type="bibr" target="#b7">(8)</ref>, (9a) and (9c), respectively. Moreover, the step size of α k = 1 is selected in (13b) for all subsequent iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof</head><p>The choice of ε is to meet a requirement of Theorem 6 and account for the differences between Lemmas 1 and 2. The rest of the proof follows similar line of reasoning as in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr">Section 9.5.3]</ref>. Define x α = x (k) + αp k . By <ref type="bibr" target="#b6">(7)</ref>, we get</p><formula xml:id="formula_145">p T k (∇ 2 F(x α ) - ∇ 2 F(x (k) ))p k ≤ αL p k 3 , which, gives p T k ∇ 2 F(x α )p k ≤ p T k ∇ 2 F(x (k) )p k + αL p k 3 . Defining F(α) F(x (k) + αp k ), we get F (α) ≤ F (0) + αL p k 3 . Integrating this inequality gives F (α) ≤ F (0) + α F (0) + α 2 L p k 3 /2. Integrating again yields F(α) ≤ F(0) + α F (0) + α 2 F (0)/2 + α 3 L p k 3 /6.</formula><p>We also have that</p><formula xml:id="formula_146">p k 2 = [H (x (k) )] -1 ∇ F(x (k) ) 2 ≤ ∇ F(x (k) ) T [H (x (k) )] -1 ∇ F(x (k) )/((1 -ε)γ ).</formula><p>In addition, we get</p><formula xml:id="formula_147">F (0) = p T k ∇ F(x (k) ) = -∇ F(x (k) ) T [H (x (k) )] -1 ∇ F(x (k) )</formula><p>and</p><formula xml:id="formula_148">F (0) = p T k ∇ 2 F(x (k) )p k = ∇ F(x (k) ) T [H (x (k) )] -1 ∇ 2 F(x (k) )[H (x (k) )] -1 ∇ F(x (k) ) ≤ ∇ F(x (k) ) T [H (x (k) )] -1 ∇ F(x (k) )/(1 -ε).</formula><p>For the last inequality, recall that by the choice of ε and Lemma 2, we have H (x (k) )-∇ 2 F(x (k) ) ≤ εγ . Hence, for any v, we get</p><formula xml:id="formula_149">v T [H (x (k) )] -1 ∇ 2 F(x (k) )[H (x (k) )] -1 v -v T [H (x (k) )] -1 v ≤ εγ v T [H (x (k) )] -2 v ≤ εv T [H (x (k) )] -1 v/(1-ε).</formula><p>This latter inequality in turn gives</p><formula xml:id="formula_150">v T [H (x (k) )] -1 ∇ 2 F(x (k) )[H (x (k) )] -1 v ≤ v T [H (x (k) )] -1 v/(1 -ε).</formula><p>Hence, with α = 1 and denoting c(x) ∇ F(x) T [H (x)] -1 ∇ F(x), we have</p><formula xml:id="formula_151">F(x (k) + p k ) ≤ F(x (k) ) + 1 2(1 -ε) -1 c(x (k) ) + L 6 1 (1 -ε)γ c(x (k) ) 3/2 ≤ F(x (k) ) + c(x (k) ) 1 2(1 -ε) -1 + L 6 1 (1 -ε)γ 3/2 c(x (k) ) 1/2 . From c(x) ≤ ∇ F(x) 2 /((1 -ε)γ ), we see that if ∇ F(x (k) ) ≤ 3(1 -ε)γ 2 1 -2ε -2(1 -ε)β /L, (<label>28</label></formula><formula xml:id="formula_152">)</formula><p>then we get F(x</p><formula xml:id="formula_153">(k) + p k ) ≤ F(x (k) ) -β∇ F(x (k) ) T [H (x (k) )] -1 ∇ F(x (k) ) = F(x (k) ) + βp T k ∇ F(x (k) ), which implies that (13b) is satisfied with α = 1.</formula><p>The proof is complete if we can find k such that both the sufficient condition of Theorem 6 as well as ( <ref type="formula" target="#formula_151">28</ref>) is satisfied. First, note that from Theorem 1, Assumption (6b) and the iteration-independent lower bound on α k , we get ∇ F(x (k) ) 2 ≤ 2K (1ρ) k (F(x (0) ) -F(x )), where = 4β(1 -β)(1 -ε)/( κκ). In order to satisfy <ref type="bibr" target="#b27">(28)</ref>, we require that</p><formula xml:id="formula_154">2K (1-ρ) k (F(x (0) ) -F(x ))≤4L -2 (1 -ε) 2 γ 4 1 -2ε -2(1 -ε)β 2 (ρ 1 -ρ 0 ) 2 ,</formula><p>which is satisfied as long as k ∈ Ω(κ κ/(1 -ε)). From Theorem 1 and Assumption (6b),we get x (k)x 2 ≤ 2(1 -ρ) k (F(x (0) ) -F(x ))/γ , which implies that</p><formula xml:id="formula_155">x (k) -x 2 ≤ 4(1 -ε) 2 γ 3 1 -2ε -2(1 -ε)β 2 (ρ 1 -ρ 0 ) 2 /(K L 2 ) ≤ 4L -2 (1 -ε) 2 γ 2 (ρ 1 -ρ 0 ) 2 .</formula><p>Hence, the condition of Theorem 6 holds and the results follow.</p><p>Note that the ε required by Theorem 13 implies a sample size of Õ(κ 2 1 ). It is also possible to obtain a globally convergent algorithm with locally superlinear rate of convergence using Algorithm 1 with iteration dependent ε(k) as ε(k) ≤ ε (k) /( <ref type="formula" target="#formula_7">4</ref>√ κ 1 ),</p><p>where ε (k) is chosen as in Theorems 7 or 8. The details are similar to Theorem 13 and are omitted here. We now give similar results for Algorithm 2.</p><p>Theorem 14 (Global convergence of Algorithm 2 with problem-independent local rate) Let Assumptions (6) and (7) hold. Consider any 0 &lt; ρ 0 , ρ 1 , ρ 2 &lt; 1 such that ρ 0 + ρ 1 &lt; ρ 2 , β ≤ 1/2, σ ≥ 4 κ/(1 -β), and</p><formula xml:id="formula_156">ε 1 ≤ min (1 -2β)/(2(1 -β)), ρ 0 /(4(1 + ρ 0 ) √ κ 1 ) , ε (0) 2 ≤ εγ 2 /(L √ κ), If γ 2 ≤ L √ κ, εL √ κ/γ 2 , Otherwise, ε (k) 2 = ρ 2 ε (k-1) 2 , k = 1, 2, . . . , where ε ≤ (1 -ε 1 ) 2 (1 -2ε 1 -2(1 -ε 1 )β) 2 ρ 1 (ρ 2 -(ρ 0 + ρ 1 ))/3.</formula><p>Using Algorithm 2 with any x (0) ∈ R p and Step 7 replaced by g(x (k) ) &lt; σ ρ k 2 ε, after at most k 0 ∈ O(κ κ/(1 -ε 1 )) iterations, we have the following with probability</p><formula xml:id="formula_157">(1 -δ) 2k for k ≥ k 0 : if "STOP", then ∇ F(x (k) ) &lt; (1 + σ ) ρ k 2 ε, otherwise, we get problem- independent R-linear convergence, i.e., x (k) -x ≤ cρ (k-k 0 ) 2</formula><p>, where c is as defined in Theorem 11. Moreover, α k = 1 is selected in (18b) for all subsequent iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof The choice of ε 1 and ε (k)</head><p>2 is to meet a requirement of Theorem 11 and account for the differences between Lemma 1 and 2. As in the proof of Theorem 13, we get F(α) ≤ F(0) + α F (0) + α 2 F (0)/2 + α 3 L p k 3 /6. We also have</p><formula xml:id="formula_158">p k 2 = [H (x (k) )] -1 g(x (k) ) 2 ≤ g(x (k) ) T [H (x (k) )] -1 g(x (k) )/ (1 -ε 1 )γ .</formula><p>By self-duality of the vector 2 norm, i.e., v 2 = sup{w T v; w 2 = 1}, and</p><formula xml:id="formula_159">∇ F(x (k) ) -g(x (k) ) ≤ ε (k) 2 , get p T k ∇ F(x (k) ) ≤ p T k g(x (k) ) + ε (k) 2</formula><p>p k , and so</p><formula xml:id="formula_160">F (0) = p T k F(x (k) ) ≤ -g(x (k) ) T [H (x (k) )] -1 g(x (k) ) + ε (k) 2 p k .</formula><p>As in the proof of Theorem 13, we also have</p><formula xml:id="formula_161">F (0) = p T k ∇ 2 F(x (k) )p k ≤ g(x (k) ) T [H (x (k) )] -1 g(x (k) )/(1 -ε 1 ).</formula><p>Hence, with α = 1 and denoting h(x) g(x) T [H (x)] -1 g(x), we get</p><formula xml:id="formula_162">F(x α ) ≤ F(x (k) ) + 1 2(1 -ε 1 ) -1 h(x (k) ) + L 6 h(x (k) ) (1 -ε 1 )γ 3/2 + ε (k) 2 h(x (k) ) (1 -ε 1 )γ 1/2 ≤ F(x (k) ) + h(x (k) ) 1 2(1 -ε 1 ) -1 + L 6 h(x (k) ) 1/3 (1 -ε 1 )γ 3/2 + ε (k) 2 h(x (k) ) -1 (1 -ε 1 )γ 1/2 ≤ F(x (k) ) + h(x (k) ) 1 2(1 -ε 1 ) -1 + L g(x (k) ) 6(1 -ε 1 ) 2 γ 2 + ε (k) 2 κ g(x (k) ) -2 1 -ε 1 1/2</formula><p>, where the last inequality follows from g(x) 2 </p><formula xml:id="formula_163">/ K |S | ≤ h(x) ≤ g(x) 2 /((1 -ε 1 )γ ). Now denoting y g(x (k) ) and A L/(6(1 -ε 1 ) 2 γ 2 ), B 0.5/(1 -ε 1 ) -1 + β, and C ε (k) 2 ( κ/(1 -ε 1 )) 1/2 ,</formula><p>we require that Ay 2 + By + C ≤ 0. After a little bit of algebra, the roots of this polynomial can be written as</p><formula xml:id="formula_164">y 1 , y 2 = 3(1 -ε 1 )γ 2 (1 -2ε 1 -2(1 -ε 1 )β) 2L ± 9(1 -ε 1 ) 2 γ 4 (1 -2ε 1 -2(1 -ε 1 )β) 2 -24(1 -ε 1 ) 3/2 γ 2 Lε (k) 2 κ1/2 2L . Let us define q 1 (ε 1 , ε (k) 2 , β, κ, L) (q -q 2 -r )/(2L) and q 2 (ε 1 , ε (k) 2 , β, κ, L) (q + q 2 -r )/(2L), where q 3(1 -ε 1 )γ 2 (1 -2ε 1 -2(1 -ε 1 )β) and also r 24(1 -ε 1 ) 3/2 γ 2 Lε (k) 2 κ1/2 . It is easy to see that q 1 (ε 1 , ε (k) 2 , β, κ, L) is increasing with ε (k) 2 and q 1 (ε 1 , 0, β, κ, L) = 0, while q 2 (ε 1 , ε (k) 2 , β, κ, L) is decreasing with ε (k) 2</formula><p>and also q 2 (ε 1 , 0, β, κ, L) is equal to the right hand side of <ref type="bibr" target="#b27">(28)</ref>. In order to ensure that q 1 and q 2 are real, we also need to have ε k) ), which implies that (18b) is satisfied with α = 1. The left hand side of ( <ref type="formula" target="#formula_165">29</ref>) is enforced by the stopping criterion of the algorithm as for any ε</p><formula xml:id="formula_165">(k) 2 ≤ 3 √ (1 -ε 1 )γ 2 (1 -2ε 1 -2(1 - ε 1 )β) 2 /(8L √ κ). Now if q 1 (ε 1 , ε (k) 2 , β, κ, L) ≤ g(x (k) ) ≤ q 2 (ε 1 , ε (k) 2 , β, κ, L), (<label>29</label></formula><formula xml:id="formula_166">) we get F(x (k) + p k ) ≤ F(x (k) ) -βg(x (k) ) T [H (x (k) )] -1 g(x (k) ) = F(x (k) ) + βp T k g(x<label>(</label></formula><formula xml:id="formula_167">(k) 2 , q 1 (ε 1 , ε (k) 2 , β, κ, L) ≤ σ ε (k) 2 . Indeed, from q 2 -r ≥ q √ r , it implies that q 1 (ε 1 , ε (k) 2 , β, κ, L) ≤ √ r /(2L) ≤ 6γ 2 ρ k 2 ε (0) 2 κ/(L κ) = 6ρ k 2 ε κ ≤ σ ρ k 2 ε.</formula><p>The proof is complete if we can find k such that both the sufficient condition of Theorem 11 as well as the right hand side of ( <ref type="formula" target="#formula_165">29</ref>) is satisfied. First note that from Theorem 3, Assumption (6b) and by using the iteration-independent lower bound on α k , it follows that ∇ F(x (k) ) 2  (k) ) . Now, to satisfy the right hand side of (29), we require that</p><formula xml:id="formula_168">≤ 2K (1 -ρ) k (F(x (0) ) -F(x )), where ρ = 8β(1 -β)(1 -ε 1 )/(9 κκ). If the stopping criterion succeeds, then since ε (k) 2 ≤ 1, by g(x (k) ) ≥ ∇F(x (k) ) -ε (k) 2 , we get ∇ F(x (k) ) &lt; (1 + σ ) ρ k 2 ε. Otherwise, by g(x (k) ) ≤ ∇ F(x (k) ) + ε (k) 2 ≤ ∇ F(x (k) ) + ε (k) 2 , we get (σ -1) ε (k) 2 ≤ ∇ F(x (k) ) , which implies that g(x (k) ) ≤ σ ∇ F(x (k) ) /(σ -1) ≤ 2 ∇ F(x</formula><formula xml:id="formula_169">8K (1 -ρ) k (F(x (0) ) -F(x )) ≤ 16(ρ 2 -(ρ 0 + ρ 1 )) 2 q 2 2 (ε 1 , ε (k) 2 , β, κ, L)/9,</formula><p>which is satisfied as long as k ∈ Ω(κ κ/(1 -ε 1 )). Again, from Theorem 3 and Assumption (6b), we get</p><formula xml:id="formula_170">x (k) -x 2 ≤ 2(1 -ρ) k (F(x (0) ) -F(x ))/γ , which implies that x (k) -x 2 ≤ 16(ρ 2 -(ρ 0 + ρ 1 )) 2 q 2 2 (ε 1 , ε (k) 2 , β, κ, L) 36γ K ≤ 4(ρ 2 -(ρ 0 + ρ 1 )) 2 (1 -ε 1 ) 2 γ 4 (1 -2ε 1 -2(1 -ε 1 )β) 2 γ K L 2 ≤ 4(ρ 2 -(ρ 0 + ρ 1 )) 2 (1 -ε 1 ) 2 γ 2 L 2 = c 2 .</formula><p>Hence, the sufficient condition of Theorem 11 is also satisfied.</p><p>Sampling complexities implied by Theorem 14 can be made more explicit as follows.</p><p>For simplicity, assume that</p><formula xml:id="formula_171">ρ 0 = ρ 1 = 1/8, ρ 2 = 1/2, γ 2 ≤ L √ κ and β ≤ 1/10, for which we have (1 -ε 1 ) 2 (1 -2ε 1 -2(1 -ε 1 )β) 2 ≥ 1/4, ∀ε 1 ≤ 1/10, i.e., ε ∈ O(1). Further, for G(x) in Lemma 3, assume that we have a uniform estimate as G(x) ≤ G &lt; ∞. The requirements on ε 1 and ε (k) 2 in Theorem 14 imply |S H | ∈ Õ(κ 2 1 ), and |S (k) g | ∈ Õ(4 k G 2 L 2 κ/γ 4 ), respectively.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Comparison of computational complexities</head><p>We now present a brief overview of the computational complexities implied by the main results of this paper. We consider both exact and inexact variants of all these algorithms for unconstrained variant of (1), i.e., D = C = R p . For inexact solutions, we consider the tolerances of θ 1 ≤ (1 -ε)/(4 κ) and θ 2 = 1/2 in ( <ref type="formula" target="#formula_57">15</ref>) and <ref type="bibr" target="#b18">(19)</ref>. We Table <ref type="table">3</ref> Complexity comparison of various Newton-type methods for unconstrained version of (1) to achieve sub-optimality F(x (k) ) -F(x ) ≤ ς for some ς ≤ 1. For step-size, we consider iterations with the worst-case α k , as prescribed by the corresponding theorem. The notation Õ implies hidden logarithmic factors, e.g., ln(κ), ln( κ), ln( p), and ln(1/δ). Constants γ, κ, κ and κ 1 are defined in Sect. 1.5. Also, ε is the Hessian approximation accuracy parameter from Lemma 1. For G(x) in Lemma 3, we assume that we have a uniform estimate as G(x) ≤ G &lt; ∞ Table <ref type="table">4</ref> Complexity comparison of various Newton-type methods for unconstrained version of (1) to achieve sub-optimality x (k) )x ≤ ς for some ς ≤ 1, assuming x (0) is close enough to x . For the local convergence rate as in ( <ref type="formula" target="#formula_103">23</ref>) and ( <ref type="formula" target="#formula_139">27</ref>), we set ρ = 1/e, where e is the Euler's number. The notation Õ implies hidden logarithmic factors, e.g., ln(κ), ln( κ), ln( p), and ln(1/δ). Constants γ, κ, κ and κ 1 are defined in Sect. 1.5. Also, ε is the Hessian approximation accuracy parameter from Lemma 2. For G(x) in Lemma 3, we assume that we have a uniform estimate as G(x) ≤ G &lt; ∞ assume that the cost of one Hessian-vector product is of the same order as evaluating a gradient, e.g, <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b41">42]</ref>. From Tables <ref type="table">3</ref> and<ref type="table">4</ref>, the overall worst-case running-time of an algorithm to achieve the prescribed sub-optimality is estimated as Column #2 + Column #3 × Column #4 × Column #5. We remind that the complexity results for the proposed algorithms in Tables <ref type="table">3</ref> and<ref type="table">4</ref> are given assuming that the underlying probabilistic events occur successfully over the required finite number of iterations to achieve the desired sub-optimality.</p><p>In Tables <ref type="table">3</ref> and<ref type="table">4</ref>, ε is the Hessian approximation accuracy parameter from Lemmas 1 and 2. As for the overall failure probability, recall that in order to get an accumulative success probability of 1 -δ 0 for k ∈ O(T ) iterations, the per-iteration failure probability is set as δ = 1 -T √ (1 -δ 0 ) ∈ Ω(δ 0 /T ). Since the overall iteration complexity is affected by ε (see Table <ref type="table">3</ref>), the per-iteration failure probability, δ, should also be chosen in relation to ε (of course, the overall failure probability, δ 0 , can be chosen arbitrarily). However, since this dependence manifest itself only logarithmically, it is of negligible consequence in overall complexity.</p><p>Here, we only compare worst-case complexities of the algorithms studied in this paper with their deterministic counterparts, i.e., Newton's method; see e.g., <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b41">42]</ref> for tables which include complexities of other methods. We note that these complexities are, not only, for worst-case analysis, but also they are very pessimistic. For example, the worst-case complexity required to incorporate gradient sub-sampling might give the impression that such sampling is advantageous merely in some marginal cases. However, this unfortunate impression is a by-product of our analysis more so than it is an inherent property of an algorithm that incorporates gradient sampling. In this light, any conclusions from these tables should be made with great care.</p><p>Table <ref type="table">3</ref> gives complexities involved in various algorithms for achieving suboptimality in objective value, i.e., F(x (k) ) -F(x ) ≤ ς for some ς ≤ 1. We consider complexity of iterations with the worst-case step-size, α k , as prescribed by the corresponding theorem, which alleviates the need to perform line-search. One can make several observations regarding Table <ref type="table">3</ref>. As expected, it is advisable to perform gradient and Hessian sub-sampling only when n 1; Table <ref type="table">3</ref>, very pessimistically, suggests that gradient and Hessian sub-sampling offer computational savings when n ≥ G 2 κ2 /(ς γ ) and n ≥ κ 1 ε -2 , respectively. Also, if n ∈ O(κ 1 ε -2 p), then one can consider using the full gradient. Notice that, as expected, gradient sampling complexity depends on the sub-optimality parameter ς . Uniform sampling gives similar worst-case iteration complexity as classical Newton's method only if κ ∈ O(κ), where κ and κ are as in ( <ref type="formula" target="#formula_15">8</ref>) and (9c), respectively. Otherwise, if problem admits favorable structure, non-uniform sampling can offer better iteration complexity than uniform sampling; see <ref type="bibr" target="#b41">[42]</ref>. From Table <ref type="table">3</ref>, one can make comparisons among these methods in terms of total worst-case running-time. For example, if n ≤ κ 1 κ/(ε 2 (1 -ε)κ), then the exact variant of Newton's method, has lower worst-case running-time than Algorithm 1 using (13a), i.e., Hessian sub-sampling might not help! Table <ref type="table">4</ref> gives similar results to achieve sub-optimality in iterates, i.e., x (k)x ≤ ς for some ς ≤ 1. For this. we assume that x (0) is close enough to x , and the local convergence rates in <ref type="bibr" target="#b22">(23)</ref> and ( <ref type="formula" target="#formula_139">27</ref>) are set to ρ = 1/e, where e is the Euler's number. Although, Newton-CG can be made super-linearly convergent <ref type="bibr" target="#b16">[17]</ref>, in Table <ref type="table">4</ref>, for simplicity, we also do not consider super-linearly convergent algorithms. As a result, computational costs of Algorithms 4 is not considered. In Step 5 of Algorithm 5, the gradient accuracy is increased at every iteration. Hence, to calculate the gradient sampling complexity in Table <ref type="table">4</ref>, we consider the accuracy at the final iteration, i.e., ε (k) 2 for k ∈ O(ln(1/ς )). From Table <ref type="table">4</ref>, one can also make similar observations. In Table <ref type="table">3</ref>, there is a noteworthy trade-off in choosing ε in terms of its effect on sampling and iteration complexities. Indeed, smaller ε yields larger samples but this, in turn, not only implies fewer iterations of CG (if (2a) is solved inexactly), but also it involves fewer overall iterations to achieve a desired sub-optimality. More subtly, if the distribution of Hessians are very skewed and we perform sampling without replacement, decreasing ε would also decrease κ, which helps with many aspects of underlying complexities. For local convergence, however, as indicated by Table <ref type="table">4</ref>, as long as ε is chosen small enough (so we can appeal to the corresponding theorems), overall iteration complexity is unaffected by ε (this is indeed implied by the problem-independent local rates); although there is still a trade-off between sampling complexity and CG iterations.</p><p>From Tables <ref type="table">3</ref> and<ref type="table">4</ref>, it is also clear that in the absence of a good preconditioner, if κ ≥ (1 -ε) p 2 , solving (2a) exactly can be potentially more efficient than resorting to any inexact method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and further thoughts</head><p>Our primary objective here was to contribute in painting a more complete picture of the theory of sub-sampled Newton-type algorithms. For that, we considered large-scale optimization problems of the form (1) where n, p 1, and we theoretically studied the global as well as local convergence behavior of Newton-type algorithms, where the Hessian and/or gradient are sub-sampled. We studied sub-sampling strategies to obtain an algorithm which enjoys desirable theoretical properties, in that, not only it is globally convergent, but also it enjoys a fast and problem-independent local convergence rate. We also showed that when the sub-problem is solved approximately to a milder inexactness tolerance than what is found in the similar literature, we can maintain the convergence properties of the methods with exact updates.</p><p>An important distinction of the "high-probability" style of analysis from classical convergence results is that, here, no sensible statement about the asymptotic convergence of an infinite sequence of these random iterates can be made. More specifically, it is clear that the overall success probability for T iterations, each having failure probability of δ is (1 -δ) k . Now for an infinite number of iterations, i.e., k → ∞, this probability goes to zero, implying that, regardless of how small δ is chosen, at some point along the way, the Hessian and/or gradient approximations fail to deliver the desired estimates. Arguably, this can be regarded as a disadvantage for such style of analysis. However, in practice, one almost always terminates the iterations either if a certain algorithmic condition is met or after a pre-prescribed maximum number of iterations is reached. In this case, the overall failure probability can be set as small as desired to fit one's required level of confidence.</p><p>Even in a finite number of iterations, one might still wonder what can happen when, at any one iteration, sub-sampled approximations fail to deliver the required properties, i.e., when the "good" probabilistic events do not occur. After all, regardless of how small δ is, there is always a positive probability that "bad" events happen. Fortunately, the algorithms incorporating line-search are inherently resilient to misestimation of the Hessian. More specifically, if at some point the sub-sampled Hessian fails to satisfy the invertibility promised by Lemma 1, then Algorithms 1 or 2 do not fail, e.g., do not diverge. In such as an unfortunate situation where the sub-sampled Hessian contains a non-trivial null-space, (augmented) CG algorithm <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref> can reliably be used to either find a solution of the underlying linear system (a solution exists when the gradient is orthogonal to the null space of Hessian) or the corresponding pseudoinverse solution. In either case, since the sub-sampled matrix is positive semi-definite, even if the obtained direction cannot not yield a sufficient decrease in the objective function, it will certainly not cause an increase, and with high probability, in the very next iteration, the algorithm will recover from such a stall. Misestimation of the gradient at any step, however, can be quite serious and result in divergence. In this case, additional safeguards needs to be put in place to avoid such unwanted behavior, e.g., restarting from the previous iterate if the objective is to increase. Investigating alternative strategies to line-search, e.g., trust-region <ref type="bibr" target="#b12">[13]</ref>, which can potentially provide more robustness to such misestimations is an interesting direction for future research.</p><p>Finally, an alternative to the high-probability style of analysis considered here, is the convergence in expectation, e.g., <ref type="bibr" target="#b4">[5]</ref>, which has the advantage of giving asymptotic results. However, convergence in expectation has its own disadvantages among which, to interpret the results, it is implied that one must run the algorithm (possibly infinitely) many times, and then average all the outcomes. In other words, unlike high-probability analysis, convergence in expectation provides no statement on the results of individual runs. We believe that these two styles of analysis are, not only, related in many ways, but also they are complementary and, together, can paint a much more complete picture of the behavior of these randomized algorithms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>2 ,</head><label>2</label><figDesc>. . . , n. Now, approximating the gradient using sub-sampling is equivalent to approximating the product AB in (12) by sampling columns and rows of A and B, respectively, and forming matrices A and B such A B ≈ AB. More precisely, for a random sampling index set S , we can represent the sub-sampled gradient<ref type="bibr" target="#b10">(11)</ref>, by the product A B where A ∈ R p×|S | and B ∈ R |S |×1 are formed by selecting uniformly at random and with replacement, |S | columns and rows of A and B, respectively, rescaled by n/|S |.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 3</head><label>3</label><figDesc>we exactly recover the convergence rate of the classical Newton's method<ref type="bibr" target="#b2">[3,</ref> Proposition 1.4.1].Using Sampling Lemma 2 and Structural Lemma 4, we are now in the position to present the main results of this section. Locally Linearly Convergent SSN with Hessian Sub-Sampling 1: Input: x (0) , 0 &lt; δ &lt; 1, 0 &lt; ε &lt; 1 2: -Set the sample size, |S |, with ε and δ as described in Lemma 2 3: for k = 0, 1, 2, • • • until termination do 4:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>σ ≥ 0 2: -Set the sample size, |S H |, with ε 1 and δ as in Lemma 1 3: for k = 0, 1, 2, • • • until termination do 4:-Select a sample set, S H , of size |S H | and form H (x(k) ) as in (10) 5:</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bullins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.03943</idno>
		<title level="m">Second order stochastic optimization in linear time</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Berahas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bollapragada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.06211</idno>
		<title level="m">An investigation of Newton-sketch and subsampled Newton methods</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nonlinear Programming</title>
		<meeting><address><addrLine>Belmont</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Convex Optimization Theory</title>
		<meeting><address><addrLine>Belmont</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Exact and inexact subsampled Newton methods for optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bollapragada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08502</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>To appear in IMA Journal of Numerical Analysis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vandenberghe</surname></persName>
		</author>
		<title level="m">Convex Optimization</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On the use of stochastic Hessian information in optimization methods for machine learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Neveitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="977" to="995" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Sample size selection in optimization methods for machine learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="127" to="155" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">An inexact successive quadratic approximation method for convex L-1 regularized optimization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Oztoprak</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.3529</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On the complexity of steepest descent, Newton&apos;s and regularized Newton&apos;s methods for nonconvex unconstrained optimization problems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cartis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I M</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phl</forename><surname>Toint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2833" to="2852" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">An example of slow convergence for Newton&apos;s method on a function with globally Lipschitz continuous Hessian</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cartis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I M</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ph</forename><forename type="middle">L</forename><surname>Toint</surname></persName>
		</author>
		<idno>13-008</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
		<respStmt>
			<orgName>School of Mathematics, Edinburgh University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Uniform sampling for matrix approximation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Musco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Musco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sidford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Innovations in Theoretical Computer Science</title>
		<meeting>the 2015 Conference on Innovations in Theoretical Computer Science</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="181" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Conn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I M</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><surname>Toint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PhL: Trust Region Methods. SIAM</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<pubPlace>Philadelphia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Inexact Newton methods</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Dembo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Eisenstat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Steihaug</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Numer. Anal</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="400" to="408" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast Monte Carlo algorithms for matrices I: approximating matrix multiplication</title>
		<author>
			<persName><forename type="first">P</forename><surname>Drineas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Mahoney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="132" to="157" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Large scale empirical risk minimization via truncated adaptive Newton method</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eisen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mokhtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ribeiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Twenty-First International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="1447" to="1455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Choosing the forcing terms in an inexact Newton method</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Eisenstat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">F</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="16" to="32" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Convergence rates of sub-sampled Newton methods</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Erdogdu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Montanari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="3034" to="3042" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hybrid deterministic-stochastic methods for data fitting</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Friedlander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1380" to="A1405" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Some Bounds on the Complexity of Gradients, Jacobians, and Hessians. Complexity in Nonlinear Optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Griewank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>World Scientific Publisher</publisher>
			<biblScope unit="page" from="128" to="161" />
			<pubPlace>Singapore</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Note on sampling without replacing from a finite collection of matrices</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Nesme</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1001.2738</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Simultaneous source for non-uniform data variance and missing data</title>
		<author>
			<persName><forename type="first">E</forename><surname>Haber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1404.5254</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Pseudoinversus and conjugate gradients</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Hestenes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="43" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Hestenes</surname></persName>
		</author>
		<title level="m">Conjugate Direction Methods in optimization</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Randomized approximation of the Gram matrix: exact computation and probabilistic bounds</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Holodnak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">C</forename><surname>Ipsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Matrix Anal. Appl</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="110" to="137" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Proximal Newton-type methods for minimizing composite functions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Saunders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1420" to="1443" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">An inexact subsampled proximal Newton-type method for large-scale machine learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.08552</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Randomized algorithms for matrices and data</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Mahoney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends® Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="224" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep learning via Hessian-free optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Machine Learning (ICML-10)</title>
		<meeting>the 27th International Conference on Machine Learning (ICML-10)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="735" to="742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Mccullagh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Nelder</surname></persName>
		</author>
		<title level="m">Generalized Linear Models</title>
		<meeting><address><addrLine>Boca Raton</addrLine></address></meeting>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Stochastic second-order optimization via von Neumann series</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mutnỳ</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.04694</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
		<title level="m">Introductory Lectures on Convex Optimization</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">87</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Cubic regularization of Newton method and its global performance</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Polyak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="177" to="205" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fast exact multiplication by the Hessian</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Pearlmutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="147" to="160" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Newton sketch: a linear-time optimization algorithm with linearquadratic convergence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pilanci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.02250</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Stochastic algorithms for inverse problems involving PDEs and many measurements</title>
		<author>
			<persName><forename type="first">F</forename><surname>Roosta-Khorasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Van Den Doel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Ascher</surname></persName>
		</author>
		<idno type="DOI">10.1137/130922756</idno>
		<ptr target="https://doi.org/10.1137/130922756" />
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="3" to="S22" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Assessing stochastic algorithms for large scale nonlinear least squares problems using extremal probabilities of linear combinations of gamma random variables</title>
		<author>
			<persName><forename type="first">F</forename><surname>Roosta-Khorasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Székely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Ascher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM/ASA J. Uncertain. Quantif</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="90" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Improved analysis of the subsampled randomized Hadamard transform</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Tropp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Adapt. Data Anal</title>
		<imprint>
			<biblScope unit="page" from="115" to="126" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>3(01n02</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">User-friendly tail bounds for sums of random matrices</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Tropp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Comput. Math</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="389" to="434" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Subsampled Hessian Newton methods for supervised learning</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1766" to="1795" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Roosta-Khorasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Mahoney</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07827</idno>
		<title level="m">Second-order optimization for non-convex machine learning: an empirical study</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Sub-sampled Newton methods with non-uniform sampling</title>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Roosta-Khorasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Mahoney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3000" to="3008" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
