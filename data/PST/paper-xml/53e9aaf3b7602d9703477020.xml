<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Biologically Motivated Multiresolution Approach to Contour Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Giuseppe</forename><surname>Papari</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Mathematics and Computing Science</orgName>
								<orgName type="institution">University of Groningen</orgName>
								<address>
									<postBox>P.O. Box 800</postBox>
									<postCode>9700 AV</postCode>
									<settlement>Groningen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Patrizio</forename><surname>Campisi</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Dipartimento di Elettronica Applicata</orgName>
								<orgName type="institution">Università degli Studi di Roma &quot;Roma Tre&quot;</orgName>
								<address>
									<addrLine>Via della Vasca Navale 84</addrLine>
									<postCode>00146</postCode>
									<settlement>Roma</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nicolai</forename><surname>Petkov</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Mathematics and Computing Science</orgName>
								<orgName type="institution">University of Groningen</orgName>
								<address>
									<postBox>P.O. Box 800</postBox>
									<postCode>9700 AV</postCode>
									<settlement>Groningen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alessandro</forename><surname>Neri</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Dipartimento di Elettronica Applicata</orgName>
								<orgName type="institution">Università degli Studi di Roma &quot;Roma Tre&quot;</orgName>
								<address>
									<addrLine>Via della Vasca Navale 84</addrLine>
									<postCode>00146</postCode>
									<settlement>Roma</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Biologically Motivated Multiresolution Approach to Contour Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F364AF97F4B2E0B0825C166FF94E0C40</idno>
					<idno type="DOI">10.1155/2007/71828</idno>
					<note type="submission">Received 3 January 2006; Revised 3 November 2006; Accepted 3 November 2006 Recommended by Maria Concetta Morrone</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Standard edge detectors react to all local luminance changes, irrespective of whether they are due to the contours of the objects represented in a scene or due to natural textures like grass, foliage, water, and so forth. Moreover, edges due to texture are often stronger than edges due to object contours. This implies that further processing is needed to discriminate object contours from texture edges. In this paper, we propose a biologically motivated multiresolution contour detection method using Bayesian denoising and a surround inhibition technique. Specifically, the proposed approach deploys computation of the gradient at different resolutions, followed by Bayesian denoising of the edge image. Then, a biologically motivated surround inhibition step is applied in order to suppress edges that are due to texture. We propose an improvement of the surround suppression used in previous works. Finally, a contour-oriented binarization algorithm is used, relying on the observation that object contours lead to long connected components rather than to short rods obtained from textures. Experimental results show that our contour detection method outperforms standard edge detectors as well as other methods that deploy inhibition.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Contour detection is a fundamental operation in image processing and computer vision which, despite of the large number of studies published in the last two decades, is still a fertile field of ongoing research.</p><p>Many edge detectors have been proposed in the literature. However, they react to all local luminance changes above a given threshold, irrespective of their origin-object contours or textures. Our goal is to isolate objects in a scene; therefore, some further processing is needed beyond general-purpose edge detection.</p><p>Examples of edge detectors proposed in previous works are operators that incorporate linear filtering <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>, local orientation analysis <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7]</ref>, fitting of analytical models to the image data <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref>. In <ref type="bibr" target="#b11">[12]</ref>, a simple energy model is introduced to simulate perception of perceptually significant elements like lines and edges. Edge detectors using local energy principles have also been proposed in <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref>. Since these operators do not make any difference between various types of edges, such as texture edges versus object contours and region boundaries, they are known as noncontextual or, simply, general edge detectors <ref type="bibr" target="#b16">[17]</ref>.</p><p>Other studies propose more elaborate edge detection techniques that take into account additional information around an edge, such as local image statistics, image topology, perceptual differences in local cues (e.g., texture, color), edge continuity and density. Examples are dual frequency band analysis, statistical analysis of the gradient field <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>, anisotropic diffusion <ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref>, complementary analysis of boundaries and regions <ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref>, use of edge density information <ref type="bibr" target="#b8">[9]</ref> and biologically motivated surround modulation <ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref>. These operators are not aimed at detecting all luminance changes in an image but rather at selectively enhancing only those of them that are of interest in the context of a specific computer vision task, such as detecting outlines of tissues in medical images, object contours in natural image scenes, and boundaries between different texture regions. Such methods are usually referred to as contextual edge detectors.</p><p>Psychophysical studies on the human visual system (HVS) have given rise to biologically motivated edge detectors <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b30">31]</ref>. In its early stages, the HVS deploys special mechanisms to differentiate between isolated edges, such as object contours and region boundaries, on the one hand, and edges in groups, such as those in textures, on the other hand. Various psychophysical studies have shown that the perception of an oriented stimulus, for example, a line segment, can be influenced by the presence of other such stimuli (distractors) in its neighborhood. This influence can, for instance, manifest itself in the decreased saliency of a contour in presence of surrounding texture <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref>, in the orientation contrast pop-out effect <ref type="bibr" target="#b33">[34]</ref>, or in the decreased visibility of letters, object icons, and bars embedded in texture <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b34">35]</ref>. These visual perception effects are in agreement with the results of neurophysiological measurements on neural cells in the primary visual cortex. These studies show that the response of an orientation selective visual neuron to an optimal bar stimulus in its classical receptive field is reduced by the addition of other oriented stimuli to the surround <ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref>. Neurophysiologists refer to this effect as nonclassical receptive field (non-CRF) inhibition <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref> or, equivalently, surround suppression <ref type="bibr" target="#b38">[39]</ref>. Statistical data <ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref> reveals that about 80% of the orientation selective cells in the primary visual cortex show this inhibitory effect. In approximately 30% of all orientation selective cells, surround stimuli of orientation that are orthogonal to the optimal central stimulus have a weaker suppression effect than stimuli of the same orientation. In 40% of the cells, the suppression effect manifests itself irrespective of the relative orientation between the surrounding stimuli and the central one. In <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b29">30]</ref>, it is suggested that the biological utility of surround suppression is enhancement of object contours in natural images rich in background texture. This mechanism has been shown to improve the contour detection performance of biologically motivated <ref type="bibr" target="#b25">[26]</ref> and conventional <ref type="bibr" target="#b39">[40]</ref> edge detection algorithms.</p><p>Other psychophysical studies <ref type="bibr" target="#b40">[41]</ref> on the HVS have shown that image perception can be divided in two subsequent stages: the preattentive stage and the attentive stage. In the first one, which lasts the first 0.1 ÷ 0.3 s after an image is projected on the retina, coarse scale information is perceived, whereas in the latter, details are identified. Some psychophysical experiments <ref type="bibr" target="#b41">[42]</ref> indicate that the visual information in different frequency bands is processed separately. Therefore it is assumed that the retinal image is decomposed through bandpass filters, which give rise to a multichannel model <ref type="bibr" target="#b42">[43]</ref>. Psychophysical validation of multiresolution scheme based on a local energy model is provided in <ref type="bibr" target="#b43">[44]</ref>. These psychophysical studies suggest us to perform contour detection in a multiresolution framework <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b45">46]</ref>.</p><p>Contour detection becomes an even more challenging task when noisy images are involved. It is well known <ref type="bibr" target="#b17">[18]</ref> that edge extraction operators enhance noise at high-spatial frequencies. Therefore, denoising needs to be deployed. Within this framework, the definition of a priori probability model for both the noise and for images is of great importance. However, modeling the statistics of natural images is a difficult task, due to the image nonstationarity. Several attempts to model image statistics in transform domains have been recently performed. Denoising algorithms operating in the wavelet domain have been proposed in <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b46">[47]</ref><ref type="bibr" target="#b47">[48]</ref><ref type="bibr" target="#b48">[49]</ref><ref type="bibr" target="#b49">[50]</ref><ref type="bibr" target="#b50">[51]</ref><ref type="bibr" target="#b51">[52]</ref>. Specifically, in <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b51">52]</ref> it is assumed that the wavelet coefficients within a local neighborhood are characterized by a Gaussian scale mixture (GSM). In <ref type="bibr" target="#b52">[53]</ref> an image denoising method based on an image representation in the edge domain and on the Bayesian estimation of the original feature is provided. Parametric probabilistic models based on Gaussian mixtures are adopted for both signal and noise edge features. Such a model is taken into account in the current study to design a Bayesian denoising step that is applied to the gradient image and that leads to an orientation-dependant zeromemory nonlinearity.</p><p>In this paper, we propose a novel, biologically motivated, multiresolution contour detector which makes use of Bayesian denoising and of an improved surround inhibition technique. Within the framework of this paper the term contour is used to represent a line delimiting an object or part of it in a scene. This is a more sophisticated concept than edge which represents a not negligible local luminance change. Therefore, in our approach, contour detection is a global concept related to the recognition of meaningful objects. Specifically, the proposed method consists in the computation of the gradient at different resolutions, followed by Bayesian denoising of the edge image. Within this framework both the a priori first-order probability density function of the edge image and of the noise are modeled as a mixture of Gaussian distributions. This approach allows us to robustly estimate the image gradient. Then, a biologically motivated surround inhibition step is applied in order to suppress the edges due to texture. When surround inhibition is applied in the way proposed in <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b53">54]</ref>, object contours are also partially suppressed in a self-inhibition process. We propose a new inhibition scheme that overcomes this problem and allows more effective inhibition of texture edges. Finally, a binarization algorithm is used that operates on connected edge components and relies on the observation that true contours lead to long connected components rather then to short rods obtained from textures.</p><p>The paper is organized as follows. In Section 2, the proposed approach is described in detail for the single-scale case. Then it is generalized in Section 3 to the multiscale case. In Section 4 experimental results are given. Finally, conclusions are drawn in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">SINGLE-SCALE CONTOUR DETECTOR</head><p>The proposed single-scale contour detector is sketched in Figure <ref type="figure" target="#fig_0">1</ref>, where I = {I(x, y)} represents the original image, I w = {I w (x, y)} is its observed version corrupted by an additive independent observation noise W = {w(x, y)}, I w = I + W, and ∇ σ I w = {∇ σ I w (x, y)} = ∇ σ I + ∇ σ W is the scale-dependent gradient of the noisy image, computed as described in Section 2.1. A Bayesian denoising algorithm, described in Section 2.2, is applied on the gradient of the noisy image, followed by a surround inhibition step for texture suppression (Section 2.3). In Section 2.4, a contour-based binarization algorithm is described. The mathematical operator that gives the binary contour map b σ (x, y) detected at the resolution σ from the original image I w (x, y) will be referred as RDCD σ (resolutiondependant contour detector):</p><formula xml:id="formula_0">b σ (x, y) = RDCD σ I w (x, y) .</formula><p>(</p><formula xml:id="formula_1">)<label>1</label></formula><p>In the notation of this section, we will use the subscript σ to indicate the dependence of the introduced quantities and operators on the resolution parameter σ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Scale-dependent gradient</head><p>Given the (noisy) input image I w (x, y), the first step toward the estimation of its contours is the computation of a scaledependent gradient ∇ σ I w (x, y), defined as follows:</p><formula xml:id="formula_2">∇ σ I w (x, y) = ∇ I w * g σ (x, y) = ⎡ ⎢ ⎢ ⎢ ⎣ I w * ∂g σ ∂x (x, y) I w * ∂g σ ∂y (x, y) ⎤ ⎥ ⎥ ⎥ ⎦ ,<label>(2)</label></formula><p>where the image I w (x, y) is convolved with the x and y derivatives of a Gaussian function <ref type="bibr" target="#b0">[1]</ref>:</p><formula xml:id="formula_3">g σ (x, y) = 1 2πσ 2 e -(x 2 +y 2 )/2σ 2 .</formula><p>(</p><formula xml:id="formula_4">)<label>3</label></formula><p>The operator ∇ σ defined in (2) and (3) depends on the parameter σ, that we will call the scale or resolution parameter. Gradient computation according to (2) depends on the scale parameter σ: the larger its value, the larger the spatial extent of the intensity transitions (blur) to which the operator responds. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Bayesian denoising</head><formula xml:id="formula_5">A Bayesian estimate ∇ σ I of ∇ σ I, given ∇ σ I w ,</formula><formula xml:id="formula_6">p ∇σ I ∇ σ I(x, y) = K i=1 λ i N 2 ∇ σ I(x, y), 0, R ∇σ Ii (x, y) , (<label>4</label></formula><formula xml:id="formula_7">)</formula><p>where N 2 [χ, μ, R] denotes the Gaussian probability density function (p.d.f.) of a bivariate random variable f with expectation m and covariance matrix R:</p><formula xml:id="formula_8">N 2 [f, m, R] = 1 2π det(R) 1/2 exp - 1 2 (f -m) T R -1 (f -m) . (<label>5</label></formula><formula xml:id="formula_9">)</formula><p>As to the gradient of the observation noise, we model again the p.d.f. of the random variable ∇ s W(x, y) as a zero mean Gaussian mixture with mixing parameters β j , namely,</p><formula xml:id="formula_10">p ∇σ W ∇ σ W(x, y) = M j=1 β j N 2 ∇ σ W(x, y), 0, R ∇σ Wj (x, y) . (6)</formula><p>Derivation of the suboptimum Bayesian estimator based on edges requires the calculation of the a posteriori p.d.f. of ∇ σ I(x, y) given ∇ σ I w (x, y). Applying Bayes rule and dropping the location (x, y) for the sake of compactness we obtain</p><formula xml:id="formula_11">p ∇σ I/∇σ I w ∇ σ I/∇ σ I w = p ∇σ I w /∇σ I ∇ σ I w /∇ σ I p ∇σ I ∇ σ I p ∇σ I w /∇σ I ∇ σ I w /∇ σ I p ∇σ I ∇ σ I d ∇ σ I (7) = M j N i β j λ i N 2 ∇ σ I w , ∇ σ I, R ∇σ Wj N 2 ∇ σ I, 0, R ∇σ Ii M j N i β j λ i N 2 ∇ σ I w , ∇ σ I, R ∇σ Wj + R ∇σ Ii . (<label>8</label></formula><formula xml:id="formula_12">)</formula><p>The evaluation of the conditional expectation ∇ σ I(x, y)= E[∇ σ I(x, y)/∇ σ I w (x, y)] associated with (8) can be written as</p><formula xml:id="formula_13">∇ σ I(x, y) = ZNL ∇ σ I w (x, y) = M j=1 N i=1 η i j ∇ σ I w (x, y) R ∇σ Ii (x, y) × R ∇σ Wi (x, y) + R ∇σ Ii (x, y) -1 ∇ σ I w (x, y), (<label>9</label></formula><formula xml:id="formula_14">)</formula><p>where ZNL stands for zero-memory nonlinearity, and</p><formula xml:id="formula_15">η i j ∇ σ I w (x, y) = β j λ i N 2 ∇ σ I w (x, y), 0, R ∇σ Wj (x, y) + R ∇σ Ii (x, y) M j N i N 2 ∇ σ I w (x, y), 0, R ∇σ Wj (x, y) + R ∇σ Ii (x, y) . (<label>10</label></formula><formula xml:id="formula_16">)</formula><p>Equation <ref type="bibr" target="#b8">(9)</ref> says that in general, for signal and noise Gaussian mixtures, the MMSE estimator is a nonlinear combination of conditionally optimal linear estimators, with</p><formula xml:id="formula_17">A C B (a) a (b)</formula><p>Figure <ref type="figure">2</ref>: The inhibition term for a given point is computed by weighted summation of the response in the shaded surroundings of that point. (a) The annular surround proposed in <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b53">54]</ref> is effective for dense texture areas (point B) but leads to undesirable partial selfinhibition of isolated edges (point A) and considerable inhibition of texture region boundaries (point C). (b) In the current paper, the inhibition surround is split into two truncated half-rings oriented along the concerned edge and the inhibition term is computed as the minimum of the two weighted averages of M σ (x, y) on these two truncated half-rings.</p><p>gains R ∇σ Ii (x, y)(R ∇σ Wi (x, y) + R ∇σ Ii (x, y)) -1 each matched to a pair (x, y) of Gaussian submodels. The weights η i j [∇ σ I w (x, y)] represent the posterior probabilities of each submodel pair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Surround inhibition</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1.">Previous work</head><p>Next, following <ref type="bibr" target="#b53">[54]</ref>, we deploy a surround inhibition mechanism that takes into account the context influence of the surroundings of each point. It consists in computing an inhibition term as an integral of the gradient magnitude in the surroundings of a point and subtracting this term from the gradient magnitude in the concerned point. The inhibition term is supposed to be large in textured areas and low on object contours thus leading to the suppression of texture while retaining contours. This operator is motivated by psychophysical and neurophysiological findings (see <ref type="bibr" target="#b25">[26]</ref> for arguments and further references). Let M σ (x, y) be the gradient magnitude:</p><formula xml:id="formula_18">M σ (x, y) = ∇ σ I(x, y) = I * ∂g σ ∂x (x, y) 2 + I * ∂g σ ∂y (x, y) 2 . (<label>11</label></formula><formula xml:id="formula_19">)</formula><p>In <ref type="bibr" target="#b53">[54]</ref>, the inhibition term T σ (x, y) is defined as the weighted local average of M σ (x, y) on a ring around each pixel and it is computed as the convolution of M σ (x, y) and a weighting function w σ (x, y):</p><formula xml:id="formula_20">t σ (x, y) = M σ * w σ (x, y). (<label>12</label></formula><formula xml:id="formula_21">)</formula><p>The weighting function w σ (x, y), according to <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b53">54]</ref>, is a half-wave rectified and L 1 -normalized difference of two concentric Gaussian functions:</p><formula xml:id="formula_22">DoG σ (x, y) = g kσ (x, y) -g σ (x, y) + w σ (x, y) = DoG σ (x, y) R 2 DoG σ (x, y)dx dy , (<label>13</label></formula><formula xml:id="formula_23">)</formula><p>where | • | + denotes half-wave rectification,</p><formula xml:id="formula_24">|ξ| + = ⎧ ⎨ ⎩ ξ, ξ ≥ 0, 0, ξ &lt; 0. (<label>14</label></formula><formula xml:id="formula_25">)</formula><p>The support of w σ (x, y) defines the annular surround of a point on which the gradient magnitude is integrated, thus obtaining the value of the inhibition term for that point (Figure <ref type="figure">2</ref>(a)). The central region that is excluded from the inhibition term computation is the essential support of the gradient operator. It can be considered as an analogue of the classical receptive field (CRF) of an orientation selective neuron in the primary visual cortex. The annular area around it can be considered as the surround of that CRF. The radius ρ 0 of the concerned central region is given by</p><formula xml:id="formula_26">ρ 0 (k) = 2σ ln k 1 -1/k 2 (15)</formula><p>and is a slowly changing function of the parameter k. For instance, for k = 4, we have ρ 0 ∼ = 2.5σ. The weighting function w σ (x, y) is essential in a region of radius kρ 0 (k), thus the radius of the annular surround is roughly k times larger than the radius of the central (CRF) region. In our experiments we take the value k = 4, corresponding to an inhibition surround being several times larger (in diameter) than the classical receptive field of visual neurons that exhibit surround modulation <ref type="bibr" target="#b35">[36]</ref>. Our experiments show that the performance of the proposed method does not depend significantly on the value of this parameter: for values of k between 3 and 6, the performance change is negligible (see Section 4.2.2).</p><p>The inhibition term computed in this way will be large for points in whose surroundings there are multiple edges, such as point B in Figure <ref type="figure">2(a)</ref>. In contrast, it will be small for points along isolated edges, such as point A in Figure <ref type="figure">2(a)</ref>. Therefore, subtraction of this term from the gradient magnitude leads to texture suppression while leaving isolated contours relatively unaffected. The result c σ (x, y) of the inhibition is computed as follows:</p><formula xml:id="formula_27">c σ (x, y) = M σ (x, y) -αt σ (x, y) + . (<label>16</label></formula><formula xml:id="formula_28">)</formula><p>The coefficient α, called inhibition strength, specifies the extent to which the inhibition term is taken into account. Depending on the value of α, the inhibition term can partially or completely suppress the response of the operator to texture edges. For this type of surround suppression, we choose the value of the inhibition coefficient α to be such that the following equation is fulfilled at the points of maximum of M σ (x, y), when the input image is a bar grating of bar spacing and bar width ρ 0 :</p><formula xml:id="formula_29">M σ (x, y) = αt σ (x, y). (<label>17</label></formula><formula xml:id="formula_30">)</formula><p>The radius ρ 0 of the "receptive field" of the gradient operator is chosen to be equal to the bar spacing and bar width so that only one edge is visible in that field. This is the smallest value of α for which the operator will not respond to a texture input defined by such a bar grating. The idea is not only to suppress texture but to minimize the partial suppression of isolated edges and contours. The inhibition strength value which satisfies these conditions is α = 1.59. However, this straightforward inhibition process has two drawbacks.</p><p>(1) While being small, the inhibition term is not zero on isolated edges because parts of such an edge fall in the inhibition surround of other parts of the same edge, see point A in Figure <ref type="figure">2</ref>(a). We refer to this effect as selfinhibition. (2) Edges at texture borders, such as point C in Figure <ref type="figure">2</ref>, are considerably inhibited as well, which is not desirable with respect to the detection of region boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.">Improved inhibition scheme</head><p>In this paper we propose a modification of the inhibition scheme that does not suffer the above-mentioned drawbacks.</p><p>The idea is to exclude from the annular surround of a point a band region of width 2a oriented along the edge, as shown in Figure <ref type="figure">2</ref>(b). We define the inhibition term T σ as the minimum of the two weighted local averages of M σ (x, y) on the two resulting half-rings. More specifically, we define two weighting functions w + σ,φ (x, y) and w - σ,φ (x, y):</p><formula xml:id="formula_31">DoG + σ,φ (x, y) = DoG σ (x, y) • U(x cos φ + y sin φ -a), DoG - σ,φ (x, y) = DoG σ (x, y) • U(a -x cos φ -y sin φ), w ± σ,φ (x, y) = DoG ± σ,φ (x, y) R 2 DoG ± σ,φ (x, y)dx dy , (<label>18</label></formula><formula xml:id="formula_32">)</formula><p>where φ ∈ [0, π) is a generic orientation and U is the step function defined as follows: Then, we define and compute the modified inhibition term as follows:</p><formula xml:id="formula_33">U(ξ) = ⎧ ⎨ ⎩ 0, ξ &lt; 0, 1, ξ ≥ 0. (<label>19</label></formula><formula xml:id="formula_34">)</formula><formula xml:id="formula_35">T σ (x, y) = min M σ * w + σ,φ (x, y), M σ * w - σ,φ (x, y) , (<label>20</label></formula><formula xml:id="formula_36">)</formula><p>where ϑ(x, y) is the orientation of ∇ σ I(x, y).</p><p>In practice, we compute the convolutions in <ref type="bibr" target="#b19">(20)</ref> for a discrete set of orientations {φ i } Nφ i=1 , φ i = π((i -1)/N φ ), as shown in Figure <ref type="figure" target="#fig_1">3</ref> for N φ = 4, and then, for each pixel, we use the result obtained for the angle that is closest to the gradient orientation ϑ σ (x, y) for that pixel. Our experiments show that (above a certain reasonable minimum of N φ = 4) the number of orientations used does not substantially influence the performance of the contour detection operator (see Section 4.2.2).</p><p>The exclusion of the central band region avoids the selfinhibition and is motivated by neurophysiological studies <ref type="bibr" target="#b35">[36]</ref> according to which, inhibitory modulation originates from the regions flanking the receptive field of an orientation selective neuron on both sides of the optimal stimulus for that neuron. The parameter a controls the width of the excluded band region and we set it to be a fraction η of the radius ρ 0 , a = ηρ 0 . Our experiments show that for values of η around 1 the exact choice of η is not critical for the performance of our algorithm (see Section 4.2.2). Therefore, we use η = 1 in the following. As to the specific choice of the minimum function used in <ref type="bibr" target="#b19">(20)</ref>, at the current moment, this is a pure design consideration. A certain neurophysiological justification for this choice can be sought for by the fact that the inhibition surround of a neuron need not be circular symmetric. For instance, only 23% of cells in area MT/V5 show circular symmetrical surrounds while 45% of the cells have asymmetrical surrounds <ref type="bibr" target="#b54">[55]</ref>. In this context <ref type="bibr" target="#b19">(20)</ref> can be considered as a maximum value combination of two surround suppression operators with opposite asymmetrical surrounds as defined by the half-rings shown in Figure <ref type="figure">2(b)</ref>. The result is a computation of a directional derivative of the gradient magnitude in direction of the gradient and can be used for effectively detecting region boundaries for the gradient magnitude as illustrated by Figure <ref type="figure">2</ref>  The edge strength c σ (x, y) is computed similar to <ref type="bibr" target="#b15">(16)</ref>, with the inhibition term T σ (x, y) according to <ref type="bibr" target="#b19">(20)</ref>,</p><formula xml:id="formula_37">c σ (x, y) = M σ (x, y) -αT σ (x, y) + . (<label>21</label></formula><formula xml:id="formula_38">)</formula><p>Figure <ref type="figure" target="#fig_3">4</ref> shows a test image elephant (Figure <ref type="figure" target="#fig_3">4(a)</ref>) and three gray level edge images representing the gradient magnitude M σ (x, y) without surround inhibition (Figure <ref type="figure" target="#fig_3">4</ref>(b)), the edge strength c σ (x, y) computed according to the previous inhibition scheme <ref type="bibr" target="#b53">[54]</ref> (Figure <ref type="figure" target="#fig_3">4</ref>(c)), and the edge strength c σ (x, y) computed according to the improved inhibition scheme proposed here (Figure <ref type="figure" target="#fig_3">4(d)</ref>). Since no self-inhibition is involved in the proposed modified inhibition scheme, a higher value of the parameter α can be used without destroying weak edges. In this way texture can be suppressed more effectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Binarization</head><p>Similar to other methods for edge and contour detection, the last step of the algorithm comprises edge thinning by nonmaxima suppression and binarization by thresholding. Traditional thresholding techniques, such as global or hysteresis thresholding <ref type="bibr" target="#b2">[3]</ref>, cannot deal adequately with texture edges that present stronger gradient magnitude values than contours, Figure <ref type="figure">5</ref>.</p><p>In this paper we present a new thresholding algorithm, based on the observation that object contours lead to long and wide connected components of nonzero pixels, while texture edges, especially after surround inhibition, lead to relatively short and thin components. Specifically, we apply nonmaxima suppression to the signal c σ (x, y). Let u σ (x, y) be the unit vector parallel to the gradient ∇ σ I(x, y), that is, ∇ σ I(x, y) = M σ (x, y)u σ (x, y); we consider the set S σ of all points which are local maxima of c σ (x, y) in the direction of u σ (x, y):</p><formula xml:id="formula_39">S σ = (x, y) ∂c σ ∂u σ = 0 ∧ ∂c σ ∂u σ &lt; 0 . (<label>22</label></formula><formula xml:id="formula_40">)</formula><p>Let C (σ) k , k = 1, . . . , N c , be the connected components of the set S σ , where N c is the number of such components. We apply a morphological dilation to C (σ) k <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b56">57]</ref>, with a 3×3 square q 3 as structuring element, and obtain dilated components D (σ)  k :</p><formula xml:id="formula_41">S σ = k C (σ) k ,<label>(23)</label></formula><formula xml:id="formula_42">D (σ) k = C (σ) k ⊕ q 3 . (<label>24</label></formula><formula xml:id="formula_43">)</formula><p>For each connected component C (σ) k , we introduce a quantity G (σ)  k , which we call global contour weight, defined as the sum of the values of c σ (x, y) over the dilated component D (σ)  k :</p><formula xml:id="formula_44">G (σ) k = (x,y)∈D (σ) k c σ (x, y). (<label>25</label></formula><formula xml:id="formula_45">)</formula><p>We compute a binary contour map b σ (x, y) by setting to 1 the value of the pixels from all connected components C (σ) k whose contour weights G (σ) k are above a given threshold G min :</p><formula xml:id="formula_46">b σ (x, y) = ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ 1, (x, y) ∈ G (σ) k &gt;Gmin C (σ) k , 0, otherwise. (<label>26</label></formula><formula xml:id="formula_47">)</formula><p>The result of this type of thresholding compared to traditional thresholding is shown in Figure <ref type="figure">6</ref>. Low-contrast contours are successfully detected and, most importantly, contours are not depleted by the binarization process.</p><p>Since the value of the contour strength G is related to the length of the contours of the object represented in an image, the value of the threshold G min should be proportional to the linear size of the image. In our experiments, performed on images of size 512 × 512 pixels, we found empirically that connected components that contain less than 7 pixels are too small to be part of an object contour. Therefore, unless a different value is specified, in our experiments we set the value of the threshold to G min = 7. In Section 4 we will discuss quantitatively the dependence of the performance of the algorithm with respect to the value of G min .</p><p>A similar connected component thresholding method has been proposed in <ref type="bibr" target="#b57">[58]</ref>. However, in our computational experiments we found out that without surround inhibition this thresholding technique gives bad results. The reason is that if the set S σ of the nonzero pixels of the gradient after non-maxima suppression is computed directly from the gradient magnitude without surrounding inhibition, the result includes many large tangled connected components of nonzero pixels that originate from noisy image regions. Such components have high contour strength values and cannot be eliminated by the proposed thresholding scheme. In contrast, surround inhibition breaks such connected components into pieces that are small enough and consequently have small contour strengths and can effectively be removed by thresholding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">MULTISCALE CONTOUR DETECTOR</head><p>It is well known from multiresolution wavelet analysis <ref type="bibr" target="#b42">[43]</ref> that coarser scales contain only the general morphology of the image where most of the high-frequency texture details disappear. This fact is illustrated in Figures <ref type="figure" target="#fig_5">7(a</ref>) and 7(b), displaying two binary contour maps b 1 (x, y) and b 2 (x, y) ob-tained with the RDCD operator defined above for σ = 1 and σ = 2, respectively. From Figure <ref type="figure" target="#fig_5">7</ref>(a) we can see that the contours detected at the fine scale (σ = 1) are detected at their correct positions and the junctions are preserved, but at the same time much texture is present. When a coarser scale is used (σ = 2, Figure <ref type="figure" target="#fig_5">7</ref>(b)), some texture is removed, but the contours are shifted away from their true positions <ref type="bibr" target="#b58">[59]</ref>, especially at positions of high curvature, and some junctions are destroyed by the nonmaxima suppression <ref type="bibr" target="#b59">[60]</ref>.</p><p>In order to exploit the advantages of both resolutions we superpose the two binary images and we select from b 1 (x, y) only those "1" pixels that are close enough to "1" pixels of b 2 (x, y). More specifically, we first apply a morphological dilation operator with a disk of radius 3σ as structuring element on the edge map b 2 (x, y) at the coarse scale and we denote the result by b 2,DIL (x, y). In our approach we apply an N-level multiscale analysis in order to remove the residual spurious texture still present in Figure <ref type="figure" target="#fig_5">7(d)</ref>. This algorithm relies on the observation that starting from a given scale that is determined by the object blur, object contours are present in the results at all scales, while texture appears only at the finer scales. Referring to the scheme shown in Figure <ref type="figure">8</ref>, we first compute the binary contour maps b k (x, y) at N different scales:</p><formula xml:id="formula_48">b k (x, y) = RDCD σk I w (x, y) , k = 1, . . . , N. (<label>27</label></formula><formula xml:id="formula_49">)</formula><p>Then we apply morphological dilation to all binary maps but the one that corresponds to the finest scale:</p><formula xml:id="formula_50">b k,DIL = b k ⊕ D 3σ , k = 2, . . . , N,<label>(28)</label></formula><p>where we use as a structuring element a disk D 3σ of radius 3σ. The final output is obtained by the logic AND of the binary maps at all resolutions:</p><formula xml:id="formula_51">b out = b 1 (x, y) • N k=2 b k,DIL (x, y). (<label>29</label></formula><formula xml:id="formula_52">)</formula><p>In the previous discussion, the scale values σ k have been considered as input parameters. Simple general considerations about the noise levels allow us to compute them automatically, thus making the algorithm unsupervised in this respect. The idea is that the only new information carried by the finer resolution channels with respect to the coarser ones is the details of the contours. However, when noise is present, human observers are not able to distinguish details of the contours and only the general shape of the objects is perceived (Figure <ref type="figure">9</ref>(b)). Consequently, for noisy images the information carried by the edge maps at the finest resolutions can be discarded <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b60">61]</ref>.</p><p>With this idea in mind, we perform a preliminary estimation of the noise level and use it to determine the value of σ 1 of the finest scale, which must be larger the larger the noise is. It can be easily proved that, when the gradient is smoothed by a Gaussian mask g σ (x, y), the noise reduction is given by</p><formula xml:id="formula_53">N out N in = erf πσ √ 2 σ √ π , (<label>30</label></formula><formula xml:id="formula_54">)</formula><p>where N in and N out are the noise levels before and after the smoothing, and</p><formula xml:id="formula_55">erf(x) = 1 √ 2π x 0 e -t 2 /2 dt. (<label>31</label></formula><formula xml:id="formula_56">)</formula><p>Therefore, once the noise level N est of the input image has been estimated, the value of σ 1 can be obtained by solving <ref type="bibr" target="#b29">(30)</ref>, where N in is set equal to N est , and N out is set to a fixed value, above which contours cannot be detected reliably anymore. We compute the value σ i for the ith resolution as follows:</p><formula xml:id="formula_57">σ i = σ 1 • 2 i-1 , i = 1, . . . , N.<label>(32)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTAL RESULTS</head><p>In this section some experimental results are presented and discussed. The performance of the proposed contour detector is compared with the performance of four other existing algorithms: the standard single-scale Canny edge detector <ref type="bibr" target="#b0">[1]</ref>, a modification 1 of the multiscale edge detector CARTOON <ref type="bibr" target="#b44">[45]</ref>, the single-scale surround inhibition (SSSI) contour detector proposed in <ref type="bibr" target="#b53">[54]</ref>, and the multiscale 1 In the original CARTOON method as proposed in <ref type="bibr" target="#b44">[45]</ref>, only two values of σ are used and the edges are detected using the Laplacian of Gaussian filter (LoG). On the other hand, the multiscale algorithms proposed here and in <ref type="bibr" target="#b45">[46]</ref> make use of multiple resolutions and detect edges by means of the gradient of Gaussian filter. In order to do a fair comparison between the proposed method and the CARTOON approach, we have reimplemented CARTOON by using the gradient of Gaussian filter for detecting edges and by using the same values of σ that are used in the other multiscale approaches discussed in this paper.</p><p>surround inhibition (MSSI) contour detector proposed in <ref type="bibr" target="#b45">[46]</ref>. We performed experiments on a set of 40 images using both noiseless (SNR = ∞) and noisy image versions corrupted by additive noise with SNR equal to 10 dB, 13 dB, and 16 dB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Qualitative comparison</head><p>Some experimental results are shown in Figures <ref type="figure">9</ref><ref type="figure" target="#fig_10">10</ref><ref type="figure" target="#fig_11">11</ref><ref type="figure" target="#fig_12">12</ref><ref type="figure" target="#fig_13">13</ref><ref type="figure" target="#fig_15">14</ref><ref type="figure" target="#fig_16">15</ref><ref type="figure" target="#fig_17">16</ref><ref type="figure" target="#fig_18">17</ref><ref type="figure" target="#fig_19">18</ref><ref type="figure" target="#fig_21">19</ref><ref type="figure" target="#fig_23">20</ref><ref type="figure" target="#fig_24">21</ref><ref type="figure" target="#fig_25">22</ref>for both noiseless images and images corrupted by additive noise of SNR = 13 dB. A larger set of examples is available on http://www.cs.rug.nl/∼imaging. We would like to stress that we used the same set of parameter values for all images in the dataset as follows: inhibition strength α = 3, binarization threshold G min = 7, ratio of the two standard deviations in DoG k = 4, number of orientations for computing the inhibition term N φ = 4, number of scales N = 3, radius of the structuring element used for dilation r σ = 3σ, and noise amplitude N out equal to 8% of the average standard deviation of the input image, computed across all images. SSSI <ref type="bibr" target="#b53">[54]</ref> applies surround inhibition in a single-scale context. The modification of CARTOON <ref type="bibr" target="#b44">[45]</ref> that we use here operates in a multiresolution framework without applying surround inhibition. MSSI <ref type="bibr" target="#b45">[46]</ref> uses the surround inhibition scheme proposed in <ref type="bibr" target="#b53">[54]</ref> in a multiscale framework. The approach proposed here is an improvement of MSSI using Bayesian denoising, a modification of the inhibition term, and a new binarization scheme.</p><p>We can see that the approach proposed in this paper outperforms the other algorithms in terms of cleanness of the detected contours, amount of suppressed texture, and robustness to noise. In particular, the results for the test images rhino and frog (Figures <ref type="figure" target="#fig_11">11</ref><ref type="figure" target="#fig_12">12</ref><ref type="figure" target="#fig_13">13</ref><ref type="figure" target="#fig_15">14</ref>) show the ability of our algorithm to suppress texture while effectively detecting weak edges in low-contrast images. On the other hand, the results for the test image bear1 (Figures <ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref> show the ability of the proposed method to suppress high-contrast oriented texture like the fur of the bear. All the other studied algorithms but MSSI completely fail in removing this type of texture. Figures <ref type="figure" target="#fig_18">17</ref><ref type="figure" target="#fig_19">18</ref>show the behavior of our algorithm with respect to low-frequency texture, like the plants in the background behind the bear. Such type of texture, well removed by our contour detector (Figure <ref type="figure" target="#fig_18">17(b)</ref>), can neither be suppressed by SSSI techniques (Figure <ref type="figure" target="#fig_18">17(d)</ref>), nor by simply projecting the image on a coarse scale domain as CARTOON and MSSI do. The simple combination of multiscale analysis and surround inhibition also fails in this case. Finally, the examples shown in Figures <ref type="figure" target="#fig_21">19</ref><ref type="figure" target="#fig_23">20</ref><ref type="figure" target="#fig_24">21</ref><ref type="figure" target="#fig_25">22</ref>illustrate the behavior of our algorithm for images containing multiple objects of different sizes. It can be noted that some object details, like for instance the windows of the building in Figure <ref type="figure" target="#fig_21">19</ref>(a), are detected by the single-scale contour detectors, but not by the multiscale ones. Indeed, whether they should be considered object contours or texture to be suppressed depends on the specific application. For instance, in the ground truth provided in the Berkeley image dataset <ref type="bibr" target="#b61">[62]</ref> such details are not considered as object contours.</p><p>By comparing the results of the modification of CAR-TOON (Figures <ref type="figure">9</ref><ref type="figure" target="#fig_10">10</ref><ref type="figure" target="#fig_11">11</ref><ref type="figure" target="#fig_12">12</ref><ref type="figure" target="#fig_13">13</ref><ref type="figure" target="#fig_15">14</ref><ref type="figure" target="#fig_16">15</ref><ref type="figure" target="#fig_17">16</ref><ref type="figure" target="#fig_18">17</ref><ref type="figure" target="#fig_19">18</ref><ref type="figure" target="#fig_21">19</ref><ref type="figure" target="#fig_23">20</ref><ref type="figure" target="#fig_24">21</ref><ref type="figure" target="#fig_25">22</ref>  f)), we can see that multiscale analysis and surround inhibition play complementary roles: the combination of the two approaches gives much better results than those obtained by each of them separately. The Bayesian denoising step, the modified computation of the inhibition term, and the contour-oriented binarization technique introduced here further improve the quality of the obtained results: the residual texture placed in the neighborhood of contours, still present when applying MSSI (especially well visible in Figures <ref type="figure" target="#fig_11">11(f</ref>) and 15(f)), disappears by applying the proposed approach. Also the residual noise present when applying MSSI is removed by our approach. Figure <ref type="figure" target="#fig_1">23</ref> illustrates the effectiveness of the Bayesian denoising step introduced in Section 2.2 for the noisy test image elephant shown in Figure <ref type="figure" target="#fig_10">10</ref>(a) (SNR = 13 dB). If the entire process explained in Sections 2 and 3 had been applied without the Bayesian denoising step, we would get the output shown in Figure <ref type="figure" target="#fig_1">23(a)</ref>. It is definitely worse than the output obtained with the algorithm proposed in this paper, where the Bayesian denoising step is performed at all resolutions (Figure <ref type="figure" target="#fig_1">23(b)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Quantitative performance evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Metric definition</head><p>Methods for performance evaluation of edge detectors can be categorized as using either synthetic or natural images, with or without specified ground truth, <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b62">63]</ref>. When the ground truth is given, performance evaluation can be readily carried out by comparing detected contours with the ground truth edges. Although synthetic images allow precise objective definition of ground truth and seem appropriate for any performance evaluation criterion, the conclusions drawn in most of the cases are not easily extrapolated for natural scenes <ref type="bibr" target="#b16">[17]</ref>. Additional qualitative metrics such as smoothness, continuity, thinness, which may sometimes be computed in absence of the ground truth, do not always properly reflect performance <ref type="bibr" target="#b63">[64]</ref>. For these reasons, most of the current evaluation methods use natural image scenes with an associated ground truth specified by a human observer <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b63">[64]</ref><ref type="bibr" target="#b64">[65]</ref><ref type="bibr" target="#b65">[66]</ref>. For a comprehensive list of performance evaluation methods for edge detection we refer to <ref type="bibr" target="#b65">[66]</ref>.</p><p>Different human observers produce different ground truth contour images for the same input image and a given pixel can be marked by some observers as a contour pixel (of value 1) and by others as a texture or background pixel (of value 0). One way to deal with this fact is to use a superposition of the binary contour maps produced by different observers <ref type="bibr" target="#b61">[62]</ref>. Here we apply an alternative approach in which we asked 8 observers to mark the contours they see. Based on their contour drawings we defined a weighted ground truth in which a pixel (x, y) is assigned a weight γ(x, y) = 1 if 5 or more out of the 8 observers drew a contour pixel within a distance of 2 pixels and weight γ(x, y) = 1/3 if this was done by 3 or 4 observers, Figure <ref type="figure" target="#fig_3">24</ref>.</p><p>Let DC be the set of points for which a given contour detection operator outputs "1" and let GT be the set of points for which γ(x, y) &gt; 0. We define generalized recall R and </p><p>Figure <ref type="figure">9</ref>: "Elephant" (512 × 512 pixels): (a) test image and contours detected using (b) the proposed approach, (c) the Canny edge detector <ref type="bibr" target="#b0">[1]</ref>, (d) single-scale surround inhibition <ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON <ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition <ref type="bibr" target="#b45">[46]</ref>.</p><p>precision P as follows:</p><formula xml:id="formula_59">recall = (x,y)∈DC∩GT γ(x, y) (x,y)∈GT γ(x, y) , precision = (x,y)∈DC∩GT γ(x, y) card{DC} ,<label>(33)</label></formula><p>where card (X) is the number of elements of the set X.</p><p>In order to compensate for small shifts of contours detected by an operator from ground truth contours, the intersection of GT and DC is computed as proposed in <ref type="bibr" target="#b29">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Results</head><p>For each of the five algorithms discussed above we evaluated R and P for a set of 40 images and computed the averages  <ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON <ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition <ref type="bibr" target="#b45">[46]</ref>.</p><p>of the obtained values. We computed such averages for the noiseless images (SNR = ∞) and for noisy versions of these images (SNR = 10 dB, 13 dB, and 16 B). Figure <ref type="figure" target="#fig_14">25</ref>(a) shows the results obtained whereby for each algorithm and SNR we used the optimal parameter values as specified in the respective references. As we can see, for all SNR values our approach gives the best performance in terms of texture suppression (e.g., P = 0.74 for noiseless images, SNR = ∞), while keeping a sufficient percentage of detected true contour pixels (R = 0.4 for noiseless images, SNR = ∞). By comparing our approach with the best of the other existing algorithms (MSSI) that we consider here, we see that the proposed approach gives a significant advantage in terms of increased precision (by a factor of at least 2) while paying a (d) single-scale surround inhibition <ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON <ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition <ref type="bibr" target="#b45">[46]</ref>.</p><p>small price in terms of decreased recall (by only 20%-25%). Canny algorithm gives good recall at the expense of a very bad precision which means that in the resulting binary map the true contours are buried in a binary texture noise (see, e.g., Figures <ref type="figure" target="#fig_11">11(c</ref>), 13(c), 15(c), and 17(c)).</p><p>The proposed approach has also the best performance in terms of noise rejection, since the value of the preci-sion achieved by our approach with the most noisy test images is higher than the one achieved by the other approaches for noiseless test images. The worst performance in terms of precision is exhibited by the Canny edge detector because this algorithm deploys no texture/noise suppression mechanism. The modification of CARTOON and SSSI provides approximately the same improvement, while  <ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON <ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition <ref type="bibr" target="#b45">[46]</ref>.</p><p>SSSI performs slightly better for noiseless images but it is more sensitive to noise. The use of the surround inhibition scheme <ref type="bibr" target="#b53">[54]</ref> in a multiscale framework as done in <ref type="bibr" target="#b45">[46]</ref> provides a considerable performance increase in terms of precision.</p><p>It is worth pointing out that the relatively high values of precision achieved by means of the proposed algorithm are obtained at the expense of the loss of some contour details. In this respect we have to note that the values of recall of the other algorithms are over estimated due to noise or texture pixels that are not suppressed and lie near true contours. This is confirmed by the fact that the value of the recall increases as the SNR decreases for all considered algorithms but the one proposed here. (d) single-scale surround inhibition <ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON <ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition <ref type="bibr" target="#b45">[46]</ref>.</p><p>The fact that with the proposed approach the recall value decreasing with increasing noise is in agreement with the property of the human visual system that tends to detect contours less effectively in presence of noise <ref type="bibr" target="#b66">[67]</ref>.  (d) single-scale surround inhibition <ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON <ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition <ref type="bibr" target="#b45">[46]</ref>.</p><p>of threshold values that leads to a broad range of recall and precision values <ref type="bibr" target="#b61">[62]</ref>. In this respect, we think that it is worth to explore the threshold space only for values that lead to some reasonably large values of the precision and recall as illustrated in Figure <ref type="figure" target="#fig_14">25(c</ref>). We studied also how the performance is influenced by the parameters related to the computation of the inhibition term T σ introduced in Section 3: the number of orientations N φ , the distance a between the two half-rings r + and r -, and the ratio k between the standard deviations of the two Gaussian functions of the inhibition weighting function <ref type="bibr" target="#b13">(14)</ref>. Our experiments have shown that the overall performance is not sensitive to the choice of these parameters. For N φ ranging between 4 and 10 (N φ = 4, 6, 8, 10), the relative (d) single-scale surround inhibition <ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON <ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition <ref type="bibr" target="#b45">[46]</ref>.</p><p>variations of the performance indicators are only 0.62% for recall and 0.88% for precision. We considered the spacing a between the two half-rings as a fraction η of the inner radius ρ 0 and experimented with values of η ranging between 1 and 2 (η = 1, 1.25, 1.5, 1.75, 2). The relative variations of the performance indicators are of 0.34% for recall and 0.65% for precision. Finally, we considered values of k ranging between 3 and 6 (k = 3, 4, 5, 6) and found the relative variations of the performance indicators to be only 0.23% for recall and 1.76% for precision. To summarize, our experiments showed that the proposed algorithm is robust to variations of these parameters. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">SUMMARY AND CONCLUSIONS</head><p>In this paper we proposed a contour detection algorithm that outperforms standard edge detectors that react to all the local luminance changes, irrespective of whether they are due to object contours or due to natural textures like grass, foliage, water, and so forth. Specifically, the method we presented relies on different characteristics of the HVS. Inspired by psychological and neurophysiological studies, we incorporated in our scheme surround inhibition of texture that (d) single-scale surround inhibition <ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON <ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition <ref type="bibr" target="#b45">[46]</ref>.</p><p>does not affect isolated edges but that inhibits edges that are surrounded by other edge stimuli. Compared with previous inhibition schemes <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b53">54]</ref>, the method we propose does not suffer the problem of self-inhibition of true contours and, therefore, allows for a stronger and thus more effective inhibition of texture. The design of the new inhibition scheme involves a few parameters for which we however found that the selection of their values does not have significant effect on the performance of the algorithm so that their values can be fixed. In order to make our algorithm robust to noise, we apply a Bayesian denoising step at each resolution before the surround inhibition step. It consists of the optimal MMSE estimator of the image gradient in additive noise for which a closed form is given. The a priori first-order p.d.f. of both the signal and the additive noise is assumed Gaussian scale mixture, according to previous studies of the statistics of the wavelet coefficients of natural images.</p><p>For binarization we use a thresholding technique that is based on weights computed for the connected and thinned (by nonmaxima suppression) components of the surround inhibited and denoised gradient magnitude. We found out that for obtaining good results it is essential that this thresholding technique is applied in combination with surround inhibition which cuts into small pieces long connected edge components that are due to noise and texture.     The second characteristic of the HVS taken into account is that, as pointed out by psychophysical experiments, the visual information in different frequency bands is processed separately. Following these findings, we perform contour detection in a multiresolution framework. Object contours can be discriminated from texture edges because the former are present at all scales (above a given scale that is determined by the contour blur), while the latter appear only at the finer scales. We use this fact and combine the binary contour maps obtained for different scales in such a way that texture is eliminated while contours and junctions are retained.</p><p>The entire algorithm can be easily implemented by computing convolutions, applying zero-memory nonlinearities and basic morphological operations, whereby convolutions are the most computationally demanding operations and have computational complexity O(N I log N I ), where N I is the linear size of the image. All the other operations can be done in linear time, therefore the overall algorithm complexity is O(N I log N I ). To summarize, with reference to Figure <ref type="figure" target="#fig_0">1</ref>, the gradient computation requires two convolution operations, the Bayesian denoising operation is computable in linear time, the computation of the inhibition term requires 2Nφ convolutions, where Nφ is the number of orientations, and the binarization is computable in linear time. Therefore, for each scale 2Nφ + 2 convolutions are required.</p><p>We tested the proposed algorithm on a set of 40 images, both noiseless and corrupted by additive white noise (with SNR = 16 dB, 13 dB, 10 dB), and compared it with other four existing contour detectors. Both visual inspection of the results and quantitative comparison with weighted ground truths lead us to the main conclusion of this paper that the proposed algorithm is superior to other known algorithms in terms of amount of texture suppressed, amount of detected contours and their cleanness and robustness to noise. The effective suppression of texture in the resulting binary contour maps is a very important aspect of the proposed algorithm, because modern shape recognition algorithms that use contour information (see, e.g., <ref type="bibr" target="#b67">[68]</ref>) rely on clean contour maps that are not corrupted by texture noise <ref type="bibr" target="#b68">[69]</ref><ref type="bibr" target="#b69">[70]</ref><ref type="bibr" target="#b70">[71]</ref>.</p><p>Similar to other multiresolution contour detection approaches (see, e.g., <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b72">73]</ref>) we rely on the assumption that object contours are present in the results at all resolutions, while texture appears only at the finer scales. More precisely, the former part of this assumption holds for sharp contours only. Blurred contours are detected more effectively at coarser scales. Though the results are encouraging for a wide set of test images with different structure, contrast and texture types, such an assumption might be a limitation as it was not verified for all considered resolutions. However, such a limitation is shared by all other edge detection techniques and finding a universal optimal solution for this problem is still an open issue.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Flowchart of the proposed single-scale contour detector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Computation scheme of the inhibition term. For each pixel of the image, inhibition terms are computed for a number of different orientations. Then the gradient orientation information is used to select the appropriate value at each pixel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: (a) A test image elephant and edge strength computed as (b) the gradient magnitude, (c) the gradient magnitude with surround inhibition according to the traditional annular surround method<ref type="bibr" target="#b53">[54]</ref> with α = 1.59, and (d) the gradient magnitude with surround inhibition according to the split-surround method proposed in this paper with α = 3. For a better representation, the three edge images have been equalized and shown in negative, thus white pixels correspond to the value zero.</figDesc><graphic coords="6,315.91,246.22,141.55,141.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Figure 5: (a) Gray level contour image c σ (x, y) obtained after surround inhibition. (b) Result of traditional binarization comprising thinning by nonmaxima suppression and thresholding. Some contour pixels are weaker than some texture edges and it is not possible to select a threshold that retains the former while eliminating the latter.</figDesc><graphic coords="7,111.67,275.08,141.43,141.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: (a), (b) Binary contour maps b 1 (x, y) and b 2 (x, y) obtained with the RDCD operator introduced in Section 2, with σ = 1 and σ = 2, respectively. At the finer scale the borders are detected at their respective positions, but some texture is present; at the coarser scale, texture is reduced but the contours are shifted and some junctions are destroyed. (c) Superposition of the contour map at the fine scale (shown in black) and the morphologically dilated contour map at the coarse scale (rendered in a gray), and (d) the result of their logic AND. Texture is reduced, contours are well detailed, and the morphological dilatation restores the junctions.</figDesc><graphic coords="8,115.57,278.02,169.75,169.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 Figure 8 :</head><label>78</label><figDesc>Figure8: Overall scheme of our multiscale contour detector, where each block "single-scale contour detector" implements the RDRC operator with a different scale parameter σ i .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>(e)), SSSI (Figures 9-22(d)), and MSSI (Figures 9-22</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Noisy elephant (SNR = 13 dB): (a) test image and contours detected using (b) the proposed approach, (c) the Canny edge detector [1], (d) single-scale surround inhibition<ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON<ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition<ref type="bibr" target="#b45">[46]</ref>.</figDesc><graphic coords="12,316.00,427.09,141.49,142.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: "Rhino" (512×512 pixels): (a) test image and contours detected using (b) the proposed approach, (c) the Canny edge detector [1],(d) single-scale surround inhibition<ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON<ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition<ref type="bibr" target="#b45">[46]</ref>.</figDesc><graphic coords="13,317.02,422.68,141.55,142.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Noisy Rhino (SNR = 13 dB): (a) test image and contours detected using (b) the proposed approach, (c) the Canny edge detector [1], (d) single-scale surround inhibition<ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON<ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition<ref type="bibr" target="#b45">[46]</ref>.</figDesc><graphic coords="14,145.06,423.76,141.43,142.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: "Frog" (564 × 496 pixels): (a) test image and contours detected using (b) the proposed approach, (c) the Canny edge detector [1],(d) single-scale surround inhibition<ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON<ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition<ref type="bibr" target="#b45">[46]</ref>.</figDesc><graphic coords="15,315.91,429.70,141.55,142.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 25 (</head><label>25</label><figDesc>b) shows the performance behavior of the proposed algorithm for various values of the threshold G min (G min = 2.5, 5, 6, 7, 8, 9, 10, 12.5). Finally, Figure25(c)shows the performance of the Canny edge detector and the proposed algorithm for a wide range of values of the respective binarization thresholds of these algorithms. Such plots have been deployed in recent literature to study the performance of boundary detection algorithms for a broad range</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 14 :</head><label>14</label><figDesc>Figure 14: Noisy frog (SNR = 13 dB): (a) test image and contours detected using (b) the proposed approach, (c) the Canny edge detector [1],(d) single-scale surround inhibition<ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON<ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition<ref type="bibr" target="#b45">[46]</ref>.</figDesc><graphic coords="16,316.03,425.71,141.43,142.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 15 :</head><label>15</label><figDesc>Figure 15: "Bear1" (512×512 pixels): (a) test image and contours detected using (b) the proposed approach, (c) the Canny edge detector [1],(d) single-scale surround inhibition<ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON<ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition<ref type="bibr" target="#b45">[46]</ref>.</figDesc><graphic coords="17,316.03,428.86,141.43,142.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 16 :</head><label>16</label><figDesc>Figure 16: Noisy bear1 (SNR = 13 dB): (a) test image and contours detected using (b) the proposed approach, (c) the Canny edge detector [1], (d) single-scale surround inhibition<ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON<ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition<ref type="bibr" target="#b45">[46]</ref>.</figDesc><graphic coords="18,315.94,436.24,141.55,142.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 17 :</head><label>17</label><figDesc>Figure 17: "Bear2" (512×512 pixels): (a) test image and contours detected using (b) the proposed approach, (c) the Canny edge detector [1],(d) single-scale surround inhibition<ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON<ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition<ref type="bibr" target="#b45">[46]</ref>.</figDesc><graphic coords="19,145.09,423.67,141.43,142.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 18 :</head><label>18</label><figDesc>Figure 18: Noisy bear2 (SNR = 13 dB): (a) test image and contours detected using (b) the proposed approach, (c) the Canny edge detector [1], (d) single-scale surround inhibition<ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON<ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition<ref type="bibr" target="#b45">[46]</ref>.</figDesc><graphic coords="20,144.01,433.69,141.52,142.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 19 :</head><label>19</label><figDesc>Figure 19: Boat (321 × 481 pixels): (a) test image and contours detected using (b) the proposed approach, (c) the Canny edge detector [1],(d) single-scale surround inhibition<ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON<ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition<ref type="bibr" target="#b45">[46]</ref>.</figDesc><graphic coords="21,173.05,507.43,113.14,169.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 20 :</head><label>20</label><figDesc>Figure 20: Noisy boat (SNR = 13 dB): (a) test image and contours detected using (b) the proposed approach, (c) the Canny edge detector [1], (d) single-scale surround inhibition<ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON<ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition<ref type="bibr" target="#b45">[46]</ref>.</figDesc><graphic coords="22,316.06,507.43,113.05,169.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 21 :</head><label>21</label><figDesc>Figure 21: "Man and woman" (480 × 320 pixels): (a) test image and contours detected using (b) the proposed approach, (c) the Canny edge detector [1], (d) single-scale surround inhibition<ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON<ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition<ref type="bibr" target="#b45">[46]</ref>.</figDesc><graphic coords="23,102.07,389.41,183.94,122.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Figure 22 :</head><label>22</label><figDesc>Figure 22: Noisy man and woman (SNR = 13 dB): (a) test image and contours detected using (b) the proposed approach, (c) the Canny edge detector [1], (d) single-scale surround inhibition<ref type="bibr" target="#b53">[54]</ref>, (e) a modification of the multiscale edge detector CARTOON<ref type="bibr" target="#b44">[45]</ref>, and (f) a multiscale contour detector with surround inhibition<ref type="bibr" target="#b45">[46]</ref>.</figDesc><graphic coords="24,102.01,395.98,184.03,122.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 23 :Figure 24 :Figure 25 :</head><label>232425</label><figDesc>Figure 23: Contours detected using the proposed algorithm for the noisy elephant image (a) without and (b) with Bayesian denoising.</figDesc><graphic coords="25,315.52,280.27,141.43,142.36" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The research of Giuseppe Papari is funded by NWO-Dutch Organization for Scientific Research.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>where he gained a specific expertise in the field of radar signal processing and in applied detection and estimation theory, becoming the chief of the advanced system group. In 1987, he joined the INFOCOM Department of the University of Rome "La Sapienza" as Associate Professor in signal and information theory. In November 1992, he joined the Electronic Department of the University of Rome "Roma Tre" as Associate Professor in electrical communications. Since September 2001, he is Full Professor in telecommunications at the University of Rome "Roma Tre." Since 1987, his research activity has been focused mainly on information theory, signal theory, and signal and image processing and their applications to both telecommunications systems and remote sensing.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A computational approach to edge detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="679" to="698" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast boundary detection: a generalization and a new algorithm</title>
		<author>
			<persName><forename type="first">W</forename><surname>Frei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="988" to="998" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The detection of intensity changes by computer and biological vision systems</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Hildreth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, Graphics, and Image Processing</title>
		<imprint>
			<date type="published" when="1983">1983</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Local orientation analysis in images by means of the Hermite transform</title>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Martens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1103" to="1116" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Linear feature extraction and description</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, Graphics, and Image Processing</title>
		<imprint>
			<date type="published" when="1980">1980</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="257" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Using angular dispersion of gradient direction for detecting edge ribbons</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Gregson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="682" to="696" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Integrated directional derivative gradient operator</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Zuniga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="508" to="517" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Edge detection by regularized cubic B-spline fitting</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="636" to="643" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Detection of composite edges</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mehrotra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="25" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Digital step edges from zero crossing of second directional derivatives</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="58" to="68" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On detecting edges</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Nalwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Binford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="699" to="714" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Feature detection in human vision: a phase-dependent energy model</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Morrone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Burr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proceedings of the Royal Society of London. Series B, Biological sciences</title>
		<imprint>
			<biblScope unit="volume">235</biblScope>
			<biblScope unit="issue">1280</biblScope>
			<biblScope unit="page" from="221" to="245" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Primitive features by steering, quadrature, and scale</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Folsom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Pinter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1161" to="1173" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Feature detection using suppression and enhancement</title>
		<author>
			<persName><forename type="first">F</forename><surname>Heitger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>Communication Technology Laboratory, Swiss Federal Institute of Technology, Zurich, Switzerland</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep. TR-163</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Image features from phase congruency</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kovesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Videre: Journal on Computer Vision Research</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2" to="27" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Feature detection from local energy</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Morrone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Owens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="303" to="313" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Edge detection and linear feature extraction using a 2-D random field model</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Venkateswar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="84" to="95" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Image field categorization and edge/corner detection from gradient covariance</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="190" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Edge detection with embedded confidence</title>
		<author>
			<persName><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Georgescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1351" to="1365" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Robust anisotropic diffusion</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Marimont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="421" to="432" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Smoothing and edge detection by time-varying coupled nonlinear diffusion equations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A Z</forename><surname>Barcelos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Mair</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="85" to="100" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Scale-space and edge detection using anisotropic diffusion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="629" to="639" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A review of nonlinear diffusion filtering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scale-Space Theory in Computer Vision</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">1252</biblScope>
			<biblScope unit="page" from="3" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">EdgeFlow: a technique for boundary detection and image segmentation</title>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Manjunath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1375" to="1388" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Contour and texture analysis for image segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="27" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A unified approach to boundary perception: edges, textures, and illusory contours</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Manjunath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="96" to="108" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Contour detection based on nonclassical receptive field inhibition</title>
		<author>
			<persName><forename type="first">C</forename><surname>Grigorescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Petkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Westenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="729" to="739" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Visual segmentation by contextual influences via intracortical interactions in the primary visual cortex</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Network: Computation in Neural Systems</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="187" to="212" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Computational models of visual neurons specialised in the detection of periodic and aperiodic oriented visual stimuli: bar and grating cells</title>
		<author>
			<persName><forename type="first">N</forename><surname>Petkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kruizinga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="83" to="96" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Suppression of contour perception by band-limited noise and its relation to nonclassical receptive field inhibition</title>
		<author>
			<persName><forename type="first">N</forename><surname>Petkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Westenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="236" to="246" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Theory of edge detection</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Hildreth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proceedings of the Royal Society of London. Series B, Biological sciences</title>
		<imprint>
			<biblScope unit="volume">207</biblScope>
			<biblScope unit="issue">1167</biblScope>
			<biblScope unit="page" from="187" to="217" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Contour integration by the human visual system: evidence for a local &quot;association field</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Hess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="193" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Kanizsa</surname></persName>
		</author>
		<title level="m">Organization in Vision: Essays on Gestalt Perception</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Praeger</publisher>
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Texture segmentation and pop-out from orientation contrast</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Nothdurft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1073" to="1078" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The visual filter mediating letter identification</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Solomon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Pelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">369</biblScope>
			<biblScope unit="issue">6479</biblScope>
			<biblScope unit="page" from="395" to="397" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Spatial distribution of contextual interactions in primary visual cortex and in visual perception</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Kapadia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Westheimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2048" to="2062" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Neuronal responses to static texture patterns in area V1 of the alert macaque monkey</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Knierim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Van Essen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="961" to="980" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Response modulation by texture surround in primate area V1: correlates of &quot;popout&quot; under anesthesia</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Nothdurft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Gallant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Van Essen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Neuroscience</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="34" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Surround suppression in primate V1</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Grieve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Sillito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2011" to="2028" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Image denoising using scale mixtures of Gaussians in the wavelet domain</title>
		<author>
			<persName><forename type="first">J</forename><surname>Portilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Strela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1338" to="1351" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Visual pattern discrimination</title>
		<author>
			<persName><forename type="first">B</forename><surname>Julesz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IRE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="84" to="92" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Application of Fourier analysis to the visibility of gratings</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">W</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Robson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Physiology</title>
		<imprint>
			<biblScope unit="volume">197</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="551" to="566" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Multifrequency channel decompositions of images and wavelet models</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2091" to="2110" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Capture and transparency in coarse quantized images</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Morrone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Burr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="2609" to="2629" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">CARTOON: a biologically motivated edge detection algorithm</title>
		<author>
			<persName><forename type="first">W</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Nishihara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dawson</surname></persName>
		</author>
		<editor>Natural Computation, W. Richards</editor>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="55" to="69" />
			<pubPlace>Cambridge, Mass, USA</pubPlace>
		</imprint>
	</monogr>
	<note>MIT A.I. Memo no. 668, chapter 4</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A multiscale approach to conour detection by texture suppression</title>
		<author>
			<persName><forename type="first">G</forename><surname>Papari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Campisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Petkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image Processing: Algorithms and Systems, Neural Networks, and Machine Learning</title>
		<meeting><address><addrLine>San Jose, Calif, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-01">January 2006</date>
			<biblScope unit="volume">6064</biblScope>
			<biblScope unit="page" from="107" to="118" />
		</imprint>
	</monogr>
	<note>of Proceedings of the SPIE</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Random cascades on wavelet trees and their use in analyzing and modeling natural images</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied and Computational Harmonic Analysis</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="89" to="123" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note>special issue on wavelet applications</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Statistical modeling of photographic images</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Image and Video Processing</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Bovik</surname></persName>
		</editor>
		<meeting><address><addrLine>Boston, Mass, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="431" to="441" />
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Waveletbased statistical signal processing using hidden Markov models</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Crouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Baraniuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="886" to="902" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Low-complexity image denoising based on statistical modeling of wavelet coefficients</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Mihc ¸ak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kozintsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramchandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="300" to="303" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Adaptive Wiener denoising using a Gaussian scale mixture model in the wavelet domain</title>
		<author>
			<persName><forename type="first">J</forename><surname>Portilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Strela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th IEEE International Conference on Image Processing (ICIP &apos;01)</title>
		<meeting>the 8th IEEE International Conference on Image Processing (ICIP &apos;01)<address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-10">October 2001</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="37" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A parametric texture model based on joint statistics of complex wavelet coefficients</title>
		<author>
			<persName><forename type="first">J</forename><surname>Portilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="71" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Anisotropic wavelet thresholding for Bayesian image denoising</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jacovitti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th European Signal Processing Conference (EUSIPCO &apos;02)</title>
		<meeting>the 11th European Signal Processing Conference (EUSIPCO &apos;02)<address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-09">September 2002</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="267" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Contour and boundary detection improved by surround suppression of texture edges</title>
		<author>
			<persName><forename type="first">C</forename><surname>Grigorescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Petkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Westenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="609" to="622" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Spatial heterogeneity of inhibitory surrounds in the middle temporal visual area</title>
		<author>
			<persName><forename type="first">D.-K</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Raiguel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Marcar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Koenderink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Orban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences of the United States of America</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="11303" to="11306" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J A M</forename><surname>Heimans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Morphological Image Operators</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Academic Press</publisher>
			<pubPlace>Boston, Mass, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Connected morphological operators for binary images</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J A M</forename><surname>Heijmans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="99" to="120" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Edge detection and ridge detection with automatic scale selection</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lindeberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="117" to="154" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Bounded diffusion for multiscale edge detection using regularized cubic B-spline fitting</title>
		<author>
			<persName><forename type="first">K.-H</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tjahjadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="291" to="297" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">On the canny edge detector</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goshtasby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="721" to="725" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Adaptive-scale filtering and feature detection using range data</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Olson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="983" to="991" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Learning to detect natural image boundaries using local brightness, color, and texture cues</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="530" to="549" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Edge detector evaluation using empirical ROC curves</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kranenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dougherty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="103" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Edge evaluation using local edge coherence</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kitchen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="597" to="605" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">An objective comparison methodology of edge detection algorithms for structure from motion task</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Goldgof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Evaluation Techniques in Computer Vision</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="235" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Comparison of edge detector performance through use in an object recognition task</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Goldgof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Image Understanding</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="160" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Suppression of contour perception by band-limited noise and its relation to nonclassical receptive field inhibition</title>
		<author>
			<persName><forename type="first">N</forename><surname>Petkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Westenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="236" to="246" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Distance sets for shape filters and shape recognition</title>
		<author>
			<persName><forename type="first">C</forename><surname>Grigorescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Petkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1274" to="1286" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Robustness of shape descriptors to incomplete contour representations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Petkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1793" to="1804" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">A cognitive evaluation procedure for contour based shape descriptors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Petkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Hybrid Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="237" to="252" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Effect of high curvature point deletion on the performance of two contour based shape recognition algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Petkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Pattern Recognition and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="913" to="924" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Edge focusing</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bergholm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="726" to="741" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Image and Vision Computing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Goshtasby</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="247" to="256" />
		</imprint>
	</monogr>
	<note>On edge focusing</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
