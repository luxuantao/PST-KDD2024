<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Polarity Analysis of Texts using Discourse Structure</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Bas</forename><surname>Heerschop</surname></persName>
							<email>basheerschop@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Erasmus University Rotterdam</orgName>
								<address>
									<postBox>P.O. Box 1738</postBox>
									<postCode>3000 DR</postCode>
									<settlement>Rotterdam</settlement>
									<country key="NL">the Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Frank</forename><surname>Goossen</surname></persName>
							<email>frank.goossen@xs4all.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">Erasmus University Rotterdam</orgName>
								<address>
									<postBox>P.O. Box 1738</postBox>
									<postCode>3000 DR</postCode>
									<settlement>Rotterdam</settlement>
									<country key="NL">the Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexander</forename><surname>Hogenboom</surname></persName>
							<email>hogenboom@ese.eur.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">Erasmus University Rotterdam</orgName>
								<address>
									<postBox>P.O. Box 1738</postBox>
									<postCode>3000 DR</postCode>
									<settlement>Rotterdam</settlement>
									<country key="NL">the Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Uzay</forename><surname>Kaymak</surname></persName>
							<email>u.kaymak@ieee.org</email>
							<affiliation key="aff0">
								<orgName type="institution">Erasmus University Rotterdam</orgName>
								<address>
									<postBox>P.O. Box 1738</postBox>
									<postCode>3000 DR</postCode>
									<settlement>Rotterdam</settlement>
									<country key="NL">the Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Eindhoven University of Technology</orgName>
								<address>
									<postBox>P.O. Box 513</postBox>
									<postCode>5600 MB</postCode>
									<settlement>Eindhoven</settlement>
									<country key="NL">the Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Franciska</forename><surname>De Jong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Erasmus University Rotterdam</orgName>
								<address>
									<postBox>P.O. Box 1738</postBox>
									<postCode>3000 DR</postCode>
									<settlement>Rotterdam</settlement>
									<country key="NL">the Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Universiteit Twente</orgName>
								<address>
									<postBox>P.O. Box 217</postBox>
									<postCode>7500 AE</postCode>
									<settlement>Enschede</settlement>
									<country key="NL">the Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Polarity Analysis of Texts using Discourse Structure</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F4B100066E2FC4D816BA2BFF0FCE24FB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing-Linguistic processing; I.2.7 [Artificial Intelligence]: Natural Language Processing-Discourse Algorithms</term>
					<term>Experimentation</term>
					<term>Performance Discourse Structure</term>
					<term>Linguistics</term>
					<term>Polarity</term>
					<term>Sentiment</term>
					<term>RST</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Sentiment analysis has applications in many areas and the exploration of its potential has only just begun. We propose Pathos, a framework which performs document sentiment analysis (partly) based on a document's discourse structure. We hypothesize that by splitting a text into important and less important text spans, and by subsequently making use of this information by weighting the sentiment conveyed by distinct text spans in accordance with their importance, we can improve the performance of a sentiment classifier. A document's discourse structure is obtained by applying Rhetorical Structure Theory on sentence level. When controlling for each considered method's structural bias towards positive classifications, weights optimized by a genetic algorithm yield an improvement in sentiment classification accuracy and macro-level F1 score on documents of 4.5% and 4.7%, respectively, in comparison to a baseline not taking into account discourse structure.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Sentiment analysis is a rather young research area focusing on how to determine the attitude or subjectivity of a text. It has many applications, such as mining social media like Facebook and Twitter for consumer opinions about products and brands. For companies, sentiment analysis on data obtained from stakeholders can provide highly valuable information. The importance of sentiment analysis in specific areas has been indicated in <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b5">5,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b18">18]</ref>, for financial markets, politics, organizations, brand management, and economic systems, respectively.</p><p>The goal of sentiment analysis is typically to determine the polarity of a piece of natural language text. Sentiment analysis methods are mainly rooted in, among others, natural language processing, computational linguistics, and text mining. Several research directions are explored in recent literature, including word sentiment scoring (i.e., learning sentiment scores of single words), subject/aspect relevance filtering (i.e., determining the relevant subject and/or aspect for a sentiment-carrying word), sentiment negation and amplification, and subjectivity analysis (i.e., determining whether sentences are subjective or objective) <ref type="bibr" target="#b12">[12]</ref>.</p><p>A typical approach to sentiment analysis is to use frequencies of positive and negative words in order to determine whether a document is predominantly positive or negative <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b31">31]</ref>. Such an approach ignores structural aspects of a document, whereas these aspects may contain valuable information <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b30">30</ref>]. Yet, using knowledge obtained from structural elements in texts is a relatively unexplored direction in sentiment analysis. When capturing a text's discourse structure, this knowledge could be used to improve sentiment analysis (e.g., by assigning different weights to conclusions and footnotes, as conclusions may be more important for the overall sentiment of a text than footnotes).</p><p>A popular model for analyzing a text's discourse structure is the Rhetorical Structure Theory (RST) <ref type="bibr" target="#b19">[19]</ref>. RST describes how to split a text into spans, each representing a meaningful part of the text. These spans can be either a nucleus or a satellite. A nucleus is considered to be the span with the highest degree of importance with respect to its related spans. Satellites support the nuclei and can therefore be seen as less important spans. By splitting a text into important and less important parts, we can treat these parts differently from each other when determining the overall sentiment. We hypothesize that by weighting text spans in accordance with their importance for the overall document sentiment, the detected document sentiment can be more reliable. We aim to investigate whether the use of discourse structure in sentiment analysis has a significant added value. For this purpose, we propose Pathos, a sentiment analysis framework that can interpret a text using RST, and use this information to classify the text's polarity.</p><p>The paper is structured as follows. Section 2 presents the related work. Subsequently, Section 3 elaborates on our proposed sentiment analysis framework, after which we present the results of our evaluation in Section 4. In Section 5, we draw conclusions and propose directions for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>In a recent literature survey on sentiment analysis, Pang and Lee <ref type="bibr" target="#b25">[25]</ref> attribute the recent surge of research interest in systems that deal with opinions and sentiment to the fact that, despite today's users' hunger for and reliance upon online advice and recommendations, explicit information on user opinions is often hard to find, confusing, or overwhelming. As sentiment analysis tools may be particularly useful in analyzing, e.g., reviews, a widely used corpus for assessing sentiment analysis approaches is a collection of 2,000 English movie reviews, annotated for sentiment <ref type="bibr" target="#b23">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">State of the Art</head><p>In many existing sentiment analysis approaches, a document is represented as a bag of words, i.e., an unordered collection of the words occurring in a document. Such an approach allows for vector representations of documents, enabling the use of machine learning techniques like Support Vector Machines for classifying documents. Features in such representations may be for instance words or parts of words. A binary representation of documents, indicating the presence or absence of specific words, has proven to be an effective approach, yielding an accuracy of 87.2% on the movie review data set <ref type="bibr" target="#b23">[23]</ref>. Later research has focused on adding other features to the vector representations of documents. For instance, Whitelaw et al. <ref type="bibr" target="#b32">[32]</ref> added features representing semantic distinctions between words based on the Appraisal Theory <ref type="bibr" target="#b20">[20]</ref>, thus yielding an accuracy of 90.2% on the movie review data set. Paltoglou and Thelwall <ref type="bibr" target="#b22">[22]</ref> report a leave-one-out accuracy of 96.9% on this data set, obtained by using tf-idf -based weights for word features rather than using a binary representation of documents.</p><p>However, even though classifiers like the ones mentioned above may perform very well in the domain that they have been trained on, their performance drops tremendously when they are used in a different domain. In this light, lexiconbased methods, operating at a deeper level of analysis by incorporating the semantic orientation of individual words, can be used as an alternative <ref type="bibr" target="#b29">[29]</ref>. A sentiment lexicon typically contains words and their associated sentiment, possibly differentiated by Part-of-Speech (POS) and/or meaning. A relatively straightforward lexicon-based sentiment analysis framework has been shown to have an accuracy up to 59.5% on the full movie review data set <ref type="bibr" target="#b11">[11]</ref>. A more sophisticated lexicon-based sentiment analysis approach has been shown to have an accuracy of 59.6% to 76.4% on 1,900 documents from the movie review data set, depending on the sentiment lexicon used <ref type="bibr" target="#b29">[29]</ref>. The latter lexicon-based approach is presented as a well-performing method, which is robust across domains and texts. Approaches like the one proposed by Taboada et al. <ref type="bibr" target="#b29">[29]</ref> enable a more thorough linguistic analysis to be incorporated in the process of analyzing sentiment in natural language text. Yet, rather than just looking at semantic orientation of individual words or groups of words, one may also consider analyzing the role these textual elements play in conveying the overall sentiment by applying discourse analysis. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Rhetorical Structure Theory</head><p>According to UsingEnglish (http://www.usingenglish. com), discourse analysis can be defined as 'the area of linguistics that is concerned with how we build up meaning in the larger communicative rather than grammatical units; meaning in a text, paragraph, conversation, etc., rather than in a single sentence'. In our current endeavors, we apply discourse analysis in order to determine the parts of the text that are most relevant to the overall document sentiment. Intuitively, by splitting the text into parts with different levels of importance, sentiment analysis can be more reliable when weighting sentiment of parts of a text in accordance with their associated impact on a document's sentiment.</p><p>One of the leading discourse theories is RST <ref type="bibr" target="#b19">[19]</ref>, which can be used to split a text into spans which are rhetorically related to each other. There are two forms of relations: hypotactic and paratactic relations. In a hypotactic relation, one span is classified as nucleus, whereas the other spans are classified as satellite. RST claims nuclei to be more significant than satellites with respect to understanding and interpreting a text. In a paratactic relation, spans are equally significant, thus resulting in all spans to be classified as nuclei. RST identifies the smallest text spans that can hold rhetorical relations as Elementary Discourse Units (EDUs). Together, multiple EDUs can form a new text span, which again holds a rhetorical relation to another text span, thus yielding in a hierarchical structure of the text. RST also distinguishes several types of relations (e.g., elaboration, attribution, contrast, etc.). The authoritative paper on RST <ref type="bibr" target="#b19">[19]</ref> defines 23 types of relations. In our framework, we differentiate among relation types by assigning them weights according to their importance, which we hypothesize to have a significant influence on the polarity of a document. Figure <ref type="figure" target="#fig_0">1</ref> shows an example of an RST-structured sentence, where the text 'Although it was great to see Brad Pitt fall off a cliff, the movie was terrible.' is split into two segments. The first span is classified as a satellite and is related to the other span, the nucleus. The relation type is 'contrast', which indicates that the satellite segment of the sentence provides a contrast with the nucleus segment.</p><p>A human would typically interpret the specific sentence of Figure <ref type="figure" target="#fig_0">1</ref> as a negative review for the movie, as he would see the second span (the nucleus) as the most important span. However, in a classical (word-counting) sentiment analysis approach, all words would contribute equally to the total sentiment. Accordingly, a computer would count 'great' as very positive, and 'terrible' as very negative, which summed up makes a neutral review. When we exploit the information contained in the RST structure, the nucleus can be given a higher weight than the satellite, thus shifting focus to the nucleus segment. In this case, a higher weight for the nucleus and a lower weight for the satellite would probably lead to a negative sentiment score for this sentence. By using the knowledge obtained from the RST structure, we can thus get a more reliable sentiment score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Parsing Structure from Documents</head><p>In order to exploit a document's discourse structure and in an analysis of the sentiment conveyed by the text, one needs to first identify the discourse structure. Manual annotation of discourse structure is typically cumbersome, timeconsuming, and not easily scalable, thus rendering automatic discourse parsing an attractive alternative. There are several discourse parsers publicly available which can parse an RST structure from a document. One of them is Sentence-level PArsing of DiscoursE (SPADE) <ref type="bibr" target="#b28">[28]</ref>, which creates RST trees for every sentence in a document. SPADE has been trained and tested on the train and test set of the RST Discourse Treebank (RST-DT) <ref type="bibr" target="#b7">[7]</ref>, where an F1 score of 83.1% is reached on identifying the right rhetorical relations and their right arguments <ref type="bibr" target="#b28">[28]</ref>.</p><p>Another publicly available discourse parser is the HIgh-Level Discourse Analyzer <ref type="bibr" target="#b13">[13]</ref> (HILDA), which applies statistical machine-learning techniques <ref type="bibr" target="#b8">[8]</ref> to parse discourse structures from documents using the Rhetorical Structure Theory. In contrast with SPADE's sentence-level parsing, HILDA offers document-level parsing. HILDA has also been trained and tested on RST-DT, and achieved an F1 score of 94.1% on identifying relations <ref type="bibr" target="#b13">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Rhetorical Structure Theory in Sentiment Analysis</head><p>Taboada et al. present an RST-based sentiment analysis approach with the Sentiment Orientation CALculator (SO-CAL) <ref type="bibr" target="#b30">[30]</ref>. The assumption is that certain parts of a text are more relevant than others with respect to the overall sentiment expressed. Two methods are proposed to extract the relevant sentences: (1) extract nuclei within sentences using the SPADE discourse parser, and (2) extract sentences that are considered on-topic using a decision tree based on the ID3 algorithm <ref type="bibr" target="#b27">[27]</ref>. Both approaches have proven to contribute to SO-CAL's performance in classifying sentiment.</p><p>However, SO-CAL merely differentiates between core elements of a text (nuclei) on the one hand, and any type of less important (satellite) element on the other hand. Yet, we hypothesize that the contribution of text elements to the overall sentiment of a document depends on their respective positions within the overall discourse structure and hence their relation to other elements. For instance, a contrasting text span may play a different role in conveying the overall sentiment than an elaboration on information in nuclei does. Therefore, we propose a more elaborate approach to utilizing RST in sentiment analysis by taking into account hypotactic relations between nuclei and satellites.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PATHOS</head><p>We present Pathos, a sentiment analysis framework that is able to interpret a text in terms of its discourse structure, and use this information to classify the text's polarity. First, we provide an overview of all components used in our framework. Then, we discuss the design of our sentiment classifier. Finally, we discuss the approaches to discourse parsing supported by this classifier. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>The proposed framework consists of three parts, depicted in Figure <ref type="figure" target="#fig_1">2</ref>. The central part is the sentiment classifier which classifies documents as either positive or negative. In order to do this, our framework first identifies the POS and the lemmas of all words and performs Word Sense Disambiguation (WSD). The positioner can employ a discourse parser (SPADE) to transform the input text into EDUs which are used to assign a weight to each individual word. The overall sentiment of a document is then computed as a weighted average of individual word scores, retrieved from a sentiment lexicon which differentiates on POS and word sense -Sen-tiWordNet 3.0 <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b9">9]</ref> (SWN), which has proven to be very useful for this purpose <ref type="bibr" target="#b11">[11]</ref>. Such a lexicon-based sentiment scoring approach is in accordance with the work by Taboada et al. <ref type="bibr" target="#b30">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sentiment Classifier</head><p>To investigate the merits of taking into account structural aspects of content in sentiment analysis, we propose a lexicon-based sentiment analysis approach, taking into account adjectives, adverbs, verbs, and nouns. Scoring a document for sentiment involves aggregating word-level sentiment scores, retrieved from a sentiment lexicon, after having initially determined each word's POS and lemma. A sentiment lexicon can contain entries for different senses for an arbitrary POS of an arbitrary word. In order to determine the appropriate sense of a word in a particular sentence, we use a similarity function proposed by Baazaoui Zghal et al. <ref type="bibr" target="#b2">[2]</ref> and inspired by the Lesk algorithm <ref type="bibr" target="#b17">[17]</ref>. We apply this algorithm because it is an unsupervised algorithm, able to compute adequate senses in a relatively small amount of time. Other unsupervised algorithms as SSI <ref type="bibr" target="#b21">[21]</ref> and Lesk <ref type="bibr" target="#b17">[17]</ref> require more computations which make the WSD a slow process. </p><formula xml:id="formula_0">S i = {S i , synonym}; end end if |S i ∩ I| &gt; |mostSimilarS i ∩ I| then mostSimilarS i = S i ; mostSimilarSynset = synset; end else if |S i ∩ I| = |mostSimilarS i ∩ I| then if |S i | &gt; |mostSimilarS i | then mostSimilarS i = S i ; mostSimilarSynset = synset; end end end return i; end end</formula><p>In our applied WSD algorithm (described in Algorithm 1), the word sense with the highest semantic similarity to the word's context is selected. Here, the similarity sim (Si, I) of a set Si, denoting the semantic neighborhood of sense i of the word to be disambiguated, with the word's context I (i.e., the set denoting the sentence lexical neighborhood of the word to be disambiguated) can be defined as:</p><formula xml:id="formula_1">sim (Si, I) = |Si ∩ I|. (<label>1</label></formula><formula xml:id="formula_2">)</formula><p>Si contains the word to be disambiguated and all the synonyms, hyponyms, hypernyms, and gloss words of the Word-Net synset. Furthermore, I contains all the words in the sentence without the word to be disambiguated. The set which has the highest similarity to I is then selected, and gives the most similar sense i. If there are more sets with the same similarity, the set Si which has the maximum number of elements is chosen. When having determined each word's POS, lemma, and its associated word sense, the score eval (d) of a document d can be computed as the sum of the scores of the individual sentences: </p><formula xml:id="formula_3">eval (d) = s i ∈d score (si) ,<label>(2)</label></formula><p>where the weights are computed differently for our three positioners in accordance with the methods explained in Section 3.3. Here, word-level sentiment scores score (wj) are assumed to be in the range [-1, 1] (anywhere in between negative and positive, respectively). Using (2), the classification class (d) of a document d can finally be determined as follows:</p><formula xml:id="formula_5">class (d) = 1 if eval(d) -offset ≥ 0, -1 if eval(d) -offset &lt; 0,<label>(4)</label></formula><p>where 1 denotes a positive document, and -1 denotes a negative document. The offset corrects a possible bias in the sentiment scores caused by people's tendency to write negative reviews with rather positive words, which can lead to a small negative sentiment score or sometimes even a positive score for a negative document, whereas a positive document usually gets a high positive sentiment score <ref type="bibr" target="#b30">[30]</ref>. The offset can be calculated by taking the average sentiment scores of both positive and negative documents in the training set and subsequently computing the equidistant point of these scores. Algorithm 2 is used to score a document. Each sentence is scored separately and its score is added to the overall document sentiment score. Sentence scores are essentially weighted averages of the sentiment scores of their individual words. The calculation for each word in a sentence (only non-stopwords) consists of five steps: (1) determining the POS, (2) retrieving the lemma of the word based on its POStype, (3) determining which meaning of a word to use (using the WSD process described in Algorithm 1), (4) retrieving the score of the word from the sentiment lexicon, and (5) assigning a weight in accordance with the word's position in the document's discourse structure. Pathos supports several methods for parsing a document's discourse structure and assigning corresponding weights to individual words, as further detailed in Section 3.3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Discourse Parsing</head><p>Existing work suggests that sentiment analysis may benefit from a better understanding of discourse in texts <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b30">30]</ref>. Hence, we propose a discourse parsing module that first retrieves the discourse structure of a document and subsequently assigns discourse-based weights to sentimentcarrying words using a so-called positioner. Our framework supports three ways of accounting for discourse structure when determining a document's polarity.</p><p>A simple example of a discourse structure found in most sentiment-carrying documents (e.g., movie reviews) is the distinction of 'introduction', 'arguments', and 'conclusions'. Intuitively, one would think that an author typically puts his final and most important opinion towards the end of the text. To test this intuition, Pathos is able to assign weights to each word of a document, based on their respective position. The words are weighted uniformly in the range [0, 1], where the first word is assigned a weight of 0, and the last word is assigned a weight of 1. This Simple positioner approach is described in Algorithm 3.</p><p>In order to obtain a more advanced discourse structure, Pathos uses SPADE <ref type="bibr" target="#b28">[28]</ref> to extract sentence-level RST structures from texts. Subsequently, Pathos is able to assign a weight to each word based on its position in an RST structure. Table <ref type="table" target="#tab_1">1</ref> shows all RST relation types handled by Pathos. These relations are a subset of the 23 standard relations defined in <ref type="bibr" target="#b19">[19]</ref>, encompassing only the relation types occurring in at least 10% of our considered set of reviews (see Section 4 for more details on our corpus).</p><p>Taboada et al. <ref type="bibr" target="#b30">[30]</ref> hypothesize that adjectives found in nuclei of a document are more important for the overall sentiment, while adjectives found in satellites potentially interfere with the overall sentiment -the latter adjectives may be tangential or even irrelevant for a document's overall sentiment. Pathos can handle the notion of discourse structure thus introduced to the sentiment mining process by means of the SPADE positioner algorithm (Algorithm 4), which tags the words in the top-level nuclei of each sentence as nuclei, and the words in all other top-level elements as satellites. If a sentence only consists of a single text span, all words in that span are tagged as nuclei. Each word can be given a weight based on the RST element in which it resides. Following Taboada et al. <ref type="bibr" target="#b30">[30]</ref>, we consider two sets of weights for nuclei and satellites: (1) 1 and 0, and (2) 1.5 and 0.5, respectively. Yet, rather than only analyzing adjectives, we additionally handle adverbs, verbs, and nouns.</p><p>Building on the idea that some text spans can be more important for the overall sentiment of a document than other text spans, we propose a third approach which further explores satellites and their relation to the nuclei. We hypothesize that a hierarchy exists between the satellite relation types -some satellite relation types may contribute differently to the overall sentiment than others. By employing the SPADE Extended algorithm, shown in Algorithm 5, Pathos can give specific weights to the words in satellite elements based on their RST relation type. In addition to the positive weights considered by Taboada et al. <ref type="bibr" target="#b30">[30]</ref> for their RST elements, we consider negative weights, as some text spans (e.g., contrasting text spans) may contribute negatively to the overall sentiment of a document. In order to be able to additionally intensify sentiment in certain text spans, we assume the weights to be in the range <ref type="bibr">[-2, 2]</ref>. These weights can be optimized by means of a Genetic Algorithm (GA).</p><p>To this end, the sum of sentiment scores in the span of each RST relation type in a document (e.g., 'nucleus' in the case of a nucleus span, or 'attribution', 'elaboration', etc. in case of satellites) is first calculated. Subsequently, a set of potential solutions -chromosomes -can be generated, where each chromosome represents a set of weights for all considered RST relation types. These chromosomes are then subject to a process of simulated biological evolution according to the principle of survival of the fittest. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EVALUATION</head><p>In this section, we evaluate our different approaches to determine the polarity of texts. Evaluation is done by assessing the processing times, accuracy, precision, recall, and F1 score of the different positioners for the sentiment analysis framework. We have evaluated our framework on a data set provided by Pang and Lee <ref type="bibr" target="#b24">[24]</ref>, which was introduced in <ref type="bibr" target="#b23">[23]</ref>. The set is a collection of 1,000 positive and 1,000 negative movie reviews, which have been extracted from movie review websites. From the original set, we have extracted a subset of 500 positive and 500 negative reviews, because SPADE was not able to process all reviews due to problems with syntax in over 800 documents.</p><p>We have randomly split the dataset into a training and test set, consisting of 60% and 40% of the documents, respectively, with both sets encompassing a proportional number of occurrences of each considered relation type. Thus, our training set contains 300 positive reviews and 300 negative reviews, whereas the test set contains 200 positive reviews and 200 negative reviews. The training set is used to train the GA for the SPADE Extended positioner, as well as to compute an offset value for each individual positioner. The test set is used to measure and compare the performances of all approaches.</p><p>For running our experiments, we have built a Graphical User Interface (GUI), enabling us to select different options for an experiment as well as to select the directories containing positive and negative documents. This GUI also displays the results of an experiment, as demonstrated in Figure <ref type="figure" target="#fig_3">3</ref>.</p><p>To evaluate Pathos' processing performance of a single document, we have created another GUI, which is depicted in Figure <ref type="figure" target="#fig_4">4</ref>. The GUI offers the possibility to evaluate all positioners which have been implemented in Pathos. Additionally, this GUI provides insight into the sentiment analysis process. For example, in Figure <ref type="figure" target="#fig_4">4</ref>, a document processed by the SPADE Extended positioner is shown. In our GUI, words are colored depending on their sentiment score (a positive word is colored green, and a negative word is colored red), and the underlying information about a word (lemma, score, weight, POS, RST relation) can be requested by selecting the word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>To test the performance of the considered positioners, we have evaluated them in our sentiment analysis framework, the core of which acts as a document processing pipeline (see Section 3.1). In this pipeline, we first determine the POS of words by using the OpenNLP <ref type="bibr" target="#b4">[4]</ref> POS tagger, which has an accuracy of 98.7% <ref type="bibr">[6]</ref>. We then determine the lemmas of words by means of a third party lemmatizer, based on WordNet using the Java WordNet Library (JWNL) API. Its estimated prediction accuracy is about 98%.  In order to subsequently determine which sentiment score of a word to select from our sentiment lexicon, we additionally employ a WSD algorithm (see Algorithm 1). A baseline for this would be always selecting the first sense from Word-Net (which is the most common sense) for each word. We have evaluated our WSD algorithm on a test set of 100 sentences extracted from our corpus. The senses of the words in these sentences have been manually evaluated and annotated by three experts until they reached agreement. Our algorithm obtains an accuracy of 68% on this test set, whereas taking the first sense from WordNet yields an accuracy of 44%.</p><p>For each non-stopword, the POS, lemma, and sense thus determined are used for retrieving the associated sentiment score from the SentiWordNet 3.0 <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b9">9]</ref> sentiment lexicon. SentiWordNet is based on WordNet <ref type="bibr" target="#b10">[10]</ref>, which is a (semantic) lexical resource, organized into sets of synonyms -synsets -which can be differentiated based on their POS type. Each synset expresses a distinct concept and is linked to other synsets through different kinds of relations (e.g., synonymy, antonymy, hyponymy, or meronymy). In Senti-WordNet, each WordNet synset σ has been assigned scores in the range [0, 1] on objectivity Obj(σ), positivity P os(σ), and negativity Neg(σ), the sum of which always equals 1. In our framework, we use SentiWordNet to compute the word sentiment score as a single number computed by subtracting Neg(σ) from P os(σ), which results in a real number in the interval [-1, 1], representing sentiment scores in the range from negative to positive, respectively.</p><p>The key of our framework is in weighting the retrieved word-level sentiment scores in accordance with the place of these words in the discourse structure of a document. As a baseline, we first assess the performance of our framework on our test set without any positioner (i.e., all words in the document are considered to equally contribute to the overall sentiment). An additional baseline is the Simple positioner, which weights the sentiment of words in accordance with their respective positions in the text. Then, we introduce two additional baselines derived from existing work <ref type="bibr" target="#b30">[30]</ref> by evaluating the SPADE positioner with different weights for nucleus and satellite, i.e., 1 and 0 (SPADE I), and 1.5 and 0.5 (SPADE II), respectively. Finally, we assess the use of weights for distinct RST relation types, optimized by a GA, and compare the performance of this positioner (SPADE Extended) with the other considered approaches in an attempt to assess how information conveyed by rhetorical structure can be utilized in sentiment analysis of natural language texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Results</head><p>The optimal set of weights for the different RST elements in our training set is presented in Table <ref type="table" target="#tab_2">2</ref>. With an associated weight of 0.771, 'Nucleus' elements appear to contribute relatively much to the overall document sentiment in our training set. Yet, some satellite elements turn out to play an important role in conveying the overall document sentiment as well. For instance, 'Elaboration' elements receive an even higher weight of 1.400, thus indicating that -in our training setwriters of reviews typically tend to express their sentiment in a more apparent fashion in elaborations on their core message. To a lesser extent, this also holds for rhetorical elements with a purpose of increasing a reader's potential ability of performing actions presented in the core of a review, as 'Enablement' elements are associated with a weight of 0.956. The information presented in 'Attribution', 'Condition', and especially 'Background' elements is clearly less relevant for the overall sentiment in reviews, as these elements receive weights of 0.451, 0.304, and 0.017, respectively.</p><p>Conversely, the sentiment conveyed by elements presenting matters contrasting with the information presented in the core of a review is typically inverted with a weight of -0.660. The sentiment conveyed by 'Cause' and 'Explanation' elements is slightly inverted as well, as these elements receive respective weights of -0.271 and -0.099. These minor inversions may however be artifacts of the relatively low frequencies of these elements in our training set, as they occur in only 89 and 134 out of 600 documents, respectively.</p><p>Tables <ref type="table" target="#tab_3">3</ref> and<ref type="table" target="#tab_4">4</ref> present the results for all considered approaches, respectively without and with offset, on our test set of 400 documents. Table <ref type="table" target="#tab_3">3</ref> shows that the baseline approach has an overall accuracy of 0.585 and a macro-level F 1 of 0.569. The Simple positioner exhibits the largest improvement with respect to these measures, i.e., 3.9% and 4.8%, respectively. Two out of three considered SPADE positioners show an improvement in terms of these measures as well, albeit to a lesser extent. With respect to the baseline, SPADE I exhibits no change in overall accuracy and a 1.2% decrease in macro-level F1. Conversely, applying discourse parsing by means of the SPADE II positioner yields a 2.1% increase in both accuracy and macro-level F1. Yet, the best performing SPADE positioner is the SPADE Extended positioner using the weights presented in Table <ref type="table" target="#tab_2">2</ref>. This positioner exhibits an increase in overall accuracy and macro-level F1 of 2.6% and 2.1%, respectively.</p><p>Yet, Table <ref type="table" target="#tab_3">3</ref> clearly shows that all considered positioners exhibit a structural bias towards positive classifications. When controlling for each positioner's structural bias, the respective positioners exhibit a less biased performance, as detailed in Table <ref type="table" target="#tab_4">4</ref>. The baseline approach now yields an overall accuracy of 0.688 and a macro-level F1 of 0.687. Compensation for the structural bias causes the Simple positioner, the SPADE I positioner, as well as the SPADE II positioner to perform below baseline. With respect to the baseline, overall accuracy and macro-level F1 decrease with 5.8% and 5.5% for the Simple positioner, 1.9% and 1.8% for the SPADE I positioner, and 0.4% and 0.4% for the SPADE II positioner, respectively. Conversely, the SPADE Extended positioner exhibits a 4.5% increase in overall accuracy and a 4.7% increase in macro-level F1 with respect to the baseline when controlling for each positioner's structural bias.</p><p>These results indicate that information contained in discourse structure of documents can improve the classification of sentiment conveyed by these documents. Additionally, the use of offsets improves the overall performance of each considered method, thus confirming the hypothesis of Taboada et al. <ref type="bibr" target="#b30">[30]</ref> that a possible structural bias caused by negative documents carrying much positive sentiment can be corrected by applying an offset in the calculation of senti-ment scores for documents. Moreover, we improve on existing work due to our more elaborate, optimized weighting scheme, which assigns distinct rhetorical elements different roles in conveying a document's overall sentiment. Our results indicate that both nuclei and satellites play an important role in conveying sentiment, whereas satellites have until now been deemed predominantly irrelevant.</p><p>However, these observed performance improvements come at a cost of increased processing time. On a standard 2,400 GHz Intel Core 2 Duo system with 2,048 MB physical memory, the average processing time for the baseline approach is approximately 2,786 milliseconds per document in our test set, with a standard deviation of approximately 1,176 milliseconds. Our Simple positioner has a similar performance, as it takes on average approximately 2,585 milliseconds to process a single document, with a standard deviation of about 1,121 milliseconds. Conversely, the SPADE positioners inspired by existing work <ref type="bibr" target="#b30">[30]</ref>, i.e., SPADE I and SPADE II, need on average about 45,862 milliseconds to process a document, with a standard deviation of 22,457 milliseconds. As the SPADE Extended positioner ignores less frequently occurring RST elements, it needs slightly less time than the SPADE I and SPADE II positioners for processing a document. On average, the SPADE Extended positioner processes a document in approximately 37,943 milliseconds, with a standard deviation of about 16,556 milliseconds.</p><p>The SPADE positioners spend a considerable amount of their processing time on a computationally intensive process of document parsing by means of the freely available SPADE discourse parser <ref type="bibr" target="#b28">[28]</ref>. When considering only the time spent on activities other than using the SPADE discourse parser, the SPADE I and SPADE II positioners show an average document processing time of approximately 2,559 milliseconds, with a standard deviation of 1,062 milliseconds, whereas the SPADE Extended positioner needs on average about 2,571 milliseconds to process a document, with a standard deviation of 1,066 milliseconds. These results indicate that a major challenge lies in finding principal ways of efficiently and effectively extracting discourse structure from natural language texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>While most research in sentiment analysis focuses on the main components of a sentiment classifier (e.g., word sentiment scoring, topic classification, negation, and intensifiers), little research has been done on analyzing the discourse structure of texts in order to identify text spans that are more important for the overall sentiment in a document. We compare three methods for dividing texts into important and less important parts. One method is based on the position of a word in a text. The other two methods exploit discourse structure in natural language text, either by distinguishing between (sentence-level) nuclei and satellites, or by identifying and exploiting (sentence-level) RST relation types. The objective of this paper is to give insights into how information can be harvested from structural aspects of content in order to improve the state-of-the art in sentiment analysis. Our results show that our method exploiting sentence-level RST relation types is the best performing approach, outperforming the baseline with a sentiment classification accuracy increased with 4.5% and a macrolevel F 1 score increased with 4.7%, when controlling for each method's structural bias towards positive classifications. A major bottleneck when accounting for discourse structure is the processing time required for identifying discourse structure in natural language text. Therefore, as future work, we aim to further explore other, scalable methods of identifying the discourse structure of texts. In addition, we would like to explore the applicability of our results in other types of sentiment mining approaches, e.g., methods making use of Support Vector Machines rather than sentiment lexicons. Furthermore, our currently used discourse parser SPADE only retrieves the RST structure on a sentence level, so it would be interesting to investigate the performance of a document level RST structure. Additionally, we aim to evaluate the performance of our methods on different corpora, which may contain other relation types or exhibit a different relation of discourse structure to the overall sentiment. Another interesting direction for future work would be to summarize a text and evaluate this summary using our sentiment classifier. Last, we would like to investigate how to best present a sentiment analysis system's results in order to suit a typical user's needs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of an RST-structured sentence.</figDesc><graphic coords="2,361.68,53.90,149.40,98.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overview of the Pathos framework.</figDesc><graphic coords="3,328.32,53.88,216.00,256.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 2 :</head><label>2</label><figDesc>Scoring a document. input : A document d output: A floating point number representing the sentiment score of document d docScore = 0; docScoreSentenceCount = 0; foreach s in d.Sentences do sentenceScore = 0; foreach w in s.W ords do pos = getPOS(w, s); lemma = getLemma(w, pos); sense = getWordSense(w, s, pos); score = getWordScore(lemma, sense, pos); weight = getWeight(w, s, document); sentenceScore = sentenceScore + (weight × score); end docScore = docScore + sentenceScore; end return docScore; where score (si) is the score of the ith sentence si in d. The score of sentence si is computed by aggregating all sentiment scores score (wj) of all words wj ∈ si, multiplied with their respective weights weight (wj ): score (si) = w j ∈s i score (wj ) × weight (wj) ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Algorithm 3 :</head><label>3</label><figDesc>Simple positioner. input : A document d output: A weighted document d wordCount = getNumberOfwords(d); coef f icient = 1/wordCount; weight = 0; foreach s in d.Sentences do foreach w in s.W ords do w.setWeight(weight); weight = weight + coef f icient; end end return d;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 4 :</head><label>4</label><figDesc>SPADE positioner. input : A document d output: A weighted document d foreach s in d.Sentences do foreach w in s.W ords do rstElement = getRSTElement(w); weight = getWeight(rstElement); w.setWeight(weight); end end return d;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Experiment GUI.</figDesc><graphic coords="6,331.80,371.02,209.20,324.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Document test GUI.</figDesc><graphic coords="7,95.64,53.88,418.40,243.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 1: Word Sense Disambiguation.</head><label></label><figDesc>The word w to be disambiguated, its part-of-speech pos, and the sentence s that contains the word output: The sense i of w with the highest semantic similarity to the words in the context I = All words in s; // The context senses = retrieveSenses(w, pos);</figDesc><table><row><cell>// All unique senses of w</cell></row><row><cell>mostSimilarS i = 0;</cell></row><row><cell>// Most similar set of related synonyms</cell></row><row><cell>mostSimilarSynset = ∅;</cell></row><row><cell>// The synset with the best similarity to w</cell></row><row><cell>if |senses| &lt;= 1 then</cell></row><row><cell>return |senses|;</cell></row><row><cell>else</cell></row><row><cell>foreach i in senses do</cell></row><row><cell>containingSynsets =</cell></row><row><cell>retrieveSynsetsContainingSense(i, pos);</cell></row><row><cell>foreach synset in containingSynsets do</cell></row><row><cell>S i = ∅;</cell></row><row><cell>foreach synonym in synset.Synonyms do</cell></row><row><cell>S</cell></row></table><note><p>input : i = {S i , synonym}; end foreach relation in synset.Relations do foreach synonym in relation.Synonyms do</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 : Relation types handled by Pathos.</head><label>1</label><figDesc></figDesc><table><row><cell>Relation Description</cell></row><row><cell>Attribution Clauses containing reporting verbs or cog-</cell></row><row><cell>nitive predicates related to reported mes-</cell></row><row><cell>sages presented in nuclei.</cell></row><row><cell>Background Information helping a reader to sufficiently</cell></row><row><cell>comprehend matters presented in nuclei.</cell></row><row><cell>Cause Information on the effects of causes pre-</cell></row><row><cell>sented in nuclei.</cell></row><row><cell>Condition Hypothetical, future, or otherwise unreal-</cell></row><row><cell>ized situations, the realization of which in-</cell></row><row><cell>fluences the realization of nucleus matters.</cell></row><row><cell>Contrast Situations juxtaposed to situations in nu-</cell></row><row><cell>clei, where juxtaposed situations are con-</cell></row><row><cell>sidered as the same in many respects, yet</cell></row><row><cell>differing in a few respects, and compared</cell></row><row><cell>with respect to one or more differences.</cell></row><row><cell>Elaboration Rhetorical elements containing additional</cell></row><row><cell>detail about matters presented in nuclei.</cell></row><row><cell>Enablement Rhetorical elements containing informa-</cell></row><row><cell>tion increasing a reader's potential ability</cell></row><row><cell>of performing actions presented in nuclei.</cell></row><row><cell>Explanation Justifications or reasons for situations pre-</cell></row><row><cell>sented in nuclei.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 : Frequencies in training set of and optimized weights for relation types handled by Pathos.</head><label>2</label><figDesc></figDesc><table><row><cell cols="3">Relation Frequency Weight</cell></row><row><cell>Nucleus</cell><cell>600</cell><cell>0.771</cell></row><row><cell>Attribution</cell><cell>461</cell><cell>0.451</cell></row><row><cell>Background</cell><cell>362</cell><cell>0.017</cell></row><row><cell>Cause</cell><cell cols="2">89 -0.271</cell></row><row><cell>Condition</cell><cell>176</cell><cell>0.304</cell></row><row><cell>Contrast</cell><cell cols="2">243 -0.660</cell></row><row><cell>Elaboration</cell><cell>531</cell><cell>1.400</cell></row><row><cell>Enablement</cell><cell>266</cell><cell>0.956</cell></row><row><cell>Explanation</cell><cell cols="2">134 -0.099</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 : Experimental results for all positioners without offset.</head><label>3</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>Positive</cell><cell></cell><cell></cell><cell>Negative</cell><cell></cell><cell cols="2">Overall</cell></row><row><cell cols="3">Positioner Offset Precision Recall</cell><cell>F1</cell><cell cols="2">Precision Recall</cell><cell>F1</cell><cell cols="2">Accuracy Macro F1</cell></row><row><cell>Baseline 0.000</cell><cell>0.562</cell><cell>0.775</cell><cell>0.651</cell><cell>0.637</cell><cell>0.395</cell><cell>0.488</cell><cell>0.585</cell><cell>0.569</cell></row><row><cell>Simple 0.000</cell><cell>0.581</cell><cell>0.770</cell><cell>0.662</cell><cell>0.659</cell><cell cols="2">0.445 0.531</cell><cell>0.608</cell><cell>0.597</cell></row><row><cell>SPADE I (1, 0) 0.000</cell><cell>0.559</cell><cell cols="2">0.810 0.661</cell><cell>0.655</cell><cell>0.360</cell><cell>0.465</cell><cell>0.585</cell><cell>0.563</cell></row><row><cell>SPADE II (1.5, 0.5) 0.000</cell><cell>0.570</cell><cell>0.795</cell><cell>0.664</cell><cell>0.661</cell><cell>0.400</cell><cell>0.498</cell><cell>0.598</cell><cell>0.581</cell></row><row><cell>SPADE Extended 0.000</cell><cell>0.570</cell><cell cols="2">0.810 0.669</cell><cell>0.672</cell><cell>0.390</cell><cell>0.494</cell><cell>0.600</cell><cell>0.582</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 : Experimental results for all positioners with offset.</head><label>4</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>Positive</cell><cell></cell><cell></cell><cell>Negative</cell><cell></cell><cell cols="2">Overall</cell></row><row><cell cols="3">Positioner Offset Precision Recall</cell><cell>F1</cell><cell cols="2">Precision Recall</cell><cell>F1</cell><cell cols="2">Accuracy Macro F1</cell></row><row><cell>Baseline 2.016</cell><cell>0.687</cell><cell>0.690</cell><cell>0.688</cell><cell>0.688</cell><cell>0.685</cell><cell>0.687</cell><cell>0.688</cell><cell>0.687</cell></row><row><cell>Simple 1.290</cell><cell>0.647</cell><cell>0.660</cell><cell>0.654</cell><cell>0.653</cell><cell>0.640</cell><cell>0.647</cell><cell>0.650</cell><cell>0.650</cell></row><row><cell>SPADE I (1, 0) 1.560</cell><cell>0.668</cell><cell cols="2">0.695 0.681</cell><cell>0.682</cell><cell>0.655</cell><cell>0.668</cell><cell>0.675</cell><cell>0.675</cell></row><row><cell>SPADE II (1.5, 0.5) 2.796</cell><cell>0.683</cell><cell>0.690</cell><cell>0.687</cell><cell>0.687</cell><cell>0.680</cell><cell>0.683</cell><cell>0.685</cell><cell>0.685</cell></row><row><cell>SPADE Extended 2.562</cell><cell>0.732</cell><cell cols="2">0.695 0.713</cell><cell>0.710</cell><cell cols="2">0.745 0.727</cell><cell>0.720</cell><cell>0.720</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>To optimize the weights, the GA applies tournament selection, one-point crossover, and two mutation functions, i.e., changing the sign for a random weight in the chromosome and switching weights in the chromosome.</p><p>The fitness of a chromosome is computed in terms of its performance in classifying document polarity, which is assessed as follows. For both the positive documents and the negative documents in our data set, we first compute precision, recall, and the F1 measure. Precision is the proportion of the positively (negatively) classified documents which have an actual classification of positive (negative). Recall is the proportion of the actual positive (negative) documents which are also classified as such. The F1 measure is the harmonic mean of precision and recall, i.e.,</p><p>The performance of a chromosome on the full corpus can then be assessed by means of the macro-level F1 measure, which is the average of the F1 scores of the positive and negative documents.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fundamental Uncertainty and Stock Market Volatility</title>
		<author>
			<persName><forename type="first">I</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vrugt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Financial Economics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="1425" to="1440" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Model-Driven Approach of Ontological Components for On-line Semantic Web Information Retrieval</title>
		<author>
			<persName><forename type="first">H</forename><surname>Baazaoui Zghal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aufaure</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ben Mustapha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Web Engineering</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="309" to="336" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baccianella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th Conference on International Language Resources and Evaluation (LREC 2010)</title>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2200" to="2204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Morton</surname></persName>
		</author>
		<author>
			<persName><surname>Opennlp</surname></persName>
		</author>
		<ptr target="http://opennlp.sourceforge.net/" />
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Competing for the Public through the News Media</title>
		<author>
			<persName><forename type="first">D</forename><surname>Baron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Economics and Management Strategy</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="339" to="376" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automatically Adapting an NLP Core Engine to the Biology Domain</title>
		<author>
			<persName><forename type="first">E</forename><surname>Buyko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wermter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Poprat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Hahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Linking Literature, Information and Knowledge for Biology and the 9th Bio-Ontologies SIG Meeting (ISMB 2006)</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="65" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Building a Discourse-Tagged Corpus in the Framework of Rhetorical Structure Theory</title>
		<author>
			<persName><forename type="first">L</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Okurowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Current Directions in Discourse and Dialogue</title>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="85" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Novel Discourse Parser Based on Support Vector Machine Classification</title>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Prendinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="665" to="673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">SentiWordNet: A Publicly Available Lexical Resource for Opinion Mining</title>
		<author>
			<persName><forename type="first">A</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th Conference on Language Resources and Evaluation (LREC 2006)</title>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="417" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sentiment Lexicon Creation from Lexical Resources</title>
		<author>
			<persName><forename type="first">B</forename><surname>Heerschop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hogenboom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Frasincar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th International Conference on Business Information Systems (BIS 2011)</title>
		<title level="s">Lecture Notes in Business Information Processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="185" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Analyzing Sentiment in a Large Set of Web Data while Accounting for Negation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Heerschop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Van Iterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hogenboom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Frasincar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Kaymak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th Atlantic Web Intelligence Conference (AWIC 2011)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="195" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">HILDA: A Discourse Parser Using Support Vector Machine Classification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hernault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Prendinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ishizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dialogue and Discourse</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="33" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mining Economic Sentiment using Argumentation Structures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hogenboom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hogenboom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Kaymak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wouters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th International Workshop on Web Information Systems Modeling (WISM 2010) at 29th International Conference on Conceptual Modeling (ER 2010)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6413</biblScope>
			<biblScope unit="page" from="200" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Identifying Disgruntled Employee Systems Fraud Risk Through Text Mining: A Simple Solution for a Multi-Billion Dollar Problem</title>
		<author>
			<persName><forename type="first">C</forename><surname>Holton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Support Systems</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="853" to="846" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Twitter Power: Tweets as Electronic Word of Mouth</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sobel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2169" to="2188" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automatic Sense Disambiguation Using Machine Readable Dictionaries: How To Tell a Pine Cone from an Ice Cream Cone</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lesk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th Annual International Conference on Systems Documentation (SIGDOC 1986)</title>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="24" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Consumer Confidence and Consumer Spending</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ludvigson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Economic Perspectives</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="29" to="50" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Rhetorical Structure Theory: Toward a Functional Theory of Text Organization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Text</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="243" to="281" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The Language of Evaluation: Appraisal in English</title>
		<author>
			<persName><forename type="first">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>White</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Palgrave Macmillan</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Structural Semantic Interconnections: A Knowledge-Based Approach to Word Sense Disambiguation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Velardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="671" to="674" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A study of Information Retrieval weighting schemes for sentiment analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Paltoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Thelwall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">48th Annual Meeting of the Association for Computational Linguistics (ACL 2010)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1386" to="1395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A Sentimental Education: Sentiment Analysis using Subjectivity Summarization based on Minimum Cuts</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">42nd Annual Meeting of the Association for Computational Linguistics (ACL 2004)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="271" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Polarity dataset v2.0</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<ptr target="http://www.cs.cornell.edu/People/pabo/movie-review-data/" />
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Opinion Mining and Sentiment Analysis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="135" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Thumbs up? Sentiment Classification using Machine Learning Techniques</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vaithyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Induction of Decision Trees</title>
		<author>
			<persName><forename type="first">J</forename><surname>Quinlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="71" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Sentence Level Discourse Parsing using Syntactic and Lexical Information</title>
		<author>
			<persName><forename type="first">R</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technology and North American Association for Computational Linguistics Conference (HLT/NAACL 2003)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="149" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Lexicon-Based Methods for Sentiment Analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Taboada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brooke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tofiloski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Voll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="267" to="307" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Extracting Sentiment as a Function of Discourse Structure and Topicality</title>
		<author>
			<persName><forename type="first">M</forename><surname>Taboada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Voll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brooke</surname></persName>
		</author>
		<ptr target="http://www.cs.sfu.ca/research/publications/techreports/#2008" />
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">20</biblScope>
		</imprint>
		<respStmt>
			<orgName>Simon Fraser University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Thumbs Up or Thumbs Down?: Semantic Orientation Applied to Unsupervised Classification of Reviews</title>
		<author>
			<persName><forename type="first">P</forename><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">40th Annual Meeting on Association for Computational Linguistics (ACL 2002)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="417" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Using Appraisal Groups for Sentiment Analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Whitelaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Argamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th ACM International Conference on Information and Knowledge Management (CIKM 2005)</title>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="625" to="631" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
