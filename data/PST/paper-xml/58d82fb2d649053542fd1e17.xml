<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">06E9A0C293803E373C38ACAD2DC54FB2</idno>
					<idno type="DOI">10.1109/ACCESS.2016.2611583</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Deep Learning</term>
					<term>Dictionary Learning</term>
					<term>Feature Representation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Two popular representation learning paradigms are dictionary learning and deep learning. While dictionary learning focuses on learning "basis'' and "features'' by matrix factorization, deep learning focuses on extracting features via learning "weights'' or "filter'' in a greedy layer by layer fashion. This research focuses on combining the concepts of these two paradigms. In this paper, we propose deep dictionary learning and show how deeper architectures can be built using layers of dictionary learning. The proposed technique is compared with other deep learning approaches such as Stacked AutoEncoder, Deep Belief Network, and Convolutional Neural Network. Experiments on benchmark datasets show that the proposed technique achieves higher classification and clustering accuracies. On a real world problem of electrical appliance classification, we show that deep dictionary learning excels where others do not yield atpar performance. We postulate that the proposed formulation can pave the path for a new class of deep learning tools.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>N representation learning paradigm, dictionary learning has received a lot of interest. Researchers applied the concept of dictionary learning in vision <ref type="bibr" target="#b0">[1]</ref> and information retrieval <ref type="bibr" target="#b1">[2]</ref> in late 90's. In those early days, the term 'dictionary learning' had not been coined; researchers were using the term matrix factorization. The goal was to learn an empirical basis from the data. It required decomposing the data matrix to a basis/dictionary matrix and a feature matrix; hence the name 'matrix factorization'.</p><p>The current popularity of dictionary learning owes to K-SVD <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. K-SVD is an algorithm to decompose a matrix (training data) into a dense basis and sparse coefficients. However, the concept of such a dense-sparse decomposition predates K-SVD <ref type="bibr" target="#b4">[5]</ref>. Since the advent of K-SVD in 2006, there has been a plethora of work on this topic. Dictionary learning can be used both for unsupervised problems (mainly inverse problems in image processing) as well as for problems arising in supervised feature extraction. Furthermore, it (dictionary learning) has been used in virtually all inverse problems arising in image processing starting from simple</p><p>The authors are with IIIT Delhi, New Delhi, India 110020. (e-mail: snigdha1491@iiitd.ac.in, angshul@iiitd.ac.in, mayank@iiitd.ac.in, rsingh@iiitd.ac.in).</p><p>image <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref> and video <ref type="bibr" target="#b7">[8]</ref> denoising, image inpainting <ref type="bibr" target="#b8">[9]</ref>, to more complex problems such as inverse half-toning <ref type="bibr" target="#b9">[10]</ref> and even medical image reconstruction <ref type="bibr" target="#b10">[11]</ref>. Such inverse problems can also be solved using the Compressed Sensing (CS) <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">13]</ref> framework. However, it has been seen that learning the basis (via dictionary learning) yields better (customized) representation compared to the fixed basis employed by Compressed Sensing.</p><p>Mathematical transforms such as Discrete Cosine Transform (DCT), wavelet, curvelet, and Gabor have been widely used in image classification problems <ref type="bibr" target="#b14">[14]</ref><ref type="bibr" target="#b15">[15]</ref><ref type="bibr" target="#b16">[16]</ref>. Existing techniques have used these transforms as a sparsifying step followed by statistical feature extraction methods such as Principal Component Analysis (PCA) or Linear Discriminant Analysis (LDA) before providing the features to a classifier. Just as dictionary learning is replacing such fixed transforms in signal processing problems, it is also replacing them in feature extraction scenarios. Dictionary learning provides researchers the opportunity to design dictionaries to yield not only sparse representation (e.g., curvelet, wavelet, and DCT) but also discriminative information.</p><p>Initial techniques in discriminative dictionary learning have proposed naïve approaches, which learn specific dictionaries for each class <ref type="bibr" target="#b17">[17]</ref><ref type="bibr" target="#b18">[18]</ref><ref type="bibr" target="#b19">[19]</ref>. Later, discriminative penalties are introduced in dictionary learning framework to improve the classification performance. One such technique is to include softmax discriminative cost function <ref type="bibr" target="#b20">[20]</ref><ref type="bibr" target="#b21">[21]</ref><ref type="bibr" target="#b22">[22]</ref>; other discriminative penalties include Fisher discrimination criterion <ref type="bibr" target="#b23">[23]</ref>, linear predictive classification error <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b25">25]</ref> and hinge loss function <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b27">27]</ref>. In <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b29">29]</ref>, discrimination is introduced by forcing the learned features to map to corresponding class labels. Prior studies on dictionary learning (DL) are, generally, 'shallow' learning models just like a restricted Boltzmann machine (RBM) <ref type="bibr" target="#b30">[30]</ref> and an autoencoder (AE) <ref type="bibr" target="#b31">[31]</ref>, the two popular deep learning architectures. In DL, the cost function is Euclidean distance between the data and the representation given by the learned basis; for RBM it is Boltzmann energy; whereas for AE, the cost is the Euclidean reconstruction error between the data and the decoded representation/features.</p><p>Almost at the same time, when dictionary learning started gaining popularity, researchers in machine learning observed that better (more abstract and compact) representation could be achieved by going deeper in neural network architecture. Deep Belief Network (DBN) is formed by stacking multiple RBMs, one RBM after the other <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b33">33]</ref>. Similarly, stacked autoencoder (SAE) are created by one AE followed by the other <ref type="bibr" target="#b34">[34,</ref><ref type="bibr" target="#b35">35]</ref>.</p><p>Inspired from both the feature learning paradigms, in this Analogous to what the researchers in the deep learning community have been able to achieve by designing deeper architectures, it is our assertion that the proposed formulation of deep dictionary learning algorithms will inspire researchers to design more effective dictionary learning algorithms. One may think that multiple levels of dictionaries can be collapsed to a single level. However, such a collapsed shallow dictionary will not be the same as the proposed deep dictionary learning. This is because dictionary learning is a bi-linear problem 1 .</p><p>Had it been linear the architecture would have been collapsible; since it is not, the shallow and the deep architectures will not be equivalent. The remaining paper first discusses the literature review of dictionary learning, deep Boltzmann machine and auto-encoder in Section II. This is followed by mathematical formulation of the proposed deep dictionary learning in Section III and experimental evaluation in Section IV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. LITERATURE REVIEW</head><p>We will briefly review prior studies on dictionary learning, stacked autoencoders, and deep Boltzmann machines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dictionary Learning</head><p>Early studies in dictionary learning focused on learning a basis for representation. There were no constraints on the dictionary atoms or the loading coefficients. The method of optimal directions <ref type="bibr" target="#b36">[36]</ref> was used to learn the basis:</p><formula xml:id="formula_0">2 , min F D Z X DZ -<label>(1)</label></formula><p>Here, X is the training data, D is the dictionary to be learned and Z consists of the loading coefficients.</p><p>For problems in sparse representation, the objective is to learn a basis that can represent the samples in a sparse fashion, i.e. Z needs to be sparse. K-SVD <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> is the most well known technique for solving this problem. Fundamentally, it solves a problem of the form:</p><formula xml:id="formula_1">2 0 , min such that F D Z X DZ Z τ - ≤<label>(2)</label></formula><p>Here we have abused the notation slightly; the l 0 -norm is defined on the vectorized version of Z. K-SVD proceeds in two stages. In the first stage it learns the dictionary and in the next stage, it uses the learned dictionary to sparsely represent the data. Solving the l 0 -norm minimization problem is NP-hard <ref type="bibr" target="#b37">[37]</ref>. K-SVD employs the greedy (sub-optimal) orthogonal matching pursuit (OMP) <ref type="bibr" target="#b38">[38]</ref> to solve the l 0 -norm minimization problem approximately. In the dictionary learning stage, K-SVD proposes an efficient technique to estimate the atoms one at a time using a rank one update. The major disadvantage of K-SVD is that it is a relatively slow technique owing to its requirement of 1 Synthesis dictionary formulation X=DZ is bilinear; the variables are the dictionary D and feature Z. Bilinearity means that it is linear in each of the variables (D and Z) if the other one is constant (Z and D respectively).</p><p>For multi-level dictionary (say 2) the formulation is X=D1D2Z. This is a trilinear formulation and is a different problem altogether. Solving the trilinear 2-level dictionary learning will not yield the same features as that of a collapsed bilinear (D=D1D2) dictionary learning problem.</p><p>computing the SVD (singular value decomposition) in every iteration. There are other efficient optimization based approaches for dictionary learning <ref type="bibr" target="#b39">[39,</ref><ref type="bibr" target="#b40">40]</ref> -these learn the full dictionary instead of updating the atoms separately.</p><p>The dictionary learning formulation in equation ( <ref type="formula" target="#formula_1">2</ref>) is unsupervised. As mentioned before, there is a large volume of work on supervised dictionary learning problems. The first work on Sparse Representation based Classification (SRC) <ref type="bibr" target="#b41">[41]</ref> is not much of a "dictionary learning technique" but a simple dictionary design problem where all the training samples are concatenated in a large dictionary. Later, several improvements to the basic SRC formulation are proposed in <ref type="bibr" target="#b42">[42]</ref><ref type="bibr" target="#b43">[43]</ref><ref type="bibr" target="#b44">[44]</ref>. In <ref type="bibr" target="#b42">[42,</ref><ref type="bibr" target="#b43">43]</ref> supervision is added in the form of groupsparsity. In <ref type="bibr" target="#b44">[44]</ref> a non-linear extension to the SRC is proposed. Later works handled the non-linear extension in a smarter fashion using the kernel trick <ref type="bibr" target="#b45">[45]</ref><ref type="bibr" target="#b46">[46]</ref><ref type="bibr" target="#b47">[47]</ref>.</p><p>The SRC does not exactly fit into the dictionary learning paradigm. However, <ref type="bibr" target="#b48">[48]</ref> proposed a simple extension of SRC -instead of using raw training samples as the basis, they learned a separate basis for each class and used these dictionaries for classification. This approach is naïve; there is no guarantee that dictionaries from different classes would not be similar. Ramirez et al. have addressed this issue by applying an additional incoherency penalty on the dictionaries <ref type="bibr" target="#b49">[49]</ref>. This penalty assures that the dictionaries from different classes look different from each other. The formulation is given as:</p><formula xml:id="formula_2">{ } 2 2 1 , 1 min i i C T i i i i j F F D Z i i j X DZ Z D D λ η = ≠ - + + ∑ ∑<label>(3)</label></formula><p>Unfortunately, this formulation does not improve the overall results too much. It learns dictionaries that look different from each other but does not produce features that are distinctive; i.e. the feature generated for the test sample from dictionaries of all classes looked more or less the same. This issue was rectified in <ref type="bibr" target="#b50">[50]</ref>. The label consistent KSVD is one of the recent techniques for learning discriminative sparse representation. It is simple to understand and implement; it showed good results for face recognition <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b29">29]</ref>. The first technique is termed as Discriminative K-SVD <ref type="bibr" target="#b28">[28]</ref> or LC-KSVD1 <ref type="bibr" target="#b29">[29]</ref>; it proposes an optimization problem of the following form:</p><formula xml:id="formula_3">2 2 2 1 2 3 1 , , min + F F F D Z A X DZ D Z Q AZ λ λ λ - + + -<label>(4)</label></formula><p>Here, Q is the label of the training samples; it is a canonical basis with a one for the correct class and zeroes elsewhere. A is a parameter of the linear classifier.</p><p>In <ref type="bibr" target="#b29">[29]</ref>, a second formulation is proposed that adds another term to penalize the classification error. The LC-KSVD2 formulation is as follows:</p><formula xml:id="formula_4">2 2 1 2 1 , , ,W 2 2 3 4 min + F F D Z A F F X DZ D Z Q AZ H WZ λ λ λ λ - + + - + -<label>(5)</label></formula><p>H is a 'discriminative' sparse code corresponding to an input signal sample if the nonzero values of H i occur at those indices where the training sample X i and the dictionary item d k share the same label. This formulation imposes labels not only on the sparse coefficient vectors Z i 's but also on the dictionary atoms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Deep Boltzmann Machine</head><p>Restricted Boltzmann Machines are undirected models that use stochastic hidden units to model the distribution over the stochastic visible units. The hidden layer is symmetrically connected with the visible unit and the architecture is "restricted" as there are no connections between units of the same layer. Traditionally, RBMs are used to model the distribution of the input data p(x).</p><p>The schematic diagram of RBM is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. The objective is to learn the network weights (W) and the representation (H). This is achieved by optimizing the Boltzmann cost function given by:</p><formula xml:id="formula_5">( , ) ( , ) E W H p W H e - =<label>(6)</label></formula><p>where,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>( , ) -T E W H H WX =</head><p>including the bias terms.</p><p>Assuming independence, the conditional distributions are given by</p><formula xml:id="formula_6">( | ) ( | ) p X H p x h = ∏ (7) ( | ) ( | ) p H X p h x = ∏<label>(8)</label></formula><p>Assuming a binary input variable, the probability that a node will be active can be given as follows,</p><formula xml:id="formula_7">( 1| ) ( ) T p x h sigm W h = = ( 1| ) ( ) p h</formula><p>x sigm Wx = = Computing the exact gradient of this loss function is almost intractable. However, there is a stochastic approximation to approximate the gradient termed as contrastive divergence gradient. A sequence of Gibbs sampling based reconstruction, produces an approximation of the expectation of joint energy distribution, using which the gradient can be computed. Usually, RBM is unsupervised, but there are studies where discriminative RBMs are trained by utilizing the class labels <ref type="bibr" target="#b51">[51]</ref>. There are also RBMs, which are sparse in nature <ref type="bibr" target="#b52">[52]</ref>. The sparsity is controlled by firing the hidden units only if they are over some threshold. Supervision can also be achieved using sparse RBMs by extending it to have similar sparsity structure within the group / class <ref type="bibr" target="#b53">[53]</ref>.</p><p>Deep Boltzmann Machines (DBM) <ref type="bibr" target="#b54">[54]</ref> is an extension of RBM created by stacking multiple hidden layers on top of each other (Fig. <ref type="figure" target="#fig_1">2</ref>). DBM is an undirected learning model and thus it is different from the other stacked network architectures in which each layer receives feedback from both the top-down and bottom-up layer signals. This feedback mechanism helps in managing uncertainty in learning models. While the traditional RBM can model logistic units, a Gaussian-Bernoulli RBM <ref type="bibr" target="#b55">[55]</ref> can be used as well with real-valued (between 0 and 1) visible units. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Stacked Autoencoder</head><p>An autoencoder consists (as seen in Fig. <ref type="figure">3</ref>) of two partsthe encoder maps the input to a latent representation and the decoder maps the latent representation back to the data. For a given input vector (including the bias term) x, the latent space is expressed as:</p><formula xml:id="formula_8">h Wx = (9)</formula><p>Here, the rows of W are the link weights from all the input nodes to the corresponding latent node. Usually, a non-linear activation function is used at the output of the hidden nodes leading to:</p><formula xml:id="formula_9">Fig. 3. Single Layer Autoencoder ( ) h Wx φ =<label>(10)</label></formula><p>Although the sigmoid function is popularly used, other nonlinear activation functions such as tanh can also be used. Rectifier units and large neural networks employ linear activation; owing to this linearity, the training process is considerably faster. The decoder reverse maps the latent variables to the data space.</p><p>' ( )</p><formula xml:id="formula_10">x W Wx φ =<label>(11)</label></formula><p>Since the data space is assumed to be the space of real numbers, there is no sigmoid function here. During training, the problem is to learn the encoding and decoding weights -W and W'. These are learned by minimizing the Euclidean cost:</p><formula xml:id="formula_11">2 , ' arg min ' ( ) F W W X W WX φ -<label>(12)</label></formula><p>Here</p><formula xml:id="formula_12">1 [ |...| ] N X x x =</formula><p>consists of all the training sampled stacked as columns where total number of training samples are N. The problem in Equation ( <ref type="formula" target="#formula_11">12</ref>) is clearly non-convex, but is</p><formula xml:id="formula_13">W X H W 2 W 1 X H 1 H 2 W W'</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input Layer Output Layer</head><p>Hidden Layer</p><p>smooth and hence can be solved by gradient descent techniques; the activation function needs to be smooth and continuously differentiable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 4. Stacked Autoencoder</head><p>There are several extensions to the basic autoencoder architecture. Stacked autoencoders have multiple hidden layers -one inside the other (see Fig. <ref type="figure">4</ref>). The corresponding cost function is expressed as follows:</p><formula xml:id="formula_14">arg min W 1 ...W L ,W ' 1 ...W ' L X -g ! f ( X ) F 2<label>(13) where, ( ) ( ) 1 2</label></formula><p>' '... ' ( )</p><formula xml:id="formula_15">L g W W W f X φ = and f = φ W L φ W L-1 ...φ(W 1 X ) ( ) ( )</formula><p>Solving the complete problem ( <ref type="formula" target="#formula_14">13</ref>) is computationally challenging. Also learning so many parameters (network weights) lead to over-fitting. To address both these issues, the weights are usually learned in a greedy layer-by-layer fashion <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b34">34]</ref>.</p><p>Stacked denoising autoencoder <ref type="bibr" target="#b35">[35]</ref> is a variant of the basic autoencoder where the input consists of noisy samples and the output consists of clean samples. Here the encoder and decoder are learned to denoise noisy input samples. Another variation for the basic autoencoder is to regularize it, i.e.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">( ) arg min ( ) ( , )</head><formula xml:id="formula_16">F W s X g f X R W X - + o<label>(14)</label></formula><p>The regularization can be a sparsity promoting term <ref type="bibr" target="#b56">[56,</ref><ref type="bibr" target="#b57">57]</ref> or a weight decay term (Frobenius norm of the Jacobian) as used in the contractive autoencoder <ref type="bibr" target="#b58">[58]</ref>. The regularization term is usually chosen so that they are differentiable and hence minimizable using gradient descent techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. DEEP DICTIONARY LEARNING</head><p>In this section, we describe the main contribution of this research. A single/shallow level of dictionary learning yields a latent representation of data and the dictionary atoms. Here, we propose to learn the latent representation of data by learning multi-level dictionaries. The idea of learning deeper levels of dictionaries stems from the success of deep learning. In this section, for ease of understanding, we first explain the concept with two-layer deep dictionary learning and then extend it to a multi-level dictionary.</p><p>The schematic diagram for dictionary learning is shown in Fig. <ref type="figure" target="#fig_2">5</ref>. Let X be the data, D 1 be the dictionary and Z be the feature/representation of X in D 1 . Dictionary learning follows a synthesis framework <ref type="bibr" target="#b15">(15)</ref>, i.e. the dictionary is learnt such that the features synthesize the data along with the dictionary. There is a dictionary learning approach termed as analysis K-SVD, but it cannot be used for feature extraction. Analysis K-SVD can only produce a 'clean' version of the data and hence, is only suitable for inverse problems.</p><p>We propose to extend the shallow (Fig. <ref type="figure" target="#fig_2">5</ref>) dictionary learning into multiple layers -leading to deep dictionary learning (Fig. <ref type="figure" target="#fig_3">6</ref>). Mathematically, the representation at the second layer can be written as: It must be noted that learning two-levels of dictionaries along with the coefficients ( <ref type="formula" target="#formula_17">16</ref>) is not the same as learning a single (collapsed) dictionary and its corresponding features. The problem (15) (single level) is a bi-linear problem and ( <ref type="formula" target="#formula_17">16</ref>) is a tri-linear problem; they are not the same. Hence one cannot expect to get the same features from single level dictionary learning and a collapsed two level dictionary learning.</p><formula xml:id="formula_17">1 2 2 X D D Z =<label>(16)</label></formula><p>The challenges of learning multiple levels of dictionaries in one go are the following: 1) Recent studies have proven convergence guarantees for single level dictionary learning <ref type="bibr" target="#b59">[59]</ref><ref type="bibr" target="#b60">[60]</ref><ref type="bibr" target="#b61">[61]</ref><ref type="bibr" target="#b62">[62]</ref><ref type="bibr" target="#b63">[63]</ref>. These proofs would be very hard to replicate for multiple layers. 2) Moreover, the number of parameters required to be solved increases when multiple layers of dictionaries are learned simultaneously. With limited training data, this could lead to over-fitting. Here we propose to learn the dictionaries in a greedy manner, which is in sync with other deep learning techniques <ref type="bibr" target="#b32">[32]</ref><ref type="bibr" target="#b33">[33]</ref><ref type="bibr" target="#b34">[34]</ref>. Moreover, layer-wise learning will guarantee the convergence at each layer. The diagram illustrating layer-wise learning is shown in Fig. <ref type="figure" target="#fig_4">7</ref>. Extending this idea, a multi-level dictionary learning problem with non-linear activation ( ϕ ) can be expressed as,</p><formula xml:id="formula_18">Input Layer Hidden Layer 1 Output Layer Hidden Layer L ……… D1 X Z D 2 D 1 X Z 2</formula><formula xml:id="formula_19">X = D 1 ϕ D 2 ϕ(...ϕ(D N Z )) ( )<label>(17)</label></formula><p>Ideally, we would have to solve the following problem.</p><p>( )</p><formula xml:id="formula_20">1 2 1 2 1 ,... , min (... ( )) N N F D D Z X D D D Z Z ϕ ϕ ϕ µ - +<label>(18)</label></formula><p>However, such a problem is highly non-convex and requires solving a huge number of parameters. With the limited amount of data, it will lead to over-fitting. To address these issues, as mentioned before, we propose a greedy approach where we learn one layer at a time -similar to pre-training in the deep learning paradigm. With the substitution ( ) <ref type="formula" target="#formula_19">17</ref>) can be written as</p><formula xml:id="formula_21">1 2 (... ( )) N Z D D Z ϕ ϕ ϕ = , Equation (</formula><formula xml:id="formula_22">1 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X DZ =</head><p>such that it can be solved as single layer dictionary learning. The representation Z 1 is not sparse. Hence it can be solved using alternating minimization -</p><formula xml:id="formula_23">1 1 2 1 1 , min F D Z X D Z -<label>(19)</label></formula><p>Optimality of solving <ref type="bibr" target="#b19">(19)</ref> by alternating minimization has been proven in <ref type="bibr" target="#b56">[56]</ref>. Therefore we follow the same approach. The dictionary D and the basis Z is learned by:</p><formula xml:id="formula_24">2 1 1 1 min F Z Z X DZ ← - (20a) 2 1 1 1 min F D D X DZ ← -<label>(20b)</label></formula><p>This is the method of optimal directions <ref type="bibr" target="#b36">[36]</ref> and both (20a) and (20b) are simple least square problems having closed form solutions.</p><p>For the second layer, we substitute 2 (... ( ))</p><formula xml:id="formula_25">N Z DZ ϕ ϕ = , which leads to 1 2 2 ( ) Z DZ ϕ = , or alternately, 1 1 2 2 ( ) Z D Z ϕ - =</formula><p>; this too is a single layer dictionary learning. Since the representation is dense, it can be solved using</p><formula xml:id="formula_26">2 2 2 1 1 2 2 , min ( ) F D Z Z D Z ϕ - -<label>(21)</label></formula><p>This too can be solved by alternating minimization as in the case of first layer <ref type="bibr" target="#b20">(20)</ref>. Continuing in this fashion till the penultimate layer, in the final layer we have 1 ( )</p><formula xml:id="formula_27">N N Z D Z ϕ -= or 1 1 ( ) N N Z D Z ϕ - -=</formula><p>. In the last level, the coefficient Z can be sparse. For learning sparse features, one needs to regularize by applying l 1 -norm on the features. This is given by:</p><formula xml:id="formula_28">2 1 1 1 , min ( ) N N N F D Z Z D Z Z ϕ λ - -- + (<label>22</label></formula><formula xml:id="formula_29">)</formula><p>This too is solved using alternating minimization.</p><formula xml:id="formula_30">2 1 1 1 2 min ( ) N N Z Z Z DZ Z ϕ λ - - ← - + (23a) 2 1 1 min ( ) N N N N F D D Z DZ ϕ - - ← -<label>(23b)</label></formula><p>As before, (23b) is a least square problem having a closed form solution. Although not analytic, the solution to (23a) can be solved using the Iterative Soft Thresholding Algorithm (ISTA) <ref type="bibr" target="#b64">[64]</ref>. The ISTA solution for (23a) is given by: ( )</p><formula xml:id="formula_31">2 1 1 2 1 1</formula><p>Initialize: min ( )</p><formula xml:id="formula_32">Iterate till convergence 1 ( ) ( )max 0, 2 N N Z T N N N Z Z DZ B Z D Z D Z Z signum B B ϕ ϕ α λ α - - - - ← - = + - ⎛ ⎞ ← - ⎜ ⎟ ⎝</formula><p>⎠ It is important to note that learning multiple dictionaries cannot be collapsed into a single one even if the activation function is linear. This is because dictionary learning is bilinear. For example, if the dimensionality of the sample is m and the first dictionary is of size m x n 1 and the second one is n 1 x n 2 , it is not possible to learn a single dictionary of size m x n 2 and expect the same results as a two-stage dictionary.</p><p>In general, for non-linear activation functions, it is not possible to collapse the multiple levels of dictionaries into a single level for testing. However, for the linear activation function, the multiple levels of dictionaries can be collapsed into a single stage by matrix multiplication of the different dictionaries and the sparse code / features computed from the thus formed single level dictionary by standard l 1minimization.</p><p>Training Algorithm (for any activation function ϕ ) Initialize: , 1...N i D i = For first level; repeat until convergence -</p><formula xml:id="formula_33">2 1 1 1 min F Z Z X DZ ← - 2 1 1 1 min F D D X DZ ← -</formula><p>From 2 nd to penultimate level; repeat until convergence -</p><formula xml:id="formula_34">Z l ← min Z l ϕ -1 (Z l-1 ) -D l Z l F 2 2 1 1 min ( ) l l l ll F D D Z D Z ϕ - - ← -</formula><p>For final level; repeat until convergence -</p><formula xml:id="formula_35">2 1 1 1 min ( ) N N N Nl N F Z Z Z DZ Z ϕ λ - - ← - + 2 1 1 min ( ) N N N NN F D D Z DZ ϕ - - ← -</formula><p>Testing Algorithm (for linear activation function) Collapse multiple levels of dictionaries into a single one </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Connection with Existing Algorithms</head><p>In this section, we compare and contrast the proposed deep dictionary approach with some popular deep learning algorithms, namely RBM and Autoencoder, and hierarchical dictionary learning approaches. From Figures <ref type="figure" target="#fig_0">1</ref> and<ref type="figure" target="#fig_2">5</ref>, it is evident that in both RBM and dictionary learning, the task is to learn the network weights/atoms and the representation given the data. They differ from each other in the cost functions used. For RBM it is the Boltzmann function whereas for dictionary learning, instead of maximizing similarity, we minimize the Euclidean distance between the data (X) and the synthesis (DZ). Further, RBM has a stochastic formulation whereas dictionary learning is deterministic. Moreover, RBM typically uses binary or real values as input. On the other hand, deep dictionary learning can work both on real and complex inputs.</p><p>Similar to RBM, a comparison of the proposed deep dictionary learning with autoencoders can be performed. The synthesis dictionary learning model is expressed as: X=D S Z where X is the data, D S is the learned synthesis dictionary and Z are the sparse coefficients. Usually one promotes sparsity in the features and the learning requires minimizing the following,</p><formula xml:id="formula_36">2 F S X D Z Z λ - +<label>(25)</label></formula><p>This is the well-known synthesis prior formulation where the task is to find a dictionary that can synthesize / generate signals from sparse features. There is an alternate co-sparse analysis prior dictionary learning paradigm <ref type="bibr" target="#b65">[65]</ref> where the goal is to learn a dictionary such that when it is applied to the data the resulting coefficient is sparse. The model is represented as</p><formula xml:id="formula_37">Â D X Z = .</formula><p>The corresponding learning problem is framed by minimizing:</p><formula xml:id="formula_38">2 1 ˆÂ F X X D X λ - +<label>(26)</label></formula><p>If we combine analysis and synthesis, using ˆ, A S X D Z D X Z = = and impute it in (25) we get:</p><formula xml:id="formula_39">2 1 ˆŜ F A A X D D X D X λ - +<label>(27)</label></formula><p>If we drop the sparsity term, it becomes</p><formula xml:id="formula_40">2 Â S F X D D X -<label>(28)</label></formula><p>This is similar to the expression of a sparse denoising autoencoder <ref type="bibr" target="#b54">[54]</ref> with linear activation at the hidden layer. Further, we can express autoencoder in the terminology of dictionary learning -autoencoder is a model that learn the analysis and the synthesis dictionaries. To the best of our knowledge, this is the first work that shows the architectural similarity between autoencoders and dictionary learning.</p><p>We also briefly discuss the differences with recently proposed dictionary learning algorithms. First, we would like to emphasize that the proposed approach is not related to hierarchical or structured dictionary learning techniques <ref type="bibr" target="#b66">[66,</ref><ref type="bibr" target="#b67">67]</ref>. In these studies, unlike the proposed approach, the goal is to learn dictionary atoms that are related to each other. Generally, these studies follow shallow learning techniques (single level) and the relationships are between atoms of dictionary within the same level.</p><p>We next discuss the work on "Double Sparsity" <ref type="bibr" target="#b68">[68]</ref> where the authors decompose the dictionary into a product of a fixed basis (e.g. wavelet, and DCT) and a sparse set of coefficients; instead of learning the full dictionary (as is done in standard dictionary learning), they learn a dictionary that can be represented as a linear combination of fixed basis. The learning mechanism is formulated as follows:</p><formula xml:id="formula_41">2 0 0 , min s.t. and F T Z X TZ T s Z s -Φ ≤ ≤<label>(29)</label></formula><p>In this formulation, T D Φ = ; i.e. instead of learning the full dictionary, the authors learn the coefficients required to synthesize the dictionary D from a fixed basis Φ. The advantage of this approach is that the learned dictionary has fast forward and ad-joint operators (since it is synthesized from an efficient operator) and hence is useful for solving large-scale inverse problems. Clearly, the proposed algorithm is different from Equation (29) <ref type="bibr" target="#b68">[68]</ref>. We learn the full dictionary in each level and continue the process for multiple levels with a goal to learn abstract representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL EVALUATION</head><p>The effectiveness of the proposed deep dictionary learning is evaluated on multiple benchmark databases from different areas such as images, text, and signals. The results are compared with related state-of-the-art algorithms. In this work, we use a linear activation function for all the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>We have evaluated the performance on several benchmarks datasets. The first one is the MNIST dataset that consists of 28x28 images of handwritten digits ranging from 0 to 9. The dataset has 60,000 images for training and 10,000 images for testing. It should be noted that we have not performed any preprocessing on this dataset.</p><p>Related to MNIST database, MNIST variations datasets are also used. These are more challenging databases, primarily due to fewer training samples (10,000) and a larger number of test samples <ref type="bibr" target="#b50">(50,</ref><ref type="bibr">000)</ref>. The validation set of 2000 samples are not used in this work since our method does not require tuning and SAE as well as DBN are already optimized for MNIST.</p><p>Here is the listing of these databases.</p><p>1. basic (smaller subset of MNIST) 2. basic-rot (smaller subset with random rotations) 3. bg-rand (smaller subset with uniformly distributed noise in background) 4. bg-img (smaller subset with random image background) 5. bg-img-rot (smaller subset with random image background plus rotation) These datasets are primarily created to empirically benchmark deep learning algorithms <ref type="bibr" target="#b69">[69]</ref>. Samples for each of the datasets are shown in Fig. <ref type="figure" target="#fig_5">8</ref>. We have used 5000 most frequent words for the binary input features and follow the same protocol as outlined in <ref type="bibr" target="#b51">[51]</ref>.</p><p>The third dataset is the GTZAN music genre dataset <ref type="bibr" target="#b70">[71]</ref>. The dataset contains 10,000 three-second audio clips, equally distributed among ten musical genres: blues, classical, country, disco, hip-hop, pop, jazz, metal, reggae, and rock. 592 Mel-Phon Coefficient (MPC) features represent each example in the set. These are a simplified formulation of the Mel-frequency Cepstral Coefficients (MFCCs) that have been shown to yield better classification performance in literature. Since there is no predefined standard split and fewer examples, we have used 10-fold cross validation (procedure mentioned in <ref type="bibr" target="#b35">[35]</ref>), where each fold consisted of 9000 (we do not require validation examples unlike <ref type="bibr" target="#b35">[35]</ref>) training examples and 1000 test examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Effect of Layers on Dictionary Learning</head><p>We first analyze the results of the proposed deep dictionary learning and the effect of increasing the number of layers. The objective of this experiment is to show that the representations learned from a single level of dictionary and multi-level dictionary are different and multi-level dictionaries yield better classification performance. With just one level of dictionary, i.e., a shallow dictionary, we learn 50 atoms for MNIST, 625 atoms for the 20-newsgroup, and 148 for GTZAN; these correspond to the last level of dictionary atoms. For deep dictionary, we performed experiments with up to three levels of dictionary. For the MNIST database and its variations, the number of basis in the multi-level dictionaries is: 300-150-50. For the 20-newsgroup and the GTZAN (music genre classification) datasets, the number of atoms in every layer is halved from that of the previous layer. The classification is performed with a simple K-Nearest Neighbor (K = 1). The classification accuracies are reported in Table <ref type="table">1</ref>, Column 2 reports the results for shallow dictionary and columns 3-5 report the results with different layers of deep dictionary. The results show that for all the databases, deep dictionary (3-layer) learning offers improvements over shallow dictionary learning. The improvement in accuracy is possibly owing to more abstract representation learned from these layers. Depending on the complexity of the dataset, the difference in performance varies from 0.40% to more than 9%. Fig. <ref type="figure" target="#fig_6">9</ref> illustrates first layer dictionary on MNIST database.</p><p>Generally, the dictionary atoms are initialized by randomly choosing samples from the training set; however, this leads to variability in results. In this research, we propose a deterministic initialization based on the QR decomposition of the training data matrix. Orthogonal vectors from Q (in order) are used to initialize the dictionary.</p><p>We next show that the multi-level dictionaries cannot be collapsed into a single one and should not be expected to yield the same results. The difference between the performance of multi-level dictionary learning and single level dictionary learning is evident in Table <ref type="table" target="#tab_2">I</ref>; see columns 2 and 5. If the learning is linear, it is possible to collapse multiple dictionaries into one; but dictionary learning is inherently nonlinear. Hence it is not feasible to learn a single layer of dictionary in place of multiple levels and expect the same output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Comparison with Deep Learning Approaches</head><p>Since the proposed deep architecture is inspired by existing deep learning approaches, we have compared our results with a stacked autoencoder (SAE) and deep belief network (DBN). The implementation for these have been obtained from [72] and [73] respectively. Similar to deep dictionary learning, SAE and DBN also have a three-layer architecture. The number of nodes is halved in every subsequent layer and comparison is performed using K-Nearest Neighbor (KNN) and Support Vector Machine (SVM). To ensure a fair comparison of representation techniques, we have kept the classifier fixed for these experiments. The results are shown in Tables II and III, respectively.  We observe that apart from one case each in Tables II and III, the proposed algorithm yields better results than DBN and SAE. For KNN, the results of deep dictionary learning are slightly better; however, with SVM classifier, deep dictionary yields considerably better results.</p><p>We have also compared the performance of the proposed algorithm with dictionary learning techniques such as D-KSVD <ref type="bibr" target="#b28">[28]</ref>, LC-KSVD <ref type="bibr" target="#b29">[29]</ref>, and supervised dictionary learning <ref type="bibr" target="#b21">[21]</ref>. These are individually fine-tuned to yield the best possible results. The comparison is also performed with stacked denoising autoencoder (SDAE), deep belief network (DBN) fine-tuned with soft-max classifier and convolutional neural network (CNN). The results on DBN and SDAE are from <ref type="bibr" target="#b35">[35]</ref>; the results from CNN are from <ref type="bibr" target="#b71">[74]</ref> -which is a baseline technique for CNN architectures. The results are summarized in Table <ref type="table" target="#tab_5">IV</ref>.</p><p>It can be observed that the proposed deep dictionary learning techniques almost always yields better results than shallow dictionary learning (supervised DL, LC-KSVD and D-KSVD); only for two instances i.e., the simple MNIST dataset and bg-img-rot, the shallow learning techniques yield better results. In other cases, the proposed algorithm is in the top two best algorithms and achieves better accuracy than highly tuned models such as DBN, SDAE, and CNN. CNN cannot be run on the 20-newsgroup dataset since it does not have local correlation and cannot be represented as a linear time invariant system -an aspect required for the convolution operation to hold.  We next compare the proposed algorithm with other deep learning approaches in terms of computational speed (train feature generation + test feature generation time). All the algorithms are run until convergence on a machine with Intel (R) Core(TM) i5 running at 3 GHz; 8 GB RAM, Windows 10 (64 bit) running Matlab 2014a. The run times for all the smaller MNIST variations are approximately the same. Therefore, we only report results for the larger MNIST dataset (60K) and the basic (10K) dataset. We do not include the training and testing time for classification here; since they will be almost the same for all the techniques as long as the dimensionality of the features remains the same. Further, Table <ref type="table" target="#tab_6">V</ref> shows that for training the proposed algorithm is around two orders of magnitude faster than deep belief network and three orders of magnitude faster than stacked autoencoder. However, the testing times (Table <ref type="table" target="#tab_7">VI</ref>) for the proposed algorithm is somewhat slower -since we need to solve an optimization problem for generating the test features whereas, the others simply need a few matrix-vector products.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Electrical Appliance Classification</head><p>The previous sections demonstrate results on benchmarking datasets. In this section, we evaluate the effectiveness of deep dictionary learning for solving a real-world problem. Gupta et al. proposed the problem of classifying electrical appliances from their energy electro-magnetic interference (EMI) signatures <ref type="bibr" target="#b72">[75]</ref>. They showed results on appliance classification from differential mode (DM) EMI signatures; but DM EMI has an inherent shortcoming. The power signal and its harmonics interfere with the DM EMI, hence analysis based on such signatures is not reliable <ref type="bibr" target="#b73">[76]</ref>. In a technical report <ref type="bibr" target="#b74">[77]</ref>, it has been shown that, using rudimentary heuristics one can achieve decent results from CM EMI based appliance classification. The details regarding the development of the CM EMI sensor, data acquisition and details are given in <ref type="bibr" target="#b74">[77]</ref>.</p><p>Fig. <ref type="figure" target="#fig_0">10</ref>. Block view of EMI sensor Fig. <ref type="figure" target="#fig_0">10</ref> shows the setup for data collection. The data is collected for five devices -CFL, CPU, LCD, Laptop Charger and Background Noise (when nothing is in use). There are five instances of every appliance. 1500 traces are collected for each instance of each appliance. Each trace is of 1 millisecond duration and constitutes a vector of length 16,384. The training set consists of samples from 1 instance for each appliance while the remaining 4 instances of each appliance constitutes the test set. Thus, for every problem, the training data for each class has 1500 traces and the test data has 4x1500=6000 traces.</p><p>The experimental protocol has been defined in <ref type="bibr" target="#b74">[77]</ref>. For testing, all 1500 traces should be considered as a single signature; the task is to identify the appliance from this signature. Therefore the predicted class labels of the 1500 samples should be fused via majority voting to a single appliance. Cepstrum features <ref type="bibr" target="#b75">[78]</ref> are used as the feature set for classification; some examples of cepstrum features are shown in Fig. <ref type="figure" target="#fig_0">11</ref>. It can be seen how the cepstrum features for the same appliance look similar and those from different appliances look different. and features extracted using Conditional Likelihood Maximization (CLM) <ref type="bibr" target="#b76">[79]</ref> followed by SVM classification. As a benchmark, the results are also compared using LC-KSVD and the results are shown for 5-fold cross validation. For the proposed method, two levels of dictionaries are learned, in the first level the number of atoms is 500 and in the second level 100. The first level generates dense features whereas the second level generates sparse features.</p><p>Table <ref type="table" target="#tab_8">VII</ref> shows that the proposed algorithm significantly outperforms all three approaches. ElectriSense yields around 30% correct classification accuracy and CLM yields around 60-67% accuracy, whereas the proposed deep dictionary learning yields more than 85% for all the folds. This also suggests that the proposed algorithm can be extended to other interesting applications where deep learning techniques may not provide an acceptable level of performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Clustering</head><p>Most deep learning tools are applied for classification problems. A recent study <ref type="bibr" target="#b77">[80]</ref> proposed GraphEncoder, which uses a stacked sparse autoencoder feature learning followed by K-means clustering. In this research, we compare the results of the proposed algorithm with GraphEncoder on a subset of the datasets (we chose only those datasets with ground-truth) used by them and follow the same experimental protocol. We extract features using deep dictionary learning and use K-means clustering on the learned features. The databases selected for this experiment are described below.</p><p>Wine [81]: This is a dataset from the UCI Machine Learning consisting of 178 instances with 13 attributes. Every instance corresponds to a certain wine with its chemical analysis information as the attributes. All instances are labeled with three wine categories. We built a cosine similarity graph using these instances and used the labels as the ground truth. 20-newsgroup <ref type="bibr" target="#b69">[69]</ref>: The dataset has already been discussed before. Every document as a vector of tf-idf (term frequency -inverse document frequency) scores of each word; the cosine similarity graph was built based on the tfidf scores. To demonstrate the robustness of our algorithms with different targeting cluster numbers, we constructed three graphs built from 3, 6, and 9 different newsgroups respectively. The newsgroup names in each graph are listed as the following, where the abbreviation NG used in graph names is short for Newsgroup. For each chosen group, 200 documents are randomly selected and thus the three graphs contain 600, 1200, and 1800 nodes respectively. The document labels are used as the ground truth.</p><p>Table <ref type="table" target="#tab_8">VIII</ref> shows the network architecture proposed in <ref type="bibr" target="#b77">[80]</ref>. We use the same number of basis in our deep dictionary learning framework and the results are summarized in Table <ref type="table" target="#tab_2">IX</ref>. Since the previous work (GraphEncoder) has already shown that the superiority of their technique over spectral clustering and K-means, we compare the results with the GraphEncoder formulation only. Along with that, we also use a DBN framework for feature extraction followed by K-means clustering. The DBN uses the same architecture as shown in the previous table. The metrics for evaluation is normalized mutual information (NMI).  The results clearly demonstrate that apart from the 3-NG subset of the 20-newsgroup database on which both DDL and GraphEncoder yield same accuracy, the proposed algorithm yields better results than DBN as well as GraphEncoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this research, we propose the idea of deep dictionary learning, where, instead of learning one shallow dictionary, we learn multiple levels of dictionaries. Learning all the dictionaries simultaneously makes the problem highly nonconvex. Also learning so many parameters (atoms of many dictionaries) is always fraught with the problem of overfitting. To account for both these issues, we learn the dictionaries in a greedy fashion -one layer at a time. The representation/features from one level are used as the input to learn the following level. Thus, the basic unit of deep dictionary learning is a simple shallow dictionary learning algorithm; which is a well known and solved problem.</p><p>Experiments are carried out for both classification and clustering problems. We compare the proposed algorithm with existing methods such as stacked autoencoder, deep belief network, and convolutional neural network. We observe that the proposed method yields comparable or better results on benchmark datasets. Experiments on a practical problem of appliance classification show that our method offers higher accuracies where other deep learning techniques yield significantly lower results. Similar to the advancements made in "deep learning", it is our assertion that the proposed formulation of deep dictionary learning provides the basis to develop more efficient dictionary learning algorithms and can help in advancing state-of-theart.</p><p>In the future, we plan to test the robustness of dictionary learning in the presence of missing data, noise and limited number of training sample. We also plan to apply this technique to other practical problems such as biometrics, vision, and speech processing. Further, there has been a lot of work on supervised dictionary learning; we expect to improve the results even further by incorporating techniques from supervised learning paradigm.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Restricted Boltzmann Machine</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Deep Boltzmann Machine</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Schematic Diagram for Dictionary Learning</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Schematic Diagram for Deep Dictionary Learning</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Greedy Layer-wise Learning</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Top to bottom. basic, basic-rot, bg-rand, bg-img, bg-img-rot</figDesc><graphic coords="7,119.62,359.67,50.05,50.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. First level dictionary for MNIST</figDesc><graphic coords="8,74.80,284.31,195.15,146.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="11,59.58,434.36,492.79,305.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I :</head><label>I</label><figDesc>DEEP VS SHALLOW DICTIONARY LEARNING</figDesc><table><row><cell>Dataset</cell><cell>Shallow (50)</cell><cell>1 layer (300)</cell><cell>2 layer (300-150)</cell><cell>3 layer (300-150-50)</cell></row><row><cell>MNIST</cell><cell>97.35</cell><cell>96.52</cell><cell>97.30</cell><cell>97.75</cell></row><row><cell>basic</cell><cell>95.02</cell><cell>94.39</cell><cell>95.27</cell><cell>95.80</cell></row><row><cell>basic-rot</cell><cell>84.19</cell><cell>83.37</cell><cell>85.39</cell><cell>87.00</cell></row><row><cell>bg-rand</cell><cell>87.19</cell><cell>86.52</cell><cell>87.49</cell><cell>89.35</cell></row><row><cell>bg-img</cell><cell>78.86</cell><cell>77.56</cell><cell>79.20</cell><cell>81.00</cell></row><row><cell>bg-img-rot</cell><cell>54.40</cell><cell>54.06</cell><cell>55.93</cell><cell>57.77</cell></row><row><cell>20-newsgroup</cell><cell>60.96</cell><cell>65.22</cell><cell>68.93</cell><cell>70.48</cell></row><row><cell>GTZAN</cell><cell>76.57</cell><cell>75.70</cell><cell>79.68</cell><cell>83.31</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II :</head><label>II</label><figDesc>COMPARING THE CLASSIFICATION ACCURACY OF DDL WITH DBN AND SAE WITH KNN (K = 1) CLASSIFICATION</figDesc><table><row><cell>Dataset</cell><cell>DDL</cell><cell>DBN</cell><cell>SAE</cell></row><row><cell>MNIST</cell><cell>97.75</cell><cell>97.05</cell><cell>97.33</cell></row><row><cell>basic</cell><cell>95.80</cell><cell>95.37</cell><cell>95.25</cell></row><row><cell>basic-rot</cell><cell>87.00</cell><cell>84.71</cell><cell>84.83</cell></row><row><cell>bg-rand</cell><cell>89.35</cell><cell>77.16</cell><cell>86.42</cell></row><row><cell>bg-img</cell><cell>81.00</cell><cell>86.36</cell><cell>77.16</cell></row><row><cell>bg-img-rot</cell><cell>57.77</cell><cell>50.47</cell><cell>52.21</cell></row><row><cell>20-newsgroup</cell><cell>70.48</cell><cell>70.09</cell><cell>69.78</cell></row><row><cell>GTZAN</cell><cell>83.31</cell><cell>80.99</cell><cell>82.79</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE III :</head><label>III</label><figDesc>COMPARING THE CLASSIFICATION ACCURACY OF DDL WITH DBN AND SAE WITH SVM CLASSIFICATION</figDesc><table><row><cell>Dataset</cell><cell>DDL</cell><cell>DBN</cell><cell>SAE</cell></row><row><cell>MNIST</cell><cell>98.64</cell><cell>98.53</cell><cell>98.50</cell></row><row><cell>basic</cell><cell>97.28</cell><cell>88.44</cell><cell>97.40</cell></row><row><cell>basic-rot</cell><cell>90.34</cell><cell>76.59</cell><cell>79.83</cell></row><row><cell>bg-rand</cell><cell>92.38</cell><cell>78.59</cell><cell>85.34</cell></row><row><cell>bg-img</cell><cell>86.17</cell><cell>75.22</cell><cell>74.99</cell></row><row><cell>bg-img-rot</cell><cell>63.85</cell><cell>48.53</cell><cell>49.14</cell></row><row><cell>20-newsgroup</cell><cell>71.97</cell><cell>71.12</cell><cell>70.49</cell></row><row><cell>GTZAN</cell><cell>84.92</cell><cell>81.50</cell><cell>83.87</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE IV :</head><label>IV</label><figDesc>COMPARING THE CLASSIFICATION ACCURACY OF DDL+SVM WITH EXISTING ALGORITHMS AND ARCHITECTURES</figDesc><table><row><cell>Dataset</cell><cell cols="5">DDL-SVM Supervised DL LC-KSVD D-KSVD DBN-Softmax</cell><cell>SDAE-Softmax</cell><cell>CNN</cell></row><row><cell>MNIST</cell><cell>98.64</cell><cell>98.95</cell><cell>93.30</cell><cell>93.6</cell><cell>98.76</cell><cell>98.72</cell><cell>99.06</cell></row><row><cell>basic</cell><cell>97.28</cell><cell>95.14</cell><cell>92.70</cell><cell>92.20</cell><cell>96.89</cell><cell>97.16</cell><cell>98.56</cell></row><row><cell>basic-rot</cell><cell>90.34</cell><cell>51.98</cell><cell>48.66</cell><cell>50.01</cell><cell>89.70</cell><cell>90.47</cell><cell>89.45</cell></row><row><cell>bg-rand</cell><cell>92.38</cell><cell>88.23</cell><cell>87.70</cell><cell>87.70</cell><cell>93.27</cell><cell>89.7</cell><cell>93.23</cell></row><row><cell>bg-img</cell><cell>86.17</cell><cell>80.92</cell><cell>80.65</cell><cell>81.20</cell><cell>83.69</cell><cell>83.32</cell><cell>88.89</cell></row><row><cell>bg-img-rot</cell><cell>63.85</cell><cell>74.31</cell><cell>75.40</cell><cell>75.40</cell><cell>52.61</cell><cell>56.24</cell><cell>57.97</cell></row><row><cell>20-newsgroup</cell><cell>71.97</cell><cell>69.22</cell><cell>68.90</cell><cell>69.45</cell><cell>72.40</cell><cell>70.93</cell><cell>-</cell></row><row><cell>GTZAN</cell><cell>84.92</cell><cell>79.86</cell><cell>76.85</cell><cell>76.78</cell><cell>81.62</cell><cell>83.98</cell><cell>69.91</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE V :</head><label>V</label><figDesc>TRAINING FEATURE GENERATION TIME (IN SECONDS)</figDesc><table><row><cell>Dataset</cell><cell>DDL</cell><cell>DBN</cell><cell>SAE</cell></row><row><cell>MNIST</cell><cell>107</cell><cell>30071</cell><cell>120408</cell></row><row><cell>basic</cell><cell>26</cell><cell>5974</cell><cell>24020</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VI :</head><label>VI</label><figDesc>TEST FEATURE GENERATION TIME (IN SECONDS)</figDesc><table><row><cell>Dataset</cell><cell>DDL</cell><cell>DBN</cell><cell>SAE</cell></row><row><cell>MNIST</cell><cell>79</cell><cell>50</cell><cell>61</cell></row><row><cell>basic</cell><cell>257</cell><cell>151</cell><cell>185</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE VII :</head><label>VII</label><figDesc>CORRECT CLASSIFICATION ACCURACY FOR APPLIANCE CLASSIFICATION DATABASE.</figDesc><table><row><cell></cell><cell></cell><cell>ElectriSense [72]</cell><cell>CLM+SVM [77]</cell><cell>LC-KSVD</cell><cell>Proposed</cell></row><row><cell></cell><cell>Fold 1</cell><cell>25.0</cell><cell>62.5</cell><cell>60.0</cell><cell>90.0</cell></row><row><cell></cell><cell>Fold 2</cell><cell>30.0</cell><cell>60.0</cell><cell>55.0</cell><cell>85.0</cell></row><row><cell></cell><cell>Fold 3</cell><cell>32.5</cell><cell>67.5</cell><cell>62.5</cell><cell>90.0</cell></row><row><cell></cell><cell>Fold 4</cell><cell>32.5</cell><cell>67.5</cell><cell>62.5</cell><cell>87.5</cell></row><row><cell>UPS Power Supply</cell><cell>Fold 5</cell><cell>30.0</cell><cell>60.0</cell><cell>60.0</cell><cell>87.5</cell></row><row><cell></cell><cell>Aggregate</cell><cell>30.0</cell><cell>63.5</cell><cell>60.0</cell><cell>88.0</cell></row><row><cell>EMI</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Sensor</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Extension</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Cord</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Appliance Under Test</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(Laptop Charger)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p><p><p>On this dataset, stacked autoencoders and deep belief networks, even after pre-processing and normalization, are not able to surpass the results with random assignment, and the classification accuracy is pegged at = 1/(number of appliances). The standard technique for classifying appliances from EMI signatures is</p><ref type="bibr" target="#b75">[78]</ref></p>; therefore we compare our proposed technique against ElectriSense</p><ref type="bibr" target="#b75">[78]</ref> </p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>• 3-NG:corp.graphics, rec.sport.baseball, talk.politics.guns. • 6-NG: alt.atheism, comp.sys.mac.hardware, rec.motorcycles, rec.sport.hockey, soc.religion.christian, talk.religion.misc. • 9-NG: talk.politics.mideast, talk.politics.misc, comp.os.mswindows.misc, comp.sys.ibm.pc.hardware, sci.electronics, sci.crypt, sci.med, sci.space, misc.forsale.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2016.2611583, IEEE Access</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>The authors would like to thank Dr. Shobha Sundar Ram and Mr. Manoj Gulati for providing the EMI sensing data. The authors also thank the associate editor and reviewers for their constructive feedback.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Snigdha Tariyal has completed her Master's from Indraprastha Institute of Information Technology, Delhi. She is currently a Teaching Fellow at Indraprastha Institute of Information Technology, Delhi. Her area of research includes signal processing and dictionary learning. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Sparse coding with an overcomplete basis set: a strategy employed by V1?</title>
		<author>
			<persName><forename type="first">B</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="3311" to="3325" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning the parts of objects by nonnegative matrix factorization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">401</biblScope>
			<biblScope unit="issue">6755</biblScope>
			<biblScope unit="page" from="788" to="791" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dictionaries for Sparse Representation Modeling</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Bruckstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1045" to="1057" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">K-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bruckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4311" to="4322" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sparse coding and NMF</title>
		<author>
			<persName><forename type="first">J</forename><surname>Eggert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Körner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Joint Conference on Neural Networks</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="2529" to="2533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Image Denoising Via Sparse and Redundant Representations Over Learned Dictionaries</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3736" to="3745" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Image Denoising Via Learned Dictionaries and Sparse representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="895" to="900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Image Sequence Denoising via Sparse and Redundant Representations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Protter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="35" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Turbo inpainting: Iterative K-SVD with a new dictionary</title>
		<author>
			<persName><forename type="first">K</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Min-Sung</forename></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rodriguez-Marek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Workshop on Multimedia Signal Processing</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Local Learned Dictionaries Optimized to Edge Orientation for Inverse Halftoning</title>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2542" to="2556" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dictionary Learning and Time Sparsity for Dynamic MR Data Reconstruction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Hajnal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="979" to="994" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Compressed sensing</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Info. Theory</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1289" to="1306" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<idno>FIG. 11</idno>
		<title level="m">CEPSTRUM FEATURES -HORIZONTAL AXIS -FREQUENCY IN KHZ AND VERTICAL AXIS -VOLT</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Near optimal signal recovery from random projections: Universal encoding strategies?</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Info. Theory</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5406" to="5425" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multiresolution methods in face recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recent Advances in Face Recognition</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bartlett</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Delac</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Grgic</surname></persName>
		</editor>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<publisher>I-Tech Education and Publishing</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="79" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Feature extraction using Radon and wavelet transforms with application to face recognition</title>
		<author>
			<persName><forename type="first">V</forename><surname>Dattatray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jadhav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Holambe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">7-9</biblScope>
			<biblScope unit="page" from="1951" to="1959" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Feature extraction using discrete cosine transform and discrimination power analysis with a face recognition technology</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dabbaghchian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Ghaemmaghami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aghagolzadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1431" to="1440" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Discriminative learned dictionaries for local image analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference of Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unifying discriminative visual codebook generation with classifier training for object category recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference of Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Classification of clouds in satellite imagery using over-complete dictionary via sparse representation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="193" to="200" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning mid-level features for recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference of Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Supervised dictionary learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Stable Discriminative Dictionary Learning via Discriminative Deviation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Tapppen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Pattern Recognition</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sparse representation for signal classification</title>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Aviyente</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Joint learning and dictionary construction for pattern recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference of Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Dictionary learning for fast classification based on soft-thresholding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1402.1973</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Supervised translation-invariant sparse coding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference of Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Discriminative sparse image models for class-specific edge detection and image interpretation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leordeanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Discriminative K-SVD for dictionary learning in face recognition</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference of Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning A Discriminative Dictionary for Sparse Coding via Label Consistent K-SVD</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2651" to="2664" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Reducing the Dimensionality of Data with Neural Networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Auto-association by multilayer perceptrons and singular value decomposition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bourlard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4-5</biblScope>
			<biblScope unit="page" from="291" to="294" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Greedy Layer-Wise Training of Deep Networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning deep architectures for AI</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Machine Learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="127" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Method of optimal directions for frame design</title>
		<author>
			<persName><forename type="first">K</forename><surname>Engan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Aase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hakon-Husoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Sparse approximate solutions to linear systems</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Natarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on computing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="227" to="234" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Orthogonal Matching Pursuit: recursive function approximation with application to wavelet decomposition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Pati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rezaiifar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Krishnaprasad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asilomar Conference on Signals, Systems and Computers</title>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Dictionary Learning for Sparse Approximations With the Majorization Method</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yaghoobi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Blumensath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Davies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2178" to="2191" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Applying alternating direction method of multipliers for constrained dictionary learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rakotomamonjy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="126" to="136" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Robust face recognition via sparse representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Robust Classifiers for Data Reduced via Random Projections</title>
		<author>
			<persName><forename type="first">A</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics, Part B</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1359" to="1371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Fast Group Sparse Classification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Canadian Journal of Electrical and Computer Engineering</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="136" to="144" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Improved Group Sparse Classifier</title>
		<author>
			<persName><forename type="first">A</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1959" to="1964" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Kernel sparse representation based classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="120" to="128" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Hyperspectral Image Classification via Kernel Sparse Representation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="217" to="231" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Kernel Sparse Representation-Based Classifier</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1684" to="1695" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">metaface learning for sparse representation based face recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Classification and clustering via dictionary learning with structured incoherence and shared features</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ramirez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sprechmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference of Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Fisher discrimination dictionary learning for sparse representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Classification using Discriminative Restricted Boltzmann Machines</title>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Analysis of Different Sparsity Methods in Constrained RBM for Sparse Representation in Cognitive Robotic Perception</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Robot and Systems</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Niu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1008.4988v1</idno>
		<title level="m">Sparse Group Restricted Boltzmann Machines</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deep Boltzmann Machines</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Gaussian-Bernoulli deep Boltzmann machine</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ilin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Joint Conference on Neural Networks</title>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Makhzani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Frey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.5663</idno>
		<title level="m">k-Sparse Autoencoders</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Simple sparsification improves sparse denoising autoencoders in denoising highly noisy images</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Contractive Auto-Encoders: Explicit Invariance During Feature Extraction, International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Low-rank Matrix Completion using Alternating Minimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Netrapalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sanghavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Theory Of Computing</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Learning Sparsely Used Overcomplete Dictionaries via Alternating Minimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Netrapalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference On Learning Theory</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Exact Recovery of Sparsely-Used Dictionaries</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Spielman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference On Learning Theory</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhaskara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1401.0579v1</idno>
		<title level="m">More Algorithms for Provable Dictionary Learning</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">When can dictionary learning uniquely recover sparse data from subsamples?</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hillar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>Sommer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1106.3616v3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">An iterative thresholding algorithm for linear inverse problems with a sparsity constraint</title>
		<author>
			<persName><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Defrise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">De</forename><surname>Mol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Communications on Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="1413" to="1457" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Analysis K-SVD: A Dictionary-Learning Algorithm for the Analysis Sparse Model</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="661" to="677" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Suo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Tran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1943</idno>
		<title level="m">Structured Dictionary Learning for Classification</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Hierarchical dictionary learning for invariant classification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE ICASSP</title>
		<imprint>
			<biblScope unit="page" from="3578" to="3581" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Double Sparsity: Learning Sparse Dictionaries for Sparse Signal Approximation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zibulevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1553" to="1564" />
			<date type="published" when="2010-03">March 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">An Empirical Evaluation of Deep Architectures on Problems with Many Factors of Variation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Musical genre classification of audio signals</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tzanetakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Audio and Speech Processing</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">PCANet: A Simple Deep Learning Baseline for Image Classification</title>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5017" to="5032" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">ElectriSense: single-point sensing using EMI for electrical event detection and classification in the home</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Patel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>ACM UBICOMP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">An in depth study into using EMI signatures for appliance identification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gulati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Ram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>ACM BuildSys</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">An In Depth Study into Using EMI Signatures for Appliance Identification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gulati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Ram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<ptr target="http://www.academia.edu/10808246/An_In_Depth_Study_into_Using_EMI_Signatures_for_Appliance_Identification" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Home appliance load disaggregation using cepstrum-smoothing-based method</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Consumer Electronics</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="30" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Conditional Likelihood Maximisation: A Unifying Framework for Information Theoretic Feature Selection</title>
		<author>
			<persName><forename type="first">G</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pocock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Luján</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="27" to="66" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Learning Deep Representations for Graph Clustering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
