<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">OSA: An Optical Switching Architecture for Data Center Networks With Unprecedented Flexibility</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
							<email>kaichen@cse.ust.hk</email>
							<affiliation key="aff0">
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ankit</forename><surname>Singla</surname></persName>
							<email>singla2@illinois.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Atul</forename><surname>Singh</surname></persName>
							<email>atuls@nec-labs.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">are with NEC Labs</orgName>
								<address>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kishore</forename><surname>Ramachandran</surname></persName>
							<email>kishore@nec-labs.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">are with NEC Labs</orgName>
								<address>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lei</forename><surname>Xu</surname></persName>
							<email>leixu@nec-labs.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">are with NEC Labs</orgName>
								<address>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Yueping</forename><surname>Zhang</surname></persName>
							<email>yueping@nec-labs.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">are with NEC Labs</orgName>
								<address>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xitao</forename><surname>Wen</surname></persName>
							<email>xwen@northwestern.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">are with Northwestern University</orgName>
								<address>
									<postCode>60208</postCode>
									<settlement>Evanston</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>Chen</surname></persName>
							<email>ychen@northwestern.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">are with Northwestern University</orgName>
								<address>
									<postCode>60208</postCode>
									<settlement>Evanston</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Editor</forename><forename type="middle">S K</forename><surname>Sengupta</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<postCode>61801</postCode>
									<settlement>Urbana</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<postCode>61801</postCode>
									<settlement>Urbana</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">OSA: An Optical Switching Architecture for Data Center Networks With Unprecedented Flexibility</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A1B2692CC91ECC774DED76127A612A3A</idno>
					<idno type="DOI">10.1109/TNET.2013.2253120</idno>
					<note type="submission">received August 15, 2012; revised January 02, 2013; accepted March 05, 2013; approved by IEEE/ACM TRANSACTIONS ON NETWORKING</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Data center networks (DCNs)</term>
					<term>optical networking technology</term>
					<term>switching architecture</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A detailed examination of evolving traffic characteristics, operator requirements, and network technology trends suggests a move away from nonblocking interconnects in data center networks (DCNs). As a result, recent efforts have advocated oversubscribed networks with the capability to adapt to traffic requirements on-demand. In this paper, we present the design, implementation, and evaluation of OSA, a novel Optical Switching Architecture for DCNs. Leveraging runtime reconfigurable optical devices, OSA dynamically changes its topology and link capacities, thereby achieving unprecedented flexibility to adapt to dynamic traffic patterns. Extensive analytical simulations using both real and synthetic traffic patterns demonstrate that OSA can deliver high bisection bandwidth (60%-100% of the nonblocking architecture). Implementation and evaluation of a small-scale functional prototype further demonstrate the feasibility of OSA.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>instance, measurement on a 1500-server Microsoft production DCN reveals that only a few Top-of-Racks (ToRs) are hot, and most of their traffic goes to a few other ToRs <ref type="bibr" target="#b4">[5]</ref>. Likewise, an analysis of high-performance computing applications shows that the bulk of interprocessor traffic is degree-bounded and slowly changing <ref type="bibr" target="#b5">[6]</ref>. Thus, even for a few thousand servers, uniformly high-capacity networks appear to be an overkill. As the size of the network grows, this weighs on the cost, power, and wiring complexity of such networks.</p><p>Dealing With the Oversubscribed Networks: Achieving high performance for data center services is challenging with oversubscribed networks. One approach is to use intelligent workload placement algorithms to allocate network-bound service components to physical hosts with high bandwidth connectivity <ref type="bibr" target="#b6">[7]</ref>, e.g., placing these components on the same rack. Such workloads exist in practice: dynamic creation and deletion of VM instances in Amazon's EC2 or periodic backup services running between an EC2 (compute) instance and an S3 (storage) bucket. An alternate approach is to flexibly allocate more network bandwidth to service components with heavy communications. If the network could "shape-shift" in such fashion, this could considerably simplify the workload placement problem.</p><p>Higher Bit Rates: There is an increasing trend toward deploying 10 GigE NICs at the end-hosts. In fact, Google already has 10 GigE deployments and is pushing the industry for 40/100 GigE <ref type="bibr" target="#b7">[8]</ref>- <ref type="bibr" target="#b9">[10]</ref>. Deploying servers with 10 GigE naturally requires much higher capacity at the aggregation layers of the network. Unfortunately, traditional copper-wire 10 GigE links are not viable for distances over 10 m <ref type="bibr" target="#b10">[11]</ref> due to the high electrical loss at higher data rate, necessitating the need to look for alternative technologies.</p><p>The optical networking technology is well suited to meet the above challenges. Optical network elements support on-demand connectivity and capacity where required in the network, thus permitting the construction of thin but flexible interconnects for large server pools. Optical links can support higher bit rates over longer distances using less power than copper cables. Moreover, optical switches run cooler than electrical ones <ref type="bibr" target="#b11">[12]</ref>, resulting in lower heat dissipation and cheaper cooling cost. The long-term advantage of optics in DCNs has been noted in the industry <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>.</p><p>Recent efforts in c-Through <ref type="bibr" target="#b13">[14]</ref> and Helios <ref type="bibr" target="#b10">[11]</ref> provide a promising direction to exploit the optical networking technology (e.g., one-hop high-capacity optical circuits) for building DCNs. Following this trailblazing research, we present OSA, a novel Optical Switching Architecture for DCNs. OSA achieves high flexibility by leveraging and extending the techniques devised by previous works and further combining them with novel techniques of its own. Similar to the previous works, OSA leverages reconfigurability of optical devices to dynamically set up one-hop optical circuits. Then, OSA employs the novel hop-by-hop stitching of multiple optical links to provide overall connectivity for mice flows and bursty communications and to handle workloads involving high fan-in/out hotspots <ref type="bibr" target="#b14">[15]</ref> that the existing one-hop electrical/optical architectures cannot address efficiently via their optical interconnects. Furthermore, OSA dynamically adjusts the capacities on the optical links to satisfy changing traffic demand at a finer granularity. Additionally, to make efficient use of expensive optical ports, OSA introduces the circulator (Section II-B), a bidirectionality-enabling component for simultaneous transmission in both directions over a circuit, which potentially doubles the usage of optical switch ports.</p><p>Overall, the highlights of this paper are as follows.</p><p>Flexible DCN Architecture: Given a number of ToR switches and a design-time-fixed parameter , OSA can assume any -regular topology over the ToRs. To illustrate how many options this gives us, consider that for just , there are over 12 billion (nonisomorphic) connected 4-regular graphs <ref type="bibr" target="#b15">[16]</ref>. In addition, OSA allows the capacity of each edge in this -regular topology to be varied from a few to a few hundred gigabits per second on demand. Evaluation results in Section V-B.2 suggest up to 150% and 50% performance improvement brought by the flexible topology and flexible link capacity, respectively.</p><p>Analysis of OSA-2560: We evaluate a particular instance of container-size OSA architecture, OSA-2560 , with 2560 servers via extensive simulations and analysis. Our evaluation results (Section V-B) suggest that it can deliver high bisection bandwidth that is 60%-100% of the nonblocking network and outperform the hybrid structures by 80%-250% for both real and synthetic traffic patterns. Our analysis (Section III-C) shows that OSA has better performance/power and performance/wiring complexity ratios than either FatTree <ref type="bibr" target="#b0">[1]</ref> or a traditional 2:1 oversubscribed network with the same number of servers. Compared to the hybrid structures, OSA achieves better performance with similar cost and slightly less power consumption. We believe that for DCNs that expect skewed traffic demands, OSA provides a compelling tradeoff between the cost, power, complexity, and performance.</p><p>OSA Prototype Implementation: We build a small-scale 8-rack OSA prototype with real optical devices and server-emulated ToRs. Through this testbed, we evaluate the performance of OSA with all software and hardware overheads. We find that OSA can quickly adapt the topology and link capacities to the changing traffic patterns, and our results show that it achieves nearly 60% of the nonblocking bandwidth in all-to-all communications. We further examine the impact of OSA on transferring bulk data and mice flows. We also measure the device characteristics of the optical equipment, evaluate the impact of multihop optical-electrical-optical (O-E-O) conversion, and discuss our experience building and evaluating the OSA prototype.</p><p>OSA, in its current form, has limitations. Small flows, especially those latency-sensitive ones, may experience nontrivial penalty due to the network reconfiguration latency ( ms). While the fraction of such affected flows is small (Section VII), we propose multiple avenues to solve this problem. The second challenge is how to scale OSA from container-size to larger DCNs consisting of tens to hundreds of thousands of servers. This requires nontrivial efforts in both architecture design and management and is left as part of our ongoing investigation. In this paper, we describe OSA that is designed to interconnect a few thousands of servers in a container.</p><p>Roadmap: In Section II, we discuss the idea of OSA's unprecedented flexibility, followed by the background on optical technologies for OSA. Then, we describe OSA architecture (Section III) and its algorithm design (Section IV) in response to traffic patterns. In Sections V and VI, we evaluate OSA via extensive simulations and implementation, respectively. We discuss some design issues and related work in Section VII before concluding in Section VIII.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MOTIVATION AND BACKGROUND</head><p>We first use a motivating example to show what kind of flexibility OSA can deliver. Then, we introduce the optical networking technologies that make OSA possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Motivating Example</head><p>We discuss the utility of a flexible network using a simple hypothetical example in Fig. <ref type="figure" target="#fig_0">1</ref>. On the left is a hypercube connecting 8 ToRs using 10G links. The traffic demand is shown in the bottom left of Fig. <ref type="figure" target="#fig_0">1</ref>. For this demand, no matter what routing paths are used on this hypercube, at least one link will be congested. One way to tackle this congestion is to reconnect the ToRs using a different topology (Fig. <ref type="figure" target="#fig_0">1</ref>, bottom center). In the new topology, all the communicating ToR pairs are directly connected, and their demand can be perfectly satisfied. Now, suppose the traffic demand changes (Fig. <ref type="figure" target="#fig_0">1</ref>, bottom right) with a new (highlighted) entry replacing an old one. If no adjustment is made, at least one link will face congestion. With the shortest path routing, will be that link. In this scenario, one way to avoid congestion is to increase the capacity of to 20G at the expense of decreasing the capacities of and to 0. Note that in all these cases, the node degree remains the same (i.e., 3), and the node capacity is no more than 30G.</p><p>As above, OSA's flexibility lies in its flexible topology and flexible link capacity. In the absence of such flexibility, the above example would require additional links and capacities to handle both traffic patterns. More generally, a large variety of traffic patterns would necessitate the nonblocking network construction. OSA, with its high flexibility, can avoid such nonblocking construction while still providing equivalent performance for various traffic patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Optical Networking Technologies</head><p>We now discuss the optical networking technologies that enable the above flexibility.</p><p>1) Wavelength Division Multiplexing (WDM): Within the C-band (conventional band) and with 100 GHz DWDM channel spacing, typically 40 or more wavelength channels can be transmitted over a single optical fiber. For the purpose of our architecture, each wavelength is rate-limited by the electrical port to which it connects.</p><p>2) Wavelength Selective Switch (WSS): A WSS is typically a switch, consisting of one common port and wavelength ports. It partitions (runtime-configurable within a few milliseconds) the set of wavelengths coming in through the common port among the wavelength ports. For example, if the common port receives 80 wavelengths, it can route wavelengths 1-20 on port 1, 30-40 on port 2, etc.</p><p>3) Optical Switching Matrix (OSM): Most OSM modules are a bipartite switching matrix where any input port can connect to any of the output ports. Microelectromechanical system (MEMS) is the most popular OSM technology and achieves reconfigurable (at 10 ms <ref type="bibr" target="#b16">[17]</ref>) one-to-one circuit by mechanically adjusting micro mirrors. A few hundred ports are common for commercial products, and for research prototypes <ref type="bibr" target="#b17">[18]</ref>. The current commercially available OSM modules are typically oblivious to the wavelengths carried across it. We use MEMS and OSM interchangeably.</p><p>4) Optical Circulators: Circulators enable bidirectional optical transmission over a fiber, allowing more efficient use of the ports of optical switches. An optical circulator is a three-port device: One port is a shared fiber or switching port, and the other two ports serve as send and receive ports.</p><p>5) Optical Transceivers: Optical transceivers can be of two types: coarse WDM (CWDM) and dense WDM (DWDM). We use DWDM-based transceivers in OSA, which support higher bit rates and more wavelength channels in a single piece of fiber compared to CWDM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. OSA ARCHITECTURE</head><p>In this section, we introduce how OSA architecture is built from the above-described optical networking technologies. Our current design is intended for container-size DCNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Building Blocks</head><p>Flexible Topology: OSA achieves the flexible topology by exploiting the reconfigurability of the MEMS. If we start by connecting each of ToRs to one port on an -port MEMS, each ToR can only communicate with one other ToR at any instant given the MEMS's bipartite port-matching, leaving the ToRlevel graph disconnected. If we connect ToRs to ports each at the MEMS, each ToR can communicate with other ToRs simultaneously. Here, is the degree of the ToR, not its port count, in the ToR graph. The MEMS configuration determines which set of ToRs are connected. OSA must ensure that the ToR graph is connected when configuring the MEMS. Given a ToR topology connected by the MEMS optical circuits, we use hop-by-hop stitching of such circuits to achieve network-wide connectivity. To reach remote ToRs that are not directly connected, a ToR uses one of its connections. This first-hop ToR receives the transmission over fiber, converts it to electrical signals, reads the packet header, and routes it toward the destination. At each hop, the packet experiences the conversion from optics to electronics and then back to optics (O-E-O) and the switching at the ToR. Note that at any port, the aggregate transit, incoming, and outgoing traffic cannot exceed the port's capacity in each direction. Therefore, the highvolume connections must use a minimal number of hops. OSA should manage the topology to adhere to this requirement. Evaluation in Section VI quantifies the overhead (both O-E-O and switching) of the hop-by-hop routing.</p><p>Flexible Link Capacity: In OSA, Each ToR connects to other ToRs. If each link has a fixed capacity, multiple links may be required for this ToR to communicate with another ToR at a rate higher than a single link can support. To overcome this problem, OSA combines the capability of optical fibers to carry multiple wavelengths at the same time (WDM) with the dynamic reconfigurability of the WSS. Consequently, each ToR is connected to the MEMS through a multiplexer (MUX) and a WSS unit (Fig. <ref type="figure" target="#fig_1">2</ref>).</p><p>Specifically, suppose ToR wants to communicate with ToR using times the line speed of a single port. The ToR will use ports, each associated with a unique wavelength, to serve this request. The WDM enables these wavelengths, together with the rest from this ToR, to be multiplexed into one optical fiber that feeds the WSS. The WSS splits these wavelengths to the appropriate MEMS port that has a circuit to ToR (doing likewise for the rest groups of wavelengths). Thus, a (line-speed) capacity circuit is set up from to at runtime. By varying the value of for each MEMS circuit, OSA achieves the dynamic link capacity.</p><p>We note that a fiber cannot carry two channels over the same wavelength in the same direction. Moreover, to enable a pair of ToRs to communicate using all available wavelengths, we require that each ToR port (facing the optical interconnect) is associated with a wavelength that is unique across the ports of a ToR. This wavelength-port association is a design time decision, and the same set of wavelengths is recycled across ToRs.</p><p>The same wavelength is used to receive traffic as well: Each port thus sends and receives traffic at one fixed wavelength. This allows all wavelengths at a source ToR to be multiplexed and delivered, after demultiplexing, to individual ports at the destination ToRs.</p><p>Efficient Port Usage: To make full use of the MEMS ports, we require that each circuit over the MEMS be bidirectional. For this purpose, we use optical circulators between the ToR and the MEMS ports. A circulator connects the send channel of the transceiver from a ToR to the MEMS (after the channel has passed through the MUX and WSS). It simultaneously delivers the incoming traffic toward a ToR from the MEMS (through the coupler and DEMUX) to this ToR. Note that even though the MEMS links are bidirectional, the capacities of the two directions are independent of each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Putting It All Together: OSA-2560</head><p>Fig. <ref type="figure" target="#fig_1">2</ref> illustrates the general OSA architecture. We now discuss one specific instantiation-OSA-2560 with ToRs, wavelengths, and ToR degree using a 320-port MEMS to support 2560 servers.</p><p>Each ToR is a commodity electrical switch with 64 10-GigE ports <ref type="bibr" target="#b18">[19]</ref>: 32 of these ports are connected to servers, while the remaining are connected to the optical interconnect. Each port facing the optical interconnect has a transceiver associated with a fixed and unique wavelength for sending and receiving data. The transceiver uses separate fibers to connect to the send and receive infrastructures.</p><p>The send fiber from the transceiver from each of the 32 ports at a ToR is connected to an optical MUX. The MUX feeds a 1 4 WSS. The WSS splits the set of 32 wavelengths it sees into four groups, each group being transmitted on its own fiber. These fibers are connected to the MEMS via circulators to enable bidirectional communications. The four receive fibers from four circulators are connected to a power coupler (similar to a multiplexer, but simpler), which combines their wavelengths onto one fiber. This fiber feeds a demultiplexer (DEMUX), which assign each incoming wavelength to its associated port on the ToR.</p><p>We point out two key properties of the above interconnect. First, each ToR can communicate simultaneously with any four other ToRs. This implies that the MEMS configuration allows us to construct all possible 4-regular graphs among ToRs. Second, through WSS configuration, the capacity of each of these four links can be varied in Gb/s. The MEMS and WSS configurations are decided by a central OSA manager. The manager estimates the traffic demand, calculates the appropriate configurations, and pushes them to the MEMS, WSS units, and ToRs. This requires direct, out-of-band connections between the OSA manager and those components. Note that our employment of such a central OSA manager is inspired by many recent works <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b19">[20]</ref> in the context of DCNs given the fact that a DCN is usually owned and operated by a single organization.</p><p>Furthermore, we choose for container-size DCNs because it is a tradeoff between the network size and performance. A larger value can enable one ToR to connect to more other  ToRs simultaneously, thus achieving higher performance. However, given a 320-port MEMS, it also means that fewer ToRs can be supported. Our experiments with indicate that can deliver considerable bisection bandwidth between thousands of servers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Analysis</head><p>Table I lists the cost and power usage of different network elements. Table <ref type="table" target="#tab_1">II</ref> is the comparison among the traditional network, hybrid structure, OSA, and FatTree.</p><p>Traditional Oversubscribed Network: To connect 2560 servers using a two-tiered 2:1 oversubscribed structure, we use 80 48 10 G port ToR switches and 80 16 10 G port aggregation switches. Each ToR switch has 32 ports connect to servers, and the remaining 16 ports connect to aggregation switches, which results in a 2:1 oversubscription ratio. Note that we picked the 2:1 oversubscription because, for all the traffic patterns we studied in Section V, OSA delivers network bisection bandwidth that is at least 60% of the nonblocking network. Thus, a 2:1 oversubscribed traditional network (50% of the nonblocking) is a conservative comparison point. This structure costs $2.6 M and consumes 25.6 kW. The number of cross-ToR fibers required is 1280. The bisection bandwidth provided is 50% of the nonblocking network. However, for skewed traffic demands, it is desirable to allocate high fraction of this capacity to more demanding flows and achieve better cost/performance tradeoff.</p><p>Simplified Model of Hybrid Structure: Helios <ref type="bibr" target="#b10">[11]</ref> and c-Through <ref type="bibr" target="#b13">[14]</ref> are two well-known hybrid electrical/optical structures. The hybrid structure model we used here and in Section V is an abstract model that captures key aspects of both. In this model, each ToR connects to both an electrical network and an optical network. The electrical network is a two-or three-tiered tree with a certain oversubscription ratio (8:1 for Table <ref type="table" target="#tab_1">II</ref>). In the optical part, each ToR has only one optical link to one other ToR, but this link is of unlimited capacity. <ref type="foot" target="#foot_0">1</ref>This hybrid structure costs $4.5 M, consumes 29 kW, and has 480 inter-ToR long fibers-160 above the MUX in the optical part and 320 above the ToRs in the electrical part.</p><p>OSA: The total cost is approximately $4.4 M, with a power consumption of 27.1 kW. ToRs and transceivers are responsible for a large portion of the cost and power budget. Compared to the traditional network, the additional cost is mainly due to transceivers, (DE)MUX, and WSS units. OSA uses DWDM transceivers that are more expensive than Gray transceivers used in the traditional network. The number of inter-ToR links required by OSA is only 320-the lowest of all these structures. OSA's cost is similar as the hybrid structure, but is more expensive than the traditional structure. However, it can dynamically adjust the bandwidth allocated to demanding flows. For all the traffic demands we evaluated in Section V, this enables OSA to achieve 60%-100% of the nonblocking bandwidth. We note that the cost of optics is expected to fall significantly with commoditization and production volume. Much of these benefits have already been reaped for the electrical technology. There is also scope for packaging multiple components on a chip-the 32 transceivers and the MUX could be packaged into one chip. This will reduce power, cost, as well as the number of fibers.</p><p>FatTree: The cost and power of FatTree mainly depend on switch port density: A FatTree topology with -port switches can connect hosts with a total number of ports. Note that for 10G port electrical switches, optical transceivers for remote connections is a necessity. To connect 2560 servers, FatTree costs $5.1 M. The power consumption is 51.2 kW. Especially, the wiring complexity for FatTree is the highest-the number of links above the ToR layer is 5120. FatTree is more expensive and consumes more power because it is designed to provide nonblocking connectivity and is also highly fault-tolerant. Our intention is not to perform a head-to-head comparison to FatTree, but to illustrate the cost/power/performance tradeoff of building a nonblocking network architecture.</p><p>Summary: For data center deployments where the skewed traffic demands are expected, we believe that OSA is a better alternative than either FatTree or the traditional oversubscribed networks: FatTree incurs higher cost, power, and wiring complexity, while the traditional architectures are inflexible and cannot assign spare bandwidth to demanding flows on the fly. Compared to the hybrid structure, OSA can achieve better performance with similar cost and power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. DESIGN</head><p>In this section, we present OSA network optimization in detail. Our goal is to compute the optimal topology and link capacities such that the network bisection bandwidth is maximized for a given traffic demand. Estimating traffic demand is not our main focus of this paper, and we assume this can be achieved using a similar way as Helios <ref type="bibr" target="#b10">[11]</ref>, c-Through <ref type="bibr" target="#b13">[14]</ref>, or Flyways <ref type="bibr" target="#b14">[15]</ref>. For optimization, we need to find: 1) a MEMS configuration to adjust the topology to localize high traffic volumes; 2) routes between ToRs to achieve high throughput, low latency, or avoid congestion; and 3) a configuration for each WSS to provision the capacities of its outgoing links.</p><p>In the following, we first present a mathematical formulation for optimization. Considering its complexity, we then introduce an approximation solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Mixed-Integer Linear Programming Problem Formulation</head><p>Given: A traffic demand between ToRs-is the desired bandwidth from to . Variables: We use four sets of variables: if is connected to through MEMS and 0 otherwise; if carries wavelength in the direction, and 0 otherwise; is the traffic volume carried by wavelength along ; a traffic-served matrix is the bandwidth achieved from to . For the last two sets of variables, have end-to-end meaning, while have hop-to-hop significance. For all the variables, are the only variables for which , and all the other variables are directional.</p><p>Objective: To achieve the optimal network bisection bandwidth, we maximize the traffic served <ref type="bibr" target="#b0">(1)</ref> Constraints: If the number of outgoing ports of the WSS is , then is connected to exactly other ToRs</p><p>A wavelength can only be used between two ToRs if they are directly connected via MEMS</p><p>To avoid wavelength contention, can only receive/send from/to at most one ToR <ref type="bibr" target="#b3">(4)</ref> Traffic carried by between two ToRs is limited by ToR port capacity and wavelength capacity <ref type="bibr" target="#b4">(5)</ref> The outgoing transit traffic is equal to the incoming transit traffic at <ref type="bibr" target="#b5">(6)</ref> Finally, the traffic served is bounded by the demand <ref type="bibr" target="#b6">(7)</ref> The above mixed-integer linear program (MILP) can be viewed as a maximum multicommodity flow problem with degree bounds, further generalized to allow constrained choices in link capacities. While several variants of the degree-bounded subgraph and maximum flow problems have known polynomial-time algorithms, the trivial combination of two is NP-hard <ref type="bibr" target="#b20">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Solution</head><p>As introduced above, in our approximation solution, we decompose the problem into three sequential subparts as shown in Fig. <ref type="figure" target="#fig_2">3</ref>, i.e., computing the topology, computing the routing, and computing the wavelength assignment. Similar as Helios <ref type="bibr" target="#b10">[11]</ref>, in this paper, we adopt the traffic demand estimation method introduced in Hedera <ref type="bibr" target="#b21">[22]</ref>, which is based on the max-min fair bandwidth allocation for TCP flows in an ideal nonblocking network.</p><p>1) Compute the Topology: We localize high-volume communicating ToR pairs over direct MEMS circuit links. This is accomplished by using a weighted -matching <ref type="bibr" target="#b22">[23]</ref>, where represents the number of ToRs that a ToR connects to via MEMS ( in OSA-2560). In the ToR graph, we assign the edge-weight between two ToRs as the estimated demand between them, and then cast the problem of localizing high-volume ToR connections to -matching. The weighted -matching is a graph theoretic problem for which polynomial-time algorithm exists <ref type="bibr" target="#b22">[23]</ref>. We implement it using multiple perfect matchings, for which public library is available <ref type="bibr" target="#b23">[24]</ref>.</p><p>The -matching graph above is not necessarily a connected graph. Fortunately, connectivity is easy to achieve via the edgeexchange operation <ref type="bibr" target="#b24">[25]</ref>. First, we find all the connected components. If the graph is not connected, we select two edges and with lowest weights in different connected components and connect them via replacing links and with links and . We make sure that the links removed are not themselves cuts in the graph. The output of step 2 is used to tell the MEMS about how to configure the new topology.</p><p>2) Compute the Routes: Once we have connectivity, the MEMS configuration is known. We proceed to compute the routes using any of the standard routing schemes such as the shortest path routing or low congestion routing. Note that some of the routes are single-hop MEMS connections, while the others are multihop ones. For simplicity, we use the shortest path routing in this paper. However, our framework can be readily applied to other routing schemes. The output of step 3 is used by the ToRs to configure their routing tables.</p><p>3) Compute the Wavelength Assignment: Given the traffic demand and routes among ToRs, we compute the capacity desired on each ToR link in order to serve the traffic demand on this link.</p><p>With the desired capacity demand on each link, we need to provision a corresponding amount of wavelengths to serve the demand. However, wavelength assignment is not arbitrary: Due to the contention, a wavelength can only be assigned to a ToR at most once. Given this constraint, we reduce the problem to be the edge-coloring problem on a multigraph. We represent our ToR-level graph as a multigraph. Multiple edges correspond to the number of wavelengths between two nodes, and we assume each wavelength has a unique color. Thus, a feasible wavelength assignment is equivalent to an assignment from the colors to the edges of the multigraph so that no two adjacent edges have the same color-exactly the edge-coloring problem <ref type="bibr" target="#b25">[26]</ref>. The edgecoloring is a known problem, and fast heuristics are known <ref type="bibr" target="#b26">[27]</ref>. Libraries implementing this are publicly available.</p><p>We also require at least one wavelength to be assigned to each edge on the physical topology. This guarantees an available path between any pair of ToRs, which may be required for mice/ bursty flows. The output of step 4 is used by the WSS to assign wavelengths.</p><p>All the above steps are handled by the OSA manager. Specifically, the OSA manager interacts with the MEMS, WSS units, and ToRs to control the topology, link capacities, and routing, respectively. We note that our decomposition heuristic is not optimal and there is room to improve. However, it provides satisfactory gains as we will see.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. SIMULATION</head><p>In this section, we evaluate OSA-2560 via analytical simulations. We start with the simulation methodology, and then present the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Simulation Methodology</head><p>Simulation Goals: Since our testbed only has 8 ToRs (Section VI), to evaluate the performance of OSA at its intended scale, we conduct analytical simulations of the network bisection bandwidth of OSA-2560 under various traffic patterns. Our results in this section are essentially computations of the expected bisection bandwidth in the steady state, ignoring software and hardware overheads that are considered in our testbed experiments in Section VI. We compare OSA to a nonblocking network, a hybrid network with varied oversubscription ratios in the electrical part, and a 2:1 oversubscribed traditional network.</p><p>Communication Patterns: We use the following real measurement traces and synthetic traffic data to evaluate the performance of OSA in the presence of changing communication patterns and traffic demands.</p><p>1) Mapreduce-Demand: We collected real traffic matrices in a production data center with around 400 servers, which mainly runs Mapreduce applications. 2 We compute the network demands by averaging the traffic over 30-s periods. For each demand, we identify the communication pattern by filtering out mice flows and focusing on the elephant ones. We duplicate these traffic demands onto OSA-2560 using spatial replication.</p><p>2) Measurement-Based: Recent measurements <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b27">[28]</ref> reveal several data center traffic characteristics. One important feature is that the hotspot ToR links are often associated with a high fan-in (or fan-out), and most of the traffic (80%) are within the rack, resulting in a highly skewed distribution. We 2 The name of the production data center company is anonymized.</p><p>synthesize this kind of traffic patterns by randomly choosing 12 hotspots out of 80 ToRs, with each one connecting to 6-10 other randomly chosen ToRs, respectively. We intentionally assume all the traffic exits the rack in order to create more intensive communications.</p><p>3) ToR-Level Shifting: We index the ToR switches from 0 to 79 and shift traffic round by round. Initially, all the servers in ToR talk to all the servers in ToRs mod 80 and mod 80. Then, we shift these communications to servers in the next ToR after each round.</p><p>4) Server-Level Shifting: We index the servers from 0 to 2559. We start with server talking to four other servers: mod 2560 and mod 2560. With 32 servers in a rack, initially, this implies that each rack communicates with four other racks. In successive rounds, server talks to mod 2560 and mod 2560 . This implies that each rack communicates with six racks in most rounds, with traffic spread across these six connections increasing and decreasing periodically.</p><p>5) Random Shifting: In each round, each server in ToR talks to servers in up to 10 randomly selected ToRs. In this pattern, many ToRs may simultaneously talk to one ToR, creating hotspots and communication bottlenecks.</p><p>6) Increasing Destinations: We gradually increase the number of destinations for each ToR from 4 to 79 (i.e., all-to-all communications) to further investigate the impact of traffic spread on OSA performance.</p><p>Evaluation Metrics: First, we measure the network bisection bandwidth provided by OSA for each communication pattern. Then, we quantify the impact of the flexible topology and flexible link capacity of OSA architecture respectively. Finally, we measure the time cost of the control algorithm described in Section IV-B. The experiments are conducted on a Dell Optiplex machine with Intel 2.33 GHz dual-core CPU and 4 GB memory.</p><p>Hybrid Structure Model: We simulate the hybrid structure model introduced in Section III-C, which captures the key features of c-Through and Helios. To optimize the network to the traffic demand, we run the maximum weighted matching to determine which optical circuits to establish. Then, we calculate how much of the remaining demand can be satisfied by the electrical network at best.</p><p>Traditional 2:1 Oversubscribed Network: We also simulate a 2:1 oversubscribed electrical network whose details were described earlier in Section III-C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evaluation Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Performance of OSA:</head><p>In this experiment, the topology and link capacities are adaptively adjusted to the current traffic pattern. As soon as traffic pattern changes, the network reconfigures its topology instantaneously. In practice, the performance of OSA would be also impacted by the time taken to estimate the traffic demand, the time taken by the algorithms to identify the appropriate topology, and the reconfiguration time of the optical devices. Experimental results from our prototype will encompass all these overheads (Section VI).</p><p>Fig. <ref type="figure" target="#fig_3">4</ref> shows the average network bisection bandwidth over 100 instances of each traffic pattern obtained by different DCN  structures. Note that all the results are normalized by the bisection bandwidth of the nonblocking scenario. We make the following observations. First, we find that OSA delivers high bisection bandwidth (60%-100% of the nonblocking network) for both the real and synthetic traffic patterns. Under the Mapreduce-demand, OSA can provide over 80% of the nonblocking bandwidth. This is because OSA adaptively changes its topology and link capacities according to the present traffic pattern. In our simulation setting, we choose 4-regular graph for OSA-that is why we are still 20% from the nonblocking given the communication distribution shown in Fig. <ref type="figure" target="#fig_4">5</ref>. Because some ToRs talk to more than four (up to eight) other ToRs, OSA cannot assign direct circuits to feed all these communications. The multihop routing possibly causes congestion on the intermediate switches, leading to performance degradation. From the figure, we find that OSA delivers higher bandwidth (90% of the nonblocking) for the measurement-based pattern because it has relatively less hotspots compared to the previous one.</p><p>Second, when each ToR communicates with four other ToRs (in the ToR-level shifting pattern), OSA achieves bisection bandwidth nearly identical to that of the nonblocking network. This result is not surprising given that OSA allows a 4-regular graph and hence provides four optical circuits at each ToR to perfectly support the demand. Note that the traditional 2:1 oversubscribed network delivers 50% of the nonblocking for all the traffic patterns.</p><p>Third, in our results (not shown here due to lack of space), we observe that the bisection bandwidth achieved by OSA oscillates periodically from approximately 60% to 100% (with the average at 80%) of the nonblocking for the server-level shifting pattern. This is because each ToR would periodically communicate with four and six other ToRs in such traffic pattern. We further observe that the bisection bandwidth obtained by OSA in the random shifting pattern is the worst-60% of the nonblocking. This is expected since the number of peers each ToR communicates with is larger than the other two shifting patterns. Specifically, for the ToR-level shifting, a ToR talks to four other peers. For the server-level shifting, a ToR communicates with four to six peers. For the random shifting pattern, a ToR communicates with 5-20 peers. As discussed above, when the number of communication peers for a ToR is larger than four, some flows will necessarily use multihop paths causing performance degradation. Concretely, most paths are direct for the ToR-level shifting, most paths are direct or 2 hops for the server-level shifting, and most paths are increased to 2-6 hops for the random shifting. Those flows passing through multiple hops would contend for the available bandwidth at the intermediate switches, limiting the maximal achievable throughput.</p><p>Next, we present the bisection bandwidth achieved by OSA with an increasing number of inter-ToR communications. As it moves gradually to the all-to-all communication (Fig. <ref type="figure" target="#fig_5">6</ref>), as expected, the network bisection bandwidth drops due to the extensive bandwidth contention at the ToRs. Note that the traditional 2:1 oversubscribed network would continue to perform at 50% of nonblocking. This result is presented only for comparison purposes since OSA is not designed for the uniform all-to-all communication.</p><p>Furthermore, we note that OSA outperforms the hybrid model by 80%-250% in our evaluation. This is not a surprising result because the hybrid model only has a perfect matching between ToRs in the optical part. This means that one ToR is able to talk to one other ToR at a time. We increase oversubscription ratios in the electrical part from 32:1 to 8:1 and see only incremental improvement due to the oversubscribed network. In contrast, in OSA-2560, we have a 4-regular graph, meaning one ToR can directly communicate with four other ToRs simultaneously. Furthermore, OSA also dynamically adapts its link capacities to the traffic demand. The higher flexibility of OSA leads to its better performance.</p><p>In Fig. <ref type="figure" target="#fig_6">7</ref>, we inspect the performance delivered by OSA with varied values (left) and the number of hops traversed by the traffic (right) using the Mapreduce-demand. We assume that there are always 80 ToRs. It is evident from the left figure that with a larger value, the network bisection bandwidth delivered is higher. However, the larger value also necessitates more MEMS ports in order to support the same number of ToRs and servers. Note that , where we see low performance, is exactly equivalent to the optical part of the hybrid structure. From the right figure, we find that, for our case of OSA-2560 (i.e.,</p><p>), the vast majority of traffic only traverses less than 3 hops-over 60% of traffic goes one hop, and over 30% of  traffic goes two hops. We also find that with a small value, a considerable portion of traffic needs to traverse multiple hops to reach the destinations. When increases, more traffic will go fewer hops, indicating better network performance. Though not shown, the similar trends hold for the remaining traffic patterns.</p><p>2) Effect of Flexible Topology and Link Capacity: We quantify the effect of the flexible topology and flexible link capacity respectively. For this purpose, in the first experiment we randomly select a fixed topology (e.g., the one generated by the first instance of a traffic pattern) and only adjust the link capacity according to the current traffic pattern. In the second experiment, we hypothetically assume each link has eight fixed wavelengths assigned (thus static link capacity) and only adjust the topology based on the current traffic pattern. Fig. <ref type="figure" target="#fig_7">8</ref> shows the bisection bandwidth of both scenarios and the original OSA. Comparing the static topology scenario to OSA, we observe up to % % % % improvement due to the flexible topology in case of the ToR-level shifting pattern. Comparing the static link capacity scenario to OSA, we observe up to % % % % improvement because of the flexible link capacity in case of the measurement-based traffic pattern. These results suggest that the flexible topology and link capacity are essential to improve the performance of OSA.</p><p>3) Time Cost of Control Algorithm: We measure the time cost of the OSA control algorithm as described in Section IV-B. We run our current software implementation with 50 randomly selected traffic patterns that we used above and compute the average value for each step. As shown in Table <ref type="table" target="#tab_1">III</ref>, the total time is 290 ms. We observe that out of the four steps, the traffic demand estimation is dominant (161 ms). The reason is that the algorithm for this step is based on the number of servers, while the rest are based on the number of ToRs. Note that our demand estimation algorithm is adopted directly from Hedera <ref type="bibr" target="#b21">[22]</ref>, which has recently been shown to consume less than 100 ms for large </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE III TIME CONSUMPTION OF THE CONTROL ALGORITHM</head><p>data centers via parallelization over multiple cores or machines. This means there is a large room to speed up with advanced technologies.</p><p>Though most of the remaining steps take only tens of milliseconds, we still believe optimizations are possible throughout the control software to make it more responsive even for larger networks. For instance, -matchings for 1024 nodes could be computed in as few as 250 ms in the year 2000 with contemporary hardware <ref type="bibr" target="#b22">[23]</ref>. It is also likely that better-performing, faster heuristics can be built based on more accurate models of the traffic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. IMPLEMENTATION</head><p>We have built a small-scale OSA prototype with real optical devices (Fig. <ref type="figure" target="#fig_8">9</ref>). We first introduce our testbed setup, and then present our experiments over it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Testbed Setup</head><p>Our testbed connects 32 end-hosts, uniformly distributed in eight racks. To reduce the cost, we configure eight Dell Optiplex servers to emulate 32 end-hosts. Each server acts as a virtual rack of end-hosts (V-Rack), running four virtual-machines (VMs) to emulate four end-hosts.</p><p>We now do not have programmable ToR switches, so we use high-end servers to emulate ToRs. We have four Dell Pow-erEdge servers, each equipped with an Intel 2.4 GHz quadcore CPU, 8 GB DRAM, and 12 1 GigE NICs. On each such server, we deploy two VMs, giving us a total of eight virtual ToRs (V-ToRs). Each V-ToR binds to six NICs: One is connected to one V-Rack, one is used for a control connection to the OSA manager, and the remaining four are used as uplinks to reach other V-ToRs via optical elements.</p><p>On top of each V-ToR is a 1 4 CoAdna WSS, a coupler, a circulator, a 1 4 MUX and DEMUX pair, and four transceivers [which are packaged into a media converted (MC) unit]. As in Fig. <ref type="figure" target="#fig_1">2</ref>, each ToR uplink is connected to a transceiver, with the send-fiber of the transceiver connected through the MUX,  Furthermore, in our testbed, the OSA manager is a separate Linux server and talks to the OSM and ToRs via Ethernet ports, and to the WSS units via RS-232 serial ports.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Understanding the Optical Devices</head><p>Two critical optical devices in OSA are OSM and WSS. A common concern for them is the reconfiguration overhead. To measure the overhead, Fig. <ref type="figure" target="#fig_9">10</ref> shows the output power level on two ports of the OSM over time during a reconfiguration event. We see a clear transition period, i.e., from the high low output power level shift on one port, to the low high output power level shift on the other port. We observe that the switching delay of our OSM is 9 ms, consistent with <ref type="bibr" target="#b10">[11]</ref> and <ref type="bibr" target="#b13">[14]</ref>.</p><p>Next, we measure the reconfiguration time of the WSS by switching a wavelength channel between two output ports. As shown in Fig. <ref type="figure" target="#fig_10">11</ref>, this transition period is around 14 ms. However, the OSA manager can perform the reconfiguration of OSM and WSS in parallel to reduce the total time of reconfiguration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Understanding the O-E-O Conversion</head><p>To measure the impact of O-E-O conversion, we specially connect four servers as in Fig. <ref type="figure" target="#fig_11">12</ref> (left). Two servers in the middle are configured as routers and equipped with optical media converters. We create a routing loop by configuring the IP forwarding tables of the routers. In each router, we deploy a netfilter kernel module and utilize the NF_IP_PRE_ROUTING hook to intercept all IP packets. We record the time lag between the instant when the packets first arrive in the network and when their time to live (TTL) expires. This way, we are able to measure the multihop latency for O-E-O conversion and compare it to the baseline where all the servers are directly connected using only electrical devices. Results in Fig. <ref type="figure" target="#fig_11">12</ref> (right) compare the average one-hop switching latency for both the hybrid optical/electrical and pure electrical architectures under different traffic loads. It is evident from the figure that the O-E-O conversion does not incur noticeable (the maximum deviation in the absolute value and standard deviation is 38 and 58 s, respectively), if any, additional switching latency, demonstrating the feasibility of O-E-O employed by OSA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. OSA System Performance</head><p>We conduct two sets of experiments: One is for original OSA, and the other is for OSA with static topology. We use synthetic traffic patterns similar to Section V-A. More specifically, traffic is described by parameters : Servers in ToR send traffic to servers in ToRs, i.e., . We change from 1 to 7 to generate different traffic loads ( means all-to-all communication). For each , we vary from 1 to 7.</p><p>Our goal is to compare the achieved bisection bandwidth of OSA against that of a nonblocking network as the traffic spreads out (with increasing ) and to measure the effect of topology reconfiguration. Note that varying with a fixed does not produce fundamentally different traffic distributions, as it merely permutes which ToRs talk with which other ToRs, thus necessitating a change of topology without a change in traffic load or spread.</p><p>In our testbed, the server NICs support 10, 100, and 1000 Mb/s full-duplex modes. In all our experiments, we limit the maximum sending rate of each flow to be 100 Mb/s. This enables us to emulate a nonblocking network for comparison (Fig. <ref type="figure" target="#fig_12">13</ref>): For OSA, all the uplink ports of ToRs are set at 100 Mb/s, while for the nonblocking, we increase some particular uplink ports to be 1000 Mb/s to satisfy the traffic demands we simulate.</p><p>Results of OSA: Fig. <ref type="figure" target="#fig_13">14</ref> shows the average bisection bandwidth of OSA with changing traffic . For each steps 1 through 7 every 20 s. The network topology is dynamically reconfigured according to the current traffic demand. The  results are along expected lines. We observe that the achieved bisection bandwidth of OSA is within 95% of the nonblocking network when is 1 or 2. This is because when , each ToR talks with two other ToRs, and when , each ToR talks with four other ToRs. Given that our topology is a 4-regular graph, OSA assigns direct links to each pair of communicating ToRs for efficient communication. For , the performance of OSA decreases, along similar lines as in the simulation (Section V). A careful reader will notice that the performance of our testbed under the all-to-all communication is 58% of the nonblocking, much higher than that in our simulation results. The reason is simple: Our testbed has eightToRs, each having a degree 4, while our simulations used a sparse graph with 80 ToRs, each having a degree 4. Our intention of the testbed results is to demonstrate the feasibility of OSA rather than to show the performance achieved in a real deployment.</p><p>Next, Fig. <ref type="figure" target="#fig_14">15</ref> shows the impact of optical device reconfigurability on the end-to-end throughput between two hosts. We observe that the performance drops during reconfiguration, but quickly resumes after it finishes.</p><p>Finally, we also present the theoretical bisection bandwidth achievable in our testbed that ignores the overhead of reconfiguration, software routing, and TCP/IP protocol, etc. We observe that the gap between the theoretically achievable values and OSA is within 5%-7%, suggesting that our prototype implementation is efficient.</p><p>Results of OSA With a Static Topology: We randomly select a topology and run the same experiments as above. We present the results in Fig. <ref type="figure" target="#fig_15">16</ref>. Given the small diameter of our topology, the static topology OSA still achieves satisfactory performance. For example, in the worst case of all-to-all traffic (i.e.,</p><p>), static  OSA achieves more than 40% of the nonblocking network's bisection bandwidth. Since all the paths are 1 or 2 hops long, even the randomly selected topology performs satisfactorily.</p><p>For different values, we find that the performance of OSA on the static topology is lower than that on the dynamic topology by 10%-40%. This is because the topology is not optimized for the current traffic pattern. We expect that on a larger network where OSA topology is sparse (e.g., the one we used in Section V), this performance gap will become more pronounced, highlighting the need for a dynamically optimized network for better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Bulk Data Transfer</head><p>We study how the network reconfiguration and multihop routing affect the bulk data transfer, i.e., elephant flows.</p><p>Impact of Network Reconfiguration: We periodically reconfigure the network and observe the completion time of transferring a chunk of data (a 100-MB file transferred using scp) during the reconfiguration events. We present the mean value of 100 trials. Fig. <ref type="figure" target="#fig_16">17</ref> shows our results and the baseline performance where no reconfiguration takes place. The stability time is defined as the lifetime for a single static topology, after which the network is reconfigured. We notice that the completion time increases in the presence of reconfigurations. After analyzing the network trace using tcpdump, we observed that the round-trip time (RTT) and accordingly the initial retransmission time out (RTO) values in data centers are very small (submillisecond level), while network reconfiguration requires tens of milliseconds. As a consequence, each reconfiguration almost always triggers RTO events, after which TCP waits for  200 ms (Linux default RTO value) before the next retransmission, thereby degrading throughput and increasing latency. Recent work <ref type="bibr" target="#b28">[29]</ref>- <ref type="bibr" target="#b30">[31]</ref> has pointed out TCP's RTO issues in data centers and proposed to reduce it to the microsecond level by employing fine-grained timers. We expect TCP's performance in OSA under network reconfiguration to significantly improve once these changes are adopted. We also note from the figure that the completion time decreases as the stability time increases-larger stability period results in fewer network state changes and thus fewer RTO events during the course of data transfer.</p><p>Impact of Multihop Routing: Our prototype topology is a low-diameter network due to an 8-node 4-regular graph. In order to evaluate the impact of multihop routing on bulk data transfer, we rearrange our eight ToRs in a line topology with a larger diameter. In Fig. <ref type="figure" target="#fig_17">18</ref>, we measure the completion time of data transfer (transferring a 100-MB file using scp) with increased hops. Specifically, we consider two cases: 1) the network is free of background traffic; 2) all the links are saturated by background elephant TCP flows. From the figure, we find that in both cases the completion time is relatively consistent regardless of the number of hops. These results imply that the influence of multihop O-E-O conversion during data transfer on our testbed is small, which is coherent with our observation in Section VI-C. We also observe a nearly constant gap between the two curves, which is due to the different link utilization in the two cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Mice Flow Transfer</head><p>After inspecting the performance of bulk data transfer, we further check the impact of multihop routing on transferring mice flows. For this purpose, we use ping to emulate latency sensitive flows and evaluate its performance with and without background traffic as above. Fig. <ref type="figure" target="#fig_18">19</ref> shows the average RTT of  100 ping packets with varying path lengths. As expected, the RTT increases with more hops: 1 ms without background traffic and 2 ms with full background traffic, respectively, after 7 hops. These results suggest that the hop-by-hop stitching of optical links is a feasible approach to provide the overall connectivity. We note that network reconfiguration may have nontrivial impact on the latency-sensitive flows transfer since it happens on the order of 10 ms. We further discuss options to handle such issues in Section VII.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. DISCUSSION AND RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Mice Flow During Reconfiguration</head><p>OSA ensures that all the ToRs are in a connected graph and uses the hop-by-hop stitching of existing circuits to provide overall network connectivity. However, during the network reconfiguration, a pair of ToRs may be temporarily disconnected for around 10 ms. While this can be largely tolerated by latency-insensitive applications such as Mapreduce or Dryad, it would affect those operating with latency-sensitive mice flows like Dynamo <ref type="bibr" target="#b31">[32]</ref>.</p><p>In Fig. <ref type="figure" target="#fig_19">20</ref>, we estimate, in the worst case, how many mice flows (in terms of flow count and size) can be potentially affected due to the reconfiguration. We use the production data center traffic from Section V-A and use 10 MB to differentiate the elephant flows from the small ones. We find that for this particular dataset, when the stability time varies from 9 to 2 s, there are 1% to 4.5% of the mice flows that can be affected during the reconfigurations. This implies that as the network experiences more frequent reconfigurations, a larger fraction of mice flows may get affected. We next discuss two possible options to handle this issue.</p><p>Our basic idea is to reserve a static, connected channel in OSA network. To do so, we can reserve a small number of wavelengths and MEMS/WSS ports that are never reconfigured, and mice flows are sent over them. Such a channel can be simply a spanning tree or other connected topologies. Given the topology of the channel is controlled by the MEMS, we can arrange it in a low-diameter manner so that the transmission of mice flows is optimized. However, this approach consumes expensive MEMS/WSS ports, which otherwise can be better utilized for other applications or at stable time.</p><p>An alternative approach to building the channel without using MEMS/WSS ports is directly connecting all the ToRs together to form a ring or a star network. For the ring, we can reserve two ports on each ToR and directly connect them iteratively. In case of OSA-2560 with 80 ToRs, the diameter is 40 hops. To reduce the path length, it is possible to reserve more ports on each ToR and connect them structurally using DHT techniques <ref type="bibr" target="#b32">[33]</ref>, e.g., the diameter is expected to be 3-4 hops with high probability for 80 ToRs if we reserve four ports on each ToR. Another option is to employ one additional central electrical switch-each ToR uses one port to connect to the central switch. Note that, in Helios or c-Through, the electrical switches (usually forming a tree or even a multiroot tree) are used for overall connectivity among all the Pods/ToRs. In OSA, the all-to-all connectivity is maintained by optical components. A comprehensive evaluation and comparison of these solutions is part of our ongoing work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. OSA Applicability Versus Traffic Properties</head><p>For the all-to-all traffic, the nonoversubscribed network is indeed more appreciated. However, such workloads are neither reflected in our dataset nor in the measurements elsewhere <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b27">[28]</ref>. Our flexible OSA architecture would work best when the traffic pattern is skewed and stable on the order of seconds. It has been noted in <ref type="bibr" target="#b4">[5]</ref> over the measurements of a 1500-server production DCN that "only a few ToRs are hot and most of their traffic goes to a few other ToRs." Another study <ref type="bibr" target="#b1">[2]</ref>, also on a 1500-server production DCN, shows that more than 90% of bytes are in elephant flows. Regarding the traffic stability, a similarly sized study <ref type="bibr" target="#b33">[34]</ref> shows that 60% of ToR-pairs see less than 20% change in traffic demands for between 1.6 to 2.2 s on average. Despite these, we expect that OSA may exhibit undesirable performance degradation if the traffic pattern is highly dynamic, in which case any topology adaptation mechanism may be unsuitable as the situation changes instantaneously. In practice, the infrastructure manager should choose the proper sensitivity of OSA according to the operational considerations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Scalability</head><p>The current OSA design focuses on the container-size DCNs. To scale, we may confront several challenges. The first one is the MEMS's port density. While the 1000-port MEMS is theoretically feasible, the largest MEMS as of today has 320 ports. One natural way to increase the port density is via interconnecting multiple small MEMS switches. However, this poses additional requirement for fast, coordinated circuit switching.</p><p>Second, larger network size necessitates more control and management overhead. In our OSA-2560 with 80 ToRs, all the intelligences, e.g., the network optimization and routing, are handled by the OSA manager. How to handle such tasks in a larger DCN with thousands of ToRs is an open question especially when the network environment is dynamic. Furthermore, circuit visit delay <ref type="bibr" target="#b13">[14]</ref> is another issue to notice when scaling. We are considering all these challenges in our continuous effort designing a scalable optical DCN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Closely Related Work</head><p>OSA's design goals are closely related to those of c-Through <ref type="bibr" target="#b13">[14]</ref> and Helios <ref type="bibr" target="#b10">[11]</ref>. In both approaches, flows requiring high bandwidth are dynamically provisioned on optical circuits, while a parallel electrical network is used to provide overall connectivity. OSA differs from these prior proposals in its degree of flexibility and its architecture. Both Helios and c-Through achieve some topology flexibility via a limited number of single-hop optical links. In their optical parts, one ToR only connects to one other ToR at a time. While it can connect to different ToRs at different time, the switching latency would be around 10 ms. On the contrary, in OSA, one ToR can connect to multiple ToRs simultaneously at a time, and multihop connection exists between any pair of remote ToRs through the hop-by-hop circuit stitching. Furthermore, OSA allows the link capacities to be adjusted on the fly. Unlike these existing hybrid architectures, OSA avoids using electrical components other than the ToR switches.</p><p>OSA is more comparable to c-Through than Helios because its current target is interrack DCNs with a few thousand servers, unlike Helios' intercontainer mega-DCN scale. Qualitatively, OSA provides more flexibility than either Helios or c-Through and is able to serve a larger space of skewed traffic demands with performance similar to that of the nonblocking network. We present a coarse quantitative comparison to an abstract hybrid architecture model in Section V, showing that OSA achieves significantly higher bisection bandwidth.</p><p>Recently, Kandula et al. <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b14">[15]</ref> proposed to dynamically configure 60-GHz short-distance multi-Gigabit wireless links between ToRs to provide additional bandwidth for hotspots. Optical and wireless interconnects provide different tradeoffs. For example, wired optical interconnects can deliver much more bandwidth at lower power consumption over long distance, while the wireless has lower costs and is easier to deploy though the management and interference are challenging issues to deal with.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</head><p>In this paper, we have presented OSA, a novel Optical Switching Architecture for DCNs. OSA is highly flexible because it can adapt its topology as well as link capacities to different traffic patterns. We have evaluated OSA via extensive simulations and prototype implementation. Our results suggest that OSA can deliver high bisection bandwidth (60%-100% of the nonblocking network) for a series of traffic patterns. Our implementation and evaluation with the OSA prototype further demonstrate its feasibility.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. OSA adapts the topology and link capacities to the changing traffic.</figDesc><graphic coords="2,337.02,64.14,184.98,136.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Overall OSA architecture; detailed structure is shown only for for clarity.</figDesc><graphic coords="3,304.98,64.14,246.00,142.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Steps in the OSA control algorithm.</figDesc><graphic coords="6,54.00,63.12,222.00,58.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Average network bisection bandwidth (normalized) achieved for different communication patterns.</figDesc><graphic coords="7,304.98,64.14,246.00,84.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Number of ToRs each ToR communicates with in every instance of the Mapreduce-demand pattern.</figDesc><graphic coords="7,334.98,192.12,184.98,85.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Network bisection bandwidth with an increasing number of peers with whom each ToR communicates.</figDesc><graphic coords="8,73.02,63.12,184.98,94.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Performance of OSA with (left) varied values and (right) the number of hops traversed by traffic.</figDesc><graphic coords="8,306.00,63.12,246.00,108.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Effect of flexible topology and flexible link capacity.</figDesc><graphic coords="8,325.02,214.14,208.98,97.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. OSA testbed.</figDesc><graphic coords="9,79.98,63.12,168.00,126.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Switching time of our OSM.</figDesc><graphic coords="9,344.04,64.14,166.92,112.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Switching time of our WSS.</figDesc><graphic coords="9,344.04,211.14,166.92,115.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Impact of O-E-O conversion.</figDesc><graphic coords="10,42.00,64.14,246.00,103.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Make a nonblocking network from OSA.</figDesc><graphic coords="10,333.00,66.12,192.00,88.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Average bisection bandwidth of OSA.</figDesc><graphic coords="10,345.00,204.12,168.00,138.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Throughput of a flow in the presence of reconfigurations.</figDesc><graphic coords="11,80.04,64.14,166.92,130.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Average bisection bandwidth of OSA with a static topology.</figDesc><graphic coords="11,79.98,227.16,168.00,135.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. Impact of topology reconfiguration on bulk data transfer.</figDesc><graphic coords="11,345.00,64.14,166.02,112.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 18 .</head><label>18</label><figDesc>Fig. 18. Impact of multihop routing on bulk data transfer.</figDesc><graphic coords="11,345.00,212.16,166.02,110.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 19 .</head><label>19</label><figDesc>Fig. 19. Impact of multihop routing on simulated mice flows.</figDesc><graphic coords="12,82.02,64.14,166.98,111.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 20 .</head><label>20</label><figDesc>Fig. 20. Potentially affected mice flows during network reconfiguration.</figDesc><graphic coords="12,81.00,211.14,168.00,156.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I COST</head><label>I</label><figDesc>(USD) AND POWER (WATT) PER PORT FOR DIFFERENT ELEMENTS. WE REFER SOME OF THE VALUES FROM HELIOS<ref type="bibr" target="#b10">[11]</ref> </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II COST</head><label>II</label><figDesc>, POWER, WIRING (# OF INTER-TOR LINKS) AND PERFORMANCE FOR DIFFERENT NETWORKS TO SUPPORT 2560 SERVERS WITH 10G PORTS. ( FOR TRAFFIC PATTERNS WE EVALUATE IN SECTION V)</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We note that, while each ToR connects to one other ToR in c-Through, one Pod can connect to one or multiple other Pods at the expense of consuming more MEMS ports in Helios.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors thank CoAdna Photonics and Polatis for the equipment support of WSS and OSM respectively, G. Liao for helpful discussions on WSS properties, and D. DePaolo for help during the testbed setup. The authors thank their NSDI shepherd D. Andersen, the anonymous IEEE/ACM TRANSACTIONS ON NETWORKING and NSDI reviewers, and C. Guo for their valuable comments.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A scalable, commodity data center network architecture</title>
		<author>
			<persName><forename type="first">M</forename><surname>Al-Fares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Loukissas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGCOMM</title>
		<meeting>SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="63" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">VL2: A scalable and flexible data center network</title>
		<author>
			<persName><forename type="first">A</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lahiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Maltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sengupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="51" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">PortLand: A scalable fault-tolerant layer 2 data center network fabric</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Mysore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pamboris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Farrington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Miri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Radhakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Subramanya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<publisher>ACM SIG-COMM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="39" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">BCube: A high performance, server-centric network architecture for modular data centers</title>
		<author>
			<persName><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="63" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Flyways to de-congest data center networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Padhye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM HotNets</title>
		<meeting>ACM HotNets</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On the feasibility of optical circuit switching for high performance computing systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Benner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hoare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hoisie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Kerbyson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Melhem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rajamony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stunkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SC</title>
		<meeting>SC</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Data center networks are in my way</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hamilton</surname></persName>
		</author>
		<ptr target="http://mvdirona.com/jrh/TalksAndPapers/JamesHamilton_CleanSlateCTO2009.pdf" />
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Scaling optical interconnects in datacenter networks opportunities and challenges for WDM</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Symp. High Perform. Interconnects</title>
		<meeting>IEEE Symp. High Perform. Interconnects</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="113" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Fiber optic communication technologies: What&apos;s needed for datacenter network operations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Koley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kamalov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Google eyes &apos;optical express&apos; for its network</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rath</surname></persName>
		</author>
		<ptr target="http://www.datacenterknowledge.com/archives/2010/05/24/google-eyes-optical-express-for-its-network/" />
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Helios: A hybrid electrical/optical switch architecture for modular data centers</title>
		<author>
			<persName><forename type="first">N</forename><surname>Farrington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Radhakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Bazzaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Subramanya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fainman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Papen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="339" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">40G Ethernet-Closer than ever to an all-optical network</title>
		<ptr target="http://cir-inc.com/resources/40-100GigE.pdf" />
	</analytic>
	<monogr>
		<title level="j">Communications Industry Researchers</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<pubPlace>Charlottesville, VA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The imminent reality of 40 and 100 Gigabit Ethernet</title>
		<author>
			<persName><forename type="first">K</forename><surname>Patel</surname></persName>
		</author>
		<ptr target="http://www.nxtbook.com/nxtbooks/bicsi/news_20100910/index.php?startid=39" />
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">c-Through: Part-time optics in data centers</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kaminsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Papagiannaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S E</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kozuch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ryan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="327" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Augmenting data center networks with multi-gigabit wireless links</title>
		<author>
			<persName><forename type="first">D</forename><surname>Halperin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Padhye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wetherall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="38" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Regular graphs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Meringer</surname></persName>
		</author>
		<ptr target="http://www.mathe2.uni-bayreuth.de/markus/reggraphs.html" />
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Beam steering optical switch fabric utilizing piezoelectric actuation technology</title>
		<author>
			<persName><forename type="first">T</forename><surname>Truex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Bent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Hagood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NFOEC</title>
		<meeting>NFOEC</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">1100 1100 port MEMS-based optical crossconnect with 4-dB maximum loss</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Nuzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Lieuwen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Lichtenwalner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Papazian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Frahm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Basavanhally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Ramsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Aksyuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-E</forename><forename type="middle">E</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Lifton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Haueis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Gasparyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Shea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Arney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Bolle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Kolodner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Ryf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Neilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Gates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Photon. Technol. Lett</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1537" to="1539" />
			<date type="published" when="2003-11">Nov. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">BCM56840 series enables mass deployment of 10 GbE in the data center</title>
		<author>
			<persName><forename type="first">Irvine</forename><surname>Broadcom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Usa</surname></persName>
		</author>
		<ptr target="http://www.broadcom.com/products/features/BCM56840.php" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Generic and automatic address configuration for data center networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGCOMM</title>
		<meeting>SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="39" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Approximation algorithms for degree-constrained bipartite network flow</title>
		<author>
			<persName><forename type="first">E</forename><surname>Akcali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ungor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ISCIS</title>
		<meeting>ISCIS</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="163" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Hedera: Dynamic flow scheduling for data center networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Al-Fares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Radhakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NSDI</title>
		<meeting>NSDI</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Implementing weighted bmatching algorithms: Insights from a computational study</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mller-Hannemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Algor</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">8</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">LEMON-Library</title>
		<ptr target="http://lemon.cs.elte.hu" />
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Finding low-diameter, low edge-cost, networks USC</title>
		<author>
			<persName><forename type="first">K</forename><surname>Obraczka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Danzig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<pubPlace>Los Angeles, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Edge-coloring</title>
		<ptr target="http://en.wikipedia.org/wiki/Edge_coloring" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A constructive proof of Vizing&apos;s theorem</title>
		<author>
			<persName><forename type="first">J</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gries</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Process. Lett</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="131" to="133" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Network traffic characteristics of data centers in the wild</title>
		<author>
			<persName><forename type="first">T</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Akella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Maltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IMC</title>
		<meeting>IMC</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="267" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Understanding TCP incast throughput collapse in datacenter networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Griffith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Joseph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM WREN</title>
		<meeting>ACM WREN</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="73" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Safe and effective finegrained TCP retransmissions for datacenter communication</title>
		<author>
			<persName><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Phanishayee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Krevat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Ganger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="303" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">ICTCP: Incast congestion control for TCP</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM CoNEXT</title>
		<meeting>ACM CoNEXT</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dynamo: Amazon&apos;s highly available key-value store</title>
		<author>
			<persName><forename type="first">G</forename><surname>Decandia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hastorun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kakulapati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lakshman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pilchin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sivasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vosshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SOSP</title>
		<meeting>SOSP</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="205" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Pastry: Scalable, decentralized object location and routing for large-scale peer-to-peer systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rowstron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Druschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Middleware</title>
		<meeting>Middleware</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="329" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The case for finegrained traffic engineering in data centers</title>
		<author>
			<persName><forename type="first">T</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Akella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. USENIX INM/ WREN</title>
		<meeting>USENIX INM/ WREN</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
