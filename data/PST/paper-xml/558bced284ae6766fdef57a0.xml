<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Retinal vessel segmentation by improved matched filtering: evaluation on a new high-resolution fundus image database</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Jan</forename><surname>Odstrcilik</surname></persName>
							<email>odstrcilik@feec.vutbr.cz</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Biomedical Engineering</orgName>
								<orgName type="department" key="dep2">Faculty of Electrical Engineering and Communication</orgName>
								<orgName type="institution">Brno University of Technology</orgName>
								<address>
									<addrLine>Technicka 12</addrLine>
									<postCode>61600</postCode>
									<settlement>Brno</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">St. Anne&apos;s University Hospital -International Clinical Research Center (ICRC)</orgName>
								<address>
									<addrLine>Pekarska 53</addrLine>
									<postCode>65691</postCode>
									<settlement>Brno</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Radim</forename><surname>Kolar</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Biomedical Engineering</orgName>
								<orgName type="department" key="dep2">Faculty of Electrical Engineering and Communication</orgName>
								<orgName type="institution">Brno University of Technology</orgName>
								<address>
									<addrLine>Technicka 12</addrLine>
									<postCode>61600</postCode>
									<settlement>Brno</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">St. Anne&apos;s University Hospital -International Clinical Research Center (ICRC)</orgName>
								<address>
									<addrLine>Pekarska 53</addrLine>
									<postCode>65691</postCode>
									<settlement>Brno</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Attila</forename><surname>Budai</surname></persName>
							<affiliation key="aff3">
								<orgName type="laboratory">Pattern Recognition Lab</orgName>
								<orgName type="institution">University of Erlangen-Nuremberg</orgName>
								<address>
									<addrLine>Martensstrasse 3</addrLine>
									<postCode>91058</postCode>
									<settlement>Erlangen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joachim</forename><surname>Hornegger</surname></persName>
							<affiliation key="aff3">
								<orgName type="laboratory">Pattern Recognition Lab</orgName>
								<orgName type="institution">University of Erlangen-Nuremberg</orgName>
								<address>
									<addrLine>Martensstrasse 3</addrLine>
									<postCode>91058</postCode>
									<settlement>Erlangen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiri</forename><surname>Jan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Biomedical Engineering</orgName>
								<orgName type="department" key="dep2">Faculty of Electrical Engineering and Communication</orgName>
								<orgName type="institution">Brno University of Technology</orgName>
								<address>
									<addrLine>Technicka 12</addrLine>
									<postCode>61600</postCode>
									<settlement>Brno</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiri</forename><surname>Gazarek</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Biomedical Engineering</orgName>
								<orgName type="department" key="dep2">Faculty of Electrical Engineering and Communication</orgName>
								<orgName type="institution">Brno University of Technology</orgName>
								<address>
									<addrLine>Technicka 12</addrLine>
									<postCode>61600</postCode>
									<settlement>Brno</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tomas</forename><surname>Kubena</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">Ophthalmology Clinic M.D. Tomas Kubena</orgName>
								<orgName type="institution" key="instit2">U zimniho stadionu</orgName>
								<address>
									<postCode>1759, 760 00</postCode>
									<settlement>Zlin</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pavel</forename><surname>Cernosek</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">Ophthalmology Clinic M.D. Tomas Kubena</orgName>
								<orgName type="institution" key="instit2">U zimniho stadionu</orgName>
								<address>
									<postCode>1759, 760 00</postCode>
									<settlement>Zlin</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ondrej</forename><surname>Svoboda</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Biomedical Engineering</orgName>
								<orgName type="department" key="dep2">Faculty of Electrical Engineering and Communication</orgName>
								<orgName type="institution">Brno University of Technology</orgName>
								<address>
									<addrLine>Technicka 12</addrLine>
									<postCode>61600</postCode>
									<settlement>Brno</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elli</forename><surname>Angelopoulou</surname></persName>
							<affiliation key="aff3">
								<orgName type="laboratory">Pattern Recognition Lab</orgName>
								<orgName type="institution">University of Erlangen-Nuremberg</orgName>
								<address>
									<addrLine>Martensstrasse 3</addrLine>
									<postCode>91058</postCode>
									<settlement>Erlangen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">IET Image Processing</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Retinal vessel segmentation by improved matched filtering: evaluation on a new high-resolution fundus image database</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1751-9659</idno>
					</monogr>
					<idno type="MD5">CECE3F8C4EA8D1D855CE0DCC05502DDD</idno>
					<idno type="DOI">10.1049/iet-ipr.2012.0455</idno>
					<note type="submission">Received on 17th August 2012 Revised on 16th January 2013 Accepted on 7th February 2013</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automatic assessment of retinal vessels plays an important role in the diagnosis of various eye, as well as systemic diseases. A public screening is highly desirable for prompt and effective treatment, since such diseases need to be diagnosed at an early stage. Automated and accurate segmentation of the retinal blood vessel tree is one of the challenging tasks in the computer-aided analysis of fundus images today. We improve the concept of matched filtering, and propose a novel and accurate method for segmenting retinal vessels. Our goal is to be able to segment blood vessels with varying vessel diameters in high-resolution colour fundus images. All recent authors compare their vessel segmentation results to each other using only low-resolution retinal image databases. Consequently, we provide a new publicly available high-resolution fundus image database of healthy and pathological retinas. Our performance evaluation shows that the proposed blood vessel segmentation approach is at least comparable with recent state-of-the-art methods. It outperforms most of them with an accuracy of 95% evaluated on the new database.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Digital imaging using a fundus camera is widely considered an integral part of medical examination in ophthalmology. Standard fundus images contain various regions which can be useful for diagnosis, such as the macula, which is usually examined in connection with age-related macular degeneration <ref type="bibr" target="#b0">[1]</ref>; the optic disc for examination of glaucoma <ref type="bibr" target="#b1">[2]</ref>; and vascular structures, which are mostly evaluated in the context of diseases affecting the circulatory system <ref type="bibr" target="#b2">[3]</ref>.</p><p>Several pathologies affecting the retinal vascular structures due to diabetic retinopathy (DR; neovascular nets, haemorrhages, microaneurysms) can be found in fundus images using precisely segmented blood vessels <ref type="bibr" target="#b3">[4]</ref>. Moreover, automatic retinal vessel segmentation algorithms can be useful in the evaluation of other diseases, such as arteriolar narrowing and vessel tortuosity due to hypertensive retinopathy <ref type="bibr" target="#b4">[5]</ref>, or glaucoma <ref type="bibr" target="#b5">[6]</ref>. Furthermore, vessel diameter, bifurcations and crossovers can be effectively measured on the segmented blood vessel tree to test for other cardiovascular diseases <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>A precise and accurate detection of the vascular tree in fundus images can provide several useful features for the diagnosis of various retinal diseases. However, retinal blood vessel segmentation can have a considerable impact on other applications, particularly when used as a preprocessing step for higher-level image analysis. For example, an accurate detection of the blood vessel tree can be used in registering time series fundus images <ref type="bibr" target="#b7">[8]</ref>, locating the optic disc or fovea <ref type="bibr" target="#b8">[9]</ref>, detecting retinal nerve fibre layer <ref type="bibr" target="#b9">[10]</ref>, or in the field of biometric identification <ref type="bibr" target="#b10">[11]</ref>.</p><p>Owing to the wide range of applications, and because the segmentation of retinal vessels is one of the most challenging tasks in the field of retinal image analysis, there is a considerable body of work on this topic (see <ref type="bibr">Section 2)</ref>.</p><p>We propose a novel and precise methodology for accurate retinal vessel tree segmentation at a wide range of blood vessel sizes in high-resolution colour fundus images. Our method is based on matched filtering (MF) in combination with minimum error thresholding technique. An earlier version of our segmentation algorithm has been presented in <ref type="bibr" target="#b11">[12]</ref>. Here, we present extensions and improvements to this earlier work including a preprocessing step for non-uniform illumination correction and contrast normalization, and a more reliable thresholding algorithm. Although the preliminary results were qualitatively sufficient, the performance of our method has not been so far quantitatively evaluated. Nowadays, all authors compare their vessel segmentation results to each other using well-known retinal image databases such as DRIVE (digital retinal images for vessel extraction) <ref type="bibr" target="#b12">[13]</ref> or STARE (structured analysis of the retina) <ref type="bibr" target="#b13">[14]</ref>. Unfortunately, these databases contain only outdated low-resolution retinal images, which are inappropriate for the evaluation of methods for detecting fine blood vessel structures. Thus, as a main contribution to the field of retinal vessel segmentation, we provide a new publicly available high-resolution fundus (HRF) image database of healthy and pathological retinas with corresponding manually segmented images, which can be used as gold standards for quantitative evaluation of segmentation algorithms.</p><p>We evaluated the proposed method using the new high-resolution retinal image database and the widely used DRIVE and STARE databases as representative examples of the state-of-the-art. The quantitative analysis shows that the results are at least comparable with other recently published methods, outperforming most of them. Moreover, our method demonstrated the feasibility of reliable detection of the retinal vascular tree even in cases of glaucoma and DR, which affects the retina causing neovascularities, and haemorrhages. This latter capability was revealed during the evaluation on the new high-resolution database.</p><p>The paper is organised as follows. Section 2 gives an overview of the state-of-the-art in the field of retinal vessel segmentation algorithms. Section 3 describes the new fundus image database and the experimental data we used. Section 4 presents, in detail, the concepts of our blood vessel segmentation algorithm. Experimental results and discussion are provided in Section 5, whereas the conclusions are given in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">State-of-the-art</head><p>There is a considerable body of work on automatic retinal vessel segmentation <ref type="bibr" target="#b14">[15]</ref>. Depending on the underlying approach, most of the proposed methods can be grouped into one of the following categories: tracking-based, machine-learning-based, model-based or filter-based.</p><p>Tracking-based methods usually map out a vessel centerline and globally trace the vascular tree from seed points according to a relevant criterion. Recently, Vlachos and Dermatas proposed a blood vessel segmentation technique based on multi-scale line-tracking <ref type="bibr" target="#b15">[16]</ref>. Other representative methods of tracking-based vessel segmentation algorithms can be found in <ref type="bibr" target="#b16">[17]</ref> and <ref type="bibr" target="#b17">[18]</ref>, where a multi-directional graph search approach and Hough transform were utilised, respectively.</p><p>Machine-learning methods usually involve the supervised classification of image pixels as either belonging to retinal vessels or not. Such classifiers are trained on a dataset of image pixels, which have already been hand-labelled as retinal vessels or non-vessels. Staal et al. <ref type="bibr" target="#b12">[13]</ref> proposed a ridge-based blood vessel segmentation method in combination with a supervised classification technique. The proposed supervised classifier was trained and evaluated on 40 images of the DRIVE database. Another classification-based algorithm, which was also trained on the DRIVE database, was proposed by Ricci and Perfetti <ref type="bibr" target="#b18">[19]</ref>. They proposed the use of a support vector machine for classifying the vessel and non-vessel pixels. Marín et al. <ref type="bibr" target="#b19">[20]</ref> developed a supervised classification-based technique, which used a seven-dimensional feature vector composed of grey-level and invariant moment-based features. They then classified vessel pixels using an artificial neural network.</p><p>Another recent approach that employed the AdaBoost classifier was proposed by Lupascu et al. <ref type="bibr" target="#b20">[21]</ref>. In general, although recent supervised-learning-based methods provide overall good results, they typically utilise (for training) low-resolution images, resulting in low sensitivity to thin retinal vessel detection.</p><p>A variety of methods fall into the category of model-based retinal vessel segmentation. Consider, for example, Delibasis et al. <ref type="bibr" target="#b21">[22]</ref> published a new method for the segmentation of vascular trees and the calculation of blood vessel diameter and orientation. Lam et al. <ref type="bibr" target="#b22">[23]</ref> developed a method for the segmentation of retinal images containing bright and dark lesions. It utilised a regularization-based multiconcavity model of retinal vessel segments. Zhu et al. <ref type="bibr" target="#b23">[24]</ref> presented a universal model-based scheme for modelling blood vessel intensity profiles with varying boundary sharpness via a phase congruency approach. Other authors used an active contour model <ref type="bibr" target="#b24">[25]</ref> or model-based region growing segmentation approach <ref type="bibr" target="#b25">[26]</ref>.</p><p>In filter-based methods, retinal vessel segmentation is typically performed using mathematical morphology operations. In this way, prior knowledge of the vessel shapes is utilised to create a morphological structuring element, which is used for filtering objects from background <ref type="bibr" target="#b26">[27]</ref>. The method proposed by Soares et al. <ref type="bibr" target="#b27">[28]</ref> used wavelet filters. Furthermore, the well-known concept of MF is also commonly utilised in filter-based methods. The use of MF in retinal vessel segmentation algorithms was first introduced by Chaudhuri et al. <ref type="bibr" target="#b28">[29]</ref>. Since then, a number of MF approaches have been proposed for retinal vessel segmentation. Prior knowledge, that is assuming a Gaussian-shape blood vessel profile, is often employed. In this case, several two-dimensional Gaussian-shape masks in different orientations are usually convolved with the green channel of colour fundus images. The filter responses are then thresholded and fused to generate a binary map of the vascular tree. This concept has been recently published in <ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref>. Al-Rawi and Karajeh <ref type="bibr" target="#b29">[30]</ref> improved the basic MF technique by combining it with genetic algorithms. Another approach proposed by Cinsdikici and Aydin <ref type="bibr" target="#b30">[31]</ref> was inspired by real ant colonies. They presented a novel hybrid model consisting of MF and an ant colony classification algorithm. The method is designed to overcome the deficiencies of using MF alone, especially its insufficiency to recover all retinal vessels (particularly capillaries) in the image. Nevertheless, the algorithm is tested using the DRIVE database which contains low-resolution images, where capillaries are barely visible. The method proposed by Zhang et al. <ref type="bibr" target="#b31">[32]</ref> presents a standard MF scheme supplemented by the first-order derivative of Gaussian. The method is presented as a reliable approach, which reduces the false-positive detections produced by the original MF method. The method also offers detection of very fine vessel structures, however the evaluation is performed only on low-resolution images.</p><p>Although there are many methods utilising diverse approaches for segmenting the blood vessel tree on fundus images, they are developed and also ultimately tested using publicly available, but low-resolution image databases (e.g. DRIVE and STARE). The true capacity of these methods to segment very fine vascular structures, including capillaries and neovascularised blood vessels, remains an unknown and is often limited. Applying them on image data of higher resolution may be only a question of parameter adjustment. However, not all methods can be easily adapted to higher resolution data. A number of them will probably fail on currently available high-resolution fundus images.</p><p>Fundus images usually exhibit specular reflectance on thick blood vessels. In this case, filter-based methods may fail because of the wrong interpretation of specular reflection as a blood vessel edge. Some authors try to solve this problem by downsampling the original image, for example <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b32">33]</ref>. However, this might lead to loss of information in the vessel structures or in indicators for retinal pathologies.</p><p>This paper presents a novel methodology for the precise detection of retinal vessel structures in a wide range of vessel widths. Our method allows the detection of fine blood vessel structures with diameter 3-5 pixels using currently available high-resolution fundus images. The proposed technique solves a common problem of the filter-based methods with the specular reflectance on the large (thick) retinal vessels, and is able to segment the largest retinal vessels as a solid structure without artefacts due to the incorrect matching of the edges.</p><p>We also present a new publicly available HRF image database of healthy and pathological eyes. Gold standard images of manually segmented blood vessels are also provided as part of the database. Thus, our database is used not only in the development and performance evaluation of our method, but also as a benchmark dataset for other authors to evaluate and compare their algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">High-resolution fundus image database</head><p>Three databases of retinal images are utilised in this paper. Primarily, the new HRF image database has been created as a new possibility for evaluation of the method's performance. Then, most commonly used DRIVE <ref type="bibr" target="#b12">[13]</ref> and STARE <ref type="bibr" target="#b13">[14]</ref> databases are utilised also for evaluation of our method and particularly for the comparison with other recent approaches in the literature.</p><p>The HRF database has been newly established by a collaborative research group consisting of two European institutions: Brno University of Technology, Faculty of Electrical Engineering and Communication, Department of Biomedical Engineering, Brno, Czech Republic, and Pattern Recognition Lab at the University of Erlangen -Nuremberg, Germany. The goal of this dataset is to support comparative studies on automatic segmentation algorithms on retinal images, especially high-resolution ones. The database can be downloaded from the public website: 'http://www5. informatik.uni-erlangen.de/research/data/fundus-images'.</p><p>This database contains three sets of fundus images: one of healthy retinas, one of glaucomatous and one of DR retinas. The first set is composed of 15 images of healthy patients without any retinal pathology. The second set includes 15 retinal images of patients with DR containing pathological changes, such as neovascular nets, haemorrhages, bright lesions and spots after laser treatment. The last group consists of 15 images of patients with glaucoma in advanced stage with symptoms of focal and diffuse nerve fibre layer loss. The second and third groups, thus, allow evaluation of the segmentation methods in the case of pathological retinas.</p><p>All fundus images were acquired with a mydriatic fundus camera CANON CF-60 UVi equipped with CANON EOS-20D digital camera with a 60-degree field of view (FOV). The image size is 3504 × 2336 pixels. The images were taken at the collaborating Tomas Kubena's Ophthalmology Clinic, Zlin, Czech Republic. Standard mydriatic drops were used to dilate the subjects' pupils. All images are 24 bits per pixel (True Color) and are stored in JPEG format with low compression rates, as is common in ophthalmological practice. For each image, a binary mask determining the FOV is provided, since the analysis is usually performed only in the area surrounded by dark background (Fig. <ref type="figure" target="#fig_0">1</ref>).</p><p>The images were manually and independently segmented by three experts working in the field of retinal image analysis.</p><p>They were trained by experienced ophthalmologists from the ophthalmology clinic where the images were taken and they were asked to label all pixels belonging only to retinal vessels. ADOBE Photoshop CS4 image editor was used for manual labelling of the images (Fig. <ref type="figure" target="#fig_0">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methods</head><p>An overview of the proposed methodology is as follows. The preprocessing step consists of illumination correction and contrast equalisation of the fundus images in preparation for further analysis. Only the green channel of an RGB image is utilised, since this channel has the highest contrast between blood vessels and other retinal structures. The segmentation of blood vessels in the preprocessed image utilises a MF approach. Five two-dimensional filters were designed according to typical blood vessel cross-sectional intensity profiles, whereas five different blood vessel widths were consideredfrom the thinnest to the thickest retinal vessels. The preprocessed image is convolved with each of the five kernels, each of which is rotated into 12 different orientations. The resulting parametric images are then fused so that the locally maximum response is selected for each pixel. The fused parametric image is then thresholded to obtain a binary map of the blood vessel tree. This is then further cleaned using morphological operators to remove small or short artefacts due to noise or other image structures that do not belong to the vascular tree. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Illumination correction and contrast equalisation</head><p>A B-spline-based illumination correction method is used as a preprocessing step to improve the accuracy of the proposed method. The non-uniform illumination correction is applied together with contrast enhancement. A multiplicative illumination model is used and the corrected image G is thus given as in <ref type="bibr" target="#b33">[34]</ref> </p><formula xml:id="formula_0">G = I b -b max + 128 (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where I is the original image and b is the background illumination model. The term (-b max + 128) ensures that the mean value of the reconstructed image will be ∼128 (for images with 256 grey levels). The background illumination model has been obtained by approximating the low-pass filtered image by a two-dimensional B-spline function as in <ref type="bibr" target="#b34">[35]</ref>. The kernel for the low-pass filtering was a simple averaging filter with 51 × 51 pixels for a given image size.</p><p>The size of the kernel was estimated to be able to sufficiently suppress all high-frequency components in the image (e.g. blood vessels, exudates and haemorrhages). This approach has been applied only on the green channel of RGB image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Two-dimensional matched filtering</head><p>The two-dimensional MF locally exploits the correlation between local image areas and 2D masks developed according to the appearance of typical blood vessel segments of different widths (diameters) and orientations. These masks were created by measuring numerous perpendicular cross-sectional intensity profiles of retinal vessels in the images from the HRF database. The cross-sectional profiles were heuristically classified into five classes of differing blood vessel thicknesses to achieve a reliable and precise detection of all possible blood vessel segments with an acceptable width resolution. Thus, 250 profiles were manually selected per blood vessel width class from all images in the database. For each width class, all its cross-sectional profiles were centred and then averaged in order to obtain a smoothed intensity profile for that class. The resulting averaged profiles cover a range of blood vessel diameters from 5 to 22 pixels, measured at a full-width at half-maximum of the cross-sectional profiles (Fig. <ref type="figure" target="#fig_1">2</ref>). The shape of the particular intensity profiles smeared by plain parallel back projection along the vessel axis thus represents pieces of retinal blood vessel structures from the thinnest blood vessels (Fig. <ref type="figure" target="#fig_1">2a</ref>) through thicker structures (Figs. <ref type="figure" target="#fig_1">2b</ref> and<ref type="figure">c</ref>) to the thickest ones, which appear with central light reflection (Figs. <ref type="figure" target="#fig_1">2d</ref> and<ref type="figure">e</ref>). The corresponding mask sizes are 14 × 14, 22 × 22, 24 × 24, 26 × 26 and 32 × 32 pixels. Hence, the particular width classes cover all types of blood vessels in a common fundus image. Particular kernels were then rotated into the angular direction j = 0, …, 165 degrees, with the angular step of 15 degrees in order to cover all possible directions of blood vessel segments. We assume a square shape of the obtained masks with the bilinearly interpolated pixel values for individual positions, which do not fit the image lattice during mask rotation. Thus, we obtained 12 differently oriented kernels for each of the width classes. The square shape of the 2D kernels was utilised as a compromise between signal-to-noise ratio (low for masks with short length) and maximal possible length of blood vessel segment fulfilling a condition of piecewise parallel edges.</p><p>Each kernel is then convolved with the preprocessed input image G(i, j). Thus, we obtain a number of 60 (5 × 12) parametric images (MFR k , j (i, j)matched filter responses) related to the corresponding width class and orientation of blood vessel segments. The magnitudes of the parametric images thus correspond to the degree of correlation between particular masks and the local areas in the image. The maximum filter response indicates the mask best matching the width and orientation of blood vessel segment contained in the respective image area. Non-existence of blood vessel in the area is indicated by a relatively low value of the filter response.</p><p>A joint parametric image is then obtained by selection of maximum response from the set of parametric images for particular pixels. Fig. <ref type="figure" target="#fig_2">3a</ref> shows resulting parametric image for the fundus image in Fig. <ref type="figure" target="#fig_0">1a</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Thresholding and postprocessing</head><p>The resulting parametric image is thresholded in order to obtain a binary representation of the vascular tree. The blood vessels are considered as a foreground (objects) and remaining parts as a background of the image, whereas only pixels inside the FOV are considered. The method utilised for thresholding belongs to the class of minimum error thresholding methods <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37]</ref>. These methods assume that the image can be formally characterised by mixture densities of foreground and background pixels <ref type="bibr" target="#b36">[37]</ref> p(g) = P(T) p f (g)</p><formula xml:id="formula_2">+ [1 -P(T)] p b (g)<label>(2)</label></formula><p>In this equation, p(g), g = 0, … ,G, where G is the maximum luminance value in the image, is referred to as a probability mass function (PMF). The terms p f (g), 0 ≤ g ≤ T, and p b (g),</p><formula xml:id="formula_3">T + 1 ≤ g ≤ G,</formula><p>where T is the threshold value, are thus the PMFs of the foreground and background pixels, respectively. P(T ) is the cumulative probability function defined as P(T ) = T g=0 p(g). The PMF p(g) can be simply estimated from one-dimensional image histogram by normalising it to the total number of samples <ref type="bibr" target="#b36">[37]</ref>.</p><p>The Kittler minimum error thresholding method <ref type="bibr" target="#b35">[36]</ref>, which is used here, assumes that the pixel values of object (i = f ) and background (i = b) are normally distributed with parameters mean µ i and variance σ 2 i , derived according to the equations <ref type="bibr" target="#b35">[36]</ref> </p><formula xml:id="formula_4">m i (T ) = 1 P i (T ) b g=a g p(g)<label>(3)</label></formula><formula xml:id="formula_5">s 2 i (T ) = 1 P i (T ) b g=a g -m i (T ) 2 p(g)<label>(4)</label></formula><formula xml:id="formula_6">P i (T ) = b g=a p(g)</formula><p>where</p><formula xml:id="formula_7">a = 0 i = f T + 1 i = b (5) b = T i = f G i = b<label>(6)</label></formula><p>An optimal threshold can then be derived by an iterative computation of the following equation <ref type="bibr" target="#b36">[37]</ref> T opt = arg min P(T ) log s f (T ) + [1 -P(T )] log s b (T )</p><formula xml:id="formula_8">-P(T ) log P(T ) -[1 -P(T )] log [1 -P(T )]}<label>(7)</label></formula><p>where σ f and σ b are foreground and background standard deviations, respectively.</p><p>Other thresholding methods, specifically standard Otsu method <ref type="bibr" target="#b37">[38]</ref> and the method based on the evaluation of local entropy from co-occurrence matrix <ref type="bibr" target="#b38">[39]</ref>, were tested as well. The results from all thresholding algorithms were evaluated and compared using the images from HRF database and it was found that the Kittler minimum error thresholding technique is the most reliable for our segmentation task.</p><p>Finally, morphological cleaning of the binary image by deleting the unconnected objects with pixel area less than selected value (generally determined in heuristic manner to 200 pixels) is applied to remove subtle artefacts that are not connected to the blood vessel tree. An example of the binary representation of blood vessels is shown in Fig. <ref type="figure" target="#fig_2">3b</ref> and the corresponding morphologically cleaned image is in Fig. <ref type="figure" target="#fig_2">3c</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental results and discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation methodology</head><p>The presented blood vessel segmentation method was primarily evaluated using the new HRF database containing hand-labelled images. Secondly, evaluation using DRIVE and STARE databases was performed as well. Inspired by other authors, the method performance was evaluated in terms of sensitivity (SE), specificity (SP), accuracy (ACC) and using receiver operating characteristic (ROC) curve <ref type="bibr" target="#b39">[40]</ref>.</p><formula xml:id="formula_9">SE = TP P = TP TP + FN = TPF (8) SP = TN N = TN TN + FP<label>(9)</label></formula><p>ACC = TP + TN TP + FN + TN + FP <ref type="bibr" target="#b9">(10)</ref> where TP (True Positives)number of pixels correctly classified as blood vessel pixels, FN (False Negatives)number of pixels incorrectly classified as background pixels, TN (True Negatives)number of pixels correctly detected as background pixels, FP (False Positives)number of pixels incorrectly classified as blood vessel pixels, Pa total number of blood vessel pixels in the gold standard manual segmentation, Na total number of background pixels in the gold standard segmentation. The sensitivity and specificity measure the ability of the method to well detect blood vessel and background pixels, respectively. Accuracy ACC can be characterised as an overall measure providing the ratio of total well-detected pixels according to gold standard hand-labelled segmentation. ROC curve is a plot of true-positive fractions TPF versus false-positive fractions FPF = 1-SP, as the grey level threshold of the thresholding algorithm is varied <ref type="bibr" target="#b39">[40]</ref>. From each ROC, an area under the curve (AUC) is computed. The closer the ROC curve is to the top left corner, the better is the performance of the method to match blood vessels correctly by designed filters. Thus, the optimal value of the AUC is equal to 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation of the method using HRF database</head><p>The proposed method was primarily designed for high-resolution images and therefore in the first instance evaluated using the new HRF database. All sets of images, that is images of healthy eyes, images with signs of DR and glaucoma, were used. Tables <ref type="table" target="#tab_0">1</ref><ref type="table" target="#tab_2">2</ref><ref type="table" target="#tab_1">3</ref>show results of the parameters SE, SP, ACC and AUC evaluated on particular datasets. Only pixels inside the FOV were considered in evaluation of each image. Minimum and maximum values are boldfaced for each parameter in these tables. Mean values and standard deviations are computed for each parameter as well. Considering mean values at the bottom of the tables, it can be seen that the results for all datasets are comparable. Taking into account a quantitative comparison of average values in the sense of accuracy, the    As we evaluate performance of the method quantitatively, we also tried to examine subjectively, if the application of five different kernels is reasonable with regard to a sufficient width resolution. Fig. <ref type="figure" target="#fig_5">6</ref> shows resulting blood vessel tree segmentation from Fig. <ref type="figure" target="#fig_2">3c</ref>. Blood vessel pixels are labelled according to the maximal filter response belonging to the five blood vessel width classes. It can be seen that the MF designed for the thinnest blood vessels has correctly maximum response mostly in the centre of the image (macular region). Thus, it agrees with the prior anatomical assumptions. It can be also clearly observed that the  Inspection of the thickness map in Fig. <ref type="figure" target="#fig_5">6</ref> in detail (bottom part of the figure) reveals an important behavior: the wide blood vessels with a specular reflection are correctly indicated by the lowest grey level mostly on the vessel's central axis, which is often surrounded by brighter lines indicating narrow structures. It is quite natural as the maximum response of the 'wide' filter appears only for a good match near to the blood vessel central axis, while the marginal stripes may appear as narrow blood vessels (compare the narrow profile in Fig. <ref type="figure" target="#fig_1">2a</ref> with any of the symmetrical halves of the thick profile in Figs. <ref type="figure" target="#fig_1">2d or e</ref>). It is an advantage of the method utilising different matched filters with the different shapes, thus enabling segmentation of the blood vessels with and without specular reflection in the vessel centerline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluation of the method using DRIVE and STARE databases</head><p>DRIVE and STARE databases were included into analysis in order to compare the proposed method with the state-of-the-art methods, since they have not been so far evaluated using the new HRF database. All these methods considered in the performance evaluation have been briefly mentioned earlier in Section 2. Owing to the low-resolution images in DRIVE and STARE databases, it is unsuitable to test all designed filtration masks for five width classes. It was experimentally determined, that applying only two of them is adequate to get acceptable results. The kernels were obtained heuristically from the profiles for 'width 1' and 'width 2' (Figs. <ref type="figure" target="#fig_1">2a</ref> and<ref type="figure">b</ref>) by downsampling corresponding masks with factor 2. Evaluation on the DRIVE and STARE was performed using the test sets of these databases, each containing 20 images with gold standard segmentations provided by the first human observer.    The test set of DRIVE database contains two manual segmentations provided by two human observers for each of the 20 images. One of these manual segmentations is usually used as a gold standard and the other one for comparison of automated segmentation methods with the human observer. The proposed method achieved good performance in comparison with the human observer (Tables <ref type="table" target="#tab_4">4</ref> and<ref type="table" target="#tab_5">5</ref>). ACC parameter for the proposed method is slightly lower than the ACC for human observer. Nevertheless, the difference between them is only 0.0133, which seems to be relatively low. In contrast, the difference between average values of sensitivities of the proposed method and the human observer approach (0.0747) is apparently higher than in case of accuracies. This is probably due to that challenging task to detect small blood vessels, since they are hard to distinguish from the background noise. Further visual inspection revealed that these structures are also barely recognisable by experienced human observer (see Fig. <ref type="figure" target="#fig_6">7</ref>). Then, a comparison of the method's sensitivity to detect the thinnest blood vessel structures can be pretty confusing, even when the second human observer differs from the first one (Table <ref type="table" target="#tab_5">5</ref>).</p><p>As for HRF database, ROC curves are plotted also for particular images of DRIVE (Fig. <ref type="figure" target="#fig_4">5d</ref> ) and STARE databases (Fig. <ref type="figure" target="#fig_4">5e</ref>). AUC value is computed for each image and averaged along the number of 20 images in the datasets (the last two columns in Table <ref type="table" target="#tab_3">4</ref>).</p><p>Table <ref type="table" target="#tab_6">6</ref> compares performance of the proposed method (note that it is a simplified version as described above) with 12 different methods from the literature, including the first MF approach <ref type="bibr" target="#b28">[29]</ref>. The human observer approach is considered as well. The gaps in this table indicate that the corresponding value was not provided by the author. The approaches are ordered according to the ACC parameter for    <ref type="table" target="#tab_6">6</ref> shows, the proposed method (even in its simplified version) is at least comparable with other recent methods in the literature. Nevertheless, it should be noted that our method is primarily designed and tested for high-resolution fundus images. Table <ref type="table" target="#tab_7">7</ref> then shows results for the new HRF database. It can be observed that the proposed method achieved much better performance using all designed filters together. This can be also compared with the results in Table <ref type="table" target="#tab_6">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Implementation of the algorithm</head><p>The method was implemented using MATLAB 7.9.0 (R2009b) programming software. Evaluation of the algorithm was performed on a personal computer with Intel ® Core™ i7 processor, 4 GB system memory, and Windows ® 7 Professional 64-bit operating system. An average computational time of one image for HRF database was 92 s, 3.22 s for DRIVE database, and 4.07 s for STARE database. Longer time needed for a computation of images from HRF database is caused by both the much higher resolution of images in this database and also a utilisation of all designed kernels. It must be noted that implementation of the presented method has not been optimised with regard to computational complexity. Generally, it is hard to compare different methods by computational time, since different authors use different programming languages and hardware equipment. To achieve better higher computational performance, different programming language and parallel image processing should be considered for implementation of the method. One of the main advantages of this method is a good possibility to implement the algorithm using parallel computing techniques, since only multiple convolution operations are needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>A method for efficient and reliable retinal vessel segmentation using colour fundus images was presented. The proposed approach utilises MF and minimum error thresholding technique to extract binary blood vessel tree. Five different kernels were designed according to typical blood vessel cross-sectional profiles considering five width classes of retinal vessels to cover all blood vessel structures in commonly utilised fundus images with reliable width resolution. One of the main priorities of the method is also a capability to segment the blood vessels with specular reflection.</p><p>The method was quantitatively evaluated using publicly available retinal databases and showing that the results are comparable with other recent methods in the literature.</p><p>Besides that we present the new retinal database of highresolution fundus images of healthy subjects and subjects affected by DR and glaucoma. Corresponding gold standard images were created for each fundus image in the database by manual labelling of the blood vessel tree. Thus, we provide a novel opportunity to researchers working in the field of retinal image analysis to evaluate their blood vessel segmentation algorithms. The database is available online in the internet and all authors can download it and share their vessel segmentation results to each other.</p><p>Today, the HRF database consists of three sets of images (images of healthy, DR and glaucomatous retinas). We intend to add further gold standard data to the existing images to help the evaluation of blood vessel segmentation algorithms aimed to differentiate between arteries and veins and measuring the vessel diameters as well.</p><p>We also intend to expand this database, not only for evaluation of retinal vessel segmentation algorithms, but as well as to help researchers to evaluate methods focused on other tasks in the area of retinal image analysis, for example glaucoma diagnosis, segmentation of optic disc or fovea, and localisation of vessel bifurcations and vessel crossing.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 Examples of fundus images from HRF database with corresponding hand-labelled gold standard segmentations</figDesc><graphic coords="3,334.49,56.69,192.08,213.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2</head><label>2</label><figDesc>Fig. 2 Depiction of averaged blood vessel cross-sectional profiles (at the top) expanded into corresponding 2D kernels of filters (at the bottom) classified into five classes of different widths: from the narrowest (a) to the widest (e) blood vessel profile Indices m, n stay for spatial coordinates of particular matrices</figDesc><graphic coords="4,76.54,591.82,444.93,145.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3</head><label>3</label><figDesc>Fig. 3 Resulting parametric image and binary representation of the blood vessel tree (the images correspond to the fundus image in Fig. 1a) a Resulting parametric image composed from the particular parametric images selecting the maximum response for each pixel b Thresholded image obtained by the proposed thresholding algorithm c Morphologically cleaned binary image</figDesc><graphic coords="5,141.73,56.69,312.11,76.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 Comparison of resulting blood vessel segmentation (top row) for each dataset (healthy, DR and glaucomatous group) with corresponding gold standard hand-labelled segmentations (bottom row)</figDesc><graphic coords="6,116.22,611.32,360.93,98.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5</head><label>5</label><figDesc>Fig. 5 ROC curves plotted for each image separately concerning images from HRF, DRIVE, and STARE databases a HRF databasehealthy group b HRF database -DR group c HRF databaseglaucomatous group d DRIVE database e STARE database ROC charts are zoomed to the top-left corner for better visual differentiation between the curves</figDesc><graphic coords="7,76.54,467.66,444.92,235.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6</head><label>6</label><figDesc>Fig. 6 The blood vessel tree labelled according to detected width class Starting from Width 1 for the narrowest class continuing to Width 5 for the widest class; top part: the blood vessel tree segmentation result labelled in grey-scale, bottom part: details of the blood vessel pixels labelled according to the vessel diameter</figDesc><graphic coords="7,317.48,56.69,228.47,184.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7</head><label>7</label><figDesc>Fig. 7 Comparison of segmentation results for the DRIVE database showing difficulty of human observer to decide whether there is a vessel or not a Section of the green channel of image '0 l_test.tif' in the test set of DRIVE database b Corresponding gold standard image labelled by the first observer c Corresponding gold standard image labelled by the second observer</figDesc><graphic coords="8,51.02,56.69,228.09,66.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8</head><label>8</label><figDesc>Fig. 8 Comparison of the best (left) and the worst (right) segmentation results measured by ACC using DRIVE database At the top: results of the proposed method, at the bottom: gold standard segmentations</figDesc><graphic coords="8,328.82,56.69,204.09,210.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Performance evaluation on the healthy group (HRF)</figDesc><table><row><cell>Image no.</cell><cell>SE</cell><cell>SP</cell><cell>ACC</cell><cell>AUC</cell></row><row><cell>1</cell><cell>0.7642</cell><cell>0.9736</cell><cell>0.9484</cell><cell>0.9641</cell></row><row><cell>2</cell><cell>0.8341</cell><cell>0.9729</cell><cell>0.9567</cell><cell>0.9793</cell></row><row><cell>3</cell><cell>0.6976</cell><cell>0.9777</cell><cell>0.9427</cell><cell>0.9541</cell></row><row><cell>4</cell><cell>0.7791</cell><cell>0.9776</cell><cell>0.9555</cell><cell>0.9734</cell></row><row><cell>5</cell><cell>0.8037</cell><cell>0.9780</cell><cell>0.9594</cell><cell>0.9775</cell></row><row><cell>6</cell><cell>0.8177</cell><cell>0.9715</cell><cell>0.9531</cell><cell>0.9782</cell></row><row><cell>7</cell><cell>0.8067</cell><cell>0.9809</cell><cell>0.9626</cell><cell>0.9785</cell></row><row><cell>8</cell><cell>0.7560</cell><cell>0.9829</cell><cell>0.9560</cell><cell>0.9739</cell></row><row><cell>9</cell><cell>0.7339</cell><cell>0.9805</cell><cell>0.9578</cell><cell>0.9721</cell></row><row><cell>10</cell><cell>0.7393</cell><cell>0.9789</cell><cell>0.9545</cell><cell>0.9687</cell></row><row><cell>11</cell><cell>0.8290</cell><cell>0.9748</cell><cell>0.9584</cell><cell>0.9833</cell></row><row><cell>12</cell><cell>0.7877</cell><cell>0.9804</cell><cell>0.9551</cell><cell>0.9778</cell></row><row><cell>13</cell><cell>0.7949</cell><cell>0.9608</cell><cell>0.9424</cell><cell>0.9701</cell></row><row><cell>14</cell><cell>0.8190</cell><cell>0.9602</cell><cell>0.9456</cell><cell>0.9768</cell></row><row><cell>15</cell><cell>0.8292</cell><cell>0.9739</cell><cell>0.9605</cell><cell>0.9844</cell></row><row><cell>mean</cell><cell>0.7861</cell><cell>0.9750</cell><cell>0.9539</cell><cell>0.9742</cell></row><row><cell>std</cell><cell>0.0392</cell><cell>0.0065</cell><cell>0.0061</cell><cell>0.0075</cell></row><row><cell cols="5">Minimum and maximum values of each parameter are boldfaced</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3</head><label>3</label><figDesc>Performance evaluation on the glaucomatous group</figDesc><table><row><cell>(HRF)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Image no.</cell><cell>SE</cell><cell>SP</cell><cell>ACC</cell><cell>AUC</cell></row><row><cell>1</cell><cell>0.8189</cell><cell>0.9567</cell><cell>0.9458</cell><cell>0.9681</cell></row><row><cell>2</cell><cell>0.7901</cell><cell>0.9627</cell><cell>0.9475</cell><cell>0.9692</cell></row><row><cell>3</cell><cell>0.7349</cell><cell>0.9771</cell><cell>0.9605</cell><cell>0.9748</cell></row><row><cell>4</cell><cell>0.8053</cell><cell>0.9673</cell><cell>0.9550</cell><cell>0.9725</cell></row><row><cell>5</cell><cell>0.7990</cell><cell>0.9720</cell><cell>0.9587</cell><cell>0.9769</cell></row><row><cell>6</cell><cell>0.8073</cell><cell>0.9670</cell><cell>0.9541</cell><cell>0.9749</cell></row><row><cell>7</cell><cell>0.8027</cell><cell>0.9637</cell><cell>0.9513</cell><cell>0.9711</cell></row><row><cell>8</cell><cell>0.8292</cell><cell>0.9518</cell><cell>0.9419</cell><cell>0.9725</cell></row><row><cell>9</cell><cell>0.7637</cell><cell>0.9705</cell><cell>0.9543</cell><cell>0.9736</cell></row><row><cell>10</cell><cell>0.8061</cell><cell>0.9652</cell><cell>0.9528</cell><cell>0.9732</cell></row><row><cell>11</cell><cell>0.8243</cell><cell>0.9555</cell><cell>0.9437</cell><cell>0.9721</cell></row><row><cell>12</cell><cell>0.8172</cell><cell>0.9533</cell><cell>0.9400</cell><cell>0.9698</cell></row><row><cell>13</cell><cell>0.7684</cell><cell>0.9639</cell><cell>0.9482</cell><cell>0.9670</cell></row><row><cell>14</cell><cell>0.7195</cell><cell>0.9621</cell><cell>0.9418</cell><cell>0.9550</cell></row><row><cell>15</cell><cell>0.7633</cell><cell>0.9677</cell><cell>0.9500</cell><cell>0.9655</cell></row><row><cell>mean</cell><cell>0.7900</cell><cell>0.9638</cell><cell>0.9497</cell><cell>0.9704</cell></row><row><cell>std</cell><cell>0.0318</cell><cell>0.0069</cell><cell>0.0061</cell><cell>0.0051</cell></row></table><note><p>Minimum and maximum values of each parameter are boldfaced</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Performance evaluation on the DR group (HRF)</figDesc><table><row><cell>Image no.</cell><cell>SE</cell><cell>SP</cell><cell>ACC</cell><cell>AUC</cell></row><row><cell>1</cell><cell>0.7595</cell><cell>0.9663</cell><cell>0.9539</cell><cell>0.9587</cell></row><row><cell>2</cell><cell>0.7529</cell><cell>0.9692</cell><cell>0.9528</cell><cell>0.9677</cell></row><row><cell>3</cell><cell>0.7124</cell><cell>0.9700</cell><cell>0.9516</cell><cell>0.9566</cell></row><row><cell>4</cell><cell>0.6406</cell><cell>0.9702</cell><cell>0.9482</cell><cell>0.9473</cell></row><row><cell>5</cell><cell>0.8276</cell><cell>0.9626</cell><cell>0.9526</cell><cell>0.9738</cell></row><row><cell>6</cell><cell>0.6415</cell><cell>0.9521</cell><cell>0.9243</cell><cell>0.9224</cell></row><row><cell>7</cell><cell>0.8108</cell><cell>0.9563</cell><cell>0.9429</cell><cell>0.9693</cell></row><row><cell>8</cell><cell>0.7638</cell><cell>0.9582</cell><cell>0.9409</cell><cell>0.9576</cell></row><row><cell>9</cell><cell>0.6728</cell><cell>0.9674</cell><cell>0.9438</cell><cell>0.9487</cell></row><row><cell>10</cell><cell>0.8006</cell><cell>0.9561</cell><cell>0.9400</cell><cell>0.9655</cell></row><row><cell>11</cell><cell>0.8075</cell><cell>0.9574</cell><cell>0.9424</cell><cell>0.9690</cell></row><row><cell>12</cell><cell>0.7446</cell><cell>0.9665</cell><cell>0.9487</cell><cell>0.9646</cell></row><row><cell>13</cell><cell>0.7597</cell><cell>0.9707</cell><cell>0.9536</cell><cell>0.9701</cell></row><row><cell>14</cell><cell>0.7266</cell><cell>0.9630</cell><cell>0.9417</cell><cell>0.9561</cell></row><row><cell>15</cell><cell>0.7730</cell><cell>0.9430</cell><cell>0.9298</cell><cell>0.9558</cell></row><row><cell>mean</cell><cell>0.7463</cell><cell>0.9619</cell><cell>0.9445</cell><cell>0.9589</cell></row><row><cell>std</cell><cell>0.0566</cell><cell>0.0077</cell><cell>0.0084</cell><cell>0.0124</cell></row><row><cell cols="5">Minimum and maximum values of each parameter are boldfaced</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc>Performance evaluation on DRIVE and STARE databases</figDesc><table><row><cell>Image no.</cell><cell>SE</cell><cell></cell><cell>SP</cell><cell></cell><cell>ACC</cell><cell></cell><cell>AUC</cell><cell></cell></row><row><cell></cell><cell>DRIVE</cell><cell>STARE</cell><cell>DRIVE</cell><cell>STARE</cell><cell>DRIVE</cell><cell>STARE</cell><cell>DRIVE</cell><cell>STARE</cell></row><row><cell>1</cell><cell>0.7872</cell><cell>0.6584</cell><cell>0.9579</cell><cell>0.9292</cell><cell>0.9345</cell><cell>0.9025</cell><cell>0.9646</cell><cell>0.9206</cell></row><row><cell>2</cell><cell>0.7963</cell><cell>0.6451</cell><cell>0.9608</cell><cell>0.8777</cell><cell>0.9353</cell><cell>0.8550</cell><cell>0.9621</cell><cell>0.8965</cell></row><row><cell>3</cell><cell>0.6121</cell><cell>0.6262</cell><cell>0.9805</cell><cell>0.9691</cell><cell>0.9240</cell><cell>0.9418</cell><cell>0.9392</cell><cell>0.9439</cell></row><row><cell>4</cell><cell>0.7062</cell><cell>0.6308</cell><cell>0.9777</cell><cell>0.9815</cell><cell>0.9397</cell><cell>0.9441</cell><cell>0.9539</cell><cell>0.9489</cell></row><row><cell>5</cell><cell>0.6833</cell><cell>0.7486</cell><cell>0.9788</cell><cell>0.9375</cell><cell>0.9366</cell><cell>0.9128</cell><cell>0.9448</cell><cell>0.9439</cell></row><row><cell>6</cell><cell>0.6571</cell><cell>0.7847</cell><cell>0.9767</cell><cell>0.9439</cell><cell>0.9297</cell><cell>0.9293</cell><cell>0.9436</cell><cell>0.9549</cell></row><row><cell>7</cell><cell>0.6358</cell><cell>0.9119</cell><cell>0.9746</cell><cell>0.9504</cell><cell>0.9280</cell><cell>0.9466</cell><cell>0.9396</cell><cell>0.9780</cell></row><row><cell>8</cell><cell>0.6064</cell><cell>0.8957</cell><cell>0.9648</cell><cell>0.9595</cell><cell>0.9180</cell><cell>0.9535</cell><cell>0.9321</cell><cell>0.9794</cell></row><row><cell>9</cell><cell>0.6676</cell><cell>0.9003</cell><cell>0.9745</cell><cell>0.9440</cell><cell>0.9365</cell><cell>0.9396</cell><cell>0.9532</cell><cell>0.9703</cell></row><row><cell>10</cell><cell>0.7044</cell><cell>0.8063</cell><cell>0.9760</cell><cell>0.9423</cell><cell>0.9418</cell><cell>0.9273</cell><cell>0.9539</cell><cell>0.9659</cell></row><row><cell>11</cell><cell>0.7128</cell><cell>0.8750</cell><cell>0.9663</cell><cell>0.9375</cell><cell>0.9324</cell><cell>0.9310</cell><cell>0.9421</cell><cell>0.9733</cell></row><row><cell>12</cell><cell>0.6989</cell><cell>0.9268</cell><cell>0.9686</cell><cell>0.9502</cell><cell>0.9333</cell><cell>0.9476</cell><cell>0.9481</cell><cell>0.9837</cell></row><row><cell>13</cell><cell>0.6808</cell><cell>0.8534</cell><cell>0.9743</cell><cell>0.9515</cell><cell>0.9310</cell><cell>0.9396</cell><cell>0.9535</cell><cell>0.9651</cell></row><row><cell>14</cell><cell>0.7144</cell><cell>0.8478</cell><cell>0.9678</cell><cell>0.9525</cell><cell>0.9367</cell><cell>0.9389</cell><cell>0.9562</cell><cell>0.9660</cell></row><row><cell>15</cell><cell>0.7563</cell><cell>0.8243</cell><cell>0.9644</cell><cell>0.9575</cell><cell>0.9420</cell><cell>0.9425</cell><cell>0.9527</cell><cell>0.9611</cell></row><row><cell>16</cell><cell>0.7192</cell><cell>0.6690</cell><cell>0.9651</cell><cell>0.9728</cell><cell>0.9314</cell><cell>0.9276</cell><cell>0.9587</cell><cell>0.9333</cell></row><row><cell>17</cell><cell>0.6764</cell><cell>0.8496</cell><cell>0.9666</cell><cell>0.9592</cell><cell>0.9290</cell><cell>0.9452</cell><cell>0.9450</cell><cell>0.9711</cell></row><row><cell>18</cell><cell>0.7447</cell><cell>0.7486</cell><cell>0.9643</cell><cell>0.9824</cell><cell>0.9380</cell><cell>0.9650</cell><cell>0.9605</cell><cell>0.9736</cell></row><row><cell>19</cell><cell>0.8202</cell><cell>0.7744</cell><cell>0.9649</cell><cell>0.9759</cell><cell>0.9465</cell><cell>0.9653</cell><cell>0.9720</cell><cell>0.9703</cell></row><row><cell>20</cell><cell>0.7390</cell><cell>0.7179</cell><cell>0.9615</cell><cell>0.9494</cell><cell>0.9365</cell><cell>0.9265</cell><cell>0.9630</cell><cell>0.9385</cell></row><row><cell>mean</cell><cell>0.7060</cell><cell>0.7847</cell><cell>0.9693</cell><cell>0.9512</cell><cell>0.9340</cell><cell>0.9341</cell><cell>0.9519</cell><cell>0.9569</cell></row><row><cell>std</cell><cell>0.0560</cell><cell>0.0975</cell><cell>0.0065</cell><cell>0.0223</cell><cell>0.0064</cell><cell>0.0234</cell><cell>0.0098</cell><cell>0.0216</cell></row><row><cell cols="4">Minimum and maximum values of each parameter are boldfaced</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc>shows sensitivity, specificity and accuracy for each image in DRIVE and STARE databases. Minimum and maximum values for each parameter are boldfaced in this table. Fig.8then shows comparison of segmentation results for the minimum and maximum value of ACC parameter together with corresponding gold standard segmentations for DRIVE database.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc>Comparison of the second and the first human observer segmentations on DRIVE database</figDesc><table><row><cell>Image no.</cell><cell>SE</cell><cell>SP</cell><cell>ACC</cell></row><row><cell>1</cell><cell>0.7972</cell><cell>0.9717</cell><cell>0.9478</cell></row><row><cell>2</cell><cell>0.8282</cell><cell>0.9707</cell><cell>0.9486</cell></row><row><cell>3</cell><cell>0.7470</cell><cell>0.9738</cell><cell>0.9391</cell></row><row><cell>4</cell><cell>0.7900</cell><cell>0.9729</cell><cell>0.9473</cell></row><row><cell>5</cell><cell>0.7436</cell><cell>0.9783</cell><cell>0.9448</cell></row><row><cell>6</cell><cell>0.7600</cell><cell>0.9644</cell><cell>0.9344</cell></row><row><cell>7</cell><cell>0.6885</cell><cell>0.9842</cell><cell>0.9435</cell></row><row><cell>8</cell><cell>0.6674</cell><cell>0.9823</cell><cell>0.9411</cell></row><row><cell>9</cell><cell>0.7757</cell><cell>0.9679</cell><cell>0.9441</cell></row><row><cell>10</cell><cell>0.7215</cell><cell>0.9782</cell><cell>0.9459</cell></row><row><cell>11</cell><cell>0.7667</cell><cell>0.9735</cell><cell>0.9459</cell></row><row><cell>12</cell><cell>0.7779</cell><cell>0.9759</cell><cell>0.9500</cell></row><row><cell>13</cell><cell>0.8079</cell><cell>0.9596</cell><cell>0.9372</cell></row><row><cell>14</cell><cell>0.7741</cell><cell>0.9785</cell><cell>0.9534</cell></row><row><cell>15</cell><cell>0.8049</cell><cell>0.9718</cell><cell>0.9538</cell></row><row><cell>16</cell><cell>0.7804</cell><cell>0.9737</cell><cell>0.9472</cell></row><row><cell>17</cell><cell>0.7406</cell><cell>0.9785</cell><cell>0.9477</cell></row><row><cell>18</cell><cell>0.8600</cell><cell>0.9589</cell><cell>0.9470</cell></row><row><cell>19</cell><cell>0.9098</cell><cell>0.9590</cell><cell>0.9528</cell></row><row><cell>20</cell><cell>0.8727</cell><cell>0.9512</cell><cell>0.9424</cell></row><row><cell>mean</cell><cell>0.7807</cell><cell>0.9712</cell><cell>0.9473</cell></row><row><cell>std</cell><cell>0.0570</cell><cell>0.0085</cell><cell>0.0051</cell></row><row><cell cols="3">Minimum and maximum values of each parameter are</cell><cell></cell></row><row><cell>boldfaced.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">First human observer is considered as gold standard</cell><cell></cell></row><row><cell>segmentation.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6</head><label>6</label><figDesc>Comparison of the proposed method with other blood vessel segmentation algorithmsevaluation on DRIVE and STARE</figDesc><table><row><cell>databases</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Segmentation method</cell><cell>SE</cell><cell></cell><cell>SP</cell><cell></cell><cell>ACC</cell><cell></cell><cell>AUC</cell><cell></cell></row><row><cell></cell><cell>DRIVE</cell><cell>STARE</cell><cell>DRIVE</cell><cell>STARE</cell><cell>DRIVE</cell><cell>STARE</cell><cell>DRIVE</cell><cell>STARE</cell></row><row><cell>Lupascu et al. [21]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.9597</cell><cell>-</cell><cell>0.9536</cell><cell>-</cell></row><row><cell>Al-Rawi et al. [30] (MF)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.9535</cell><cell>0.9385</cell><cell>0.9435</cell><cell>0.9077</cell></row><row><cell>second human observer</cell><cell>0.7807</cell><cell>0.8953</cell><cell>0.9712</cell><cell>0.9374</cell><cell>0.9473</cell><cell>0.9339</cell><cell>-</cell><cell>-</cell></row><row><cell>Soares et al. [28]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.9466</cell><cell>0.9480</cell><cell>0.9614</cell><cell>0.9671</cell></row><row><cell>Marín et al. [20]</cell><cell>0.7067</cell><cell>0.6944</cell><cell>0.9801</cell><cell>0.9819</cell><cell>0.9452</cell><cell>0.9526</cell><cell>0.9588</cell><cell>0.9769</cell></row><row><cell>Staal et al. [13]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.9441</cell><cell>0.9516</cell><cell>0.9520</cell><cell>0.9614</cell></row><row><cell>Lam et al. [23]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.9383</cell><cell>0.9454</cell><cell>0.9519</cell><cell>0.9562</cell></row><row><cell>Zhang et al. [32] (MF)</cell><cell>0.7120</cell><cell>0.7166</cell><cell>0.9724</cell><cell>0.9673</cell><cell>0.9382</cell><cell>0.9439</cell><cell>-</cell><cell>-</cell></row><row><cell>Delibasis et al. [22]</cell><cell>0.6654</cell><cell>-</cell><cell>0.9792</cell><cell>-</cell><cell>0.9377</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>proposed method (simplified version)</cell><cell>0.7060</cell><cell>0.7847</cell><cell>0.9693</cell><cell>0.9512</cell><cell>0.9340</cell><cell>0.9341</cell><cell>0.9519</cell><cell>0.9569</cell></row><row><cell>Cinsdikici et al. [7] (MF)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.9293</cell><cell>-</cell><cell>0.9407</cell><cell>-</cell></row><row><cell>Al-Diri et al. [1]</cell><cell>0.7282</cell><cell>0.7521</cell><cell>0.9551</cell><cell>0.9681</cell><cell>0.9258</cell><cell>0.9330</cell><cell>-</cell><cell>-</cell></row><row><cell>Palomera-Pérez et al. [26]</cell><cell>0.6440</cell><cell>0.7690</cell><cell>0.9670</cell><cell>0.9449</cell><cell>0.9250</cell><cell>0.9260</cell><cell>-</cell><cell>-</cell></row><row><cell>Chaudhuri et al. [29] (MF)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.8773</cell><cell>-</cell><cell>0.7878</cell><cell>-</cell></row></table><note><p>Minimum and maximum values of each parameter are boldfaced MF indicates the methods based on the matched filtering. Particular approaches are ordered according to the ACC parameter for DRIVE database</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7</head><label>7</label><figDesc>Evaluation of the proposed method using HRF</figDesc><table><row><cell cols="4">database in comparison with DRIVE and STARE databases</cell></row><row><cell></cell><cell>SE</cell><cell>SP</cell><cell>ACC</cell><cell>AUC</cell></row><row><cell>proposed method (HRF -</cell><cell cols="4">0.7861 0.9750 0.9539 0.9742</cell></row><row><cell>healthy images)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>proposed method (HRF -</cell><cell cols="4">0.7900 0.9638 0.9497 0.9704</cell></row><row><cell>glaucomatous images)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>proposed method (HRF -DR</cell><cell cols="4">0.7463 0.9619 0.9445 0.9589</cell></row><row><cell>images)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>proposed method (DRIVE)</cell><cell cols="4">0.7060 0.9693 0.9340 0.9519</cell></row><row><cell>proposed method (STARE)</cell><cell cols="4">0.7847 0.9512 0.9341 0.9569</cell></row><row><cell cols="5">Minimum and maximum values of each parameter are boldfaced</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>IET Image Process., 2013, Vol. 7, Iss. 4, pp. 373-383</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>doi: 10.1049/iet-ipr.2012.0455 &amp; The Institution of Engineering and Technology 2013</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>IET Image Process., 2013, Vol. 7, Iss. 4, pp. 373-383 &amp; The Institution of Engineering and Technology 2013 doi: 10.1049/iet-ipr.2012.0455</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>&amp; The Institution of Engineering and Technology 2013 doi: 10.1049/iet-ipr.2012.0455</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>7 Acknowledgment Department of Biomedical Engineering, FEEC, Brno University of Technology: This work has been supported by European Regional Development Fund -Project FNUSA-ICRC (No.CZ.1.05/1.1.00/02.0123) and by Czech-German project no. 7AMB12DE002 under Ministry of Education, Youth and Sports. Pattern Recognition Lab and Erlangen Graduate School in Advanced Optical Technologies (SAOT) University of Erlangen -Nuremberg: The authors gratefully acknowledge funding of the Erlangen Graduate School in Advanced Optical Technologies (SAOT) by the German Research and also German-Czech project no. 54447730 supported by DAAD (Deutscher Akademischer Austausch Dienst). 8 References</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Retina and optic nerve imaging</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Ciulla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Regillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Harris</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Lippincott Williams and Wilkins</publisher>
			<biblScope unit="page">369</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Glaucoma risk index: automated glaucoma detection from color fundus images</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Nyúl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Michelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="471" to="481" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Retinal vessel diameter and cardiovascular mortality: pooled data analysis from two older populations</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rochtchina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Knudtson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. Heart J</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="1984" to="1992" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automated microaneurysm detection using local contrast normalization and local vessel detection</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Goatman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Sharp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1223" to="1232" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A novel method for the automatic grading of retinal vessel tortuosity</title>
		<author>
			<persName><forename type="first">E</forename><surname>Grisan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Foracchia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ruggeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="310" to="319" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Retinal vessel diameter in normal and glaucomatous eyes: the Beijing eye study</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Jonas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin. Exp. Ophth</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="800" to="807" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automatic detection and characterization of retinal vessel tree bifurcations and crossovers in eye fundus images</title>
		<author>
			<persName><forename type="first">D</forename><surname>Calvo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Penedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rouco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Programs Biomed</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="38" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Registration and fusion of the autofluorescent and infrared retinal images</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kolar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kubecka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Biomed. Imaging</title>
		<imprint>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Segmentation of the optic disc, macula and vascular arch in fundus photographs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Niemeijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Abramoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ginneken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="116" to="127" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Detection of retinal nerve fiber layer defects on retinal fundus images for early diagnosis of glaucoma</title>
		<author>
			<persName><forename type="first">Ch</forename><surname>Muramatsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sawada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Opt</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The recognition based on band tree for blood vessel of ocular fundus</title>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ch</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. on Mechatronics and Automation</title>
		<meeting>IEEE Int. Conf. on Mechatronics and Automation<address><addrLine>Changchun, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-08">August 2009</date>
			<biblScope unit="page" from="3348" to="3353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Improvement of vessel segmentation by matched filtering in colour retinal images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Odstrcilik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kolar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gazarek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. World Congress on Med</title>
		<meeting>World Congress on Med<address><addrLine>Munich, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-09">September 2009</date>
			<biblScope unit="page" from="327" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ridge-based vessel segmentation in color images of the retina</title>
		<author>
			<persName><forename type="first">J</forename><surname>Staal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Abramoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niemeijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ginneken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="501" to="509" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Locating blood vessels in retinal images by piece-wise threshold probing of a matched filter response</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hoover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kouznetsova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Goldbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="203" to="210" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Blood vessel segmentation methodologies in retinal images -a survey</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Fraz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Remagnino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Programs Biomed</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="407" to="433" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multi-scale retinal vessel segmentation using line tracking</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dermatas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Med. Imaging Graph</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="213" to="227" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A web-based system for the quantitative and reproducible assessment of clinical indexes from the retinal vasculature</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tramontan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Poletti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fiorin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ruggeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="818" to="821" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Enhanced classification-based vessel tracking using vessel models and Hough transform</title>
		<author>
			<persName><forename type="first">A</forename><surname>Giani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grisan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ruggeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Third Europe on Medical and Biological Engineering Conf. EMBEC 2005</title>
		<meeting>Third Europe on Medical and Biological Engineering Conf. EMBEC 2005<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-11">November 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Retinal blood vessel segmentation using line operators and support vector classification</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Perfetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1357" to="1365" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A new supervised method for blood vessel segmentation in retinal images by using gray-level and moment invariants-based features</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marín</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aquino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Gegúndez-Arias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Bravo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="146" to="158" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">FABC: Retinal vessel segmentation using AdaBoost</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Lupascu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tegolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Trucco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Technol. Biomed</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1267" to="1274" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Automatic model-based tracing algorithm for vessel segmentation and diameter estimation</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Delibasis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">A</forename><surname>Kechriniotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tsonos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Assimakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Programs Biomed</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="108" to="122" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">General retinal vessel segmentation using regularization-based multiconcavity modeling</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S Y</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wee-Chung-Liew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1369" to="1380" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fourier cross-sectional profile for vessel detection on retinal images</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Med. Imaging Graph</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="203" to="212" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An active contour model for segmenting and measuring retinal vessels</title>
		<author>
			<persName><forename type="first">B</forename><surname>Al-Diri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Steel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1488" to="1497" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Parallel multiscale feature extraction and region growing: application in retinal blood vessel detection</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Palomera-Pérez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Martinez-Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Benítez-Pérez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Ortega-Arjona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Technol. Biomed</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="500" to="506" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Segmentation of retinal blood vessels by combining the detection of centerlines and morphological reconstruction</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Mendonca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Campilho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1200" to="1213" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Retinal vessel segmentation using the 2-D Gabor wavelet and supervised classification</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V B</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J G</forename><surname>Leandro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Cesar</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">F</forename><surname>Jelinek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Cree</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1214" to="1222" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Detection of blood vessels in retinal images using two-dimensional matched filters</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goldbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="263" to="269" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Genetic algorithm matched filter optimization for automated detection of blood vessels from digital retinal images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Al-Rawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Karajeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Programs Biomed</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="248" to="253" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Detection of blood vessels in ophthalmoscope images using MF/ant (matched filter/ant colony) algorithm</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Cinsdikici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Aydin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Programs Biomed</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="85" to="95" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Retinal vessel extraction by matched filter with first-order derivative of Gaussian</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Karray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Biol. Med</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="438" to="445" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multiscale blood vessel segmentation in retinal fundus images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Budai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Michelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Bildverarbeitung für die Med. 2010 -Alg., Syst</title>
		<imprint>
			<biblScope unit="page" from="261" to="265" />
			<date type="published" when="2010-03">March 2010</date>
			<pubPlace>Anwendungen, Aachen, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Towards automated diagnostic evaluation of retina images</title>
		<author>
			<persName><forename type="first">H</forename><surname>Niemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chrastek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn. Image Anal</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="671" to="676" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Curve and surfaces fitting with splines</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dierckx</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Minimum error thresholding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Illingworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="47" />
			<date type="published" when="1986">1986, 19</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Survey over image thresholding techniques and quantitative performance evaluation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sezgin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sankur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Electron. Imaging</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="146" to="165" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A threshold selection method from gray-level histograms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Otsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Systems Man Cybernet</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="62" to="66" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">An efficient blood vessel detection algorithm for retinal images using local entropy thresholding</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chanwimaluang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp. Circuits Systems</title>
		<meeting>Int. Symp. Circuits Systems<address><addrLine>Bangkok, Thailand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-05">2003. May 2003</date>
			<biblScope unit="page" from="21" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An introduction to ROC analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fawcett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn. Lett</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="861" to="874" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Automated detection and differentiation of drusen, exudates, and cotton-wool spots in digital color fundus photographs for diabetic retinopathy diangosis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Niemeijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S A</forename><surname>Suttorp-Schulten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Abramoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Invest. Ophthalmol. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2260" to="2267" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Automated detection of exudates in colored retinal images for diagnosis of diabetic retinopathy</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">U</forename><surname>Akram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tariq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Anjum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Younnus-Javed</surname></persName>
		</author>
		<ptr target="www.ietdl.org" />
	</analytic>
	<monogr>
		<title level="j">Appl. Opt</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="4858" to="4866" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
