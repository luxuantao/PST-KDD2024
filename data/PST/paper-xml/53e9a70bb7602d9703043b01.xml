<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A new hybrid heuristic approach for solving large traveling salesman problem q</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Cheng-Fa</forename><surname>Tsai</surname></persName>
							<email>cftsai@mail.npust.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Management Information Systems</orgName>
								<orgName type="institution">National Pingtung University of Science and Technology</orgName>
								<address>
									<addrLine>1, Hseuh-Fu Rd</addrLine>
									<postCode>91201</postCode>
									<settlement>Nei-Pu Shan, Pingtung</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chun-Wei</forename><surname>Tsai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Management Information Systems</orgName>
								<orgName type="institution">National Pingtung University of Science and Technology</orgName>
								<address>
									<addrLine>1, Hseuh-Fu Rd</addrLine>
									<postCode>91201</postCode>
									<settlement>Nei-Pu Shan, Pingtung</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ching-Chang</forename><surname>Tseng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Management Information Systems</orgName>
								<orgName type="institution">National Pingtung University of Science and Technology</orgName>
								<address>
									<addrLine>1, Hseuh-Fu Rd</addrLine>
									<postCode>91201</postCode>
									<settlement>Nei-Pu Shan, Pingtung</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A new hybrid heuristic approach for solving large traveling salesman problem q</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C9B3906839FDF1F78FB4A24454916353</idno>
					<idno type="DOI">10.1016/j.ins.2003.11.008</idno>
					<note type="submission">Received 17 January 2003; received in revised form 9 September 2003; accepted 6 November 2003</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T10:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Ant colony system</term>
					<term>Traveling salesman problem</term>
					<term>Metaheuristic approach</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents a new metaheuristic approach called ACOMAC algorithm for solving the traveling salesman problem (TSP). We introduce multiple ant clans' concept from parallel genetic algorithm to search solution space utilizing various islands to avoid local minima and thus can yield global minimum for solving the traveling salesman problem. Moreover, we present two approaches named the multiple nearest neighbor (NN) and the dual nearest neighbor (DNN) to ACOMAC to enhance large TSPs. To validate the proposed methods, numerous simulations were conducted to compare ACOMAC and Dorigo's ACS with and without the addition of the multiple nearest neighbor (NN) method or the dual nearest neighbor (DNN) approach, using a range of TSP benchmark problems. According to the results of the simulation, adding the NN or DNN approach to ACOMAC or ACS, as initial solutions, also significantly enhances the performance of ACOMAC and ACS in solving the traveling salesman problem. Meanwhile, using ACOMAC + DNN with TSP can yield better solutions than the other stated approaches. Additionally, ACOMAC or ACOMAC + NN, utilizing five ant clans with a total of 20 ants, is verified to yield better solutions. Furthermore, ACOMAC with a local weighting (w) set to 0.6 can yield better solutions in terms of length.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The most important member of the large set of combinatorial optimization problems is undoubtedly the traveling salesman problem (TSP), which involves the task of determining a route among a given set of nodes with the shortest possible length <ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref>. The study of this problem has attracted several researchers in various fields such as artificial intelligence, biology, mathematics, physics, and operations research, and there is a very large of literature exists on the problem. Although it is easily formulated, it involves all aspects of combinatorial optimization and has served and continues to serve as a benchmark problem to which to apply new algorithms, including ant system (AS) <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref>, evolutionary methods, neural networks <ref type="bibr" target="#b13">[14]</ref>, tabu search <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>, simulated annealing (SA) <ref type="bibr" target="#b14">[15]</ref>, genetic algorithm (GA) <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b19">20]</ref>, and greedy algorithm <ref type="bibr" target="#b3">[4]</ref>.</p><p>Ant system comprises a set of cooperating agents called ants, which utilize an indirect form of communication mediated by a pheromone. The ant system has been inspired by the collective behavior of real ant colonies, and in particular, by their foraging behavior. The primary idea of the ant algorithm is the indirect communication among ants in the colony agents, based on pheromone trails. The pheromone trails constitute a type of distributed numerical information, which is altered by the ants to reflect the experiences gained when solving a particular problem. Ant system is known as one of the most efficient algorithm for TSP. Inspired by the collective behavior of ant colony, Dorigo developed the ant system (AS) <ref type="bibr" target="#b1">[2]</ref>, and later continue to design this system <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b17">18]</ref>. To demonstrate the AS method, Dorigo apply this approach to the jobshop scheduling problem, classical traveling salesman problem (TSP), and quadratic assignment problem (QAP). AS shows very excellent results in each applied area. More recently Dorigo has been designing expanded versions of the AS paradigm. The AS is one such extension and has been applied to the symmetric and asymmetric TSP with excellent results <ref type="bibr" target="#b8">[9]</ref>. The AS has also been successfully applied to other combinatorial optimization problems, including the telecommunications networks, partitioning, scheduling, coloring, and vehicle routing problem <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. Recently, the ant colony optimization (ACO) meta-heuristic has been proposed, representing a unifying framework to support most applications of ant algorithms to combinatorial optimization problems. All the ant algorithms applied to the TSP fit perfectly into the ACO meta-heuristic; therefore, these algorithms are hereinafter also called ACO algorithms.</p><p>This study describes a very simple, yet empirically powerful approach, called the ant colony optimization with multiple ant clans (ACOMAC) algorithm, that has been found more effective than the ant colony system (ACS) or ant colony optimization (ACO) approach proposed by Dorigo for the TSP on some benchmark test problems in the literature <ref type="bibr" target="#b17">[18]</ref>. Moreover, this work introduces the multiple ant clans concept from the parallel genetic algorithm to search the solution space utilizing different islands to avoid local minima and thus obtain a global minimum for solving the TSP problem. In addition, we present two methods called multiple nearest neighbor (NN) and dual nearest neighbor (DNN) to ACOMAC to improve large TSPs thus obtain good solutions quickly.</p><p>The multiple nearest neighbor (NN) heuristic for determining a traveling salesman tour is near at hand. The salesman starts at a city and then visits the city nearest to the starting city. From there he visits the nearest city not yet visited, and repeats this process until he has visited all cities, after which he returns to the starting city. Multiple nearest neighbor (NN) tours provide the advantage of only involving a few serious mistakes, but long segments connect nodes with short edges. Consequently, such tours serve as good starting tours to which to apply improvements, and making efforts to design heuristics based on the multiple nearest neighbor (NN) principle is reasonable.</p><p>This paper also presents another new method, called the dual nearest neighbor (DNN) approach, to improve ACOMAC or ACO (ACS) and thus search the solution space efficiently in the initial searching stage. According to the results of the simulation, employing the DNN approach can augment the search solution space in the initial searching stage more efficiently than using the single starting point searching method and the multiple nearest neighbor (NN) heuristic, yielding much better comparisons of the lengths of TSPs.</p><p>To validate the proposed methods, numerous simulations were performed to compare ACOMAC and Dorigo's ACS with and without the addition of the multiple nearest neighbor (NN) method or the dual nearest neighbor (DNN) approach, using a range of TSP benchmark problems. For example, the simulations were run to compare the ACOMAC (include ACOMAC + NN and ACOMAC + DNN) with Dorigo's ACS (include ACS + NN and ACS + DNN) using the Kroa100 benchmark problem with 100 nodes. Using ACO-MAC + DNN with TSP was observed to improve significantly the global optimum solution or a near global optimum solution.</p><p>The rest of this paper is organized as follows. Section 2 describes the ant colony optimization approach. Section 3 presents our proposed ACOMAC algorithm. Section 4 illustrates our simulation results. Section 5 makes a conclusion for this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Ant colony optimization (ACO)</head><p>The ant colony optimization (ACO) technique has emerged recently <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b21">22]</ref> as a relatively novel meta-heuristic for solving hard combinatorial optimization problems. It was designed to simulate the ability of ant colonies to determine the shortest paths to food. While individual ants have few capabilities, a colony can exhibit complex behavior. The ant colony optimization technique has emerged recently as a new meta-heuristic that belongs to the class of problemsolving strategies derived from nature. (Other categories include neural networks, simulated annealing, and evolutionary algorithms) <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref>. Ants lay trails of pheromone (in varying quantities) on the ground as they move, thus creating a trail. While isolated ants move essentially at random, ants that encounter previously laid pheromone trails detect these trails and are highly likely to follow them, thus reinforcing the trails with their own pheromone. The ant colony system (ACS) is investigated as a representative ACO method. The results can be generalized to other members of the ACO group. The ant colony optimization algorithm can briefly described as Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>The steps of the ACO algorithm are illustrated as follows (see <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18]</ref>):</p><p>Step 1: initialize the pheromone table</p><p>Step 2: randomly allocate ants to every node</p><p>Step 3: every ant must walk to next city, depending on the probability distribution given in Eq. ( <ref type="formula" target="#formula_0">2</ref>) (local search) Step 4: compute the length of the path traveled by each ant, and allocate a quantity amount of pheromone to the path, according to the length of its path Step 5: perform a local update Step 6: compute whether a better solution is obtained in this time step than the last; if so, then perform a global update on the solution and empty the Tabu value; repeat Steps 2 to 6</p><p>In discrete time steps, add one element (edge) to the solution of each ant until the termination condition is met. After an element is added, the quantity of pheromone associate with that element is altered. The amount of pheromone is a scalar value that allows ants to communicate with one another regarding the utility of an element. The accumulated strength of the pheromone on element i is represented by sðiÞ. At the beginning of each time step, Eq. ( <ref type="formula">1</ref>) is applied to select the next element s to that is added to the solution. The elements that may still be added to the solution by ant k in step r are indicated by J k ðrÞ. gðsÞ measures how good element s would be for the solution; restated, it represents an incremental cost measure. With respect to the TSP, the measure corresponds to the distance between two cities.</p><p>The following describes the state transition rule, global updating rule, and local updating rule as Eqs. ( <ref type="formula">1</ref>)-(3), respectively. Eq. ( <ref type="formula">1</ref>) is a very greedy selection technique that favors the optimum combination of pheromone level and cost. Eq. ( <ref type="formula">1</ref>) describes the state transition rule of ACS <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18]</ref>. This rule favors transitions toward nodes connected by short edges and large amounts of pheromone. The state transition rule represents the selection by an ant on node s of the city s to which to move <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18]</ref>, where S represents a random variable selected according to the probability distribution given in Eq. ( <ref type="formula" target="#formula_0">2</ref>); q denotes a random number uniformly distributed in [0 . . . 1], and q 0 represents a parameter (0 6 q 0 6 1) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18]</ref>. This probabilistic selection is essential to avoid premature convergence to a small group of elite solutions. Notably, the parameter can determine the relative importance of exploitation and exploration: whenever an ant in city r must choose a city s to move to, it samples a random number 0 6 q 6 1. If q 6 q 0 then the best edge, depending on Eq. (1), is selected (exploitation); otherwise an edge is selected according to Eq. (1) (biased exploration) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18]</ref> </p><p>For minimization (maximization) problems, the parameter b is negative (positive), meaning that smaller (larger) costs of each s are favored. The pheromone level of the selected element is updated depending on the local updating rule (Eq. ( <ref type="formula">3</ref>)) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18]</ref> otherwise a represents the local pheromone decay parameter. 0 &lt; a &lt; 1; Dsðr; sÞ ¼ s 0 denotes the initial amount of pheromone deposited on each of the elements, and L gb is the length of the optimal global tour from the beginning of the trail. While building a tour (that is, a solution) of the TSP, ants visit edges and change their pheromone level by applying the local updating rule, as in Eq. ( <ref type="formula">4</ref>) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18]</ref> sðr; sÞ ð1 À qÞ Á sðr; sÞ þ q Á Dsðr; sÞ ð 4Þ</p><p>where q denotes the global pheromone decay parameter. 0 &lt; q &lt; 1. Dsðr; sÞ is utilized to reinforce the pheromone level of the elements that compose the best solution obtained (Eq. ( <ref type="formula" target="#formula_1">5</ref>)) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18]</ref>.</p><formula xml:id="formula_1">Ds k ij ¼ Q L k if ði; jÞ 2 tour described by tabu k 0 otherwise 8 &lt; :<label>ð5Þ</label></formula><p>where Q denotes a constant that is usually set to 100. L k represents the tour length obtained by the kth ant. Notably, for each edge, the intensity of trail at time 0 (s ij ð0Þ) is set to a very small value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The proposed approach</head><p>This investigation develops a very simple, yet empirically powerful approach, named the ant colony optimization with multiple ant clans (ACO-MAC) algorithm. Additionally, we present two methods called the multiple nearest neighbor (NN) and the dual nearest neighbor (DNN) to ACOMAC to improve performance for large TSPs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">The ACOMAC algorithm</head><p>This study illustrates a novel ant colony optimization with multiple ant clans (ACOMAC) algorithm for solving the traveling salesman problem. The proposed algorithm can find optimal solutions via differently favorable strategy. The ACOMAC technique builds the mechanism utilizing the differently favorable ant clans' strategy. Restated, we adopt the basic concept of parallel genetic algorithm (PGA) to search solution space that utilizing different islands to avoid local minima and thus get global minimum for solving the traveling salesman problem.</p><p>Assume that all the ants are located in the same map or area, and are divided into several clans due to differences in favored modes of communication (i.e., local search). Sometimes one clan may acquire knowledge through messages received from other clans (i.e., global search). Increasing clan knowledge in this manner can increase clan survival capabilities. The detailed concept regarding the societal rule of multiple ant clans can be illustrated as follows. First, the entire ant clans search for the solution at each iteration by themselves, respectively (namely, local search). Meanwhile, after each fixative several local search iterations the ant clans will perform information communication to others (namely, global search). Furthermore, every clan must map its pheromone path to its register and then conduct information communication via Eq. ( <ref type="formula" target="#formula_2">6</ref>). Notably, Eq. ( <ref type="formula" target="#formula_2">6</ref>) represents the fact regarding pheromone exchange among clans.</p><formula xml:id="formula_2">Clan i ¼ Clan k Â ð1 À wÞ þ Clan i Â w; if i ¼ 1 Clan i ¼ Clan iÀ1 Â ð1 À wÞ þ Clan i Â w; otherwise<label>ð6Þ</label></formula><p>where i is the ith Clan, k denotes the number of clans, w represents the weighting of pheromone table of one clan (local weighting), 1 À w denotes the weighting of pheromone table of another clan (foreign weighting), 0 6 w 6 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Multiple nearest neighbor approach</head><p>The Nearest Neighbor (NN) approach is one kind of local search method <ref type="bibr" target="#b18">[19]</ref>. The multiple nearest neighbor (NN) heuristic for constructing a traveling salesman tour is addressed. The salesman starts at a city and then visits the city closest to the starting city. From there, he visits the nearest city that was not yet visited, until he has visited all cities, and then he returns to the first city. The multiple nearest neighbor (NN) tours have the advantage that they incorporate only a few serious mistakes, long segments connect nodes with short edges. Therefore, such tours are good starting tours for subsequent application of improvement methods and the expending of some effort to design heuristics based on the multiple nearest neighbor (NN) principle is reasonable. This paper also combines this concept with ACOMAC to search the solution space quickly. Furthermore, these near-optimal solutions are used as initial solutions for ACO or ACOMAC, reducing the time to convergence. In other words, employing the nearest neighbor approach to determine optimal solutions in the initial stage will increase slightly the strength of the pheromone trail (rs) along the search paths of the ant clans. Hence, the time taken by the ants to search for the shortest path will be reduced. This investigation calls this approach, the ''multiple nearest neighbor'' due to the fact that multiple solutions generated by the nearest neighbor approach are used as initial solutions. Fig. <ref type="figure">2</ref> illustrates the multiple nearest neighbor approach. Fig. <ref type="figure">2</ref>(a) depicts an initial map for the multiple nearest neighbor approach. Fig. <ref type="figure">2(b)</ref> shows the path sought by AC-OMAC or ACO to using various starting points. Notably, the figures on the left-hand side and the right-hand side of Fig. <ref type="figure">2(b)</ref> present two examples using a single starting point. Fig. <ref type="figure">2(c</ref>) demonstrates (the initial pheromone table) the total pheromone value (pheromone trial strength) of the path determined by the multiple nearest neighbor approach. Fig. <ref type="figure">2(c</ref>) assumes that the two solutions generated by the nearest neighbor approach are used as initial solutions; then the pheromone strengths of line AB, CE and DE in the initial pheromone table are 3rs, and those of lines AC, AD and BD equal 2rs, where rs represents the pheromone trail strength at the search paths of the ant clans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Dual nearest neighbor approach</head><p>Another novel method, called the dual nearest neighbor (DNN) approach, is proposed to enhance ACOMAC or ACO, by increasing the rate at which the solution space is searched in the initial search stage. In the dual nearest neighbor approach, the first city is randomly generated as a starting city (for example, node Starting 1 in Fig. <ref type="figure">3(b)</ref>) and then, the city farthest from the first city is generated as a second starting node (for example, node Starting 2 in Fig. <ref type="figure">3(b)</ref>). Notably, only the first city is randomly generated. The nearest neighbors are then found; then their nearest neighbors are found, and so on. Finally, only two lines are found not to be connected on the map. According to the results of the simulation, utilizing the DNN approach can increase the rate of the search of the solution space in the initial search stage, over that associated with the single starting point searching method. Notably, the DNN approach uses two starting points. Fig. <ref type="figure">3</ref> reveals the dual nearest neighbor approach. Fig. <ref type="figure">3(a)</ref> presents the initial map. Fig. <ref type="figure">3(b)</ref> shows the fact that two starting points (A Fig. <ref type="figure">2</ref>. The multiple nearest neighbor approach. and E) begin to search its nearest neighbor, respectively. Fig. <ref type="figure">3(c</ref>  Fig. <ref type="figure">3</ref>. The dual nearest neighbor approach.</p><p>using the NN and DNN approaches, respectively, to update the pheromone table. In Figs. <ref type="figure" target="#fig_1">4</ref> and<ref type="figure" target="#fig_2">5</ref>, the first while loop performs the ACOMAC algorithm, while the second while loop exchanges information among ants in the clan.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiment results</head><p>To demonstrate the performance of our proposed approach, we conduct some computer simulations on a PC Pentium III. In all the experiments of this section we set parameter values, if not differently indicated, as follows: the number of ant clans ¼ 5, each ant clan with 4 ants, q 0 ¼ 0:9, b ¼ 2, q ¼ a ¼ 0:1, m ¼ 10, and s 0 ¼ a very small constant ¼ ðn Á L nn Þ À1 , where L nn denotes the tour length produced by the nearest neighbor heuristic and n represents the number of cities, computer simulation runs ¼ 30, local weighting ðwÞ ¼ 0:6, foreign weighting ¼ 1 À w ¼ 0:4. Moreover, we conduct Eil51, Eil76, Kroa100, and D198 benchmark problems to compare the average length for our proposed ACOMAC and Dorigo's ACS <ref type="bibr" target="#b20">[21]</ref>. Notably, all our sample problem instances have been taken from the library TSPLIB, which is a publicly available set of TSP and vehicle routing problem data. It comprises most of the problem  instances for which computational results have been published <ref type="bibr" target="#b20">[21]</ref>. Table <ref type="table" target="#tab_4">1</ref> and Fig. <ref type="figure">6</ref> compare the proposed ACOMAC and Dorigo's ACS with and without the added NN approach or DNN approach, using various TSP benchmark problems. Fig. <ref type="figure">6</ref>   solution or near global optimum solution. According to the simulation results, adding the NN or DNN approach to ACOMAC or ACS, as initial solutions, also improves the performance of these methods in solving the traveling salesman problem. Meanwhile, using ACOMAC + DNN with TSP can yield better solutions than the other stated approaches. Moreover, ACOMAC or ACOMAC + NN, using five ant clans with a total of 20 ants, is verified to yield better solutions. Furthermore, ACOMAC with a local weighting (w) set to 0.6 can yield better solutions in terms of length. According to the simulation results (Tables <ref type="table" target="#tab_4">1</ref> and<ref type="table" target="#tab_5">2</ref>, Figs. <ref type="figure">7</ref> and<ref type="figure" target="#fig_3">8</ref>), a larger number of ant clans in DNN, NN or the multiple ant clans method will yield better solutions to the traveling salesman problem. However, more ant clans will also increase the time required to solve the problem. Hence, the use of five clans with the proposed algorithm is recommended to solve the traveling salesman problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This paper presents a new metaheuristic approach called ACOMAC algorithm for solving the traveling salesman problem (TSP). We introduce multiple ant clans' concept from parallel genetic algorithm to search solution space that using various islands to avoid local minima and thus yield global minimum or near global minimum to the traveling salesman problem. In addition, we present two methods called the multiple nearest neighbor (NN) and the dual nearest neighbor (DNN) to ACOMAC to improve large TSPs. According to the simulation results, adding the NN or DNN approach to ACOMAC or ACS, as initial solutions, also significantly enhances the performance of ACOMAC and ACS in solving the traveling salesman problem. Meanwhile, using ACOMAC + DNN with TSP can yield better solutions than the other stated approaches. Moreover, ACOMAC or ACOMAC + NN, utilizing five ant clans with a total of 20 ants, is demonstrated to yield better solutions. Furthermore, ACOMAC with a local weighting (w) set to 0.6 can yield better solutions in terms of length. It is observed that a larger number of ant clans in DNN, NN or the multiple ant clans method will yield better solutions to the traveling salesman problem. However, more ant clans will also increase the time required to solve the problem. Accordingly, the use of five clans with the proposed algorithm is recommended to solve the traveling salesman problem.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The ACO algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The proposed ACOMAC algorithm using multiple nearest neighbor to update pheromone table.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The proposed ACOMAC algorithm using dual nearest neighbor to update pheromone table.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Comparison of ACOMAC using different number of ant clans but total with 20 ants in Eil76 benchmark problem. (For color see online version.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>.</figDesc><table><row><cell>s ¼</cell><cell>8 &lt; :</cell><cell>arg max u2J k ðrÞ sðr; uÞ ½ n S</cell><cell>Á gðr; uÞ ½</cell><cell>b</cell><cell>o</cell><cell cols="2">if q 6 q 0 ðexploitationÞ otherwise ðbiased explorationÞ</cell></row><row><cell cols="3">8 &gt; &lt; P 0 &gt; :</cell><cell></cell><cell></cell><cell cols="2">otherwise</cell><cell>ð1Þ</cell></row></table><note><p>k ðr; sÞ ¼ ½sðr; sÞ Á ½gðr; sÞ b P u2J k ðrÞ ½sðr; zÞ Á ½gðr; zÞ b if s 2 J k ðrÞ</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>.</figDesc><table><row><cell>sðr; sÞ</cell><cell cols="2">ð1 À aÞ Á sðr; sÞ þ a Á Dsðr; sÞ</cell><cell>ð 3Þ</cell></row><row><cell>where</cell><cell></cell><cell></cell></row><row><cell cols="2">Dsðr; sÞ ¼</cell><cell>ðL gb Þ</cell></row></table><note><p><p>À1 </p>; if ðr; sÞ 2 global -best -tour 0;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>) is the initial pheromone table. Figs.4 and 5depict the proposed ACOMAC algorithm,</figDesc><table><row><cell>procedure ACOMAC algorithm for TSPs</cell></row><row><cell>Set parameters, initialize pheromone trails</cell></row><row><cell>Use Multiple Nearest Neighbor to update pheromone table</cell></row><row><cell>while (termination condition not met) do /* iterations */</cell></row><row><cell>while (termination condition not met) do /* steps */</cell></row><row><cell>Construct Solutions</cell></row><row><cell>ApplyLocalSearch</cell></row><row><cell>LocalPheromoneUpdate</cell></row><row><cell>After T Set local (i) pheromone := a P *(1-w) + ( l P *w)</cell></row><row><cell>loop</cell></row><row><cell>GlobalPheromoneUpdate</cell></row><row><cell>loop</cell></row><row><cell>end ACOMAC algorithm</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1</head><label>1</label><figDesc>compares the novel ACOMAC (including ACOMAC + NN and ACOMAC + DNN) with Dorigo's ACS (including ACS + NN and ACS + DNN) using the Kroa100 benchmark problem with 100 nodes. Table2compare ACOMAC and ACOMAC + NN using various numbers of ant clans in Eil51, Eil76 and Kroa100 benchmark problems. Table3compares ACOMAC using various local weightings (w) applied to different benchmark problems. Figs. 7 and 8 compare ACOMAC, using various Comparison of our ACOMAC (include ACOMAC + NN and ACOMAC + DNN) with Dorigo's ACS (include ACS + NN and ACS + DNN) using four different TSP benchmark problems</figDesc><table><row><cell>Bench-</cell><cell>ACS</cell><cell cols="3">ACOMAC ACS + NN ACOMAC</cell><cell>ACS</cell><cell>ACOMAC</cell></row><row><cell>mark</cell><cell></cell><cell></cell><cell></cell><cell>+ NN</cell><cell>+ DNN</cell><cell>+ DNN</cell></row><row><cell>problem</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Eil51</cell><cell>434.178</cell><cell>430.684</cell><cell>434.0757</cell><cell>430.0437</cell><cell>430.6656</cell><cell>430.0076</cell></row><row><cell>Eil76</cell><cell>559.7041</cell><cell>555.230</cell><cell>559.1892</cell><cell>553.94</cell><cell>557.772</cell><cell>552.6128</cell></row><row><cell cols="2">Kroa100 21,684.64</cell><cell>21,457.93</cell><cell>21,487.953</cell><cell>21,433.33</cell><cell cols="2">21,440.0923 21,408.23</cell></row><row><cell>D198</cell><cell>16,826.6</cell><cell>16041</cell><cell>16,558.7</cell><cell>16,034</cell><cell>16,337.8</cell><cell>15,955.6</cell></row></table><note><p><p>Comparison of our ACOMAC (include ACOMAC + NN and ACOMAC + DNN) with Dorigo's ACS (include ACS + NN and ACS + DNN). Using Kroa100 benchmark problem with 100 nodes. (For color see online version.)</p>numbers of ant clans but with a total of 20 ants, used to solve Eil51 and Eil76 benchmark problems, respectively. Using ACOMAC with TSP is observed to improve significantly improvement the determination of a global optimum</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2</head><label>2</label><figDesc>Comparison of ACOMAC and ACOMAC + NN using different number of ant clans in Eil51, Eil76, and Kroa100 benchmark problems</figDesc><table><row><cell></cell><cell>Number of clans</cell><cell>ACOMAC</cell><cell>ACOMAC + NN</cell></row><row><cell>Eil51</cell><cell>2</cell><cell>431.226</cell><cell>430.9563</cell></row><row><cell>Eil51</cell><cell>3</cell><cell>431.5412</cell><cell>430.6895</cell></row><row><cell>Eil51</cell><cell>4</cell><cell>430.6884</cell><cell>430.68953</cell></row><row><cell>Eil51</cell><cell>5</cell><cell>430.6884</cell><cell>430.04376</cell></row><row><cell>Eil76</cell><cell>2</cell><cell>557.678</cell><cell>557.317</cell></row><row><cell>Eil76</cell><cell>3</cell><cell>555.7606</cell><cell>555.724</cell></row><row><cell>Eil76</cell><cell>4</cell><cell>555.2301</cell><cell>553.94</cell></row><row><cell>Eil76</cell><cell>5</cell><cell>555.701</cell><cell>555.598</cell></row><row><cell>Kroa100</cell><cell>2</cell><cell>21,621.333</cell><cell>21,531.893</cell></row><row><cell>Kroa100</cell><cell>3</cell><cell>21,471.8333</cell><cell>21,559.183</cell></row><row><cell>Kroa100</cell><cell>4</cell><cell>21,487.9533</cell><cell>21,513.73</cell></row><row><cell>Kroa100</cell><cell>5</cell><cell>21,457.93</cell><cell>21,433.33</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>C.-F. Tsai et al. / Information Sciences 166 (2004) 67-81</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The author would like to thank the National Science Council of Republic of China for financially supporting this research under grant NSC 90-2213-E-020-003.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>q This research was partially supported by National Science Council under grant NSC 90-2213-E-020-003.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Optimization Learning and Natural Algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
		<respStmt>
			<orgName>Dip. Elettronica, Politecnico di Milano</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Positive Feedback as a Search Strategy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Maniezzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Colorni</surname></persName>
		</author>
		<idno>91-106</idno>
	</analytic>
	<monogr>
		<title level="j">Dip. Elettronica</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Politecnico di Milano</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The ant system: optimization by a colony of cooperating agent</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Maniezzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Colorni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on System, Man, and Cybernetics--Part B</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="42" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Maniezzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Colorni</surname></persName>
		</author>
		<title level="m">Evolutionary Algorithms in Engineering and Computer Science</title>
		<meeting><address><addrLine>England</addrLine></address></meeting>
		<imprint>
			<publisher>John Wily &amp; Sons Ltd</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Applying the Ant System to the vehicle routing problem</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bullnheimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Hartl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Strauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Metaheuristics</title>
		<meeting>the 2nd International Conference on Metaheuristics</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">AntNet: distributed stigmergetic control for communications networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Di</forename><surname>Caro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research (JAIR)</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="317" to="365" />
			<date type="published" when="1998-12">December. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">HAS-SOP: Hybrid Ant System for the Sequential Ordering Problem</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<idno>IDSIA 11-97</idno>
	</analytic>
	<monogr>
		<title level="j">IDSIA</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<pubPlace>Lugano, Switzerland</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The MAZ-MIN ant system and local search for the traveling salesman problem</title>
		<author>
			<persName><forename type="first">T</forename><surname>Stutzle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Evolutionary Computation (ICEC&apos;97)</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Baeck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</editor>
		<meeting>the IEEE International Conference on Evolutionary Computation (ICEC&apos;97)</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="309" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ant colony system: a cooperative learning approach to the traveling salesman problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="66" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The Traveling Salesman Problem</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Lawer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Lenstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H R</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Shmoys</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The traveling salesman problem</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Flood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operation Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="61" to="78" />
			<date type="published" when="1955">1955</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">H</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><surname>Noschang</surname></persName>
		</author>
		<author>
			<persName><surname>Webpage</surname></persName>
		</author>
		<ptr target="http://www.ececs.uc.edu/~mnoschan/sale.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The immune genetic algorithm and its convergence</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Proceedings</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1347" to="1350" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural computations of decisions in optimization problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hopfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="141" to="152" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Annealing framework with learning memory</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Hus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on System, Man, Cybernetics, Part A</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Tabu search-part I</title>
		<author>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ORSA Journal of Computing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="190" to="206" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Tabu search-part II</title>
		<author>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ORSA Journal of Computing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="32" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Ant system: optimization by a colony of cooperating agents</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Maniezzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Colorni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on System, Man and Cybernetics--Part B</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="41" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An analysis of several heuristics for the traveling salesman problem</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rosenkrantz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Stearns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal of Computer</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="563" to="581" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Cantu-Paz</forename><surname>Erick</surname></persName>
		</author>
		<title level="m">A Summary of Research on Parallel Genetic Algorithms, IlliGAL Report No. 95007</title>
		<imprint>
			<date type="published" when="1995-07">July 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName><surname>Tsplib Webpage</surname></persName>
		</author>
		<ptr target="http://www.iwr.uni-heidelberg.de/groups/comopt/software/TSPLIB95/tsp/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">The Ant Colony Optimization Meta-Heuristic, New Ideas in Optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Caro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>McGraw-Hill</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
