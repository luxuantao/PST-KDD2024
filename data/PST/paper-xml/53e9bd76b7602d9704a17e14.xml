<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cosegmentation of Image Pairs by Histogram Matching -Incorporating a Global Constraint into MRFs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Carsten</forename><surname>Rother</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vladimir</forename><surname>Kolmogorov</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tom</forename><surname>Minka</surname></persName>
							<email>minka@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Blake</surname></persName>
							<email>ablake@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research Cambridge</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Cosegmentation of Image Pairs by Histogram Matching -Incorporating a Global Constraint into MRFs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5E459EC02928EA064976B673E7E524FE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce the term cosegmentation which denotes the task of segmenting simultaneously the common parts of an image pair. A generative model for cosegmentation is presented. Inference in the model leads to minimizing an energy with an MRF term encoding spatial coherency and a global constraint which attempts to match the appearance histograms of the common parts. This energy has not been proposed previously and its optimization is challenging and NP-hard. For this problem a novel optimization scheme which we call trust region graph cuts is presented. We demonstrate that this framework has the potential to improve a wide range of research: Object driven image retrieval, video tracking and segmentation, and interactive image editing. The power of the framework lies in its generality, the common part can be a rigid/non-rigid object (or scene), observed from different viewpoints or even similar objects of the same class.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This paper looks at segmentation, which is a fundamental problem in computer vision, and particularly at the simultaneous segmentation of a pair of images, an operation that we term "cosegmentation". Powerful procedures for low-level segmentation can be produced by incorporating difference measures at the level of pixels, into a global objective function <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b16">17]</ref>. The objective function can also incorporate a tendency to coherence of regions. Completely automatic segmentation is possible <ref type="bibr" target="#b19">[20]</ref> but prone to error, and interactive input <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b16">17]</ref> or fusion with other modalities <ref type="bibr" target="#b12">[13]</ref>, is normally needed to correct those errors. Another source of information for correcting segmentation is to supply a database of related images and segment them simultaneously <ref type="bibr" target="#b20">[21]</ref>. Here we demonstrate that supplying just one additional image can be sufficient to segment both together, to higher accuracy than is achieved with either one alone. Furthermore, in contrast to <ref type="bibr" target="#b20">[21]</ref> we do not exploit a shared shape model which has the advantage of being completely viewpoint independent.</p><p>Apart from clear applications in interactive graphics, for segmentation of images and videos, cosegmentation has implications in another important area: image similarity measures. Commonly the degree of similarity of a pair of images has been computed by comparing the global statistics of the two images. Typically the comparison is applied to the histograms of each image, constructed from features such as colour and texture <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b6">7]</ref>. However, such a global, undifferentiated approach to comparison is liable to result in crude comparisons, as figures 5, 6 show. Apparently, it is essential to incorporate some form of differentiation of parts of images, so that comparison can be based on those parts of an image pair which are shared in common. In that way, a similarity between subjects can be scored highly, without unreasonable dilution by differences in backgrounds. (Conversely, similarities in the background scenes of a pair of images could be captured despite the subjects being unrelated.) One approach to such differentiation, is "integrated region matching" <ref type="bibr" target="#b10">[11]</ref>, in which images are subjected to mean-shift segmentation <ref type="bibr" target="#b4">[5]</ref>, and then a simple similarity measure records the similarity of paired regions, in a search over both segmented images. However, the choice of paired regions takes no account of object coherence, and so cannot properly take account of the distinction between subject and background. Here we address that shortcoming by jointly cosegmentation the image pair using a proper MRF coherence prior and a histogram matching cost, and then compare either subject or background.</p><p>A sub-problem which arises in cosegmentation is the problem of finding a coherent image region with given target histogram. This problem has been approached previously using ellipses or active contours to define coherence <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b8">9]</ref>. Inspired by <ref type="bibr" target="#b16">[17]</ref>, we instead define coherence via MRF priors and solve the problem with iterated graph cuts.</p><p>In order to arrive at an objective function for cosegmentation, we begin, in sec. 2, by setting out a generative model for an image pair, and then evaluating the hypothesis that the images share common material. The recovered cosegmentation will then be that pair of regions, one from each image, under which that hypothesis is most probable. One approach to the generative model considers pixels in the backgrounds and foregrounds of each image to have been generated independently from a certain probability distribution for colour (or texture). Then, under the hypothesis, the foreground distributions are constrained to be identical. This can be shown to yield, as a likelihood for the images, a function of the well-known Jensen-Shannon divergence between foreground histograms (see <ref type="bibr" target="#b17">[18]</ref>). However, the independence assumption is something of a drawback, as it is known that nearby pixels in an image are not generally independent <ref type="bibr" target="#b7">[8]</ref>. If instead we choose a generative model for the foreground histograms as a whole, rather than individual pixels, we can obtain other standard divergences such as variational distance. A further Ising prior on segmentations, gated by image contrast <ref type="bibr" target="#b2">[3]</ref>, encourages smooth boundaries.</p><p>The optimisation of the objective function arising from that generative model, is something of a challenge. Graph cut algorithms are widely used for binary optimisation in Markov models <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b2">3]</ref>, but have not been used before where the objective function contains a histogram difference measure. It transpires that such an objective function is not "submodular" and therefore strictly not tractable. Therefore we develop, in sec. 3, a new, approximate algorithm based on graph cuts. Finally, in sec. 4, we show a series of results, demonstrating the effectiveness of the new model and algorithm in image segmentation, and in the development of image similarity measures that respect the distinction between subject and background.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">A Generative Model for Cosegmenting Image Pairs</head><p>Due to lack of space the following derivation includes several approximations and one particular image generation model, the full derivation including an alternative image generation model can be found in <ref type="bibr" target="#b17">[18]</ref>.</p><p>Let k ∈ {1, 2} range over images and i ∈ {1, . . . , n} range over pixels.</p><p>• x ki ∈ {0, 1} indicates whether pixel i in image k is foreground. x k is shorthand for the entire labeling in image k, and x is shorthand for both images. • z ki is an image measurement, e.g. colour or texture at pixel i in image k. We assume that this measurement falls into a finite number of bins. Symbol z will range over these bins. Given x k , z kf is shorthand for all foreground pixels, and z kb for all background pixels. z k is shorthand for the entire image k, and z is shorthand for all images. • θ kf denotes foreground model parameters for z k . θ kb denotes background model parameters. θ k is shorthand for both (θ kf , θ kb ), and θ is shorthand for all θ k .</p><p>Given two images z = (z 1 , z 2 ), we consider two possible generative models, illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>. In both models, the segmentations and background models are independent across images. If J = 0 then the foreground models are independent; if J = 1 then the foreground models are the same. This difference shows up only in the prior for θ. Therefore the image model given the segmentations is:</p><formula xml:id="formula_0">p(z|J, x) = p( θ|J) k p(z kf |θ kf )p(z kb |θ kb )d θ . (1)</formula><p>Due to the number of pixels, the likelihood will be sharp so for simplicity we approximate the integral over θ with the maximum <ref type="foot" target="#foot_0">1</ref> :</p><formula xml:id="formula_1">p(z|J = 0, x) ≈ max θ p( θ) k p(z kf |θ kf )p(z kb |θ kb ) (2a) p(z|J = 1, x) ≈ max θ 1f =θ 2f p( θ) k p(z kf |θ kf )p(z kb |θ kb ) .<label>(2b)</label></formula><p>Under this approximation, p(z|J = 0, x) ≥ p(z|J = 1, x) always.</p><p>We want to choose the segmentations x k so that the hypothesis J = 1 has high posterior probability. In other words, we want to find</p><formula xml:id="formula_2">x⋆ = argmax x p(J = 1|z, x)p(x)<label>(3)</label></formula><p>where p(J = 1|z, x) = p(z|J = 1, x)p(J = 1) p(z|J = 0, x)p(J = 0) + p(z|J = 1, x)p(J = 1) .</p><p>We will set p(J = 0) = p(J = 1), so these terms disappear.</p><p>To simplify the formula, define</p><formula xml:id="formula_3">D(z|x) = log p(z|J = 0, x) p(z|J = 1, x) .<label>(4)</label></formula><p>In this ratio, the background terms cancel, and we will obtain a measure of divergence between the foreground areas of z 1 and z 2 . Under the approximation (2), D ≥ 0.</p><p>Taking the negative logarithm of (3) gives the following energy minimization problem:</p><formula xml:id="formula_4">x⋆ = argmin x log(1 + exp(D(z|x))) -log p(x) (5a) ≈ argmin x 1 2 D(z|x) -log p(x) . (<label>5b</label></formula><formula xml:id="formula_5">)</formula><p>This approximation is justified when D is small at the optimum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prior p(x)</head><p>We use an MRF model for each image. Furthermore, we assume that larger foreground regions are more likely a priori. Thus, we have</p><formula xml:id="formula_6">-log p(x) = λ bg k,i (1-x ki )+ k,(i,j) λ ki,kj |x ki -x kj |+const (6)</formula><p>where the second sum is over pairs of neighboring pixels. We use the following expression for coefficients λ ki,kj :</p><formula xml:id="formula_7">λ ki,kj = λ 1 + λ 2 exp(-β||I ki -I kj || 2 )</formula><p>where I ki is the colour of pixel i in image k and β = (2 ||I ki -I kj || 2 ) -1 . This is similar to the contrastsensitive term in <ref type="bibr" target="#b16">[17]</ref>, with the addition of Ising prior λ 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image generation model</head><p>The remaining task is to specify the image generation model for the foreground region: p(z kf |θ kf ). By choosing this model carefully, we obtain a commonly used divergence measure D. Our choice is a Gaussian model on histograms, which leads to the classical variational distance. Let ĥkf be the empirical un-normalized histogram of foreground pixels: ĥkf (z) = i x ki δ(z kiz). Given a histogram, the foreground is generated by laying out exactly the expected number of pixels from each colour bin, then randomly permuting them. Therefore p(z kf |θ kf ) is proportional to p(h kf = ĥkf |θ kf ) and we only need to specify the distribution p(h kf |θ kf ). In the following, everything concerns foreground so we will drop the f subscript. The target histogram h k is generated by a Gaussian distribution with parameters</p><formula xml:id="formula_8">x 1 z 1 θ 1b θ 1f x 2 z 2 θ 2b θ 2f J = 0 x 1 z 1 θ 1b θ ⋆f x 2 z 2 θ 2b J = 1</formula><formula xml:id="formula_9">θ k = (m k , v k ),</formula><p>with hyperparameter c k controlling the expected size of the foreground region:</p><formula xml:id="formula_10">p(h k |m k , v k ) = z N (h k (z); c k m k (z), c 2 k v k (z)) .<label>(7)</label></formula><p>Note that (m k , v k ) are shared under J = 1 but c k is not. Therefore c k can compensate for foreground size differences among the images. We will use a uniform prior on m k and Gamma prior on v k :</p><formula xml:id="formula_11">p(v k (z)) ∝ v k (z) exp(- v k (z) b 2 ) .<label>(8)</label></formula><p>When J = 0, mk = ĥk /c k and vk = 0 so:</p><formula xml:id="formula_12">p(z|J = 0, x) ≈ 1 .<label>(9)</label></formula><p>When J = 1:</p><formula xml:id="formula_13">m⋆ = 1 2 k ĥk c k , v⋆ (z) = b 2 ĥ1 (z) c 1 - ĥ2 (z) c 2<label>(10)</label></formula><formula xml:id="formula_14">p(z|J = 1, x) ≈ z p(v ⋆ (z)) k N ( ĥk (z); m⋆ (z), v⋆ (z)) D(z|x) = 1 b z ĥ1 (z) c 1 - ĥ2 (z) c 2 . (<label>11</label></formula><formula xml:id="formula_15">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Optimization</head><p>In the previous section we described a generative model that yields the following energy function:</p><formula xml:id="formula_16">E(x; c 1 , c 2 ) = -log p(x) + E global ( ĥ1 , ĥ2 ; c 1 , c 2 ) (12)</formula><p>The first term is given by ( <ref type="formula">6</ref>); it encodes the usual MRF prior on labeling x. The second term is quite different from the first one: it depends on global properties of segmentation x, namely histograms of foreground regions ĥ1 , ĥ2 :</p><formula xml:id="formula_17">E global ( ĥ1 , ĥ2 ; c 1 , c 2 ) = 1 2b z ĥ1 (z) c 1 - ĥ2 (z) c 2 . (<label>13</label></formula><formula xml:id="formula_18">)</formula><p>The presence of this global term makes the minimization problem quite challenging. One could think of using some general inference algorithm, such as Swendsen-Wang Cuts for sampling arbitrary posterior probabilities <ref type="bibr" target="#b0">[1]</ref>. Another possibility is to use active contours <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b8">9]</ref>. We argue, however, that since the MRF term is an essential part of the energy, it is desirable to use the well-established technique for binary MRFs -min cut/max flow algorithm <ref type="bibr" target="#b3">[4]</ref>. Fortunately, the form of our global term will allow to use max flow algorithm inside the method called submodular-supermodular procedure <ref type="bibr" target="#b14">[15]</ref>.</p><p>For simplicity, in this paper we set c 1 = c 2 = 1, which means that we prefer foreground regions of the same size. It is easy, however, to extend the model to account for different sizes: we can put some prior on c 1 , c 2 and minimize energy (12) iteratively, i.e. fix c 1 , c 2 and optimize over x and then the other way around.</p><p>We now describe how we minimize energy <ref type="bibr" target="#b11">(12)</ref>. We iterate between the following two steps: (1) Fix x 2 , optimize over x 1 , and (2) fix x 1 , optimize over x 2 . Each subproblem requires minimizing the following function:</p><formula xml:id="formula_19">-log p(x k ) + 1 2b z | ĥk (z) -h target (z)|<label>(14)</label></formula><p>where the target histogram h target is the empirical histogram of the foreground in other image. For the remainder of this section we focus on how to solve this subproblem for a given image k. Since k is fixed, we will omit it for brevity.</p><p>The energy function can be written as</p><formula xml:id="formula_20">E(x) = E 1 (x) + E 2 (x)<label>(15)</label></formula><p>where the first term corresponds to the prior on x and the second to the global histogram term. An important observation is that E 1 is submodular and E 2 is supermodular, i.e. they satisfy</p><formula xml:id="formula_21">E 1 (x ∧ x ′ ) + E 1 (x ∨ x ′ ) ≤ E 1 (x) + E 1 (x ′ ) E 2 (x ∧ x ′ ) + E 2 (x ∨ x ′ ) ≥ E 2 (x) + E 2 (x ′ )</formula><p>for all configurations x, x ′ . It is well-known that any submodular function can be minimized in polynomial time <ref type="bibr" target="#b18">[19]</ref>. In our case E 1 (x) is a sum of unary and pairwise terms, so a global minimum of E 1 can be computed very efficiently via min cut/max flow algorithm. The presence of supermodular part, however, makes the problem NP-hard.</p><p>The submodular-supermodular procedure <ref type="bibr" target="#b14">[15]</ref> is a promising approximate minimization technique for functions of the form <ref type="bibr" target="#b14">(15)</ref>. Sec. 3.1 gives an overview of this approach. Sec. 3.2 we discusses its potential difficulties and proposes an alternative method -trust region graph cuts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Submodular-supermodular procedure (SSP)</head><p>This method was inspired by concave-convex procedure for minimizing functions of continuous variables <ref type="bibr" target="#b21">[22]</ref>. SSP is an iterative technique which produces a sequence of configurations x 0 , x 1 , . . . , x t , . . .. The main property of SSP is that the energy never goes up, i.e. E(x 0 ) ≥ E(x 1 ) ≥ . . .. Let x t be the current configuration. The method performs the following steps:</p><p>(a) Replace supermodular part E 2 (x) with a linear approximation E 2 (x) = C + x, y = C + i x i y i where C is a constant and y is a real-valued vector.</p><p>(Such a function is also called modular).</p><p>(b) Compute a global minimum of function E 1 (x) + E 2 (x) to get new configuration x t+1 .</p><p>Note that minimization in the second step can be performed in polynomial time since the function is submodular. (Linear function y, x simply adds unary terms to E 1 (x)). Linear approximation chosen in step (a) must satisfy two properties: (i) It must be an upper bound on the supermodular part, i.e. E 2 (x) ≥ E 2 (x) for all configurations x. (ii) The functions should touch at x t : E 2 (x t ) = E 2 (x t ). These properties ensure that the original energy does not go up since</p><formula xml:id="formula_22">E(x t+1 ) ≤ E 1 (x t+1 ) + E 2 (x t+1 ) ≤ E 1 (x t ) + E 2 (x t ) = E(x t ).</formula><p>It remains to specify how to choose an upper bound E 2 (x) (i.e. corresponding vector y) with the properties above. (Existance of such a bound follows from supermodularity of E 2 ). <ref type="bibr" target="#b14">[15]</ref> uses the following procedure. First, an ordering of nodes π(•) is selected which "respects" current labeling x t , i.e. all ones precede all zeros:</p><formula xml:id="formula_23">x t π(1) ≥ x t π(2) ≥ . . . ≥ x t π(n)</formula><p>. This ordering defines the following n + 1 configurations: x (0) = (0, 0, . . . , 0), x (1) = (1, 0, . . . , 0), . . . , x (n) = (1, 1, . . . , 1), where we assumed that the nodes are ordered according to π. (Formally, x (j) i is zero if π(i) ≤ j, and one otherwise). The fact that ordering π "respects" current labeling x t simply means that x t is one of these n + 1 configurations. Finally, approximation E 2 (x) is chosen so that it is exact for these n + 1 configurations: E 2 (x (j) ) = E 2 (x (j) ), j = 0, 1, . . . , n. Solving n + 1 equations with n + 1 unknowns yields</p><formula xml:id="formula_24">C = E 2 (x (0) ) , y π(i) = E 2 (x (i) ) -E 2 (x (i-1) )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Trust region graph cuts (TRGC)</head><p>For SSP it is important to choose "good" representative configurations x (0) , . . . , x (n) . If, for example, a global minimum of E(•) happens to be among these configurations, then the procedure will find this minimum. Choosing good configurations, however, is a difficult problem. First, there is a restriction on representative configurations 2 : there must hold either x (j) ≤ x t or x (j) ≥ x t . Second, even if there is an ordering that would decrease the energy, computing such an ordering is an NP-complete problem (see discussion in <ref type="bibr" target="#b17">[18]</ref>).</p><p>It could be desirable to choose linear approximation E 2 (x) = C + x, ỹ which is not based on any ordering. For example, we could set ỹi = E 2 (x i;1 ) -E 2 (x i;0 ) where x i;s is the labeling obtained from x t by setting x i to s. This approximation is exact for all configurations that differ from x t by at most one pixel. It can also be obtained by keeping linear terms in the Taylor expansion of energy E 2 expressed as a function of the global histogram of x (assuming that E 2 is differentiable).</p><p>Unfortunately, this approximation is not an upper bound on E 2 (x). This means that minimizing E 1 (x) + E 2 (x) is not guaranteed to decrease the original energy. To remedy this problem, we propose an alternative method which we call trust region graph cuts (TRGC). It allows arbitrary linear approximations E 2 (x) which are not upper bounds. Furthermore, in this method function E 2 (x) can also be arbitrary -it is no longer required to be supermodular.</p><p>Trust region methods are well-known in continuous optimization <ref type="bibr" target="#b1">[2]</ref>; TRGC can be viewed as their discrete analogue. A related continuous optimization method is the linearization method of Pschenichnyj <ref type="bibr" target="#b15">[16]</ref>.</p><p>Description of TRGC Instead of selecting unary potentials y based on some ordering, we will optimize over y. Our technique produces a sequence of vectors (x 0 , y 0 ), . . . , (x t , y t ), . . . with the following properties: (i) x t = arg min x E 1 (x) + x, y t , and (ii) the energy does not go up: E(x 0 ) ≥ E(x 1 ) ≥ . . ..</p><p>The method works as follows. Let (x t , y t ) be the current state, and E 2 (x) = C + x, ỹ be a desired approximation of E 2 (x). Let us define y(α) = (1α)y t + αỹ, and let x(α) be a global minimum of function E 1 (x) + x, y(α) <ref type="foot" target="#foot_2">3</ref> . Note that α = 0 corresponds to the current solution x t , and α = 1 corresponds to taking approximation E 2 (x). We now search for α ∈ [0, 1] that minimizes E(x(α)). This defines new vectors x t+1 and y t+1 . If α = 0 is within the range of values that we test, the energy is guaranteed not to go up.</p><p>We implemented the following one-dimensional search routine: we start with α = 1 and we keep halving it until one of the following happens: (a) x(α) = x t ; (b) α &lt; 10 -3 ; or (c) energy E(x(α)) is larger compared to the previous α, and the energy for the previous α was smaller than E(x t ).</p><p>It is important to note that TRGC is a trust region method working in the dual space: we optimize over dual variables y rather than primal variables x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Implementational details</head><p>The general structure of the algorithm for cosegmenting an image pair is described in the beginning of sec. 3. The remaining question is the initialization of the target distributions and the segmentation for the first iteration. For this we employ a procedure which finds the largest regions in two images of the same size whose histograms match perfectly. This is done via a greedy algorithm that adds one pixel at a time to the first and second foreground regions. Note, this gives the minimum energy if the spatial prior is ignored.</p><p>SSP. The most important question for SSP is how to choose an ordering of nodes π. We tested two schemes. In the first one we selected a random permutation of elements that respects current configuration x. This is similar to the technique used in <ref type="bibr" target="#b14">[15]</ref>, with one modification: we take random permutation of 10 × 10 blocks rather than individual pixels. Inside each block pixels with the same segmentation are ordered sequentially. Thus, we try to take into account the fact that due to spatial coherence all pixels inside a block are likely to have the same segmentation. Our second scheme is deterministic: given initial configuration, we compute a signed distance map from segmentation boundary and order pixels according to this distance. In this scheme representative configurations x (0) , . . . , x (n) correspond to diluting or eroding the current foreground region. For a fixed target histogram we ran a maximum of 50 iterations of SSP procedure. We observed, however, that in the majority of cases only the first few iterations decrease the energy, and then the energy stays constant.</p><p>TRGC. We used the SSP procedure for initialization (i.e. for computing (x 0 , y 0 )). We ran the algorithm until convergence, i.e. until searching over α did not yield any improvement in the energy.</p><p>For both approaches we used maxflow algorithm in <ref type="bibr" target="#b3">[4]</ref>. Furthermore for all experiments we set λ bg = 0.3, λ 1 = 1, λ 2 = 50 and b = 0.5. Finally let us introduce our appearance model. We have experimented with a simple 2D intensity normalized RGB colour space and a richer texture (texton) based model <ref type="bibr" target="#b13">[14]</ref>, which has been proven to be very powerful for image retrieval <ref type="bibr" target="#b6">[7]</ref>. Apart from scenarios of retrieving images of the same class we have used the simple model since the emphases on colour improved the performance, if the common part is the identical object. A thorough testing of different appearance models is a part of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Comparison of SSP and TRGC. We built a data set of 50 images which depict a foreground object in front of a background. The ground truth segmentation of the foreground object has been achieved manually 4 . In some im- 4 The data set is publicly available at http://research.microsoft.com/vision/cambridge/i3l/segmentation/GrabCut.htm  ages the object is "camouflaged" (e.g. fig. <ref type="figure" target="#fig_2">3</ref>(left)), where fore-and background have similar appearance, in other images (e.g. 4(left)) they have different appearances. Given the target histogram of the ground truth segmentation we compare the performance of the submodular-supermoduler procedure (SSP) with our version (TRGC). We also compare the performance of ordering of the nodes (see sec. 3.3): Random ordering (rand.), as suggested in <ref type="bibr" target="#b14">[15]</ref>, versus distance map ordering (dist.). As performance measure we utilize the average energy (av. Energy) and the percentage of misclassified pixels (av. Error) with respect to ground truth. The results are summarized in table <ref type="table">4</ref>. It is clear that TRGC outperforms SSP considerably both in terms of lower energy and quality of result. Note that the energy of TRGC was always lower than SSP. With respect to the pixel ordering: random versus distance transform, the later performs slightly better, and is also deterministic. Consequently we used the TRGC method with distance transform ordering for initialization as our method for the remaining experiments. Fig. <ref type="figure" target="#fig_2">3</ref> shows an example where TRGC outperforms SSP. Note, the fact that the ground truth has a relatively low energy shows that our problem setting is reasonable. Examples of cosegmentation using TRGC are shown in fig. <ref type="figure" target="#fig_0">1,</ref><ref type="figure" target="#fig_3">4</ref><ref type="figure" target="#fig_4">5</ref><ref type="figure">6</ref><ref type="figure">7</ref>. Fig. <ref type="figure" target="#fig_3">4</ref> demonstrates that the segmentation quality depends on the background penalty λ bg . Our generative framework gives us the option of learning this parameter given a training and validation data set. To obtain such a database is part of future work. Robust Image distance for Image retrieval. In the following we consider two examples where we demonstrate that cosegmentation improves an image retrieval system based on global histogram comparison. The key idea is to use the energy as a distance measure between an image pair. This is a valid measurement since identical images have energy (distance) 0. Another nice feature of our energy is that by adjusting λ bg = ∞ it gives the standard global histogram difference of the whole image, as used in e.g. <ref type="bibr" target="#b6">[7]</ref>. As in all previous examples we set λ bg = 0.3.</p><p>In fig. <ref type="figure" target="#fig_4">5</ref> we compare the distance between three images where two of them depict the same scene and the third an unrelated scene. We demonstrate that using cosegmentation two images of the same scene have a smaller distance than two unrelated images. This is in contrast to using an appearance statistics of the whole image where two unrelated images have a smaller distance (details in figure caption).</p><p>In the second example, fig. <ref type="figure">6</ref>, we compare the distance of a triplet of images where two images depict an object of the same class (bus) and a third unrelated image. The findings are as in the previous case, cosegmentation gives the correct relationship for the triplet (see figure caption for details). Given the middle image in fig. <ref type="figure">6</ref> as query, the right image is in fact the most similar image from the Corel database of 1000 images used in <ref type="bibr" target="#b10">[11]</ref> and based on global texture (texton <ref type="bibr" target="#b13">[14]</ref>) statistics. The fact that our cosegmentation system returns an image containing an object of the same class ( fig. <ref type="figure">6 left</ref>) is a proof of concept that the retrieval performance for this particular query image improves. Further quantitative tests on the whole database have to be carried out. In particular, it has to be tested that ignoring the similarity of the background does not decrease performance for a query image which does not contain a well defined object. Further Applications. Let us demonstrate other applications where our generative framework can be applied successfully. Fig. <ref type="figure">7</ref> shows an example for video summarization and interactive cosegmentation (see figure caption for details). Fig. <ref type="figure" target="#fig_5">8</ref> depicts an application where our generative framework is used for automatically tracking and segmenting a foreground object in a video sequence given a target distribution in the first key frame (details in figure caption).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Work</head><p>We have presented a novel generative model for cosegmenting the common parts of an image pair. The strength of the model is its generality: The common part can be a rigid/non-rigid object (or scene), observed from different viewpoints or even similar objects of the same class. Inference in the model leads to minimization an energy with an MRF term encoding spatial coherency and a global constraint which tries to match the appearance histograms of the common parts. This exact energy has not been proposed earlier and its optimization is challenging and NP-hard. We have presented a novel optimization scheme which we call trust region graph cuts, and have demonstrated its superiority to a competitive method on a large data set. Our new framework has clear applications for interactive graphics,  The distance (SAD) of the global colour histograms of the whole images says that the middle image is more similar to the right (48%) than to the left image (52%). Running cosegmentation gives the expected answer (bottom row). The cosegmentation of the left and middle image nicely moves the regions which do not appear in both images (telephone box, sky and road) to the background (label light blue). Note that the depicted cosegmentation of the middle image is with respect to the left image. When using the energy of the cosegmentation as distance measure, the middle image is now more similar (42%) to the left than the right image (58%). Note that the percentages are derived by comparing the absolute energies. Also, note that the cosegmentation measure without the spatial coherence term (MRF) gives, as the global histogram of whole images, the incorrect answer. Figure <ref type="figure">6</ref>. Robust Image distance -similar objects. Same explanation as in fig. <ref type="figure" target="#fig_4">5</ref>, apart from the fact that the appearance model is based on texture (textons <ref type="bibr" target="#b13">[14]</ref>). Note that the trees in the background where assigned a different texton label. Figure <ref type="figure">7</ref>. Video Summarization and Interactive cosegmentation. Given two key frames from a video, our method can extract automatically the common part. This can be used to summarize the video. In this case the segmentation is not perfect, due to colour variations on the book cover. In an interactive cosegmentation system the foreground object can be extracted from both images, by editing only one image. We utilize the interactive brushing style of <ref type="bibr" target="#b2">[3]</ref>. In the image (second from right) a red brush stroke indicates an explicit marking of the foreground. Obviously, the updated histogram of the left image forced a better solution for the right image. video tracking and segmentation. Probably the most important application is object-driven image retrieval, for which we propose a new and robust similarity measurement for image pairs. In the future we hope to quantify our initial findings in this area. A further future direction is the incorporation of feature matches (optical flow) which is an essential component of any standard wide-baseline matching, or tracking system. Also a comparison with an alternative generative model, introduced in <ref type="bibr" target="#b17">[18]</ref>, is important.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Introducing cosegmentation. Given a pair of images (a) the objective is to segment the common part in both images. (b) Shows the result of applying GrabCut [17] on the images separately, with a preference of foreground being more likely in the image center. The result is as expected since the joint foreground is not modeled. (c) Shows the result of performing cosegmentation, however, without any spatial constraints. (d) Result of our complete cosegmentation framework.</figDesc><graphic coords="2,50.17,75.12,492.32,89.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The two hypotheses for image generation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Comparison of TRGC and SSP. The goal is to segment the object (penguin) in the input image (a) given the target histogram of the ground truth segmentation (b). The result of TRGC (c) clearly outperforms SSP (d).</figDesc><graphic coords="6,55.31,73.80,224.73,89.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Dependency on background penalty. The background penalty determines the amount of shared foreground. With our standard setting of λ = 0.3 only part of the object was detected. By increasing λ bg = 0.8 we force more foreground material to appear. Given our generative model we plan to learn λ bg from a larger training/validation data set.</figDesc><graphic coords="7,64.40,66.64,463.98,84.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Robust Image distance -same scene. Consider the triplet of images in the top row. The left and middle image depict part of the same scene, where the right image shows an unrelated forest scene.The distance (SAD) of the global colour histograms of the whole images says that the middle image is more similar to the right (48%) than to the left image (52%). Running cosegmentation gives the expected answer (bottom row). The cosegmentation of the left and middle image nicely moves the regions which do not appear in both images (telephone box, sky and road) to the background (label light blue). Note that the depicted cosegmentation of the middle image is with respect to the left image. When using the energy of the cosegmentation as distance measure, the middle image is now more similar (42%) to the left than the right image (58%). Note that the percentages are derived by comparing the absolute energies. Also, note that the cosegmentation measure without the spatial coherence term (MRF) gives, as the global histogram of whole images, the incorrect answer.</figDesc><graphic coords="7,89.47,456.59,379.29,231.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Video Tracking and Segmentation. Given a perfect segmentation in a key frame (a) we would like to segment the the foreground object in all subsequent frames, e.g. fame 10 (b). An obvious solution is to apply standard image segmentation<ref type="bibr" target="#b2">[3]</ref> using a trimap, which is derived by dilating the segmentation of the previous frame by a fixed number of pixels. The result (c) is good, however the segmentation of the book is sub-optimal. Our result (d) is better, by forcing the foreground object to have the same target histogram as in the previous frame.</figDesc><graphic coords="8,127.62,200.63,337.58,80.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison of SSP and TRGC with radome ordering (rand.) and distance map ordering (dist.) of the nodes. Note that the energies are scaled by 10 -2 .</figDesc><table><row><cell>Method</cell><cell cols="3">av. Energy av. Error (%) av. # Iter.</cell></row><row><cell>TRGC(dist.)</cell><cell>408</cell><cell>2.33</cell><cell>7.8</cell></row><row><cell>TRGC (rand.)</cell><cell>417</cell><cell>2.33</cell><cell>7.8</cell></row><row><cell>SSP (dist.)</cell><cell>426</cell><cell>2.77</cell><cell>4.6</cell></row><row><cell>SSP (rand.)</cell><cell>461</cell><cell>2.81</cell><cell>4.6</cell></row><row><cell>Ground Truth</cell><cell>429</cell><cell>0.0</cell><cell>-</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>This approximation does not affect the final answer up to constant<ref type="bibr" target="#b17">[18]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Note that this restriction on representative configurations does not necessarily mean that SSP cannot "exchange" pixels. If some configuration is not among x (0) , . . . , x (n) , it may still happen that approximation E 2 (x) is tight for this configuration. Furthermore, even if the approximation is not very tight, theoretically it is still possible that SSP will go there.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>If there are multiple global minima, then x(α) will denote one of the them. There is one exception, however: if x t is also a global minimum, then we set x(α) = x t .</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Generalizing Swendsen-Wang to sampling arbitrary posterior probabilities</title>
		<author>
			<persName><forename type="first">A</forename><surname>Barbu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Nonlinear Programming</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Athena Scientific</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Interactive graph cuts for optimal boundary and region segmentation of objects in N-D images</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-P</forename><surname>Jollie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2004-09">September 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Mean shift analysis and applications</title>
		<author>
			<persName><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1197" to="1203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Kernel-based object tracking</title>
		<author>
			<persName><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="564" to="575" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Classification error rate for quantitative evaluation of content-based image retrieval systems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Relations between the statistics of natural images and the response properties of cortical cells</title>
		<author>
			<persName><forename type="first">D</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optical Soc. of America A</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2379" to="2394" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Active contours for tracking distributions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Freedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T. Image Processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Exact MAP estimation for binary images</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Greig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Porteous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Seheult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Royal Statistical Society</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="271" to="279" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Simplicity: Semantics-sensitive integrated matching for picture libraries</title>
		<author>
			<persName><forename type="first">Z</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wiederhold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="947" to="963" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Shape gradients for histogram segmentation using active contours</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jehan-Besson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barlaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Aubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Faugeras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bi-layer segmentation of binocular stereo video</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Recognizing surfaces using threedimensional textons</title>
		<author>
			<persName><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A supermodular-submodular procedure with applications to discriminative structure learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2005-07">July 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The Linearization Method for Constrained Optimization</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">N</forename><surname>Pshenichnyj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computat. Mathematics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Grabcut: Interactive foreground extraction using iterated graph cuts</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIG-GRAPH</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="309" to="314" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Cosegmentation of image pairs by histogram matching -incorporating a global constraint into MRFs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<idno>MSR-TR-2006-36</idno>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A combinatorial algorithm minimizing submodular functions in strongly polynomial time</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schrijver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. of Combinatorial Theory, Ser. B</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="346" to="355" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">LOCUS: Learning object classes with unsupervised segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jojic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The concave-convex procedure (CCCP)</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
