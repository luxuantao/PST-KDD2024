<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Certifiable Robustness and Robust Training for Graph Convolutional Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Zügner</surname></persName>
							<email>zuegnerd@in.tum.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">KDD &apos;19</orgName>
								<address>
									<addrLine>August 4-8</addrLine>
									<postCode>2019</postCode>
									<settlement>Anchorage</settlement>
									<region>AK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stephan</forename><forename type="middle">2019 Certifiable</forename><surname>Günnemann</surname></persName>
							<email>guennemann@in.tum.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">KDD &apos;19</orgName>
								<address>
									<addrLine>August 4-8</addrLine>
									<postCode>2019</postCode>
									<settlement>Anchorage</settlement>
									<region>AK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Robustness</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">KDD &apos;19</orgName>
								<address>
									<addrLine>August 4-8</addrLine>
									<postCode>2019</postCode>
									<settlement>Anchorage</settlement>
									<region>AK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Certifiable Robustness and Robust Training for Graph Convolutional Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3292500.3330905</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent works show that Graph Neural Networks (GNNs) are highly non-robust with respect to adversarial attacks on both the graph structure and the node attributes, making their outcomes unreliable. We propose the first method for certifiable (non-)robustness of graph convolutional networks with respect to perturbations of the node attributes 1 . We consider the case of binary node attributes (e.g. bag-of-words) and perturbations that are L 0 -bounded. If a node has been certified with our method, it is guaranteed to be robust under any possible perturbation given the attack model. Likewise, we can certify non-robustness. Finally, we propose a robust semisupervised training procedure that treats the labeled and unlabeled nodes jointly. As shown in our experimental evaluation, our method significantly improves the robustness of the GNN with only minimal effect on the predictive accuracy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Graph data is the core for many high impact applications ranging from the analysis of social networks, over gene interaction networks, to interlinked document collections. One of the most frequently applied tasks on graph data is node classification: given a single large (attributed) graph and the class labels of a few nodes, the goal is to predict the labels of the remaining nodes. Applications include the classification of proteins in interaction graphs <ref type="bibr" target="#b8">[9]</ref>, prediction of customer types in e-commerce networks <ref type="bibr" target="#b5">[6]</ref>, or the assignment of scientific papers from a citation network into topics <ref type="bibr" target="#b11">[12]</ref>. While there exist many classical approaches to node classification <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b14">15]</ref>, recently graph neural networks (GNNs), also called graph convolutional networks, have gained much attention and improved the state of the art in node classification <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13]</ref>.</p><p>However, there is one big catch: Recently it has been shown that such approaches are vulnerable to adversarial attacks <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref>: Even only slight deliberate perturbations of the nodes' features or the graph structure can lead to completely wrong predictions. Such negative results significantly hinder the applicability of these models. The results become unreliable and such problems open the door for attackers that can exploit these vulnerabilities.</p><p>So far, no effective mechanisms are available, which (i) prevent that small changes to the data lead to completely different predictions in a GNN, or (ii) that can verify whether a given GNN is robust w.r.t. specific perturbation model. This is critical, since especially in domains where graph-based learning is used (e.g. the Web) adversaries are omnipresent, e.g., manipulating online reviews and product websites <ref type="bibr" target="#b10">[11]</ref>. One of the core challenges is that in a GNN a node's prediction is also affected when perturbing other nodes in the graph -making the space of possible perturbations large. How to make sure that small changes to the input data do not have a dramatic effect to a GNN?</p><p>In this work, we shed light on this problem by proposing the first method for provable robustness of GNNs. More precisely, we focus on graph convolutional networks and potential perturbations of the node attributes, where we provide: 1) Certificates: Given a trained GNN, we can give robustness certificates that state that a node is robust w.r.t. a certain space of perturbations. If the certificate holds, it is guaranteed that no perturbation (in the considered space) exists which will change the node's prediction. Furthermore, we also provide non-robustness certificates that, when they hold, state whether a node is not robust; realized by providing an adversarial example.</p><p>2) Robust Training: We proposes a learning principle that improves the robustness of the GNN (i.e. making it less sensitive to perturbations) while still ensuring high accuracy for node classification. Specifically, we exploit the semi-supervised nature of the GNN learning task, thus, taking also the unlabeled nodes into account.</p><p>In contrast to existing works on provable robustness for classical neural networks/robust training (e.g. <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b19">20]</ref>), we tackle various additional challenges: Being the first work for graphs, we have to deal with perturbations of multiple instances simultaneously. For this, we introduce a novel space of perturbations where the perturbation budget is constrained locally and globally. Moreover, since the considered data domains are often discrete/binary attributes, we tackle challenging L 0 constraints on the perturbations. Lastly, we exploit a crucial aspect of semi-supervised learning by taking also the unlabeled nodes into account for robust training.</p><p>The key idea we will exploit in our work is to estimate the worstcase change in the predictions obtained by the GNN under the space of perturbations. If the worst possible change is small, the GNN is robust. Since, however, this worst-case cannot be computed efficiently, we provide bounds on this value, providing conservative estimates. More technically, we derive relaxations of the GNN and the perturbations space, enabling efficient computation.</p><p>Besides the two core technical contributions mentioned above, we further perform extensive experiments:</p><p>3) Experiments: We show on various graph datasets that GNNs trained in the traditional way are not robust, i.e. only few of the nodes can be certified to be robust, respectively many are certifiably non-robust even with small perturbation budgets. In contrast, using our robust training we can dramatically improve robustness increasing it by in some cases by factor of four.</p><p>Overall, using our method, significantly improves the reliability of GNNs, thus, being highly beneficial when, e.g., using them in real production systems or scientific applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>The sensitivity of machine learning models w.r.t. adversarial perturbations has been studied extensively <ref type="bibr" target="#b7">[8]</ref> . Only recently, however, researchers have started to investigate adversarial attacks on graph neural networks <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref> and node embeddings <ref type="bibr" target="#b0">[1]</ref>. All of these works focus on generating adversarial examples. In contrast, we provide the first work to certify and improve the robustness of GNNs. As shown in <ref type="bibr" target="#b20">[21]</ref>, both perturbations to the node attributes as well as the graph structure are harmful. In this work, we focus on perturbations of the node attributes and we leave structure perturbations for future work.</p><p>For 'classical' neural networks various heuristic approaches have been proposed to improve the the robustness to adversarial examples <ref type="bibr" target="#b16">[17]</ref>. However, such heuristics are often broken by new attack methods, leading to an arms race. As an alternative, recent works have considered certifiable robustness <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b19">20]</ref> providing guarantees that no perturbation w.r.t. a specific perturbation space will change an instance's prediction.</p><p>For this work, specifically the class of methods based on convex relaxations are of relevance <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b19">20]</ref>. They construct a convex relaxation for computing a lower bound on the worst-case margin achievable over all possible perturbations. This bound serves as a certificate of robustness. Solving such convex optimization problems can often been done efficiently, and by exploiting duality it enables to even train a robust model <ref type="bibr" target="#b19">[20]</ref>. As already mentioned, our work differs significantly from the existing methods since (i) it considers the novel GNN domain with its relational dependencies, (ii) it handles a discrete/binary data domain, while existing works have only handled continuous data; thus also leading to very different constraints on the perturbations, and (iii) we propose a novel robust training procedure which specifically exploits the semi-supervised learning setting of GNNs, i.e. using the unlabeled nodes as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARIES</head><p>We consider the task of (semi-supervised) node classification in a single large graph having binary node features. Let G = (A, X ) be an attributed graph, where A ∈ {0, 1} N ×N is the adjacency matrix and X ∈ {0, 1} N ×D represents the nodes' features. W.l.o.g. we assume the node-ids to be V = {1, . . . , N }. Given a subset V L ⊆ V of labeled nodes, with class labels from C = {1, 2, . . . , K }, the goal of node classification is to learn a function f : V → C which maps each node v ∈ V to one class in C. In this work, we focus on node classification employing graph neural networks. In particular, we consider graph convolutional networks where the latent representations H (l ) at layer l are of the form</p><formula xml:id="formula_0">H (l ) = σ (l ) Â(l−1) H (l −1) W (l −1) + b (l −1) for l = 2, ..., L<label>(1)</label></formula><p>where H (1) = X and with activation functions given by</p><formula xml:id="formula_1">σ (L) (•) = softmax (•) , σ (l ) (•) = ReLU (•) for l = 2, ..., L − 1.</formula><p>The output H (L) vc denotes the probability of assigning node v to class c. The Â(l) are the message passing matrices that define how the activations are propagated in the network. In GCN <ref type="bibr" target="#b11">[12]</ref>, for example,</p><formula xml:id="formula_2">Â(1) = ... = Â(L−1) = D− 1 2 Ã D− 1 2</formula><p>, where Ã = A + I N ×N and Dii = j Ãij . The W (.) and b (.) are the trainable weights of the graph neural network, usually simply learned by minimizing the cross-entropy loss on the given labeled training nodes V L .</p><p>Notations: We denote with N l (t) the l-hop neighborhood of a node t, i.e. all nodes which are reachable with l hops (or less) from node t, including the node t itself. Given a matrix X , we denote its positive part with [X ] + = max(X , 0) where the max is applied entrywise. Similarly, the negative part is [X ] − = − min(X , 0), which are non-negative numbers. All matrix norms ||X || p used in the paper are meant to be entry-wise, i.e. flattening X to a vector and applying the corresponding vector norm. We denote with h (l ) the dimensionality of the latent space in layer l, i.e.</p><formula xml:id="formula_3">H (l ) ∈ R N ×h (l )</formula><p>. X i: denotes the i-th row of a matrix X and X :j its j-th column.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CERTIFYING ROBUSTNESS FOR GRAPH CONVOLUTIONAL NETWORKS</head><p>Our first goal is to derive an efficient principle for robustness certificates. That is, given an already trained GNN and a specific node t under consideration (called target node), our goal is to provide a certificate which guarantees that the prediction made for node t will not change even if the data gets perturbed (given a specific perturbation budget). That is, if the certificate is provided, the prediction for this node is robust under any admissible perturbations. Unlike existing works, we cannot restrict perturbations to the instance itself due to the relational dependencies. However, we can exploit one key insight: for a GNN with L layers, the output H (L) t : of node t depends only on the nodes in its L − 1 hop neighborhood N L−1 (t). Therefore, instead of operating with Eq. (1), we can 'slice' the matrices X and Â(l) at each step to only contain the entries that are required to compute the output for the target node t. <ref type="foot" target="#foot_0">2</ref> This step drastically improves scalability -reducing not only the size of the neural network but also the potential perturbations we have to consider later on. We define the matrix slices for a given target t as follows:<ref type="foot" target="#foot_1">3</ref> </p><formula xml:id="formula_4">A (l ) = Â(l) N L−l (t ), N L−l +1 (t ) for l = 1, ..., L − 1, X = X N L−1 (t ): (2)</formula><p>where the set indexing corresponds to slicing the rows and columns of a matrix, i.e. ÂN 2 (t ), N 1 (t ) contains the rows corresponding to the two-hop neighbors of node t and the columns corresponding to its one-hop neighbors. As it becomes clear, for increasing l (i.e. depth in the network), the slices of Â(l) become smaller, and at the final step we only need the target node's one-hop neighbors.</p><p>Overall, we only need to consider the following sliced GNN:</p><formula xml:id="formula_5">Ĥ (l ) = A (l −1) H (l −1) W (l −1) + b (l −1) for l = 2, ..., L<label>(3)</label></formula><formula xml:id="formula_6">H (l ) nj = max Ĥ (l ) nj , 0 for l = 2, ..., L − 1 (4)</formula><p>and H (1) = X . Here, we replaced the ReLU activation by its analytical form, and we denoted with Ĥ (l ) the input before applying the ReLU, and with H (l ) the corresponding output. Note that the matrices are getting smaller in size -with Ĥ (L) actually reducing to a vector that represents the predicted log probabilities (logits) for node t only. Note that we also omitted the softmax activation function in the final layer L since for the final classification decision it is sufficient to consider the largest value of Ĥ (L)</p><p>. Overall, we denote the output of this sliced GNN as</p><formula xml:id="formula_7">f t θ ( X , A) = Ĥ (L) ∈ R K .</formula><p>Here θ is the set of all parameters, i.e. θ = {W (•) , b (•) }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Robustness Certificates for GNNs</head><p>Given this set-up, we are now ready to define our actual task: We aim to verify whether no admissible perturbation changes the prediction of the target node t. Formally we aim to solve: Problem 1. Given a graph G, a target node t, and an GNN with parameters θ . Let y * denote the class of node t (e.g. given by the ground truth or predicted). The worst case margin between classes y * and y achievable under some set X q,Q ( X ) of admissible perturbations to the node attributes is given by</p><formula xml:id="formula_8">m t (y * , y) := minimize X f t θ ( X , A) y * − f t θ ( X , A) y (5) subject to X ∈ X q,Q ( X )</formula><p>If m t (y * , y) &gt; 0 for all y y * , the GNN is certifiably robust w.r.t. node t and X q,Q .</p><p>If the minimum in Eq. ( <ref type="formula">5</ref>) is positive, it means that there exists no adversarial example (within our defined admissible perturbations) that leads to the classifier changing its prediction to the other class y -i.e. the logits of class y * are always larger than the one of y.</p><p>Setting reasonable constraints to adversarial attacks is important to obtain certificates that reflect realistic attacks. Works for classical neural networks have constrained the adversarial examples to lie on a small ϵ-ball around the original sample measured by, e.g., the infinity-norm or L2-norm <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b19">20]</ref>, often e.g. ϵ &lt; 0.1 This is clearly not practical in our binary setting as an ϵ &lt; 1 would mean that no attribute can be changed. To allow reasonable perturbations in a binary/discrete setting one has to allow much larger changes than the ϵ-balls considered so far.</p><p>Therefore, motivated by the existing works on adversarial attacks to graphs <ref type="bibr" target="#b20">[21]</ref>, we consider a more realistic scenario: We define the set of admissible perturbations by limiting the number of changes to the original attributes -i.e. we assume a perturbation budget Q ∈ N and measure the L 0 norm in the change to X . It is important to note that in a graph setting an adversary can attack the target node by also changing the node attributes of its L − 1 hop neighborhood. Thus, Q acts as a global perturbation budget.</p><p>However, since changing many attributes for a single node might not be desired, we also allow to limit the number of perturbations locally -i.e. for each node in the L − 1 hop neighborhood we can consider a budget of q ∈ N. Overall, in this work we consider admissible perturbations of the form:</p><formula xml:id="formula_9">X q,Q ( X ) = X Xnj ∈ {0, 1} ∧ ∥ X − X ∥ 0 ≤ Q (6) ∧ ∥ Xn: − X n: ∥ 0 ≤ q ∀n ∈ N L−1 .</formula><p>Challenges: There are two major obstacles preventing us from efficiently finding the minimum in Eq. ( <ref type="formula">5</ref>). First, our data domain is discrete, making optimization often intractable. Second, our function (i.e. the GNN) f t θ is nonconvex due to the nonlinear activation functions in the neural network. But there is hope: As we will show, we can efficiently find lower bounds on the minimum of the original problem by performing specific relaxations of (i) the neural network, and (ii) the data domain. This means that if the lower bound is positive, we are certain that our classifier is robust w.r.t. the set of admissible perturbations. Remarkably, we will even see that our relaxation has an optimal solution which is integral. That is, we obtain an optimal solution (i.e. perturbation) which is binary -thus, we can effectively handle the discrete data domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Convex Relaxations</head><p>To make the objective function in Eq. ( <ref type="formula">5</ref>) convex, we have to find a convex relaxation of the ReLU activation function. While there are many ways to achieve this, we follow the approach of <ref type="bibr" target="#b19">[20]</ref> in this work. The core idea is (i) to treat the matrices H (•) and</p><formula xml:id="formula_10">Ĥ (•)</formula><p>in Eqs. <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b3">4)</ref> no longer as deterministic but as variables one can optimize over (besides optimizing over X ). In this view, Eqs. <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b3">4)</ref> become constraints the variables have to fulfill. Then, (ii) we relax the non-linear ReLU constraint of Eq. ( <ref type="formula">4</ref>) by a set of convex ones.</p><p>In detail: Consider Eq. ( <ref type="formula">4</ref>). Here, Ĥ (l ) nj denotes the input to the ReLU activation function. Let us assume we have given some lower bounds R (l ) nj and upper bounds S (l ) nj on this input based on the possible perturbations (in Section 4.5 we will discuss how to find these bounds). We denote with I (l ) the set of all tuples (n, j) in layer l for which the lower and upper bounds differ in their sign, i.e. R Consider the case I (l ) : We relax Eq. ( <ref type="formula">4</ref>) using a convex envelope:</p><formula xml:id="formula_11">H (l ) nj ≥ Ĥ (l ) nj , H (l ) nj ≥ 0, H (l ) nj S (l ) nj − R (l ) nj ≤ S (l ) nj Ĥ (l ) nj − R (l ) nj if (n, j) ∈ I (l ) R 0 S H Ĥ</formula><p>The idea is illustrated in the figure on the right. Note that H (l ) nj is no longer the deterministic output of the ReLU given its input but it is a variable. For a given input, the variable is constrained to lie on a vertical line above the input and below the upper line of the envelope.</p><p>Accordingly, but more simply, for the cases I (l ) + and I (l ) − we get:</p><formula xml:id="formula_12">H (l ) nj = Ĥ (l ) nj if (n, j) ∈ I (l ) + H (l ) nj = 0 if (n, j) ∈ I (l )</formula><p>− which are actually not relaxations but exact conditions. Overall, Eq. ( <ref type="formula">4</ref>) has now been replaced by a set of linear (i.e. convex) constraints. Together with the linear constraints of Eq. ( <ref type="formula" target="#formula_5">3</ref>) they determine the set of admissible H (•) and</p><formula xml:id="formula_13">Ĥ (•)</formula><p>we can optimize over. We denote the collection of these matrices that fulfill these constraints by Z q,Q ( X ). Note that this set depends on X since H (1) = X .</p><p>Overall, our problem becomes:</p><formula xml:id="formula_14">mt (y * , y) := minimize X ,H (•) , Ĥ (•) Ĥ (L) y * − Ĥ (L) y = c ⊤ Ĥ (L) (7) subject to X ∈ X q,Q ( X ) , [H (•) , Ĥ (•) ] ∈ Z q,Q ( X )</formula><p>Here we introduced the constant vector c = e y * − e y , which is 1 at position y * , −1 at y, and 0 else. This notation clearly shows that the objective function is a simple linear function.</p><p>Corollary 4.1. The minimum in Eq. ( <ref type="formula">7</ref>) is a lower bound on the minimum of the problem in Eq. ( <ref type="formula">5</ref>), i.e. mt (y * , y) ≤ m t (y * , y).</p><p>Proof. Let X be the perturbation obtained by Problem 1, and [H (•) , Ĥ (•) ] the resulting exact representations based on Eq. ( <ref type="formula" target="#formula_5">3</ref>)+(4).</p><p>By construction, [H (•) ,</p><formula xml:id="formula_15">Ĥ (•) ] ∈ Z q,Q ( X ).</formula><p>Since Eq. ( <ref type="formula">7</ref>) optimizes over the full set Z q,Q ( X ) its minimum can not be larger. □ From Corollary 4.1 it follows that if mt (y * , y) &gt; 0 for all y y * , the GNN is robust at node t. Directly solving Eq. ( <ref type="formula">7</ref>), however, is still intractable due to the discrete data domain.</p><p>As one core contribution, we will show that we can find the optimal solution in a tractable way. We proceed in two steps: (i) We first find a suitable continuous, convex relaxation of the discrete domain of possible adversarial examples. (ii) We show that the relaxed problem has an optimal solution which is integral; thus, by our specific construction the solution is binary.</p><p>More precisely, we relax the set X q,Q ( X ) to:</p><formula xml:id="formula_16">Xq,Q ( X ) = X Xnj ∈ [0, 1] ∧ ∥ X − X ∥ 1 ≤ Q (8) ∧ ∥ Xn: − X n: ∥ 1 ≤ q ∀n ∈ N L−1</formula><p>Note that the entries of X are now continuous between 0 and 1, and we have replaced the L 0 norm with the L 1 norm. This leads to:</p><formula xml:id="formula_17">mt (y * , y) := minimize X ,H (•) , Ĥ (•) Ĥ (L) y * − Ĥ (L) y = c ⊤ Ĥ (L) (9) subject to X ∈ Xq,Q ( X ) , [H (•) , Ĥ (•) ] ∈ Z q,Q ( X )</formula><p>It is worth mentioning that Eq. ( <ref type="formula">9</ref>) is a linear problem since besides the linear objective function also all constraints are linear. We provide the explicit form of this linear program in the appendix. Accordingly, Eq. ( <ref type="formula">9</ref>) can be solved optimally in a tractable way. Since Xq,Q ( X ) ⊃ X q,Q ( X ) , we trivially have mt (y * , y) ≤ mt (y * , y). But even more, we obtain: Theorem 4.2. The minimum in Eq. ( <ref type="formula">7</ref>) is equal to the minimum in Eq. ( <ref type="formula">9</ref>), i.e. mt (y * , y) = mt (y * , y).</p><p>We will proof this theorem later (see Sec. 4.4) since it requires some further results. In summary, using Theorem 4.2, we can indeed handle the discrete data domain/discrete perturbations exactly and tractably by simply solving Eq. ( <ref type="formula">9</ref>) instead of Eq. ( <ref type="formula">7</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Efficient Lower Bounds via the Dual</head><p>In order to provide a robustness guarantee w.r.t. the perturbations on X , we have to find the minimum of the linear program in Eq. ( <ref type="formula">9</ref>) to ensure that we have covered the worst case. While it is possible to solve linear programs 'efficiently' using highly optimized linear program solvers, the potentially large number of variables in a GNN makes this approach rather slow. As an alternative, we can consider the dual of the linear program <ref type="bibr" target="#b19">[20]</ref>. There, any dual-feasible solution is a lower bound on the minimum of the primal problem. That is, if we find any dual-feasible solution for which the objective function of the dual is positive, we know that the minimum of the primal problem has to be positive as well, guaranteeing robustness of the GNN w.r.t. any perturbation in the set.</p><p>Theorem 4.3. The dual of Eq. ( <ref type="formula">9</ref>) is equivalent to:</p><formula xml:id="formula_18">maximize Ω,η, ρ д t q,Q X , c, Ω, η, ρ<label>(10)</label></formula><p>subject to</p><formula xml:id="formula_19">Ω (l ) ∈ [0, 1] | N L−l |×h (l ) for l = L − 1, ..., 2, η ∈ R | N L−1 | ≥0 , ρ ∈ R ≥0</formula><p>where</p><formula xml:id="formula_20">д t q,Q (...) = L−1 l =2 (n, j)∈I (l ) S (l ) nj R (l ) nj S (l ) nj − R (l ) nj Φ(l+1) nj + − L−1 l =1 1 ⊤ Φ (l +1) b (l ) − Tr X ⊤ Φ(1) − ∥Ψ∥ 1 − q • n η n − Q • ρ and Φ (L) = −c ∈ R k Φ(l) = A (l )⊤ Φ (l +1) W (l )⊤ ∈ R | N L−l |×h (l ) for l = L − 1, ...,<label>1</label></formula><formula xml:id="formula_21">Φ (l ) nj =              0 if (n, j) ∈ I (l ) − Φnj if (n, j) ∈ I (l ) + S (l ) n j S (l ) n j −R (l ) n j Φ(l) nj + − Ω (l ) nj Φ(l) nj − if (n, j) ∈ I (l ) for l = L − 1, ..., 2 Ψ nd = max {∆ nd − (η n + ρ), 0} ∆ nd = Φ(1) nd + • (1 − X nd ) + Φ(1) nd − • X nd</formula><p>The proof is given in the appendix. Note that parts of the dual problem in Theorem 4.3 have a similar form to the problem in <ref type="bibr" target="#b19">[20]</ref>. For instance, we can interpret this dual problem as a backward pass on a GNN, where the Φ(l) and Φ (l ) are the hidden representations of the respective nodes in the graph. Crucially different, however, is the propagation in the dual problem with the message passing matrices A coming from the GNN formulation where neighboring nodes influence each other. Furthermore, our novel perturbation constraints from Eq. ( <ref type="formula">8</ref>) lead to the dual variables η and ρ, which have their origin in the local (q) and global (Q) constraints, respectively. Note that, in principle, our framework allows for different budgets q per node. The term Ψ has its origin in the constraint Xnj ∈ [0, 1].</p><p>While on the first look, the above dual problem seems rather complicated, its specific form makes it amenable for easy optimization. The variables Ω, η, ρ have only simple, element-wise constraints (e.g. clipping between [0, 1]). All other terms are just deterministic assignments. Thus, straightforward optimization using (projected) gradient ascent in combination with any modern automatic differentiation framework (e.g. TensorFlow, PyTorch) is possible.</p><p>Furthermore, while in the above dual we need to optimize over η and ρ, it turns out that we can simplify it even further: for any feasible Ω, we get an optimal closed-form solution for η, ρ.</p><p>Theorem 4.4. Given the dual problem from Theorem 4.3 and any dual-feasible value for Ω. For each node n ∈ N L−1 , let S n be the set of dimensions d corresponding to the q largest values from the vector ∆ n: (ties broken arbitrarily). Further, denote with o n = min d ∈S n ∆ nd the smallest of these values. The optimal ρ that maximizes the dual is the Q-th largest value from [∆ nd ] n ∈N L−1 ,d ∈S n . For later use we denote with S Q the set of tuples (n, d) corresponding to these Q-largest values. Moreover, the optimal η n is</p><formula xml:id="formula_22">η n = max {0, o n − ρ}.</formula><p>The proof is given in the appendix. Using Theo. 4.4, we obtain an even more compact dual where we only have to optimize over Ω. Importantly, the calculations done in Theo. 4.4 are also available in many modern automatic differentiation frameworks (i.e. we can back-propagate through them). Thus, we still get very efficient (and easy to implement) optimization.</p><p>Default value: As mentioned before, it is not required to solve the dual problem optimally. Any dual-feasible solution leads to a lower bound on the original problem. Specifically, we can also just evaluate the function д t q,Q once given a single instantiation for Ω. This makes the computation of robustness certificates extremely fast. For example, adopting the result of <ref type="bibr" target="#b19">[20]</ref>, instead of optimizing over Ω we can set it to</p><formula xml:id="formula_23">Ω (l ) nj = S (l ) nj • (S (l ) nj − R (l ) nj ) −1 ,<label>(11)</label></formula><p>which is dual-feasible, and still obtain strong robustness certificates. In our experimental section, we compare the results obtained using this default value to results for optimizing over Ω. Note that using Theo. 4.4 we always ensure to use the optimal η, ρ w.r.t. Ω.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Primal Solutions and Certificates</head><p>Based on the above results, we can now prove the following: Corollary 4.5. Eq. ( <ref type="formula">9</ref>) is an integral linear program with respect to the variables X .</p><p>The proof is given in the appendix. Using this result, it is now straightforward to prove Theo. 4.2 from the beginning.</p><p>Proof. Since Eq. ( <ref type="formula">9</ref>) has an optimal (thus, feasible) solution where X is integral, we have X ∈ Xq,Q ( X ) and, thus, X has to be binary to be integral. Since in this case the L 1 constraints are equivalent to the L 0 constraints, it follows that X ∈ X q,Q ( X ). Thus, this optimal solution of Eq. 9 is feasible for Eq. 7 as well. Together with mt (y * , y) ≤ mt (y * , y) it follows that mt (y * , y) = mt (y * , y). □ In the proof of Corollary 4.5, we have seen that in the optimal solution, the set {(n, d) ∈ S Q | ∆ nd &gt; 0} =: P indicates those elements which are perturbed. That is, we constructed the worstcase perturbation. Clearly, this mechanism can also be used even if Ω (and, thus, ∆) is not optimal: simply perturbing the elements in P. In this case, of course, the primal solution might not be optimal and we cannot use it for a robustness certificate. However, since the resulting perturbation is primal feasible (regarding the set X q,Q ( X )), we can use it for our non-robustness certificate: After constructing the perturbation X based on P, we pass it through the exact GNN, i.e. we evaluate Eq. ( <ref type="formula">5</ref>). If the value is negative, we found a harmful perturbation, certifying non-robustness.</p><p>In summary: By considering the dual program, we obtain robustness certificates if the obtained (dual) values are positive for every y y * . In contrast, by constructing the primal feasible perturbation using P, we obtain non-robustness certificates if the obtained (exact, primal) values are negative for one y y * . For some nodes, neither of these certificates can be given. We analyze this aspect in more detail in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Activation Bounds</head><p>One crucial component of our method, the computation of the bounds R (l ) and S (l ) on the activations in the relaxed GNN, remains to be defined. Again, existing bounds for classical neural networks are not applicable since they neither consider L 0 constraints nor do they take neighboring instances into account. Obtaining good upper and lower bounds is crucial to obtain robustness certificates, as tighter bounds lead to lower relaxation error of the GNN activations.</p><p>While in Sec. 4.3, we relax the discreteness condition of the node attributes X in the linear program, it turns out that for the bounds the binary nature of the data can be exploited. More precisely, for every node m ∈ N L−2 (t), we compute the upper bound S</p><p>(2) mj in the second layer for latent dimension j as</p><formula xml:id="formula_24">S (2) mj = sum_top_Q [ A (1) mn Ŝ(2) nji ] n ∈N 1 (m),i ∈ {1, ...,q } + H (2) mj (12) Ŝ(2) nji = i-th_largest (1 − X n: ) ⊙ W (1) :j + + X n: ⊙ W (1) :j −</formula><p>Here, i-th_largest(•) denotes the selection of the i-th largest element from the corresponding vector, and sum_top_Q(•) the sum of the Q largest elements from the corresponding list. The first term of the sum in Eq. ( <ref type="formula">12</ref>) is an upper bound on the change/increase in the first hidden layer's activations of node m and hidden dimension j for any admissible perturbation on the attributes X . The second term are the hidden activations obtained for the (un-perturbed) input X , i.e. H</p><p>(2) mj = A (1) XW (1) + b (1) . In sum we have an upper bound on the hidden activations in the first hidden layer for the perturbed input X . Note that, reflecting the interdependence of nodes in the graph, the bounds of a node m depend on the attributes of its neighbors n.</p><p>Likewise for the lower bound we use: R</p><p>(2)</p><formula xml:id="formula_25">mj = -sum_top_Q [ A (1) mn R(2) nji ] n ∈N 1 (m),i ∈ {1, ...,q } + H (2) mj (13) R(2) nji = i-th_largest X n: ⊙ W (1) :j + + (1 − X n: ) ⊙ W (1) :j −</formula><p>We need to compute the bounds for each node in the L − 2 hop neighborhood of the target, i.e. for a GNN with a single hidden layer (L = 3) we have R (2) , S (2) ∈ R N 1 (t )×h <ref type="bibr" target="#b1">(2)</ref> .</p><p>Corollary 4.6. Eqs. ( <ref type="formula">12</ref>) and ( <ref type="formula">13</ref>) are valid, and the tightest possible, lower/upper bounds w.r.t. the set of admissible perturbations.</p><p>The proof is in the appendix. For the remaining layers, since the input to them is no longer binary, we adapt the bounds proposed in <ref type="bibr" target="#b17">[18]</ref>. Generalized to the GNN we therefore obtain:</p><formula xml:id="formula_26">R (l ) = A (l −1) R (l −1) W (l −1) + − S (l −1) W (l −1) − S (l ) = A (l −1) S (l −1) W (l −1) + − R (l −1) W (l −1) − for l = 3, . . . , L − 1.</formula><p>Intuitively, for the upper bounds we assume that the activations in the previous layer take their respective upper bound wherever we have positive weights, and their lower bounds whenever we have negative weights (and the lower bounds are analogous to this). While there exist more computationally involved algorithms to compute more accurate bounds <ref type="bibr" target="#b19">[20]</ref>, we leave adaptation of such bounds to the graph domain for future work.</p><p>It is important to note that all bounds can be computed highly efficiently and one can even back-propagate through them -important aspects for the robust training (Sec. 5). Specifically, one can compute Eqs. ( <ref type="formula">12</ref>) and ( <ref type="formula">13</ref>) for all m ∈ V (!) and all j together in time O(h (2) • (N • D + E • q)) where E is the number of edges in the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Note that R(2)</head><p>nj: can be computed in time O(D) by unordered partial sorting; overall leading to the complexity O(N • h (2) • D). Likewise the sum of top Q elements can be computed in time O(N 1 (m) • q) for every 1 ≤ j ≤ h (2) and m ∈ V, together leading to O(E • q • h (2) ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">ROBUST TRAINING OF GNNS</head><p>While being able to certify robustness of a given GNN by itself is extremely valuable for being able to trust the model's output in real-world applications, it is also highly desirable to train classifiers that are (certifiably) robust to adversarial attacks. In this section we show how to use our findings from before to train robust GNNs.</p><p>Recall that the value of the dual д can be interpreted as a lower bound on the margin between the two considered classes. As a shortcut, we denote with p t θ (y,</p><formula xml:id="formula_27">Ω (•) ) = −д t q,Q X , c k , Ω k 1≤k ≤K</formula><p>the K-dimensional vector containing the (negative) dual objective function values for any class k compared to the given class y, i.e. c k = e y − e k . That is, node t with class y * t is certifiably robust if p t θ &lt; 0 for all entries (except the entry at y * t which is always 0). Here, θ denotes the parameters of the GNN.</p><p>First consider the training objective typically used to train GNNs for node classification:</p><formula xml:id="formula_28">minimize θ t ∈V L L f t θ ( X , A), y * t , (<label>14</label></formula><formula xml:id="formula_29">)</formula><p>where L is the cross entropy function (operating on the logits) and V L the set of labeled nodes in the graph. y * t denotes the (known) class label of node t.</p><p>To improve robustness, in <ref type="bibr" target="#b19">[20]</ref> (for classical neural networks) it has been proposed to instead optimize minimize</p><formula xml:id="formula_30">θ, Ω t,k t ∈V L , 1≤k ≤K t ∈V L L p t θ (y * t , Ω t, • ), y * t (<label>15</label></formula><formula xml:id="formula_31">)</formula><p>which is an upper bound on the worst-case loss achievable. Note that we can omit optimizing over Ω by setting it to Eq. <ref type="bibr" target="#b10">(11)</ref>. We refer to the loss function in Eq. ( <ref type="formula" target="#formula_30">15</ref>) as robust cross entropy loss. One common issue with deep learning models is overconfidence <ref type="bibr" target="#b13">[14]</ref>, i.e. the models predicting effectively a probability of 1 for one and 0 for the other classes. Applied to Eq. ( <ref type="formula" target="#formula_30">15</ref>), this means that the vector p t θ is pushed to contain very large negative numbers: the predictions will not only be robust but also very certain even under the worst perturbation. To facilitate true robustness and not false certainty in our model's predictions, we therefore propose an alternative robust loss that we refer to as robust hinge loss:</p><formula xml:id="formula_32">LM p, y * = k y * max {0, p k + M } . (<label>16</label></formula><formula xml:id="formula_33">)</formula><p>This loss is positive if −p t θ k = д t q,Q X , c k , Ω k &lt; M; and zero otherwise. Put simply: If the loss is zero, the node t is certifiably robust -in this case even guaranteeing a margin of at least M to the decision boundary. Importantly, realizing even larger margins (for the worst-case) is not 'rewarded'.</p><p>We combine the robust hinge loss with standard cross entropy to obtain the following robust optimization problem min</p><formula xml:id="formula_34">θ, Ω t ∈V L LM p t θ (y * t , Ω t, • ), y * t + L f t θ ( X , A), y * t .<label>(17)</label></formula><p>Note that the cross entropy term is operating on the exact, nonrelaxed GNN, which is a strong advantage over the robust cross entropy loss that only uses the relaxed GNN. Thus, we are using the exact GNN model for the node predictions, while the relaxed GNN is only used to ensure robustness. Effectively, if all nodes are robust, the term LM becomes zero, thus, reducing to the standard cross-entropy loss on the exact GNN (with robustness guarantee).</p><p>Robustness in the semi-supervised setting: While Eq. ( <ref type="formula" target="#formula_34">17</ref>) improves the robustness regarding the labeled nodes, we do not consider the given unlabeled nodes. How to handle the semi-supervised setting which is prevalent in the graph domain, ensuring also robustness for the unlabeled nodes? Note that for the unlabeled nodes, we do not necessarily want robustness certificates with a very large margin (i.e. strongly negative p t θ ) since the classifier's prediction may be wrong in the first place; this would mean that we encourage the classifier to make very certain predictions even when the predictions are wrong. Instead, we want to reflect in our model that some unlabeled nodes might be close to the decision boundary and not make overconfident predictions in these cases.</p><p>Our robust hinge loss provides a natural way to incorporate these goals. By setting a smaller margin M 2 for the unlabeled nodes, we can train our classifier to be robust, but does not encourage worstcase logit differences larger than the specified M 2 . Importantly, this does not mean that the classifier will be less certain in general, since the cross entropy term is unchanged and if the classifier is already robust, the robust hinge loss is 0. Overall:  where ỹt = arg max k f t θ ( X , A) k is the predicted label for node t. Note again that the unlabeled nodes are used for robustness purposes only -making it very different to the principle of self-training (see below). Overall, Eq. ( <ref type="formula" target="#formula_35">18</ref>) aims to correctly classify all labeled nodes using the exact GNN, while making sure that every node has at least a margin of M * from the decision boundary even under worst-case perturbations.</p><formula xml:id="formula_35">min θ, Ω t ∈V L LM 1 p t θ (y * t , Ω t, • ), y * t + L f t θ ( X , A), y * t (<label>18</label></formula><formula xml:id="formula_36">)</formula><formula xml:id="formula_37">+ t ∈V\V L LM 2 p t θ ( ỹt , Ω t, • ), ỹt</formula><p>Eq. ( <ref type="formula" target="#formula_35">18</ref>) can be optimized as is. In practice, however, we proceed as follows: We first train the GNN on the labeled nodes using Eq. ( <ref type="formula" target="#formula_34">17</ref>) until convergence. Then we train on all nodes using Eq. ( <ref type="formula" target="#formula_35">18</ref>) until convergence.</p><p>Discussion: Note that the above idea is not applicable to the robust cross entropy loss from Eq. ( <ref type="formula" target="#formula_30">15</ref>). One might argue that one could use a GNN trained using Eq. ( <ref type="formula" target="#formula_30">15</ref>) to compute predictions for all (or some of the) unlabeled nodes. Then, treating these predictions as the correct (soft-)labels for the nodes and recursively apply the training. This has two undesired effects: If the prediction is very uncertain (i.e. the soft-labels are flat), Eq. ( <ref type="formula" target="#formula_30">15</ref>) tries to find a GNN where the worst-case margin exactly matches these uncertain labels (since this minimizes the cross-entropy). The GNN will be forced to keep the prediction uncertain for such instances even if it could do better. On the other hand, if the prediction is very certain (i.e. very peaky), Eq. ( <ref type="formula" target="#formula_30">15</ref>) tries to make sure that even in the worst-case the prediction has such high certainty -thus being overconfident in the prediction (which might even be wrong in the first place). Indeed, this case mimics the idea of self-training: In self-training, we first train our model on the labeled nodes. Subsequently, we use the predicted classes of (some of) the unlabeled nodes, pretending these are their true labels; and continue training with them as well. Selftraining, however, serves an orthogonal purpose and, in principle, can be used with any of the above models.</p><p>Summary: When training the GNN, the lower and upper activation bounds are treated as a function of θ , i.e. they are updated accordingly. While this can be done efficiently as discussed in Sec. 4.5, it is still the least efficient part of our model and future work might consider incremental computations. Overall, since the dual program in Theorem 4.3 and the upper/lower activations bounds are differentiable, we can train a robust GNN with gradient descent and standard deep learning libraries. Note again that by setting Ω to its default value, we actually only have to optimize over θ -like in standard training. Furthermore, computing p t θ for the default parameters has roughly the same cost as evaluating a usual (sliced) GNN K many times, i.e. it is very efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTAL EVALUATION</head><p>Our experimental contributions are twofold. (i) We evaluate the robustness of traditionally trained GNNs using, and thus analyzing, our certification method. (ii) We show that our robust training procedure can dramatically improve GNNs' robustness while sacrificing only minimal accuracy on the unlabeled nodes.</p><p>We evaluate our method on the widely used and publicly available datasets Cora-ML (N=2,995, E=8,416, D=2,879, K=7) <ref type="bibr" target="#b15">[16]</ref>, Citeseer (N=3,312, E=4,715, D=3,703, K=6) <ref type="bibr" target="#b18">[19]</ref>, and PubMed (N=19,717, E=44,324, D=500, K=3) <ref type="bibr" target="#b18">[19]</ref>. For every dataset, we allow local (i.e. per-node) changes to the node attributes amounting to 1% of the attribute dimension, i.e. q = 0.01D. Q is analyzed in detail in the experiments reflecting different perturbation spaces.</p><p>We refer to the traditional training of GNNs as Cross Entropy (short CE), to the robust variant of cross entropy as Robust Cross Entropy (RCE), and to our hinge loss variants as Robust Hinge Loss (RH) and Robust Hinge Loss with Unlabeled (RH-U), where the latter enforces a margin loss also on the unlabeled nodes. We set M 1 , i.e. the margin on the training nodes to log(0.9/0.1) and M 2 to log(0.6/0.4) for the unlabeled nodes (RH-U only). This means that we train the GNN to (correctly) classify the labeled nodes with output probability of 90% in the worst case, and the unlabeled nodes with 60%, reflecting that we do not want our model to be overconfident on the unlabeled nodes. Please note that we do not need to compare against graph adversarial attack models such as <ref type="bibr" target="#b20">[21]</ref> since our method gives provable guarantees on the robustness.</p><p>While our method can be used for any GNN of the form in Eq. ( <ref type="formula" target="#formula_0">1</ref>), we study the well-established GCN <ref type="bibr" target="#b11">[12]</ref>, which has shown to outperform many more complicated models. Following <ref type="bibr" target="#b11">[12]</ref>, we consider GCNs with one hidden layer (i.e. L = 3), and choose a latent dimensionality of 32. We split the datasets into 10% labeled and 90% unlabeled nodes. See the appendix for further details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Certificates: Robustness of GNNs</head><p>We first start to investigate our (non-)robustness certificates by analyzing GNNs trained using standard cross entropy training. Figure <ref type="figure">1</ref> shows the main result: for varying Q we report the percentage of nodes (train+test) which are certifiable robust/non-robust on Cora-ML. We can make two important observations: (i) Our certificates are often very tight. That is, the white area (nodes for which we cannot give any -robustness or non-robustness -certificate) is rather small. Indeed, for any given Q, at most 30% of the nodes cannot be certified across all datasets and despite no robust training, highlighting the tightness of our bounds and relaxations and the effectiveness of our certification method. (ii) GNNs trained traditionally are only certifiably robust up to very small perturbations. At Q = 12, less than 55% of the nodes are certifiably robust on Cora-ML. In case of Citeseer even less than 20% (Table <ref type="table" target="#tab_0">1</ref>; training: CE). Even worse, at this point already two thirds (for Citeseer) and a quarter (Cora-ML) of the nodes are certifiably non-robust (i.e. we can find adversarial examples), confirming the issues reported in <ref type="bibr" target="#b20">[21]</ref>. PubMed behaves similarly (as we will see later, e.g., in Table <ref type="table" target="#tab_0">1</ref>).</p><p>In our experiments, the labeled nodes are on average more robust than the unlabeled nodes, which is not surprising given that the classifier was not trained using the labels of the latter.</p><p>We also investigate what contributes to certain nodes being more robust than others. In Figure <ref type="figure">2</ref> we see that neighborhood purity (i.e. the share of nodes in a respective node's two-hop neighborhood that is assigned the same class by the classifier) plays an important role. On Cora-ML, almost all nodes that are certifiably robust above Q ≥ 50 have a neighborhood purity of at least 80%. When analyzing the degree (Figure <ref type="figure" target="#fig_2">3</ref>), it seems that nodes with a medium degree are most robust. While counterintuitive at first, having many neighbors also means a large surface for adversarial attacks. Nodes with low degree, in contrast, might be affected more strongly since each node in its neighborhood has a larger influence. Tightness of lower bounds: Next, we aim to analyze how tight our dual lower bounds are, which we needed to obtain efficient certification. For this, we analyze (i) the value of д q,Q (•) we obtain from our dual solution (either when optimizing over Ω are using the default value), compared to (ii) the value of the primal solution we obtain using our construction from Sec. 4.4. The smaller the difference, the better. As seen in Figure <ref type="figure" target="#fig_4">7</ref>, when optimizing over Ω, for most of the nodes the gap is 0. Thus, indeed we can often find the exact minimum of the primal via the dual. As expected, when using the default value for Ω the difference between dual and primal is larger. Still, for most nodes the difference is small. Indeed, and more importantly, when considering the actual certificates (where we only need to verify whether the dual is positive; its actual value is not important), the difference between optimizing Ω and its default value become negligible: on Cora-ML, the average maximal Q for which we can certify robustness drops by 0.54; Citeseer 0.18; PubMed 2.3. This highlights that we can use the default values of Ω to very efficiently certify many or even all nodes in a GNN. In all remaining experiments we, thus, only operate with this default choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Robust Training of GNNs</head><p>Next, we analyze our robust training procedure. If not mentioned otherwise, we use our robust hinge-loss including the unlabeled nodes RH-U and we robustify the models with Q = 12 since for this value more than 50% of nodes across our datasets were not certifiably robust (when using standard training).</p><p>Figure <ref type="figure">4</ref> and 5 show again the percentage of certified nodes w.r.t. a certain Q -now when using a robustly trained GCN. With dotted lines, we have plotted the curves one obtains for the standard (non-robust) training -e.g. the dotted lines in Fig. <ref type="figure">4</ref> are the ones already seen in Fig. <ref type="figure">1</ref>. As it becomes clear, with robust training, we can dramatically increase the number of nodes which are robust. Almost every node is robust when considering the Q for which the model has been trained for. E.g. for Citeseer, our method is able to quadruple the number of certifiable nodes for Q = 12. Put simply: When performing an adversarial attack with Q ≤ 12 on this model, it cannot do any harm! Moreover the share of nodes that can be certified for any given Q has increased significantly (even though we have not trained the model for Q &gt; 12). Most remarkably, nodes for which we certified non-robustness before become now certifiably robust (the blue region above the gray lines).</p><p>Accuracy: The increased robustness comes at almost no loss in classification accuracy as Table <ref type="table" target="#tab_0">1</ref> shows. There we report the results for all datasets and all training principles. The last two columns show the accuracy obtained for node classification (for train and test nodes separately). In some cases, our robust classifiers even outperform the non-robust one on the unlabeled nodes. Interestingly, for PubMed we see that the accuracy on the labeled nodes drops to the accuracy on the unlabeled nodes. This indicates that our method can even improve generalization.</p><p>Training principles: Comparing the different robust training procedures (also given in more detail in Figure <ref type="figure">6</ref>), we see that RH-U achieves significantly higher robustness when considering Q = 12. This is shown by the third-last column in the table, where the percentage of nodes which are certifiably robust for Q = 12 (i.e. the Q the models have been robustified for) is shown. The third column shows the largest Q for which a node is still certifiably robust (averaged over all nodes). As shown, for all training principles the average exceeds the value of 12.</p><p>Effect of training with Q: If we strongly increase the Q for which the classifier is trained for, we only observe a small drop in    the classification accuracy. E.g., training accuracy drops from 99% to 87% when going from Q = 12 to 48, while test accuracy stays almost unchanged (68% vs. 66%) on Citeseer. We attribute this to the fact that the GNN still uses the normal CE loss in addition to our robust hinge loss during training. Figure <ref type="figure" target="#fig_7">9</ref> shows the results for Cora where we trained three models with different Q. To clarify: We have to distinguish between the Q used for training a model (mentioned in the legend) and the Q we are computing certificates for (the x-axis). We see: (i) Clearly, all trainings lead to significantly more robust models. Though, the larger Q, the harder it gets. (ii) Importantly, each model is the 'winner in robustness' when considering the Q for which the model has been trained for.</p><p>Training Dynamics: Lastly, we analyze the behavior when training a GCN using either standard training or robust training with RH-U. In Figure <ref type="figure" target="#fig_5">8</ref> we monitor the worst-case margin (averaged over a minibatch of nodes; separately for the labeled and unlabeled nodes) obtained in each training iteration. As seen, with RH-U the worst-case margin increases to the specified values M 1 /M 2 -i.e. making them robust. In contrast, for standard training the worstcase margin decreases. Specifically the unlabeled nodes (which account to 90% of all nodes) are not robust.</p><p>Overall, all experiments show that our robust training is highly effective: robustness is increased while the accuracy is still high.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>We proposed the first work on certifying robustness of GNNs, considering perturbations of the node attributes under a challenging L 0 perturbation budget and tackling the discrete data domain. By relaxing the GNN and considering the dual, we realized an efficient computation of our certificates -simultaneously our experiments have shown that our certificates are tight since for most nodes a certificate can be given. We have shown that traditional training of GNNs leads to non-robust models that can easily be fooled. In contrast, using our novel (semi-supervised) robust training the resulting GNNs are shown to be much more robust. All this is achieved with only a minor effect on the classification accuracy. As future work we aim to consider perturbations of the graph structure.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>−</head><label></label><figDesc>the tuples where both bounds are non-negative and non-positive, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Certificates for a GNN trained with standard training on Cora-ML.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Robustness of nodes vs. their degree.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :Figure 5 :Figure 6 :</head><label>456</label><figDesc>Figure 4: Robust training (Cora-ML). Dashed lines are w/o robust training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Difference of Primal and Dual Bound.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Training dynamics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Robust training, diff. Q</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Robust training results. Our robust training methods significantly improve the robustness of GNNs while not sacrificing accuracy. Robust training was done for Q = 12. Results are averaged over five random data splits.</figDesc><table><row><cell cols="2">Dataset Training Citeseer CE RCE RH RH-U</cell><cell>Avg. Max Q robust 6.77 18.62 15.51 18.48</cell><cell>% Robust Q = 12 0.17 0.58 0.54 0.76</cell><cell>Acc. (labeled) 1.00 0.99 0.99 0.99</cell><cell>Acc. (unlabeled) 0.67 0.69 0.68 0.68</cell><cell>0 M 2 M 1 Avg Worst-case Margin</cell><cell>RH-U-Unlabeled RH-U-Labeled CE-Unlabeled CE-Labeled</cell><cell></cell></row><row><cell>Cora-ML</cell><cell>RH RH-U CE RCE</cell><cell>32.49 35.58 16.36 38.58</cell><cell>0.74 0.91 0.54 0.77</cell><cell>1.00 1.00 1.00 1.00</cell><cell>0.83 0.83 0.83 0.83</cell><cell>0</cell><cell>250 Training iterations 500 750</cell><cell>1000</cell></row><row><cell>PubMed</cell><cell>CE RCE RH RH-U</cell><cell>5.82 50.68 48.56 47.56</cell><cell>0.15 0.62 0.62 0.63</cell><cell>0.99 0.88 0.90 0.90</cell><cell>0.86 0.84 0.85 0.86</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">Note that the shapes of W and b do not change.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1">To avoid clutter in the notation, since our method certifies robustness with respect to a specific node t , we omit explicitly mentioning the target node t in the following.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2">W.l.o.g. we assume Q ≤ | N L−1 | • q here; otherwise we simply select all of the q largest ∆ nd per row (which is equivalent to choosingQ = | N L−1 | • q)</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This research was supported by the German Research Foundation, grant GU 1409/2-1.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">APPENDIX</head><p>Implementation Details: We perform the robust training using stochastic gradient descent with mini-batches and Adam Optimizer. For this we randomly sample in each iteration 20 nodes from the labeled nodes (for RH-U from all nodes) and compute the nodes' twohop neighbors. We then slice the adjacency and attribute matrices appropriately and compute the lower/upper activation bounds for all nodes in the batch. We use dropout of 0.5, L 2 regularization with strength 1e − 5, learning rate of 0.001. We use Tensorflow 1.12 and train on NVIDIA GTX 1080 Ti.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Proofs</head><p>We reformulate the problem in Eq. ( <ref type="formula">9</ref>) as the linear program below. minimize X , H (•) ,</p><p>H</p><p>Note that X = H (1) ; moreover the</p><p>can be simply eliminated from the optimization. λ, µ, and τ are only defined for (n, j) ∈ I (l ) ; we keep the matrix notation for simplicity.</p><p>Proof of Theorem 4.3. Applying standard duality construction, the (non-simplified!) dual problem of the above linear program is max</p><p>for l = 2, . . . L, (n, j) ∈ I (l )</p><p>As done in <ref type="bibr" target="#b19">[20]</ref> we can exploit complementarity of the ReLU constraints corresponding to H (l ) ≥ 0 and H (l ) ≥ Ĥ (l ) to eliminate τ , µ, and λ from the problem. For this we write</p><p>where we have defined Φ(l) := A (l )⊤ Φ (l +1) W (l )⊤ . Given the nonnegativity of the dual-variables, it becomes apparent that τ (l ) and µ (l ) "share" the negative part of Φ(l) . Thus, we define new variables</p><p>nj we can rephrase to get</p><p>Similarly, by complementarity of the constraints, we know that only one of ε + nj and ε − nj and only one of γ + nj and γ − nj can be positive. From Eq. ( <ref type="formula">20</ref>) we can therefore see that ε + nj and γ + nj need to "share" the positive part of the left hand side in Eq. ( <ref type="formula">20</ref>) (since all variables are ≥ 0); similarly ε − nj and γ − nj share the negative part. We denote this (unknown) share by a new variable β nj ∈ [0, 1] and get</p><p>Putting this into Eq. ( <ref type="formula">21</ref>) we can now see that 1) , from which we can get</p><p>to replace the constraint in Eq. ( <ref type="formula">21</ref>). Now we can simplify the following term from the dual objective</p><p>Research Track Paper KDD '19, August 4-8, 2019, Anchorage, AK, USA</p><p>In the definition of ∆ nj we essentially have a case distinction: if Φ(1) nj is positive, we know that increasing the value of the corresponding primal variable Xnd will improve the primal objective. If X nd is already 1, however, we set the value of ∆ nj to zero by multiplying by 1 − X nd (similarly for the case when Φ(1) nj is negative). This effectively enforces the 0 ≤ X ≤ 1 constraint on the perturbations.</p><p>Plugging all terms defined above into our dual objective we get max</p><p>Notice that Tr X ⊤ Φ(1) = n j Φnj X nj . Since ∆ ≥ 0 and β ≥ 0 we could safely write ∥∆ ⊙ β ∥ 1 . By observing that ∆ ≥ 0 for all entries we see that to maximize the objective, we will set β to a value as small as is admissible. This means we can replace Eq. ( <ref type="formula">22</ref>) with β = max 1 −</p><p>, 0 . Thus, we have now eliminated all dual variables except Ω, ρ, and η n . Finally, we define Ψ nj := ∆ nj β nj = max ∆ nj − (η n + ρ), 0 , which finalizes the proof. □ Proof of Theorem 4.4. Given a fixed Ω, the dual function</p><p>and ∆ nd constant. Noticing that Ψ nd ≥ 0, we see that maximizing the dual is equivalent to minimizing min</p><p>Observe that we can equivalently rephrase this as min</p><p>Here we have replaced max{∆ nd −(η n +ρ), 0} in h(ρ, η n ) with a new variable U nd with the constraints U nd ≥ 0 and ) ). Since we are minimizing, the optimal values w.r.t. h ′ (ρ, η n , U ) and h(ρ, η n ) will be the same.</p><p>Finding the minimum of h ′ (•) is a linear program. Thus, we can again form its dual (denoting the dual variables as α nd ):</p><p>An optimal solution of this dual can be seen and computed easily. Since all ∆ nd are nonnegative, we simply set those α nd to 1 corresponding to the largest values of ∆ nd -additionally taking the two other constraints into account: The third constraint tells us that the row sums of the α matrix can be at most q, hence we can only set the α nd corresponding to the q largest ∆ nd to 1 for each row to maximize the objective. The second constraint means that we can set at most Q entries α nd to 1. So among the set of all q largest ∆ nd of the rows we select again the Q largest ∆ nd and set their corresponding α nd to 1 4 . Observe that this is precisely the selection process described in the main text for Thm. 4.4. That is, an optimal solution of the dual can be found by setting α nd = 1 ⇔ (n, d) ∈ S Q .</p><p>We now prove that the variables ρ and η n as described in the main text (along with U nd = max{∆ nd − η n − ρ, 0}) correspond to an optimal solution of their respective problem. For this we show that the Karush-Kuhn-Tucker (KKT) conditions hold -using the above constructed solution for α nd . (1) Dual and primal feasibility hold by construction. (2) Next, we check complementary slackness</p><p>If α nd &gt; 0 it must hold that the second term is 0. In this case we know that ∆ nd ≥ η n + ρ and thus U nd = ∆ nd − η n − ρ, which means the term is always 0. When the second term in Eq. ( <ref type="formula">23</ref>) is nonzero, α nd must be 0. This is given since when ∆ nd &lt; η n + ρ + U nd it is smaller than the smallest ∆ nd for which α nd is set to 1 and therefore α nd = 0. (3) Finally we show that</p><p>since we set exactly Q many α nd to 1 (and the rest to 0); η n follows analogously. ∇ U nd L(θ, α) = I U nd &gt;0 (1 − α nd ) = 0 holds since when α nd = 0, ∆ nd −η n −ρ ≤ 0 which means that U nd must be 0 because of its constraints. Thus, all KKT conditions hold. □ Proof of Corollary 4.5. Assume we are given the optimal values for Ω. We can then compute the optimal values of ρ and η as described in Theorem 4.4. Recall from the proof of Thm. 4.3 that the ∆ nd denote the improvement in the primal function objective when changing the attribute X nd . As shown in the proof of Thm. 4.4 with the optimal α nd we exactly choose the values ∆ nd that lead to the largest improvement of the objective function -and we trivially observed α nd = 1 for those elements. Thus, an optimal solution can be obtained by perturbing the attribute entries X nd from the set P := {(n, d)|α nd = 1, ∆ nd &gt; 0}, i.e. setting them to 1 − X nd . Thus, by construction we found an optimal solution which is integral, making the original linear program integral w.r.t. the attributes Xnd . By construction of α nd the set P</p><p>Proof of Corollary 4.6. Using Eq. ( <ref type="formula">3</ref>), the (un-perturbed)</p><p>m: XW</p><p>:j + b</p><p>(1)</p><p>mn X nd W</p><p>(1)</p><p>j which is simply a linear sum in X nd . Clearly, for maximizing Ĥ (2) mj , one should only perturb X nd if ( A</p><p>mn W</p><p>(1) d j is positive and X nd = 0) or ( A</p><p>mn W</p><p>(1) d j is negative and X nd = 1). Thus, the maximal increase of Ĥ (2) mj based on X nd one can achieve is A d j ] − • X nd ) , which matches the terms in Eq. <ref type="bibr" target="#b11">(12)</ref>. To obtain the maximal overall increase in Ĥ (2) mj , and, thus, an upper bound, one simply picks the largest elements that still adhere to the budget constraints (Q,q). Obviously, since this is an admissible perturbation, this upper bound is tight. The proof for the lower bound is accordingly. □</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Adversarial Attacks on Node Embeddings via Graph Poisoning</title>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Semi-Supervised Learning. Adaptive Computation and Machine Learning series</title>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Zien</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Provable robustness of relu networks via maximization of linear regions</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maksym</forename><surname>Andriushchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In AISTATS</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adversarial Attack on Graph Structured Data</title>
		<author>
			<persName><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering</title>
		<author>
			<persName><forename type="first">Michaël</forename><surname>Defferrard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ZooBP: Belief Propagation for Heterogeneous Networks</title>
		<author>
			<persName><forename type="first">Dhivya</forename><surname>Eswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Disha</forename><surname>Makhija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="625" to="636" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Neural Message Passing for Quantum Chemistry</title>
		<author>
			<persName><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<idno>ICML. 1263-1272</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Inductive Representation Learning on Large Graphs</title>
		<author>
			<persName><forename type="first">Rex</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation</title>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maksym</forename><surname>Andriushchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2263" to="2273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">BIRDNEST: Bayesian Inference for Ratings-Fraud Detection</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Hooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leman</forename><surname>Akoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Disha Makhija, and Christos Faloutsos</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="495" to="503" />
		</imprint>
	</monogr>
	<note>SDM</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Predict then Propagate: Graph Neural Networks meet Personalized PageRank</title>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Klicpera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Simple and scalable predictive uncertainty estimation using deep ensembles</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Balaji Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Collective Classification of Network Data</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>London</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Classification: Algorithms and Applications</title>
		<imprint>
			<biblScope unit="volume">399</biblScope>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automating the construction of internet portals with machine learning</title>
		<author>
			<persName><forename type="first">Andrew Kachites</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamal</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Rennie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristie</forename><surname>Seymore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="127" to="163" />
			<date type="published" when="2000">2000. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distillation as a Defense to Adversarial Perturbations Against Deep Neural Networks</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Security and Privacy</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semidefinite relaxations for certifying robustness to adversarial examples</title>
		<author>
			<persName><forename type="first">Aditi</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><forename type="middle">S</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Collective classification in network data</title>
		<author>
			<persName><forename type="first">Prithviraj</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Galileo</forename><surname>Namata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Bilgic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Galligher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tina</forename><surname>Eliassi-Rad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">93</biblScope>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Provable defenses against adversarial examples via the convex outer adversarial polytope</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zico</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5283" to="5292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adversarial attacks on neural networks for graph data</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Akbarnejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2847" to="2856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Adversarial Attacks on Graph Neural Networks via Meta Learning</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
