<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3171E16200EF99440B6A982ABA47B4AE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prior Learning and Gibbs Reaction-Diffusion Song Chun Zhu and David Mumford</head><p>Abstract-This article addresses two important themes in early visual computation: First, it presents a novel theory for learning the universal statistics of natural images-a prior model for typical cluttered scenes of the world-from a set of natural images, and, second, it proposes a general framework of designing reaction-diffusion equations for image processing. We start by studying the statistics of natural images including the scale invariant properties, then generic prior models were learned to duplicate the observed statistics, based on the minimax entropy theory studied in two previous papers. The resulting Gibbs distributions have potentials of with S = {F (1) , F (2) , ..., F (K) } being a set of filters and L = {l (1) (), l (2) (), ..., l (K) ()} the potential functions. The learned Gibbs distributions confirm and improve the form of existing prior models such as lineprocess, but, in contrast to all previous models, inverted potentials (i.e., l(x) decreasing as a function of |x|) were found to be necessary. We find that the partial differential equations given by gradient descent on U(I; L, S) are essentially reaction-diffusion equations, where the usual energy terms produce anisotropic diffusion, while the inverted energy terms produce reaction associated with pattern formation, enhancing preferred image features. We illustrate how these models can be used for texture pattern rendering, denoising, image enhancement, and clutter removal by careful choice of both prior and data models of this type, incorporating the appropriate features.</p><p>Index Terms-Visual learning, Gibbs distribution, reaction-diffusion, anisotropic diffusion, texture synthesis, clutter modeling, image restoration.</p><p>----------3 ----------</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>N computer vision, many generic prior models have been proposed to capture the universal low level statistics of natural images. These models presume that surfaces of objects be smooth, and adjacent pixels in images have similar intensity values unless separated by edges, and they are applied in vision algorithms ranging from image restoration, motion analysis, to 3D surface reconstruction.</p><p>For example, in image restoration, general smoothness models are expressed as probability distributions <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b10">[11]</ref>: </p><p>where I is the image, Z is a normalization factor, and x I(x, y) = I(x + 1, y) -I(x, y),y I(x, y) = I(x, y + 1) -I(x, y) are differential operators. Three typical forms of the potential function y() are displayed in Fig. <ref type="figure" target="#fig_2">1</ref>. The functions in Fig. <ref type="figure" target="#fig_22">1b</ref> and Fig. <ref type="figure" target="#fig_22">1c</ref> have flat tails to preserve edges and object boundaries, and thus they are said to have advantages over the quadratic function in Fig. <ref type="figure" target="#fig_22">1a</ref>.</p><p>These prior models have been motivated by regularization theory <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b17">[18]</ref>, 1 physical modeling <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b3">[4]</ref>, 2 Bayesian theory <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b19">[20]</ref>, and robust statistics <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b2">[3]</ref>. Some connections between these interpretations are also observed in <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref> based on effective energy in statistics mechanics. Prior models of this kind are either generalized from traditional physical models <ref type="bibr" target="#b36">[37]</ref> or chosen for mathematical convenience. There is, however, little rigorous theoretical or empirical justification for applying these prior models to generic images, and there is little theory to guide the construction and selection of prior models. One may ask the following questions:</p><p>1) Why are the differential operators good choices in capturing image features? 2) What is the best form for p(I) and y()? 3) A relevant fact is that real world scenes are observed at more or less arbitrary scales, thus a good prior model should remain the same for image features at multiple scales. However none of the existing prior models has the scale-invariance property on the 2D image lattice, i.e., is renormalizable in terms of renormalization group theory <ref type="bibr" target="#b35">[36]</ref>.</p><p>In previous work on modeling textures, we proposed a new class of Gibbs distributions of the following form <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>,</p><formula xml:id="formula_1">p S Z e U S I I ; , ; , L L c h b g = - 1<label>(2)</label></formula><p>1. Where the smoothness term is explained as a stabilizer for solving "illposed" problems <ref type="bibr" target="#b31">[32]</ref>.</p><p>2. If y() is quadratic, then variational solutions minimizing the potential are splines, such as flexible membrane or thin plate models.  (</p><formula xml:id="formula_2">)<label>3</label></formula><p>In the above equation, S = {F (1) , F (2) , ..., F (K) } is a set of linear filters, and L = {l (1)  * I estimated over a set of the training images I-while having the maximum entropyand the best set of features {F (1) , F (2) , ..., F (K) } is selected by minimizing the entropy of p(I) <ref type="bibr" target="#b40">[41]</ref>. The conclusion of our earlier papers is that, for an appropriate choice of a small set of filters S, random samples from these models can duplicate very general classes of textures-as far as normal human perception is concerned. Recently, we found that similar ideas of model inference using maximum entropy have also been used in natural language modeling <ref type="bibr" target="#b0">[1]</ref>.</p><p>In this paper, we want to study to what extent probability distributions of this type can be used to model generic natural images, and we try to answer the three questions raised above.</p><p>We start by studying the statistics of a database of 44 real world images, and then we describe experiments in which Gibbs distributions in the form of (2) were constructed to duplicate the observed statistics. The learned potential functions l (a) (), a = 1, 2, ..., K can be classified into two categories: diffusion terms which are similar to Fig. <ref type="figure" target="#fig_22">1c</ref>, and reaction terms which, in contrast to all previous models, have inverted potentials (i.e., l(x) decreasing as a function of |x|).</p><p>We find that the partial differential equations given by gradient descent on U(I; L, S) are essentially reactiondiffusion equations, which we call the Gibbs Reaction and Diffusion Equations (Grade). In Grade, the diffusion components produce denoising effects which are similar to the anisotropic diffusion <ref type="bibr" target="#b24">[25]</ref>, while reaction components form patterns and enhance preferred image features.</p><p>The learned prior models are applied to the following applications.</p><p>First, we run the Grade starting with white noise images and demonstrate how Grade can easily generate canonical texture patterns, such as leopard blobs and zebra stripe, as the Turing reaction-diffusion equations do <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b37">[38]</ref>. Thus our theory provides a new method for designing PDEs for pattern synthesis.</p><p>Second, we illustrate how the learned models can be used for denoising, image enhancement, and clutter removal by careful choice of both prior and noise models of this type, incorporating the appropriate features extracted at various scales and orientations. The computation simulates a stochastic process-the Langevin equations-for sampling the posterior distribution.</p><p>This paper is arranged as follows: Section 2 presents a general theory for prior learning. Section 3 demonstrates some experiments on the statistics of natural images and prior learning. Section 4 studies the reaction-diffusion equations. Section 5 demonstrates experiments on denoising, image enhancement and clutter removal. Finally, Section 6 concludes with a discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">THEORY OF PRIOR LEARNING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Goal of Prior Learning and Two Extreme Cases</head><p>We define an image I on an N ¥ N lattice L to be a function such that for any pixel (x, y), I(x, y) OE /, and / is either an interval of R or / Ã Z. We assume that there is an underlying probability distribution f(I) on the image space / o t be a set of observed images which are independent samples from f(I). The objective of learning a generic prior model is to look for common features and their statistics from the observed natural images. Such features and their statistics are then incorporated into a probability distribution p(I) as an estimation of f(I), so that p(I), as a prior model, will bias vision algorithms against image features which are not typical in natural images, such as noise distortion and blurring. For this objective, it is reasonable to assume that any image features have an equal chance to occur at any location, so f(I) is translation invariant with respect to (x, y). We will discuss the limits of this assumption in Section 6.</p><p>To a f a f is an unbiased estimate for f (a) (z), and as</p><formula xml:id="formula_3">M AE •, m a obs z a f a f converges to f (a) (z) = E f [H (a) (z; I)].</formula><p>Now, to learn a prior model from the observed images</p><formula xml:id="formula_4">I n M n obs , , , ... , = 1 2 o</formula><p>t , immediately we have two simple solutions. The first one is:</p><formula xml:id="formula_5">p xy obs o x y L I I a f c h d i a f b g = OE ' m , , ,<label>(4)</label></formula><p>where </p><formula xml:id="formula_6">I I a f b g d i b g = -Â 1 1 y , , .<label>(5)</label></formula><p>The second solution is: </p><p>where &lt;, &gt; is inner product, y 2 (0) = 0, and y 2 (x) = • if x π 0, i.e., y 2 () is similar to the Potts model <ref type="bibr" target="#b36">[37]</ref>. These two solutions stand for two typical mechanisms for constructing probability models in the literature. The first is often used for image coding <ref type="bibr" target="#b34">[35]</ref>, and the second is a special case of the learning scheme using radial basis functions (RBF) <ref type="bibr" target="#b26">[27]</ref>. <ref type="foot" target="#foot_0">3</ref> Although the philosophies for learning these two prior models are very different, we observe that they share two common properties.</p><p>1) The potentials y 1 (), y 2 () are built on the responses of linear filters. In <ref type="bibr" target="#b6">(7)</ref> </p><formula xml:id="formula_8">M increases, E H z E H z p f a a a f a f c h c h ; ; I I AE .</formula><p>This second property is in general not satisfied by existing prior models in <ref type="bibr" target="#b0">(1)</ref>. p(I) in both cases meets our objective for prior learning, but intuitively they are not good choices. In <ref type="bibr" target="#b4">(5)</ref>, the d() filter does not capture spatial structures of larger than one pixel, and in <ref type="bibr" target="#b6">(7)</ref>, filters F (obsn) are too specific to predict features in unobserved images.</p><p>In fact, the filters used above lie in the two extremes of the spectrum of all linear filters. As discussed by Gabor <ref type="bibr" target="#b6">[7]</ref>, the d filter is localized in space but is extended uniformly in frequency. In contrast, some other filters, like the sine waves, are well localized in frequency but are extended in space. Filter F (obsn) includes a specific combination of all the components in both space and frequency. A quantitative analysis of the goodness of these filters is given in Table <ref type="table">1</ref> in Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Learning Prior Models by Minimax Entropy</head><p>To generalize the two extreme examples, it is desirable to compute a probability distribution which duplicates the observed marginal distributions for an arbitrary set of filters, linear or nonlinear. This goal is achieved by a minimax entropy theory studied for modeling textures in our previous papers <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>.</p><p>Given a set of filters {F (a) , a = 1, 2, ..., K}, and observed</p><formula xml:id="formula_9">statistics m a a obs z K a f a f { } , , ,..., =1<label>2</label></formula><p>, a maximum entropy distribution is derived which has the following Gibbs form:</p><formula xml:id="formula_10">p S Z e U S I I ; , ; , L L c h b g = - 1 (8) U S F x y x y K I I ; , , , L c h e jc h a f a f b g = * F H I K Â Â = l a a a 1<label>(9)</label></formula><p>In the above equation, we consider linear filters only, and</p><formula xml:id="formula_11">L = {l (1) (), l (2) (), ..., l (K) ()</formula><p>} is a set of potential functions on the features extracted by S. In practice, image intensities are discretized into a finite gray levels, and the filter responses are divided into a finite number of bins, therefore l (a) () is approximated by a piecewisely constant functions, i.e., a vector, which we denote by l (a) , a = 1, 2, ..., K.</p><p>The l (a) s are computed in a nonparametric way so that the learned p(I; L, S) reproduces the observed statistics:</p><formula xml:id="formula_12">E H z z K z p S obs I I ; , ; , , ... , , L a f a f a f c h a f a a m a = = "<label>1 2</label></formula><p>.</p><p>Therefore as far as the selected features and their statistics are concerned, we cannot distinguish between p(I; L, S) and the "true" distribution f(I).</p><p>Unfortunately, there is no simple way to express the l (a) s in terms of the m a obs a f s as in the two extreme examples. To compute l (a) s, we adopted the Gibbs sampler <ref type="bibr" target="#b8">[9]</ref>, which simulates an inhomogeneous Markov chain in image space</p><formula xml:id="formula_13">/ N 2</formula><p>. This Monte Carlo method iteratively samples from the distribution p(I; L, S), followed by computing the histogram of the filter responses for this sample and updating the l (a) to bring the histograms closer to the observed ones.</p><p>For a detailed account of the computation of l (a) s, the readers are referred to <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>.</p><p>In our previous papers, the following two propositions are observed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PROPOSITION 1. Given a filter set S, and observed statistics</head><formula xml:id="formula_14">m a a obs K a f { } , , ,..., =1<label>2</label></formula><p>, there is an unique solution for</p><formula xml:id="formula_15">l a a a f { } , , , ... , = 1 2 K . PROPOSITION 2.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>f(I) is determined by its marginal distributions, thus p(I) = f(I) if it reproduces all the marginal distributions of linear filters.</head><p>But for computational reasons, it is often desirable to choose a small set of filters which most efficiently capture the image structures. Given a set of filters S, and an ME distribution p(I; L, S), the goodness of p(I; L, S) is often measured by the Kullback-Leibler information distance between p(I; L, S) and the ideal distribution f(I) <ref type="bibr" target="#b16">[17]</ref>, where S is chosen from a general filter bank B such as Gabor filters at multiple scales and orientations. Enumerating all possible sets of features S in the filter bank and comparing their entropies is computationally too expensive. Instead, in <ref type="bibr" target="#b40">[41]</ref> we propose a stepwise greedy procedure for minimizing the KL-distance. We start from S = ∆ and p(I; L, S) a uniform distribution, and introduce one filter at a time. Each added filter is chosen to maximally decrease the KL-distance, and we keep doing this until the decrease is smaller than a certain value.</p><formula xml:id="formula_16">KL f p S f f p S d E f E p S</formula><p>In the experiments of this paper, we have used a simpler measure of the "information gain" achieved by adding one new filter to our feature set S. This is roughly an L 1 -distance (vs. the L 2 -measure implicit in the Kullback-Leibler distance), the readers are referred to <ref type="bibr" target="#b41">[42]</ref> for a detailed account. DEFINITION 3. Given S = {F (1) , F (2) , ..., F (K) } and p(I; L, S) defined above, the information criterion (IC) for each filter F ;I .</p><formula xml:id="formula_17">(b) OE B/S at step K + 1 is: IC M H z E H z M H z z n obs p S n M n obs obs n M = - - - = = Â Â 1 2 1 2</formula><p>For a filter F (b) , the bigger AIG is, the more information</p><formula xml:id="formula_18">F (b)</formula><p>captures as it reports the error between the current model and the observations. AIF is a measure of disagreement between the observed images. The bigger AIF is, the less their responses to F (a) have in common.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS ON NATURAL IMAGES</head><p>This section presents experiments on learning prior models, and we start from exploring the statistical properties of natural images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Statistic of Natural Images</head><p>It is well known that natural images have statistical properties distinguishing them from random noise images <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b23">[24]</ref>. In our experiments, we collected a set of 44 natural images, six of which are shown in Fig. <ref type="figure">2</ref>. These images are from various sources, some digitized from books and postcards, and some from a Corel image database. Our database includes both indoor and outdoor pictures, country and urban scenes, and all images are normalized to have intensity between zero and 31. As stated in Proposition 2, marginal distributions of linear filters alone are capable of characterizing f(I). In the rest of this paper, we shall only study the following bank B of linear filters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) An intensity filter d().</head><p>2) Isotropic center-surround filters, i.e., the Laplacian of Gaussian filters.</p><p>LG x y s const x y s e</p><p>x y s , ,</p><formula xml:id="formula_19">c h e j = ◊ + - - + 2 2 2 2 2 2 , (<label>10</label></formula><formula xml:id="formula_20">)</formula><p>where s = 2s stands for the scale of the filter. We de-note these filters by LG(s). A special filter is LG , , ; , , ; , , -, and we denote it by D.</p><p>3) Gabor filters with both sine and cosine components, which are models for the frequency and orientation sensitive simple cells.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G x y s const Rot e e s s</head><p>x y i x , , ,q</p><formula xml:id="formula_21">q p c h a f e j = - + - o o 1 2 2 2 2 2 4 (<label>11</label></formula><formula xml:id="formula_22">)</formula><p>It is a sine wave at frequency 2p s modulated by an elongated Gaussian function, and rotated at angle q.</p><p>We denote the real and image parts of G(x, y, s, q) by Gcos(s, q) and Gsin(s, q). Two special Gsin(s, q) filters are the gradientsx ,y . 4) We will approximate large scale filters by filters of small window sizes on the high level of the image pyramid, where the image in one level is a "blowndown" version (i.e., averaged in 2 ¥ 2 blocks) of the image below.</p><p>We observed three important aspects of the statistics of natural images.</p><p>First, for some features, the statistics of natural images vary widely from image to image. We look at the d() filter as in Section 2.1. The average intensity histogram of the 44 images m obs o a f is plotted in Fig. <ref type="figure" target="#fig_11">3a</ref>, and Fig. <ref type="figure" target="#fig_11">3b</ref> is the intensity histogram of an individual image (the temple image in Fig. <ref type="figure">2</ref>). It appears that m obs o z a f a f is close to a uniform distri- bution (Fig. <ref type="figure" target="#fig_11">3c</ref>), while the difference between Fig. <ref type="figure" target="#fig_11">3a</ref> and Fig. <ref type="figure" target="#fig_11">3b</ref> is very big. Thus IC for filter d() should be small (see Table <ref type="table">1</ref>). Second, for many other filters, the histograms of their responses are amazingly consistent across all 44 natural images, and they are very different from the histograms of noise images. For example, we look at filterx . Fig. <ref type="figure">4a</ref> is the average histogram of 44 filtered natural images, Fig. <ref type="figure">4b</ref> is the histogram of an individual filtered image (the same image as in Fig. <ref type="figure" target="#fig_11">3b</ref>), and Fig. <ref type="figure">4c</ref> is the histogram of a filtered uniform noise image.</p><p>The average histogram in Fig. <ref type="figure">4a</ref> is very different from a Gaussian distribution. To see this, Fig. <ref type="figure">5a</ref> plots it against a Gaussian curve (dashed) of the same mean and same variance. The histogram of natural images has higher kurtosis and heavier tails. Similar results are reported in <ref type="bibr" target="#b5">[6]</ref>. To see the difference of the tails, Fig. <ref type="figure">5b</ref> plots the logarithm of the two curves.</p><p>Third, the statistics of natural images are essentially scale invariant with respect to some features. As an example, we look at filters - </p><formula xml:id="formula_23">+ = + + + + + + + 1 2 2 2 2 1 2 1 2 2 1 2 1 , ,<label>,</label></formula><p>, ,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>b g c h c h c h c h</head><p>The size of</p><formula xml:id="formula_24">I n s is N/2 s ¥ N/2 s .</formula><p>For the filterx , let m x,s (z) be the average histogram of 1) natural images contains objects of all sizes and 2) natural scenes are viewed and made into images at arbitrary distances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Empirical Prior Models</head><p>In this section, we learn the prior models according to the theory proposed in Section 2 and analyze the efficiency of the filters quantitatively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Experiment I</head><p>We start from S = ∆ and p 0 (I) a uniform distribution. We compute the AIF, AIG, and IC for all filters in our filter bank. We list the results for a small number of filters in Table <ref type="table">1</ref>. The filter D has the biggest IC (= 0.642), thus is chosen as F (1) . An ME distribution p 1 (I; L, S) is learned, and the information criterion for each filter is shown in the column headed p 1 (I) in Table <ref type="table">1</ref>. We notice that the IC for the filter D drops to near zero, and IC also drops for other filters because these filters are in general not independent of D. Some small filters like LG <ref type="bibr" target="#b0">(1)</ref> have smaller ICs than others, due to higher correlations between them and D.</p><p>The big filters with larger IC are investigated in Experiment II. In this experiment, we choose bothx andy to be F (2) , F (3) as in other prior models. Therefore, a prior model ),</p><formula xml:id="formula_25">y 3 (z) = 1.95(1 -1/(1 + (|z|/2.8) 1.5</formula><p>), respectively. A synthesized image sampled from p 3 I a f is displayed in Fig. <ref type="figure">8</ref>.</p><p>So far, we have used three filters to characterize the statistics of natural images, and the synthesized image in Fig. <ref type="figure">8</ref> is still far from natural ones. Especially, even though the learned potential functions l (a) (z), a = 1, 2, 3 all have flat tails to preserve intensity breaks, they only generate small speckles instead of big regions and long edges as one may expect. Based on this synthesized image, we compute the AIG and IC for all filters, and the results are listed in Table <ref type="table">1</ref> in column p 3 (I).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Experiment II</head><p>It is clear that we need large-scale filters to do better. Rather than using the large scale Gabor filters, we chose to usex andy on four different scales and impose explicitly the scale invariant property that we find in natural images.</p><p>Given an image I defined on an N ¥ N lattice L, we build a pyramid in the same way as before. Let I [s] , s = 0, 1, 2, 3 be four layers of the pyramid. Let H x,s (z, x, y) denote the histo-</p><formula xml:id="formula_26">gram of -x I [s]</formula><p>(x, y) and H y,s (z, x, y) the histogram ofy I</p><p>[s] (x, y). We ask for a probability model p(I) which satisfies </p><formula xml:id="formula_27">E H z x y z z x y L s p x s s I a f c h a f c h , ,<label>, , , , , , , = "</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE 1 THE INFORMATION CRITERION FOR FILTER SELECTION</head><p>Fig. <ref type="figure">9</ref> displays l x,s (), s = 0, 1, 2, 3. At the beginning of the learning process, all l x,s (), s = 0, 1, 2, 3 are of the form displayed in Fig. <ref type="figure">7</ref> with low values around zero to encourage smoothness. As the learning proceeds, gradually l x,3 () turns "upside down" with smaller values at the two tails. Then l x,2 () and l x,1 () turn upside down one by one. Similar results are observed for l y,s (), s = 0, 1, 2, 3. Fig. <ref type="figure" target="#fig_18">11</ref> is a typical sample image from p s (I). To demonstrate it has scale invariant properties, in Fig. <ref type="figure" target="#fig_22">10</ref> we show the histograms H x,s and log H x,s of this synthesized image for s = 0, 1, 2, 3.</p><p>The learning process iterates for more than 10,000 sweeps. To verify the learned l()s, we restarted a homogeneous Markov chain from a noise image using the learned model, and found that the Markov chain goes to a perceptually similar image after 6,000 sweeps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.1">Remark 1</head><p>In Fig. <ref type="figure">9</ref>, we notice that l x,s () are inverted, i.e., decreasing functions of |z| for s = 1, 2, 3, distinguishing this model from other prior models in computer vision. First of all, as the image intensity has finite range [0, 31],x I [s] is defined in <ref type="bibr">[-31, 31]</ref>. Therefore we may define l x,s (z) = 0 for |z| &gt; 31, so p s (I) is still well-defined. Second, such inverted potentials have significant meaning in visual computation. In image restoration, when a high intensity difference <ref type="figure">y</ref>) is present, it is very likely to be noise if s = 0.</p><formula xml:id="formula_28">-x I [s] (x,</formula><p>However this is not true for s = 1, 2, 3. Additive noise can hardly pass to the high layers of the pyramid because at each layer the 2 ¥ 2 averaging operator reduces the variance of the noise by four times. Whenx I [s] (x, y) is large for s = 1, 2, 3, it is more likely to be a true edge and object boundary. So in p s (I), l x,0 () suppresses noise at the first layer, while l x,s (), s = 1, 2, 3 encourages sharp edges to form, and thus enhances blurred boundaries. We notice that regions of various scales emerge in Fig. <ref type="figure" target="#fig_18">11</ref>, and the intensity contrasts are also higher at the boundary. These appearances are missing in Fig. <ref type="figure">8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.2">Remark 2</head><p>Based on the image in Fig. <ref type="figure" target="#fig_18">11</ref>, we computed IC and AIG for all filters and list them under column p s (I) in Table <ref type="table">1</ref>. We also compare the two extreme cases discussed in Section 2.1. For the d() filter, AIF is very big, and AIG is only slightly bigger than AIF. Since all the prior models that we learned have no preference about the image intensity domain, the image intensity has uniform distribution, but we limit it inside [0, 31], thus the first row of Table <ref type="table">1</ref> has the same value for IC and AIG. For filter I (obsi) , AIF M M = -1 , i.e., the biggest among all filters, and AIG AE 1. In both cases, ICs are the two smallest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">GIBBS REACTION-DIFFUSION EQUATIONS 4.1 From Gibbs Distribution to Reaction-Diffusion Equations</head><p>The empirical results in the previous section suggest that the forms of the potentials l (a) (z) learned from images of real world scenes can be divided into two classes: upright curves l(z) for which l() is an even function increasing as |z| increases and inverted curves for which the opposite happens. A similar phenomenon was observed in our learned texture models <ref type="bibr" target="#b39">[40]</ref>.</p><p>In Fig. <ref type="figure">9</ref>, l x,s (z) are fit to the family of functions (see the dashed curves),</p><formula xml:id="formula_29">f x x x g b g d i = - + - F H G G I K J J &gt; a b a 1 1 1 0 0 / y x x x g b g d i = - + - F H G G I K J J &lt; a b a 1 1 1 0 0 /</formula><p>x 0 , b are, respectively, the translation and scaling constants, and ʈaʈ weights the contribution of the filter.</p><p>In general, the Gibbs distribution learned from images in a given application has potential function of the following form,  Instead of defining a whole distribution with U, one can use U to set up a variational problem. In particular, one can attempt to minimize U by gradient descent. This leads to a non-linear parabolic partial differential equation:</p><formula xml:id="formula_30">I I I t n n K F F F F d d = * * + * * - ¢ = - ¢ = + Â Â a a a a a a a a f y a f a f a f a f a f a f e j e j<label>1 1 (14)</label></formula><p>with</p><formula xml:id="formula_31">F x y F x y - - = - -- a a a f a f c h c h , ,</formula><p>. Thus starting from an input image I(x, y, 0) = I in , the first term diffuses the image by reducing the gradients, while the second term forms patterns as the reaction term. We call <ref type="bibr" target="#b13">(14)</ref> the Grade. Since the computation of ( <ref type="formula">14</ref>) involves convolving twice for each of the selected filters, a conventional way for efficient computation is to build an image pyramid so that filters with large scales and low frequencies can be scaled down into small ones in the higher level of the image pyramid. This is appropriate especially when the filters are selected from a bank of multiple scales, such as the Gabor filters and the wavelet transforms. We adopt this representation in our experiments.</p><p>For an image I, let I [s] be an image at level s = 0, 1, 2, ..  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Anisotropic Diffusion and Gibbs Reaction-Diffusion</head><p>This section compares Grades with previous diffusion equations in vision.</p><p>In <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b22">[23]</ref>, anisotropic diffusion equations for generating image scale spaces are introduced in the following form,</p><formula xml:id="formula_32">I t = div(c(x, y, t)-I), I(x, y, 0) = I in , (<label>15</label></formula><formula xml:id="formula_33">)</formula><p>where div is the divergence operator, i.e., div r V P Q</p><p>x y</p><formula xml:id="formula_34">d i = -+ - for r V P Q = ,</formula><p>c h. Perona and Malik defined the heat conduc- tivity c(x, y, t) as functions of local gradients, for example:</p><formula xml:id="formula_35">I I I I I t x x x y y y b b = - + F H G G I K J J + - + F H G G G I K J J J 1 1 1 1 2 2 / / c h e j<label>(16)</label></formula><p>Equation ( <ref type="formula" target="#formula_35">16</ref>) minimizes the energy function in a continuous form, are plotted in Fig. <ref type="figure" target="#fig_21">12</ref>. Similar forms of the energy functions are widely used as prior distributions <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b10">[11]</ref>, and they can also be equivalently interpreted in the sense of robust statistics <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b2">[3]</ref>.</p><p>In the following, we address three important properties of the Gibbs reaction-diffusion equations.</p><p>First, we note that ( <ref type="formula">14</ref>) is an extension to (15) on a discrete lattice by defining a vector field,</p><formula xml:id="formula_36">r V x y n n K d d , , ... , , , ... , b g c h c h c h c h a f c h c h a f = F H G I K J ¢ ¢ + ¢ ¢ f f y y 1 1</formula><p>and a divergence operator,</p><formula xml:id="formula_37">div = * + * + + * - - - F F F K 1 2 a f a f a f L .</formula><p>Thus ( <ref type="formula">14</ref>) can be written as,</p><formula xml:id="formula_38">I t V = div r d i .<label>(17)</label></formula><p>Compared to <ref type="bibr" target="#b14">(15)</ref>, which transfers the "heat" among adjacent pixels, (17) transfers the "heat" in many directions in a graph, and the conductivities are defined as functions of the local patterns not just the local gradients. Second, in Fig. <ref type="figure" target="#fig_22">13,</ref><ref type="figure">f</ref> Third, the learned potential functions confirmed and improved the existing prior models and diffusion equations, but, more interestingly, reaction terms are first discovered, and they can produce patterns and enhance preferred features. We will demonstrate this property in the experiments below. </p><formula xml:id="formula_39">a f, ≥ 1. (b) f x g a f, &lt; 1. (c) ¢ ≥ f x g a f, 1. (d). ¢ &lt; f x g a f, 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Gibbs Reaction-Diffusion for Pattern Formation</head><p>In the literature, there are many nonlinear PDEs for pattern formation, of which the following two examples are interesting:</p><p>1) The Turing reaction-diffusion equation which models the chemical mechanism of animal coats <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b20">[21]</ref>. Two canonical patterns that the Turing equations can synthesize are leopard blobs and zebra stripes <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b37">[38]</ref>. These equations are also applied to image processing such as image halftoning <ref type="bibr" target="#b28">[29]</ref>, and a theoretical analysis can be found in <ref type="bibr" target="#b14">[15]</ref>. 2) The Swindale equation which simulates the development of the ocular dominance stripes in the visual cortex of cats and monkey <ref type="bibr" target="#b29">[30]</ref>. The simulated patterns are very similar to the zebra stripes.</p><p>In this section, we show that these patterns can be easily generated with only two or three filters using the Grade. We run <ref type="bibr" target="#b13">(14)</ref> starting with I(x, y, 0) as a uniform noise image, and Grade converges to a local minimum. Some synthesized texture patterns are displayed in Fig. <ref type="figure" target="#fig_26">14</ref>.</p><p>For all six patterns in Fig. <ref type="figure" target="#fig_26">14</ref>   It seems that the leopard blobs and zebra stripes are among the most canonical patterns which can be generated with easy choices of filters and parameters. As shown in <ref type="bibr" target="#b39">[40]</ref>, the Gibbs distribution are capable of modeling a large variety of texture patterns, but filters and different forms for y(x) have to be learned for a given texture pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">IMAGE ENHANCEMENT AND CLUTTER REMOVAL</head><p>So far we have studied the use of a single energy function U(I) either as the log likelihood of a probability distribution at I or as a function of I to be minimized by gradient descent. In image processing, we often need to model both the underlying images and some distortions, and to maximize a posterior distribution. Suppose the distortions are additive, i.e., an input image is,</p><formula xml:id="formula_40">I in = I + C.</formula><p>In many applications, the distortion images C are often not i.i.d. Gaussian noise, but clutter with structures such as trees in front of a building or a military target. Such clutter will be very hard to handle by edge detection and image segmentation algorithms.</p><p>We propose to model clutter by an extra Gibbs distribution, which can be learned from some training images by the minimax entropy theory as we did for the underlying image I. Thus an extra pyramidal representation for I in -I is needed in a Gibbs distribution form as shown in Fig. <ref type="figure" target="#fig_25">15</ref>. The resulting posterior distributions are still of the Gibbs form with potential function,</p><formula xml:id="formula_41">U * (I) = U C (I in -I; L C , S C ) + U(I; L, S), (<label>18</label></formula><formula xml:id="formula_42">)</formula><p>where U C () is the potential of the clutter distribution.  The analyses of convergence of the equations can be found in <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b7">[8]</ref>. The computational load for the annealing process is notorious, but, for applications like denoising, a fast decrease of temperature may not affect the final result very much.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiment I</head><p>In the first experiment, we take U C to be quadratic, i.e., C to be an i.i.d. Gaussian noise image. We first compare the performance of the three prior models p l (I), p t (I), and p s (I) whose potential functions are, respectively:  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experiment II</head><p>In many applications, i.i.d. Gaussian models for distortions are not sufficient. For example, in Fig. <ref type="figure" target="#fig_22">17a</ref>, the tree branches in the foreground will make image segmentation and object recognition extremely difficult, because they cause strong edges across the image. Modeling such clutter is a challenging problem in many applications. In this paper, we only consider clutter as two-dimensional pattern, despite its geometry and 3D structure. We collected a set of images of buildings and a set of images of trees all against clean background-the sky. For the tree images, we translate the image intensities to [-31, 0], i.e., zero for sky. In this case, since the trees are always darker than the building, thus the negative intensity will approximately take care of the occlusion effects. We learn the Gibbs distributions for each set respectively in the pyramid, then such models are respectively adopted as the prior distribution and the likelihood as in <ref type="bibr" target="#b17">(18)</ref>. We recovered the underlying images by maximizing a posteriori distribution using the stochastic process.   As a comparison, we run the anisotropic diffusion process <ref type="bibr" target="#b24">[25]</ref> on Fig. <ref type="figure" target="#fig_22">19a</ref>, and images at iterations t = 50, 100, 300 are displayed in Fig. <ref type="figure">20</ref>. As we can see that as t AE •, I(t) becomes a flat image. A robust anisotropic diffusion equation is recently reported in <ref type="bibr" target="#b1">[2]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we studied the statistics of natural images, based on which a novel theory is proposed for learning the generic prior model-the universal statistics of real world scenes. We argue that the same strategy developed in this paper can be used in other applications. For example, learning probability models for MRI images and 3D depth maps.</p><p>The learned prior models demonstrate some important properties such as the "inverted" potentials terms for patterns formation and image enhancement. The expressive power of the learned Gibbs distributions allow us to model structured noise-clutter in natural scenes. Furthermore, our prior learning method provides a novel framework for designing reaction-diffusion equations based on the observed images in a given application, without modeling the physical or chemical processes as people did before <ref type="bibr" target="#b32">[33]</ref>.</p><p>Although the synthesized images bear important features of natural images, they are still far from realistic ones. In other words, these generic prior models can do very little beyond image restoration. This is mainly due to the fact that all generic prior models are assumed to be translation invariant, and this homogeneity assumption is unrealistic. We call the generic prior models studied in this paper the first-level prior. A more sophisticated prior model should incorporate concepts like object geometry, and we call such prior models second-level priors. Diffusion equations derived from this second-level prior are studied in image segmentation <ref type="bibr" target="#b38">[39]</ref>, and in scale space of shapes <ref type="bibr" target="#b15">[16]</ref>. A discussion of some typical diffusion equations is given in <ref type="bibr" target="#b21">[22]</ref>. It is our hope that this article will stimulate further investigations on building more realistic prior models as well as sophisticated PDEs for visual computation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Three existing forms for y(). (a) Quadratic: y(x) = ax 2 . (b) Line process: y(x) = a min(q 2 , x 2 ). (c) T-function: y x</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Then for a fixed model complexity K, the best feature set S * is selected by the following criterion:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>We call the first term "average information gain" (AIG) by choosing F(b) , and the second term "average information fluctuation" (AIF). Intuitively, AIG measures the average error between the filter responses in the database and the marginal distribution of the current model p(I; L, S). In practice, we need to sample p(I; L, S), thus synthesize images I n syn n estimate E p(I; L ,S) [H (b) (z; I)] by m</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 2 .Fig. 3 .Fig. 4 .Fig. 5 .</head><label>2345</label><figDesc>Fig. 2. Six out of the 44 collected natural images.</figDesc><graphic coords="4,294.55,540.83,251.89,158.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>x andy . For each image I n obs obs NI OE , we build a pyramid with I n s being the image at the sth layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>I</head><label></label><figDesc>, over n = 1, 2, ..., 44. Fig. 6a plots m x,s (z), for s = 0, 1, 2, and they are almost identical. To see the tails more clearly, we display log m x,s (z), s = 0, 1, 2 in Fig. 6c. The differences between them are still small. Similar results are observed for m y,s (z), s = 0, 1, 2, the average histograms ofy n obs I . In contrast, Fig. 6b plots the histograms of -x s I with I s being a uniform noise image at scales s = 0, 1, 2. Combining the second and the third aspects above, we conclude that the histograms of -x n s I ,y n s I are very consistent across all observed natural images and across scales s = 0, 1, 2. The scale invariant property of natural images is largely caused by the following facts:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>p 3 (</head><label>3</label><figDesc>I) is learned with potential: for z OE[-22, 22]. These three curves are fitted with the functions y 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>N ¥ N being the size of synthesized image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 6 .Fig. 7 .Fig. 8 .</head><label>678</label><figDesc>Fig. 6. (a) m x,s(z), s = 0, 1, 2. (b) logm x,s (z), s = 0 (solid), s = 1 (dash-dotted), and s = 2 (dashed). (c) Histograms of a filtered uniform noise image at scales: s = 0 (solid curve), s = 1 (dash-dotted curve), and s = 2 (dashed curve).</figDesc><graphic coords="7,24.63,242.46,164.52,131.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>is the image lattice at level s, and m z a f is the aver- age of the observed histograms ofx I[s] andy I[s] on all 44 natural images at all scales. This results in a maximum entropy distribution p s (I) with energy of the following form,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>filter set is now divided into two parts S = S d ʜ S r , with S d = {F (a) , a = 1, 2, .., n d } and S r = {F (a) , a = n d + 1, ..., K}. In most cases S d consists of filters such asx , y , D which capture the general smoothness of images, and S r contains filters which characterize the prominent features of a class of images, e.g., Gabor filters at various orientations and scales which respond to the larger edges and bars.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 9 .Fig. 10 .</head><label>910</label><figDesc>Fig. 9. Learned potential functions l x,s (), s = 0, 1, 2, 3. The dashed curves are fitting functions: f(x) = a(1 -1/(1 + (|x|/b) g ). (a) (a = 5, b = 10, x o = 0, g = 0.7). (b) (a = -2.0, b = 10, x o = 0, g = 1.6). (c) (a = -4.8, b = 15, x o = 0, g = 2.0). (d) (a = -10.0, b = 22, x o = 0, g = 5.0).</figDesc><graphic coords="9,99.69,404.51,197.15,129.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>a</head><label></label><figDesc>. of a pyramid, and I[0] = I, the potential function becomes We can derive the Grade equations similarly for this pyramidal representation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. A typical sample of p s (I) (384 ¥ 384 pixels).</figDesc><graphic coords="10,30.61,59.99,251.74,251.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>.F</head><label></label><figDesc>(x) has round tip for g ≥ 1, and a cusp occurs at x = 0 for 0 &lt; g &lt; 1 which leaves ¢ f x b g unde- fined, i.e., ¢ f x b g can be any value in (-•, •) as shown by the dotted curves in Fig. 13d. An interesting fact is that the potential function learned from real world images does have a cusp as shown in Fig. 9a, where the best fit is g = 0.7. This cusp forms because a large part of objects in real world images have flat intensity appearances, and f(x) with g &lt; 1 will produce piecewise constant regions with much stronger forces than g ≥ 1. By continuity, ¢ f x b g can be assigned any value in the range [-w, w] for x OE [-⑀, ⑀] In numerical simulations, for x OE [-w, w], we take the summation of the other terms in the differential equation whose values are well defined. Intuitively when g &lt; 1 and x = (F (a) * I)(x, y) = 0, f (a)¢ (0) forms an attractive basin in its neighborhood 1 (a) (x, y) specified by the filter window of F(a) . For a pixel (u, v) OE 1 (a) (x, y), the depth of the attractive basin is w a in multiple zero filter responses, it will accumulate the depth of the attractive basin generated by each filter. Thus unless the absolute value of the driving force from other well-defined terms is larger than the total depth of the attractive basin at (u, v), I(u, v) will stay unchanged. In the image restoration experiments in later sections, g &lt; 1 shows better performance in forming piecewise constant regions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. (a) l(x) = alog(1 + (x/b) 2 ). (b) ¢ = +( )</figDesc><graphic coords="11,112.42,244.35,164.49,136.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>1 a</head><label>1</label><figDesc>Fig.14b, and Fig.14c, we choose isotropic center-surround</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>F 1 2 2 a 2 a</head><label>122</label><figDesc>Fig. 14e where (a = -3.5, b = 10, g = 2.0, x o = 0) for y x 1 2 a f b g.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Fig. 14f is 3 ) for y x 1 2 a f b g and y x 1 3 a f b g.</head><label>323</label><figDesc>Fig. 14f is generated with two reaction filters Gcos(4, 30 o ), Gcos(4, 60 o ) at level one, where (a = -3.5, b = 10, g = 2.0, x o = -3) for y x 1 2 a f b g and y x 1 3 a f b g.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. The computational scheme for removing noise and clutter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Leopard blobs and zebra stripes synthesized by Grades.</figDesc><graphic coords="12,30.56,59.79,251.86,193.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. (a) The noise distorted image. (b)-(d) Restored images by prior models p I l a f, p I t a f, and p I s a f, respectively.</figDesc><graphic coords="13,24.52,282.96,251.91,272.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head></head><label></label><figDesc>. (a) The observed image. (b) The restored image using six filters. For example, Fig. 17b is computed using six filters with two filters for I: {x,0 ,y,0 }, and four filters for I C : {d,x ,y , Gcos(2, 30 o )}, i.e., the potential for I C is: are fit to the potential functions learned from the set of tree images: energy term f * (I(x, y)) forces zero intensity for the clutter image while allowing for large negative intensities for the dark tree branches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head></head><label></label><figDesc>Fig. 18b is computed using eight filters with four filters for I and four filters for I C . Thirteen filters are used for Fig. 19 where the clutter is much heavier.As a comparison, we run the anisotropic diffusion process<ref type="bibr" target="#b24">[25]</ref> on Fig.19a, and images at iterations t = 50, 100, 300 are displayed in Fig.20. As we can see that as t AE •, I(t) becomes a flat image. A robust anisotropic diffusion equation is recently reported in<ref type="bibr" target="#b1">[2]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Fig. 18 .Fig. 19 .Fig. 20 .</head><label>181920</label><figDesc>Fig. 18. (a) An observed image. (b) The restored image using eight filters.</figDesc><graphic coords="14,30.59,59.99,251.80,151.03" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>In RBF, the basis functions are presumed to be smooth, such as a Gaussian function. Here, using d() is more loyal to the observed data.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>This work was started when the authors were at Harvard University. This research was supported by a U.S. National Science Foundation grant and a grant from ARO. We thank Y.N. Wu and S. Geman for valuable discussion.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Maximum Entropy Approach to Natural Language Processing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Della</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Della Pietra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Robust Anisotropic Diffusion</title>
		<author>
			<persName><forename type="first">M</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marimont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On the Unification of Line Processes, Outlier Rejection, and Robust Statistics With Applications in Early Vision</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Visual Reconstruction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, Mass</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Uncertainty Relation for Resolution in Space, Spatial Frequency, and Orientation Optimized by Two-Dimensional Visual Cortical Filters</title>
		<author>
			<persName><forename type="first">J</forename><surname>Daugman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optical Soc. America</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1" to="160" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Relations Between the Statistics of Natural Images and the Response Properties of Cortical Cells</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optical Soc. America, A</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Theory of Communication</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gabor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEE Proc</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">26</biblScope>
			<date type="published" when="1946">1946</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On Sampling Methods and Annealing Algorithms</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Gelfand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Mitter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Markov Random Fields-Theory and Applications</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Stochastic Relaxation, Gibbs Distributions and the Bayesian Restoration of Images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="721" to="741" />
			<date type="published" when="1984-07">July 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Diffusion for Global Optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Control and Optimization</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Constrained Restoration and the Recover of Discontinuities</title>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Reynoids</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="367" to="383" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Parallel and Deterministic Algorithms for MRFs: Surface Reconstruction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Girosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="401" to="412" />
			<date type="published" when="1991-05">May 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Common Framework for Image Segmentation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="227" to="243" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Renormalization Group Approach to Image Processing Problems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gidas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1989-02">Feb. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">The Theory and Applications of Reaction-Diffusion Equations</title>
		<author>
			<persName><forename type="first">P</forename><surname>Grindrod</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Oxford Univ. Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Shapes, Shocks, and Deformations I: The Components of Two-Dimensional Shape and the Reaction-Diffusion Space</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kimia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tannebaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="189" to="224" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On Information and Sufficiency</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kullback</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Leibler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Math. Stat</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="79" to="86" />
			<date type="published" when="1951">1951</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Probabilistic Solution of Ill-Posed Problems in Computational Vision</title>
		<author>
			<persName><forename type="first">J</forename><surname>Marroguin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mitter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Statistical Assoc</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">397</biblScope>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Robust Regression Methods for Computer Vision: A Review</title>
		<author>
			<persName><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Optimal Approximations by Piecewise Smooth Functions and Associated Variational Problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. Pure Applied Math</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="577" to="684" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Pre-Pattern Formation Mechanism for Mammalian Coat Markings</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Theoretical Biology</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="161" to="199" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A General Framework for Geometry-Driven Evolution Equations</title>
		<author>
			<persName><forename type="first">W</forename><surname>Niessen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Romeny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Florack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="187" to="205" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Nonlinear Image Filtering With Edge and Corner Enhancement</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nitzberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shiota</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="826" to="833" />
			<date type="published" when="1992-08">Aug. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Natural Image Statistics and Efficient Coding</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop on Information Theory and the Brain</title>
		<meeting>Workshop on Information Theory and the Brain</meeting>
		<imprint>
			<date type="published" when="1995-09">Sept. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Scale-Space and Edge Detection Using Anisotropic Diffusion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="629" to="639" />
			<date type="published" when="1990-07">July 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Computational Vision and Regularization Theory</title>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">317</biblScope>
			<biblScope unit="page" from="314" to="319" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Networks for Approximation and Learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Girosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page">497</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Statistics of Natural Images: Scaling in the Woods</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Ruderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bialek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Letter</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="814" to="817" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">M-Lattice: From Morphogenesis to Image Processing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sherstinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="1996-07">July 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A Model for the Formation of Ocular Dominance Stripes</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Swindale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Royal Soc. London B</title>
		<imprint>
			<biblScope unit="volume">208</biblScope>
			<biblScope unit="page" from="243" to="264" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multilevel Computational Processes for Visual Surface Reconstruction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, Graphics, and Image Processing</title>
		<imprint>
			<date type="published" when="1983">1983</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="52" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Solutions of Ill-Posed Problems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Tikhonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Y</forename><surname>Arsenin</surname></persName>
		</author>
		<editor>V.H. Winston &amp; Sons</editor>
		<imprint>
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The Chemical Basis of Morphogenesis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Turing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophy Trans. Royal Soc. London</title>
		<imprint>
			<biblScope unit="volume">237</biblScope>
			<biblScope unit="issue">B</biblScope>
			<biblScope unit="page" from="37" to="72" />
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Generating Textures on Arbitrary Surfaces Using Reaction-Diffusion</title>
		<author>
			<persName><forename type="first">G</forename><surname>Turk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Efficiency of Model Human Image Code</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optical Soc. America A</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The Renormalization Group: Critical Phenomena and the Knodo Problem</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rev. Mod. Phys</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="773" to="840" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Image Analysis, Random Fields and Dynamic Monte Carlo Methods</title>
		<author>
			<persName><forename type="first">G</forename><surname>Winkler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Reaction-Diffusion Textures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Region Competition: Unifying Snakes, Region Growing, and Bayes/MDL for Multi-Band Image Segmentation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="884" to="900" />
			<date type="published" when="1996-09">Sept. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Mumford</surname></persName>
		</author>
		<title level="m">Filters, Random Fields, and Minimax Entropy (FRAME): Towards a Unified Theory for Texture Modeling</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
	<note>Proc. CVPR</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Minimax Entropy Principle and Its Application to Texture Modeling</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="1997-11">Nov. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Learning Generic Prior Models for Visual Computation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Mumford</surname></persName>
		</author>
		<idno>TR-96-05</idno>
		<imprint>
			<biblScope unit="volume">97</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>Harvard Robotics Lab</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
