<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Shallow-Depth 3D Interaction: Design and Evaluation of One-, Two-and Three-Touch Techniques</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mark</forename><surname>Hancock</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Calgary Calgary</orgName>
								<address>
									<region>AB</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sheelagh</forename><surname>Carpendale</surname></persName>
							<email>sheelagh@cs.ucalgary.ca</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Calgary Calgary</orgName>
								<address>
									<region>AB</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Cockburn</surname></persName>
							<email>andrew.cockburn@canterbury.ac.nz</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Canterbury Christchurch</orgName>
								<address>
									<region>NZ</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Shallow-Depth 3D Interaction: Design and Evaluation of One-, Two-and Three-Touch Techniques</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CEEC1538E58B27635628F7A95172F827</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Shallow-depth 3D</term>
					<term>tabletop display</term>
					<term>direct-touch</term>
					<term>rotation and translation H5.2 [Information interfaces and presentation]: User Interfaces -Interaction styles</term>
					<term>Input devices and strategies</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>On traditional tables, people frequently use the third dimension to pile, sort and store objects. However, while effective and informative for organization, this use of the third dimension does not usually extend far above the table. To enrich interaction with digital tables, we present the concept of shallow-depth 3D -3D interaction with limited depth. Within this shallow-depth 3D environment several common interaction methods need to be reconsidered. Starting from any of one, two and three touch points, we present interaction techniques that provide control of all types of 3D rotation coupled with translation (6DOF) on a direct-touch tabletop display. The different techniques exemplify a wide range of interaction possibilities: from the one-touch technique, which is designed to be simple and natural, but inherits a degree of imprecision from its simplicity; through to three-touch interaction, which allows precise bimanual simultaneous control of multiple degrees of freedom, but at the cost of simplicity. To understand how these techniques support interaction in shallow-depth 3D, we present a user study that examines the efficiency of, and preferences for, the techniques developed. Results show that users are fastest and most accurate when using the three-touch technique and that their preferences were also strongly in favour of the expressive power available from three-touch.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>In this paper, we consider the concept of shallow-depth 3D -full 3D visuals with full 3D interaction, but extremely limited depth -as a potential interaction space. This work is motivated by the new generation of hardware and software that more closely emulates physical workspaces. Tabletop displays, for example, have the potential to bring the advantages of electronic media to the type of interactions that occur over traditional desktops, and software environments like 'BumpTop' <ref type="bibr" target="#b0">[1]</ref> greatly enhance the reality of interaction through physics modelling. But these environments, and others like them, are limited in that they typically allow only a single point of cursor or pen-based contact for manipulating objects from a single perspective through a single interaction plane. Compared to the rich means available for controlling physical objects, this single point can be limiting.</p><p>Several hardware technologies allow multiple concurrent points of contact <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5]</ref> and researchers have used them to create direct manipulation techniques that naturally emulate 2D rotation, translation, and scaling <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b12">13]</ref>. 3D manipulations, however, have not yet been fully explored.</p><p>We focus on shallow-depth interaction in the z-plane for two reasons: first, interactions on physical desktops take place within a shallow-depth field (e.g. riffling, sorting and manipulating piles, and rotating or flipping objects on the surface); second, current desktop graphical user interfaces are similarly limited to a shallow-depth field. We argue in this paper that providing users with shallow-depth 3D capabilities allows for a more engaging and rich experience.</p><p>To empirically explore shallow-depth 3D as an interaction space, we consider the task of moving and rotating a small 3D object (e.g. a cube) across a tabletop (see Figure <ref type="figure" target="#fig_0">1</ref>). We first present design guidelines for direct-touch 3D interaction. Next we discuss alternative candidate interaction techniques for supporting these manipulations using one, two and three points of contact, formally demonstrating how two-dimensional surface interactions can be used to directly manipulate shallow-depth 3D objects. We then describe a usability study that compares the speed and accuracy of the techniques as well as the users' subjective perceptions of them. In closing we discuss the implications and suggest two alternative techniques based on the results of this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RELATED WORK</head><p>Almost all windowing interfaces currently use shallow 3D effects to support interaction. The layering and shadowing effects both enhance the visual appeal of the interfaces and provide a natural metaphor for switching documents and workspaces into and out of focus. Some commercial interfaces further extend the 3D effects, using animations to clarify feedback effects such as distorting windows and icons to show the relationship between pre-and post-action states (Mac OS R X). Researchers are also investigating problems and solutions that arise from moving between layers on the desktop. Dragicevic <ref type="bibr" target="#b2">[3]</ref>, for example, describes 3D visuals of dog-ears, folding and shuffling to make working with overlapping windows more intuitive. Agarawala and Balakrishnan's <ref type="bibr" target="#b0">[1]</ref> 'BumpTop' wholeheartedly adopts the emulation of reality on the desktop, using both rich 3D visuals and physics modelling to enrich interaction-objects can be piled on top of one another or flipped onto their backs; objects can be thrown at others, and the visual effects of collisions depends on their mass and velocity. The reality of the lustrous environment, however, is hindered by its constraint to a single point of interaction through a stylus input device. For comparison with the reality it attempts to emulate, though, consider the awkwardness of manipulating objects on your physical desk using only one index finger.</p><p>For collaborative tabletop displays, a variety of 3D effects have been proposed. Ståhl and Lundberg's <ref type="bibr" target="#b13">[14]</ref> tabletop 3D virtual pond floats items in use to the surface and allows items to sink when they are no longer in active use. The Lumisight table <ref type="bibr" target="#b9">[10]</ref> and Nakashima et al.'s 3D table <ref type="bibr" target="#b10">[11]</ref> provide up to four users with a coherent view of a 3D image in the centre of the display. While these systems are capable of rich 3D visuals in a collaborative setting, they do not fully address the interaction with these 3D models. Furthermore, these systems require a very large tabletop to achieve a small central 3D display.</p><p>In the study of high degree-of-freedom (DOF) input devices, there has been a general consensus about the separability of rotation and translation. It is widely believed that input is superior if these are kept separate. Frölich et al. <ref type="bibr" target="#b3">[4]</ref> provide a good discussion of this phenomenon. They both argue and demonstrate empirically that the separation into "forceless isotonic rotational input" and "force-requiring elastic translational input" is key to a good design of a 6DOF input device. However, other researchers suggest that rotation and translation are not separable in the human mind <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b14">15]</ref>. Studies of 2D interaction techniques for 2D tabletop interfaces, such as RNT <ref type="bibr" target="#b8">[9]</ref>, which require only 3DOF, tend to confirm that users typically ignore this difference and that integration of rotation and translation is essential for the support of communication in a collaborative setting <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b5">6]</ref>. Although these two claims appear contradictory, we argue that rotation and translation can be separated, but performed simultaneously and that this provides a natural interface for communication without sacrificing performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3D TABLETOP INTERACTION DESIGN GUIDELINES</head><p>Our eventual goal is to enable the existing freedom of object manipulation available on physical tables within digital desktops. In this endeavour, we attempt to combine the benefits of both 3D interaction and digital tabletops. In order to be successful, we need to take care in the design of new techniques to support interaction. We suggest the following design guidelines for interaction on tabletop displays in 3D:</p><p>• Provide More Degrees of Freedom: Interactions including flipping of objects, storage and communication through small adjustments of objects become possible by allowing full rotation and translation in three dimensions.</p><p>-Simultaneity of Rotation and Translation: In the real world, people are capable of simultaneously activating a combination of muscles to perform a single action that both moves and rotates an object. Similarly, a 3D tabletop interface should allow users to simultaneously rotate and translate an object.</p><p>-Independence of Rotation and Translation: Along the same lines, users should be able to activate rotation and translation using distinct actions, in the same way that different muscle groups are used to perform these actions in reality. Thus, users could combine these actions at the cognitive level instead of combining them in a potentially awkward way through the interaction technique itself.</p><p>• Provide Connected Manipulation: Connected manipulation is direct manipulation in which the user maintains a constant visual and physical connection with the object throughout the entire interaction. We distinguish this from direct input -when input space and display space are superimposed -by specifically requiring that the object being manipulated, not just the display space, remain in physical contact with the input mechanism. This guideline is also important when manipulating 2D objects on a digital table <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8]</ref>, but we emphasize its importance in 3D here, as it may be more tempting to ignore this constraint when more DOF are required.</p><p>• Prevent Cognitive Disconnect: By allowing users to interact directly with 3D objects, one should avoid actions that (though possible with technology) do not conform to what users expect. For example, since it is impossible to push one's finger through the display, limiting the depth of interaction maintains that expectation and prevents disconnect. Furthermore, traditional tabletops offer interaction on the surface of the table and the space between the top of the table and the user; however, most interaction takes place in the first few inches. Limiting interaction to a small finite z depth places a virtual surface just below the actual display, providing a similar few inches for 3D interaction.</p><p>• Provide Appropriate 3D Visual Feedback: 3D visual cues can make interactions more familiar, since they relate closely to the physical world.</p><p>-Provide Appropriate Shading: Tabletops afford interaction from all sides of the table. This can pose problems in recognizing concavity and convexity because in the absence of other cues, lighting will be assumed to originate from over one's shoulder <ref type="bibr" target="#b15">[16]</ref>, causing a button to appear depressed from one side of the table but not the other. Use of full 3D projections with additional depth cues such as shape and cast shadows can reduce this effect. -Consider Parallax: As the z depth increases a single perspective projection can appear different to users at different locations. Even for a single user, parallax can occur from left to right, simply due to the size of the display and the proximity of the user.</p><p>• Support Many Identifiable Points of Contact for each user at the table: Current tabletop display hardware provides a mosaic of supporting technology. Some technologies allow for a large number of points of contact, without identifying information <ref type="bibr" target="#b4">[5]</ref>, and others provide identifiable input for a single point of contact for a small number of users <ref type="bibr" target="#b1">[2]</ref>. In order to fully support direct-touch 3D interaction for multiple users on tables, the hardware needs to support identification of not only where a finger is touching, but also which finger of which user is touching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DIRECT-TOUCH 3D INTERACTION TECHNIQUES</head><p>We have designed three new direct-touch interaction techniques for manipulating 3D objects on a tabletop display. These designs were in part informed by our suggested guidelines, but mostly have helped to generate them.</p><p>On the two-dimensional surface of the table, each point of contact provides two degrees of freedom of input. It is possible to create interaction techniques that vary from being essentially 2D input (one touch point and 2DOF), through being 2D+ input (two touch points and 4DOF), to being fully 3D input (three touch points and 6DOF). The shallow-depth 3D output we wish to provide has the following five degrees of freedom:</p><p>• x &amp; y -the position on the surface of the table</p><p>• yaw -object rotation about the z-axis (planar)</p><p>• roll -object rotation about the y-axis (side-to-side)</p><p>• pitch -object rotation about the x-axis (front-to-back)</p><p>Note that we also describe how z (movement into the table) could be manipulated in some cases, but this has (purposefully) not been implemented. Future designs could apply this z movement to other degrees of freedom (e.g. scaling).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>One-Touch Input</head><p>We can achieve 5DOF movement with a single point (2DOF input) by extending the RNT algorithm <ref type="bibr" target="#b8">[9]</ref> into the third dimension. Instead of an explicit rotation about the axes (yaw, pitch and roll), the axis of rotation can be determined from the point of contact (see Figure <ref type="figure" target="#fig_1">2</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm</head><p>Let T = (x, y) and T = (x , y ) be the initial and final points of contact. Let T = (x, y, z), where z is the value in the z-buffer at (x, y) (i.e. the z-value of the point on the object "nearest" to the point T at the surface of the table ). Let T = (x , y , z) (using the same z-value as T ).</p><p>Let C = (x c , y c , z c ) be the initial centre of the object in the 3D scene.</p><formula xml:id="formula_0">∆x = x -x, ∆y = y -y a = -→ CT × --→ CT θ = ∠T CT</formula><p>where, a is the axis of rotation and θ is the angle of rotation about that axis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description</head><p>While the discrepancy in mapping between input degrees of freedom (2DOF) and output degrees of freedom (5DOF) is high, the actual action feels quite natural (see Figure <ref type="figure" target="#fig_0">1</ref>). Touching a point on the cube works like a sticky finger in that the contact point will rise toward the surface and the leading direction, causing the cube to rotate in x, y, and z until the contact point is as close to the surface and the lead direction as the shape of the cube will allow. Rotating the chosen side to the surface merely involves touching that side and dragging. This can require a re-touch for an initially occluded side.</p><p>Despite the fact that this technique provides the ability to rotate and translate a 3D object to any position and orientation, it is common for users to want to perform more constrained interaction, such as translation alone or planar rotation. We provide this ability through dedicated areas on the object. For polygonal objects, a circular area about the centre of each face is reserved for translations and a doughnut-shaped region around that circle is reserved for planar rotations (using the 2D RNT algorithm). For non-polygonal objects, a more abstract central location can be chosen on some surface of the object, about which the circle and doughnut shapes can be drawn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Two-Touch Input</head><p>Five or six degrees of freedom of output can be achieved using only two points of contact (4DOF input). The first point of contact can use the RNT algorithm <ref type="bibr" target="#b8">[9]</ref> to achieve both translation in x and y as well as yaw. The second point can be used to specify pitch and roll (see Figure <ref type="figure" target="#fig_2">3</ref>). If z motion is desirable, this can be manipulated according to the change in distance between the two points. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm</head><p>Let T i = (x i , y i ) and T i = (x i , y i ) be the initial and final points for the ith point of contact, where i ∈ {1, 2}. Let C = (x c , y c , z c ) be the initial centre of the object. Let C xy = (x c , y c ) (the projection of C in the 2D surface).</p><formula xml:id="formula_1">∆x = x 1 -x 1 , ∆y = y 1 -y 1 ∆z = | --→ T 1 T 2 | -| --→ T 1 T 2 | (if desired) ∆yaw = ∠T 1 C xy T 1 (about T 1 ) ∆roll = K 1 (x 2 -x 2 ), ∃K 1 ∈ R ∆pitch = K 2 (y 2 -y 2 ), ∃K 2 ∈ R</formula><p>In our user study, T 1 was provided through the index finger of the dominant hand and T 2 through the index finger of the non-dominant hand. However, the technique is not limited to this configuration; other sensible configurations include reversing these two fingers or using the index finger and thumb on the same hand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description</head><p>This technique provides easy causal movement coupled with rotation that maintains the vertical orientation of the object's projection. If the vertical orientation needs adjusting, for example if the right side of a cube is not at the surface, it can be adjusted with a finger on the non-dominant hand.</p><p>As with the one-touch technique, it is often desirable to perform constrained translation-only movement. This is again provided at the centre of each face of a polygon or an abstract central location on the surface of a non-polygonal object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Three-Touch Input</head><p>Our three-touch interaction technique maps 6DOF input to 5 or 6DOF output (see Figure <ref type="figure" target="#fig_3">4</ref>). In this mapping, the first point of contact is used for translation, the second point for yaw about the first point, and the third point for pitch and roll about the centre of the object. The depth can be specified by the difference in distance between the first and second touch points. The order of the points can be specified either by taking the points in order of contact with the table or in a predefined order (if the source of each point is identifiable). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm</head><p>Let T i = (x i , y i ) and T i = (x i , y i ) be the initial and final points for the ith point of contact, where i ∈ {1, 2, 3}.</p><formula xml:id="formula_2">∆x = x 1 -x 1 , ∆y = y 1 -y 1 ∆z = | --→ T 1 T 2 | -| --→ T 1 T 2 | (if desired) ∆yaw = ∠T 2 T 1 T 2 (about T 1 ) ∆roll = K 1 (x 3 -x 3 ), ∃K 1 ∈ R ∆pitch = K 2 (y 3 -y 3 ), ∃K 2 ∈ R</formula><p>In our user study, T 1 and T 2 were provided through the index finger and thumb of the dominant hand, respectively. T 3 was provided through the index finger of the non-dominant hand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description</head><p>In principle this interaction is quite simple. For example, a single touch with one's index finger supports translation only, including one's thumb adds rotation around the z-axis and the addition of a finger from one's other hand provides the other two rotations.</p><p>In theory, three-touch allows the most efficient means for control because users can concurrently and independently manipulate all six degrees of freedom. However, there is a risk that this freedom may be confusing for users. Furthermore, both the two-and three-touch techniques may disconnect the object from the initial touch location upon rotation in pitch or roll. This disconnect may further confuse the user, creating an advantage to the one-touch technique. Hence, empirical comparison of the techniques is necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>USER STUDY</head><p>To better understand how people interact with these three (one, two and three finger) connected manipulation rotation and translation techniques, we conducted a study that compares them in terms of their speed, accuracy and the subjective preferences of the participants. Since these techniques vary considerably in interaction styles, conducting an empirical comparison can shed light on which balance of design tradeoffs are the most effective and satisfying for people.</p><p>For example, one-touch interaction is likely to be slow, but users may appreciate its simplicity and reliability; threetouch interaction may be fast if the participants can adapt to its comparative power and complexity, but they may report a higher cognitive load if it fails to be perceived as 'natural'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Twelve students (6 male, 6 female) from a local university participated in the study. Both national and international students were selected from a variety of disciplines. Five participants reported no prior experience with 3D gaming and seven reported some. The experience of these seven varied from once a year to four times a month. Ages ranged from 21 to 33 (M = 26.3, SD = 3.8). All participants were righthanded and no participant reported any colourblindness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Apparatus</head><p>The experiment was performed on a front-projected 1024 × 768 pixel tabletop display using DiamondTouch <ref type="bibr" target="#b1">[2]</ref> input with an 87 cm × 66 cm display area (12 pixels / cm). Multifinger input was provided by attaching distinct Diamond-Touch sensors to both the index finger and thumb of a righthanded insulating glove. The third touch-point was provided with a regular DiamondTouch pad through the left hand. The display surface was 72 cm above the floor and participants were provided with an adjustable chair. An orthogonal 3D projection was used to render objects on the display. Objects were all full 3D objects but to provide the shallowdepth environment there was no movement in z. That is, objects could roll, tumble, and flip but the object's centre remained at a fixed z depth. Thus interaction was limited in all conditions to 5DOF. Software automatically logged the users actions and task times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure and Design</head><p>For each technique (one-, two-, and three-touch), participants performed three tasks in the same order. The order of techniques was counterbalanced between participants using a Latin square. Afterwards, each participant was asked to complete a questionnaire to provide both background and feedback about their experience. Participants were then interviewed by the experimenter.</p><p>The primary dependent measure in the two formally analysed tasks (tasks 1 and 2) was the task completion time. We additionally analysed data characterising how the users interacted with the techniques, including the time spent touching, translating and rotating the objects, and also the locations on the objects that the users touched. In order to determine a person's ability to use each technique for communication with other people, our first task required participants to pass a cube to one of three "virtual" people with a specific side of the cube facing upward and toward the virtual person (see Figure <ref type="figure" target="#fig_5">5</ref>). This task was modelled after the study done on the 2D RNT rotation technique <ref type="bibr" target="#b8">[9]</ref>. Each side of the cube had a distinct grayscale icon. At the start of each trial, the cube was in the same location immediately in front of the participant, with the "top" side (a happy face) uppermost. Virtual participants were located to participants left, right and opposite. To start each trial an icon appeared on the screen and one of the virtual participants was indicated in red. The participant then matched that trial icon with one on the cube and passed the cube to the indicated virtual participant with the correct icon facing upward. The task was repeated six times -once for each side of the cubefor each target destination, giving 54 trials per participant (6 sides × 3 destinations × 3 techniques). A different random order of trials within each technique was chosen for each participant. Participants performed six practice trials each time they began again with a new interaction technique.</p><p>Data from this task were analysed using a within-subjects analysis of variance for the following three factors:</p><p>• Technique: one-touch, two-touch, three-touch;</p><p>• Destination: left (40 cm), opposite (38 cm), right (40 cm);</p><p>• Target-side: top, bottom, left, right, back, front;</p><p>Task 2: Docking</p><p>To explore performance differences in the three techniques, we asked participants to complete a docking task. This task was a variation of the task developed by Zhai and Milgram <ref type="bibr" target="#b16">[17]</ref> and used more recently to compare GlobeFish and GlobeMouse to other 6DOF techniques <ref type="bibr" target="#b3">[4]</ref>.</p><p>In this task, participants were asked to dock a tetrahedron inside another of equal size (see Figure <ref type="figure" target="#fig_6">6</ref>). Spines around the vertices were used to indicate docking tolerance. The vertices and edges of the tetrahedra were coloured to aide the participants in determining object orientation and the edges were haloed to aide in depth perception. When a given vertex was moved within target range, the vertex would change colour. Once all four vertices were in place for 700 ms, the source tetrahedron would disappear and the participant could begin the next trial by pressing the start button. Each trial had a 40 second time limit, after which the trial was abandoned and the next trial automatically began. Trials were repeated for three levels of difficulty and for two levels of orientation. The levels of difficulty varied the size of tolerance bars at each vertex on the destination tetrahedron -easy trials had a 54 pixel tolerance, medium trials 38 pixels, and hard trials 23 pixels. The two levels of orientation allowed us to compare the techniques' support for planar rotations with more complex rotations -planar rotations used a 135 • rotation about the z-axis, and complex rotations used and a 135 • rotation about the x-y-z-axis.</p><p>Each participant performed five repetitions of each combination of difficulty and starting orientation for each interaction technique for a total of 90 trials. A different random order of trials within each technique was chosen for each participant. Participants performed six practice trials each time they began again with a new technique (each combination of difficulty and starting position was performed once).</p><p>Data from the docking task were analysed using a threefactor within-subjects analysis of variance on the factors:</p><p>• Technique: one-touch, two-touch, three-touch;</p><p>• Difficulty: easy, medium, hard.</p><p>• Rotation: planar, spatial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task 3: Puzzle</head><p>This task was used to examine how the participants' chose to use each of the techniques when completing a more realistic and less constrained task. Participants were asked to assem-  In both cases, three-touch interaction is fastest, followed by two-touch, and one-touch is slowest.</p><p>ble a tetrahedron-shaped puzzle composed of four smaller tetrahedron shapes and a centre piece (see Figure <ref type="figure" target="#fig_7">7</ref>). Participants performed this task once for each interaction technique. Although software logged the users' actions, data from this task was not formally analysed; our interest here was in observations of use, subjective preferences and comments about the techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task Completion Times</head><p>Data from the task completion times violated Mauchly's test of sphericity for the repeated measures analysis of variance. We therefore report results using the Greenhouse-Geisser correction (influencing df , F and p values).</p><p>Task completion times (TCT) in both the passing and docking tasks showed the same trend, with users successfully exploiting the more expressive capabilities of the two-and three-touch interaction techniques. These results are summarised in Figure <ref type="figure" target="#fig_8">8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Passing Task</head><p>There was a marginally significant main effect of technique (F 1,16 = 3.4, p = .07), with mean times reducing from 18.9 s (SD = 2.8) with one-touch, through 15.7 s (SD = 2.2) with two-touch, to 13.3 s (SD = 2.0) with threetouch; a 30% reduction in task time across the three conditions. Post-hoc pairwise comparisons only showed a significant difference between one-touch and three-touch techniques (p &lt; .01). Despite the comparative efficiency of the three-touch technique, it is worth noting that even its mean task times were high-few tasks involving passing real objects would take this long, regardless of the level of precision required. We return to this issue in the discussion.</p><p>There was no significant effect of destination (F 1,18 = 0.06, p = .91), nor were there significant interactions between it and the other two factors, suggesting that performance with the techniques is not substantially influenced by the direction of information sharing.</p><p>The target side, however, did have a significant effect on task performance (F 3,36 = 11.8, p &lt; .001). The mean time to attain the top-side target (10.6 s) was markedly lower than all others (bottom: 17.1 s; left: 17.2 s; right: 18.3 s; back: 17.3 s; and front: 15.5 s). This effect is explained by the lack of rotation necessary with the top side as the target. Such tasks, therefore, predominantly involved translation and planar rotation rather than the more complex spatial rotations required with the other sides. Post-hoc analysis showed pairwise differences (p &lt; .05) between the top side and all other sides, and between the right and front sides. This latter difference is likely due to the combination of the facts that forward motion can more easily combine the required translation and rotation (advantaging discovery of the front side) and that our participants were right-handed, causing occlusion and disadvantaging trials involving the right side.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Docking Task</head><p>The results for the docking task showed similar trends to those for the passing task, but with stronger significance. Mean performance of the docking task with the three techniques improved significantly (F 2,19 = 14.2, p &lt; .001) as the number of touches increased from one to three. Means for the one-, two-and three-touch techniques were 20.1 s, 17.0 s and 14.3 s respectively (see Figure <ref type="figure" target="#fig_8">8</ref>), showing a similar overall percentage improvement between one-and threetouch (29%) to that observed in the passing task. Post-hoc pairwise comparison showed significant differences between one-touch and both others (p &lt; .01), and a marginal difference between two-and three-touch (p = .06).</p><p>As anticipated, there was a significant effect of difficulty (F 2,20 = 39.6, p &lt; .001), with means rising from 15.0 s on easy tasks, through 16.9 s on medium ones, and 19.6 s on hard tasks (post-hoc pairwise significant for all pairs at p &lt; .01). Somewhat surprisingly, though, there was no technique × difficulty interaction (F 3,29 = 0.5, p = .77).</p><p>We had anticipated that one-touch may suffer more than the other techniques on high precision tasks because it does not allow independent manipulation of each degree of freedom, but the data did not support this hypothesis.</p><p>Complex rotations (M = 22.6 s) were significantly slower than planar ones (M = 11.7 s): F 1,11 = 66.7, p &lt; .001. But again, there was no evidence that any of the techniques was particularly good or bad for complex manipulations (technique × rotation interaction, F 2,20 = 1.2, p = .33).</p><p>Only tasks that were completed within the 40 s time limit were included in this analysis. To check that these results were not adversely influenced by different rates of incomplete trials in different conditions, we analysed the number of incomplete trials using the same 3×3×3 ANOVA. This analysis further supports the results above. Timed-out tasks were significantly more prevalent when using fewer points of contact (F 1,16 = 7.3, p = .01), with means of 1.3, 0.6 and 0.2 timeouts per condition with one-, two-and three-touch respectively. There were significant effects for difficulty (F 1,14 = 9.4, p &lt; .01) and rotation (F 1,11 = 14.8, p &lt; .01); but there was additionally a significant technique × rotation interaction (F 1,16 = 7.9, p &lt; .01), due to a much more dramatic increase in timed-out tasks between planar and complex tasks with one-touch than with two-and three-touch (Figure <ref type="figure" target="#fig_9">9</ref>). As before, the technique × difficulty interaction was not significant (F 3,31 = 0.8, p = .15).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Characterising Interaction with the Techniques</head><p>The analysis above shows that the participants completed tasks more quickly when given more points of contact for interaction, and that the benefits of doing so become larger in more complex tasks. In order to better understand the strengths and weaknesses of each of the techniques for particular types of object manipulations, we now further scrutinise data on the time spent conducting particular types of manipulations, and the object regions used to do so.</p><p>To conduct this analysis we broke down the TCTs into time spent performing translation, planar rotation and spatial rotation. For the one-touch technique, this can be separated by time spent touching each dedicated area on the objects. For the two-touch technique, it is done by separating time spent inside and outside the translation-only area, and by measuring time spent using the second finger. For the three-touch technique, it is separated into time spent touching with each finger. Note that the sum of all movement types can be more than the TCT for the two-and three-touch techniques, since the user can perform multiple movements at the same time.</p><p>We analysed the decomposed TCTs using a 3 × 3 withinsubjects ANOVA for factors technique (one-, two-, three-touch) and movement type (translation, planar rotation, and spatial rotation).</p><p>There was a main effect of technique (F 2,18 = 8.5, p &lt; .01).</p><p>Figure <ref type="figure" target="#fig_10">10</ref> shows mean time spent for each technique. Posthoc comparisons show that participants touched the screen significantly less with the one-touch technique than with the three-touch technique (p &lt; .001) and marginally less than with the two-touch technique (p = .06). The difference between the two-touch and three-touch techniques was not significant (p = .12). This effect is in direct contrast to the main effect of technique for TCTs alone. This contrast suggests that participants spent more time performing cognitive processing than interaction with less DOF and that this resulted in higher TCTs. Experimenter observations also confirmed that participants tended to have more difficulty with mental rotations when using the one-touch technique. Note, however that the measures fail to discriminate between manipulations that occur in parallel and in series, so this result should be cautiously appraised.</p><p>There was a significant interaction between technique and movement type (   The results for the docking task are sufficiently similar to not warrant reiteration here. However, the fact that both tasks have the same main effect, interaction and pairwise differences further strengthens this result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Touches</head><p>We observed during the experiment that participants tended to use object corners for spatial rotations much more with some techniques. We recorded the locations of every touch intended for spatial rotation made by each participant and rendered each point using a constant transparency. Patterns clearly show that for the one-touch technique, users concentrated their touches at the corners and for the two-and three-touch techniques, the touch locations were more central. Figure <ref type="figure" target="#fig_13">12</ref> shows a typical face of both the cube from the passing task and the tetrahedron from the docking task for each technique. We also recorded the number of times the participants missed the objects completely and found that this occurred most frequently with the one-touch technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subjective Ratings</head><p>Figure <ref type="figure" target="#fig_14">13</ref> shows the average scores on the follow-up questionnaire. For the docking task, 9 participants preferred the three-touch technique and 3 preferred the two-touch technique. For the passing task, 7 participants preferred the three-touch technique, four preferred the two-touch, and 1 preferred the one-touch technique. Overall, 7 participants preferred the three-touch, 3 preferred the two-touch, and 1 claimed there was no clear winner.</p><p>All subjective data shows a clear order of preference from three-touch (best), two-touch, to one-touch (worst). Participants consistently rated the three-touch technique as the easiest to use (Q1) with the most appropriate reaction (Q3), as the least difficult to control (Q2) and rotate -both in the plane (Q4) and spatially (Q5). Also, the three-touch technique was most preferred for docking, passing and overall. The two-touch technique was rated second in all categories and the one-touch third, though with much higher variance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overall Discussion</head><p>Our study showed that the techniques that use a higher number of touches were better both in terms of performance and user preference. These benefits likely appeared because the higher number of touches provided users with the opportunity to independently control more degrees of freedom. This type of freedom provides increased flexibility for how users decide to perform the interactions.</p><p>Our study showed that one-touch interaction was rated as difficult to use and resulted in the worst performance. This result implies that one-touch interaction (as designed here) was not efficient for interacting in shallow-depth 3D on the table. One response would be to redesign the one-touch interaction technique (one alternative is discussed below). Perhaps a more important consequence is that most existing hardware input technology is currently insufficient for supporting multi-touch interaction. Our results suggest that multiple independent inputs for each person at the table will be beneficial for both performance and satisfaction.</p><p>One concern we had when initially developing the techniques was that the complexity of multi-touch interactions would prove confusing and deter users from its acceptance. In contrast, allowing users separate and simultaneous control of rotation and translation provided a more preferred interaction with better performance. From watching people use these techniques, one could see that their interactions became more natural and easy as the number of touch points increased. Users are not only capable of this more engaged, complex control, but prefer it.</p><p>Generally, participants in our study were both intrigued and excited by all three techniques. This enthusiasm is likely due to the novel ability to use digital objects in a way that was more similar to their experiences with physical objects on tables. Users commented that with these techniques it felt "more like I was touching it" and that "I almost want to look" under the objects. However considering the actual TCTs in comparison with what people are capable of with physical objects, there is considerable scope for future research refining these and other new techniques for manipulating shallow-depth 3D objects. Nonetheless, these techniques do provide the first steps toward enabling the more complex 3D interactions with which we are familiar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ALTERNATIVE TECHNIQUES</head><p>In light of the results of our study, we have explored alternative designs for our interaction techniques. Specifically, we believe that a redesign of the one-touch technique might make for a feasible method for interacting on tables incapable of multi-user, multi-touch, direct-touch interaction. Furthermore, our multi-touch techniques typically assign object transformations based on the movement of every finger. Another way of implementing bimanual, multi-touch rotation would be to use the additional touches to introduce constraints that limit chosen aspects of the interaction. Such interactions have been shown to be an approach that users can easily cope with, due to the kinesthetic feedback <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alternative One-Touch Technique</head><p>The results of our experiment showed that, while spatial rotation interactions were accessible from both edges and corners, people typically made almost exclusive use of the corners. We also found that users had difficulty acquiring the corners and would frequently miss the object entirely. In our new design, the 3D rotation previously available on the entire surface of the object is only allowed at the corners and the user may acquire the corner by selecting anywhere inside a sphere about each vertex of the polygon. The object still has a translate-only region in the centre of each face, but the remaining parts of the object allow only planar RNT interaction. This new technique still benefits from the property that the selected point remains under the user's finger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alternative Multi-Touch Technique</head><p>One of the disadvantages of both multi-touch techniques used in our study is that the point of contact may not remain under the user's finger once a rotation is performed with the finger on the non-dominant hand. We propose an alternative three-touch technique that constrains the effect of the primary finger based on the presence or absence of contact of the thumb and/or the finger on the non-dominant hand. When the user manipulates the object with their primary finger and no other finger is touching, the object reacts as it would in the one-touch technique. When the user uses both the thumb and the index finger, planar rotation is performed as in the three-touch technique. The user can then limit the movement to translation-only by touching the table with a finger on the non-dominant hand. This technique also has the advantage that the point of contact remains under the user's finger. It also corresponds to the way physical objects react, in that additional points of contact allow for more precise, constrained motion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION &amp; FUTURE WORK</head><p>In this paper, we have introduced and studied three new rotation and translation techniques for interacting in shallow-depth 3D on a digital table. In light of insights gained through our study we suggest two additional approaches to providing this type of interaction. These techniques are the first steps toward realizing our vision of shallow-depth 3D interactions in the digital realm which are much more closely aligned to those we are familiar with on traditional tables.</p><p>We provide guidelines for the design of direct-touch interaction in 3D and a user study that reinforces these guidelines.</p><p>Our study also shows that the greater expressive power of more touch points can improve performance and user satisfaction for direct-touch manipulation of 3D objects on a digital table. In detail:</p><p>• Shallow-depth was easily understood and interpreted as a natural environment.</p><p>• People are generally enthusastic about manipulating 3D objects on digital tables.</p><p>• A higher number of touches allows more natural and flexible interaction.</p><p>• One-touch interaction should be re-explored,</p><p>• Multiple points of identifiable touches should be supported in hardware</p><p>• People are not only capable of separable simultaneous control of rotation and translation, but prefer it.</p><p>While continuing to explore further refinements of our techniques, we also intend to empirically explore what type of feedback is appropriate in a shallow-depth 3D interface. We are specifically interested in addressing issues of shading and parallax that are most closely associated with the use of 3D in a collaborative setting. Our vision is an interface where multiple users can interact simultaneously from any side of the table combined with the rich expressive interactions available in 3D.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. A sequence of motion using one-touch interaction in shallow-depth 3D. The black dot represents the point of contact of the user's finger.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. One-touch interaction in shallow-depth 3D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Using the two-touch interaction, users can perform 2D rotations and translations with the index finger of the dominant hand using the RNT algorithm while simultaneously performing pitch and roll rotations (shown above) with a second finger on the non-dominant hand.</figDesc><graphic coords="4,53.80,53.80,239.10,140.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Using three-touch interaction, users can perform a simultaneous translation and rotation on the surface of the table, as shown here. The user can also simultaneously rotate the object in pitch and roll with a finger on the non-dominant hand.</figDesc><graphic coords="4,328.77,53.80,215.19,135.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. In the passing task, participants were asked to pass a cube to a target person with the target side facing up and toward the "virtual" user. The start position of the cube was close to the centre of the table.</figDesc><graphic coords="5,341.44,54.51,189.86,146.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. In the docking task, users were asked to dock a tetrahedron object (right) in another tetrahedron (left).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. The puzzle task.</figDesc><graphic coords="6,78.39,563.79,189.92,129.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Mean TCTs for both the passing task and the docking task.In both cases, three-touch interaction is fastest, followed by two-touch, and one-touch is slowest.</figDesc><graphic coords="6,334.75,53.80,203.23,134.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. There was a significant interaction between technique and required rotation for the number of incomplete trials. For one-touch interaction, the difference between planar-only trials and trials requiring spatial rotation was larger than for two-and three-touch interaction.</figDesc><graphic coords="7,77.72,53.80,191.27,138.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. Mean time spent touching the object, separated into translations, planar rotations and spatial rotations.</figDesc><graphic coords="7,340.72,53.80,191.28,126.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>F 2,23 = 18.7, p &lt; .001) shown in Figure 11.Post-hoc comparisons show that for one-touch interaction, participants spent significantly more time performing spatial rotations than either translations (p &lt; .001) or planar rotations (p &lt; .001) and that for three-touch interaction, participants spent significantly more time performing translations than either planar rotations (p &lt; .001) or spatial rotations (p &lt; .01). All other pairwise differences were not significant (p &gt; .05). This interaction shows that participants typically spent an approximately equal amount of time performing rotations with all three techniques. Furthermore, the larger amount of translations in the three-touch condition may be because participants were able perform translations in tandem with the other types of rotation. This result illustrates very well that simultaneity of movements provides a strong advantage for multiple DOF interaction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. There was a significant interaction between technique and movement type. For the one-touch technique, participants performed more spatial rotations than translations or planar rotations and for the three-touch technique, participants spent more time performing translations than planar or spatial rotations. The difference in movement type did not differ significantly for the two-touch technique.</figDesc><graphic coords="8,65.76,477.60,215.18,158.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 12 .</head><label>12</label><figDesc>Figure 12. Touch locations on a typical face of the cubes in the passing task (top) and tetrahedrons in the docking task (bottom) separated into one-touch (left), two-touch (middle), and three-touch techniques (right). The coloured arcs represent the mean distances to the nearest corner for each touch location, black arcs represent the standard deviation from these means.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 13 .</head><label>13</label><figDesc>Figure 13. Mean ratings and (standard deviations) on the follow-up questionnaire. Users rated their level of agreement on a scale from 1 (strongly disagree) to 7 (strongly agree).</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We would like to thank Natural Science and Engineering Research Council of Canada, Alberta's Informatics Circle of Research Excellence, Alberta Ingenuity, and the Canadian Foundation of Innovation for research support. We also thank Edward Tse for help with glove building, Petra Neumann for her many insights, and both the reviewers and iLab members for their helpful comments on this work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Keepin&apos; it real: Pushing the desktop metaphor with physics, piles and the pen</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agarawala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1283" to="1292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">DiamondTouch: a multi-user touch technology</title>
		<author>
			<persName><forename type="first">P</forename><surname>Deitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Leigh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST</title>
		<meeting>UIST</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="page" from="219" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Combining crossing-based and paper-based interaction paradigms for dragging and dropping between overlapping windows</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST</title>
		<meeting>UIST</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="193" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The GlobeFish and the GlobeMouse: Two new six degree of freedom input devices for graphics applications</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fröhlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hochstrate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Skuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Huckauf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="191" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Low-cost multi-touch sensing through frustrated total internal reflection</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST</title>
		<meeting>UIST<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="115" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Rotation and translation mechanisms for tabletop interaction</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vernier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wigdor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Tabletop</title>
		<meeting>Tabletop</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J K</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Sibert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Mcfarlane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Preston</forename><surname>Mullen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Integrality and separability of input devices. TOCHI</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="26" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Roles of orientation in tabletop collaboration: Comprehension, coordination and communication</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kruger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JCSCW</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="501" to="537" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fluid integration of rotation and translation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kruger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Lumisight table: a face-to-face collaboration support system that optimizes direction of projected information to each stakeholder</title>
		<author>
			<persName><forename type="first">M</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ohguro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shirai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kakehi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Naemura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CSCW</title>
		<meeting>CSCW</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="274" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A 2D-3D integrated environment for cooperative work</title>
		<author>
			<persName><forename type="first">K</forename><surname>Nakashima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Machida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kiyokawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Takemura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VRST</title>
		<meeting>VRST</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="16" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The prevention of mode errors through sensory feedback</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Sellen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Kurtenbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Buxton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">HCI</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="141" to="164" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Diamondspin: an extensible toolkit for around-the-table interaction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D</forename><surname>Vernier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Forlines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ringel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="167" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Information exploration using the pond</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ståhl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wallberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Söderberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Humble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Fahlén</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bullock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lundberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVE</title>
		<meeting>CVE</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="72" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The structure of object transportation and orientation in human-computer interaction</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Mackenzie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Summers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Booth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="312" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Information Visualization: Perception for Design</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ware</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Quantifying coordination in multiple DOF movement and its application to evaluating 6 DOF input devices</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milgram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="320" to="327" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
