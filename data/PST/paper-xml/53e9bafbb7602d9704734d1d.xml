<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Branch History Matching: Branch Predictor Warmup for Sampled Simulation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Simon</forename><surname>Kluyskens</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ELIS Department</orgName>
								<orgName type="institution">Ghent University Sint</orgName>
								<address>
									<addrLine>Pietersnieuwstraat 41</addrLine>
									<postCode>B-9000</postCode>
									<settlement>Gent</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Lieven</forename><surname>Eeckhout</surname></persName>
							<email>leeckhou@elis.ugent.be</email>
							<affiliation key="aff0">
								<orgName type="department">ELIS Department</orgName>
								<orgName type="institution">Ghent University Sint</orgName>
								<address>
									<addrLine>Pietersnieuwstraat 41</addrLine>
									<postCode>B-9000</postCode>
									<settlement>Gent</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Branch History Matching: Branch Predictor Warmup for Sampled Simulation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Computer architects and designers rely heavily on simulation. The downside of simulation is that it is very time-consuming -simulating an industry-standard benchmark on today's fastest machines and simulators takes several weeks. A practical solution to the simulation problem is sampling. Sampled simulation selects a number of sampling units out of a complete program execution and only simulates those sampling units in detail. An important problem with sampling however is the microarchitecture state at the beginning of each sampling unit. Large hardware structures such as caches and branch predictors suffer most from unknown hardware state. Although a great body of work exists on cache state warmup, very little work has been done on branch predictor warmup.</p><p>This paper proposes Branch History Matching (BHM) for accurate branch predictor warmup during sampled simulation. The idea is to build a distribution for each sampling unit of how far one needs to go in the pre-sampling unit in order to find the same static branch with a similar global and local history as the branch instance appearing in the sampling unit. Those distributions are then used to determine where to start the warmup phase for each sampling unit for a given total warmup length budget. Using SPEC CPU2000 integer benchmarks, we show that BHM is substantially more efficient than fixed-length warmup in terms of warmup length for the same accuracy. Or reverse, BHM is substantially more accurate than fixed-length warmup for the same warmup budget.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Architectural simulations are extensively used by computer architects and designers for evaluating various design tradeoffs. Unfortunately, architectural simulation is very timeconsuming. Even on today's fastest machines and simulators, simulating an industrystandard benchmark easily takes several weeks to run to completion. As such, simulating entire benchmark executions is infeasible for exploring huge microarchitecture design spaces. Therefore, researchers have proposed sampled simulation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4]</ref>. Sampled simulation takes a number of so called sampling units that are simulated in detail. Statistics or appropriate weighting is then applied to the simulation results of the various sampling units for predicting the performance of the overall benchmark execution.</p><p>An important issue with sampled simulation is the microarchitecture state at the beginning of each sampling unit, i.e., the microarchitecture state at the beginning of a sampling unit is unknown during sampled simulation. This is well known in the literature as the cold-start problem. A solution to the cold-start problem is to warmup various microarchitecture structures prior to each sampling unit. A large amount of work has been done on cache structure warmup. However, the amount of work done on branch predictor warmup is very limited.</p><p>This paper proposes Branch History Matching (BHM) as a novel branch predictor warmup method. The basic idea is to inspect the pre-sampling unit, i.e., the instructions in the dynamic instruction stream prior to the sampling unit, for branch instances of the same static branch with similar global and local histories as the branch instances in the sampling unit. A BHM distribution is then built for all sampling units that quantifies the locality in the branch execution stream taking into account both the global and local histories of the branches. As a final step, the appropriate warmup length is then determined for each sampling unit taking into account the BHM distributions as well as the total warmup budget. In other words, the total warmup budget is distributed across the various sampling units according to the BHM distribution. Sampling units that show good locality are given a small warmup length; sampling units that show poor locality are given a larger warmup length.</p><p>BHM is microarchitecture-independent, i.e., the warmup lengths are computed once and are then reused across branch predictors during design space exploration. An appealing way of using BHM in practice for sampled processor simulation is to use (i) checkpointed sampling <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref> maintaining reduced checkpoints of architecture state (registers and memory) along with (ii) checkpointed cache warmup <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref> and (iii) compressed branch traces <ref type="bibr" target="#b9">[10]</ref> that are reduced through BHM. In other words, instead of having branch traces of full benchmark executions as proposed in <ref type="bibr" target="#b9">[10]</ref>, BHM limits the length of the compressed branch traces. This would result in a reduction in required disk space as well as a reduction in overall simulation time while pertaining the advantage of compressed branch traces of being branch predictor independent.</p><p>This paper makes the following contributions:</p><p>-First, we show that branch predictor warmup is an issue when it comes to guaranteeing an accurate hardware state at the beginning of a sampling unit. We show that for small sampling unit sizes, branch predictor warmup is required in order to achieve an accurate estimate of the hardware state at the beginning of the sampling unit. We provide results showing that even for (fairly large) 1M instruction sampling units branch predictor warmup is required. -Second, we propose Branch History Matching (BHM) as a novel branch predictor warmup approach. Using the SPEC CPU2000 integer benchmarks and 10Kinstruction sampling units, we show that BHM is 39% more accurate than fixedlength warmup for the same warmup length. Or reverse, BHM achieves the same accuracy as fixed-length warmup with a 1.6X shorter warmup length. Compared to MRRL, BHM is 87% more accurate.</p><p>This paper is organized as follows. We first revisit sampled simulation and cover the main issues related to sampled simulation. We then present BHM as a branch predictor warmup method. We subsequently evaluate BHM and compare it against fixed-length warmup and MRRL. And finally, we conclude.</p><p>In sampled simulation, a number of sampling units are chosen from a complete benchmark execution. Those sampling units are then simulated in detail; the pre-sampling units, i.e., the instructions prior to a given sampling unit, are skipped. The performance of the complete benchmark is then estimated by simply aggregating or weighting the performance numbers from the various sampling units.</p><p>There are basically three issues with sampled simulation. First, the sampling units need to be chosen in such a way that the sampling units are representative for the entire program execution. Various authors have proposed various approaches for achieving this, such as random sampling <ref type="bibr" target="#b0">[1]</ref>, periodic sampling as done in SMARTS <ref type="bibr" target="#b2">[3]</ref> and targeted sampling based on program phase behavior as done in SimPoint <ref type="bibr" target="#b1">[2]</ref>.</p><p>The second issue is how to get to those sampling units. In other words, the architecture state (register and memory state) needs to be reconstructed so that all sampling units can be functionally simulated in a correct way. This can be achieved through fastforwarding or (reduced) checkpointing <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b8">9]</ref>. Checkpointing is especially beneficial for the parallel simulation of sampling units <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>.</p><p>The third issue with sampled simulation is to estimate the microarchitecture state at the beginning of each sampling units. The microarchitecture structures that suffer the most from the cold-start problem are cache structures and branch predictors. We will discuss warmup approaches tailored towards these types of hardware structures in the following two subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Cache warmup</head><p>Given the fact that caches have the largest state in a microprocessor, they are likely to suffer the most from inaccurate microarchitecture warmup. In fact, most of the prior research on the cold-start problem has been done on cache warmup. Various approaches have been proposed such as no warmup, stale state (also called stitch) <ref type="bibr" target="#b12">[13]</ref>, fixed warmup <ref type="bibr" target="#b0">[1]</ref>, cache miss rate estimators <ref type="bibr" target="#b13">[14]</ref>, no-state-loss <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b14">15]</ref>, minimal subset evaluation (MSE) <ref type="bibr" target="#b15">[16]</ref>, memory reference reuse latency (MRRL) <ref type="bibr" target="#b16">[17]</ref>, boundary line reuse latency (BLRL) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18]</ref>, self-monitored adaptive cache warmup (SMA) <ref type="bibr" target="#b18">[19]</ref>, memory hierarchy state (MHS) <ref type="bibr" target="#b4">[5]</ref>, memory timestamp record (MRT) <ref type="bibr" target="#b6">[7]</ref>, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Branch predictor warmup</head><p>Compared to the amount of work done on cache warmup, very little work has been done on branch predictor warmup.</p><p>The first paper dealing with branch predictor warmup was by Conte et al. <ref type="bibr" target="#b0">[1]</ref>. They proposed two approaches to branch predictor warmup, namely stale state and fixedlength warmup. Stale state (or stitch) means that the branch predictor state at the end of the previous sampling unit serves as an approximation for the branch predictor state at the beginning of the current sampling unit. An important disadvantage of stale state is that it serializes the simulation of the various sampling units, i.e., it is impossible to simulate the current sampling unit without having finalized the simulation of the previous sampling unit. Fixed-length warmup is a simple-to-implement method that achieves good accuracy if sufficiently long warmup lengths are chosen.</p><p>The second paper mentioning branch predictor warmup is by Haskins and Conte <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20]</ref> in which they propose memory reference reuse latency (MRRL). The idea of MRRL is to look in the pre-sampling unit how far one needs to go in order to encounter the same static branch as the one in the sampling unit. MRRL computes the reuse latency, i.e., the number of instructions between the branch instance in the pre-sampling unit and the one in the sampling unit, for all branch instances in the pre-sampling unit and sampling unit. For a given target cumulative probability, for example 99.5%, it is then determined where warmup should start in the pre-sampling unit. During this warmup period, the branch predictor is warmed up but no misprediction rates are computed.</p><p>A number of papers have proposed checkpointed sampling techniques <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9]</ref> in which the architecture state is stored on disk, as mentioned above. These techniques typically use checkpointed microarchitecture warming for warming cache state, such as memory timestamp record <ref type="bibr" target="#b6">[7]</ref>, live-points <ref type="bibr" target="#b8">[9]</ref> and memory hierarchy state (MHS) <ref type="bibr" target="#b4">[5]</ref>. They suggest to store the branch predictor state as part of the microarchitecture state for the various branch predictors one may be interested in during design space exploration. This can be space-inefficient in case multiple branch predictors need to be stored, and in addition, it prevents from simulating a branch predictor that is not contained in the microarchitecture warmup.</p><p>For addressing this problem, Barr and Asanovic <ref type="bibr" target="#b9">[10]</ref> propose to employ branch trace compression. They store a compressed branch trace on disk and upon branch predictor warming they simply decompress the compressed branch trace and use the decompressed trace for branch predictor warming. This approach is branch predictor independent and can be used to warm any branch predictor during sampled simulation. The branch trace compression scheme by Barr and Asanovic <ref type="bibr" target="#b9">[10]</ref> however does not address the issue of how far one needs to go back in the pre-sampling unit. They assume that the entire branch trace from the beginning of the benchmark execution up to the current sampling unit needs to be compressed and decompressed. This can be time-consuming in practice, especially for sampling units deep down the benchmark execution. BHM as proposed in this paper can be used to cut down the branch traces that need to be compressed. This saves both disk space and simulation time, while keeping the benefit of the warmup approach to be branch predictor independent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The need for branch predictor warmup</head><p>Branch predictors need to be warmed up during sampled simulation. This is illustrated in Figure <ref type="figure" target="#fig_0">1</ref> where the number of branch mispredictions per thousand instructions (MPKI) is shown for gcc for four sampling unit sizes: 10K, 100K, 1M and 10M instruction sampling unit sizes. Note this is in the range of sampling units used in contemporary sampled simulation environments such as SMARTS <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9]</ref> (sampling unit size of 10K instructions) and SimPoint <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b20">21]</ref> (sampling unit sizes from 1M to 100M instructions). Each graph shows the MPKI for four (fairly aggressive) branch predictors: a 128Kbit gshare predictor, a 256Kbit local predictor, a 128Kbit bimodal predictor and a 192Kbit hybrid predictor -more details about the experimental setup and the branch predictors are given in section 5. The various bars correspond to various branch predictor warmup strategies: no warmup, stale state and perfect warmup. The no warmup approach assumes an initialized branch predictor at the beginning of a sampling unit, i.e., the branch predictor content is flushed at the beginning of the sampling unit -twobit saturating counters in adjacent entries are initialized in alternate '01' '10' states. The stale state approach assumes that the branch predictor at the beginning of the sampling unit equals the branch predictor state at the end of the previous sampling unit. Note that the stale state approach assumes that sampling units are simulated sequentiallythis excludes parallel sampled simulation. The perfect warmup approach is an idealized warmup scenario where the branch predictor is perfectly warmed up, i.e., the branch predictor state at the beginning of the sampling unit is the state as if all instructions prior to the sampling unit were simulated.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> clearly shows that the no warmup and stale state approaches fail in being accurate, especially for small sampling unit sizes. For example for 10K instruction sampling units, the ∆M P KI can be very high for both no warmup and stale state. Even for 1M instruction sampling units, the error can be significant, more than 1.5 ∆M P KI for the no warmup strategy and the gshare predictor. Note that the error varies across branch predictors. The error is typically higher for the gshare predictor than for the bimodal predictor, which is to be understood intuitively, the reason being the fact that the XOR hashing in the gshare predictor typically results in more entries being accessed in the branch predictor table than the bimodal predictor does. As a result of the non-uniform warmup error across branch predictors, incorrect design decisions may be taken. For example, using the no warmup approach, a computer architect would conclude that the local predictor achieves a better accuracy (a lower MPKI) than the gshare predictor. This is the case for 10K, 100K and even 1M instruction sampling units. However, this conclusion is just an artifact of the inadequate warmup approach. Perfect warmup shows that the gshare predictor outperforms the local predictor. The stale state warmup approach only solves this problem for the 1M instruction sampling unit, however, it does not solve the problem for smaller sampling unit sizes and it cannot be used for parallel sampled simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Branch History Matching</head><p>This paper proposes Branch History Matching (BHM) as a novel branch predictor warmup approach. Computing the branch predictor warmup length through Branch History Matching (BHM) is done in two steps. First, we compute the BHM distribution for all sampling units. In a second phase, we then determine the warmup length for each sampling unit for a given total warmup length budget using the BHM distributions for all sampling units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Computing the BHM distribution</head><p>Computing the BHM distribution for a given sampling unit is illustrated in Figure <ref type="figure" target="#fig_1">2</ref>. At the top of Figure <ref type="figure" target="#fig_1">2</ref>, a sampling unit along with its pre-sampling unit is shown. The bullets represent a single static branch being executed multiple times in the pre-sampling unit as well as in the sampling unit. Instructions with labels '1' thru '6' are part of the pre-sampling unit; instructions labeled '7', '8' and '9' are part of the sampling unit. A white bullet represents a non-taken branch; a black bullet shows a taken branch. Figure 2 also shows the global and local history for each dynamic instance of the given static branch; the example assumes three global history bits and three local history bits. Note that the most recent branch outcome is shifted in on the right hand side of the history register; for example, a non-taken branch changes the local history from '011' to '110'.</p><p>In order to compute the BHM distribution, we first compute the BHM histogram. The BHM histogram is computed by scanning all the branch instances in the sampling unit and proceeds as follows.</p><p>-Searching the sampling unit. We first determine whether there is a perfect match for the local and global history of the given branch instance in the sampling unit versus the local and global histories of all the preceding branch instances of the same static branch in the sampling unit. A perfect match means that both the local and global histories are identical for the two respective branch instances. For the example given in Figure <ref type="figure" target="#fig_1">2</ref>, the local and global histories of branch instance '9' in the sampling unit show a perfect match with the local and global history of branch instance '7' in the sampling unit. This case increments the count for d = 0 in the BHM histogram. -Searching the pre-sampling unit. In case there is no perfect match with a preceding branch instance in the sampling unit, we search the pre-sampling unit for the most recent branch instance that shows the highest match with the local and global history for the given branch instance. This is done by computing the Branch History Matching Score (BHMS) between the given branch instance in the sampling unit with all the branch instances of the same static branch in the pre-sampling unit. The BHMS between two branch instances is computed as the number of bit positions that are identical between the local and global histories of the respective branch instances. When computing the number of identical bit positions we count from the most recent bit to the least recent bit and we stop counting as soon as there is disagreement for a given bit, i.e., we count the matching most recent history bits. This done for both the global and local histories; the overall BHMS then is the sum of the global and local BHMSs. Computed BHMSs are shown in Figure <ref type="figure" target="#fig_1">2</ref> for the first and second branch instances of the sampling unit. For example, the BHMS for branch instance <ref type="bibr">'</ref> The first branch instance (with label '7') achieves a perfect match (BHMS equals 6) for the branch instance with label '5'. The idea is then to update the BHM histogram reflecting the fact that in order to have an accurate warmup for instruction '7' we need to go back to instruction '5' in the pre-sampling unit. For this purpose, the BHM histogram is incremented at distance d1 with 'd1' being the number of instructions between the branch instance with label '5' and the beginning of the sampling unit -this is to say that branch predictor warmup should start at branch instruction '5'. For the second branch instance (with label '8') in the sampling unit,  the highest BHMS is obtained for the branch instance with label '6'; the number of instructions between that branch instance and the sampling unit starting point is denoted as d2 in Figure <ref type="figure" target="#fig_1">2</ref>. We then increment the BHM histogram at distance d2.</p><formula xml:id="formula_0">(i = 0; i &lt; n; i++) { if ((P[i][d[i] + b] -P[i][d[i]])/b &gt; max_prob) { max_prob = (P[i][d[i] + b] -P[i][d[i]])</formula><p>Dividing the BHM histogram with the number of branch instances in the sampling unit, we then obtain the BHM distribution. Figure <ref type="figure" target="#fig_1">2</ref> shows the cumulative BHM distribution for the given sampling unit: since there are three branch instances in our example sampling unit, the cumulative distribution starts at 1/3 for distance d = 0, reaches 2/3 at distance d = d2 and finally reaches 1 at distance d = d1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Determining warmup length</head><p>Once the BHM distribution is computed for each sampling unit we determine the warmup length per sampling unit for a given total warmup length budget. The goal is to partition a given warmup length budget over a number of sampling units so that accuracy is maximized. In other words, sampling units that do not require much warmup, are granted a small warmup length; sampling units that require much more warmup are given a much larger warmup length.</p><p>The algorithm for determining the appropriate warmup length per sampling unit works as follows, see also Figure <ref type="figure" target="#fig_2">3</ref> for the pseudocode of the algorithm. We start from n BHM distributions, with n being the number of sampling units. In each iteration, we determine the sampling unit i out of the n sampling units that faces the maximum slope in the BHM distribution. This means that the sampling unit i (called max i in the pseudocode in Figure <ref type="figure" target="#fig_2">3</ref>) is determined that maximizes the slope Pi(di+b)−Pi(di) b , with P i (d) being the probability for distance d in the cumulative BHM distribution for sampling unit i, and d i being the warmup length granted to sampling unit i in the current state of the algorithm. For the sampling unit i that maximizes the slope, we increase the granted warmup length d i to d i + b. This algorithm is iterated until the total warmup length over all sampling units equals a user-defined maximum warmup length L w , i.e., n i=1 d i = L w . By doing so, we effectively budget warmup to samples that benefit the most from the granted warmup.</p><p>Note that this algorithm is only one possible design point in BHM warmup. More in particular, this algorithm heuristically determines to increase the warmup length for the sampling unit that faces the maximum slope in the BHM distribution. The algorithm does not take into account the distance over which this slope is observed; taking this distance into account for determining appropriate warmup lengths would be an interesting avenue for future work though.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Discussion</head><p>Most branch predictors in the literature as well as in today's commercial processors use a global and/or local branch history. Because BHM is also based on global and local branch history matching, it is to be expected that BHM will be an appropriate warmup technique for most branch predictors considered today. However, some branch predictors proposed in the literature are path-based and use a sequence of recent branch addresses as the branch history. In this paper though, we limit ourselves to branch predictors that are based on global and local branch histories. However, as part of our future work, we will further evaluate BHM for a broader range of branch predictors than the ones used in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental setup</head><p>We use SPEC CPU2000 integer benchmarks with reference inputs in our experimental setup. We include all integer benchmarks except for perlbmk because its branch misprediction rate is very low; in fact, no warmup is very accurate for perlbmk. The binaries which were compiled and optimized for the Alpha 21264 processor, were taken from the SimpleScalar website. All measurements presented in this paper are obtained using the binary instrumentation tool ATOM <ref type="bibr" target="#b21">[22]</ref>. The branch predictors considered in this paper are shown in Table <ref type="table" target="#tab_2">1</ref>. We consider four fairly aggressive branch predictors: a gshare predictor, a local predictor, a bimodal predictor and a hybrid predictor <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>.</p><p>Our primary metric for quantifying the accuracy of the branch predictor warmup approaches proposed in this paper is ∆M P KI which is defined as the absolute difference between the number of misses per thousand instructions under perfect warmup (M P KI perfect ) versus the number of misses per thousand instructions under the given branch predictor warmup approach (M P KI warmup ). In other words, ∆M P KI = M P KI warmup − M P KI perfect and thus the smaller ∆M P KI, the better. Our second metric, next to accuracy, is warmup length which is defined as the number of instructions required by the given warmup technique. Likewise, the smaller the warmup length, the smaller the total simulation time, the better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation</head><p>We now evaluate the accuracy and warmup length of BHM compared to fixed-length warmup; section 6.1 covers accuracy and section 6.2 covers warmup length. Throughout this evaluation we consider a sampling unit size of 10K instructions. The reason is that, as mentioned in section 3, small sampling unit sizes suffer most from the lack of warmup; small sampling unit sizes will stress our warmup approach the most. All the results presented in this paper are for 50 sampling units.</p><p>Further, we assume that the number of global and local history bits equals 16 for the BHM approach in sections 6.1 and 6.2. Section 6.3 then studies the impact of the BHM history length on accuracy and warmup length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Accuracy</head><p>Comparison against fixed-length warmup. Figure <ref type="figure">4</ref> evaluates the accuracy of BHM compared to fixed-length warmup. Both warmup techniques are budgeted a 1M warmup length per sampling unit, i.e., both warmup techniques use the same warmup length. The four graphs in Figure <ref type="figure">4</ref> represent four different branch predictors, namely the gshare, local, bimodal and hybrid branch predictors. The ∆M P KIs are shown for both warmup techniques. We observe that BHM substantially outperforms fixed-length warmup. Over all four branch predictors, the average ∆M P KI decreases from 0.48 (under fixed-length warmup) to 0.29 (under BHM) which is 39% more accurate.</p><p>Comparison against MRRL. Figure <ref type="figure">5</ref> compares BHM against MRRL. As mentioned before, MRRL looks how far one needs to go back in the pre-sampling unit for encountering branch instances of the same static branch for all branch instances in the sampling unit. The results in Figure <ref type="figure">5</ref> show that BHM clearly outperforms MRRL. Over all four branch predictors, the average ∆M P KI decreases from 2.13 (under MRRL) to 0.29 (under BHM) which is 87% more accurate. The important difference between MRRL and BHM is that BHM, in contrast to MRRL, takes into account branch histories; this results in significantly more accurate branch predictor state warmup for BHM compared to MRRL. Note that MRRL also performs worse than fixed 1M warmup, compare Figure <ref type="figure">4</ref> against Figure <ref type="figure">5</ref>. The reason is that, because of the fact that MRRL does not take   into account branch history, MRRL is unable to come up with long enough warmup lengths for accurately warming up the branch predictors. The average warmup length through MRRL is only 200K instructions per sampling unit; according to our results, much larger warmup lengths are required to accurately warmup branch predictors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Warmup length</head><p>In order to quantify the reduction in warmup length through BHM compared to fixedlength warmup, we have measured the average ∆M P KI over the four branch predictors as a function of warmup length, see Figure <ref type="figure">6</ref>. The average ∆M P KI is shown for fixed-length warmup with the warmup budget varying between 1M and 2M instructions per sampling unit. The ∆M P KI for BHM with a 1M warmup length budget per sampling unit is shown on the right. We observe that fixed-length warmup achieves about the same accuracy as BHM for a warmup length of 1.6M instructions per sampling unit.</p><p>In other words, BHM with a 1M warmup budget per sampling unit results in a 1.6X reduction in warmup length compared to fixed-length warmup while achieving the same accuracy.</p><p>Figure <ref type="figure" target="#fig_4">7</ref> shows MPKI versus warmup length for the gcc benchmark and the four branch predictors. Note that the axes are shown on a log scale. The two curves in each graph represent fixed-length warmup and BHM warmup, respectively; and the various points in these curves represent different warmup budgets. This graph clearly shows that BHM achieves the same accuracy with substantially shorter warmup lengths, or reverse, BHM achieves better accuracy for the same warmup length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Impact of BHM history length</head><p>Note that the amount of branch history used by three of the four branch predictors, namely the gshare, local and hybrid predictors, equals 16 bits. The number of BHM history bits used for computing the length also equals 16 bits. The question however is how sensitive BHM's accuracy is to the BHM history length. Figure <ref type="figure" target="#fig_6">8</ref> explores the impact of the BHM history length. The average ∆M P KI over all benchmarks is shown on the vertical axis versus the warmup length on the horizontal axis. The five curves represent the five branch predictors. The different points on each curve represent different BHM history lengths. We varied the BHM history length from 0, 2, 4, 8 to 16; when varying the history length we simultaneously vary the global and local BHM history lengths. A zero BHM history length means that no global and local history is taken into account for building the BHM distribution. In other words, the BHM warmup method then simply looks for the last occurrence of the same static branch for updating the BHM distribution. In all of these experiments, we budgeted a warmup length to 1M instructions per sampling unit.</p><p>There are two interesting observations to be made from this graph. First, accuracy improves or ∆M P KI decreases with increasing BHM history lengths. This is to be expected because the more history is taken into account, the better BHM will be able to determine how far it needs to go back in the pre-sampling unit for appropriate warmup. Second, small BHM histories are unable to budget the warmup lengths so that the average warmup length per sampling unit effectively equals the 1M instruction warmup budget. For example, a zero BHM history only yields slightly more than 200K instructions of warmup per sampling unit. In other words, it is impossible for BHM with limited history to fully exploit the available warmup budget. By increasing the BHM history length, BHM is better able to approach the target 1M warmup length per sampling unit. (Note that the MRRL approach <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20]</ref> corresponds to a zero BHM history length.) We further observe that an 8 bit and a 16 bit BHM history length yields ap-  proximately the same accuracy. From this experiment, we thus conclude that in order to achieve accurate warmup for branch predictors, the BHM history length needs to be set to an appropriate value, for example, to the maximum history length one would look at during the branch predictor design space exploration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>Sampled simulation is a well known approach to speed up architectural simulations that are heavily used by computer architects and designers. An important issue with sampled simulation however is the cold-start i.e., the microarchitecture state is unknown at the beginning of each sampling unit. Although a great deal of work has been done on cache structure warmup, very little research has been done on branch predictor warmup.</p><p>This paper proposed Branch History Matching (BHM) as a novel branch predictor warmup method. The idea is to analyze the sampling unit as well as the pre-sampling unit for recurring branch instances of the same static branch with similar global and local branch histories. By doing so, BHM builds a distribution for each sampling unit that characterizes the branch locality behavior. BHM then budgets its total warmup budget to the various sampling units. Sampling units that are warmup-sensitive are budgeted more warmup; sampling units that are warmup-insensitive are budgeted less warmup. Compared to fixed-length warmup, BHM achieves better accuracy for the same total warmup budget, or reverse, BHM achieves the same accuracy with a shorter total warmup budget.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. No warmup, stale state and perfect warmup MPKI results for gcc and 4 branch predictors and 4 sampling unit sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. An example illustrating how the cumulative Branch History Matching distribution is computed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The algorithm in pseudocode for determining the warmup length per sampling unit using BHM distributions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Fig.5. ∆M P KI results for MRRL and BHM for the gshare, local, bimodal and hybrid branch predictors. For MRRL, we consider all branch instances in the sampling unit, hence the 'MRRL 100%' labels.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Comparing BHM versus fixed warmup in terms of MPKI versus warmup length for gcc.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Evaluating the impact of the BHM history length on accuracy and warmup length.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>The branch predictors considered in this paper.</figDesc><table><row><cell cols="2">predictor configuration</cell></row><row><cell cols="2">gshare 16-bit history gshare predictor, 128Kbit total state</cell></row><row><cell>local</cell><cell>16-bit local predictor, 8K entries at first level, 64K entries at second level</cell></row><row><cell></cell><cell>256 Kbit total state</cell></row><row><cell cols="2">bimodal 64K-entry bimodal predictor, 128Kbit total state</cell></row><row><cell cols="2">hybrid hybrid predictor consisting of a 32K-entry bimodal predictor, a 15-bit history</cell></row><row><cell></cell><cell>gshare predictor and a 32K-entry PC-indexed meta predictor; 192Kbit total state</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>∆M P KI results for fixed 1M warmup and BHM for the gshare, local, bimodal and hybrid branch predictors.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">gshare predictor</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">local predictor</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">fixed 1M</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">fixed 1M</cell></row><row><cell></cell><cell>1.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">BHM 1M</cell><cell>2.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">BHM 1M</cell></row><row><cell>DMPKI</cell><cell>0.8 1.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>DMPKI</cell><cell>1.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.0</cell><cell>bzip2</cell><cell>crafty</cell><cell>eon</cell><cell>gap</cell><cell>gcc</cell><cell>gzip</cell><cell>mcf</cell><cell>parser</cell><cell>twolf</cell><cell>vortex</cell><cell>vpr</cell><cell>avg</cell><cell>0.0</cell><cell>bzip2</cell><cell>crafty</cell><cell>eon</cell><cell>gap</cell><cell>gcc</cell><cell>gzip</cell><cell>mcf</cell><cell>parser</cell><cell>twolf</cell><cell>vortex</cell><cell>vpr</cell><cell>avg</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">bimodal predictor</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">hybrid predictor</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.50</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.50</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.45</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">fixed 100K</cell><cell></cell><cell></cell><cell></cell><cell>0.45</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">fixed 1M</cell></row><row><cell></cell><cell>0.40</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">BHM 100K</cell><cell></cell><cell></cell><cell></cell><cell>0.40</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">BHM 1M</cell></row><row><cell>DMPKI</cell><cell>0.25 0.30 0.35</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>DMPKI</cell><cell>0.25 0.30 0.35</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.20</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.20</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.15</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.15</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.05</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.05</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.00</cell><cell>bzip2</cell><cell>crafty</cell><cell>eon</cell><cell>gap</cell><cell>gcc</cell><cell>gzip</cell><cell>mcf</cell><cell>parser</cell><cell>twolf</cell><cell>vortex</cell><cell>vpr</cell><cell>avg</cell><cell>0.00</cell><cell>bzip2</cell><cell>crafty</cell><cell>eon</cell><cell>gap</cell><cell>gcc</cell><cell>gzip</cell><cell>mcf</cell><cell>parser</cell><cell>twolf</cell><cell>vortex</cell><cell>vpr</cell><cell>avg</cell></row><row><cell cols="2">Fig. 4.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Average ∆M P KI over the four branch predictors as a function of warmup length for the fixed-length warmup approach compared to BHM 1M.</figDesc><table><row><cell></cell><cell>0.45</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.35</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DMPKI</cell><cell>0.2 0.25</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.15</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.05</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>fixed 1M</cell><cell>fixed 1.1M</cell><cell>fixed 1.2M</cell><cell>fixed 1.3M</cell><cell>fixed 1.4M</cell><cell>fixed 1.5M</cell><cell>fixed 1.6M</cell><cell>fixed 1.7M</cell><cell>fixed 1.8M</cell><cell>fixed 1.9M</cell><cell>fixed 2.0M</cell><cell>BHM 1M</cell></row><row><cell>Fig. 6.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="13">5. ∆M P KI results for MRRL and BHM for the gshare, local, bimodal and hybrid branch</cell></row><row><cell cols="13">predictors. For MRRL, we consider all branch instances in the sampling unit, hence the 'MRRL</cell></row><row><cell>100%' labels.)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors would like to thank the anonymous reviewers for their valuable feedback. Lieven Eeckhout is a Postdoctoral Fellow with the Fund for Scientific Research-Flanders (Belgium) (FWO-Vlaanderen). This research is also supported by Ghent University, IWT, HiPEAC and the European SARC project No. 27648.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Reducing state loss for effective trace sampling of superscalar processors</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Conte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Menezes</surname></persName>
		</author>
		<editor>ICCD.</editor>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="468" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Automatically characterizing large scale program behavior</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ASPLOS</title>
		<imprint>
			<biblScope unit="page" from="45" to="57" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">SMARTS: Accelerating microarchitecture simulation via rigorous statistical sampling</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Wunderlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Hoe</surname></persName>
		</author>
		<editor>ISCA.</editor>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="84" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Characterizing and comparing prevailing simulation techniques</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Kodakara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sendag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Lilja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Hawkins</surname></persName>
		</author>
		<editor>HPCA.</editor>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="266" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient sampling startup for sampled processor simulation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Van Biesbrouck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Eeckhout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">HiPEAC</title>
		<imprint>
			<biblScope unit="page" from="47" to="67" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">TurboSMARTS: Accurate microarchitecture simulation in minutes</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wenish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wunderlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoe</surname></persName>
		</author>
		<editor>SIGMETRICS.</editor>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="408" to="409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Accelerating multiprocessor simulation with a timestamp record</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asanovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPASS</title>
		<imprint>
			<biblScope unit="page" from="66" to="77" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">NSL-BLRL: Efficient cache warmup for sampled processor simulation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Van Ertvelde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hellebaut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Eeckhout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>De Bosschere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ANSS</title>
		<imprint>
			<biblScope unit="page" from="168" to="175" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Simulation sampling with live-points</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Wunderlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Hoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPASS</title>
		<imprint>
			<biblScope unit="page" from="2" to="12" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Branch trace compression for snapshot-based simulation</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asanovic</surname></persName>
		</author>
		<editor>ISPASS.</editor>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="25" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">DiST: A simple, reliable and scalable method to significantly reduce processor architecture simulation time</title>
		<author>
			<persName><forename type="first">S</forename><surname>Girbal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mouchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Temam</surname></persName>
		</author>
		<editor>SIGMETRICS.</editor>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Accelerating architectural simulation by parallel execution of trace samples</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lauterbach</surname></persName>
		</author>
		<idno>SMLI TR-93-22</idno>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
		<respStmt>
			<orgName>Sun Microsystems Laboratories Inc.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A comparison of trace-sampling techniques for multimegabyte caches</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="664" to="675" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A model for estimating trace-sample miss ratios</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kessler</surname></persName>
		</author>
		<editor>SIGMETRICS.</editor>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="79" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Combining trace sampling with single pass methods for efficient cache simulation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Conte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Hwu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="714" to="720" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Minimal subset evaluation: Rapid warm-up for simulated hardware state</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Haskins</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Skadron</surname></persName>
		</author>
		<editor>ICCD-2001.</editor>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="32" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Memory Reference Reuse Latency: Accelerated warmup for sampled microarchitecture simulation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Haskins</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Skadron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPASS</title>
		<imprint>
			<biblScope unit="page" from="195" to="203" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">BLRL: Accurate and efficient warmup for sampled processor simulation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Eeckhout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>De Bosschere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>John</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Computer Journal</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="451" to="459" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Self-monitored adaptive cache warm-up for microprocessor simulation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Eeckhout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SBAC-PAD</title>
		<imprint>
			<biblScope unit="page" from="10" to="17" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Accelerated warmup for sampled microarchitecture simulation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Haskins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Skadron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Architecture and Code Optimization (TACO)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="78" to="108" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Picking statistically valid and early simulation points</title>
		<author>
			<persName><forename type="first">E</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
		<editor>PACT.</editor>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="244" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">ATOM: A system for building customized program analysis tools</title>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Eustace</surname></persName>
		</author>
		<idno>94/2</idno>
	</analytic>
	<monogr>
		<title level="j">Western Research Lab</title>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>Compaq</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Combining branch predictors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mcfarling</surname></persName>
		</author>
		<idno>WRL TN-36</idno>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
		<respStmt>
			<orgName>Digital Western Research Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Alternative implementations of two-level adaptive branch prediction</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
		<editor>ISCA.</editor>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="124" to="134" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
