<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Auto-Predication of Critical Branches*</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Adarsh</forename><surname>Chauhan</surname></persName>
							<email>adarsh.chauhan@intel.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Processor Architecture Research Lab Intel Labs Bengaluru</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jayesh</forename><surname>Gaur</surname></persName>
							<email>jayesh.gaur@intel.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Processor Architecture Research Lab Intel Labs Bengaluru</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zeev</forename><surname>Sperber</surname></persName>
							<email>zeev.sperber@intel.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Intel Corporation Haifa</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Franck</forename><surname>Sala</surname></persName>
							<email>franck.sala@intel.com</email>
							<affiliation key="aff3">
								<orgName type="institution">Intel Corporation Haifa</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lihu</forename><surname>Rappoport</surname></persName>
							<email>lihu.rappoport@intel.com</email>
							<affiliation key="aff4">
								<orgName type="institution">Intel Corporation Haifa</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Adi</forename><surname>Yoaz</surname></persName>
							<email>adi.yoaz@intel.com</email>
							<affiliation key="aff5">
								<orgName type="institution">Intel Corporation Haifa</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sreenivas</forename><surname>Subramoney</surname></persName>
							<email>sreenivas.subramoney@intel.com</email>
							<affiliation key="aff6">
								<orgName type="laboratory">Processor Architecture Research Lab Intel Labs Bengaluru</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Auto-Predication of Critical Branches*</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/ISCA45697.2020.00019</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Microarchitecture</term>
					<term>Dynamic Predication</term>
					<term>Control Flow Convergence</term>
					<term>Run-time Throttling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Advancements in branch predictors have allowed modern processors to aggressively speculate and gain significant performance with every generation of increasing out-of-order depth and width. Unfortunately, there are branches that are still hard-to-predict (H2P) and mis-speculation on these branches is severely limiting the performance scalability of future processors. One potential solution to mitigate this problem is to predicate branches by substituting control dependencies with data dependencies. Predication is very costly for performance as it inhibits instruction level parallelism. To overcome this limitation, prior works selectively applied predication at run-time on H2P branches that have low confidence of branch prediction. However, these schemes do not fully comprehend the delicate trade-offs involved in suppressing speculation and can suffer from performance degradation on certain workloads. Additionally, they need significant changes not just to the hardware but also to the compiler and the instruction set architecture, rendering their implementation complex and challenging.</p><p>In this paper, by analyzing the fundamental trade-offs between branch prediction and predication, we propose Auto-Predication of Critical Branches (ACB) -an end-to-end hardware-based solution that intelligently disables speculation only on branches that are critical for performance. Unlike existing approaches, ACB uses a sophisticated performance monitoring mechanism to gauge the effectiveness of dynamic predication, and hence does not suffer from performance inversions. Our simulation results show that, with just 386 bytes of additional hardware and no software support, ACB delivers 8% performance gain over a baseline similar to the Skylake processor. We also show that ACB reduces pipeline flushes because of mis-speculations by 22%, thus effectively helping both power and performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>High accuracy of modern branch predictors <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b4">[5]</ref> has allowed Out-of-Order (OOO) processors to speculate aggressively on branches and gain significant performance with every generation of increasing processor depth and width. Unfortunately, there still remains a class of branches that are Hard-to-Predict (H2P) for even the most sophisticated branch Fig. <ref type="figure" target="#fig_4">1</ref>. Performance trends with scaling of OOO processor. The 1X point is similar in parameters to the Skylake processor <ref type="bibr" target="#b0">[1]</ref>. Performance potential for future processors is bound by the problem of mis-speculation.</p><p>predictors <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b7">[8]</ref>. These branches cost not only performance but also significant power overheads because of pipeline flush and re-execution upon wrong speculation.</p><p>Figure <ref type="figure" target="#fig_4">1</ref> shows the performance improvements from an oracle perfect branch predictor with increasing processor depth and width 1 . For these results, the baseline is similar in parameters to the Intel Skylake processor <ref type="bibr" target="#b0">[1]</ref> and uses a branch predictor similar to TAGE <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>. We show the performance impact of perfect branch prediction on a continuum of processors with varying OOO resources compared to Skylake. As is evident from Figure <ref type="figure" target="#fig_4">1</ref>, the performance potential of perfect speculation increases with OOO processor scaling. For instance, a three times wider and deeper machine than the Skylake baseline is almost two times more speculation bound than Skylake. These results clearly motivate the need for mitigating branch mis-speculations, especially since future OOO processors are expected to scale deeper and wider <ref type="bibr" target="#b8">[9]</ref>. As it gets harder to improve branch prediction, there is an urgent need to investigate solutions to address this problem. One possible solution is to limit speculation when an H2P branch is encountered. A classic approach to achieve this is predication <ref type="bibr" target="#b9">[10]</ref>, which allows fetching both the taken and not-taken portions of a conditional branch, but the execution is conditional based on the final branch outcome. Because predication inherently limits instruction level parallelism, it can be detrimental to overall performance. To overcome this, several prior techniques have tried to predicate only those instances of H2P branches which have low confidence of prediction <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b13">[14]</ref>. Policies like Diverge Merge Processor (DMP) <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b14">[15]</ref> use careful compiler profiling to select target H2P branches, and then throttle their application using run-time monitoring of branch prediction confidence. These techniques showed great promise in mitigating the problems with H2P branches. Unfortunately for almost a decade, no advancement has been further made in these policies, and as we will show in this paper, on modern OOO processors with accurate branch predictors these policies end up creating severe run-time bottlenecks for some applications, thereby limiting their applicability. Moreover, these techniques need significant changes to the compiler and the instruction set architecture (ISA), which makes their adoption challenging.</p><p>In this work, we first perform a thorough study of the performance trade-offs created by limiting speculation using predication. Based on this analysis, we propose Auto-Predication of Critical Branches (ACB) that intelligently tries to disable speculation only on branches critical for performance. ACB needs no compiler or ISA support and has a micro-architecture which is implementable in modern OOO processors. Specifically, we make the following new contributions. <ref type="bibr" target="#b0">1)</ref> We present an analysis of the fundamental cost-benefit trade-offs that come to the fore when branch prediction is replaced by predication, especially on how it impacts the program critical path. Guided by this understanding, we propose ACB, a light-weight mechanism that intelligently decides whether limiting speculation for a given critical branch is helpful or detrimental to performance. ACB is a holistic and complete solution that mitigates performance losses by wrong speculation, while ensuring that it does not create performance inversions. 2) We describe ACB's implementation in a modern OOO processor with no ISA changes or compiler support. ACB learns its targeted critical branch PCs (program counters) using simple heuristics, and uses a novel hardware mechanism to accurately detect control flow convergence using generic patterns of convergence. This is unlike previous approaches <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b13">[14]</ref> that were dependent upon compiler analysis and profiling. With small changes to Fetch and OOO pipelines, ACB dynamically predicates critical branches, thereby reducing costly pipeline flushes and improving performance. 3) We also propose a unique throttling system (Dynamo) that monitors the run-time performance delivered by applying ACB on any targeted branch and promptly throttles ACB instances that are found to be degrading performance. This is in contrast to typical throttling mechanisms that rely on monitoring multiple local performance counters. Cost-benefit estimation is complex for predication based solutions as they influence performance, negatively or positively, in many different ways. By directly monitoring the dynamic performance, Dynamo makes holistic and informed decisions. With suitable adaptations, Dynamo's generic approach can be applied to control any performance feature which similarly requires balancing of cost-benefit trade-off. Our simulation results show that with just 386 bytes of overall additional storage, ACB delivers 8% performance improvement over a baseline processor similar to Intel Skylake <ref type="bibr" target="#b0">[1]</ref>. Since ACB requires little additional hardware and saves 22% of the baseline mispredictions, it helps both power and performance. We also show that ACB overcomes some of the fundamental limitations of past compiler-based optimizations and scales seamlessly to future processors, that are expected to be even more bound by branch mis-speculations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND AND MOTIVATION</head><p>Modern branch predictors use program history to predict future outcomes of a branch <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>. Decades of research have made them very accurate. However, there remains a class of branches that are still hard to predict. Many such branches are data dependent branches and are difficult to predict using just program history <ref type="bibr" target="#b5">[6]</ref>.</p><p>We characterized branch mispredictions on our selected workloads <ref type="foot" target="#foot_0">2</ref> . We found that on average, in a given program phase, 64 branch PCs sufficiently contribute to more than 95% of all dynamic mispredictions. Analysing the type of H2P branches reveals that a majority of total mispredictions come from direct conditional branches, of which 72% comes from convergent conditional branches. We define convergent branches as those branches whose taken and not-taken paths can converge to some later point in the program (using the same convergence criterion as DMP <ref type="bibr" target="#b6">[7]</ref>). Loops are naturally converging and contribute to another 13%. Remaining 13% conditional branches exhibit non-converging control flows. These observations lead us to conclude that the majority of branch misspeculations can be addressed by focusing on a small set of 64 convergent conditional H2P branches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Program Criticality</head><p>The performance of any OOO processor is bound by the critical path of execution. Critical path can be conceptually understood as the sequence of (data/control) dependent instructions which determines the total execution cycles of a program. Fields et al. <ref type="bibr" target="#b15">[16]</ref> presented a graph-based definition of the critical path where the critical path is the maximum weighted path in the data-dependency graph (DDG). Instructions, whose execution lies on this path, are critical for performance.</p><p>Branch mis-speculation appears on the critical path as a control dependency between the mispredicting branch and the correct target fetched after branch resolution. While most of the branch mispredictions usually lie on the critical path, not all instances are critical for performance. Some mispredictions lie in the shadow of other, more critical events (e.g. long latency loads that miss LLC) and may not be critical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Predication</head><p>One possible solution to the branch misprediction problem is to prevent speculation when an H2P branch is encountered. Static predication provides code for both the taken and nottaken directions of conditional hammocks, but the run-time execution is conditionally data-dependent on the branch outcome. Most ISAs have some support for static predication <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>. Even though predication reduces critical path length by preventing pipeline flushes upon mispredictions, it substitutes control dependencies with data dependencies in the execution of the program. This limits instruction level parallelism and can elongate the critical path. To mitigate this, past approaches have dynamically applied predication only on branch instances having low confidence from branch prediction <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>.</p><p>Wish Branches <ref type="bibr" target="#b11">[12]</ref> relies on the compiler to provide predicated code for every branch PC. For every dynamic branch instance, branch prediction confidence is used to select between fetching the predicated code or speculate normally. However, this approach increases the compiled code footprint. Dynamic Hammock Predication (DHP <ref type="bibr" target="#b10">[11]</ref>) uses the compiler to identify simple, short hammocks which can be predicated dynamically (and profitably) and fetches both the directions of the hammock in hardware. Diverge Merge Processor (DMP) <ref type="bibr" target="#b6">[7]</ref> improves upon both Wish Branches and DHP. DMP uses compiler analysis-and-profiling to identify frequently mispredicting branch candidates and modifies the compiled binary to supply the convergence information for frequently converging, complex control flow patterns. Using ISA support and changes to processor front-end, DMP fetches both taken and not-taken paths of the conditional branch. Register Alias Table (RAT) in the OOO is forked and both the paths are renamed separately. Select-micro-ops are injected to dynamically predicate the data outcome from both paths.</p><p>By predicting branch confidence separately at run-time, DMP tries to effectively predicate only those instances that are likely to mispredict and delivers significant performance. However, as we will analyze in the following section, predicationbased strategies like DMP can create new critical paths of execution, which are difficult to comprehend just by monitoring branch confidence. Also, training data-sets used by the compiler (for developing static/profiling-based branch selection criteria) can be very different from actual testing data seen during execution. Since many H2P branches are data dependent, the efficacy of compiler analyses <ref type="bibr" target="#b14">[15]</ref> is dependent on the quality of profiled input. As a result, application of DMP and similar schemes may result in performance inversions on certain workloads. Moreover, such schemes need simultaneous changes to the hardware, compiler as well as ISA, which makes their practical implementation challenging.</p><p>In Section V-C, we will quantitatively discuss the performance of DMP and contrast it with our proposal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Effects of Predication on Critical Path</head><p>As mentioned above, there are costs of performing predication to realize the benefits of saving mispredictions by eliminating speculation on branches. An imbalance in this delicate trade-off for predication can cause performance inversions. Hence, it is important to understand and consider the factors influencing this balance. Additionally, to encourage adoption on modern processors, we need techniques that are easy to implement completely in hardware, without needing support from the compiler or ISA. In this section, we will hence use program criticality to first develop an understanding of how predication changes the critical path of execution. Through this analysis, we will motivate the need for our feature.</p><p>1) Limiting Allocation: Predication, by fetching both the taken and not-taken paths of a branch, alters the critical path of execution. Figure <ref type="figure" target="#fig_0">2</ref>(a) shows an example DDG (using notations from <ref type="bibr" target="#b15">[16]</ref>) with and without predication. Without predication on a branch, a branch misprediction introduces the misprediction latency on the critical path. However, with predication, the critical path involves the latency of fetching control dependent region on both the directions and allocating them into the OOO (whereas the baseline speculates and fetches on only one direction).</p><p>Consider the misprediction rate for a given H2P branch as mispred rate, and the taken path has T and not-taken path has N instructions. Assume p to be the probability of the branch being taken. With predication, we need to fetch (T +N ) instructions for every predicated instance. alloc width is the maximum number of instructions that can be allocated in the OOO per cycle and mispred penalty is the penalty of misprediction, i.e. the total time taken to execute the mispredicting branch, signal the misprediction and the subsequent pipeline flush latency. For the baseline, misprediction increases the critical path of execution by (mispred rate ? mispred penalty) cycles. On the other hand, with predication, the critical path increases by</p><formula xml:id="formula_0">((T + N ) -(p ? T + (1 -p) ? N ))/alloc width.</formula><p>Predication will be profitable if,</p><formula xml:id="formula_1">((1 -p) ? T + p ? N )</formula><p>alloc width ? (mispred rate ? mispred penalty) (1) Equation 1 clearly shows the trade-off between higher allocations and saving the pipeline flushes by mispredictions. Let's assume that allocation width (alloc width) is 4, pipeline flush latency (mispred penalty) is 20 cycles and we have equal probability of predicting taken and not-taken. If misprediction rate is 10%, then predication will be beneficial only if the total instructions in the predicated branch body (taken and not-taken paths combined (T + N )) are less than 16. On the other hand, if branch body size is larger, say 32 instructions, then predication should be applied only for branches having misprediction rate greater than 20%. Realistically, the actual penalty for a branch misprediction is higher than just the pipeline flush latency, since it includes the execution latency of the branch-sources required for computing its outcome. Hence, equation 1 will have a higher value for mispred penalty, and predication may be able to tolerate somewhat larger number of extra allocations. Therefore, we can conclude that both misprediction rate and branch body size need to be considered to qualify any branch for predication. For those micro-architectures that allocate in OOO in terms of microoperations <ref type="bibr" target="#b18">[19]</ref>, this equation needs to be suitably adjusted.</p><p>2) Increasing Branch Mispredictions: Since B1 is a small hammock, it should be very amenable to dynamic predication. However, there is another branch B2 that is perfectly correlated with B1, but is not amenable to predication. Interestingly, in the baseline, B2 usually does not see any misprediction since B1 is more likely to execute (and cause pipeline flushes) before B2 can be executed. Perfect correlation between them would mean that B2 will always be correctly predicted when it is re-fetched, since it knows the outcome of B1. This happens because the global branch predictor would repair the prediction of B1 when there is no predication (since global history is updated), and B2 will always learn the correlation with B1.</p><p>With predication, however, there is no update to global history from B1. Therefore, B2 will start mispredicting and the effective number of mis-speculations will not come down. In fact, because of predication on B1, B2 will now take a longer time to execute, thereby elongating the critical path. Hence, branches like B1 should not be predicated, unless B2 can also be predicated. This effect of increasing the baseline mispredictions is more pronounced in cases of dynamic predication on branches with complex control flow patterns and large control dependent regions. Since branch history update and resolution are separated in branch speculation, the branch history cannot be perfectly corrected to improve the prediction for branches following the predicated region.</p><p>3) Elongating Critical Paths: Figure <ref type="figure" target="#fig_0">2</ref>(c) shows another example where the body of an H2P branch creates sources for a critical (long latency) load. Without predication, the load would still be launched, and may be correct if the branch prediction was correct. However, due to predication, this long latency load's dispatch is dependent upon the execution of the predicated branch. As a result, the critical path of execution may get elongated. If this H2P branch is very frequent, predication can result in a long chain of dependent instructions. In all such scenarios, resorting to normal branch speculation, even if the accuracy of branch prediction is low, may be a more optimal solution than predication.</p><p>To summarize our learnings, we first need to detect our target branches and learn their convergence patterns. Secondly, the selection criteria for critical branches should take into account the size of the branch body and the misprediction rate. Thirdly, alterations to the critical path due to predication need to be detected and handled at run-time. Finally, predication needs to be dynamic and completely implementable in hardware. These problems motivate us towards our proposal which we will describe in detail in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. AUTO-PREDICATION OF CRITICAL BRANCHES (ACB)</head><p>The essential idea behind ACB is to eliminate speculation when the criteria discussed in Section II are satisfied. ACB first detects conditional critical branches and then uses a novel hardware mechanism to find out their point of reconvergence. Thereafter, a simple mechanism is used to fetch both taken and not-taken portions (up to the reconvergence point) of the conditional branch. After the ACB-branch executes in the OOO, the predicated-true path is executed, whereas small micro-architectural modifications in the pipeline make the predicated-false path transparent to program execution. Finally, a dynamic monitoring (Dynamo) scheme monitors the runtime performance and appropriately throttles ACB. We now describe the micro-architecture of ACB in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Learning Target Branches</head><p>As reasoned in Section II-A, not all mispredicting branch instances impact performance. However, branches that frequently mispredict, invariably end up having several dynamic instances that lie on the critical path. We found that the frequency of misprediction for a given branch PC is a good measure of its criticality. Our scheme hence uses a simple criticality filter (?16 mispredictions in 200K retired instructions window) to filter out infrequently mispredicting branches. Once convergence is confirmed for a branch, we further ensure by learning that it has sufficient misprediction rate using confidence counters in the later stages.</p><p>We also experimented with other criticality heuristics to improve the above qualification criteria. Offline analysis of data dependence graphs for different applications expectedly showed that some fraction of the branch misprediction instances are not on the critical path. However, segregating such instances on-the-fly, and with reasonable hardware, is very challenging. We considered the heuristic of counting a mis-speculation event as critical only if, at the time of misprediction, the branch is within a fourth of the ROB size from head of the ROB (i.e. oldest entry in the ROB). Those mispredictions which happen near the retirement are more critical for performance as they will cause a greater part of ROB to be flushed and consequently, more controlindependent work to be wasted. This simple heuristic slightly improved the accuracy of the frequency based criticality filter. Such criticality heuristics can be improved by future research.</p><p>To track critical branches, ACB uses a direct-mapped Critical Table indexed by the PC of mispredicting conditional branches. Each table entry stores an 11 bit tag to prevent aliasing, a 2 bit utility counter for managing conflicts, and a 4 bit saturating critical counter. Every critical branch misprediction event (as defined by our heuristics) increments both critical counter and utility counter of its PC-entry. In case of conflict misses in the table, utility counter is decremented. An old entry will be replaced by a new contending entry only if utility counter is zero. As section II suggested, our experimental sweeps over this table size show that a small 64-entry table provides sufficient coverage useful for performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Learning Convergent Branches</head><p>The next step involves identifying convergent candidates among the identified critical branches. For this, ACB uses a single entry Learning Table <ref type="bibr">(20 bytes</ref>) to detect convergence one-branch-at-a-time which is sufficient for its functionality.</p><p>Types of Convergence: Through analysis of various control flow patterns in different workloads, we identified three generic cases by which conditional direct branches can converge. Figure <ref type="figure" target="#fig_2">3</ref> illustrates the three types, that we refer to as Type-1, Type-2 and Type-3. Type-1 convergence is characterized by the reconvergence point being identical to the ACB-branch target. The simplest form of Type-1 branches are IF-guarded hammocks that do not have an ELSE counterpart. Type-2 convergence is characterized by the not-taken path having some Jumper branch, which when taken, has a branch-target that is ahead of the ACB-branch target. This naturally guarantees that the taken path which starts from the ACB-branch target will fall-through to meet the Jumper branch target, making it the reconvergence point in this case. Type-2 covers conditional branches having pair of IF-ELSE clauses. Finally, Type-3 convergence possesses a more complex control flow pattern (which can have either IF-only or IF-ELSE form). It is characterized by the taken path encountering a Jumper branch which takes the control flow to its target that is less than the ACB-branch target. This ensures that the not-taken path naturally falls through to meet the Jumper branch target.</p><p>We have generalized these three types so that other complex cases (see Figure <ref type="figure" target="#fig_2">3</ref>) can also be contained within this set. However, the above description defines conditions that hold true for only forward-going branches (where the ACB-branch target PC is more than the branch PC). To cover the cases of backward-going branches, we adapted our algorithm by exploiting the commutative nature of convergence for backbranches. We use an important observation that by simply moving the original back-branch from the beginning of its Not-Taken block to the beginning of its Taken block, and modifying it accordingly to being a forward branch with target as its own original PC, the program remains logically unchanged. Thus, the reconvergence point detected in this modified scenario is going to be the same as original. Figure <ref type="figure" target="#fig_3">4</ref> illustrates this idea through an example.</p><p>Convergence detection mechanism is implemented during fetch since it needs to track only the PCs of instructions being fetched. When an entry in the critical table saturates its critical count, we copy the branch PC into the Learning Table which is occupied until we confirm convergence or divergence on both its directions. The mechanism first tries to learn if the ACBbranch is a Type-1 or Type-2 convergence. It begins by first inspecting the Not-Taken path. We track the first N fetched PC's following the ACB-branch. If we receive the target of the ACB-branch within this interval, we classify it as Type-1 and finish learning. Otherwise, if another taken branch is observed whose target is ahead of the ACB-branch's target, then we record this branch's target as the reconvergence point. We then validate the occurrence of the same reconvergence point on the next instance when the ACB-branch fetches the Taken direction, within the same N instruction limit, before confirming it as Type-2. If neither Type is confirmed, we leave the ACB-branch as unclassified.</p><p>If still unclassified, we finally try to learn it as Type-3 by inspecting the Taken path. If, within N instructions, we observe a taken branch whose target is before the ACB-branch, then we record this branch's target as the reconvergence point. We then validate the occurrence of the same reconvergence point on the next instance when the ACB-branch fetches the Not-Taken direction. Upon success, we confirm it as Type-3.</p><p>At any stage, if we exhaust the N instruction counting limit, we reset the Learning Table entry as a sign of nonconvergence. Upon confirmation of any Type, we copy the branch PC to a new ACB Table entry, along with the learned convergence information. We then vacate the corresponding Critical Table entry and reset the Learning Table entry. Based on the analysis in Section II-C1 and experimental sweeps, we found N = 40 to be optimal to cover large-body convergences that can be supported while being profitable with the given misprediction rate thresholds.</p><p>Criticality Confidence: We use a 32-entry, 2-way ACB Table (indexed by branch PCs) having a 6-bit saturating probabilistic-counter. All the meta-data needed to fetch both the paths upon ACB application on a targeted branch PC is also stored in this table entry (detailed composition in Table <ref type="table">I</ref>). Before ACB can dynamically predicate, we need to establish confidence in accordance with the trade-off described by Equation <ref type="formula">1</ref>. During learning, we record the combined body size of both paths that need to be fetched (encoded in 2 bits) and proportionally set the required misprediction rate m for this branch, using a static mapping of Body-Size-to-Misprediction-Rate (refer Table <ref type="table">I</ref>). The confidence counter in the ACB table is incremented for every mis-predicting instance of this branch that triggers a pipeline flush. It is decremented probabilistically by 1/M (where M = 1 m -1) on every correct prediction. When this counter becomes higher than 32 (half of its saturated value), we start applying ACB.</p><p>Convergence Confidence: While critical counter is less than 32, we use a single-entry Tracking Table to monitor the occurrence of the learned reconvergence point PC on both taken and not-taken paths for every fetched branch instance. If the learned convergence does not happen, we reset its confidence counter. This way we exclude branches from getting activated which tend to diverge more often. Despite low-associativity of ACB Table, we did not observe any major contention/thrashing issues. In our sensitivity studies, increasing its size from 32 to 256 had negligible effect on performance (since Learning Table acts as a filter for allocation from Critical Table to ACB Table ).  ). If the branch is Type-1 or Type-2, we override the branch predictor decision to first fetch the Not-Taken direction. If it is Type-3, we fetch the Taken direction first. If the convergence was Type-1, then we will naturally reach the PC for the point of convergence. For convergences of Type-2 and Type-3, we wait for fetching the Jumper branch which is predicted taken and whose target is our expected reconvergence point. One should note that this Jumper is allowed to be a different branch than what was seen during training. Having found the Jumper which will take us to the point of reconvergence, we now override the target of this Jumper branch to be either ACBbranch target (when first fetched direction is Not-Taken) or next PC after the ACB-branch (when first fetched direction is Taken). This step is needed to fetch the other path. Once the convergence PC is reached, present ACB Context is closed and we wait for another ACB-branch instance. The ACBbranch, Jumper branch, Reconvergence point and ACB-body instructions are all attached with a 3-bit identifier for OOO to identify and associate every predicated region with the corresponding ACB-branch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Run-Time Application</head><p>Occasionally, reconvergence point on either path may not be reached. In such cases the front-end only waits for a certain threshold (in terms of fetched instructions) beyond the allowed convergence distance after the ACB-branch; if convergence is not detected by then, we set the same 3-bit identifier to indicate divergence for this instance. When the OOO receives this signal, it forces a pipeline flush at the ACB-branch after it resolves itself. It continues fetching from the correct target normally thereafter. We also reset the confidence and the utility bits in the ACB Table to make it re-train. Since we train for convergence as well, divergence injected pipeline flushes are rare and do not hurt performance.</p><p>2) Effective Predication in the OOO: OOO uses the ACB identifiers set during fetch to handle the predicated region. ACB-branch is stalled at scheduling for dispatch until ei-ther the reconvergence-point or the divergence-identifier is received. This stalling of ACB-branch is needed since a failure in convergence implies incorrect fetching by ACB. To recover, we force a pipeline flush on diverging ACB-branch instances once their direction is known upon execution.</p><p>All instructions in the body of the ACB-branch are forced to add the ACB-branch as a source, effectively stalling them from execution until the ACB-branch has executed. Instructions post the reconvergence point are free to execute. If they have true data dependencies with any portion predicated by the ACBbranch, they will be naturally stalled by the OOO. Once ACB-branch executes, instructions on the predicated-true path execute normally. However, since predicated-false path was also allocated and OOO may have already added dependencies for predicated-true path with predicated-false path, we need to ensure Register Transparency beyond predicated-false path.</p><p>To achieve this aim, every instruction in the body of ACB that is a producer of some logical register or flags, also tracks the physical register corresponding to its logical destination. For example, an instruction of the type mov RAX, RBX will be tracking RAX (i.e. its destination) in the OOO. After ACBbranch resolution, if an ACB-body instruction is identified as belonging to the predicated-true path, we will execute it normally as a move from RBX to RAX. If it instead turns out as a predicated-false path instruction, then we will ignore the original operation and it will act as a special move from RAX to RAX: it copies the last correctly produced value of RAX to the register allocated to it for writing RAX. Since RAT provides us with the last writer to a given logical register during OOO allocation, we obtain the last written physical register ID from the RAT during register renaming. Hence, the predicated-false path is able to propagate the correct data for the live-outs it produces, making it effectively transparent. Any instruction on the predicated-false path, that does not produce register or flags (like stores or branches), instantly releases its resources.</p><p>Prior works <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref> have relied on select-micro-op based approaches to handle correctness of data dependencies after the predicated region. While using select-microops also allows the execution of the predicated region before the reconvergence point (unlike ACB which stalls it until ACB-branch resolution), it requires complex RAT forkand-merge on every predicated instance. This also causes frequent loss of performance-critical allocation bandwidth, which becomes more significant in future wider processors. ACB's design choices included the relatively simpler logicaldestination tracking approach. Using these less intrusive micro-architectural changes, we are able to achieve register transparency without resorting to complex RAT recovery mechanisms or re-execution as proposed in <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref>.</p><p>3) Predicated-False Path Loads/Stores: All ACB body loads and stores are stalled in the OOO-IQ until ACB resolves its direction. Memory disambiguation logic <ref type="bibr" target="#b19">[20]</ref> stalls on stores since their addresses are not computed yet. When the branch resolves, these are dispatched from IQ with predicatedtrue/false path information. Predicated-false path loads/stores are invalidated in Load-Store Queue (LSQ) and are excluded from matching addresses with younger loads. These invalidated loads/stores deallocate (upon retirement) without dispatching to caches/memory. Predicated-true path loads/stores participate in store-load forwarding within the LSQ and are dispatched normally. Dynamo: Like other predication strategies, ACB can have undesirable and dynamically varying side-effects on performance as analyzed in Section II-C. Hence, ACB requires run-time monitoring and throttling to optimize for performance and prevent inversions. However, performance can be affected by various diverse phenomena which, by tracking limited local heuristics, cannot be accurately evaluated. In fact, this is a generic problem that affects many other features which involve balancing costbenefit trade off to maximize performance.</p><p>We propose a novel dynamic monitoring (Dynamo) algorithm that monitors the run-time performance delivered by ACB. Dynamo is a first of its kind predictor that tracks actual performance and compares it with baseline performance. Figure <ref type="figure" target="#fig_5">5</ref> describes the various elements of Dynamo and their interactions. Dynamo assumes a 3-bit FSM-state for each entry in the ACB Table, with the possible states being NEUTRAL, GOOD, LIKELY-GOOD, LIKELY-BAD and BAD. FSM-state transitions happen for all entries together at every W retired instructions, which we call as one epoch. Entries reaching the final states (GOOD or BAD) do not undergo further transitions. Choosing a very small epoch-length will be highly susceptible to noisy IPC changes, whereas a very large observation window will not correctly evaluate the performance impact since major program phase change falling in this window might affect the overall IPC dominantly. Through experimental analysis, we found epoch-length of 8K to 32K instructions as optimal (16K chosen for best performance).</p><p>Dynamo computes the cycles taken to complete a given epoch using an 18 bit saturating counter. Allocation in the ACB Table initializes each entry with NEUTRAL state. For the odd-numbered epoch, Dynamo disables ACB for all the branches except those in GOOD state. In this epoch, the baseline performance would be observed. For the even-numbered epoch, Dynamo enables ACB for all the branches except those in BAD state. At the end of every odd-even pair of epochs, Dynamo checks the difference in cycles between the two.</p><p>If the cycles have increased due to enabling ACB beyond a thresholded factor, then it means that doing ACB for this set of unconfirmed branches is likely bad and Dynamo transitions the state of all the involved ACB-branches towards BAD. On the other hand, if the cycles have improved due to ACB, then Dynamo moves the state of all the involved ACB-branches towards GOOD. We found this cycle-change factor to be optimum at 1/8. Intuitively, a high threshold will be insensitive to subtle performance degradation by ACB whereas a low threshold will be susceptible to minor IPC changes because of changing program execution behavior.</p><p>To identify the ACB-branches responsible for affecting IPC in a given epoch, Dynamo also counts the per-instance activity of each ACB-branch in a 4 bit saturating Involvement Counter, which is incremented on every predicated dynamic instance. State transitions of activated ACBs are allowed only if their involvement counter is saturated. This prevents Dynamo from associating unrelated IPC fluctuations (or natural program phase changes) to its judgment of any activated ACB. To make it even more robust, Dynamo does not directly transition any branch to the final (GOOD or BAD) states. Instead it relies on observing positive or negative impacts of the branch consecutively to obtain a final decision regarding GOOD or BAD. Branches in GOOD state will perform ACB while those in BAD state are disabled henceforth. If the cycle-change factor is within allowed thresholds, then we do not update states in either direction and continue with the next epoch-pair.</p><p>It must be noted that multiple ACBs may be learned and simultaneously start getting applied in a given epoch. Dynamo evaluates IPC changes with and without all the actively working ACBs together since they eventually will be working alongside each other. Also, since program phase changes can potentially change the criticality of some branches, we wanted to give a fair chance to the blocked candidates to re-learn through Dynamo. So, we reset Dynamo state information for all entries periodically (?10 million retired instructions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Storage Requirement</head><p>Table I enlists all the tabular structures used by ACB. Aggregate storage required by ACB is just 386 bytes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. SIMULATION METHODOLOGY</head><p>We simulate an Out-of-Order x86-ISA core on a cycleaccurate simulator that accurately models the wrong path on branch mispredictions. Simulated core runs at 3.2 GHz and micro-architecture parameters are similar to Intel Skylake <ref type="bibr" target="#b0">[1]</ref> configuration. Detailed parameters enlisted in Table <ref type="table" target="#tab_1">II</ref>.</p><p>We experimented with 70 diverse, single-threaded workloads from different categories (details in Table <ref type="table" target="#tab_1">III</ref>). The performance is measured in instructions-per-cycle (IPC).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RESULTS</head><p>We first present the performance improvement by ACB on our workloads in Section V-A. We then evaluate the effectiveness of Dynamo as a throttling scheme in Section V-B. In Section V-C, we contrast ACB with state-of-the-art dynamic  predication approach. We evaluate ACB's performance on future OOO processors in Section V-D. Finally, we perform a qualitative analysis of ACB's effects on power in Section V-E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Performance Summary of ACB</head><p>Figure <ref type="figure" target="#fig_6">6</ref> summarizes the performance benefits of applying ACB. ACB gives an overall performance gain of 8.0% (geometric-mean) while providing an effective reduction in branch mis-speculations by 22% on average. Figure <ref type="figure" target="#fig_7">7</ref> shows a line graph correlating the performance improvement with reduction in pipeline flushes for all our studied workloads. We see that mis-speculation reduction correlates positively with the observed performance gains. The largest positive outlier (lammps) provides more than 2X speedup. Due to Dynamo's intervention, losses are contained within -5%. An interesting observation comes from the analysis of outliers like soplex (on the left-end of Figure <ref type="figure" target="#fig_7">7</ref>), where despite significant reduction in total mis-speculations, the performance gains are unexpectedly low. Here, the accounted branch mispredictions are not on the critical path of execution in the baseline itself. As seen in Section II-A, such mispredictions are not important for perfor-Benchmarks Category perlbench, bzip2, gcc, mcf, gobmk, hmmer, sjeng, libquantum, h264ref, omnetpp, astar, xalancbmk ISPEC <ref type="bibr" target="#b20">[21]</ref> bwaves, gamess, milc, zeusmp soplex, povray, calculix, gemsfdtd, tonto, lbm, wrf, sphinx3 gromacs, cactusADM, leslie3D, namd, deall, FSPEC <ref type="bibr" target="#b20">[21]</ref> catcubssn, lbm, cam4, pop2, imagick, nab, roms, perlbench, gcc, mcf, omnetpp, xalancbmk, x264, deepsjeng, leela, exchange, xz SPEC17 <ref type="bibr" target="#b21">[22]</ref> winzip, photoshop, sketchup, premiere SYSmark <ref type="bibr" target="#b22">[23]</ref> tabletmark <ref type="bibr" target="#b23">[24]</ref>, geekbench <ref type="bibr" target="#b24">[25]</ref>, compression, 3dmark <ref type="bibr" target="#b25">[26]</ref>, eembc <ref type="bibr" target="#b26">[27]</ref>, chrome Client lammps <ref type="bibr" target="#b27">[28]</ref>, parsec <ref type="bibr" target="#b28">[29]</ref> Server mance. Another side-effect of ACB is noticeable in the largest negative outlier (omnetpp), where the mis-speculations slightly increase after applying ACB. This relates to Section II-C2 as ACB overrides the branch predictor decision consistently (to fetch both paths), causing the branch history to get modified. This starts affecting the BPU's predictability for some other branches due to correlation effects. These outliers represent those scenarios where the newly manifested mispredictions cannot be helped by ACB due to its selective coverage. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Analysis of Dynamo</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 8 compares ACB's performance with and without</head><p>Dynamo for all workloads. Dynamo brings up native ACB's performance from 6.7% to 8.0%. Without Dynamo, the largest negative outliers (eembc and SPEC-h264) suffer nearly 20% performance loss, strongly exhibiting the negative impacts of non-judicious predication. Dynamo helps throttle out harmful ACB-able PCs in such cases helping recover performance.</p><p>Prior to Dynamo, we also experimented with execution stalls (i.e. waiting for dispatch at issue queue) counting based simpler metric, since predication primarily creates additional data-dependencies. But in few cases, we observed that despite high stall counts, performing predication was favorable as saved pipeline flushes outweighed the additional stalls incurred. This was also vulnerable to bad tuning. Dynamo was designed to holistically evaluate this trade-off for ACB.  In this section, we compare against Diverge-Merge Processor (DMP) <ref type="bibr" target="#b6">[7]</ref>, which relies on changes to the compiler, ISA and micro-architecture to perform selective predication on low confidence branch predictions. We modeled the enhanced DMP <ref type="bibr" target="#b14">[15]</ref>, which improved upon the DMP solution through profile-assisted compiler techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Comparison with Prior Compiler-based Solutions</head><p>Figure <ref type="figure" target="#fig_8">8</ref> compares the performance of ACB (both with and without Dynamo) and DMP. ACB and DMP both produce impressive positive outliers (category A). Workloads marked as B1 and B2 are the cases of DMP outperforming ACB. The category B1 benefits from DMP's multiple reconvergence point support by compiler assisted convergence detection. ACB can be enhanced to support the same by actively learning and allocating multiple reconvergence points in ACB Table . For category B2, ACB's approach of stalling both the paths reduces its performance gains compared to DMP which eagerly executes the predicated region before the branch resolves itself. DMP achieves this with the help of select-micro-ops based micro-architecture. We experimented with adding selectmicro-op support to ACB which improves ACB's performance gains by only about 0.2%. Since Dynamo already throttles negative outliers, this scheme only helps the positive gainers slightly. This trade-off justifies ACB's logical-destination tracking approach to save hardware complexity (RAT and fetch forking). Workloads marked as C in Figure <ref type="figure" target="#fig_8">8</ref> suffer from negative performance impact for both DMP and ACB without Dynamo. This clearly highlights the utility of dynamic performance monitoring. In these workloads, both ACB and DMP qualify similar set of branches to be predicated. Despite ACB's stricter qualification constraints, these branches incur more costs by creating data-dependency based stalls in the OOO (as explained in Section II-C3). With Dynamo we are able to identify and block such delinquent candidates. While enhanced-DMP also has a detailed cost-benefit analysis through static compiler-profiling, the work itself acknowledges its limitation in being able to account for only fetch related costs and not execution related costs <ref type="bibr" target="#b14">[15]</ref>. Compiler-based techniques are also susceptible to inefficiencies arising from differences between input sets used for profiling and actual execution.</p><p>Figure <ref type="figure" target="#fig_9">9</ref> focuses only on Category D and E workloads, showing a correlation between mis-speculation ratio and performance over baseline. There is a significant increase in branch mispredictions by applying DMP. This may seem surprising at first, but as we had reasoned in Section II, predication (DMP or ACB) changes the branch history that is being learned by the branch predictor. It is well known that speculative update of the branch history is very important for branch predictor accuracy <ref type="bibr" target="#b29">[30]</ref>. In the baseline, branch history is always speculatively updated, assuming the previous branch predictions were correct. When a branch mispredicts, a pipeline flush happens and subsequent branches that are re-fetched use the updated branch history. Hence, branch history is always up-to-date for all valid predictions (except on the wrong path, that is eventually flushed out). However, when a branch is dynamically predicated, subsequently fetched branches do not have any knowledge of the predicated branch's direction, since no real prediction happened for it. They will know the direction only upon branch resolution of DMPed branch in OOO. By that time branch predictions have already happened and front-end has moved ahead, making it impossible to correct predictions for these branches.</p><p>In case of ACB, we remove all ACB predicated instances from the branch history, so the branch predictor adapts itself to predict without the knowledge of the ACB-ed branch. However in DMP, based on the branch confidence some instances are predicated and others are not. This effectively means that many more possible branch histories are possible, including wrong branch history. Recall that the TAGE branch predictor <ref type="bibr" target="#b1">[2]</ref> allocates a higher branch history prediction table on every misprediction, and the presence of unstable branch histories results in severe thrashing of the tables. This badly effects the baseline accuracy of the predictor, not just for the target branch but also other branches. Also as described in Section II, many branches are perfectly correlated with older branches, and if the older branch is removed from the branch history by predication, they lose their accuracy.</p><p>DMP uses compile time profiling to pick the target H2P branches. Unfortunately the application of DMP at runtime changes the branch predictor behavior in some applications, rendering the compile time profiling sub-optimal and causing performance inversions in category D and E. To validate this hypothesis, we ran category D and E workloads with an oracle update of branch history and compared it to DMP and ACB performance in Figure <ref type="figure" target="#fig_9">9</ref>. As is evident from Figure <ref type="figure" target="#fig_9">9</ref>, DMP-PBH (oracle with perfect branch history), recovers most of the losses for category D, and reduces mispredictions over baseline. A similar observation was made by Klauser et al. <ref type="bibr" target="#b10">[11]</ref> for branch history update and dynamic predication. Interestingly, Category E workloads are still not optimal even with the perfect branch history. Figure <ref type="figure" target="#fig_10">10</ref> correlates their performance with increase in allocation stalls of the OOO processor. Even though these workloads reduce mispredictions, in presence of perfect branch history, they suffer from allocation stalls because of data dependencies with select-uops beyond the reconvergence point. A throttling mechanism like Dynamo is needed for such cases.</p><p>Comparison against DHP: Unlike DMP, DHP <ref type="bibr" target="#b10">[11]</ref> performs predication only on simple and short hammocks, targeting minimal cost of fetching the additional path as compared to speculation. Limited by its simplicity of application, DHP cannot cover complex, non-traditional control flows which lead to convergence. On average, ACB delivers (8.0%) nearly double the performance of DHP (4.3%). Figure <ref type="figure" target="#fig_11">11</ref> illustrates this performance difference on a per-workload basis, clearly highlighting the impact of difference in targeted coverage. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Effect of Core Scaling</head><p>Simulations on a scaled-up version of the present configuration (8-wide with twice the execution/fetch resources) showed that performance of ACB improves to 8.6% owing to a wider and deeper processor amplifying the problem of inefficiency due to mispredictions. This also highlights ACB's improved efficiency and robustness in tackling branch mis-speculations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Qualitative Power Analysis</head><p>ACB reduces pipeline flushes by 22% leading to reduction in the number of speculative OOO allocations. While ACB also allocates additional instructions in OOO for the wrong fetched path, our analysis reveals that ACB effectively reduces the total number of OOO allocations by 5%, which naturally translates to reduction in energy consumption.</p><p>Since tabular structures used by ACB are small and are looked up only for branches, the front-end power increment is insignificant. Additionally, one must note that mispredictions cost power not just through pipeline flushes, but also through re-execution of already executed (and correct) controlindependent instructions. Each eliminated misprediction tributes to energy savings by preventing this wastage of work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. RELATED WORK</head><p>Software predication has been studied extensively in the past <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>. Popular ISAs support static predication <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref> but due to large overheads, the realistic benefits are diminished <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b11">[12]</ref>. Wish Branches <ref type="bibr" target="#b11">[12]</ref> rely on the compiler to supply predicated code but applies predication dynamically only on less predictable instances. Dynamic Hammock Predication <ref type="bibr" target="#b10">[11]</ref> targets only small, simple hammocks. Hyperblock predication <ref type="bibr" target="#b32">[33]</ref> uses compiler profiling to predicate frequently occurring basic blocks. Generalized multipath execution was proposed in <ref type="bibr" target="#b33">[34]</ref>- <ref type="bibr" target="#b35">[36]</ref>. Diverge-Merge Processor (DMP) <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b14">[15]</ref> uses branch prediction confidence to selectively predicate conditional branches, while using the compiler for convergence and branch selection information. DMP outperformed previous schemes and was the focus of our comparison. Joao et al. <ref type="bibr" target="#b36">[37]</ref> extended dynamic predication to indirect branches. Stephenson et al. <ref type="bibr" target="#b37">[38]</ref> proposed another compiler based approach to simplify prior hardware complexity needed for enforcing correct dependence flow in predication. Their targeted hammocks are restricted by having specific register writing patterns in the predicated region, which are provided by the compiler. As examined in Section II-C and comparatively analyzed in Section V-C, prior works do not fully comprehend the delicate performance trade-offs created by disabling speculation causing performance inversions in certain scenarios. Additionally, they need significant changes to hardware, compiler and ISA, making their implementation challenging. In contrast, ACB is a pure hardware solution.</p><p>Several mechanisms exploiting control independence <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref> also exist which perform selective flush on a branch misspeculation wherein only the control dependent instructions are flushed and re-executed. In contrast to ACB, these techniques require complex hardware to remove, re-fetch and reallocate the selectively flushed instructions, along with complicated methods to correct data dependencies post pipeline flush. Skipper <ref type="bibr" target="#b40">[41]</ref> proposed out-of-order fetch-and-execute of instructions post-control flow convergence to exploit control independence but required large area (about 6KB) for supporting its learning and application. SYRANT <ref type="bibr" target="#b41">[42]</ref> simplified this approach by targeting only converging conditional branches and smarter reservation of OOO resources. However, it is limited in application only to consistently behaving branches. Control Flow Decoupling (CFD) <ref type="bibr" target="#b7">[8]</ref> is a branch pre-computation based solution which modifies the targeted branches by separating the control-dependent and controlindependent branch body using the compiler. Hardware then does an early resolution of the control flow removing the need for branch prediction. Store-Load-Branch (SLB) Predictor <ref type="bibr" target="#b42">[43]</ref> is an adjunct branch predictor which improves accuracy by targeting data-dependent branches whose associated loads are memory-dependent upon stores. It detects dependency between stores, loads and branches using compiler and modifies hardware to override branch prediction with available precomputed outcomes. ACB is applicable on top of any baseline branch predictor, including SLB.</p><p>Rotenberg et al. <ref type="bibr" target="#b43">[44]</ref> proposed a hardware to detect only forward convergence scenarios. Collins et al. <ref type="bibr" target="#b44">[45]</ref> proposed detecting any type of reconvergence. Their mechanism identifies the common patterns of convergence and adds dedicated hardware to the backend to simultaneously learn the different reconvergence points of different branches, all at once, by broadcasting the PCs of instructions being retired. As a result it requires significant area (nearly 4KB) and much more complex implementation. In contrast, ACB is extremely light-weight with the overall mechanism needing just 386 bytes, including the reconvergence detection hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. SUMMARY</head><p>In this paper, we have presented ACB, a lightweight mechanism and completely implementable in hardware, that intelligently disables speculation by dynamic predication of only selective critical branches, thereby mitigating some of the costly pipeline flushes because of wrong speculation. ACB uses a combination of program criticality directed selection of hard-to-predict branches and a runtime monitoring of performance to overcome the undesirable side-effects of disabling speculation. Micro-architecture solutions invented for ACB, like convergence detection and dynamic performance monitor, can have far reaching effects on future micro-architecture research. Our results on a diverse set of workloads show that ACB is a power-and-performance feature that delivers 8% average performance gain while reducing power consumption. ACB also scales seamlessly to future out-of-order processors and continues to deliver high performance at lower power.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (a) demonstrates change in the critical path due to extra-allocation by predication through a Data-Dependency-Graph (defined by Fields et al. [16]). (b) gives an example of a perfectly correlating branch following a predicated branch. (c) shows an example where a critical long-latency load is dependent on a predicated branch outcome. (Instructions in (b) and (c) have right-most logical register as destination.)</figDesc><graphic url="image-1.png" coords="4,63.56,69.00,228.36,131.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 (</head><label>2</label><figDesc>b) shows a sample program where branch B1 frequently mispredicts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Three Types (left-most three) categorized by ACB's dynamic convergence detection algorithm. Other complex convergence patterns (right-most two) can also be condensed into the same set of Types.</figDesc><graphic url="image-4.png" coords="5,63.72,71.71,391.27,156.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. By interchanging the perspective of branch and its target for backwardgoing branches, we classify among the same set of Types.</figDesc><graphic url="image-6.png" coords="6,63.32,72.00,232.68,93.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>1 )</head><label>1</label><figDesc>Fetching the Taken and Not-Taken Paths: After learning branches that are candidates for ACB, we need to fetch both directions for predicated branches at run-time. Upon fetching every dynamic branch instance whose PC has reached confidence in the ACB Table, we open an ACB Context that records the target of the branch (from the Branch Target Array), and the reconvergence point (from the ACB Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Finite State Machine for Dynamo.</figDesc><graphic url="image-8.png" coords="7,466.87,139.71,91.91,129.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. All workloads (category-wise) results for ACB.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. ACB's mis-speculation and performance ratio over baseline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Comparison of ACB against DMP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. DMP and Oracle DMP (DMP-PBH) for Categories D and E.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Allocation stalls comparison for Category E workloads.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Comparison of ACB against DHP. DHP has lower coverage and hence many workloads do not show sensitivity to it.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II CORE</head><label>II</label><figDesc>PARAMETERS USED IN OUR SIMULATOR.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>Study list used is described in Section IV.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Authorized licensed use limited to: University of Wollongong. Downloaded on July 18,2020 at 16:24:49 UTC from IEEE Xplore. Restrictions apply.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Inside 6th-generation intel core: New microarchitecture code-named skylake</title>
		<author>
			<persName><forename type="first">J</forename><surname>Doweck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mandelblat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rahatekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rappoport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rotem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yasin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yoaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="52" to="62" />
			<date type="published" when="2017-03">Mar 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A new case for the tage branch predictor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
		<idno type="DOI">10.1145/2155620.2155635</idno>
		<ptr target="http://doi.acm.org/10.1145/2155620.2155635" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO-44</title>
		<meeting>the 44th Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO-44<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="117" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A 64-kbytes ittage indirect branch predictor</title>
	</analytic>
	<monogr>
		<title level="m">Third Championship Branch Prediction (JWAC-2)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The inner most loop iteration counter: A new dimension in branch history</title>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Miguel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Albericio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 48th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)</title>
		<imprint>
			<date type="published" when="2015-12">Dec 2015</date>
			<biblScope unit="page" from="347" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dynamic branch prediction with perceptrons</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings HPCA Seventh International Symposium on High-Performance Computer Architecture</title>
		<meeting>HPCA Seventh International Symposium on High-Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2001-01">Jan 2001</date>
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An analysis of hard to predict branches</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ozturk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sendag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE International Symposium on Performance Analysis of Systems Software (ISPASS)</title>
		<imprint>
			<date type="published" when="2010-03">March 2010</date>
			<biblScope unit="page" from="213" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Diverge-merge processor (dmp): Dynamic predicated execution of complex control-flow graphs based on frequently executed paths</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Joao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2006 39th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO&apos;06)</title>
		<imprint>
			<date type="published" when="2006-12">Dec 2006</date>
			<biblScope unit="page" from="53" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Control-flow decoupling</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tuck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rotenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 45th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2012-12">Dec 2012</date>
			<biblScope unit="page" from="329" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">High-performance throughput computing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Caprioli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tremblay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="32" to="45" />
			<date type="published" when="2005-05">May 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Conversion of control dependence to data dependence</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Porterfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Warren</surname></persName>
		</author>
		<idno type="DOI">10.1145/567067.567085</idno>
		<ptr target="http://doi.acm.org/10.1145/567067.567085" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages, ser. POPL &apos;83</title>
		<meeting>the 10th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages, ser. POPL &apos;83<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1983">1983</date>
			<biblScope unit="page" from="177" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dynamic hammock predication for non-predicated instruction set architectures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Klauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grunwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=522344.825698" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1998 International Conference on Parallel Architectures and Compilation Techniques, ser. PACT &apos;98</title>
		<meeting>the 1998 International Conference on Parallel Architectures and Compilation Techniques, ser. PACT &apos;98<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page">278</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Wish branches: Combining conditional branching and predication for adaptive predicated execution</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO.2005.38</idno>
		<ptr target="https://doi.org/10.1109/MICRO.2005.38" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO 38</title>
		<meeting>the 38th Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO 38<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="43" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Restricted dual path execution</title>
		<author>
			<persName><forename type="first">T</forename><surname>Heil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Farrens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tyson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Selective dual path execution</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Heil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Profile-assisted compiler support for dynamic predication in diverge-merge processors</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Joao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Code Generation and Optimization (CGO&apos;07)</title>
		<imprint>
			<date type="published" when="2007-03">March 2007</date>
			<biblScope unit="page" from="367" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Focusing processor policies via critical-path prediction</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fields</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bodik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 28th Annual International Symposium on Computer Architecture</title>
		<meeting>28th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2001-06">June 2001</date>
			<biblScope unit="page" from="74" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Intel 64 and ia-32 architectures optimization reference manual</title>
		<ptr target="https://software.intel.com/sites/default/files/managed/9e/bc/64-ia-32-architectures-optimization-manual.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Arm instruction set version 1.0 reference guide</title>
		<idno>100076 0100 00 en.pdf</idno>
		<ptr target="https://static.docs.arm.com/100076/0100/" />
		<imprint/>
	</monogr>
	<note>arm instruction set reference guide</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The microarchitecture of intel, amd and via cpus: An optimization guide for assembly programmers and compiler makers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fog</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2" to="29" />
		</imprint>
		<respStmt>
			<orgName>Copenhagen University College of Engineering</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Scalable hardware memory disambiguation for high ilp processors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sethumadhavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Desikan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Keckler</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=956417.956553" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO 36</title>
		<meeting>the 36th Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO 36<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page">399</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Spec cpu2006 benchmark descriptions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Henning</surname></persName>
		</author>
		<idno type="DOI">10.1145/1186736.1186737</idno>
		<ptr target="http://doi.acm.org/10.1145/1186736.1186737" />
	</analytic>
	<monogr>
		<title level="j">SIGARCH Comput. Archit. News</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2006-09">Sep. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A workload characterization of the spec cpu2017 benchmark suite</title>
		<author>
			<persName><forename type="first">A</forename><surname>Limaye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Adegbija</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)</title>
		<imprint>
			<date type="published" when="2018-04">April 2018</date>
			<biblScope unit="page" from="149" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Sysmark 2018 -bapco</title>
		<ptr target="http://bapco.com/wp-content/uploads/2018/08/SYSmark2018WhitePaper1.0.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Tabletmark 2017 -white paper</title>
		<ptr target="https://bapco.com/wp-content/uploads/2017/02/TabletMark-2017-WhitePaper-1.0.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Geekbench 4 cpu workloads</title>
		<ptr target="https://www.geekbench.com/doc/geekbench4-cpu-workloads.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">3dmark 11 -the gamer&apos;s benchmark for directx 11whitepaper</title>
		<ptr target="http://s3.amazonaws.com/download-aws.futuremark.com/3DMark11Whitepaper.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A benchmark characterization of the eembc benchmark suite</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Poovey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Conte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gal-On</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="18" to="29" />
			<date type="published" when="2009-09">Sep. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">A quick tour of lammps</title>
		<ptr target="https://lammps.sandia.gov/workshops/Aug15/PDF/tutorialPlimpton.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The parsec benchmark suite: Characterization and architectural implications</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bienia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2008 International Conference on Parallel Architectures and Compilation Techniques (PACT)</title>
		<imprint>
			<date type="published" when="2008-10">Oct 2008</date>
			<biblScope unit="page" from="72" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The effect of speculative updating branch history on branch prediction accuracy, revisited</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Po-Yung</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MICRO-27. The 27th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>MICRO-27. The 27th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="1994-11">Nov 1994</date>
			<biblScope unit="page" from="228" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Using predicated execution to improve the performance of a dynamically scheduled machine with speculative execution</title>
		<author>
			<persName><forename type="first">P.-Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Chang</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=224659.224698" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IFIP WG10.3 Working Conference on Parallel Architectures and Compilation Techniques, ser. PACT &apos;95</title>
		<meeting>the IFIP WG10.3 Working Conference on Parallel Architectures and Compilation Techniques, ser. PACT &apos;95<address><addrLine>Manchester, UK, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="99" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A framework for balancing control flow and predication</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>August</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mahlke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 30th Annual International Symposium on Microarchitecture</title>
		<meeting>30th Annual International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="1997-12">Dec 1997</date>
			<biblScope unit="page" from="92" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Effective compiler support for predicated execution using the hyperblock</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mahlke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Hank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Bringmann</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=144953.144998" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Annual International Symposium on Microarchitecture</title>
		<meeting>the 25th Annual International Symposium on Microarchitecture<address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="45" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multipath execution: Opportunities and limits</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Skadron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.1145/277830.277854</idno>
		<ptr target="http://doi.acm.org/10.1145/277830.277854" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Supercomputing, ser. ICS &apos;98</title>
		<meeting>the 12th International Conference on Supercomputing, ser. ICS &apos;98<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="101" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Instruction fetch mechanisms for multipath execution processors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Klauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grunwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd Annual ACM/IEEE International Symposium on Microarchitecture</title>
		<meeting>the 32nd Annual ACM/IEEE International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="1999-11">Nov 1999</date>
			<biblScope unit="page" from="38" to="47" />
		</imprint>
	</monogr>
	<note>in MICRO-32</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Selective eager execution on the polypath architecture</title>
		<author>
			<persName><forename type="first">A</forename><surname>Klauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Paithankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grunwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 25th Annual International Symposium on Computer Architecture (Cat. No.98CB36235)</title>
		<meeting>25th Annual International Symposium on Computer Architecture (Cat. No.98CB36235)</meeting>
		<imprint>
			<date type="published" when="1998-07">July 1998</date>
			<biblScope unit="page" from="250" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Dynamic predication of indirect jumps</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Joao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Architecture Letters</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="4" />
			<date type="published" when="2008-01">Jan 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Lightweight predication support for out of order processors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stephenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rangan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE 15th International Symposium on High Performance Computer Architecture</title>
		<imprint>
			<date type="published" when="2009-02">Feb 2009</date>
			<biblScope unit="page" from="201" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Spf: Selective pipeline flush</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Kothinti Naresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Cain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE 36th International Conference on Computer Design (ICCD)</title>
		<imprint>
			<date type="published" when="2018-10">Oct 2018</date>
			<biblScope unit="page" from="152" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Reducing branch misprediction penalty via selective branch recovery</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Akkary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Srinivasan</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2004.10004</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2004.10004" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Symposium on High Performance Computer Architecture, ser. HPCA &apos;04</title>
		<meeting>the 10th International Symposium on High Performance Computer Architecture, ser. HPCA &apos;04<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">254</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Skipper: a microarchitecture for exploiting control-flow independence</title>
		<author>
			<persName><forename type="first">Chen-Yong</forename><surname>Cher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Vijaykumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 34th ACM/IEEE International Symposium on Microarchitecture</title>
		<meeting>34th ACM/IEEE International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2001-12">Dec 2001</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="4" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Syrant: Symmetric resource allocation on not-taken and taken paths</title>
		<author>
			<persName><forename type="first">N</forename><surname>Premillieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
		<idno type="DOI">10.1145/2086696.2086722</idno>
		<ptr target="http://doi.acm.org/10.1145/2086696.2086722" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Archit. Code Optim</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="43" />
			<date type="published" when="2012-01">Jan. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Store-load-branch (slb) predictor: A compiler assisted branch prediction for data dependent branches</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">U</forename><surname>Farooq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Khubaib</surname></persName>
		</author>
		<author>
			<persName><surname>John</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE 19th International Symposium on High Performance Computer Architecture (HPCA)</title>
		<imprint>
			<date type="published" when="2013-02">Feb 2013</date>
			<biblScope unit="page" from="59" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Control independence in trace processors</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rotenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO-32. Proceedings of the 32nd Annual ACM/IEEE International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="1999-11">Nov 1999</date>
			<biblScope unit="page" from="4" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Control flow optimization via dynamic reconvergence prediction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">37th International Symposium on Microarchitecture (MICRO-37&apos;04)</title>
		<imprint>
			<date type="published" when="2004-12">Dec 2004</date>
			<biblScope unit="page" from="129" to="140" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
