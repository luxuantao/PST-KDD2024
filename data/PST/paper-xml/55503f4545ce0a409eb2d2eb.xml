<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Experience with using the Parallel Workloads Archive</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-07-05">5 July 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">J</forename><surname>Parallel</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Distrib</forename><surname>Comput</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dror</forename><forename type="middle">G</forename><surname>Feitelson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The Hebrew University</orgName>
								<address>
									<postCode>91904</postCode>
									<settlement>Jerusalem</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dan</forename><surname>Tsafrir</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Technion -Israel Institute of Technology</orgName>
								<address>
									<postCode>32000</postCode>
									<settlement>Haifa</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Krakov</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The Hebrew University</orgName>
								<address>
									<postCode>91904</postCode>
									<settlement>Jerusalem</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">.swf</orgName>
								<orgName type="laboratory">Log Period Months PEs Users Jobs Util. File Cleaned NASA iPSC</orgName>
								<orgName type="institution">NASA-iPSC</orgName>
								<address>
									<addrLine>10/93-12/93 3 128 69 42</addrLine>
									<postCode>264 0.47, 1993-3</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="laboratory">LANL</orgName>
								<address>
									<addrLine>CM5 10/94-09/96 24 1, 024 213 201</addrLine>
									<postCode>387 0.75</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="laboratory">LANL</orgName>
								<orgName type="institution">SDSC</orgName>
								<address>
									<addrLine>Par95 12/94-12/95 12 400 98 76, SDSC-Par-1995-3.swf yes SDSC Par96 12/95-12/96 12 400 60 38, 719 0.76 SDSC-Par-1996-3.swf yes CTC SP2 06/96-05/97 11 338 679 79, 302 0.85 CTC-SP2-1996-3.swf yes KTH SP2 09/96-08/97 11 100 214 28</addrLine>
									<postCode>CM5-1994-4, 872 0.72, 489 0.70</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">KTH</orgName>
								<address>
									<postBox>.swf SDSC SP2 04/98-04/00 24 128 437 73</postBox>
									<postCode>SP2-1996-2, 496 0.84</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="laboratory">LANL-O2K</orgName>
								<orgName type="institution">SDSC</orgName>
								<address>
									<addrLine>048 337 122, 1999-2.swf OSC cluster 01/00-11/01 22 178 254 80, 714 0.14 OSC-Clust-2000-3.swf yes SDSC Blue 04/00-01/03 32 1,152 468 250</addrLine>
									<postCode>SP2-1998-4.swf, LANL O2K 11/99-04/00 5 2, 233 0.70, 440 0.77</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution">SDSC-BLUE</orgName>
								<address>
									<addrLine>2000-4.swf yes Sandia Ross 11, 37 1, 524 204 85, 355 0.50 Sandia-Ross-2001-1.swf HPC2N 07/02-01/06 42 240 258 527</addrLine>
									<postCode>01-01/05, 371 0.70, HPC2N-2002-2</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="institution">SDSC</orgName>
								<address>
									<addrLine>Datastar 03, 13 1, 664 460 96</addrLine>
									<postCode>04-04/05, 089 0.63</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="institution">SDSC-DS</orgName>
								<address>
									<addrLine>2004-2.swf SHARCNET 12/05-01/07 13 6, 828 412 1, 195,242 n/a SHARCNET-2005-2.swf LLNL uBGL 11/06-06/07 7 2, 048 62 112, 611 0.56 LLNL-uBGL-2006-2.swf LLNL Atlas 11/06-06/07 8 9, 216 132 60</addrLine>
									<postCode>332 0.64</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<orgName type="institution" key="instit1">LLNL-Atlas</orgName>
								<orgName type="institution" key="instit2">LLNL</orgName>
								<address>
									<addrLine>Thunder 01/07-06/07 5 4, 008 283 128, 662 0.88 LLNL-Thunder-2007-1.swf yes MetaCentrum 12/08-06/09 7 806 147 103, 656 0.36 METACENTRUM-2009-2.swf ANL Intrepid 01, 840 236 68, 936 0.60 ANL-Intrepid-2009-1.swf PIK IPLEX 04/09-07/12 40 2, 965 0.38 PIK-IPLEX-2009-1.swf RICC 05/10-09/10 5 8, 192 176 447, 794 0.87 RICC-2010-2.swf CEA Curie 02/11-10/12 20 93</addrLine>
									<postCode>2006-2, 09-09/09 8 163, 560, 225 742, 312 722, 773, 138 0.29</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Experience with using the Parallel Workloads Archive</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-07-05">5 July 2014</date>
						</imprint>
					</monogr>
					<idno type="MD5">AAB8AE23D6C48B01EE332274E79AA2A3</idno>
					<idno type="DOI">10.1016/j.jpdc.2014.06.013</idno>
					<note type="submission">Received 14 October 2012 Received in revised form 29 May 2014 Accepted 25 June 2014</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Workload log Data quality Parallel job scheduling</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>h i g h l i g h t s</head><p>• Reliable performance evaluations require reliable data about workloads.</p><p>• Workload logs may have data quality problems despite being automatically generated.</p><p>• Finding data quality problems is hard and findings must be reported.</p><p>• In some cases data quality can be improved e.g. by filtering dubious data.</p><p>• Such data analysis and cleaning is an important component of the scientific method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The study and design of computer systems requires good data regarding the workload to which these systems are subjected, because the workload has a decisive effect on the observed performance <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b37">38]</ref>. As an example, consider the question of scheduling parallel jobs on a large-scale cluster or supercomputer. As each job may require a different number of processors, this is akin to bin packing <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b47">48]</ref>. Hence the best scheduling algorithm may depend on the distribution of job sizes, or on the possible correlation between job size and runtime <ref type="bibr" target="#b26">[27]</ref>.</p><p>But how can we know what the distribution is going to be? The common approach is to collect data logs from existing systems and to assume that future workloads will be similar. The Parallel Workloads Archive, whose data is the focus of this paper, is a repository of such logs; it is accessible at URL www. cs.huji.ac.il/labs/parallel/workload/. The archived logs (see Table <ref type="table">1</ref>) contain accounting data about the jobs that executed on parallel supercomputers, clusters, and grids, which is necessary in order to evaluate schedulers for such systems. These logs have been used in many hundreds of research papers since the archive was started in 1999. Fig. <ref type="figure">1</ref> shows the accumulated number of hits that the Parallel Workload Archive gets when searching for it in Google Scholar (supplemented by the number of hits associated with the Grid Workloads Archive <ref type="bibr" target="#b20">[21]</ref>, which serves a similar purpose). The high citation count bears witness to the need for such data in the Fig. <ref type="figure">1</ref>. Accumulated yearly number of hits received when searching for the Parallel Workloads Archive (PWA) and the Grid Workloads Archive (GWA) in Google Scholar as of 28 October 2013. GWA contains those logs from PWA that pertain to grid systems, as well as a few other grid logs. The query used was ''Parallel Workload(s) Archive'' (both singular and plural) and the archive's URL, and likewise for the grid archive. Papers that cite both archives are only counted once in ''both''. research community and highlights the importance of using the data judiciously.</p><p>At first blush it seems that accounting logs should provide reliable and consistent data. After all, this is just a mechanistic and straightforward recording of events that happened on a computer system (as opposed to, say, genome data, which is obtained via complex experimental procedures that lead to intrinsic errors <ref type="bibr" target="#b29">[30]</ref>). But upon inspection, we find that the available logs are often deficient. This is not a specific problem with the data that is available to us. All such logs have data quality problems, and in fact the logs available in the Parallel Workloads Archive actually represent relatively good data. We have additional logs that were never made public in the archive because an initial investigation found the data contained in them to be so lacking.</p><p>The issue of data quality has a long history (the International Conference on Information Quality has been held annually since 1996). The most general definition of data quality is ''fitness for use'', implying that it is not an objective but rather a contextsensitive attribute <ref type="bibr" target="#b43">[44]</ref>. Indeed, work on data quality has identified no less than 20 dimensions of data quality, the top five of which are accuracy, consistency, security, timeliness, and completeness <ref type="bibr" target="#b22">[23]</ref>. In the context of computer systems, practically all discussions have been about the quality of data handled by the system, e.g. the data contained in enterprise databases <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b27">28]</ref>. Low quality data has been blamed for bad business decisions, lost revenue, and even implicated in catastrophes leading to the loss of human life <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b30">31]</ref>. The quality of data in scientific repositories, such as biological genome data, has also been studied, both to assess the quality of existing repositories and to suggest ways to improve data quality <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b29">30]</ref>. Likewise, there have been problems with repositories used for empirical software engineering research; for example, massive repetitions of records taint evaluations of learning schemes that attempt to identify defective modules, by causing overlaps between the training and test datasets <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b33">34]</ref>.</p><p>At the same time, there has been little if any work on the quality of data describing computer systems, such as workload data. In this paper we report on our experience with the data available in the Parallel Workloads Archive. We start the discussion by considering log formats in Section 2. The main problem here is representational aspects of data quality, where the same field in different logs may have slightly different semantics. The bulk of the paper is contained in Section 3, which lists and classifies known problems in the different logs. These are mainly intrinsic correctness problems, such as inconsistency (redundant data fields should not contradict each other), errors (data should not imply that the number of processors being used at a certain instant is larger than the number available in the machine), and missing data in certain records and fields. In addition, there are problems of representativeness, as when logs include high-volume abnormal activity by a small set of users. Due to the data quality problems we have found, using log data as-is (even as input to a statistical analysis) might lead to unreliable results. Section 4 then outlines actions that we have taken to improve data quality and make the logs more useful. The conclusions are presented in Section 5, and include a perspective of our work in relation to the work on data quality in other domains.</p><p>The main contribution of this work is to promote solid experimental work on the evaluation of parallel systems, and to strengthen the scientific basis of such studies. Science is based, among other things, on observation. The experimental procedures used to obtain data are an important part of any science. Regrettably, Computer Science lags behind in this respect, and we do not have a data-driven culture as in other fields <ref type="bibr" target="#b7">[8]</ref>. In particular, researchers are often unaware of data quality issues. This paper is dedicated to improving this situation by recording the considerations behind the procedures that were used to handle the data made available in the Parallel Workloads Archive. These procedures represent over a decade of research on data quality issues in these logs, including the identification of many unexpected problems. The evaluation of the data is also important in order to provide context for the hundreds of papers that use this data, and to validate the data on which they are based. It should be noted that the procedures we use are non-trivial and not self evident. By publicizing them, we hope to also initiate a debate about data quality and data cleaning in experimental computer systems research, a subject which has not received sufficient attention to date.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Log formats</head><p>A pre-requisite for analyzing logs is being able to parse them. In some classes of systems, such as web servers, standard log formats have been defined. Regrettably, there is no such standard for parallel job schedulers, and each one has defined its own format with its own idiosyncrasies. To ease work with the logs, we defined a Standard Workload Format 1 for use in the archive <ref type="bibr" target="#b2">[3]</ref>. This format was proposed by David Talby and refined through discussions with James Patton Jones and others.</p><p>The considerations applied in designing the standard format included the following.</p><p>• It should be easy to parse. The chosen format is an ASCII file with one line per job, space-separated fields, and exclusive use of numerical values (that is, no strings and special date or time formats). Fields for which data is unavailable are given as -1.</p><p>• It should be well defined. We sacrificed extensibility in the interest of standardization, and require that data be expressed in given units. Regrettably, this also means that sometimes data that is actually available in a log does not have a corresponding field in the format, and is therefore lost in the conversion process. For example, this happens for the data about suspending and resuming jobs that is available in the SHARCNET log. It is therefore important to also maintain the original log file.</p><p>1 Files in the standard workload format were naturally denoted by the suffix.swf.</p><p>Unfortunately, this suffix was later also adopted for shockwave flash files.</p><p>• It should be general. In particular, the same format is suitable both for logs from production machines and for statistical models. For example, this consideration favors the use of the time triplet ⟨submit, wait, run⟩ over the triplet ⟨submit, start, end⟩, because wait and run times better separate the effect of the scheduler and the application. When used for the output of a model, the wait time can be left undefined.</p><p>• It should be safe <ref type="bibr" target="#b31">[32]</ref>. To preserve privacy, users and applications are replaced by numerical codes that are allocated in order of first appearance.</p><p>Of course, striving for consistency does not mean that it can always be achieved. An example in point is the very basic data about runtime, typically expressed in logs by the combination of start time and end time. The problem is that the precise semantics of these fields are usually ill-defined. Thus start time may refer to the time that the scheduler decided to start the job, or the time when the first process was started, or the time when the last process was started, or perhaps the time when the logging facility was notified that the job was started. Likewise, end time may refer to the time that the first process terminated, the time that the last one terminated, or the time when this was recorded.</p><p>For example, the KTH SP2 log includes a field called uwall giving the used wall clock time, which intuitively seems to correspond to the runtime. However, uwall is actually defined to be the interval from the last node allocation to the first node deallocation. Note that this may be negative if processes fail immediately, and there is no period of time when they are all actually running in parallel. Therefore, in the conversion to the standard format, we elected to use the more commonly used start and end times (even though their precise semantics are unknown). Another problem in the KTH SP2 log is that the system administrators sometimes faked the submit times in order to boost a job's priority. Such cases were identified by comparing the submit time field with the submit time that was encoded in the job ID. A similar problem occurs in the LANL O2K log format, which does not contain an explicit field specifying the job end time. The field specifying the time that the job-termination event was logged was used instead.</p><p>Another notoriously problematic field is the job status. In many cases a successful completion status is recorded only if the job terminated with a 0 exit code. While this has been the convention on Unix systems since their inception, there is no guarantee that applications indeed follow it. In cases where jobs do not have a ''success'' status, we interpret ''failed'' as jobs that started to run but suffered from some problem or exception condition, and ''canceled'' as jobs that were killed by the user. In the latter case, a job could have been canceled before it started to run, in which case its runtime and allocated processors may be undefined. However, there is no guarantee that logs indeed use the terminology in the same way we interpret it. Thus it is dangerous to filter jobs based on their recorded status.</p><p>The Standard Workload Format was established when the main concerns were the arrivals of jobs and their basic resource requirements, namely processors and compute time. It serendipitously included a field used to specify the partition used to run the job, which has since been found to be useful to represent data about grids including multiple clusters (e.g. SHARCNET and Meta-Centrum). However, it cannot handle more complex data requirements. For example, it has been suggested that information about specific job requirements and specific capabilities of different clusters may lead to involved and limiting constraints, which induce significant complexity on the scheduling, and lead to greatly reduced performance <ref type="bibr" target="#b21">[22]</ref>. This cannot be expressed using the current version of the standard format. Likewise, it has been suggested that it may be important to follow the dynamics of resource usage during the execution of a job, by sampling them at regular intervals. To store such data, one needs to augment the standard workload data with additional data that includes multiple (and potentially very many) records for each job <ref type="bibr" target="#b4">[5]</ref>. This leads to a database-like structure, where one table includes the original general data about all the jobs, and another table includes the dynamic records. The tables can be associated with each other based on the job ID. Finally, the standard format does not include facilities for distinguishing between nodes, processors, and cores. However, this is believed not to be very important, because allocating a full node to a task rather than just a single core is usually a disguise for allocating all the node's memory to the task. It is better to express this directly as an allocation of memory, which is possible in the standard format.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Problems with log data</head><p>Over the years, the logs available at the Parallel Workloads Archive have been found to contain various problems. This is not unique to this repository-collected data in practically all fields are known to have problems. It also does not detract from the importance and in many cases also not from the usefulness of the data. However, it is definitely desirable to be cognizant of the problems and deal with them when possible. Importantly, most of the problems are not isolated anecdotes but rather are repeated in many logs. We therefore present multiple examples of each one in the following subsections. Cases which are indeed unique are identified as such.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Incomplete data</head><p>One problem that we sometimes encounter is that the data is incomplete. This means that some important information is simply missing. As a result the usability of the available data is limited. In the following we provide some examples.</p><p>The vast majority of parallel supercomputers and clusters dedicate processors to jobs. This means that when a job is scheduled, a certain partition of the machine is carved out for it. The job is then run on the processors in this partition until it terminates. Upon termination, the processors become free and can then be allocated to another job. But it is also possible to use time slicing. The Connection Machine CM-5 was one of the only commercial parallel supercomputers to support gang scheduling <ref type="bibr" target="#b39">[40]</ref>. This meant that it could context switch from one parallel job to another. And indeed the LANL CM5 log includes an indication of whether jobs ran on dedicated nodes or not. In those cases where jobs did not run on dedicated nodes, the implication is that they did not run for the full duration from their start time to their end time. However, there is no indication of precisely what fraction of the time was actually used. As a result the real runtimes are actually unknown. Naturally this makes the data practically unusable for simulations of job scheduling and for analyzing utilization. However, it can still be used to study the arrival process, user behavior, memory usage [9], etc.</p><p>Another example comes from the SDSC Paragon logs. The data here is given as two separate logs: one for 1995, and the other for 1996. In the interest of preserving privacy, user names were replaced by random numbers in the original logs. Regrettably, this user numbering was inconsistent in 1995 and 1996, and the mapping from the 1995 numbers to the 1996 numbers is not available. Hence the logs cannot be united into a single longer log (unless user information is deemed unimportant), but each can be used in isolation.</p><p>A third example is provided by the NASA iPSC log. This log simply does not include submit times at all-only start times and run times. Similarly, the LLNL Atlas and Thunder logs include only start and end times. In the conversion to the standard format we therefore use start times to also represent arrival times. Obviously, this data cannot be used to study the arrival process, as the recorded start times reflect the combined effect of the original arrivals and the wait time. Wait times distort arrival data because they may be influenced by priorities of the scheduling policy. They may also reflect a smoothing out of load <ref type="bibr" target="#b11">[12]</ref>. However, the logs can still be used to obtain a lot of useful data, and in fact the NASA iPSC log was the first log to be analyzed in detail <ref type="bibr" target="#b12">[13]</ref>.</p><p>Other fields that are often missing from logs are memory usage, CPU time, and requested resources (in distinction from the resources that were actually used). These are important for studies that need this data, but are not needed for the simplest scheduling studies that consider only processors and runtime.</p><p>In addition to fields that are totally absent, it is not uncommon for data to be missing only for a subset of the jobs. Table <ref type="table" target="#tab_0">2</ref> shows that in most cases submit, start, and end times are missing only for a small fraction of the jobs (except for those logs where submit times are just not available at all). Fields like CPU time or memory used tend to be missing much more often. Fig. <ref type="figure" target="#fig_0">2</ref>. Allocation of processors on the ANL Intrepid machine. Allocating more than the number requested may result from fragmentation (rounding up to a possible partition size) or from the need to allocate all the memory in a node to a single process, rather than sharing it among processes running on multiple cores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Inconsistent data</head><p>Another type of problem is inconsistent data. This means that the data in the log contradicts itself, and does not pass some simple sanity check (called ''integrity constraints'' in <ref type="bibr" target="#b5">[6]</ref>).</p><p>Table <ref type="table" target="#tab_0">2</ref> lists several circumstances that are easily identified as inconsistent. For example, if a job ran successfully then various resource-usage metrics must be positive or at least non-negative: the wait time, the runtime, the number of processors used, the amount of memory used, etc. Likewise, the average CPU time used per processor cannot be larger than the wall clock running time of the whole job. In some cases it also does not make sense for a job to receive more resources than it had asked for, but such an inconsistency is merely puzzling but not impossible.</p><p>It should be noted that timing inconsistencies do not necessarily indicate a real problem. Some cases of zero runtime, for example, could be the result of a resolution problem, e.g. when runtime is measured in seconds and the job's runtime is smaller than half a second. This is unlikely, however, because the distribution of runtimes usually starts at several seconds, and sometimes at tens of seconds. Shorter runtimes cannot be recorded simply due to the delay associated with setting up all the parallel processes and receiving notifications regarding their terminations. (Note that in distinction from measured runtime, requested runtime should not be 0, so this is considered an error and not an inconsistency or a resolution problem.)</p><p>Negative times may result from clock skew or from notification delays between node daemons and a frontend workstation. Therefore we report only differences of more than 1 min in Table <ref type="table" target="#tab_0">2</ref>. This filtering may be very meaningful. For example, in the SDSC-SP2 log 4291 jobs got more runtime than they requested, but in only 463 of these the difference was larger than 1 min. A negative runtime occurred 1 time and negative wait times occurred 183 times, and these were all smaller than 1 min and therefore considered insignificant.</p><p>Inconsistent data is of course not limited to time fields. In the SDSC Blue log, 253 jobs got less processors than they requested. This may look very strange, as it is unclear how a job could run on less processors than it requires. However, parallel jobs are often coded in a style that can use any given number of nodes, and receive the number actually used in a certain run as a parameter.</p><p>The opposite may also occur, but often this is not a real problem. On many parallel machines processors are allocated in predefined partitions, and there is a minimal partition size. In some cases this corresponds to the number of processors (or cores) in a node. In other cases the minimal partition may include many nodes. For example, the ANL Intrepid machine consists of 40 racks, housing 40,960 quad-core nodes, and partition sizes are powers of two. Moreover, in 8 racks the minimal partition size is 64 nodes (256 cores), and in the rest the minimal size is 512 nodes (2048 cores). Jobs that require less are nevertheless allocated these sizes, and the extra processors are lost to fragmentation. Similar rounding up is done on other machines as well. But in many logs we do not know how many are actually used and how many are lost.</p><p>In addition to partition size restrictions, over-allocation of processors may be a by-product of allocating memory. Using the Intrepid machine again as an example, each node on that machine has 2 GB of memory, implying 512 MB per core. If a job requires more than that, allocating the required memory will imply that cores will remain unused. Evidence that this happens is shown in Fig. <ref type="figure" target="#fig_0">2</ref>. This depicts the correlation between the requested number of processors and the allocated number. The high values (dark shading) on the main diagonal imply that most jobs indeed get what they requested. But note that high values also appear on a second diagonal where allocations are four times higher than requests. This most probably reflects requests where the required memory forces a full node to be allocated to each process, even though it will use only one of the four available cores.</p><p>In the above examples examining the value of a single field immediately showed that the data is problematic. Logs may also include redundant data, that allows for sanity checks by comparing the values in several related fields. For example, the HPC2N log uses the Maui scheduler, which records copious data. In particular, the following fields are included: In principle, it may happen that not all requested tasks are actually allocated, so tasksAlloc ̸ = tasksReq. However, in this log this only happens for 767 jobs, which are 0.14%, so in effect we may take these fields as equal. Likewise, we find that nodesReq = |nodesList| for all but one job. This allows for the following checks:</p><p>• Calculate number of nodes based on task requirements as tasksReq/tasksPerNode. This turns out not to match the actual number of nodes in 6428 cases. This is worse than it seems because nodesReq is actually specified in only 89,903 cases (in 437,468 jobs nodesReq is 0, so there is nothing to compare with). Also, in 30,357 jobs tasksPerNode is given as 0, so the check is undefined.</p><p>• Compare the number of processors in the allocated nodes (each node has 2 processors) with the number calculated based on task requirements, which is tasksReq * procsPerTask (or tasksReq * procsPerTask+1 in case it is odd). These do not match in 6250 cases.</p><p>When inconsistencies are discovered, one has to decide which of the competing data to use. Oftentimes it is unclear what to do. As a simple example, consider the following record from the SDSC Paragon 1995 log, with had a submit time of 05/27/95 13:59:38, a start time of 05/27/95 13:04:08, and an end time of 05/27/95 14:03:13. The problem here is that the start time is before the submit time, so when calculating the wait and run times the wait is negative. The options of how to handle this are listed in Table <ref type="table" target="#tab_1">3</ref>. Setting the start time to the submit time without changing anything else reduces the runtime from nearly an hour to 3 1  2 minutes, which is a big change. We can also do the opposite, and move the submit time back to the start time. An alternative based on using the ⟨submit, wait, run⟩ triplet is to just set the wait time to 0. This effectively means setting the start time to the submit time, and changing the end time to maintain the original runtime. Any of these options may or may not reflect what had actually happened in reality.</p><p>Another example of such a dilemma is provided by the RICC log. In this log the maximal momentary utilization is erratic, and often surpasses 100%, which should not happen (more on this in the next section). But if we filter out jobs that were marked as canceled, the utilization results are much more reasonable (Fig. <ref type="figure" target="#fig_1">3</ref>). This is still troubling, however, because the canceled jobs are in fact recorded as having used time on the processors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Erroneous data</head><p>A third type of problem is when the recorded data is downright wrong. For example, the LLNL Atlas and Thunder logs contain jobs with a recorded time limit of 4294967294 s. This is most probably the result of mishandling a 32-bit signed value of -2 by placing it in an unsigned variable. In the SDSC Blue log, timestamps are given in human-readable form in the format 2000-12-23-19:52:38. However, when these are tabulated they lead to a daily cycle that peaks from the evening hours to midnight, and achieves a minimum from 10 to 11 AM. This is most probably due to mishandling of UTC timestamps and using the gmtime function rather than the localtime function that corrects for time zones.</p><p>In some cases wrong data is the result of intentional misreporting. For example, in the KTH SP2 system the system administrators report that sometimes they have pushed jobs through the FIFO queue by giving them artificially low 'enter-fifo' times. Thus the arrival time and the wait time as recorded in the log are bogus.</p><p>A more subtle situation that actually happens in nearly all logs is that the recorded utilization is occasionally greater than 100%, which is technically impossible. To calculate the utilization, one scans the log and simply counts the number of processors in the jobs that are reported as running at each instant (note that if one job terminates and another starts in its place, they should not both be counted). This is then compared to the number of processors in the system to obtain the utilization. The results of performing such calculations are shown in Fig. <ref type="figure" target="#fig_2">4</ref>, indicating exceptions that are sometimes large.</p><p>There are three possible explanations for such utilization exceptions. The first is timing inconsistency, where one job is recorded as running a few seconds beyond its actual termination, or another is recorded as starting slightly before it actually got hold of the processors. Such situations may be identified and corrected, as shown in Section 4.5 below. The second is that there is no real problem, because a job had released some of its processors before it terminated. While possible in principle, all our logs assume rigid jobs that use all their processors for the duration of the run. As a result we have no data to support this possibility. The third possible explanation is simply a logging error. For example, this is the most likely explanation when the log contains a sequence of several large jobs with very similar parameters that all started on the same second, and together require more processors than are available in the system. Despite the utilization exceptions, it turns out that all the logs are actually stable in the sense that the service rate is higher than the arrival rate. This is important because it implies that the logs can actually be used for simulations of parallel job scheduling. To verify stability we divided each log into fixed intervals of length T , and counted the fraction of intervals where the work that arrives in the interval cannot be accommodated within the interval. ''Accommodation'' had two interpretations. The first is just total resource usage by all jobs, meaning that the amount of work arriving within an interval of T was less than the capacity available during this interval. The second is whether they can actually be scheduled by a backfilling scheduler, when jobs are sorted favorably (that is, from longest to shortest or from largest to smallest) and all of them are assumed to arrive at the outset. In both cases, jobs that are longer than T are divided into slices of length T that are assigned to successive intervals.</p><p>The results were that in all cases the fraction of unaccommodated intervals went down to zero as T increased (Fig. <ref type="figure">5</ref>). However, in some cases very long T s were needed. For example, in the SDSC SP2 log 12% of the weekly intervals were not accommodated, and in the CTC SP2 log 8% of the biweekly intervals suffered the same fate. In both cases this dropped to zero only for intervals of a full month.</p><p>A common feature of many utilization graphs is the horizontal upper bound of 100% utilization (albeit sometimes it is breached). A special case of utilization exception is when this upper bound occurs below 100% utilization. This most probably indicates that our information regarding the number of processors is wrong. For example, the size of the CTC SP2 machine was 512 processors, of which 430 were in the batch partition. Assuming this is the number of processors being used leads to the utilization graph shown in Fig. <ref type="figure">6</ref>, with an upper bound of around 78.38%. This indicated that the true size of the batch partition used to capture the log was most probably only 338 processors, and not 430. Subsequent digging in the Internet archive to find old versions of the original web pages describing this machine indicated that the true size may have been 336 processors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Environment variability</head><p>A major problem with parallel workload logs is that the configuration of the underlying machine may be heterogeneous and may even change with time. This can be expected to have an effect on the workload, to the point of making it non-stationary. In many cases we do not have information about such effects, but sometimes we can deduce them from the log data.</p><p>An important type of variability is apparent changes in system capacity. This is evident from the utilization graphs, as shown in Fig. <ref type="figure" target="#fig_3">7</ref>. The SDSC SP2 seems to have grown about a third of the way into the log. In the Sandia Ross machine the available capacity dropped significantly about a quarter of the way into the log. The LLNL Atlas had an initial trial period with half the final capacity. More extreme examples are the LPC cluster, which started with only one node and was later expanded to the full size of 70 nodes, and the CEA Curie machine, which started with one partition containing 11,520 cores and was later expanded with another partition of 80,640 cores. In all these cases, using the whole log consecutively seems to be inappropriate, because it is actually composed of the juxtaposition of two distinct workloads recorded under different conditions.</p><p>A more subtle form of variability is the imposition of resource constraints. The scheduling of parallel jobs is often controlled by defining a set of queues with different priorities and resource constraints. Jobs are submitted to the appropriate queue, as a means of specifying their requirements. The scheduler then judiciously selects jobs for execution from the different queues so as to create a ''good'' job mix that meets the scheduling objectives. 2 This 2 This is based on the assumption that the jobs are indeed submitted to the ''most appropriate'' queue, which tightly fits the job's requirements. In retrospect this assumption is naive, and jobs often use only a small fraction of their runtime limit <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b28">29]</ref>.</p><p>obviously has an effect on the representation of different types of jobs in the log. To confound things, system administrators may change the queue definitions over time.</p><p>For example, the SDSC Paragon system employed the system of queues described in Table <ref type="table">4</ref>. The ones with an 'f' indicate use of 32 MB (fat) nodes, while the others are for 16 MB nodes. The scheduler could use different sets of nodes for different queues during prime time and non-prime time (nights and weekends) <ref type="bibr" target="#b44">[45]</ref>. Specifically, during prime time it was desirable to provide quick turnaround times for short jobs, so a set of nodes were set aside for such jobs. But despite this richness, the log actually contained quite a few additional queues, including test, interactive, qf32test, q_tmp32, sdsc_test, q1ll, holding, q320m, q4t, and q256s. For some of these we can guess the resource requirements, but for the others we cannot.</p><p>A striking example of the effect of such constraints occurred when the scheduler was changed on the LLNL T3D <ref type="bibr" target="#b10">[11]</ref> (regrettably, this data is not available on the Archive). When effective gang scheduling was introduced in March 1996 it became much easier to run large jobs. By October the distribution of job sizes had changed, with the fraction of resources devoted to 32-processor jobs dropping by two thirds, while the fraction of resources devoted to 64, 128, and 256-processor jobs more than doubled.</p><p>The KTH SP2 system also imposed various limits on job run times (and this was also changed during the period that the log was recorded). In essence jobs were limited to running for up to 4 h during weekdays, which were defined to be from 7 AM to 4 PM Monday through Friday. At nights they could run for 15 h, and over the weekend for 60 h. By tabulating the number of jobs with long requested runtimes that were submitted at different times of the Fig. <ref type="figure">5</ref>. Stability results of logs that had relatively many unstable intervals. In most other logs only a few percent at most of even the short intervals were unstable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 4</head><p>Queues on the SDSC Paragon. day and the week, one can see that requests to run jobs longer than 4 h peak every day after 4 PM, and requests to run jobs longer than 15 h are nearly always submitted on Friday afternoon. In addition to differences in configuration, schedulers may exhibit idiosyncratic behavior. A small example is the batching of jobs. Some schedulers accumulate jobs across short intervals, rather than immediately scheduling jobs as they arrive. This leads to a modal inter-start-time distribution, as opposed to a smoother inter-arrival distribution, as demonstrated in Fig. <ref type="figure" target="#fig_4">8</ref>.</p><p>The point of these examples is to demonstrate that the observed workload is not necessarily a ''natural'' workload that reflects what the users want to run. Rather, users may mold their requirements according to the limitations imposed by each system's administrators and schedulers. And to make matters worse, these limitations may be quite involved, may change unpredictably, and may be unknown to us.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Non-representative behavior</head><p>Another source of variability is the users themselves. In quite a few cases we find users whose behavior is different from the behavior of all others, and might be considered to taint the log data.</p><p>An early example was the behavior of the system administrators on the NASA iPSC machine. It turns out that these administrators commonly ran the Unix pwd command (print working directory) on a single node of the machine as a means to verify that the system was operational and responsive. All told, no less than 56.8% of the jobs recorded in the log were such pwd commands. Another example comes from the SDSC Paragon log, where an automatic script was executed every day at around 3:45 AM, most probably to perform a sequence of cleanup or maintenance operations. This caused a noticeable perturbation of the normal daily cycle of activity.</p><p>Another type of non-representative behavior is flurries of activity by individual users, which dominate all other activity in the system <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b41">42]</ref>. Examples are shown in Fig. <ref type="figure" target="#fig_5">9</ref>. To create these graphs, the number of jobs in each week was counted and the weeks with the highest level of activity singled out. Then, the top users in these weeks were identified and their activity color-coded throughout the log. Here we focus on job flurries, but in logs from parallel machines like ours flurry observations can also be based on processes. Importantly, process flurries are not necessarily correlated with job flurries, as they can be created by a relatively small number of jobs that each include a very large number of processes. Examples of logs that contain process flurries that do not correspond to job flurries include SDSC SP2, SDSC Blue, HPC2N, SHARCNET, LLNL Atlas, LLNL Thunder, and RICC.</p><p>Flurries can be roughly classified into three types.</p><p>• Sporadic large flurries, where the number of jobs produced by a single user is 5-10 times the average weekly total, but this continues only for a short period. A prominent example is the activity of user 374 in the SDSC SP2 log, or the three large flurries in the LANL CM5 log. Note that these are not necessarily the most active users in the log, but their concentration makes them unique.</p><p>• Long-range dominance, where the abnormal level of activity by a single user continues for a long time, and perhaps even dominates the whole log. A striking example is the activity of user 2 in the HPC2N log, who is responsible for no less than 57.8% of the whole log.</p><p>• Small flurries, where some user displays a relatively high level of activity, but not as exceptional as the previous classes.</p><p>Nevertheless, even such small flurries may cause instabilities in simulations used to evaluate schedulers. An example is the flurry in the CTC SP2 log <ref type="bibr" target="#b13">[14]</ref>.</p><p>While the large-scale flurries pop out and are obviously behavioral outliers, the identification of small flurries is more contentious. There seems to be no precise rule for deciding when a user's activity is abnormal, and when it is just the most active from among a distribution of users. Moreover, the degree that a user's activity appears to be abnormal may depend on the resolution of observation. For example, when using a daily resolution flurries may look more prominent than when using a weekly resolution (Fig. <ref type="figure" target="#fig_6">10</ref>). In the Parallel Workloads Archive we attempt to be conservative, and flag only flurries that look prominent on a weekly scale. However, smaller flurries may also be flagged if we know that they lead to problems in simulations.</p><p>Other patterns are even more subtle than small flurries, but nevertheless may be important. For example, a study of the interactions between workloads and system schedulers found that the CTC SP2 log is unique in having many serial jobs that are relatively very long <ref type="bibr" target="#b9">[10]</ref>. This was attributed to the fact that this machine inherited the workload of an IBM ES/9000 mainframe that was decommissioned at the same site. Importantly, this arcane attribute of the workload actually turned out to influence performance results in the context of simulations of scheduling with backfilling <ref type="bibr" target="#b9">[10]</ref>. Thus knowing about it may be a consideration when deciding whether or not to use this workload in an evaluation. In a related vein, most parallel workloads exhibit a weak positive correlation between the parallelism and runtime of jobs, but the LANL O2K log exhibits a weakly negative correlation. This can be important in situations where the correlation between job size and runtime affects performance <ref type="bibr" target="#b26">[27]</ref>.  Another strange workload attribute is the user residence pattern in the SDSC Blue log. <ref type="foot" target="#foot_0">3</ref> In most logs, many new users are observed in the first few weeks (these are the users who were actively using the system when the logging commenced). Then new user arrivals stabilize at a lower rate. The opposite happens with the users' last appearances in the logs: initially they are randomly distributed, and towards the end of the log one finds a large concentration. But the SDSC Blue log exhibits a different and strange pattern. This log is 32 months long, and includes data about 467 users. Surprisingly, the first user to leave does so only after 248 days (more than 8 months). By this time no less than 307 different users had been observed, and all of them continue to be active. Moreover, only 10 users leave within the first 20 months. Of the remaining 457 users 106 leave during the last month, and the other 351 leave during the period from the 21st month to the 31st month, at an average rate of 32 per month. While we currently do not know of any consequences of this strange pattern, it nevertheless remains highly unusual.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">End effects</head><p>The way that most logs are collected is that the record describing each job is written when the job terminates. If jobs are extremely short this has no appreciable effect. But if jobs can be very long, as is the case for parallel jobs executed on large supercomputers, this can have a marked effect on the observed workload at the log's ends, and on the calculated utilization. This assumes that the machine is in production use, and logging is done for an arbitrary limited duration.</p><p>At the beginning of the log we often see a warmup effect. This is because the first timestamp in the log is typically the arrival time of a job that had a very long response time and terminated soon after logging commenced. Jobs that ran in parallel to this job but had shorter response times were not logged, because they terminated before logging commenced. Hence the logged load is smaller than it really was in the initial portion of the log (Fig. <ref type="figure" target="#fig_7">11</ref>).</p><p>The opposite effect happens near the end of the log, where only short jobs get logged. Jobs with longer response times that start towards the end of the logging period may not terminate within the logging period, and hence are not logged. Again, the effect is of logging only part of the load that was actually present.</p><p>To counteract these effects, care must be taken. When calculating a machine's utilization, one usually calculates the total resource usage (processors×time) of all jobs, and divides this by the available resources (totalProcessors×logDuration). To reduce the end effects, it is best to interpret the log duration as the interval from the first termination to the last termination, rather than as the interval from the first timestamp to the last timestamp or the interval from the first arrival to the last arrival.</p><p>When performing a simulation using a log, it is important to discard some initial subset of the results in order to allow for warmup. Also, stop measuring when the last arrival occurs, because after that time the simulated jobs will encounter less and less competition, leading to unrealistically good results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">Missing downtime data</head><p>The activity on a parallel supercomputer may be interrupted occasionally due to various reasons, such as scheduled maintenance, software failures, and hardware failures. Obviously this affects the logged workload, and creates time intervals where the utilization drops to zero. Jobs may be truncated and re-submitted later. As a side effect, this also distorts overall utilization calculations.</p><p>Failure data is also directly important for performance evaluations. Failures may reduce observed performance as jobs need to wait for resources to become available <ref type="bibr" target="#b21">[22]</ref>. Their existence also suggests the system-level metric of how many jobs were killed due to failures. Conversely, job data may help in analyzing failures and producing reliable data regarding the severity and effect of failures <ref type="bibr" target="#b46">[47]</ref>.</p><p>Failure data exists for a few of the systems in the Parallel Workloads Archive. Examples include the NASA iPSC, SDSC Paragon, LPC grid, the MetaCentrum grid <ref type="bibr" target="#b21">[22]</ref>, and ANL Intrepid <ref type="bibr" target="#b46">[47]</ref>. However, this data is not integrated into the standard workload format. Note that a separate repository concerning failure data exists at www.usenix.org/cfdr, and in the future it may be beneficial to create some connections between this repository and our archive. Another related repository is the Failure Trace Archive at fta.scem.uws.edu.au, which has made inroads toward defining a standard format for recording failure data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Attempting to improve log data quality</head><p>An important goal of the archive is to capture experience with using the logs. This is done by providing improved or specially ''cleaned'' versions of the logs which reflect our experience. Such versions allow users of the data to benefit from our experience without delving into all the details and cleaning decisions themselves, and also ensure that different users use data that was cleaned in the same way. Needless to say, users are also free to inspect the original data for themselves and make other decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">General procedure</head><p>Importantly, we have found that cleaning operations developed for one log are often applicable to others too. Thus whenever a new log is accepted into the archive it undergoes a battery of tests for data quality.</p><p>Some of the data quality improvements are applied automatically as part of our conversion to the standard workload format. These include the following:</p><p>• Some attempts are made to recover missing timing data based on redundant or related fields, as described in Section 4.3. Negative wait and run times that are larger than 1 h and 5 min (to allow for possible changes in daylight saving time and for clock drifts) are then changed to -1 (which means the value is unknown), while smaller negative values are simply changed to 0.</p><p>• Fields that should be positive (e.g. number of processors, memory usage, and requested runtime) but are recorded as having a 0 value are changed to -1.</p><p>• Users, groups, and applications are anonymized by replacing them with serial numbers in order of first appearance.</p><p>In other cases visual summaries of the data are prepared, like the arrival graphs of Fig. <ref type="figure" target="#fig_5">9</ref> or the capacity graphs of Fig. <ref type="figure" target="#fig_2">4</ref>. These can then be checked by us to determine whether any cleaning is needed to remove data that we feel should not be used because it is erroneous or not representative of normal production use.</p><p>The cleaning itself is performed by a script that can handle the following specifications of which jobs to remove from a given log:</p><p>• Jobs with a specific field value. For example, this is useful to remove all the jobs submitted by a certain user.</p><p>• A specified span of jobs. When combined with a user, this can be used to specify a flurry but leave the user's other non-flurry activity intact.</p><p>• Jobs within a specified time span. The span can be one sided, so an initial prefix of the log can be specified.</p><p>• Jobs running at specific times each day. When combined with a user this can be used to remove automatic jobs that are fired each day. These specifications can be combined using Boolean AND, OR, and NEGATION.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Removing initial low-load intervals</head><p>Some of the logs were started when the machines being logged were very new, before users started to use them for real. As a result they have initial segments that do not reflect real production use but system testing, often interspersed with long idle periods. Such initial segments are typically of no interest for system evaluations (albeit they might be of interest for studies of how the workload evolves <ref type="bibr" target="#b19">[20]</ref>). In other logs the initial part of the log reflects a partial configuration, which is later completed to the full configuration of the machine. In the interest of providing data that can be used as-is, we shorten the logs and remove the initial low-load periods from the cleaned versions.</p><p>An example is the LLNL Atlas log. As shown in the utilization plot in Fig. <ref type="figure" target="#fig_3">7</ref>, this log has an initial segment from 10 November 2006 to 7 December 2006 where the utilization is up to 50%, indicating that </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5</head><p>Calculation of job timing data based on available input data. The notation ''(X )? S1 : S2'' means that if input X is available or true then action S1 is taken, otherwise action S2 is taken. Note that these may be stringed to form ''else if'' sequences. succ means the job has a success status. Note that in some combinations of unavailable inputs some of the desired outputs are left undefined.</p><p>most probably the machine was operating at half capacity. Then there is a short interval with no activity, and finally full production work is started on 18 December 2006. In the cleaned version the log is shortened and everything before 18 December 2006 is removed.</p><p>An extreme case of unrepresentative data is the LLNL uBGL workload log. In this log of 112,611 jobs, 101,331 are recorded as failed, and in fact the vast majority (99,401) did so within 5 s. This is attributed to the fact that the machine was new and unstable at the time this log was recorded. As a result, the whole log is actually unrepresentative of production use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Reconstructing missing data</head><p>Among the most important attributes of parallel jobs are their arrival time and running time. Regrettably, in some cases this information or related information (e.g. the start time or end time) are missing. Nevertheless, sometimes missing data can be reconstructed at least partially.</p><p>Our conversion scripts accept the following partly redundant fields that all relate to job timing: The output of the conversion needs the following three nonredundant fields:</p><formula xml:id="formula_0">• Arrival time (ARR) • Wait time (WAIT ) • Running time (RUN)</formula><p>The way these are set based on the available input data is given in Table <ref type="table">5</ref>. This reflects various heuristics to automatically recover as much data as possible in those cases that explicit data is erroneous or unavailable. For example, if start is missing, we assume it to be arr. If run and cpu are also not available, we can then estimate the runtime as endarr. However, this should be qualified by job status. If the job was canceled before it was started, it is more appropriate to assign this interval to the wait time, and leave the runtime undefined.</p><p>While such heuristics may recover some data and enhance the usability of the log, they may also cause problems. For example, in the SDSC SP2 log, a straightforward analysis revealed that 4291 jobs got more runtime than they requested, and in 463 cases the extra runtime was larger than 1 min. However, 5831 jobs had undefined start times, so their runtime was not computed. When the missing start times were replaced by the submit times, the number of jobs that got more runtime than they requested jumped up to 6154, and in 2284 of them the difference was larger than 1 min. As we saw previously, there is no way to know what the correct data was. We need to make a subjective decision based on the data that is available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Data cleaning by removing flurries</head><p>The anomalous behaviors described in Section 3.5 degrade data quality because they are anomalous and do not represent normal usage. Using logs that contain such anomalies as input to evaluations risks results that are tainted by the anomalies. For example, if a log contains voluminous non-representative activity by a single user, and this is used to evaluate schedulers and suggest operational parameters, we risk making the selection so as to optimize the performance of a non-representative user that was active on a single system some years ago. Flurries may also cause evaluations to be overly sensitive to details. In previous work we have identified and described a situation where the average slowdown of all the jobs in the simulation changed by 8% after a miniscule change to a single job (changing its runtime from 18 h and 30 s to 18 h flat). The sensitivity was attributed to a flurry of jobs submitted later that were affected en-masse <ref type="bibr" target="#b41">[42]</ref>.</p><p>Of course, removing the abnormal behavior also entails risk. First, maybe we are wrong and the data is not as bad as we think. Second, by removing part of the data we are left with a log that does not give the full picture. In particular, the behavior of other users may have been affected by the load placed on the system by the abnormal user. Therefore the cleaning process deserves careful attention, and we have considered the following cleaning options <ref type="bibr" target="#b40">[41]</ref>:</p><p>• Avoid the issue by using only short samples of representative jobs. This approach is motivated by computer architecture studies, where the execution of complete benchmarks is often substituted with the execution of representative slices (e.g. <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b34">35]</ref>). The motivation there is that simulating the billions of instructions in complete benchmarks is extremely time consuming, so settling for slices is worthwhile. In parallel job scheduling we typically do not have that problem, and logs contain no more than several hundreds of thousands of jobs. It is therefore better to use all the data, and avoid the debate over what subsets of jobs are ''representative''. • Remove complete days as was suggested in <ref type="bibr" target="#b3">[4]</ref>. This removes not only the anomalous data but also contemporaneous data that may have been affected by it, at the cost of leaving a gap in the log. But this may be perfectly OK, because the effect of flurries is typically limited in time. For example, in the sensitivity example noted above, the effect was due to a 10-hour flurry on day 581 of a 730-day log. Removing this flurry affected subsequent simulation behavior for 5 days: simulations with and without the flurry were identical except for days 581 through 585. So removing these days leaves use with 725 days of undisputed valid data. However, identifying exactly how far the effect of the flurry extends is difficult, and may also be context dependent.</p><p>• Remove tainted results from the final analysis, rather than removing jobs from the input. Separating the input jobs into classes and reporting performance results for individual classes has been used in various situations (e.g. <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b9">10]</ref>). Thus we can simply compute our performance indicators based on only the ''good'' jobs, and exclude the flurry jobs from the average. However, this faces two risks. First, the mere presence of the flurry jobs may affect the performance experienced by other jobs that ran at the same time. Second, we need to develop a methodology to identify the problematic jobs that should be excluded, and trust analysts to incorporate it into their evaluation frameworks and use it correctly and consistently.</p><p>• Remove only the flurry jobs, as we suggested in <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b41">42]</ref>. In cases we checked, this turns out to have practically the same effect as excluding the flurry jobs from the final averages, but it is safer because it is simpler and cannot be misused.</p><p>The policy adopted in the Parallel Workloads Archive is to remove the most prominent dominant users and flurries, but at the same time also provide the original log as is. By using our cleaned logs, analysts can tap into our experience and avoid the need to make cleaning decisions for themselves. This also has the benefit that different analyses will be comparable by virtue of using exactly the same data. On the other hand, if they do indeed want to invest the time in studying anomalous data and deciding what to do about it, this is possible.</p><p>About half the logs in the archive have cleaned versions. In further support of cleaning, we note that in most cases the impact on the log is minimal. For example, in the SDSC SP2 log, removing the flurry of activity by user 374 reduced the overall utilization only from 83.7% to 83.5%. The reason is that all the jobs by this user were both small (using only a single processor) and short (typically lasting for less than a minute, but with some lasting up to an hour, as indicated in Fig. <ref type="figure" target="#fig_9">12</ref>). The most extreme case was the HPC2N log, where user 2 was responsible for a full 57.8% of the jobs in the log. However, removing them only reduced the load from 70.2% to 60.2%. Again, these jobs tended to be small (up to 8 processors) or short (up to a minute), albeit in some cases they were larger (e.g. 20 processors) or longer (e.g. an hour).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Enforcing the capacity constraint</head><p>The errors mentioned in Section 3.3 whereby the utilization exceeds 100% may be reduced by two means. The first is ''shaking'' the input, namely making small modifications to job start times such that the jobs will fit in <ref type="bibr" target="#b42">[43]</ref>. Specifically, we used a linear solver to see whether all jobs could be accommodated if we increase some of the wait times by different amounts. However, this invariably led to either of two outcomes: either a proof that no solution could be found within the specified limits (e.g. only change wait times by up to 1 h), or failure of the linear solver to terminate within a few hours.</p><p>The second option is to simply delete the offending jobs. In order to find which jobs to delete, we first divide the log into cliques of jobs that overlap in time <ref type="bibr" target="#b1">[2]</ref>. For those cliques where a utilization exception occurs, we solve a linear program that describes the problem (which jobs were not deleted and the capacity constraint). The optimization criterion is to minimize the number of jobs that are removed, or alternatively the total node-seconds that are removed. This enables a tradeoff between removing a few large jobs or many small jobs. We settle the tradeoff by choosing the approach that leads to the minimal maximal reduction. For example, if removing few large jobs leads to a reduction of LJ percent of the jobs and LU percent of the utilization, while removing many small jobs leads to a reduction of SJ percent of the jobs and SU percent of the utilization, we will choose the first option if max(LJ, LU) &lt; max(SJ, SU), and the second otherwise.</p><p>Scanning the logs, we find that in some cases very many jobs are involved, and trying to eliminate all the utilization errors would mean removing lots of jobs throughout the log. We therefore decided to leave such logs as they are. But in about half of the logs the utilization errors can be cleaned by removing only a small fraction of the jobs. In these cases using the utilization criterion typically leads to smaller maximal impact. In most cases up to 1 or 2 percent of the jobs and utilization need to be removed, and in one case nearly 5 percent. At the time of writing, actually doing this is ongoing work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>Even in the age of information overload, good data is a precious and scarce resource. This is especially true in Computer Science, for two reasons. The first is that this field does not have a tradition of experimental research based on empirical observations. The second is the rapid progress in computing technology, which creates the risk that data will be outdated and irrelevant not long after it is collected. Nevertheless, we contend that using real data is still generally preferable over using baseless assumptions. Collecting data and subjecting it to analysis and sanity checks is a crucial part of scientific progress.</p><p>Aging is but one aspect of a more general problem, namely the problem of data quality. Thus data should be used intelligently, and experience regarding the cleaning of data and its validity constraints should be recorded and maintained together with the data itself <ref type="bibr" target="#b36">[37]</ref>. In the Parallel Workloads Archive, some of the logs have been publicly available for over a decade. Nevertheless, we still occasionally find new and previously unknown artifacts or deficiencies in them. It is unreasonable to expect each user of the data to be able to analyze this independently and achieve comprehensive results. Thus sharing experience is no less important than sharing the data in the first place.</p><p>It is interesting to compare our work with work done on data quality in other domains. Knight and Burn have reviewed the commonly cited dimensions of data quality, based on the pioneering work of Wang and Strong and others <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b43">44]</ref>. Table <ref type="table" target="#tab_4">6</ref> shows how these dimensions apply to the Parallel Workloads Archive. It turns out that the data itself inherently satisfies some of the dimensions, for example relevance, believability, and value-added. Furthermore, the archive naturally addresses many additional dimensions, for example by making the data available and accessible. The Standard Workload Format that is used also helps, for example by providing privacy and understandability. But other dimensions are indeed problematic. Specifically, the bulk of this paper was devoted to the description of various accuracy and inconsistency problems. Completeness is another potential problem.</p><p>In many cases the decisions regarding how to handle problematic data are subjective in nature. This is of course an undesirable situation. However, it seems to be unavoidable, because the information required in order to make more informed decisions is unavailable. The alternative of leaving the data as is no better, because the question of how to handle the data arose due to problems in the data itself. Therefore we contend that the best solution is to make the best subjective decision that one can, and document this decision. Doing so in the Parallel Workloads Archive leads to two desirable outcomes. First, users of the data will all be using the same improved version, rather than having multiple competing and inconsistent versions. Second, this can be used as the basis for additional research on methods and implications of handling problematic data.</p><p>A further improvement in the usability of workload data may be gained by combining filtering with workload modeling. Specifically, in recent work we considered the concept of workload re-sampling at the user level <ref type="bibr" target="#b45">[46]</ref>. This means that the workload log is partitioned into independent job streams by the individual users. These job streams are then combined in randomized ways to generate new workloads for use in performance evaluation. Among other benefits, this approach allows for the removal of users who exhibit non-representative behavior such as the workload flurries of Section 3.5. The reconstructed workloads will also not suffer from underlying configuration changes such as those noted in Section 3.4.</p><p>Additional future work concerns data cleaning. One important outstanding issue is how to handle situations where the utilization exceeds 100%, as demonstrated in Section 3.3. As noted in Section 4.5, in about half of the logs we did not find a simple fix to this problem. Another interesting question is to assess the effect of the different problems we found in workload logs. This would enable an identification of the most important problems, which are the ones that cause the biggest effect and therefore justify increased efforts to understand their sources and how to fix them. Likewise, many thanks are due to the managers who approved the release of the data. Thanks are also due to students who have helped in converting file formats and maintaining the archive.</p><p>Our research on parallel workloads has been supported by the Israel Science Foundation (Grant Nos. 219/99 and 167/03) and by the Ministry of Science and Technology, Israel.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Field 2 :</head><label>2</label><figDesc>Nodes Requested (nodesReq) Field 3: Tasks Requested (tasksReq) Field 22: Tasks Allocated (tasksAlloc) Field 23: Required Tasks Per Node (tasksPerNode) Field 32: Dedicated Processors per Task (procPerTask) Field 38: Allocated Host List (nodesList)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Strange effect of canceled jobs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Examples of utilization exceptions. For each day the range between the minimal and maximal utilizations observed is colored.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Examples of utilization variability probably due to configuration change.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Examples of modal inter-start-time distributions due to batching by the scheduler.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Examples of large flurries of activity by individual users.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Flurries observed at different resolutions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Example of sampling effects at the ends of the logging period.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>= startarr OK (run)? RUN = run: RUN = endstart n/a (run)? RUN = run: (cpu)? RUN = cpu n/a * (run)? RUN = run: (cpu)? RUN = cpu OK (run)? WAIT = (endrun) -arr: (cpu)? WAIT = (endcpu) -arr: (succ)? RUN = endarr, WAIT = 0: WAIT = endarr n/a OK * ARR = start OK (run)? RUN = run: RUN = endstart n/a (run)? RUN = run: (cpu)? RUN = cpu n/a * (run)? RUN = run: (cpu)? RUN = cpu OK (run)? ARR = endrun: (cpu)? ARR = endcpu: ARR = end</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Scatter plots showing size/runtime data for a whole log, and highlighting jobs of a single highly active user.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>•</head><label></label><figDesc>Bill Nitzberg for the NASA iPSC log • Curt Canada for the LANL CM5 log • Reagan Moore and Allen Downey for the SDSC Paragon logs • Dan Dwyer and Steve Hotovy for the CTC SP2 log • Lars Malinowsky for the KTH SP2 log • Victor Hazlewood for the SDSC SP2 and SDSC Datastar logs • Fabrizio Petrini for the LANL Origin 2000 log • David Jackson for the OSC cluster log • Travis Earheart and Nancy Wilkins-Diehr for the SDSC Blue Horizon log • Jon Stearley for the Sandia Ross log • Ake Sandgren and Michael Jack for the HPC2N log • John Morton and Clayton Chrusch for the SHARCNET log • Moe Jette for the uBGL, Atlas, and Thunder logs from LLNL • Susan Coghlan, Narayan Desai, and Wei Tang for the ANL Intrepid log • Dalibor Klusáček and Czech National Grid Infrastructure MetaCentrum for the MetaCentrum log • Ciaron Linstead for the PIK IPLEX log • Motoyoshi Kurokawa for the RICC log • Joseph Emeras for the CEA Curie log</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2</head><label>2</label><figDesc>Occurrences of incomplete or inconsistent data in the different logs.</figDesc><table><row><cell></cell><cell></cell><cell>Missing</cell><cell></cell><cell></cell><cell>Zero</cell><cell></cell><cell></cell><cell></cell><cell>Negative</cell><cell></cell><cell cols="2">More than req.</cell><cell></cell><cell>CPU</cell></row><row><cell>Log</cell><cell>Jobs</cell><cell>Submit</cell><cell>Start</cell><cell>End</cell><cell>Proc</cell><cell>Run</cell><cell>CPU</cell><cell>Mem</cell><cell>Wait</cell><cell>Run</cell><cell>Run</cell><cell>Proc</cell><cell>Mem</cell><cell>&gt;run</cell></row><row><cell>NASA iPSC</cell><cell>42,264</cell><cell>n/a</cell><cell>-</cell><cell>n/a</cell><cell>-</cell><cell>-</cell><cell>n/a</cell><cell>n/a</cell><cell>n/a</cell><cell>-</cell><cell>n/a</cell><cell>n/a</cell><cell>n/a</cell><cell>n/a</cell></row><row><cell>LANL CM5</cell><cell>201,387</cell><cell>3</cell><cell>3</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>37,199</cell><cell>19,517</cell><cell>-</cell><cell>1</cell><cell>36,198</cell><cell>1212</cell><cell>21,036</cell><cell>17</cell></row><row><cell>SDSC Par</cell><cell>115,591</cell><cell>1608</cell><cell>23</cell><cell>14</cell><cell>-</cell><cell>-</cell><cell>6181</cell><cell>n/a</cell><cell>27</cell><cell>15</cell><cell>-</cell><cell>-</cell><cell>n/a</cell><cell>3073</cell></row><row><cell>CTC SP2</cell><cell>79,302</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>6</cell><cell>4</cell><cell>n/a</cell><cell>-</cell><cell>-</cell><cell>1380</cell><cell>-</cell><cell>n/a</cell><cell>155</cell></row><row><cell>KTH SP2</cell><cell>28,490</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>n/a</cell><cell>n/a</cell><cell>-</cell><cell>-</cell><cell>64</cell><cell>219</cell><cell>n/a</cell><cell>n/a</cell></row><row><cell>SDSC SP2</cell><cell>73,496</cell><cell>-</cell><cell>2</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>1731</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>463</cell><cell>-</cell><cell>-</cell><cell>3</cell></row><row><cell>LANL O2K</cell><cell>122,233</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>21,156</cell><cell>221</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>1886</cell></row><row><cell>OSCcluster</cell><cell>80,714</cell><cell>-</cell><cell>1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>6177</cell><cell>n/a</cell><cell>1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>n/a</cell><cell>27,596</cell></row><row><cell>SDSC Blue</cell><cell>250,440</cell><cell>-</cell><cell>262</cell><cell>-</cell><cell>2</cell><cell>-</cell><cell>4203</cell><cell>n/a</cell><cell>28</cell><cell>-</cell><cell>8167</cell><cell>458</cell><cell>n/a</cell><cell>2</cell></row><row><cell>Sandia Ross</cell><cell>85,355</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>1</cell><cell>-</cell><cell>807</cell><cell>1548</cell><cell>-</cell><cell>-</cell><cell>3069</cell><cell>-</cell><cell>-</cell><cell></cell></row><row><cell>HPC2N</cell><cell>527,371</cell><cell>-</cell><cell>-</cell><cell>77</cell><cell>-</cell><cell>-</cell><cell>73,483</cell><cell>5646</cell><cell>12</cell><cell>3</cell><cell>6784</cell><cell>767</cell><cell>2548</cell><cell>60,608</cell></row><row><cell>SDSC Datastar</cell><cell>96,089</cell><cell>-</cell><cell>4</cell><cell>149</cell><cell>-</cell><cell>-</cell><cell>8976</cell><cell>n/a</cell><cell>12</cell><cell>87</cell><cell>1044</cell><cell>-</cell><cell>n/a</cell><cell>149</cell></row><row><cell>SHARCNET</cell><cell>1,195,242</cell><cell>-</cell><cell>26</cell><cell>12,389</cell><cell>-</cell><cell>-</cell><cell>78</cell><cell>16,231</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>1237</cell></row><row><cell>LLNL Atlas</cell><cell>60,332</cell><cell>n/a</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>n/a</cell><cell>n/a</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>19</cell><cell>n/a</cell><cell>n/a</cell></row><row><cell>LLNL Thunder</cell><cell>128,662</cell><cell>n/a</cell><cell>1208</cell><cell>1208</cell><cell>-</cell><cell>-</cell><cell>n/a</cell><cell>n/a</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>155</cell><cell>n/a</cell><cell>n/a</cell></row><row><cell>MetaCentrum</cell><cell>103,656</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>n/a</cell><cell>8</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>n/a</cell></row><row><cell>ANL Intrepid</cell><cell>68,936</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>n/a</cell><cell>n/a</cell><cell>-</cell><cell>-</cell><cell>9096</cell><cell>30,948</cell><cell>n/a</cell><cell>n/a</cell></row><row><cell>PIK IPLEX</cell><cell>742,965</cell><cell>-</cell><cell>10,710</cell><cell>-</cell><cell>1</cell><cell>-</cell><cell>68,191</cell><cell>-</cell><cell>45</cell><cell>83</cell><cell>2581</cell><cell>2</cell><cell>-</cell><cell>2632</cell></row><row><cell>RICC</cell><cell>447,794</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>n/a</cell><cell>n/a</cell><cell>-</cell><cell>-</cell><cell>2581</cell><cell>-</cell><cell>n/a</cell><cell>n/a</cell></row><row><cell>CEA Curie</cell><cell>773,138</cell><cell>-</cell><cell>561</cell><cell>-</cell><cell>1229</cell><cell>-</cell><cell>n/a</cell><cell>n/a</cell><cell>-</cell><cell>-</cell><cell>4848</cell><cell>105,019</cell><cell>n/a</cell><cell>n/a</cell></row><row><cell cols="15">''-'' means that there were no such inconsistencies. ''n/a'' means not applicable, e.g. if the log does not contain such data at all. For runtime and wait time, more than requested</cell></row><row><cell cols="15">or negative is by a margin of 1 min or more to allow for clock skew or notification delays. Missing start time and 0 processors/CPU/memory are counted only for jobs that</cell></row><row><cell cols="14">had a ''success'' status (but missing start time with CPU &gt; 0 is noted). In the Curie log, the 561 jobs with missing start time actually represent missing run time.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3</head><label>3</label><figDesc>Example of possible actions when facing inconsistent timing data.</figDesc><table><row><cell>action</cell><cell></cell><cell>submit</cell><cell>wait</cell><cell>run</cell></row><row><cell>none</cell><cell></cell><cell>unchanged</cell><cell>-55:34 min</cell><cell>59:05 min</cell></row><row><cell>start = submit</cell><cell></cell><cell>unchanged</cell><cell>0</cell><cell>03:35 min</cell></row><row><cell>submit = start</cell><cell></cell><cell>changed</cell><cell>0</cell><cell>59:05 min</cell></row><row><cell>start = submit end+ = submit -start</cell><cell></cell><cell>unchanged</cell><cell>0</cell><cell>59:05 min</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Running time (wall clock, run) • CPU time (average per processor, cpu) If the data is available and consistent, we should have arr ≤ start ≤ end, run = endstart, and cpu ≤ run.</figDesc><table><row><cell>• Arrival time (arr)</cell></row><row><cell>• Start time (start)</cell></row><row><cell>• End time (end)</cell></row><row><cell>•</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6</head><label>6</label><figDesc>Applicability of data quality dimensions to the Parallel Workloads Archive.</figDesc><table><row><cell>1</cell><cell>accuracy</cell><cell>some problems occur as described in this paper</cell></row><row><cell>2</cell><cell>consistency</cell><cell>some internal (among fields in the same log) and external (among similar fields in different logs) inconsistencies occur</cell></row><row><cell>3</cell><cell>security</cell><cell>free access is a goal; privacy is maintained by encoding users, groups, and applications</cell></row><row><cell>4</cell><cell>timeliness</cell><cell>some logs are dated, but enable research about workload evolution</cell></row><row><cell>5</cell><cell>completeness</cell><cell>some desirable data is missing, e.g. job dependencies, memory and I/O requirements, other scheduling constraints</cell></row><row><cell>6</cell><cell>conciseness</cell><cell>log files are typically small enough to be easily handled</cell></row><row><cell>7</cell><cell>reliability</cell><cell>some problems occur as described in this paper</cell></row><row><cell>8</cell><cell>accessibility</cell><cell>freely accessible via the world-wide web</cell></row><row><cell>9</cell><cell>availability</cell><cell>freely accessible via the world-wide web</cell></row><row><cell>10</cell><cell>objectivity</cell><cell>logs come from different locations and machine types with no biased selection</cell></row><row><cell>11</cell><cell>relevancy</cell><cell>extremely relevant as witnessed by extensive use</cell></row><row><cell>12</cell><cell>usability</cell><cell>simple format; ASCII files</cell></row><row><cell>13</cell><cell>understandability</cell><cell>simple format; documentation of format and background on each log are provided</cell></row><row><cell>14</cell><cell>amount of data</cell><cell>seems to be adequate for common usage scenarios</cell></row><row><cell>15</cell><cell>believability</cell><cell>data comes from large scale production systems; non-representative behavior is cleaned</cell></row><row><cell>16</cell><cell>navigability</cell><cell>table listing logs and their main attributes is provided</cell></row><row><cell>17</cell><cell>reputation</cell><cell>data comes from major installations</cell></row><row><cell>18</cell><cell>usefulness</cell><cell>witnessed by extensive use</cell></row><row><cell>19</cell><cell>efficiency</cell><cell>A year's activity can typically be simulated in seconds</cell></row><row><cell>20</cell><cell>value-added</cell><cell>data provides needed grounding in reality</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>This observation is due to Netanel Zakay.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Many thanks are due to all those who spent their time collecting the data and preparing it for dissemination. In particular, we thank the following for the workload data they graciously provided:</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>David Krakov is a lead system architect at EMC XtremIO, where his main focus is performance optimization and system analysis. He has accumulated at EMC and prior over 10 years of professional software development and design experience. He recently completed his M.Sc. in Computer Science at the Hebrew University in Jerusalem, with primary research in the field of performance evaluation. When not coding, he can probably be found with a DSLR in hands, trying to catch just the perfect photo of his baby daughter's smile.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An approach to the workload characterization problem</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Agrawala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Mohr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Bryant</surname></persName>
		</author>
		<idno type="DOI">10.1109/C-M.1976.218610</idno>
		<ptr target="http://dx.doi.org/10.1109/C-M.1976.218610" />
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="18" to="32" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Mixed integer-linear formulations of cumulative scheduling constraints-A comparative study</title>
		<author>
			<persName><forename type="first">M</forename><surname>Aronsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bohlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kreuger</surname></persName>
		</author>
		<idno>2399</idno>
		<ptr target="http://soda.swedish-ict.se/2399/" />
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Swedish Institute of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">SICS Report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Benchmarks and standards for the evaluation of parallel job schedulers</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Chapin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cirne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Feitelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Leutenegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Schwiegelshohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Talby</surname></persName>
		</author>
		<idno type="DOI">10.1007/3-540-47954-6_4</idno>
		<ptr target="http://dx.doi.org/10.1007/3-540-47954-6_4" />
	</analytic>
	<monogr>
		<title level="m">Job Scheduling Strategies for Parallel Processing</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">1659</biblScope>
			<biblScope unit="page" from="67" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Cirne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Berman</surname></persName>
		</author>
		<idno type="DOI">10.1109/WWC.2001.990753</idno>
		<ptr target="http://dx.doi.org/10.1109/WWC.2001.990753" />
		<title level="m">A comprehensive model of the supercomputer workload, in: 4th Workshop on Workload Characterization</title>
		<imprint>
			<date type="published" when="2001-12">Dec 2001</date>
			<biblScope unit="page" from="140" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Emeras</surname></persName>
		</author>
		<title level="m">Workload traces analysis and replay in large scale distributed systems</title>
		<meeting><address><addrLine>Grenoble University</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A revival of integrity constraints for data cleaning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Geerts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endowment</title>
		<meeting>VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1522" to="1523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Packing schemes for gang scheduling</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Feitelson</surname></persName>
		</author>
		<idno type="DOI">10.1007/BFb0022289</idno>
		<ptr target="http://dx.doi.org/10.1007/BFb0022289" />
	</analytic>
	<monogr>
		<title level="m">Job Scheduling Strategies for Parallel Processing</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">1162</biblScope>
			<biblScope unit="page" from="89" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Experimental computer science: the need for a cultural change</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Feitelson</surname></persName>
		</author>
		<ptr target="http://www.cs.huji.ac.il/~feit/papers/exp05.pdf" />
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Feitelson</surname></persName>
		</author>
		<idno type="DOI">10.1007/3-540-63574-2_17</idno>
		<ptr target="http://dx.doi.org/10.1007/3-540-63574-2_17" />
	</analytic>
	<monogr>
		<title level="m">Memory usage in the LANL CM-5 workload, in: Job Scheduling Strategies for Parallel Processing</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">1291</biblScope>
			<biblScope unit="page" from="78" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Experimental analysis of the root causes of performance evaluation results: a backfilling case study</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Feitelson</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPDS.2005.18</idno>
		<ptr target="http://dx.doi.org/10.1109/TPDS.2005.18" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Parallel Distrib. Syst</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="175" to="182" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improved utilization and responsiveness with gang scheduling</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Feitelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Jette</surname></persName>
		</author>
		<idno type="DOI">10.1007/3-540-63574-2_24</idno>
		<ptr target="http://dx.doi.org/10.1007/3-540-63574-2_24" />
	</analytic>
	<monogr>
		<title level="m">Job Scheduling Strategies for Parallel Processing</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">1291</biblScope>
			<biblScope unit="page" from="238" to="261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On the definition of on-line in job scheduling problems</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Feitelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Mu'alem</surname></persName>
		</author>
		<idno type="DOI">10.1145/1052796.1052797</idno>
		<ptr target="http://dx.doi.org/10.1145/1052796.1052797" />
	</analytic>
	<monogr>
		<title level="j">SIGACT News</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="122" to="131" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Job characteristics of a production parallel scientific workload on the NASA Ames iPSC/860</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Feitelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nitzberg</surname></persName>
		</author>
		<idno type="DOI">10.1007/3-540-60153-8_38</idno>
		<ptr target="http://dx.doi.org/10.1007/3-540-60153-8_38" />
	</analytic>
	<monogr>
		<title level="m">Job Scheduling Strategies for Parallel Processing</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">949</biblScope>
			<biblScope unit="page" from="337" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Workload sanitation for performance evaluation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Feitelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tsafrir</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISPASS.2006.1620806</idno>
		<ptr target="http://dx.doi.org/10.1109/ISPASS.2006.1620806" />
	</analytic>
	<monogr>
		<title level="j">IEEE Intl. Symp. Performance Analysis Syst. &amp; Software</title>
		<imprint>
			<biblScope unit="page" from="221" to="230" />
			<date type="published" when="2006-03">Mar 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Workload characterization and selection in computer performance measurement</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ferrari</surname></persName>
		</author>
		<idno type="DOI">10.1109/C-M.1972.216939</idno>
		<ptr target="http://dx.doi.org/10.1109/C-M.1972.216939" />
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="18" to="24" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Data quality in practice: experience from the frontline</title>
		<author>
			<persName><forename type="first">C</forename><surname>Firth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. Information Quality</title>
		<imprint>
			<date type="published" when="1996-10">Oct 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Criticality of data quality as exemplified in two disasters</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Kingma</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0378-7206(01)00083-0</idno>
		<ptr target="http://dx.doi.org/10.1016/S0378-7206" />
	</analytic>
	<monogr>
		<title level="j">Inf. Manage</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="83" to="83" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The misuse of the NASA metrics data program data sets for automated software defect prediction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bowes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Davey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Christianson</surname></persName>
		</author>
		<idno type="DOI">10.1049/ic.2011.0012</idno>
		<ptr target="http://dx.doi.org/10.1049/ic.2011.0012" />
	</analytic>
	<monogr>
		<title level="j">Evaluation &amp; Assessment in Softw. Eng</title>
		<imprint>
			<biblScope unit="page" from="96" to="103" />
			<date type="published" when="2011-04">Apr 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The genome sequence database (GSDB): improving data quality and data access</title>
		<author>
			<persName><forename type="first">C</forename><surname>Harger</surname></persName>
		</author>
		<idno type="DOI">10.1093/nar/26.1.21</idno>
		<ptr target="http://dx.doi.org/10.1093/nar/26.1.21" />
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="26" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<author>
			<persName><forename type="first">S</forename><surname>Hotovy</surname></persName>
		</author>
		<idno type="DOI">10.1007/BFb0022285</idno>
		<ptr target="http://dx.doi.org/10.1007/BFb0022285" />
	</analytic>
	<monogr>
		<title level="m">Workload evolution on the Cornell Theory Center IBM SP2, in: Job Scheduling Strategies for Parallel Processing</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">1162</biblScope>
			<biblScope unit="page" from="27" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The grid workloads archive</title>
		<author>
			<persName><forename type="first">A</forename><surname>Iosup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Anoep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dumitrescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wolters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H J</forename><surname>Epema</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.future.2008.02.003</idno>
		<ptr target="http://dx.doi.org/10.1016/j.future.2008.02.003" />
	</analytic>
	<monogr>
		<title level="j">Future Gener. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="672" to="686" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The importance of complete data sets for job scheduling simulations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Klusáček</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rudová</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-16505-4_8</idno>
		<ptr target="http://dx.doi.org/10.1007/978-3-642-16505-4_8" />
	</analytic>
	<monogr>
		<title level="m">Job Scheduling Strategies for Parallel Processing</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Frachtenberg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Schwiegelshohn</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6253</biblScope>
			<biblScope unit="page" from="132" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Developing a framework for assessing information quality on the world wide web</title>
		<author>
			<persName><forename type="first">S.-A</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Burn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Informing Science J</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="159" to="172" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Choosing representative slices of program execution for microarchitecture simulations: a preliminary application to the data stream</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lafage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">rd Workshop on Workload Characterization</title>
		<imprint>
			<date type="published" when="2000-09">Sep 2000</date>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multi-capacity bin packing algorithms with applications to job scheduling under multiple constraints</title>
		<author>
			<persName><forename type="first">W</forename><surname>Leinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. Parallel Processing</title>
		<imprint>
			<date type="published" when="1999-09">Sep 1999</date>
			<biblScope unit="page" from="404" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Using metadata and web metrics to create a ranking of genomic databases</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lichtnow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IADIS Intl. Conf. WWW/Internet</title>
		<imprint>
			<date type="published" when="2011-11">Nov 2011</date>
			<biblScope unit="page" from="253" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A comparative study of real workload traces and synthetic workload models for parallel job scheduling</title>
		<author>
			<persName><forename type="first">V</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Windisch</surname></persName>
		</author>
		<idno type="DOI">10.1007/BFb0053979</idno>
		<ptr target="http://dx.doi.org/10.1007/BFb0053979" />
	</analytic>
	<monogr>
		<title level="m">Job Scheduling Strategies for Parallel Processing</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">1459</biblScope>
			<biblScope unit="page" from="25" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Overview and framework for data and information quality research</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Madnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1145/1515693.1516680</idno>
		<ptr target="http://dx.doi.org/10.1145/1515693.1516680" />
	</analytic>
	<monogr>
		<title level="j">ACM J. Data &amp; Inf. Quality</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Utilization, predictability, workloads, and user runtime estimates in scheduling the IBM SP2 with backfilling</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Mu'alem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Feitelson</surname></persName>
		</author>
		<idno type="DOI">10.1109/71.932708</idno>
		<ptr target="http://dx.doi.org/10.1109/71.932708" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Parallel Distrib. Syst</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="529" to="543" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Data quality in genome databases</title>
		<author>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Freytag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th Intl. Conf. Information Quality</title>
		<imprint>
			<date type="published" when="2003-11">Nov 2003</date>
			<biblScope unit="page" from="269" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The impact of poor data quality on the typical enterprise, Commun</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Redman</surname></persName>
		</author>
		<idno type="DOI">10.1145/269012.269025</idno>
		<ptr target="http://dx.doi.org/10.1145/269012.269025" />
	</analytic>
	<monogr>
		<title level="j">ACM</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="79" to="82" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Reiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tumanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Ganger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Kozuch</surname></persName>
		</author>
		<idno type="DOI">10.1145/2391229.2391236</idno>
		<ptr target="http://dx.doi.org/10.1145/2391229.2391236" />
		<title level="m">Heterogeneity and dynamicity of clouds at scale: Google trace analysis, in: 3rd Symp. Cloud Comput</title>
		<imprint>
			<date type="published" when="2012-10">Oct 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Evaluation of task assignment policies for supercomputing servers: the case for load unbalancing and fairness</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harchol-Balter</surname></persName>
		</author>
		<idno type="DOI">10.1023/B:CLUS.0000018564.05723.a2</idno>
		<ptr target="http://dx.doi.org/10.1023/B:CLUS.0000018564.05723.a2" />
	</analytic>
	<monogr>
		<title level="j">Cluster Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="151" to="161" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Data quality: some comments on the NASA software defect datasets</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shepperd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mair</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSE.2013.11</idno>
		<ptr target="http://dx.doi.org/10.1109/TSE.2013.11" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Softw. Eng</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1208" to="1215" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Automatically characterizing large scale program behavior</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
		<idno type="DOI">10.1145/605397.605403</idno>
		<ptr target="http://dx.doi.org/10.1145/605397.605403" />
	</analytic>
	<monogr>
		<title level="j">10th Intl. Conf. Architect. Support for Prog. Lang. &amp; Operating Syst</title>
		<imprint>
			<biblScope unit="page" from="45" to="57" />
			<date type="published" when="2002-10">Oct 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Backfilling with lookahead to optimize the packing of parallel jobs</title>
		<author>
			<persName><forename type="first">E</forename><surname>Shmueli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Feitelson</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jpdc.2005.05.003</idno>
		<ptr target="http://dx.doi.org/10.1016/j.jpdc.2005.05.003" />
	</analytic>
	<monogr>
		<title level="j">J. Parallel Distrib. Comput</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1090" to="1107" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A survey of data provenance in e-science</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename><surname>Simmhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Plale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gannon</surname></persName>
		</author>
		<idno type="DOI">10.1145/1084805.1084812</idno>
		<ptr target="http://dx.doi.org/10.1145/1084805.1084812" />
	</analytic>
	<monogr>
		<title level="j">SIGMOD Rec</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="31" to="36" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Workloads (creation and use)</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1145/1297797.1297821</idno>
		<ptr target="http://dx.doi.org/10.1145/1297797.1297821" />
	</analytic>
	<monogr>
		<title level="j">Comm. ACM</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="45" to="50" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Data quality in context</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Strong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1145/253769.253804</idno>
		<ptr target="http://dx.doi.org/10.1145/253769.253804" />
	</analytic>
	<monogr>
		<title level="j">Comm. ACM</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="103" to="110" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m">Connection Machine CM-5 Technical Summary</title>
		<imprint>
			<publisher>Thinking Machines Corp</publisher>
			<date type="published" when="1992-11">Nov 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Modeling, evaluating, and improving the performance of supercomputer scheduling</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tsafrir</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
		<respStmt>
			<orgName>Hebrew University</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Instability in parallel job scheduling simulation: the role of workload flurries</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tsafrir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Feitelson</surname></persName>
		</author>
		<idno type="DOI">10.1109/IPDPS.2006.1639311</idno>
		<ptr target="http://dx.doi.org/10.1109/IPDPS.2006.1639311" />
	</analytic>
	<monogr>
		<title level="m">20th Intl. Parallel &amp; Distributed Processing Symp</title>
		<imprint>
			<date type="published" when="2006-04">Apr 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Reducing performance evaluation sensitivity and variability by input shaking</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tsafrir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ouaknine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Feitelson</surname></persName>
		</author>
		<idno type="DOI">10.1109/MASCOTS.2007.58</idno>
		<ptr target="http://dx.doi.org/10.1109/MASCOTS.2007.58" />
	</analytic>
	<monogr>
		<title level="m">th Modeling</title>
		<imprint>
			<date type="published" when="2007-10">Oct 2007</date>
			<biblScope unit="page" from="231" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Beyond accuracy: what data quality means to data consumers</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Strong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Management Inf. syst</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="5" to="33" />
			<date type="published" when="1996">1996</date>
			<pubPlace>Spring</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A batch scheduler for the Intel Paragon with a non-contiguous node allocation algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kremenek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Steube</surname></persName>
		</author>
		<idno type="DOI">10.1007/BFb0022287</idno>
		<ptr target="http://dx.doi.org/10.1007/BFb0022287" />
	</analytic>
	<monogr>
		<title level="m">Job Scheduling Strategies for Parallel Processing</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">1162</biblScope>
			<biblScope unit="page" from="48" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Workload resampling for performance evaluation of parallel job schedulers</title>
		<author>
			<persName><forename type="first">N</forename><surname>Zakay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Feitelson</surname></persName>
		</author>
		<idno type="DOI">10.1002/cpe.3240</idno>
		<ptr target="http://dx.doi.org/10.1002/cpe.3240" />
	</analytic>
	<monogr>
		<title level="j">Concurrency &amp; Computation-Pract. Exp</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Coanalysis of RAS log and job log on Blue Gene/P</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Coghlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Buettner</surname></persName>
		</author>
		<idno type="DOI">10.1109/IPDPS.2011.83</idno>
		<ptr target="http://dx.doi.org/10.1109/IPDPS.2011.83" />
	</analytic>
	<monogr>
		<title level="m">Intl. Parallel &amp; Distributed Processing Symp</title>
		<imprint>
			<date type="published" when="2011-05">May 2011</date>
			<biblScope unit="page" from="840" to="851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Job packing and re-packing schemes for enhancing the performance of gang scheduling</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Walsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Brent</surname></persName>
		</author>
		<idno type="DOI">10.1007/3-540-47954-6_7</idno>
		<ptr target="http://dx.doi.org/10.1007/3-540-47954-6_7" />
	</analytic>
	<monogr>
		<title level="m">Job Scheduling Strategies for Parallel Processing</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">1659</biblScope>
			<biblScope unit="page" from="129" to="143" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
