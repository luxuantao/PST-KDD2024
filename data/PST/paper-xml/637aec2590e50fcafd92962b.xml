<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AXI-Pack: Near-Memory Bus Packing for Bandwidth-Efficient Irregular Workloads</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chi</forename><surname>Zhang</surname></persName>
							<email>chizhang@iis.ee.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Integrated Systems Laboratory</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Scheffler</surname></persName>
							<email>paulsc@iis.ee.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Integrated Systems Laboratory</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Benz</surname></persName>
							<email>tbenz@iis.ee.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Integrated Systems Laboratory</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matteo</forename><surname>Perotti</surname></persName>
							<email>mperotti@iis.ee.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Integrated Systems Laboratory</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luca</forename><surname>Benini</surname></persName>
							<email>lbenini@iis.ee.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Integrated Systems Laboratory</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical, Electronic, and Information Engineering</orgName>
								<orgName type="institution">University of Bologna</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AXI-Pack: Near-Memory Bus Packing for Bandwidth-Efficient Irregular Workloads</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Computer architecture</term>
					<term>On-chip interconnects</term>
					<term>Memory systems</term>
					<term>Irregular workloads</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data-intensive applications involving irregular memory streams are inefficiently handled by modern processors and memory systems highly optimized for regular, contiguous data. Recent work tackles these inefficiencies in hardware through core-side stream extensions or memory-side prefetchers and accelerators, but fails to provide end-to-end solutions which also achieve high efficiency in on-chip interconnects. We propose AXI-Pack, an extension to ARM's AXI4 protocol introducing bandwidth-efficient strided and indirect bursts to enable end-toend irregular streams. AXI-Pack adds irregular stream semantics to memory requests and avoids inefficient narrow-bus transfers by packing multiple narrow data elements onto a wide bus. It retains full compatibility with AXI4 and does not require modifications to non-burst-reshaping interconnect IPs. To demonstrate our approach end-to-end, we extend an open-source RISC-V vector processor to leverage AXI-Pack at its memory interface for strided and indexed accesses. On the memory side, we design a banked memory controller efficiently handling AXI-Pack requests. On a system with a 256-bit-wide interconnect running FP32 workloads, AXI-Pack achieves near-ideal peak on-chip bus utilizations of 87% and 39%, speedups of 5.4x and 2.4x, and energy efficiency improvements of 5.3x and 2.1x over a baseline using an AXI4 bus on strided and indirect benchmarks, respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Growing performance demands and large, sparse datasets in domains like machine learning <ref type="bibr" target="#b0">[1]</ref>, graph analytics <ref type="bibr" target="#b1">[2]</ref>, fluid dynamics <ref type="bibr" target="#b2">[3]</ref>, and recommender systems <ref type="bibr" target="#b3">[4]</ref> push data-driven applications toward increasingly irregular data access patterns. This poses a challenge to general-purpose CPUs <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref> and GPUs <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b6">[7]</ref> optimized for highly regular compute. To keep their functional units highly utilized and achieve satisfactory performance and energy efficiency, single-instruction, multipledata (SIMD) architectures require contiguous data chunks not naturally found in irregular workloads. Memory hierarchies are also tuned to contiguous, high-locality data and struggle with irregular access patterns <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, resulting in long latencies, poor bandwidth utilization, and cache thrashing.</p><p>Existing research aims to improve irregular workload performance and tackle these shortcomings through core-side or memory-side hardware extensions. Core-side extensions often use stream abstractions <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b7">[8]</ref>- <ref type="bibr" target="#b9">[10]</ref> to describe entire sequences of irregular accesses, freeing processors from address calculation and decoupling memory accesses from exe- ? Both authors contributed equally to this research. cution. Most works focus on accelerating strided and indirect streams, which are most common in practice <ref type="bibr" target="#b5">[6]</ref>. Mapping these streams to architectural registers <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b7">[8]</ref>- <ref type="bibr" target="#b9">[10]</ref> further improves functional unit utilization and enables significant speedups. However, these works largely ignore downstream interconnects and memory systems. While some authors propose high-level cache policies to avoid thrashing <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, they do not address fundamental limitations like the high index-fetching overhead of core-side indirection and the inherent inefficiency of narrow bus accesses in address-based interconnects.</p><p>In contrast, memory-side extensions prefetch and accelerate irregular accesses using pattern-aware memory controllers <ref type="bibr" target="#b10">[11]</ref>, prefetchers <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, and data layout transform (DLT) accelerators <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. Unlike core-side extensions, these solutions reduce access times and prevent narrow bus accesses by packing fetched irregular elements into bus-wide lines, which are then mapped to virtual addresses <ref type="bibr" target="#b10">[11]</ref>, written to internal scratchpads <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, or written back to memory <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. However, these solutions have their own drawbacks: they occupy virtual or physical memory and lack the tight architectural integration of core-side extensions, limiting their acceleration potential and complicating programming.</p><p>Thus, while existing core-and memory-side extensions tackle inefficiencies in their respective domains, they forego each other's benefits and do not integrate with established onchip interconnect protocols, failing to provide an end-to-end solution for bandwidth-efficient irregular streams.</p><p>To address these shortcomings, we propose AXI-PACK, an extension to Arm's widespread Advanced eXtensible Interface 4 (AXI4) on-chip protocol enabling end-to-end, tightly-packed strided and indirect memory streams. AXI-PACK transparently extends AXI4's existing contiguous bursts, leveraging their decoupled, latency-resilient nature. It remains compatible with all existing AXI4 features and even existing interconnect blocks that do not reshape bursts. It encodes stream semantics (stride or index base and size) directly into burst requests, ensuring performance and flexibility even for short streams. Indirection is efficiently handled at memory endpoints. In principle, AXI-PACK supports non-core requestors (e.g., accelerators) and systems with multiple requestors and endpoints.</p><p>To demonstrate AXI-PACK in an end-to-end full-system context, we extend an open-source RISC-V vector processor for efficient strided and indexed accesses and design a banked memory controller efficiently handling irregular bursts. On a system with a 256-bit-wide AXI-PACK bus running various irregular FP32 workloads, we achieve bus utilizations of up to 87 % on strided and 39 % on indirect benchmarks, resulting in peak speedups of 5.4? and 2.4? over a baseline with a standard AXI4 bus. We implement our evaluation system in GlobalFoundries' 22nm FD-SOI technology and find that AXI-PACK improves energy efficiency by up to 5.3? and 2.1? in strided and indirect benchmarks while incurring only 6.2 % of our vector processor's area for our controller. Finally, we analyze the impact of element and index size as well as bank count on AXI-PACK performance and controller complexity.</p><p>To summarize, our contributions are as follows: 1) We extend the widespread high-performance on-chip protocol AXI4 to support end-to-end bus-packed strided and indirect streams with full backward compatibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2)</head><p>We extend an open-source RISC-V vector processor with AXI-PACK to enable high bus efficiencies and significant speedups on irregular workloads, and demonstrate a simple banked memory controller to serve irregular bursts. 3) We evaluate AXI-PACK by benchmarking irregular workloads on our extended vector processor, achieving bus utilizations of up to 87 % and 39 % and speedups of up to 5.4? and 2.4? for strided and indirect workloads. 4) We evaluate our AXI-PACK system and controller in terms of timing, area, and energy efficiency benefits, finding energy efficiency improvements of up to 5.3? and 2.1?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. ARCHITECTURE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. AXI-Pack Protocol</head><p>AXI-PACK extends Arm's AXI4 <ref type="bibr" target="#b15">[16]</ref>, a widely-adopted highperformance non-coherent on-chip memory protocol. AXI4 defines five independent channels: AR and AW carry read and write requests, R and W carry read and write data, and B carries the write response. Without extensions, linear, fixed, and wrapping bursts are supported. Each channel provisions a user field of parametric width that allows extending functionality without compromising compatibility with the baseline protocol.</p><p>AXI-PACK extends the request channels AR and AW with user signals to support packed irregular bursts as illustrated in Figure <ref type="figure">1</ref>. The pack bit indicates whether our extension is used, while the indir bit differentiates between strided and indirect bursts. The remaining bits are shared between both burst types; they indicate either the element stride for strided bursts or the index size and base offset for indirect bursts.</p><p>While active, the new irregular burst types alter the semantics of existing channel fields. Most notably, data elements of the requested size, scattered in memory, are tightly packed onto the R and W data buses to fully utilize them. Additionally, the start of irregular bursts is aligned with the bus instead of the address to simplify feeding data to and from vectorized functional units. Finally, the AR and AW size fields, usually only changed for narrow beats, indicate the data element size.</p><p>In addition to performance and bus utilization, these semantics aim to maximize the transparency and portability of AXI-PACK: they ensure that any existing AXI4 intellectual property (IP) blocks handling non-modifiable transactions without splitting, such as the routing blocks provided in <ref type="bibr" target="#b16">[17]</ref>, are already compatible with AXI-PACK without any modifications. IPs that require burst splitting or reshaping, such as bus width converters, can easily be extended to support AXI-PACK by repacking bus-aligned data elements as for existing burst types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Vector Processor Extension</head><p>To demonstrate the benefits and flexibility of AXI-PACK, we extend the open-source Ara <ref type="bibr" target="#b17">[18]</ref> RISC-V vector processor to leverage it for efficient irregular memory accesses. Ara acts as a co-processor to the CVA6 core <ref type="bibr" target="#b18">[19]</ref>, which dispatches vector instructions to Ara. Both access memory over AXI4.</p><p>As mandated by its instruction set, Ara supports three vector memory access types: contiguous, strided, and indexed. Without extensions, only contiguous accesses can leverage bursts. For strided and indexed accesses, Ara must compute the address and issue individual narrow accesses for each element, leaving the data channels severely underutilized as shown in Figure <ref type="figure">1</ref>.</p><p>Figure <ref type="figure" target="#fig_0">2a</ref> shows our extensions to Ara. We modify its vector load-store unit (VLSU) to use AXI-PACK for strided and indexed vector accesses. For strided accesses, we simply translate the existing vlse and vsse instructions to AXI-PACK requests and exchange the read or written data directly with vector registers or functional lanes for chaining. The existing indexed access instructions vl(o|u)xei and vs(o|u)xei in the RISC-V vector extension presume that indices are already loaded into vector registers, necessitating the move of indices into the core and precluding efficient memory-side indirection. To remedy this, we extend Ara's decoder and introduce two new in-memory indexed access instructions, vlimxei and vsimxei, which use index arrays in memory for indirection. These instructions can directly be translated to indirect AXI-PACK bursts and allow for packed bus data to be exchanged with registers or lanes without format changes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Banked Memory Controller</head><p>To demonstrate the efficient handling of AXI-PACK at banked memory endpoints, we design a proof-of-concept controller translating AXI-PACK requests to sequences of parallel banked memory accesses. Our controller is fully backward-compatible with and efficiently handles regular AXI4 bursts.</p><p>Figure <ref type="figure" target="#fig_0">2b</ref> shows the controller architecture. The adapter translates both regular and irregular bursts to sequences of n parallel word accesses, where a word is the same width W as the used memory banks and determines the smallest efficientlyhandled element size. For D-bit-wide AXI-PACK data buses, n = D/W , since we must read or write D/W words in parallel Internally, the adapter forwards requests to one of five converters which may concurrently handle bursts. The base converter handles regular AXI4 bursts, while the remaining converters are dedicated to strided and indirect read and write operations, respectively. Handling reads and writes individually leverages the inherent concurrency of the R and W channels.</p><p>Figure <ref type="figure" target="#fig_0">2c</ref> details the strided read converter architecture. For each beat in a burst, the request generator issues n parallel word requests fetching the elements to be packed and pushes metadata needed for later packing into an info queue. The words read from the banks are stored in decoupling queues and then passed to the beat packer, which packs the words as specified by metadata popped from the info queue to form the R beats. To prevent word queue overflows, a request regulator limits the number of requests in-flight for each word lane.</p><p>Figure <ref type="figure" target="#fig_0">2d</ref> shows the indirect read converter architecture. It involves two stages sharing the n word request ports through round-robin arbitration: the index stage fetches indices from memory and the element stage uses these indices to fetch indirect elements and pack them into R beats. The index stage is analogous to the strided read converter, but issues only contiguous word requests. The fetched indices are passed to the element request generator, which shifts and adds them to the specified base address to generate word requests for the desired elements. Finally, the requested elements are packed by a beat packer as specified by metadata from the element request generator to form the desired R beats.</p><p>The corresponding strided and indirect write converters are similar and differ only in the direction of the datapath: a beat unpacker splits beats into individual words, which are then used as write data for the generated write requests. The memory responses are combined and forwarded to the B channel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EVALUATION A. Setup and Workloads</head><p>To evaluate AXI-PACK, we consider three RISC-V systemson-chip (SoCs) using CVA6 with Ara as a vector processor, AXI4 interconnects, and a banked on-chip SRAM memory:</p><p>? BASE: unmodified CVA6 and Ara connecting to a regular banked memory over a standard AXI4 bus. ? PACK: unmodified CVA6 and AXI-PACK-extended Ara connecting to a banked memory with an AXI-PACK controller over an AXI-PACK-extended bus. ? IDEAL: like BASE, but Ara connects directly to an exclusive, idealized memory with one port per lane, serving data with ideal packing, bandwidth, and latency.</p><p>IDEAL provides an upper bound for possible AXI-PACK benefits by idealizing interactions between Ara's VLSU and memory. However, it does not avoid inefficiencies arising from Ara's internal microarchitecture or CVA6. In all systems, Ara is parameterized to eight vector lanes and 256-bit-wide data buses. The banked memories provide eight 32-bit-wide word ports backed by 17 banks, which we determine in Section III-E to provide a good area-performance tradeoff.</p><p>On each system, we evaluate a set of vectorized benchmarks benefiting from efficient strided and indirect memory accesses:</p><p>? ismt: in-situ matrix transpose. We transpose a square matrix in place by swapping and rotating elements above and below the diagonal using strided accesses. ? gemv: general matrix-vector multiply. We investigate both rowand column-wise dataflows, with the latter trading vector reductions for strided accesses, and use the fastest approach on each system for fair comparisons. ? trmv: triangular matrix-vector multiply, a gemv with an upper-triangular matrix. Only nonzero elements are streamed, incurring bursts of varying lengths. We again use the fastest dataflow on each system. ? spmv: sparse matrix-vector multiply, a widespread irregular memory-bound operation using indirect accesses. ? prank: PageRank <ref type="bibr" target="#b19">[20]</ref>, which rates each node in a graph based on the edges inbound to it. The graph is represented as a sparse weighted adjacency matrix.</p><p>? sssp: single-source shortest path, which calculates the shortest path from one node to all others in a weighted, directed graph represented as a sparse matrix. We run the first three benchmarks leveraging strided streams on randomly-generated square matrices and the latter three leveraging indirect streams on real-world sparse matrices from the SuiteSparse collection in the widespread compressed sparse rows (CSR) format. Elements are stored as 32-bit floats and indices as 32-bit integers. On indirect workloads, the PACK system uses our extensions to handle indirection in-memory, whereas BASE and IDEAL systems fetch indices into Ara.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Performance</head><p>We simulate our systems at the register transfer level (RTL) to determine the performance and read bus utilization for each benchmark. We initially assume a fixed matrix size of 256 for strided workloads and the sparse matrix heart1 (390 average nonzeros per row) for indirect workloads. gemv and trmv use a column-wise dataflow on PACK and IDEAL and a row-wise dataflow on BASE, which we will show to be optimal for each respective system. Fig. <ref type="figure" target="#fig_1">3a</ref> shows PACK speedups over BASE and read bus utilizations with and without index transfers. AXI-PACK significantly improves bus utilization and performance for all workloads, achieving 97 % of the IDEAL performance on average. On strided workloads, we measure peak speedups of 5.4? (ismt) and bus utilizations of 87 % (gemv). We note that read bus utilizations on ismt are limited to 50 % due to read-write ordering in Ara. On indirect workloads, we achieve speedups of up to 2.4? (spmv) and bus utilizations of up to 39 % (sssp).</p><p>PACK handles indirection directly in its AXI-PACK controller, avoiding IDEAL's waste of up to 20 % (spmv) of bus time on index traffic and shifting indexed workloads further from the memory-bound toward the compute-bound regime.</p><p>Figs. 3b and 3c compare the row-and column-wise dataflow performance for gemv and trmv. Row-wise flows use only long contiguous accesses, so their performance is identical for BASE and PACK and very close to IDEAL. However, they require costly vector reductions, limiting BASE bus utilizations to 37 % and 23 %. Column-wise flows avoid reduction by working on multiple results at once, providing higher IDEAL performance and PACK utilizations of 87 % and 72 %. However for BASE, we stick to a row-wise flow, as the performance impact of strided accesses outweighs that of reductions without our extensions.</p><p>We also analyze the impact of input size and bus width on AXI-PACK speedups for representative strided and indirect workloads. Figure <ref type="figure" target="#fig_1">3d</ref> shows ismt speedups for matrix dimensions of 8 to 256 and bus widths of 64 to 256 bit, corresponding to 2 to 8 Ara lanes. As matrix size increases, speedups converge and reach up to 1.9, 3.2, and 5.4?; as we widen the bus, the narrow accesses of BASE become less efficient, increasing peak PACK speedups. As matrix size decreases, streams and useful computation phases shorten and become bottlenecked by the overhead of row iteration, decreasing speedups. Figure <ref type="figure" target="#fig_1">3e</ref> shows spmv speedups for sparse matrices with 2 to 390 average nonzeros per row and the same bus widths as before. Speedups again converge and reach up to 1.4, 1.8, and 2.4?. We see similar scaling trends as for ismt because in spmv, the nonzeros per row determine the computation phase and stream lengths in each row iteration. We note that thanks to our request-bundling approach, using AXI-PACK never results in a slowdown no matter how short streams become.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Area and Timing</head><p>We synthesize our AXI-PACK adapter with Synopsys Design Compiler for GlobalFoundries' 22 nm FD-SOI technology, targeting the SSG corner at -40 ?C with low-V t cells, 0.72V supply voltage, and no back-biasing. Unless otherwise specified, we constrain a 1 GHz clock and 100 ps IO delays and parameterize the decoupling queues to a depth of four.</p><p>Fig. <ref type="figure" target="#fig_4">4a</ref> shows the minimum achieved clock period and area for different clock constraints and bus widths of 64, 128, and 256 bit. Our adapter shows good scalability, increasing linearly in area with bus width and incurring 69, 130 and 257 kGE at 1 GHz. Our full 256-bit controller incurs merely 6.2 % of Ara's area, demonstrating that AXI-PACK handling at banked endpoints is reasonably inexpensive. As we decrease the constrained clock, we see that adapter area scales gracefully past Ara's 1 GHz clock target and reaches minimum periods of 787, 800, and 839 ps with only small increases in area.</p><p>Fig. <ref type="figure" target="#fig_4">4b</ref> shows a hierarchical area breakdown of the adapter. As expected, the read and write converters are similar in size for both irregular burst types, since they simply reverse each other's datapaths. While the simpler strided converters are only up to 42 % larger than the base AXI4 converter, the indirect converters are nearly double this size due their two stages.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Energy and Power</head><p>We estimate the power consumption of PACK and BASE, excluding the SRAM crossbar and banks, in the TT corner of GlobalFoundries' 22 nm FD-SOI technology at 1 GHz. We topographically synthesize our system using Synopsys Design Compiler and estimate power on the benchmarks from Section III-B using Synopsys PrimeTime. Figure <ref type="figure" target="#fig_4">4c</ref> shows the average power and energy efficiency improvement of PACK over BASE for each benchmark. Despite small power increases in PACK by at most 31 % (trmv), all workloads see notable energy efficiency improvements, achieving peaks of 5.3? (ismt) and 2.1? (sssp) on strided and indirect benchmarks, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Parameter Sensitivity</head><p>To gain deeper insight into the scaling of AXI-PACK performance and hardware complexity, we investigate the impact of element and index size as well as bank count on read bus utilization and bank crossbar area. For performance measurements, we connect our controller to an ideal requestor issuing continuous read requests of length 256 and use random indices. Unless otherwise specified, parameters default on their PACK system configuration, but we increase decoupling queue depths to 32 to avoid bottlenecks unrelated to our analysis. We consider power-of-two bank counts from 8 to 32, which result in minimal addressing logic, as well as prime counts in this range, which minimize bank conflicts across different strides. We also consider an ideal memory without bank conflicts.</p><p>Indirect accesses: Figure <ref type="figure">5a</ref> shows the bus utilization achieved on indirect reads for different element-index size pairs and bank counts. For all size pairs, utilization increases monotonically with bank count as fewer bank conflicts occur. Since indirect bursts involve one contiguous and one random but no strided bank access sequences, prime bank counts show  <ref type="figure">5b</ref> shows the bus utilization for strided reads for different element sizes and bank counts, averaged across element strides of 0 to 63. As expected, prime bank counts offer significant performance benefits on strided accesses, though more banks further improve performance for both power-of-two and prime bank counts. With increasing element size, conflicts become less likely for all bank counts as there are fewer aligned elements in each bus-wide line.</p><p>Bank crossbar area: Figure <ref type="figure">5c</ref> shows the bank crossbar's total area for different bank counts, highlighting the overhead prime bank counts incur for modulo and division units to compute bank addresses. Power-of-two-banked crossbars are generally cheaper and prime-banked overheads decrease with increasing bank counts. Since 17 banks provide good areaoverhead and area-performance tradeoffs (95% and 81% of ideal performance on strided and indirect reads on average), this is the bank count we chose for our evaluation systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RELATED WORK</head><p>Existing hardware approaches to efficient strided and indirect streams focus mostly on either end of the memory system.</p><p>Core-side extensions decouple accesses from execution and eliminate redundant load-store and bookkeeping instructions. Prodigy <ref type="bibr" target="#b4">[5]</ref> prefetches nested indirect streams and proposes dynamic cache bypass policies. While highly decoupled, it does not simplify program flow, limiting its acceleration. Wang et al. <ref type="bibr" target="#b5">[6]</ref> propose strided and indirect streams mapped directly to architectural registers. This eliminates load-store and address iteration instructions, but still incurs dedicated instructions to step streams. Stream semantic registers <ref type="bibr" target="#b7">[8]</ref> and their indirection extensions <ref type="bibr" target="#b8">[9]</ref> implicitly step streams on access, enabling near-continuous useful instruction issues even on single-issue in-order cores. Domingos et al. <ref type="bibr" target="#b9">[10]</ref> extend register-mapped irregular streams to vector processors. Except for cache policies, these extensions ignore interconnect and memory system efficiency. AXI-PACK is largely orthogonal to all of them; it may be used with any bus width, burst length, or mapping mechanism, providing a reusable protocol carrying irregular streams through interconnects and to stream-aware endpoints with high bus efficiency.</p><p>Memory-side extensions focus on bus efficiency and access latency. The Impulse memory controller <ref type="bibr" target="#b10">[11]</ref> maps irregular streams to virtual pages; it provides inherent, on-the-fly bus packing, but relies on managed virtual addressing. Hussain et al. propose pattern-aware memory controllers <ref type="bibr" target="#b12">[13]</ref> and systems <ref type="bibr" target="#b11">[12]</ref> prefetching irregular stream descriptors to dedicated scratchpads. This enables fast, packed core accesses, but incurs notable complexity overheads. PLANAR <ref type="bibr" target="#b13">[14]</ref> accelerates layout transforms by writing packed, cacheable irregular data to memory ahead of use, and the data rearrangement engine <ref type="bibr" target="#b14">[15]</ref> is integrated directly into a hybrid memory cube architecture. While DLT accelerators are highly bandwidth-efficient, they require physical memory buffers and explicit, ahead-of-time invocation to be beneficial. AXI-PACK enables the benefits of all of the above extensions. Bus packing can be done on the fly by our controller or ahead of time by an AXI-PACK-capable direct memory access (DMA) controller. Our lightweight irregular requests provide performance without precluding the use of more complex, memory-mapped stream descriptors. However unlike other proposals, AXI-PACK builds on an established protocol and extends irregular streams throughout interconnects, feeding directly into cores in an end-to-end fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this work, we present AXI-PACK, an extension to the widespread AXI4 on-chip protocol enabling highly-efficient end-to-end strided and indirect memory streams. AXI-PACK is fully backward-compatible and enables decoupled, bus-packed streams whose semantics are directly encoded into requests, ensuring high performance and flexibility even for short streams. To demonstrate AXI-PACK in an end-to-end system, we extend an open-source RISC-V vector processor to use it for strided and indexed accesses and design a banked memory controller serving irregular bursts. We evaluate the performance of the resulting vector processor system by evaluating benchmarks involving strided and indirect accesses. AXI-PACK increases bus utilizations up to 87% in strided and 39% in indirect benchmarks, resulting in speedups of up to 5.4? and 2.4?. Synthesizing our AXI-PACK controller, we find that it incurs only 6.2% of the area of Ara, but improves energy efficiency by up to 5.3? in strided and 2.1? in indirect workloads.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. AXI-PACK processor extension, multi-banked controller, and converter architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. AXI-PACK performance results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(c) Benchmark powers and energy efficiency improvements</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. AXI-PACK area, timing, and energy results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Across all bank counts, utilization improves mainly with the ratio r of element size to index size: since we fetch indices as whole bus lines, we must fetch one index line for every r data beats on average, limiting our ideal bus utilization to r /r+1. For 32-bit elements and index sizes of 32, 16, and 8 bit, this corresponds to ideal utilizations of 50, 67, and 80 %. Thus, with larger elements or smaller indices,</figDesc><table><row><cell cols="2">100</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>R bus utilization (%)</cell><cell>40 60 80</cell><cell></cell><cell>8-bank 11-bank</cell><cell cols="3">16-bank 17-bank</cell><cell>31-bank 32-bank</cell><cell>ideal</cell></row><row><cell></cell><cell cols="7">3 2 / 3 2 3 2 / 1 6 6 4 / 3 2 3 2 / 8 6 4 / 1 6 1 2 8 / 3 2 6 4 / 8 1 2 8 / 1 6 2 5 6 / 3 2 1 2 8 / 8 2 5 6 / 1 6 2 5 6 / 8 element and index size (bits)</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">(a) Indirect read utilization</cell></row><row><cell>R bus utilization (%)</cell><cell>70 80 90 100</cell><cell>32</cell><cell>64 element size (bits) 128 8-bank 256 11-bank 16-bank 17-bank 32-bank 31-bank</cell><cell>area (kGE)</cell><cell>0 20 40</cell><cell cols="2">bank count 8 11 16 17 31 32 crossbar modulo divider</cell></row><row><cell></cell><cell cols="3">(b) Strided read utilization</cell><cell></cell><cell></cell><cell cols="2">(c) Bank crossbar area</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">Figure 5. AXI-PACK parameter sensitivity results</cell></row><row><cell cols="4">no inherent advantage here.</cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p>AXI-PACK indirection bus utilizations can further exceed those shown in Section III-B.</p>Strided accesses: Figure</p></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Sparsity in deep learning: Pruning and growth for efficient inference and training in neural networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hoefler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Alistarh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ben-Nun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dryden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Peste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">124</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Mailthody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qureshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><surname>Hwu</surname></persName>
		</author>
		<title level="m">Proc. VLDB Endowment</title>
		<meeting>VLDB Endowment</meeting>
		<imprint>
			<publisher>Emogi</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Conjugate gradients on multiple gpus</title>
		<author>
			<persName><forename type="first">S</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Okuda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Numerical Methods in Fluids</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cusnmf: A sparse non-negative matrix factorization approach for large-scale collaborative filtering recommender systems on multi-gpu</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Int. Symp. Parallel and Distributed Process. with Applicat. and 2017 IEEE Int. Conf. Ubiquitous Computing and Commun</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1144" to="1151" />
		</imprint>
		<respStmt>
			<orgName>ISPA/IUCC</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Prodigy: Improving the memory latency of data-indirect irregular workloads using hardware-software co-design</title>
		<author>
			<persName><forename type="first">N</forename><surname>Talati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Behroozi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kaszyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vasiladiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Morton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ahmadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F P</forename><surname>O'boyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mahlke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Mudge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Dreslinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE Int. Symp. High-Performance Comput. Architecture (HPCA)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="654" to="667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Stream-based memory access specialization for general purpose processors</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM/IEEE 46th Annu. Int. Symp. Comput. Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="736" to="749" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A gpu implementation of inclusion-based points-to analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>M?ndez-Lojo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Burtscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PPoPP &apos;12</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Stream semantic registers: A lightweight risc-v isa extension achieving full compute utilization in single-issue cores</title>
		<author>
			<persName><forename type="first">F</forename><surname>Schuiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zaruba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hoefler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Benini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="212" to="227" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Indirection stream semantic register architecture for efficient sparse-dense linear algebra</title>
		<author>
			<persName><forename type="first">P</forename><surname>Scheffler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zaruba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schuiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hoefler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Benini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 Design, Automation &amp; Test in Europe Conf. &amp; Exhibition (DATE)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1787" to="1792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unlimited vector extension with data streaming support</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Domingos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Roma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tom?s</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 ACM/IEEE 48th Annu. Int. Symp. Comput. Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="209" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Impulse: building a smarter memory controller</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Stoller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brunvand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kuramkote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schaelicke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tateyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proc. Fifth Int. Symp. High-Performance Comput. Architecture</title>
		<imprint>
			<biblScope unit="page" from="70" to="79" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A novel hardware support for heterogeneous multi-core memory system</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Parallel Distributed Comput</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="31" to="49" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Memory controller for vector processor</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Palomar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">S</forename><surname>Unsal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cristal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ayguad?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Signal Process. Syst</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="1533" to="1549" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Planar: a programmable accelerator for near-memory data rearrangement</title>
		<author>
			<persName><forename type="first">A</forename><surname>Barredo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Armejach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Beard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moret?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Int. Conf. Supercomputing</title>
		<meeting>ACM Int. Conf. Supercomputing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">In-memory data rearrangement for irregular, data-intensive computing</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Gokhale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="18" to="25" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">AMBA AXI and ACE Protocol Specification</title>
		<author>
			<persName><surname>Arm</surname></persName>
		</author>
		<ptr target="https://developer.arm.com/documentation/ihi0022/hc" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An open-source platform for high-performance noncoherent on-chip communication</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kurth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>R?nninger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Benz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Cavalcante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schuiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zaruba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Benini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comp</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="1794" to="1809" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A &quot;new ara&quot; for vector computing: An open source highly efficient risc-v v 1.0 vector processor design</title>
		<author>
			<persName><forename type="first">M</forename><surname>Perotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cavalcante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wistoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Andri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cavigelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Benini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE 33rd International Conference on Application-specific Systems, Architectures and Processors</title>
		<imprint>
			<publisher>ASAP</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="43" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The cost of application-class processing: Energy and performance analysis of a linux-ready 1.7-ghz 64-bit risc-v core in 22nm fdsoi technology</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zaruba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Benini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Very Large Scale Integration (VLSI) Syst</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2629" to="2640" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The pagerank citation ranking : Bringing order to the web</title>
		<author>
			<persName><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The university of florida sparse matrix collection</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Math. Softw</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
