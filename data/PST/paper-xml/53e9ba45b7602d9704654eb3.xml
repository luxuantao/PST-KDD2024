<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visual navigation and obstacle avoidance using a steering potential function</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2006-01-03">3 January 2006</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Wesley</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
							<email>whuang@cs.rpi.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Rensselaer Polytechnic Institute</orgName>
								<address>
									<postCode>12180</postCode>
									<settlement>Troy</settlement>
									<region>NY</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Brett</forename><forename type="middle">R</forename><surname>Fajen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Cognitive Science</orgName>
								<orgName type="institution">Rensselaer Polytechnic Institute</orgName>
								<address>
									<postCode>12180</postCode>
									<settlement>Troy</settlement>
									<region>NY</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jonathan</forename><forename type="middle">R</forename><surname>Fink</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Rensselaer Polytechnic Institute</orgName>
								<address>
									<postCode>12180</postCode>
									<settlement>Troy</settlement>
									<region>NY</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">William</forename><forename type="middle">H</forename><surname>Warren</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Cognitive and Linguistic Sciences</orgName>
								<orgName type="institution">Brown University Providence</orgName>
								<address>
									<postCode>02912</postCode>
									<region>RI</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Visual navigation and obstacle avoidance using a steering potential function</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2006-01-03">3 January 2006</date>
						</imprint>
					</monogr>
					<idno type="MD5">E79F4B8DE0F036401BB795AC43046D5C</idno>
					<idno type="DOI">10.1016/j.robot.2005.11.004</idno>
					<note type="submission">Received 6 January 2005; received in revised form 20 November 2005; accepted 21 November 2005</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Local navigation</term>
					<term>Obstacle avoidance</term>
					<term>Vision-based navigation</term>
					<term>Potential fields</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Humans have a remarkable ability to navigate using only vision, but mobile robots have not been nearly as successful. We propose a new approach to vision-guided local navigation, based upon a model of human navigation. Our approach uses the relative headings to the goal and to obstacles, the distance to the goal, and the angular width of obstacles, to compute a potential field over the robot heading. This potential field controls the angular acceleration of the robot, steering it towards the goal and away from obstacles. Because the steering is controlled directly, this approach is well suited to local navigation for nonholonomic robots. The resulting paths are smooth and have continuous curvature. This approach is designed to be used with single-camera vision without depth information but can also be used with other kinds of sensors. We have implemented and tested our method on a differential-drive robot and present our experimental results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Local navigation is a fundamental problem for mobile robots operating in real-world environments: a robot must make progress towards a goal location while avoiding unexpected obstacles. Usually, robots make use of active sensors such as SONAR and scanning laser rangefinders. However, we know through our own personal experience that it is possible to navigate locally using only vision. Transferring this capability to robots has been difficult.</p><p>Though a rich sensing modality, vision has a number of shortcomings as a sole sensing modality for obstacle avoidance. Three-dimensional scene recovery using stereo vision requires two cameras. Camera calibration is important for getting accurate results, and the computational cost is high. It is possible to recover depth to obstacles using a single camera, but this requires either structure from motion techniques <ref type="bibr" target="#b25">[26]</ref> (which are also computationally expensive) or a ground plane assumption (e.g., <ref type="bibr" target="#b10">[11]</ref>).</p><p>We propose a method for obstacle avoidance that uses a single camera without recovering depth. One solution to this problem is to compute optical flow in order to estimate the "time to impact" which can then be used to steer around fastapproaching obstacles <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b18">19]</ref>. In our approach, however, we rely only upon the headings to obstacles and their angular widths: features that can be extracted with relative ease and good accuracy. Our approach to obstacle avoidance requires only this information, but if the distances to obstacles are available (even coarse depth information), through vision or some other sensing modality, it can be easily incorporated.</p><p>Our method is based on Fajen and Warren's model of human navigation <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b28">29]</ref>. This model takes the relative heading and distance to the goal and obstacles and computes an angular acceleration to steer the robot towards the goal and away from obstacles. There are many advantages to the general framework of this model. Because it controls angular acceleration, it is directly applicable to steering nonholonomic vehicles: the resulting paths are smooth and have continuous curvature. The paths also have a "natural look", as one would expect from a model based on human navigation. The method is completely reactive and is simple and fast to compute. However, Fajen and Warren's model is not directly suitable for vision-based robot navigation for several reasons: <ref type="bibr" target="#b0">(1)</ref> obstacles are treated as points with no extent, (2) knowledge of obstacle distance is used, and (3) collisions with obstacles are possible.</p><p>We have adapted and extended Fajen and Warren's model to accommodate obstacles of finite width, to use the angular width of an obstacle instead of its distance, and to use speed control to guarantee that the robot will not collide with an obstacle. The resulting model retains the advantages of being reactive, simple to compute, and directly applicable to controlling nonholonomic robots, while now being suitable for obstacle avoidance on a mobile robot.</p><p>In our study of Fajen and Warren's model, we found that it can be interpreted as following a potential field over the robot heading angles. The goal corresponds to an attractor that pulls the robot heading towards the goal, and obstacles correspond to repellors that push the robot heading away. However, this potential field is quite unlike the traditional potential fields in robotics. Since the heading to the obstacles and the goal changes as the robot moves, the potential landscape also changes; for traditional potential fields, the potential is static and is fixed in the world frame. In addition, local minima in our potential are not the problem that they are for traditional potential fields -any local minimum in our potential will steer the robot around the obstacles (robot and obstacle widths notwithstanding) and will eventually become a global minimum! We have found the potential field interpretation of Fajen and Warren's model to be more easily understandable and to provide greater insight into the operation of this model. We present our extensions to the model in this paradigm, and one of our extensions depends on the potential values.</p><p>After a review of related work in Section 2, we describe Fajen and Warren's model in detail in Section 3, both in the original acceleration formulation and in our potential field formulation. In Section 4, we describe our extensions to this model. We have implemented and tested our model on a differential drive robot; details of our experiments and results appear in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>There have been many different approaches to local navigation for mobile robots. Early obstacle avoidance work used SONAR sensors almost exclusively; today, scanning laser rangefinders are often used. Most of the earliest obstacle avoidance methods were based on the potential field approach, so we begin our review of related work there. While potential fields are still used for local navigation, there are a number of other commonly used techniques which we review next. Finally, we review some work from the dynamical systems approach to behavior, which was the inspiration for the Fajen and Warren model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Potential fields</head><p>The potential fields approach to local navigation was developed by Khatib <ref type="bibr" target="#b13">[14]</ref> in the 1980's to create real-time systems. With the limited computational resources in the early years of robotics, the prevalent approach of modeling (i.e., map building) and geometric motion planning simply required too much computation to operate in real time. Potential fields provide a simple and easily computed method to reach a goal location while avoiding unknown obstacles.</p><p>One shortcoming of this approach is that a robot can get stuck in a local minimum of the potential. A variety of approaches have been proposed for a robot to find its way out of these spots, including active search, backtracking, and random walks <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b17">18]</ref>. Methods have also been proposed that use a navigation function <ref type="bibr" target="#b19">[20]</ref> (a local-minimum-free potential) on a local map <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15]</ref>.</p><p>Another problem with potential fields is that they specify a direction that the robot should move, and this may not respect nonholonomic constraints, e.g., for a car-like or differential-drive robot. There have been several approaches to this problem: deforming the potential field to respect the nonholonomic constraints <ref type="bibr" target="#b22">[23]</ref>, using control techniques to track the path produced by the potential field <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b15">16]</ref>, and using a potential field that respects the nonholonomic constraints <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b4">5]</ref>. In addition, there are methods for tracking a preplanned path that make use of potential fields for obstacle avoidance, e.g., <ref type="bibr" target="#b16">[17]</ref>.</p><p>One variation of the potential field approach that uses the bearing, distance, and orientation of an obstacle was proposed by Khatib and Chatila <ref type="bibr" target="#b12">[13]</ref>. They compute a force from a traditional potential field but then modify this force to control the rotation of the robot, resulting in more direct paths when obstacles do not impede the path to the goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Obstacle avoidance methods</head><p>There have been many other approaches to local navigation that have departed from the potential field approach.</p><p>Borenstein and Koren's vector field histogram (VFH) method <ref type="bibr" target="#b1">[2]</ref> transforms a local map into a one-dimensional discretized "polar obstacle density" function. This density function is explicitly searched for a heading close to the goal heading where there is low (or zero) obstacle density. While this approach can better pick a heading direction due to the explicit search, it does not account for robot dynamics. This method has been extended to incorporate robot dynamics and local search, resulting in the VFH+ and VFH* methods <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28]</ref>.</p><p>Nonholonomic constraints were incorporated into the steer angle field approach of Feiten et al. <ref type="bibr" target="#b8">[9]</ref>. In this approach, the robot builds a local map, and projects the robot's path forward to determine what ranges of steering angles would cause a collision within a certain "hit distance". If no collision-free steering angle can move the robot towards a goal location, a higher-level planner is consulted.</p><p>Simmons' curvature-velocity method <ref type="bibr" target="#b23">[24]</ref> and the dynamic window approach of Fox et al. <ref type="bibr" target="#b9">[10]</ref> search a space of the robot's translational and rotational velocities. Obstacles near the robot are transformed into this space by eliminating all commanded velocities that would cause a collision within a certain time period. These methods both take into account the kinematics and the dynamics of the robot. Commanded velocities are chosen based on an objective function that considers both progress towards the goal and robot safety.</p><p>The TerraScout project at Carnegie Mellon University <ref type="bibr" target="#b20">[21]</ref> has incorporated Fajen and Warren's original model into their obstacle avoidance system. The robot used in this project travels on outdoor terrain at 3-7 m s -1 along a preplanned path and must avoid obstacles. It creates a discretized local map using scanning laser rangefinders, and places a point obstacle in each occupied cell; the goal is set to a point a certain distance ahead on the path. The steering of the robot is set according to the angular acceleration computed by Fajen and Warren's model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Dynamics of behavior</head><p>The dynamical systems approach to behavior studies the formulation of behaviors for autonomous agents. Schöner et al. <ref type="bibr" target="#b21">[22]</ref> describe a framework for designing behaviors for autonomous robots. As an example, they formulate heading control of a mobile robot using a first order system that places an attractor at the goal heading and repellors at obstacle headings. They make the distinction between the potential field approach, where the system's attractor is a (static) pose of the robot, and their "dynamical approach" in which behavior (e.g. control of the robot heading) is determined by the location of an attractor, and this behavior changes appropriately with time and the robot state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">A model of human navigation</head><p>Inspired by the work of Schöner et al. <ref type="bibr" target="#b21">[22]</ref>, Fajen and Warren <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b28">29]</ref> devised a model of human navigation based upon experiments with human subjects. These experiments were conducted in a virtual environment where human subjects wore a head-mounted display and were physically free to move about in a 12 m by 12 m space. Subjects were instructed to walk through the virtual environment towards a goal; in some cases, they had to avoid obstacles along the way. A tracking system recorded subjects' position and orientation as they moved.</p><p>In the first set of experiments, subjects initially walking along a linear path were presented with a goal at different angles and distances from their initial position and heading. The data revealed that angular acceleration toward the goal increased with goal angle and decreased with goal distance. In the second set of experiments, subjects walking straight towards a goal were presented with an obstacle located at different initial angles and distances. In this case, angular acceleration away from the obstacle decreased with both obstacle angle and distance.</p><p>In this section, we describe the details of Fajen and Warren's model, first in the original acceleration framework, and then in our potential field interpretation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Acceleration model</head><p>The inputs to Fajen and Warren's model, illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>, are the agent's heading (φ) and the bearing and distance to the goal (ψ g and d g ) and to the obstacles (ψ o i and d o i ). The angular acceleration is computed according to the following equation:</p><formula xml:id="formula_0">φ = -b φ -k g (φ -ψ g )(e -c 1 d g + c 2 ) + i k o i (φ -ψ o i )(e -c 3 |φ-ψ o i | )(e -c 4 d o i ).</formula><p>(</p><formula xml:id="formula_1">)<label>1</label></formula><p>This equation consists of three terms: a damping term, a goal term, and an obstacle term:</p><p>• The damping term opposes acceleration of the heading in proportion to turning rate φ according to the damping constant b.</p><p>• The goal term pulls the heading towards the goal. Its strength increases proportionally with goal angle (φψ g ), and decreases exponentially with goal distance. Note that the goal component never decreases to zero with goal distance, ensuring that the agent will turn toward distant goals. The "stiffness" parameter k g modulates the strength of this component, c 1 determines the rate of decay with goal distance, and c 2 adjusts the minimum angular acceleration toward distant goals. A graph of this component appears in Fig. <ref type="figure">2</ref>(a).</p><p>• The obstacle component pushes the heading away from obstacles. Its influence increases proportionally with obstacle angle for small angles but decreases exponentially with obstacle angle for larger angles. This means that as the agent turns toward an obstacle, the obstacle's repulsion increases, but only up to a certain point so that the agent can cut in front of the obstacle. In addition, the obstacle component decreases exponentially to zero as obstacle distance increases. Thus, the agent will not turn away from distant obstacles, even those located at small bearing angles.</p><p>The parameter k o determines the strength of the obstacle component, c 3 determines the rate of decay with obstacle angle, and c 4 determines the rate of decay with obstacle distance. A graph of this component appears in Fig. <ref type="figure">2(b)</ref>.</p><p>The model parameters were fit to the human data using a least-squares technique; the resulting parameters produced goal and obstacle angle profiles that matched the mean human paths with a Pearson correlation coefficient close to 1.0. Using these parameters, the model was simulated with more complex configurations of obstacles, including pairs of obstacles, culde-sacs, and arrays of randomly positioned obstacles. With few exceptions, the model successfully reached the goal while avoiding the obstacles. Additional experiments with human subjects in similar complex configurations revealed patterns of route selection behavior similar to those predicted by the model. The model was demonstrated to be robust through simulations with random noise in angular acceleration at each time step or with 10% error introduced in perceptual variables and parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Potential field model</head><p>We have found that Fajen and Warren's model can be expressed as a potential field where the goal and obstacles give rise to potential functions over the agent heading. The overall potential can be expressed as:</p><formula xml:id="formula_2">Φ(φ) = Φ g (φ) + i Φ o i (φ)<label>(2)</label></formula><p>where each obstacle i generates an independent potential Φ o i . The agent is then controlled according to:</p><formula xml:id="formula_3">φ = dΦ dφ -b φ (3)</formula><p>which is equivalent to Eq. ( <ref type="formula" target="#formula_1">1</ref>). This potential field is different than the traditional potentials used for agent navigation because the "potential landscape" keeps changing as the agent moves (which changes the relative headings and distances to the goal and obstacles). We describe this view of Fajen and Warren's model to provide additional insight into its operation and because one of our extensions depends on the potential values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Goal potential</head><p>The goal component of Eq. ( <ref type="formula" target="#formula_1">1</ref>) can be expressed as a potential function by taking the negative integral with respect to φ. The goal potential is:</p><formula xml:id="formula_4">Φ g [ψ g , d g ](φ) = 1 2 k g (φ -ψ g ) 2 (e -c 1 d g + c 2 ). (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>The potential is a parabolic bowl over φ that is centered at the heading to the goal ψ g . Note that this potential is a function of ψ g and d g which change as the agent moves. The distance to the goal d g scales this potential so that it is steeper when the goal is near. See Fig. <ref type="figure">3</ref>(a) for a graph of this potential. When the agent heading is aligned with the goal, there is no angular acceleration from the goal component of Eq. ( <ref type="formula" target="#formula_1">1</ref>); this corresponds to the agent heading being at the minimum of the potential. When the agent is not aligned towards the goal, its heading will accelerate downhill on this potential, i.e., towards the goal. However, as the agent moves closer to the goal, the heading to the goal will change. Damping is therefore required to prevent oscillations around the equilibrium point.</p><p>Fig. <ref type="figure" target="#fig_2">4</ref> illustrates the evolution of the goal potential over several points on a path to a goal. Also note the effect of distance to the goal -as the agent approaches the goal, the potential grows steeper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Obstacle potential</head><p>The obstacle component of Eq. ( <ref type="formula" target="#formula_1">1</ref>) can also be expressed as a potential function over the heading by taking the negative integral with respect to φ:</p><formula xml:id="formula_6">Φ o i [ψ o i , d o i ](φ) = k o c 3 |φ -ψ o i | + 1 c 2 3 (e -c 3 |φ-ψ o i | )(e -c 4 d o i ).<label>(5)</label></formula><p>The obstacle potential is a "bump" centered at the obstacle heading ψ o i , dropping sharply to both sides, and then decaying to zero. The height of the obstacle potential also decreases exponentially with increased distance to the obstacle so that distant obstacles have a lesser effect on the agent's steering. See Fig. <ref type="figure">3</ref>(b) for a graph of this potential. Again note that this potential changes as the agent moves: this potential pushes the agent's heading away from the obstacle which causes the relative heading to the obstacle to increase at the same time.</p><p>When the agent's heading is close to an obstacle, this potential will cause the agent heading to accelerate away from the obstacle. As the agent passes by an obstacle, |φ -ψ o i | grows, dramatically reducing the influence of the obstacle on the agent heading.</p><p>One difference from the traditional potential field method is that the obstacle potential has a finite maximum. This is actually necessary so that the agent heading can cross from one side of an obstacle to the other. For example, if an agent is pointed straight into a cluster of obstacles, the agent heading will have to pass in front of at least one obstacle as it steers around the cluster. Fig. <ref type="figure" target="#fig_3">5</ref> illustrates the evolution of the total potential (obstacle and goal) over several points on a path to the goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Local minima and maxima</head><p>There will be local minima in the total potential function; however, this is not the problem that it is for traditional potential field methods. In traditional potential field approaches, a local minimum is a location where the agent will stop making progress towards the goal. In Fajen and Warren's model, the potential field controls only the steering direction; the translational velocity is held constant. Local minima in the potential represent possible headings to drive around an obstacle and reach the goal. In general, the agent will follow steering directions determined by local minima, and that a local minimum will become a global minimum once the agent has avoided all the obstacles and has a clear route to the goal.</p><p>When there are two or more obstacles arranged symmetrically to the left and right of the heading, the obstacle potentials sum together to create a local minimum at a heading between the two innermost obstacles. The local minimum represents a path that the agent may follow even if the obstacles are too close together. It is possible for errors in actuation to dislodge the agent from the shallow local minimum produced in this case -once the agent is sufficiently far off the line of symmetry, one obstacle peak will become larger while the other becomes smaller, and this can cause the local minimum to disappear. Both our extensions presented in Section 4 combine to avoid these situations.</p><p>One problem with the original model is a consequence of having a finite obstacle potential: it can produce an unstable local maximum. This is most unfortunate because should the agent not be dislodged from this local maximum, it will run right into the obstacle. While in any real system, we could probably count on noise to dislodge the heading from this point, limited sensor resolution could conspire to prevent this. We have introduced speed control (in Section 4.2) to deal with this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Agent and obstacle width</head><p>Another problem with Fajen and Warren's model is that the agent and obstacles are treated as points, which means that paths would not take into account robot and obstacle widths. One could tune the parameters to adjust for changes in agent or obstacle size, but collisions are still possible, especially when the sizes of obstacles in a scene vary from small to large. In Section 4, we show how this problem can be solved using angular width together with knowledge of robot size and minimum obstacle size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">A model for robot navigation</head><p>We made two major modifications to Fajen and Warren's model. First, we modified the obstacle term to account for non-point obstacles; the revised term generates a potential appropriate to the obstacle size and relative to the robot size. Second, we introduced velocity control to guarantee that the robot won't collide with an obstacle.</p><p>We assume that the goal heading and distance are known, that these quantities can either be sensed directly or may be given to the robot, e.g., a point further ahead on a preplanned path provided by a high-level path planning module. For obstacles, however, we have only what can be sensed by a single camera: the heading to the obstacle and its angular width. We do assume that obstacles are circular or are conservatively approximated by circles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Extension to obstacle widths</head><p>Several things are required to adapt Fajen and Warren's model to a robot which must avoid obstacles with nonzero widths. First, wider obstacles should generate a wider obstacle potential so the robot takes a wider path around the obstacle. To guarantee that the robot does not collide with an obstacle, this potential must approach infinity as the robot gets closer and closer to the obstacle. Finally, we wish to remove the dependence on the distance to obstacles so that our method can be implemented using single-camera vision.</p><p>We have achieved all these objectives by replacing the term e -c 4 d o in the obstacle potential by (tan(θ i + c 5 ) -tan c 5 ) where θ i is the angular width of the ith obstacle and c 5 is a new parameter. The obstacle potential is now:</p><formula xml:id="formula_7">Φ o i [ψ o i , d o ](φ) = k o c 3 |φ -ψ o i | + 1 c 2 3 × (e -c 3 |φ-ψ o i | )(tan(θ i + c 5 ) -tan c 5 ).<label>(6)</label></formula><p>The new term makes use of the tangent function to drive the potential toward infinity as θ i approaches some maximum value. As the robot gets closer and closer to an obstacle, its angular width will increase. For any given sized obstacle, there will be a maximum angular width that occurs when the robot has made contact with the obstacle. If we knew the obstacle radius, we could set c 5 exactly:</p><formula xml:id="formula_8">c 5 = π 2 -2 tan -1 r o r o + r r<label>(7)</label></formula><p>where r o is the obstacle radius and r r is the robot radius. Since we cannot depend on knowing the size of each obstacle, we conservatively set c 5 using the radius of the smallest obstacle.</p><p>This has the effect of making the robot conservative about avoiding distant large obstacles; however, given our aim to avoid using the obstacle distance, there is no other choice. We discuss the effect of different obstacle widths in Section 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Velocity control</head><p>If the robot is following a local minimum between two symmetrically placed and closely spaced obstacles, the robot may still try to pass between them, even using the new obstacle term above: as the robot gets closer, the potential for each obstacle gets bigger and bigger, but because of the symmetry, there is still a local minimum between them. <ref type="foot" target="#foot_0">1</ref>To keep the robot from attempting to squeeze through an opening that is too narrow, we introduce speed control. Whereas speed was held constant in the original model, we now set it to decrease exponentially as a function of the height of the obstacle potential:</p><formula xml:id="formula_9">v = max{v max e -k v Φ o -, 0}<label>(8)</label></formula><p>where is a small positive constant so that the velocity becomes zero for sufficiently large values of Φ o .</p><p>In the absence of obstacles, the obstacle potential is zero, and so speed is equal to v max . When obstacles are nearby and/or closely aligned with heading, the obstacle potential is greater, which causes speed to decrease.</p><p>The addition of speed control also helps with collision avoidance because the robot will make sharper turns. The navigation model controls angular acceleration and velocity independent of how close the obstacles are. For a given rotational velocity φ, the robot will travel with a curvature radius of v/ φ, where v is the translational velocity. If v decreases, then the turning radius will also decrease resulting in a more aggressive obstacle avoidance maneuver.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Example</head><p>Fig. <ref type="figure" target="#fig_4">6</ref> shows a sample path between two obstacles of different sizes to a goal 5 m ahead. The bottom graph of this figure shows the velocity profile, with white squares indicating speed at the four locations along the path. Fig. <ref type="figure">7</ref> shows the corresponding potential for these four points: the top row shows the total potential, and the bottom row shows the goal and obstacle components separately.</p><p>When the robot is at the starting location (location A), its heading is aligned with the goal and close to the minimum of the total potential function. Although the obstacle potential is weak because both obstacles are still far away, the peak of the obstacle potential is closely aligned with the robot's heading, which causes the robot to move at less than its maximum speed of 0.7 m s -1 . By the time the robot reaches location B, the larger obstacle has created a local minimum in the total potential function, which shifts the global minimum to the left of the goal and causes the robot to turn away from this obstacle. The height of the obstacle potential at the robot's heading is also greater than it was at location A, resulting in a further drop in speed.</p><p>At location C, the robot is heading slightly to the left of the obstacle, but the goal and the smaller obstacle push the global minimum to the right, which eventually causes the robot to turn back in that direction. Note that the influence of the smaller obstacle is considerably less than the influence of the larger obstacle because its angular width is smaller. Also, the robot's speed is greater than it was at location B because the obstacle potential at the robot's heading is now lower.</p><p>By the time the robot reaches location D, it has settled into the minimum of the total potential, which is dominated by the goal potential because the obstacles are now behind the robot. The robot's speed at this location is close to maximum speed because the obstacle potential is close to zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Simulations with different obstacle widths</head><p>In Section 4.1, we pointed out that the robot will behave conservatively when avoiding a distant large obstacle because it turns as if to avoid a nearby small obstacle with the same angular width. This is a consequence of our aim to develop an approach that does not require distance information. When the sizes of obstacles in the scene are similar, then this conservative bias will be inconsequential. As the ratio of the largest to the smallest obstacle increases, the bias may result in longer, more circuitous routes. This is illustrated in Fig. <ref type="figure" target="#fig_5">8(a)</ref>, which shows a series of simulations with varying obstacle size ratios. For larger ratios, the robot leaves more room than necessary when avoiding the larger obstacle. However, the robot still avoids the obstacles and reaches the goal. Considering the fact that the robot is able to navigate without distance information, avoiding collisions at the expense of taking a longer route is a reasonable tradeoff.</p><p>Although the algorithm was designed to work without distance information, such information can be seamlessly incorporated into the algorithm when it is available. Rather than assume that each obstacle's width is equal to the width of the smallest obstacle, the actual width of each obstacle can Fig. <ref type="figure">7</ref>. Potential functions for the four locations on the path in Fig. <ref type="figure" target="#fig_4">6</ref>. The top row shows the total potential; obstacle headings are indicated by black circles with the size corresponding to the obstacle size, the goal heading is indicated by the X, and robot heading is indicated by the square. The bottom row shows the goal potential (dashed line) and total obstacle potential (dotted line) separately.  be estimated using distance information together with angular width. That is, distance information can be used to set a different c 5 parameter for each obstacle. This eliminates the conservative bias, and allows the robot to navigate through a field of obstacles whose sizes vary across a wide range. Fig. <ref type="figure" target="#fig_5">8</ref>(b) shows the routes followed by the robot using distance information under the same conditions used in Fig. <ref type="figure" target="#fig_5">8(a)</ref>. Note that the path is affected by the change in obstacle size only to the extent that it is necessary to avoid a collision.</p><p>Fig. <ref type="figure" target="#fig_7">9</ref>(a) demonstrates that the robot with distance information can effectively navigate through a field of five differently-sized obstacles. When the gap between the last two obstacles is large enough for the robot to fit through, the robot takes the shorter route to the goal (Fig. <ref type="figure" target="#fig_7">9(b)</ref>). This illustrates that when distance information is available, it can be used to improve obstacle avoidance and route selection with just a minor modification to the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental implementation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Implementation details</head><p>We implemented our model on a MagellanPro robot; this is a differential drive robot made by iRobot, with an on-board PC and wireless Ethernet. Although this robot has SONAR and IR sensor rings, the only sensor used in our experiments was an omnidirectional camera mounted atop the robot.</p><p>The camera is pointed upwards at a hyperbolic mirror and produces a 640 by 480 pixel image that is then dewarped to a 936 by 240 pixel image with a maximum 0.348 degree/pixel angular resolution. In order to reduce processing time, only half of this image is actually dewarped to provide a 180 degree view; this should not affect navigation since obstacles with large relative headings have a very small effect on the steering.</p><p>The goal and obstacles used in our experiments were cylindrical columns ranging from 0.1 to 0.23 m in diameter. The goal was taller than the obstacles (0.6 m high as compared to 0.3 m for the obstacles) in order to avoid goal occlusion. The goal and obstacles were different colors, so color segmentation followed by connected region extraction was used to recover goal and obstacle headings and obstacle angular widths. The distance to the goal was estimated based on its width in the image, taking advantage of its known size of 0.1 m.</p><p>The image capture and processing ran at 10 Hz which provided an adequate sample rate to produce smooth paths that avoided obstacles and reached the goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Tuning model parameters</head><p>We have developed a procedure for tuning the parameters of our model. In general, the parameters from Fajen and Warren's experiments cannot be used because the robot uses the model at discrete intervals (at 10 Hz) instead of continuously. Table <ref type="table" target="#tab_0">1</ref> contains a summary of the parameters, their values in our experiments, and a explanation of their effect on the path.</p><p>First, the parameters for goal directed behavior must be tuned. This can be done by starting the robot with the goal off to one side and observing the path that the robot takes. The goal potential will accelerate the heading towards the goal; the aim of this phase of the tuning procedure is to achieve a desired response without any oscillation of the robot heading about the goal direction. The c 1 and c 2 parameters should be set to 0.4; this is their value from Fajen and Warren's experiments, and we have found these values to work well on our robot. Initially k g and b should be set to low values (e.g., 1.0). The damping parameter b should be then increased so that oscillations in the path are eliminated, even for large initial relative headings to the goal. Once this basic response is achieved, k g can be increased to make the robot turn towards the goal more quickly. The tradeoff for higher values of k g is that higher values of b are required to prevent oscillations, and this will make the robot less responsive to obstacles. Next, parameters for the obstacle term are set in experiments with a single obstacle. The robot should start pointing towards the goal, and the obstacle should be about halfway between the robot and goal, slightly off to one side. First, note that the c 5 parameter should be calculated according to Eq. ( <ref type="formula" target="#formula_8">7</ref>) (for the minimum obstacle size). The obstacle gain k o should be set initially to 2k g , the c 3 parameter, to 4.0. The k o and c 3 parameters should then be adjusted so that the robot smoothly avoids a range of obstacle sizes. Increasing k o will cause the robot to begin turning away from the obstacle earlier. Increasing c 3 causes the robot to take paths closer to the obstacle because the obstacle potential will be narrower. Since the tangent term of the obstacle function is designed to rapidly approach infinity when the perceived angular width of an obstacle approaches π 2 -c 5 , it is important to tune c 3 such that the robot takes a path far enough around the largest obstacle.</p><p>If using the distance component of the obstacle term, c 4 can initially be set to zero (effectively eliminating this component) and then increased to better control the distance at which the robot starts to avoid the obstacle.</p><p>Tests with multiple obstacles should be done to further tune k o and c 3 (and c 4 if using the distance component). By decreasing k o and increasing c 3 , the paths taken are made more aggressive and goal dominated. They will come closer to obstacles and usually try to fit through gaps between obstacles. The opposite adjustment (increasing k o and decreasing c 3 ) will result in more conservative paths that tend to go around all the obstacles to get to the goal. As c 4 is increased, the robot will ignore more distant obstacles and can then be made to respond more aggressively to nearby obstacles.</p><p>Finally, the speed parameter k v should be chosen so that the robot stops before colliding with an obstacle. This should be tested with a goal directly in front of the robot and two obstacles of minimum size placed on either side of the goal heading, and spaced too close together for the robot to pass. This configuration produces the smallest potential that should stop the robot. The k v parameter should be set high enough that the robot comes to a stop before a collision occurs.</p><p>In general, there are many sets of parameters for which the model will correctly avoid obstacles and reach the goal. However, by changing different parameters, the paths can be drastically altered to be more or less conservative or take "inside" or "outside" paths. See Table <ref type="table" target="#tab_0">1</ref> for a summary description of each parameter's effect on the path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Experiments</head><p>We conducted more than fifty experiments to test our model. We ran all of these experiments with a maximum velocity of 0.7 m s -1 . There were a number of trials with varying complexity to show that the model works for different sizes and numbers of obstacles. Fig. <ref type="figure" target="#fig_8">10</ref> shows some trials designed to test basic obstacle avoidance behavior. Note that the paths are all smooth and take reasonably efficient paths through the field of obstacles.</p><p>The experiments shown in Fig. <ref type="figure" target="#fig_9">11</ref> illustrate the effect of obstacle width on the robot's path. A wider obstacle creates a larger and wider potential, steering the robot further away from that obstacle. Fig. <ref type="figure" target="#fig_10">12</ref> shows experiments to test the behavior of the robot avoiding a cluster of obstacles. In Fig. <ref type="figure" target="#fig_10">12</ref>(a), the robot chooses  a path through a gap between two obstacles. When the obstacles are spaced closely together, as in Fig. <ref type="figure" target="#fig_10">12(b</ref>), the resulting obstacle potential causes the robot to steer completely around the cluster. There are, however, situations such as in Fig. <ref type="figure" target="#fig_10">12(c</ref>), in which the robot is following a local minimum corresponding to a gap that is too narrow for the robot to pass. As the robot approaches this gap, the level of the obstacle potential rises, causing the robot to slow down and stop before a collision occurs. In some cases the robot can rotate until it reaches another local minima in the potential that can lead it out of this situation.</p><p>These experiments demonstrate the basic capabilities of our method for obstacle avoidance. Note that this is accomplished without any depth information for the obstacles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Comparison with VFH+</head><p>We performed a series of tests in simulation to compare the behavior of our model with VFH+ <ref type="bibr" target="#b26">[27]</ref>, a commonly used obstacle avoidance method. VFH+ (an enhanced version of the Vector Field Histogram method) takes a local occupancy grid map and creates a polar histogram based on a thresholded "obstacle density". It then eliminates steering directions that violate kinodynamic constraints of the robot and then chooses a steering direction in an obstacle-free valley of the histogram.</p><p>In order to make a fair comparison between our model and VFH+, we incorporated distance information as described in Section 4.4. We implemented our method in the Player/Stage framework using the model for an ActivMedia Pioneer robot (a differential drive robot) with a SICK laser scanner. Depth discontinuities were used to segment the laser scan, and the distance, bearing, and angular width were calculated for each segment. We used the built-in implementation of VFH+ in Player/Stage.</p><p>We ran a number of simulations for fields of circular obstacles of varying size; a few of our results are shown in Fig. <ref type="figure" target="#fig_11">13</ref>. In general, we found that our method produces much smoother paths than the VFH+ method. This is not surprising given that the VFH+ method starts with a local map and therefore does not consider distant obstacles. In addition, the "obstacle density" is a function of the distance to an obstacle, so an obstacle would not surpass the threshold until it is relatively close. Thus when VFH+ comes upon an obstacle, it tends to have to take sharper turns to avoid it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In this paper, we described and analyzed a model of human navigation, and adapted it for vision-based robot navigation. Both the original and adapted versions of the model can be described in terms of a potential function defined over the robot's heading. The goal potential is a parabolic bowl centered on the goal heading, and the potential for each obstacle is a peak centered on the obstacle heading. Because the potential is formulated in terms of relative headings to the goal and obstacles, the potential function changes as the robot moves.</p><p>Local minima in the total potential function represent headings that will steer the robot around obstacles and toward the goal. Once the robot has avoided all of the obstacles and has a clear route to the goal, the local minimum will become a global minimum centered on the heading of the goal. In this sense, our potential function provides a control law for the robot heading to track a path to the goal.</p><p>The original model of human navigation is completely reactive and simple to compute, directly applicable to steering nonholonomic vehicles, and produces smooth, natural looking paths. However, this model is not suitable for vision-based robot navigation because obstacles are treated as points, knowledge of obstacle distance is required, and collisions with obstacles are possible. Our modification of the original model uses the obstacles' angular width rather than distance, and controls speed based on the obstacle potential to help with collision avoidance. Together, these two modifications address the shortcomings of the original model, while still retaining its advantages. We implemented our model on a differentialdrive mobile robot and conducted experiments with multiple obstacles of varying sizes.</p><p>Because the angular width of obstacles, not their distance, is used, our method is somewhat conservative -a large distant obstacle can have the same angular width as a closer small obstacle. Despite this limitation, our method has been demonstrated to be effective for real-time navigation and obstacle avoidance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Subject orientation φ and the angles to the goal ψ g and an obstacle ψ o are measured from the world x axis. Distance to the goal d g and obstacle d o are also shown.</figDesc><graphic coords="3,336.73,66.76,181.00,91.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .Fig. 3 .</head><label>23</label><figDesc>Fig. 2. Components of acceleration: (a) the goal acceleration in terms of the relative heading to the goal (φψ g ) and distance to the goal d g , (b) the obstacle acceleration in terms of the relative heading to the obstacle (φψ g ) and the distance to the obstacle d o i .</figDesc><graphic coords="4,89.04,279.40,427.05,169.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Evolution of the goal potential along a path. The dot on the potential function indicates the agent's current heading.</figDesc><graphic coords="5,67.73,66.76,181.13,128.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Evolution of the total potential from a goal and one obstacle along a path. The dot on the potential function indicates the agent's current heading.</figDesc><graphic coords="5,337.23,66.76,180.25,138.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Simulated example path for our model. The top figure shows the robot path with four locations indicated. The bottom figure shows the velocity profile for this path with squares placed for each of the locations along the path.</figDesc><graphic coords="7,42.23,66.76,232.27,188.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Simulated paths for four obstacle size ratios (1:1, 2:1, 4:1, and 6:1). Figure (a) uses our original model, while Figure (b) incorporates distance information.</figDesc><graphic coords="8,52.05,66.76,232.02,240.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Fig. 8. Simulated paths for four obstacle size ratios (1:1, 2:1, 4:1, and 6:1). Figure (a) uses our original model, while Figure (b) incorporates distance information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Simulated navigation of an obstacle field using distance information. In (b), a gap between the last two obstacles has closed, so the robot must go around them.</figDesc><graphic coords="8,321.04,66.76,232.02,240.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10 .</head><label>10</label><figDesc>Fig.10. Experimental results: simple trials to illustrate the paths taken by our model. Note that in these and other experimental data shown, the robot was programmed to slow down and stop short of the goal (the white circle). The black circles are sized proportionately to the corresponding obstacle's size.</figDesc><graphic coords="10,60.04,283.34,216.02,177.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Experimental results showing the effect of obstacle width.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Experimental results for avoiding a cluster of obstacles.</figDesc><graphic coords="11,128.73,66.76,328.23,177.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Simulations comparing our model, in figures (a) and (c), to the VFH+ method, in figures (b) and (d).</figDesc><graphic coords="11,79.23,382.57,158.05,333.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Model parameters and their effect on paths</figDesc><table><row><cell>Parameter</cell><cell>Value</cell><cell>Effect on path</cell></row><row><cell>b</cell><cell>5.5</cell><cell>Controls oscillations when following local minima to goal</cell></row><row><cell>k g</cell><cell>2.0</cell><cell>Sets rate of goal attraction. Increasing will result in paths that more</cell></row><row><cell></cell><cell></cell><cell>aggressively steer towards the goal.</cell></row><row><cell>c 1</cell><cell>0.4</cell><cell>Used to balance the attraction of a distant goal with near obstacles</cell></row><row><cell>c 2</cell><cell>0.4</cell><cell>Ensures that a very distant goal still has effect.</cell></row><row><cell>k o</cell><cell>9.0</cell><cell>Controls obstacle repulsion. Increasing will result in paths that avoid</cell></row><row><cell></cell><cell></cell><cell>obstacles more drastically. Decreasing will allow the robot to approach closer</cell></row><row><cell></cell><cell></cell><cell>to obstacles before avoiding.</cell></row><row><cell>c 3</cell><cell>4.0</cell><cell>Controls "gap shooting" behavior. Increasing will result in paths that try to go</cell></row><row><cell></cell><cell></cell><cell>between obstacles. Decreasing will result in paths that go around groups of</cell></row><row><cell></cell><cell></cell><cell>obstacles. Also controls the clearance a path takes around an obstacle.</cell></row><row><cell>c 4</cell><cell>0.0</cell><cell>Only used when estimating distance to obstacles. Increasing this parameter</cell></row><row><cell></cell><cell></cell><cell>will decrease the effect of distant obstacles so that paths can be more</cell></row><row><cell></cell><cell></cell><cell>aggressive for close obstacles.</cell></row><row><cell>c 5</cell><cell>1.16</cell><cell>Increases obstacle potential to infinity as the robot approaches an obstacle to</cell></row><row><cell></cell><cell></cell><cell>avoid collisions. This parameter is calculated based on the angular width of</cell></row><row><cell></cell><cell></cell><cell>the minimum-size obstacle.</cell></row><row><cell>k v</cell><cell>0.5</cell><cell>Rate at which translational velocity is decreased. Should be adjusted to stop</cell></row><row><cell></cell><cell></cell><cell>the robot before a collision.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We note that this situation can occur when the obstacles are not exactly symmetric and when the obstacles appear symmetric to the robot. For sufficient difference in obstacle depth, however, this symmetry will be broken because the angular widths will change at different rates as the robot moves forward.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Wes Huang and Jon Fink were supported in part by the NSF through grant IIS-9983642. Bill Warren was supported by the NIH through grant EY10923.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Is visual reconstruction necessary? Obstacle avoidance without passive ranging</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Aloimonos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Robotic Systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="843" to="858" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The vector field histogram -fast obstacle avoidance for mobile robots</title>
		<author>
			<persName><forename type="first">J</forename><surname>Borenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics and Automation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="278" to="288" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">High-speed navigation using the global dynamic window approach</title>
		<author>
			<persName><forename type="first">O</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Khatib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="341" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Real-time singleworkstation obstacle avoidance using only wide-field flow divergence</title>
		<author>
			<persName><forename type="first">T</forename><surname>Camus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Coombs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Pattern Recognition</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="323" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Nonholonomic path planning using harmonic functions</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Connolly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Grupen</surname></persName>
		</author>
		<idno>UM-CS-1994-050</idno>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts at Amherst</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Dudek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jenkin</surname></persName>
		</author>
		<title level="m">Computational Principles of Mobile Robotics</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Behavioral dynamics of steering, obstacle avoidance, and route selection</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Fajen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Warren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="343" to="362" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A dynamical model of steering, obstacle avoidance, and route selection</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Fajen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Warren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Termizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Kaebling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="13" to="34" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Robust obstacle avoidance in unknown and cramped environments</title>
		<author>
			<persName><forename type="first">W</forename><surname>Feiten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lawitzky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="2412" to="2417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The dynamic window approach to collision avoidance</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Burgard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics &amp; Automation Magazine</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="33" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Indoor robot navigation with single camera vision</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Gini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition in Information Systems</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="67" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Tracking the gradient of artificial potential fields: sliding mode control for mobile robots</title>
		<author>
			<persName><forename type="first">J</forename><surname>Guldner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">I</forename><surname>Utkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Control</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="417" to="432" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An extended potential field approach for mobile robot sensor-based motions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Khatib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chatila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Autonomous Systems</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="490" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Real-time obstacle avoidance for manipulators and mobile robots</title>
		<author>
			<persName><forename type="first">O</forename><surname>Khatib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="90" to="98" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A gradient method for realtime robot control</title>
		<author>
			<persName><forename type="first">K</forename><surname>Konolige</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="639" to="646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Potential fields for nonholonomic vehicles</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Kyriakopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kakambouras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Krikelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Intelligent Control</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="461" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Reactive trajectory deformation for nonholonomic systems: Application to mobile robots</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lamiraux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bonnafous</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="3099" to="3104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Robot Motion Planning</title>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Latombe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Kluwer Academic Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A theory of visual control of braking based on information about time-to-collision</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="437" to="459" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Exact robot navigation using artificial potential functions</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rimon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koditschek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics and Automation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="501" to="518" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Results in combined route traversal and collision avoidance</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hamner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hwangbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Field and Service Robotics</title>
		<imprint>
			<date type="published" when="2005-07">July 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dynamics of behavior: theory and applications for autonomous robot architectures</title>
		<author>
			<persName><forename type="first">G</forename><surname>Schöner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Engels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="213" to="245" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Nonholonomic deformation of a potential field for motion planning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sekhavat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chyba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="817" to="822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The curvature-velocity method for local obstacle avoidance</title>
		<author>
			<persName><forename type="first">R</forename><surname>Simmons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2275" to="2282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Nonholonomic stabilization with collision avoidance for mobile robots</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Tanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Loizou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Kyriakopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1220" to="1225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Shape and motion without depth</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference in Computer Vision</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="91" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">VFH+: Reliable obstacle avoidance for fast mobile robots</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ulrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Borenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="1572" to="1577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">VFH*: Local obstacle avoidance with lookahead verification</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ulrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Borenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="2505" to="2511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">From optic flow to laws of control</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Warren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Fajen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Optic Flow and Beyond</title>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Vaina</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Beardsley</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Rushton</surname></persName>
		</editor>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="307" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Huang is an Assistant Professor in the Computer Science Department at Rensselaer Polytechnic Institute</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wesley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">He received an S.B. in Electrical Engineering from the Massachusetts Institute of Technology in 1991, and a Ph.D. from the Robotics Institute at Carnegie Mellon University in 1997. Prior to joining Rensselaer, he was a postdoctoral fellow in the Institute for Complex Engineered Systems at Carnegie Mellon. His research spans robotic manipulation, mobile manipulation, and mobile robotics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Before joining Rensselaer, he was a Postdoctoral Research Associate in the Department of Cognitive and Linguistic Sciences at Brown University. His research focuses on the visual guidance of action and optic flow</title>
	</analytic>
	<monogr>
		<title level="m">He is currently pursuing a Ph.D. in Electrical &amp; Systems Engineering as a member of the GRASP Lab at the University of Pennsylvania. His research interests include mobile robotics, mobile sensor networks, and computational approaches to design and planning with uncertainty in dynamic simulation</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>Brett Fajen is an Assistant Professor in the Cognitive Science Department at Rensselaer Polytechnic Institute</orgName>
		</respStmt>
	</monogr>
	<note>Mathematics from Bucknell University in 1993, and a Ph</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">did post-doctoral work at the University of Edinburgh (1983), and has been a professor at Brown ever since. He is the recipient of a National Research Service Award from NIH</title>
		<author>
			<persName><forename type="first">H</forename><surname>William</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Experimental Psychology from the University of Connecticut</title>
		<imprint>
			<date type="published" when="1982">1982. 1983. 1989. 1997-2002</date>
		</imprint>
		<respStmt>
			<orgName>Warren is Professor and Chair of the Department of Cognitive and Linguistic Sciences at Brown University</orgName>
		</respStmt>
	</monogr>
	<note>Fulbright Research Fellowship. and Brown&apos;s Elizabeth Leduc Teaching Award for Excellence in the Life Sciences</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
