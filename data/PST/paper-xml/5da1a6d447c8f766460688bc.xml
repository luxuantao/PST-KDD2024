<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SWQUE: A Mode Switching Issue Queue with Priority-Correcting Circular Queue</title>
				<funder>
					<orgName type="full">Synopsys Inc.</orgName>
				</funder>
				<funder>
					<orgName type="full">University of Tokyo</orgName>
				</funder>
				<funder>
					<orgName type="full">VLSI Design and Education Center</orgName>
					<orgName type="abbreviated">VDEC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Hideki</forename><surname>Ando</surname></persName>
							<email>ando@nuee.nagoya-u.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Nagoya University Nagoya</orgName>
								<address>
									<settlement>Chikusa</settlement>
									<region>Aichi</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<address>
									<addrLine>MICRO-52, October 12-16</addrLine>
									<postCode>2019</postCode>
									<settlement>Columbus</settlement>
									<region>OH</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SWQUE: A Mode Switching Issue Queue with Priority-Correcting Circular Queue</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3352460.3358293</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>issue queue, instruction scheduling</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The improvement of single-thread performance is much needed. Among the many structures that comprise a processor, the issue queue (IQ) is one of the most important structures that influences high single-thread performance. Correctly assigning the issue priority and providing high capacity efficiency are key features, but no conventional IQ organizations do not sufficiently have these.</p><p>In this paper, we propose an IQ called the switching issue queue (SWQUE), which dynamically configures the IQ as a modified circular queue (CIRC-PC) or random queue with an age matrix (AGE) by responding to the degree of capacity demand. CIRC-PC corrects the issue priority when wrap-around occurs by exploiting the finding that instructions that are wrapped around are latency-tolerant. CIRC-PC is used for phases in which capacity efficiency is less important and the correct priority is more important; and AGE is used for phases in which capacity efficiency is more important. Our evaluation results using SPEC2017 benchmark programs show that SWQUE achieved higher performance by averages of 9.7% and 2.9% (up to 24.4% or 10.6%) for integer and floating-point programs, respectively, compared with AGE, which is widely used in current processors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>? Computer systems organization ? Superscalar architectures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>including the cooling problem. The clock frequency of a processor has hardly increased since then. Simultaneously, the interests of many computer architects have moved from core microarchitecture toward multicore and uncore architectures. Since then, few studies have been conducted on core microarchitecture. This academic trend has also made single-thread performance sluggish. However, improving single-thread performance is still strongly required for many applications.</p><p>Correct priority and capacity efficiency in the issue queue: For high single-thread performance, the issue queue (IQ) plays an important role. The IQ schedules instructions to be executed by selecting and issuing instructions from the ready-to-execute instructions in each cycle. For higher performance, two features are required: 1) correct priority and 2) large capacity.</p><p>It is essential that the IQ assigns the correct priority when scheduling instructions. We say that the priority of the instructions is correct if the execution time is minimized when these instructions are scheduled based on their priority. Theoretically, the correct priority is assigned based on the height of the node of the instruction in the dataflow graph. Intuitively, the higher the node of an instruction, the longer the total execution time until the leaf instruction is executed, and thus, this instruction should be executed earlier.</p><p>Consider two instructions: instruction A, which is off the critical path of the dataflow graph, and instruction B, which is the highest node on the critical path. If the priority assigned to A is higher than that assigned to B, then this can hinder the issuing of instruction B.</p><p>If the issuing of instruction B is delayed, then this will increase the execution time. Unfortunately, it is difficult for hardware to assign the correct priorities to instructions. However, it is widely known that age-based priority, where a higher priority is assigned to older instructions, is sub-optimal. The rationale behind this heuristic is that a critical path is composed of a long dependence chain; thus, the instructions on a critical path remain in the IQ for a long time. Older instructions are therefore likely to be those on a critical path. Hereafter, we say that a priority is correct if it is assigned based on age.</p><p>Capacity is also an important feature for high performance. The larger the IQ, the higher the probability that ready instructions will be found. Apparently, programs with a large amount of instructionlevel parallelism (ILP) require this feature. High capacity is also important for memory-intensive programs, in which memory-level parallelism (MLP) is the main source for high performance. If the IQ is larger, more loads will be allowed to be executed for a short time. If multiple loads cause cache misses, then their memory accesses overlap. MLP can hide the memory access times of several loads using the memory access time of the counterpart. This reduces the negative impact of cache misses on the execution time, thereby improving performance. Given the amount of hardware allocated to the IQ, capacity efficiency is important for an effectively large capacity. Capacity efficiency is defined as the ratio of the number of instructions held in the IQ to the total number of IQ entries.</p><p>IQ organizations: There are three types of IQ: shifting queue (SHIFT) <ref type="bibr" target="#b5">[9]</ref>, circular queue (CIRC), and random queue (RAND). SHIFT achieves the highest IPC among these types because it assigns perfectly correct priorities and has good capacity efficiency. However, the circuit is complex, and thus its delay is longest among the types of IQ and it consumes a large amount of power. Therefore, SHIFT was only used in old processors with a small IQ and is not currently in use.</p><p>By contrast, the delays of CIRC and RAND are short because of the circuits' simplicity. However, the IPC of CIRC is low because of incorrect priorities caused by wrap-around and low capacity efficiency. CIRC is also not used in current processors.</p><p>RAND offers good capacity efficiency; however, the priority is incorrect because of the random ordering of instructions. Therefore, RAND is not used alone. A circuit called the age matrix <ref type="bibr" target="#b18">[22,</ref><ref type="bibr" target="#b20">24]</ref>, which selects the single oldest ready instruction, is used together with RAND in current processors <ref type="bibr" target="#b7">[11,</ref><ref type="bibr" target="#b18">22,</ref><ref type="bibr" target="#b22">26]</ref>. We call this organization AGE. AGE considers the ages of instructions; however, it only assigns the single oldest instruction to the highest priority, and does not assign the correct priority to all instructions.</p><p>Proposal: In this paper, we propose a novel IQ organization called the switching issue queue (SWQUE), which achieves correct prioritization and high capacity efficiency when either property is more needed using a simple circuit. SWQUE dynamically configures the IQ as a modified CIRC or AGE based on the degree of capacity demand, which is monitored during execution.</p><p>For less capacity-demanding phases (i.e., priority-sensitive phases), SWQUE operates as a modified CIRC. Here, the modified CIRC, which we call the priority-correcting CIRC (CIRC-PC), essentially uses the CIRC organization, but it correctly prioritizes instructions even when wrap-around occurs. The scheme corrects the priority by exploiting the finding that the instructions that are wrapped around are latency-tolerant. Capacity efficiency remains low, similar to the original CIRC; however, CIRC-PC is used for phases in which the correct priority is more important than capacity efficiency. Always assigning the correct priority to instructions achieves high performance.</p><p>By contrast, for capacity-demanding phases, SWQUE operates as an AGE with high capacity efficiency. The correct priority is not assigned to all instructions; however, high capacity efficiency still delivers high performance.</p><p>Section organization: The remainder of this paper is organized as follows: In Section 2, we explain the organization of conventional IQs to aid the understanding of the organization of SWQUE. We propose SWQUE in Section 3 and present the evaluation results in Section 4. In Section 5, we describe related work. Finally, we present our conclusions in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">ORGANIZATION AND CIRCUIT OF CONVENTIONAL IQS</head><p>In this section, we explain the organization and circuit of conventional IQs to aid the understanding of SWQUE and CIRC-PC. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Basic Organization</head><p>There are two types of IQ organizations, depending on the type of wakeup logic circuit: content-addressable memory (CAM) and RAM <ref type="bibr" target="#b9">[13]</ref>. These are both used in commercial processors. For example, the CAM type is used in the AMD Bulldozer <ref type="bibr" target="#b7">[11]</ref>, whereas the RAM type is used in the IBM POWER8 <ref type="bibr" target="#b22">[26]</ref>. We assume the CAM type in this paper. Applying the SWQUE scheme to the RAM-type IQ is our future work.</p><p>The IQ mainly comprises the wakeup logic, select logic, tag RAM, and payload RAM <ref type="bibr" target="#b9">[13,</ref><ref type="bibr" target="#b16">20,</ref><ref type="bibr" target="#b26">30]</ref>, as illustrated in Figure <ref type="figure" target="#fig_0">1</ref>. The wakeup logic is a one-dimensional array in which each wakeup logic entry holds the tags for two source operands and ready flags indicating the data dependence state (resolved or not) for the corresponding instruction. If both data dependences are resolved, an issue request is sent to the select logic, which grants some requests by considering resource constraints. The grant signals are sent to the payload RAM that holds instructions. Instructions are read (issued) from the payload RAM and sent to the function units. The grant signals are also sent to the tag RAM, the wordlines of the tag RAM are directly connected to the grant signals (i.e., there is no address decoder), and the destination tags are read by responding to the grant signals. These tags are broadcast to the wakeup logic to update the ready flags.</p><p>The issue operation described above is pipelined. The wakeup, select, and tag RAM read are performed in the first cycle whereas the payload RAM is read in the second cycle. The first cycle operations are not generally pipelined; if pipelined, dependent instructions cannot be issued back-to-back;<ref type="foot" target="#foot_0">1</ref> , thus the IPC is degraded. The path composed of these three operations is the critical path of the IQ, and is a critical path of the processor <ref type="bibr" target="#b17">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Circuits</head><p>In this section, we briefly describe the circuits of the conventional IQ. The following three sections explain the wakeup logic, select logic, and tag RAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Wakeup Logic.</head><p>The wakeup logic is composed of CAM. Each entry in CAM holds the tags for two source operands of an instruction and two ready flags that indicate whether the corresponding source operand is ready. The IW destination tags of issued instructions are broadcast to all IQS entries in CAM using the search lines, which we call tag lines. Here, IW and IQS denote the issue width and IQ size, respectively. The broadcast destination tags are compared with two source operand tags in each entry. If there is a match, then the ready flag is set. If both ready flags that correspond to two operands are set, then an issue request is output to the select logic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Select Logic.</head><p>The select logic receives an issue request signal for each entry and outputs IW grant signals (?rant 0 , . . . , ?rant IW -1 ) for each entry, where each grant signal corresponds to a specific issue port <ref type="bibr" target="#b8">[12,</ref><ref type="bibr" target="#b26">30]</ref>.</p><p>The most widely known circuit used as select logic is a tree arbiter <ref type="bibr" target="#b17">[21]</ref>. This circuit uses a tree structure to connect multiple small arbiter cells. For example, if the small arbiter cell arbitrates four requests, then the overall tree arbiter is organized using a quad-tree. For an IW -issue IQ, IW tree arbiters are stacked and the grants are determined from the highest priority in order from the bottom of the stacked arbiters <ref type="bibr" target="#b8">[12,</ref><ref type="bibr" target="#b17">21]</ref>.</p><p>Note that the priority in arbitration is not flexible but is fixed with respect to the IQ position to make the delay short. Recall that the IQ critical path is a critical path in a processor; thus, the shorter delay is strongly required for high performance. Generally, the lower the position, the higher the priority.</p><p>Also note that ?rant 0 , . . . , ?rant IW -1 correspond to the instructions in descending order in terms of the priority <ref type="bibr" target="#b8">[12,</ref><ref type="bibr" target="#b17">21]</ref>; that is, ?rant 0 is the grant signal of the instruction with the highest priority, ?rant 1 is that of the instruction with the second-highest priority, and so on. This ordering is used because the grants are determined from the highest priority in order, as previously described.</p><p>Another select logic circuit exists that uses prefix-sum logic <ref type="bibr" target="#b8">[12,</ref><ref type="bibr" target="#b26">30]</ref>. Although this logic is faster than the tree arbiter, it is not different in terms of the fixed position-based priority and grant signal ordering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Tag RAM.</head><p>The tag RAM consists of an SRAM that stores destination tags without an address decoder. It has IW ports, with IW -bit grant lines per entry from the select logic directly connected to the IW wordlines per entry. Up to IW destination tags held in the SRAM cells connected to the asserted wordlines are read.</p><p>Note that, for this study, the tag RAM outputs bogus data from a read port when the corresponding wordline is not asserted (i.e., no instruction is issued from the corresponding issue port). The bogus data are zeros for all bits in current SRAM designs in nano-LSI technology, where eight-transistor (8T) cells are used rather than conventional six-transistor (6T) cells to ensure read margins under low supply voltages <ref type="bibr" target="#b25">[29]</ref>. In fact, Intel switched from 6T to 8T cells for its 45nm line of Core processors <ref type="bibr" target="#b14">[18]</ref>. When using 8T cells, each bitline is single and an inverter is used to read the value of the bitline. Therefore, if a wordline is not asserted, the precharged bitline is simply read, and the output is thus zero. The bogus data from the tag RAM do not represent a valid tag, but are functionally used as a bogus tag that is not used as a tag for any in-flight instructions, and thus never matches any of the source operand tags in the wakeup logic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Taxonomy</head><p>There are three types of IQs in terms of instruction ordering. The first type is the shifting queue (SHIFT). SHIFT was used in old processors (e.g., DEC Alpha 21264 <ref type="bibr" target="#b5">[9]</ref> two decades ago), where the IQ size was small. In the SHIFT, instructions stay physically ordered by age from the head to the tail of the queue. A compaction circuit, which computes shift amount and shifts instructions to fill the "holes" created by the instructions that have been issued, is responsible for this. Because the select logic is position based, the priority assigned to instructions is always perfect. Additionally, compaction achieves good capacity efficiency. However, the compaction circuit is highly complex, and is inserted into the critical path of the IQ <ref type="bibr" target="#b5">[9]</ref>. Thus, the delay of the IQ is significantly increased. Additionally, compaction needs to perform numerous shifts of instructions, and thus consumes a large amount of power. SHIFT is no longer used in current processors.</p><p>The second type of IQ is the circular queue (CIRC), which is composed of a circular buffer. In this queue, instructions remain physically ordered by age, as per SHIFT, but it does not have a compaction circuit. Although this queue is simple, unlike SHIFT, remaining "holes" causes serious capacity inefficiency. This significantly degrades performance in capacity-sensitive programs. Additionally, wrap-around occurs in instruction order, and this reverses the issue priority, further degrading performance. CIRC was often assumed in previous studies on IQs (e.g., <ref type="bibr" target="#b2">[6,</ref><ref type="bibr" target="#b11">15]</ref>), but is not used in current processors.</p><p>The last type of IQ is the random queue (RAND), where instructions are simply dispatched into the "holes. " Although the capacity is fully used, the order of instructions in the queue becomes random because "holes" arise randomly in the long term. Thus, the issue priorities of the instructions are assigned randomly because of their random ordering. Therefore, the IPC is low in priority-sensitive programs.</p><p>To mitigate IPC degradation in the RAND, an additional circuit called the age matrix <ref type="bibr" target="#b18">[22,</ref><ref type="bibr" target="#b20">24]</ref> is used. We refer to this type of IQ as AGE. The age matrix is used in parallel with the select logic <ref type="bibr" target="#b7">[11]</ref>, and selects only the single oldest ready instruction. The circuit of the age matrix is a logic matrix, where each row and column of the matrix is associated with an instruction in the IQ. Each cell of the matrix holds a single bit that represents age ordering information. In each row, the circuit determines whether the input issue request is the oldest by bitwise ANDing the row vector stored in the matrix with the transposed issue request vector. Although the age matrix considers age, the priority correctness is imperfect because only the single oldest instruction is selected. Therefore, effectiveness is limited.</p><p>We have described all the published IQ organizations used in commercial processors to the best of our knowledge in this section. Although all processor vendors do not publish their IQ organizations, AGE is generally used in modern processors <ref type="bibr" target="#b7">[11,</ref><ref type="bibr" target="#b18">22,</ref><ref type="bibr" target="#b22">26]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">CIRC-PC: Priority-Correcting Circular Queue</head><p>In this section, we provide details on CIRC-PC. In Section 3.1.1, we explain the problem of the incorrect priority caused by wraparound. Then we describe a possible straightforward circuit to solve this problem, and demonstrate its high complexity in Section 3.1.2. In Section 3.1.3, we describe our approach to this problem. Finally, we provide details on the circuits of CIRC-PC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Reversed Priority Problem.</head><p>In CIRC, the issue priority becomes incorrect when wrap-around occurs. Figure <ref type="figure" target="#fig_1">2</ref> illustrates how the priority becomes dependent on wrap-around, where the select logic circuit is configured such that instructions in lower entries are assigned a higher priority. As shown in Figure <ref type="figure" target="#fig_1">2</ref>(a), the priority is correct when wrap-around has not occurred. By contrast, as shown in Figure <ref type="figure" target="#fig_1">2</ref>(b), the incorrect priorities are assigned to instructions when wrap-around occurs. Despite the instructions in the area from the head entry to the top of the queue being older than those in the area from the tail entry to the bottom of the queue, the former instructions are assigned a lower priority, whereas the latter instructions are assigned a higher priority. Hereafter, we call the instructions in the area close to the top the normal priority instructions (NR instructions), whereas those in the area close to the bottom are the reversed priority instructions (RV instructions). The priority of the RV instructions must be corrected so that it is lower than that of the NR instructions.</p><p>3.1.2 Possible Straightforward Circuit. One possible but straightforward circuit that solves the incorrect priority problem caused by wrap-around with only minimal modification of the IQ involves exchanging the requests from the NR instructions with those from the RV instructions in terms of the position by inserting an exchange network. The exchange network is essentially composed of many IQS-to-1 MUXes for each input of the select logic. These MUXes are controlled using the values of the head and tail pointers. Although this circuit can be implemented theoretically, the huge fan-out of request signals with vertically traversing long wires and huge fan-in of MUXes significantly increase the delay and energy consumption. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Approach to Correct Reversed Priority.</head><p>To enable CIRC-PC to correct the priority when wrap-around occurs, we prepare an additional select logic denoted by S RV for the RV instructions only; the original select logic, which is denoted by S N R , is used for the NR instructions only. Issue requests from the wakeup logic are first sent to either S N R or S RV , depending on whether they are from the NR or RV instructions, respectively. Some requests are then granted independently in either select logic. At this moment, unlike a normal IQ, instructions to be issued are not yet determined. The grant signals from each select logic then read destination tags from the tag RAM. Finally, up to IW tags are selected from these read destination tags to determine the instructions to be issued, with higher priority assigned to the tags that originated from S N R . In this scheme, the final tag selection process is responsible for the correction of the issue priority because higher priority is assigned to the tags of the NR instructions.</p><p>Although the scheme described above successfully corrects the priority, it has a serious implementation problem, because it doubles the number of ports of the tag RAM, which significantly increases the delay of the IQ. Therefore, we implement time-sliced tag RAM access; that is, the tag RAM is accessed at the end of each clock cycle as per normal for the NR instructions, whereas it is accessed at the beginning of the next clock cycle for the RV instructions. Because the tag RAM is a small circuit (see Figure <ref type="figure" target="#fig_14">13</ref>), doubling the number of accesses is possible without increasing the IQ delay. However, the downside is that the wakeup-select for the RV instructions requires two cycles. This virtually increases the latency of the RV instructions by one cycle, and thus the IPC is reduced. However, our evaluation in Section 4.4 indicates that this adverse effect is very small. This means that ready instructions with low priority (i.e., ready RV instructions, which are placed near the tail of the queue and are thus young) are off the critical path and thus latencytolerant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4">Organization Details .</head><p>Figure <ref type="figure" target="#fig_2">3</ref> shows the organization of the CIRC-PC. The blue boxes represent added logic. The additional select logic, S RV , is placed on the right-hand side of S N R , and receives issue requests for the RV instructions from the wakeup logic. D-FFs are placed between S RV and S N R to allow the grant signals from S RV to be sent to the tag RAM in the next cycle. The final tag selection, which we call tag merge, is performed in the logic called the destination tag multiplexer (DTM), which is placed above the tag RAM.</p><p>Figure <ref type="figure" target="#fig_3">4</ref> shows the pipeline timing chart, which explains the detailed timing of the wakeup-select operation. Instructions i0, i1, and i3 are NR instructions, whereas instruction i2 is an RV instruction. In the figure, the phases of W and T represent the wakeup and tag RAM read, respectively, whereas the phases of S N R and S RV represent the selection for the NR and RV instructions, respectively. The length of each phase in the chart is proportional to the delay evaluated by our HSPICE simulation of the IQ for our default processor model described in Section 4.1.</p><p>For NR instructions i0 and i1, W, S N R , and T are performed in a single cycle as per normal. By contrast, for RV instruction i2, only W and S RV are performed in the first cycle and T is then performed at the beginning of the next cycle 2 . The destination tags of the RV instructions read from the tag RAM are temporarily stored in the DTM (see Figure <ref type="figure" target="#fig_2">3</ref>). To achieve this, the DTM contains latches called pending tag latches (PTLs). (The DTM circuit is explained in detail in Section 3.1.5.) After the NR instructions are read from the tag RAM, the DTM merges the tags of the NR instructions i1 with the tags stored in the PTLs, with higher priority assigned to the tags of the NR instructions in the merging operation (see the red line in Figure <ref type="figure" target="#fig_3">4</ref>). The merged tags are output to the tag lines of the wakeup logic. Therefore, the correction of the priority is performed during the merging operation in the DTM.</p><p>There are several concerns about this implementation, which are described as follows, but they are not substantial problems:</p><p>? The issue operation of the RV instructions takes two cycles, which reduces the IPC. However, the RV instructions are young, and are thus unlikely to be on the critical path of the dataflow if they are ready. This implies that the ready RV instructions are latency-tolerant, and the increase in the number of cycles of the issue operation thus hardly affects the IPC. Our evaluation in Section 4.4 indicates that the adverse impact of this increase on performance is only 1.1% on average. ? The DTM increases the IQ delay. However, it only represents 1.3% of the entire IQ delay, according to our LSI design and HSPICE simulation, as described in Section 4.7. ? The tag RAM is accessed twice within a single cycle. To achieve this, double the delay of a single tag RAM read including the precharge time must be accommodated within a 2 The blank at the beginning of the cycle in the timing chart represents the precharging of the tag RAM for the immediate next read. For the wakeup and select logic, one precharges whereas the other operates, and thus precharging is hidden.  single cycle. According to our LSI design and HSPICE simulation results (for the methodology, see Section 4.1), the total delay of the double tag RAM accesses including the precharge time is 66% of the entire IQ delay, and thus there is a large margin.</p><p>? The additional select logic increases the processor cost. However, the impact on the core or entire chip in a current commercial processor (Intel Skylake) is only 0.034% or 0.010%, respectively.</p><p>3.1.5 Circuit Details. In this section, we provide details on the circuits that must be added to those of the conventional IQ. Entry Slice: Figure <ref type="figure" target="#fig_5">5</ref> illustrates the circuits for the entry slice of the CIRC-PC, where the entry slice represents a single row of the IQ. The reverse flag (which is not illustrated in Figure <ref type="figure" target="#fig_2">3</ref>) indicates that the corresponding instruction is an RV instruction at dispatch time. This flag is set when an instruction is dispatched if wrap-around occurs; otherwise, it is cleared. Signal R, which is the reverse flag ANDed with the signal that indicates that the instructions in the IQ are currently wrapped around, controls whether the issue request signal from the wakeup logic is input to S N R or S RV ; that is, if R is true, the request signal is input to S RV and is masked for S N R ; otherwise, the opposite operation is performed. Similarly, grant signals are selected by the clock signal masked by R (the clock is high during the first half of the clock cycle and low for the remaining time). If the control signal to the MUX is true, then the grant signals from S RV are selected; otherwise, the grant signals from S N R are selected.</p><p>The delay of this circuit is only increased by the single AND gate and MUX. Thus, it is negligibly small. DTM: The DTM is used for tag merge, where the tags of the NR instructions and those of the RV instructions stored in the PTLs are merged, with higher priority assigned to the tags of the NR instructions. Figure <ref type="figure" target="#fig_6">6</ref> shows the circuit (IW = 4 as an example). The MUXes select the tags output to the wakeup logic from the tags of NR instructions (dta? N R 0..3 ) and those in the PTLs (dta? RV 0..3 ). The MUXes are controlled using valid bits (V 0..3 ) to indicate that the tags of the NR instructions are valid. We modified the tag RAM to output the validity of each output data, where the validity is created by the wordlines. This means that if the output tag is valid, the corresponding valid bit is true; otherwise (i.e., bogus tag), it is false. The tags of the NR instructions are prioritized during selection as follows: if V i is true, then dta? N R i is selected; otherwise, the tag of the PTL is selected.</p><p>Suppose that the priority is higher when the suffix of dta? is smaller for both the NR and RV instructions; that is, the priorities of dta? N R   descending in terms of the priority. Note that tags are aligned on one side in terms of priority because of the select logic circuit, as described in Section 2.2.2. As shown in Figure <ref type="figure" target="#fig_6">6</ref>, we arrange the tags, dta? N R i and dta? RV i , in opposing order as inputs to the MUXes. This means that dta? N R 0 to dta? N R 3 are aligned from left to right, whereas dta? RV 0 to dta? RV 3 are aligned from right to left. This opposing alignment successfully merges tags in terms of priority.</p><p>In the example shown in Figure <ref type="figure" target="#fig_6">6</ref>, two dta?s N R i (i = 0, 1) are valid, whereas three dta?s RV i (i = 0, 1, 2) in the PTLs are valid (the remaining PTL holds a bogus tag). The same example is presented in Table 1(a) for clarification. In this case, the two MUXes on the lefthand side output dta? N R 0 and dta? N R 1 , whereas the two MUXes on the right-hand side output dta? RV 0 and dta? RV 1 . Note that dta? RV 2 remains, but it is simply discarded during this cycle (i.e., the PTL is overwritten in the next cycle).</p><p>Another example is shown in Table <ref type="table" target="#tab_0">1</ref>(b). In this example, only a single valid tag appears for the NR instructions, whereas two valid tags are held in the PTLs for the RV instructions. As shown in the merge results, the MUX second from the left outputs a bogus tag.</p><p>As described previously, the DTM increases the IQ delay. We indicate the critical path of the DTM with the broken orange line in Figure <ref type="figure" target="#fig_6">6</ref>. This path includes the valid bit lines because the PTLs are updated at the beginning of each clock cycle, whereas selection using the valid bits is performed immediately before the tag broadcast to the wakeup logic. We evaluate the increased delay in Section 4.7.</p><p>Finally, we explain how the final grant signal ?rant_f inal i output to the payload RAM is generated from the two sets of grant signals: ?rant N R i (the grant from S N R ) and ?rant RV i (the grant from S RV ) (i = 0, . . . , IW -1). As performed in the DTM, the final grant signal is selected using the valid bits for the NR instructions from the tag RAM (V i ). Given that the tags are merged in opposing order in terms of priority in the DTM, the final grant signals are obtained as follows:</p><formula xml:id="formula_0">?rant_f inal i = V i ? ?rant N R i ? V ? i ? ?rant RV IW -i-1 .</formula><p>Note that this operation is performed in the pipeline stage in which the payload RAM is read (see Figures <ref type="figure" target="#fig_2">3</ref> and<ref type="figure" target="#fig_5">5</ref>). Because the access time for the small payload RAM is short (only 43% of the IQ critical path delay according to our HSPICE simulation), this additional operation does not increase the clock cycle time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Switching Scheme between CIRC-PC and AGE</head><p>The IQ configuration is switched between CIRC-PC and AGE, depending on the degree of capacity demand. If the capacity demand is high, then the IQ is configured as AGE; otherwise, it is configured as CIRC-PC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Metrics to</head><p>Estimate the Degree of Capacity Demand. Two metrics are used to estimate the degree of capacity demand that corresponds to two performance sources, ILP and MLP. For MLP, a large capacity is beneficial for memory-intensive phases because if more loads are issued within a short time, then many last-level cache (LLC) misses can be overlapped with higher probabilities. Therefore, we monitor the frequency of LLC misses, specifically in terms of LLC misses per kilo-instructions (MPKI). If the MPKI is higher than a predetermined threshold, then the current phase is considered to be capacity-demanding.</p><p>For ILP, we monitor the frequency of instruction issues from the predetermined lowest priority region of the IQ. We call this metric the frequency of low-priority instruction issues (FLPI ). If the FLPI is high, this means that ready instructions reside throughout the IQ; that is, many ready instructions reside in the lowest priority region, not only in the higher priority region. We thus determine that a phase is capacity-demanding if the FLPI is higher than a predetermined threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Reconfiguration of the IQ.</head><p>The reconfiguration of the IQ is determined periodically based on two metrics. If the MPKI and FLPI are both high or both low in the current interval, then the IQ will be configured as AGE or CIRC-PC in the next interval, respectively. If they disagree in the current interval, then the IQ is configured as AGE in the next interval. This AGE-favoring policy achieves better performance than the CIRC-favoring policy, according to our evaluation.</p><p>The IQ hardware reconfiguration is simple. The head and tail pointers and wrap-around signal (see Section 3.1.5) operate in CIRC-PC mode, whereas a free entry list for the IQ is maintained in AGE mode. In the AGE configuration, the wrap-around signal is always set to false. This disables the use of SL RV and any requests go to SL N R . When switching between AGE and CIRC-PC modes, the scheme flushes the pipeline and ensures that the necessary  structures work. Because of the requirement for a pipeline flush, a penalty is imposed on switching. This penalty is similar to that for branch misprediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Stabilizing Mode Transitions.</head><p>Two FLPI thresholds are required that correspond to AGE and CIRC-PC modes. This causes an instability problem in the mode transitions during low MPKI phases. It is difficult to determine the thresholds for each mode, which causes the state to remain in an optimal mode with higher stability, according to our preliminary evaluation. In the worst case scenario, each mode repeatedly dictates that the other mode is beneficial, and the mode goes back and forth as a result. To stabilize the mode transition, we emphasize the decision in CIRC-PC mode, and dynamically adjust the FLPI threshold in AGE mode to make AGE mode more likely to remain unchanged. For this purpose, we prepare a single small saturated resetting counter, called the instability counter, which evaluates the mode transition instability. The counter is incremented if the FLPI decision in CIRC-PC mode determines that AGE mode is beneficial; otherwise, it is reset to zero. If the instability counter reaches a predetermined value, then we determine that the mode transition is unstable. In this case, the FLPI threshold AGE mode is reduced by a predetermined value. This makes AGE mode more likely to remain unchanged, and the mode transition thus becomes more stable. Additionally, we periodically reset both the instability counter and FLPI threshold in AGE mode to restart learning and adapt phase changes. Figure <ref type="figure" target="#fig_8">7</ref> illustrates an example of this behavior. In this example, the instability counter is initially zero, and its threshold is 2. Additionally, the MPKI is low through all phases. The mode starts from CIRC-PC mode. At the end of phase 1, suppose that the is found to be high. The mode is thus transferred to AGE mode. This mode transition increments the instability counter. Next, suppose that the FLPI is low in phase 2. The mode is then transferred back to CIRC-PC mode. Next, suppose that the FLPI is high again in phase 3. The mode is then transferred back to AGE mode again. The instability counter is incremented at this time, and reaches the threshold, thereby determining that the mode transition is unstable. Thus, the FLPI threshold for AGE mode is reduced so that remaining in AGE mode is more likely. With this low threshold, the FLPI becomes high in phase 4, unlike in phase 2. Accordingly, the mode transition becomes more stable, remaining in AGE mode. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION RESULTS</head><p>We first describe the evaluation methodology in Section 4.1. We then compare the performance of SWQUE with that of the conventional IQ organizations in Section 4.2. In Section 4.3, we evaluate how effective SWQUE will be in a future large-sized processor. In Section 4.4, we evaluate the effectiveness of CIRC-PC by comparing it with the performance of the idealized CIRC. Next, we evaluate the energy consumption and area overhead of SWQUE in Sections 4.5 and 4.6, respectively. Then, we evaluate the circuit delay specific to SWQUE in Section 4.7. In Section 4.8, we evaluate the performance impact of the mode switch penalty. Finally, we evaluate the performance of SWQUE and AGE when we enhance the AGE scheme using multiple age matrices in Section 4.9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Methodology</head><p>We built a simulator based on the SimpleScalar Tool Set version 3.0a [1] to evaluate the IPC. The instruction set used was Alpha ISA. We used all the programs from the SPEC2017 benchmark suite except gcc and wrf ; these programs were excluded because they do not run correctly on our simulator at present. The programs were compiled using gcc version 4.5.3 with option -O3. The configuration of the base processor used for the evaluation is summarized in Table <ref type="table" target="#tab_2">2</ref>.</p><p>We simulated 100M instructions after the first 16B instructions were skipped using the refspeed inputs. The parameters specific to SWQUE are summarized in Table <ref type="table" target="#tab_3">3</ref>.</p><p>In addition to the IPC evaluation, we evaluated the area and delay of the IQ circuits. We designed the IQ at the transistor level, assuming MOSIS design rules <ref type="bibr">[2]</ref>. We then performed a circuit simulation using HSPICE to evaluate the delay, assuming the 16nm predictive transistor model [3] developed by Arizona State University for HSPICE, and the resistance and capacitance per unit length of the wire predicted in the International Technology Roadmap for Semiconductors <ref type="bibr" target="#b12">[16]</ref>. Drivers and repeaters were optimally inserted on </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance Comparison</head><p>Before presenting a detailed performance comparison of SWQUE with AGE, we present the average performance comparison results for various conventional IQs. Figure <ref type="figure" target="#fig_9">8</ref> shows the performance (IPC) degradation of the various IQs relative to that of SHIFT for integer (INT) and floating-point (FP) programs on the geometric mean ("GM int" and "GM fp, " respectively). The longer the bars, the worse the performance; thus, shorter bars are better. Note that SHIFT is the best in terms of the IPC in the various IQs evaluated because of its perfectly correct priority and highest capacity efficiency. As shown in Figure <ref type="figure" target="#fig_9">8</ref>, the performance of CIRC and RAND significantly degraded in both the INT and FP programs by more than 10% compared with SHIFT. The performance degradation of RAND is mitigated by adding the age matrix (i.e., AGE), but there is still considerable room for improvement. By contrast, SWQUE achieves nearly the same performance as SHIFT in the INT programs (only 0.8% worse), and also achieves good performance in the FP programs (only 2.4% worse).</p><p>Figure <ref type="figure" target="#fig_10">9</ref> shows the speedup of SWQUE when compared with AGE for each of the programs. Two bars for each program represent the speedups in medium-and large-sized processors. The mediumsized processor is the default processor; the processor configuration is listed in Table <ref type="table" target="#tab_2">2</ref>, whereas the large-sized processor scales the seven parameters of the configuration as listed in Table <ref type="table" target="#tab_4">4</ref>; the other parameters remain unchanged from their default values. In this section, we discuss the results for the medium-sized processor; the results for the large-sized processor are discussed in Section 4.3. The notation above the graph for each program represents programs with a moderate amount of ILP (blue box), rich ILP (red box), or MLP (green box) programs. The IPC threshold between the moderate and rich ILP programs is 3.3, and that for MPKI, whether the program is MLP or not, is 3.0.</p><p>As shown in the figure, SWQUE achieves a significant speedup over AGE in five out of seven moderate ILP programs in the INT programs. In particular, in deepsjeng, exchange2, leela and mcf, the speedups are considerably higher by more than 10% (up to 24.4%). In the moderate ILP programs, the IQ is configured as CIRC-PC for most of the execution time, as shown in Figure <ref type="figure" target="#fig_11">10</ref>. The results show that the correct prioritization for all instructions is performed very well by the CIRC-PC scheme, in contrast to AGE, where the prioritization is correct for only a single instruction. However, SWQUE achieves almost no speedup in the MLP programs because SWQUE is essentially configured as an AGE for these programs. On average, SWQUE achieves a 9.7% speedup in the INT programs.</p><p>In the FP programs, SWQUE again achieves a significant speedup in the moderate ILP programs, but no speedup in the MLP programs. The FP programs include rich ILP programs, unlike the INT programs. Rich ILP programs are capacity-demanding, and thus SWQUE is essentially configured as AGE, thereby achieving no speedup. Because moderate ILP programs constitute only half the total number of FP programs, the speedup is limited (2.9% on average).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Performance in a Large-Sized Processor</head><p>In this section, we discuss the results obtained when the processor size is scaled up to verify the effectiveness of SWQUE in the future. The results are shown as red bars in Figure <ref type="figure" target="#fig_10">9</ref>. The larger the window size (i.e., the size of IQ, load/store queue, reorder buffer, and register file), the more issue conflicts occur, and the importance of the issue priority thus increased. Additionally, the IQ capacity shortage in the CIRC-PC mode of SWQUE is mitigated. Hence, SWQUE becomes more advantageous. By contrast, fewer the issue conflicts occur as the issue width and the number of function units increase, and the effectiveness of SWQUE thus decreases.</p><p>As shown in Figure <ref type="figure" target="#fig_10">9</ref>, the speedup of SWQUE when compared with AGE is increased in most of the moderate ILP programs, compared with that in the medium-sized processor. In the capacitydemanding programs (rich ILP and MLP programs), there is almost no speedup as per the medium-sized processor. On average, the speedups in the INT and FP programs are 13.4% and 4.0%, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation of CIRC-PC</head><p>In this section, we discuss the effectiveness of priority correction in CIRC. Figure <ref type="figure" target="#fig_12">11</ref> shows the evaluation of the average performance of various CIRC configurations for INT and FP programs. The Yaxis represents the performance degradation relative to SHIFT. The longer the bars, the worse the performance; thus, shorter bars are better. Three types of CIRC are compared. CIRC-CONV is the conventional circular IQ, which is simply called CIRC in the other sections. CIRC-PPRI is the circular queue with perfect priority, which assigns the correct priority even when wrap-around occurs. Finally, CIRC-PC is the circular queue that we proposed in Section 3.1, which is used in SWQUE.</p><p>As shown in the figure (also evaluated in Section 4.2), CIRC-CONV degrades performance in both INT and FP programs because   of the incorrect priority that it assigns when wrap-around occurs and capacity inefficiency. By contrast, CIRC-PPRI improves the performance because the correct priority is perfectly assigned. For CIRC-PC, although the RV instructions require two cycles to be issued, the performance is almost identical to that of CIRC-PPRI in the INT programs, and it is only slightly worse in the FP programs. This means that the RV instructions are latency-tolerant, and the issue delay thus hardly affects performance adversely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Energy Consumption</head><p>In this section, we evaluate the energy consumption of a core using McPAT <ref type="bibr" target="#b15">[19]</ref>, assuming 22nm LSI technology (22nm technology is the finest that McPAT supports), and a temperature of 320K. We compare SWQUE with the idealized shifting queue (I-SHIFT) where the increases of energy consumption and delay caused by compaction are not considered, which means that it is the simplest circuit and the execution time is shortest (a longer execution time equates to more static energy being consumed) among the IQs we evaluated in this paper. We could not compare AGE because McPAT does not support the age matrix. For the same reason, the energy consumption evaluation for SWQUE does not include the energy consumed by the age matrix.</p><p>Figure <ref type="figure" target="#fig_13">12</ref> shows the energy consumption relative to that of I-SHIFT. The bar is divided into four parts: static and dynamic energies for the basic operation of the IQ and SWQUE-specific operation (the extra select logic operation and twice as many tag RAM accesses). As the figure shows, the energy consumed by the SWQUE-specific operation is very low (the static energy is too low to be visible in the figure). Consequently, the energy consumption of SWQUE is almost the same (only 0.5% increase) compared with that of the I-SHIFT.</p><p>As described previously, the energy consumption of the age matrix is not included in this evaluation. However, it is smaller than that of the select logic, and thus, if included, it would be added as a small constant value to both I-SHIFT and SWQUE, and so the graph would hardly be changed.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Area Overhead</head><p>The SWQUE area overhead is the additional select logic. In this section, we estimate the impact of this area overhead.</p><p>McPAT calculates the area of the various structures in a core of a processor, including the IQ, but it neglects the area of the select logic 3 . Additionally, it does not assume that the IQ has an age matrix, as described in Section 4.5. Therefore, we manually drew the LSI layout of the IQ, assuming MOSIS design rules [2], and compared the area with that of the Intel Skylake fabricated using 14nm LSI technology.</p><p>Before providing the results, we compare the transistor density of our design with that of several examples in Table <ref type="table" target="#tab_5">5</ref> to illustrate that our layout design is reasonable. As the table shows, the transistor density of any circuit composed of an IQ is sparser than the single-port 512KB L2 cache (one of the densest structures in processors), but denser than the 54-bit multiplier (dense logic array). Additionally, when compared with the entire Intel Skylake processor chip, the transistor density of the circuits in our design is comparable or denser. These results indicate that our layout design is reasonable.</p><p>Our evaluation indicates that the area overhead is 17% compared with the baseline IQ area. Figure <ref type="figure" target="#fig_14">13</ref> illustrates the relative sizes of each circuit in SWQUE.</p><p>Table <ref type="table" target="#tab_6">6</ref> lists the cost impact on a processor along with the costneutral performance comparison results. The first three rows of the table list the additional area (assuming 14nm LSI technology) and its ratio relative to that of the Intel Skylake core and entire chip. As listed in the table, the additional costs and their are very small. The two remaining rows Table <ref type="table" target="#tab_6">6</ref> list the cost-neutral performance comparison results. We evaluated the performance of AGE, has 17% increase in entries (150 entries) when using 3 McPAT calculates the energy consumption of the select  the additional area for SWQUE. As listed, simply increasing the small number of entries does not enhance the performance (it even slightly reduces the performance by increasing issue conflicts).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Delay Issues</head><p>The SWQUE delay is increased by the DTM. As shown in Figure <ref type="figure" target="#fig_6">6</ref>, the broken orange line represents the critical path of the DTM. However, the delay of this critical path is not completely exposed to the IQ delay because valid signals (V ) in the DTM travel parallel to tags (dta?) from the left-hand side of the tag RAM to the wakeup logic along the top of the tag RAM. These tags must even travel in the IQ with the basic organization, without the DTM. Therefore, the increased net delay produced by the DTM is caused by the increase in the load capacitance provided by the gate capacitance of the transistors for MUX control. We compared the IQ delay with and without the DTM via HSPICE simulation, and found that the additional delay caused by the DTM is only 1.3% of the entire IQ delay.</p><p>Another concern is whether the double accesses to the tag RAM are accommodated within a single cycle. We evaluated this using HSPICE simulations and found that the total delay of the double tag RAM accesses, including precharge time is 66% of the entire IQ delay, and thus there is a large margin. This short access time is related to the small size of the tag RAM as shown in Figure <ref type="figure" target="#fig_14">13</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Switch Penalty Sensitivity</head><p>The default penalty at the transition between AGE and CIRC-PC is 10 cycles, as listed in Table <ref type="table" target="#tab_3">3</ref>. We evaluated the sensitivity of this penalty by changing it to 40 cycles. SWQUE performance degradation relative to the case in which the default penalty was used was only 0.02%. This insensitivity arises because the transition occurs infrequently at 8 times per 1M clock cycles, on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9">Using Multiple Age Matrices</head><p>One approach to enhance the AGE scheme is to prepare multiple age matrices, and thus divide and conquer the priority problem using these matrices. This approach logically prepares multiple instruction buckets, where each bucket uses a single age matrix. Instructions are steered to one of these buckets at dispatch (i.e., write) to the IQ, and the single oldest ready instruction is selected from the instructions in each bucket. It is reasonable to prepare these buckets based on function units. Note that the buckets do not physically exist, and thus the IQ is thus not split. Because the IQ remains monolithic, the capacity efficiency also remains high. This approach can increase the IPC by having multiple age matrices select multiple high-priority instructions, although they are selected from each bucket (not from the entire IQ). The downside of this approach is simply the need for multiple age matrices, which increases the size of the IQ. Because the age matrix is a large circuit (see Figure <ref type="figure" target="#fig_14">13</ref>) compared with the other circuits in the IQ, the increase in the IQ area is significant. This increases the IQ delay by requiring global wires (for request and grant signals) to traverse the IQ, and can have a significant adverse impact on the clock cycle time. Therefore, the IQ size must be reduced to compensate for the delay increase in practice so that the IQ delay does not increase. In this section, we evaluate the IPC as a performance; we do not consider the increased delay and do not reduce the IQ size.</p><p>In the evaluation, the enhanced AGE scheme uses seven and nine age matrices for the medium-and large-sized processors, respectively. buckets are prepared based on function units; that is, the IQ of the medium-sized processor uses three, two, and two buckets for INT, memory, and FP instructions, respectively. The buckets are prepared in a similar manner for the large-sized processor. A load-balancing algorithm is used to steer instructions to the buckets. As with previous evaluations in this paper, the priorities of all ready instructions are essentially assigned based on the IQ position, but instructions selected by the age matrices are assigned the highest priority independently of their IQ position.</p><p>Figure <ref type="figure" target="#fig_15">14</ref> shows the evaluation results. The Y-axis represents the average speedup over the baseline AGE with a single age matrix for the medium-and large-sized processors. The blue (left), red (middle), and yellow (right) bars represent the speedups of SWQUE with a single age matrix (SWQUE-1AM) (the default evaluated in Section 4.2), AGE with multiple age matrices (AGE-multiAM), and SWQUE with multiple age matrices (SWQUE-multiAM), respectively.</p><p>Although, as shown in the figure, AGE-multiAM increases the performance by 1.4%, the performance gap versus that of SWQUE is still very large in the INT programs. This is because SWQUE strictly selects issue instructions in priority order from all the ready instructions in the IQ, whereas AGE-multiAM is constrained in the selection of high priority instructions because of the buckets; that is, instructions with the second or lower priority in a bucket are still placed in the random selection, even if they should have been selected when all the ready instructions were considered.</p><p>Note that the source of the speedup in SWQUE is the CIRC-PC scheme in the INT programs, as described in Section 4.2, and thus having multiple age matrices only affects the performance slightly. By contrast, the SWQUE speedup is at a level similar to that for AGE-multiAM in the FP programs because SWQUE is configured as an AGE in many programs in the FP programs, as described in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>The IQ was extensively studied around 2000, and a comprehensive survey was performed by Abella et al <ref type="bibr" target="#b0">[4]</ref>.</p><p>One processor that implemented SHIFT was the DEC Alpha 21264 <ref type="bibr" target="#b5">[9]</ref>. Although this scheme outperforms the other schemes we evaluated in this paper in terms of IPC, the shifting and compaction of the instructions needed to keep the order result in more complex circuits, increasing the delay and consuming large amounts of power, as described in Section 2.3. SHIFT is no longer used in modern processors.</p><p>Butler et al. investigated the effect of several select policies of the IQ, including random selection and selection based on the number of dependent instructions <ref type="bibr" target="#b4">[8]</ref>. Their evaluation results showed that the select policies they investigated delivered almost the same performance for the INT programs (SPEC89 benchmark) but the performance differed by up to 20% for the FP programs. They noted that similar performance arose from the number of ready instructions in a clock cycle being heavily skewed to zero. By contrast, our results (SHIFT vs. RAND) differ from their results, particularly for the INT programs. These differences have arisen because Butler et al. assumed full function units capable of integer execution, which caused no issue conflict on function units. We also confirmed that the number of ready instructions is skewed to zero, but there is still a significant number of clock cycles where the number of ready instructions is greater than zero. These statistics strongly depend on the program.</p><p>Although the age-aware select policy implements the correct priority, it is only a heuristic policy. Ideally, for high performance, the instructions on a critical path of the dataflow should be selected with high priority. Fields et al. proposed a scheme to identify the criticality of an instruction <ref type="bibr" target="#b6">[10]</ref>. However, the scheme is difficult to implement because of its high complexity and large area.</p><p>Stark et al. proposed breaking the wakeup-select loop into different pipeline stages <ref type="bibr" target="#b23">[27]</ref>. Brown et al. proposed issuing instructions without selection <ref type="bibr" target="#b3">[7]</ref>, where the select operation is eliminated from the critical path. These schemes are similar to our CIRC-PC in terms of pipelining the issue operation. However, these schemes pipeline the issue operation for all instructions to reduce the clock cycle time, whereas our scheme only pipelines the issue operation for latency-tolerant instructions. Additionally, these schemes are speculative; thus, misspeculation occurs frequently. This significant increases power consumption.</p><p>Brekelbaum et al. proposed a hierarchical scheduling window that divides the IQ into a large slow queue and a small fast queue <ref type="bibr" target="#b2">[6]</ref>. The larger queue requires multiple cycles for scheduling whereas the small queue requires only a single cycle. The large queue is CIRC and this scheme searches for several non-ready instructions from its head, which are moved to the small queue. The critical instructions are issued from the fast small queue, whereas latencytolerant instructions are issued from the slow large queue. This scheme is similar to ours because the instruction operations are segregated in terms of latency tolerance; however, moving the oldest non-ready instructions complicates the IQ, increases the delay, and consumes large amounts of power.</p><p>Henry et al. addressed the problem caused by wrap-around (i.e., incorrect issue priority) in CIRC at the circuit level <ref type="bibr" target="#b11">[15]</ref>. However, in their proposed circuits, the wires traverse vertically within the IQ to transfer information from the top to the bottom, and thus they increase the delay.</p><p>The delay of the conventional age matrix increases the IQ delay. Because the wire delay is dominant in the delay of this circuit, the reduction of the number of cells that the wires must traverse is effective to reduce the delay. It is also helpful to reduce wire delay traversing on this circuit. Sassone et al. proposed a scheme that dynamically allocates transposed issue request lines for a group of instructions to reduce the age matrix width <ref type="bibr" target="#b20">[24]</ref>. The downside of this scheme is that it still requires an arbiter to arbitrate the requests among the instructions in a group. Because the instructions are distributed within the IQ even for a single group (because the queue is a random queue), the wires for the arbiter traverse the IQ vertically. The arbiter delay is thus not trivial, and the effectiveness is consequently reduced. <ref type="bibr">Kora et al.</ref> proposed configuring the IQ to exploit ILP and MLP <ref type="bibr" target="#b13">[17]</ref>. To exploit ILP, the IQ is reduced, whereas to exploit MLP, the IQ is increased and pipelined. This scheme is similar to ours in terms of configuring the IQ depending on which parallelism the IQ attempts to exploit. However, that study did not address the problem of incorrect priority.</p><p>Sakai et al. proposed an IQ scheme that assigns high priority to multiple oldest instructions <ref type="bibr" target="#b19">[23]</ref> (not the single oldest instruction as in the age matrix). The scheme divides the IQ into a large main queue and small old queue, and the select logic is shared among both queues and assigns a higher priority to the instructions in the old queue than those in the main queue. The scheme moves multiple oldest instructions in the main queue to the old queue each cycle, and consequently succeeds in assigning higher priority to multiple oldest instructions.</p><p>Ando proposed an IQ scheme that reduces the branch misprediction penalty by issuing instructions in an unconfident branch slice as early as possible <ref type="bibr" target="#b1">[5]</ref>. Unconfident branch slices are defined as instructions that a branch directly or indirectly depends on and its branch prediction is unconfident. The scheme reserves several priority entries in the IQ for the instructions in the unconfident branch slices. During execution, the scheme constructs a pointer table that links instructions to the associated branch if there is a dependence. The confidence of branch prediction is estimated, and then whether instructions belong to an unconfident branch slice is determined by looking up the constructed pointer table. If an instruction is determined to belong to an unconfident branch slice, then it is dispatched into one of the reserved priority entries, and consequently issued with the highest priority.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>The stagnation of single-thread performance improvement is currently very serious. Following the end of Dennard scaling, architectural improvements are now more necessary than ever. In particular, improvements in the IQ are essential, and correct issue priority and high capacity efficiency are both vital for high performance.</p><p>In this paper, we proposed a new IQ called SWQUE that dynamically configures the IQ as a modified CIRC (CIRC-PC) or AGE based on the degree of capacity demand. The IQ is configured as CIRC-PC when the correct priority is more important than the capacity efficiency; otherwise, it is configured as AGE. CIRC-PC is effective for phases with moderate amounts of ILP, whereas AGE is effective for phases with large amounts of ILP or memory-intensive phases.</p><p>CIRC-PC, which we proposed in this paper, corrects the incorrect priority caused by wrap-around with a simple circuit by exploiting the finding that the instructions that are wrapped around are latency-tolerant.</p><p>Using CIRC-PC, SWQUE achieves higher performance than the IQ with the age matrix (AGE) that is currently used by 9.7% and 2.9% (up to 24.4% and 10.6%) in INT and FP programs, respectively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Organization of the IQ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Priority depending on whether wrap-around occurs in CIRC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>abbreviations:-SNR: select logic for NR instructions -SRV: select logic for RV instructions -DTM: destination tag MUX</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>abbreviation:-W: wakeup -T: tag RAM read -SNR: select for NR instructions -SRV: select for RV instructions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Entry slice circuit of CIRC-PC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Destination tag MUX circuit (DTM) with IW = 4 for tag merge.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Stabilizing the mode transition using the instability counter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Performance degradation relative to that of SHIFT for various IQs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Speedup over AGE for medium-(default) and large-sized processors. "m-ILP," "r-ILP," and "MLP" represent moderate ILP, rich ILP, and MLP programs, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Breakdown of the execution cycles in terms of modes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Performance degradation relative to SHIFT for various CIRC configurations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Energy consumption relative to I-SHIFT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Relative size of each circuit in SWQUE. The size of each circuit is scaled in proportion to the actual size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 14 :</head><label>14</label><figDesc>Figure 14: Performance comparison when using multiple age matrices.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Tag merge examples.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Base processor configuration.</figDesc><table><row><cell>Pipeline width</cell><cell>6-instruction wide for each of fetch,</cell></row><row><cell></cell><cell>decode, issue, and commit</cell></row><row><cell>Reorder buffer</cell><cell>256 entries</cell></row><row><cell>IQ</cell><cell>128 entries</cell></row><row><cell>Load/store queue</cell><cell>128 entries</cell></row><row><cell cols="2">Physical registers 256(int) + 256(fp)</cell></row><row><cell cols="2">Branch prediction 12-bit history 4K-entry PHT gshare,</cell></row><row><cell></cell><cell>2K-set 4-way BTB,</cell></row><row><cell></cell><cell>10-cycle misprediction penalty</cell></row><row><cell>Function unit</cell><cell>3 iALU, 1 iMULT/DIV, 2 Ld/St, 2 FPU</cell></row><row><cell>L1 I-cache</cell><cell>32KB, 8-way, 64B line</cell></row><row><cell>L1 D-cache</cell><cell>32KB, 8-way, 64B line, 2 ports,</cell></row><row><cell></cell><cell>2-cycle hit latency, non-blocking</cell></row><row><cell>L2 cache</cell><cell>2MB, 16-way, 64B line,</cell></row><row><cell></cell><cell>12-cycle hit latency</cell></row><row><cell>Main memory</cell><cell>300-cycle min. latency, 8B/cycle bandwidth</cell></row><row><cell>Data prefetch</cell><cell>stream-based: 32-stream tracked,</cell></row><row><cell></cell><cell>16-line distance, 2-line degree,</cell></row><row><cell></cell><cell>prefetch to L2 cache</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Parameters for SWQUE.</figDesc><table><row><cell>Switch interval</cell><cell>10k instructions</cell></row><row><cell>Switch penalty</cell><cell>10 cycles</cell></row><row><cell>Switch MPKI threshold</cell><cell>1.0</cell></row><row><cell>FLPI threshold</cell><cell>0.04</cell></row><row><cell>Instability counter threshold</cell><cell>2</cell></row><row><cell cols="2">Reduction of FLPI threshold at instability 0.01</cell></row><row><cell>Instability counter reset interval</cell><cell>1M instructions</cell></row><row><cell cols="2">long wires to reduce the delay, in accordance with experimentation</cell></row><row><cell>results.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Parameters of medium/large-sized processor models.</figDesc><table><row><cell>Parameter</cell><cell cols="2">Processor model Medium Large</cell></row><row><cell>Fetch/decode/Issue/commit width</cell><cell>6</cell><cell>8</cell></row><row><cell>IQ size</cell><cell>128</cell><cell>256</cell></row><row><cell>Load/store queue size</cell><cell>128</cell><cell>256</cell></row><row><cell>Reorder buffer size</cell><cell>256</cell><cell>512</cell></row><row><cell>Physical regs (int+fp)</cell><cell cols="2">256+256 512+512</cell></row><row><cell>Number of iALUs</cell><cell>3</cell><cell>4</cell></row><row><cell>Number of FPUs</cell><cell>2</cell><cell>3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Transistor density comparison.</figDesc><table><row><cell>Design</cell><cell>Circuit</cell><cell>Tr. density (?10 -3 /? 2 )</cell></row><row><cell></cell><cell>tag RAM</cell><cell>1.399</cell></row><row><cell>Author</cell><cell>wakeup logic</cell><cell>1.586</cell></row><row><cell></cell><cell>select logic</cell><cell>0.740</cell></row><row><cell></cell><cell>age matrix</cell><cell>1.708</cell></row><row><cell cols="2">Sun Micro[25] 512KB L2 cache</cell><cell>3.957</cell></row><row><cell>Fujitsu[14]</cell><cell>54-bit multiplier for FP</cell><cell>0.726</cell></row><row><cell>Intel</cell><cell>processor (Skylake)</cell><cell>0.701</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Additional costs and cost-neutral performance comparison.</figDesc><table><row><cell></cell><cell>value</cell><cell>0.0029mm 2</cell></row><row><cell>additional cost</cell><cell>vs. Skylake core</cell><cell>0.034%</cell></row><row><cell></cell><cell>vs. Skylake chip</cell><cell>0.010%</cell></row><row><cell cols="2">perf improvement SWQUE (128 entries)</cell><cell>9.8%(INT), 3.7%(FP)</cell></row><row><cell>over baseline AGE</cell><cell>AGE (150 entries)</cell><cell>-0.6%(INT), -0.1%(FP)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Pipelining these operations was studied in[7,  </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p><ref type="bibr" target="#b23">27]</ref> and is discussed in Section 5.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>SWQUE: SWITCHING ISSUE QUEUEIn this section, we propose the switching issue queue (SWQUE). SWQUE configures the IQ as the priority-correcting CIRC (CIRC-PC) or AGE depending on the degree of capacity demand. We first explain CIRC-PC in Section 3.1. Then we explain the switching scheme in Section 3.2.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>The author thanks the anonymous reviewers for their useful comments. This work was supported by the <rs type="funder">VLSI Design and Education Center (VDEC)</rs>, the <rs type="funder">University of Tokyo</rs> in collaboration with <rs type="funder">Synopsys Inc.</rs></p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Power-and Complexity-Aware Issue Queue Designs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Abella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Canal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gonzalez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<date type="published" when="2003-09">2003. September-October 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Performance Improvement by Prioritizing the Issue of the Instructions in Unconfident Branch Slices</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 51st Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="82" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hierarchical Scheduling Windows</title>
		<author>
			<persName><forename type="first">E</forename><surname>Brekelbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rupley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 35th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="27" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Select-Free Instruction Scheduling Logic</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 34th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="204" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An Investigation of the Performance of Various Dynamic Scheduling Techniques</title>
		<author>
			<persName><forename type="first">M</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 25th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Issue Logic for a 600-MHz Out-of-Order Execution Microprocessor</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="707" to="712" />
			<date type="published" when="1998-05">1998. May 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Focusing Processor Policies via Critical-Path Prediction</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fields</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bod?k</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual International Symposium on Computer Architecture</title>
		<meeting>the 28th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="74" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">40-Entry Unified Out-of-Order Scheduler and Integer Execution Unit for the AMD Bulldozer x86-64 Core</title>
		<author>
			<persName><forename type="first">M</forename><surname>Golden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arekapudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Solid-State Circuits Conference</title>
		<imprint>
			<biblScope unit="page" from="80" to="82" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
	<note>Digest of Technical Papers</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Research on High-Speed Instruction Scheduling Logic for Outof-Order ILP Processor</title>
		<author>
			<persName><forename type="first">M</forename><surname>Goshima</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>Ph.D. Dissertation. Kyoto University</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A High-Speed Dynamic Instruction Scheduling Scheme for Superscalar Processors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Goshima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nishino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kitamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nakashima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tomita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 34th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="225" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A 4.1-ns Compact 54 ? 54-b Multiplier Utilizing Sign-Select Booth Encoders</title>
		<author>
			<persName><forename type="first">G</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ohe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kashiwakura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mitarai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tsuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Izawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1676" to="1682" />
			<date type="published" when="1997-12">1997. December 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Circuits for Wide-Window Superscalar Processors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Kuszmaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Loh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual International Symposium on Computer Architecture</title>
		<meeting>the 27th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="236" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<ptr target="http://www.itrs2.net/)" />
		<title level="m">International Technology Roadmap for Semiconductors</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">MLP-Aware Dynamic Instruction Window Resizing for Adaptively Exploiting Both ILP and MLP</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 46th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A Family of 45nm IA Processors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Solid-State Circuits Conference</title>
		<imprint>
			<biblScope unit="page" from="58" to="59" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
	<note>Digest of Technical Papers</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">McPAT: An Integrated Power, Area, and Timing Modeling Framework for Multicore and Manycore Architectures</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Strong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 42nd Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="469" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Quantifying the Complexity of Superscalar Processors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Palacharla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<idno>CS-TR-1996-1328</idno>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin-Madison</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Complexity-Effective Superscalar Processors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Palacharla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual International Symposium on Computer Architecture</title>
		<meeting>the 24th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="206" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Design of an 8-wide Superscalar RISC Microprocessor with Simultaneous Multithreading</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Preston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Badeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Biro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Bowhill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Dever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Felix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gammack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Germini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Gowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gronowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Morton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Pickholtz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Reilly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Solid-State Circuits Conference</title>
		<imprint>
			<biblScope unit="page" from="334" to="472" />
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
	<note>Digest of Technical Papers</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Rearranging Random Issue Queue with High IPC and Short Delay</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Suenaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shioya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th IEEE International Conference on Computer Design</title>
		<meeting>the 36th IEEE International Conference on Computer Design</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="123" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Matrix Scheduler Reloaded</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Sassone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rupley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brekelbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Loh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th Annual International Symposium on Computer Architecture</title>
		<meeting>the 34th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="335" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Design and Implementation of an Embedded 512-KB Level-2 Cache Subsystem</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Petrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Leon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1815" to="1820" />
			<date type="published" when="2005-09">2005. September 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">IBM POWER8 Processor Core Microarchitecture</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sinharoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Van Norstrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Eickemeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leenstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Konigsburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Levitan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hrusecky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gschwind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boersma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kroener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kaltenbacha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Karkhanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Fernsler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="2015-01">2015. January -February 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On Pipelining Dynamic Instruction Scheduling Logic</title>
		<author>
			<persName><forename type="first">J</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 33rd Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The Free Lunch Is Over: A Fundamental Turn Toward Concurrency in Software</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dr. Dobb&apos;s Journal</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="202" to="210" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H E</forename><surname>Weste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Harris</surname></persName>
		</author>
		<title level="m">CMOS VLSI Design: A Circuits and Systems Perspective</title>
		<imprint>
			<publisher>Addition Wesley</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>fourth edition</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Evaluation of Issue Queue Delay: Banking Tag RAM and Identifying Correct Critical Path</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Computer Design</title>
		<meeting>the 29th International Conference on Computer Design</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="313" to="319" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
