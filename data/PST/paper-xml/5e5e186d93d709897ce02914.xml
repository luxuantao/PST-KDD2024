<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evaluation on Neural Network Models for Video-Based Stress Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Alvin</forename><surname>Kennardi</surname></persName>
							<email>alvin.kennardi@anu.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">Research School of Computer Science</orgName>
								<orgName type="institution">Australian National University</orgName>
								<address>
									<settlement>Canberra</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jo</forename><surname>Plested</surname></persName>
							<email>jo.plested@anu.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">Research School of Computer Science</orgName>
								<orgName type="institution">Australian National University</orgName>
								<address>
									<settlement>Canberra</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Evaluation on Neural Network Models for Video-Based Stress Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1007/978-3-030-36802-9_47</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Feature selection</term>
					<term>Long Short-Term Memory</term>
					<term>Stress recognition</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We examined neural network models to perform video-based stress recognition using ANUStressDB data set <ref type="bibr" target="#b5">[6]</ref>. Recent works on video-based stress recognition <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11]</ref> requires feature engineering process, which is time consuming and expensive. The neural network (NN) model aims to reduce this process. In this work, we set a baseline Feed-Forward Neural Network (FFNN) and extended the model using Feature Selection Technique, namely magnitude measure technique [3] and -1 regularisation <ref type="bibr" target="#b8">[9]</ref>. Subsequently, we performed extensive evaluation between those models with the Long Short-Term Memory (LSTM) [5] model, which are designed to store state information for time-series data. We show that feature selection technique model used significantly less parameters compare to the LSTM model with the expense of small accuracy loss. We also show that the NN models performed well in video-based stress recognition task as compare to the previous work with hand-crafted feature engineering from experts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper examines several models to perform video-based stress recognition task. These include, the Feed-Forward Neural Network (FFNN) and recurrent neural network with Long Short-Term Memory (LSTM). Recent researches on video-based stress recognition system incorporates feature engineering process before making a prediction <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11]</ref>. However, this process is expensive and timeconsuming. In our work, we compared methods to improve neural network models for video-based stress recognition task to reduce the feature engineering process. We set the feed-forward neural network (FFNN) as our baseline model. We extended this model with feature selection techniques to enhance the performance. The magnitude measure technique <ref type="bibr" target="#b2">[3]</ref> uses the absolute value of weights from a fully trained network to measure the contribution of input features towards output values. The -1 norm regularisation technique <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8]</ref> is an embedded feature selection technique used to bring weight of irrelevant inputs to 0, hence remove them from the model during training <ref type="bibr" target="#b8">[9]</ref>. Finally, we compared improved NN models with a recurrent neural network model with LSTM <ref type="bibr" target="#b4">[5]</ref> to perform video-based stress recognition task. The LSTM model worked well with time-series data set with additional parameters to store information from the previous state.</p><p>In this work, we trained and evaluated NN models with ANUStressDB [6] data set. The data set consists of statistical summary from video sample of 24 different subjects. To the best of our knowledge, extensive comparison between reduced FFNN models with the LSTM, which are designed for time-series data, has never been proposed for this data set. Our work makes two main contributions as follows:</p><p>-We evaluated the feature selection techniques, namely magnitude measure technique and -1 norm regularisation to reduce the number of parameters in FFNN. These models used significantly less parameters compare to the LSTM model with the expense of small accuracy loss. -All the models performed well in video-based stress recognition task as compare to the model from previous work which requires hand-crafted feature engineering from the experts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>Method section describes the data set, the models used in this experiment, and also the evaluation method used to measure the model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Set</head><p>The ANUStressDB data set <ref type="bibr" target="#b5">[6]</ref> consists of video samples from 24 subjects. Each video has a duration of 32 min 17 s, divided into 58110 samples (30 samples for 1 s). Each sample has 34 statistical summary features derived from the sample frames. The video has 12 clip partitions with two labels, namely stressful and not stressful. The proposed models were used to classify clip partitions into those classes. The experiment used two snippets from each class, stressful and not stressful. For every snippet, we used the samples from 20 s after snippet started until 30 s after snippet started to ensure the subjects has developed the emotion (i.e. stressful or not stressful) and reflected on the reading. For feed-forward neural network model, we considered each frame to be one data point, and for the LSTM model, the sequence consists of 15 samples or 0.5 s. For each feature, the data was standardised into zero-mean and unit-variance. We split the data set based on the snippet with 70% training set and 30% test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Feed-Forward Neural Network Model</head><p>Our baseline model is a feed-forward neural network with one hidden layer. The model takes an input with 34 features, denotes as x ? R 34 . A weight matrix W ih ? R 7?34 transforms input vector into a vector with 7-dimension. Finally, ReLU activation function <ref type="bibr" target="#b3">[4]</ref> is applied to this 7-dimensional vector producing hidden vector, denotes as h ? R 7 . The mapping between an input vector to a hidden unit, follows the equation below.</p><formula xml:id="formula_0">h = ReLU (W ih x)<label>(1)</label></formula><p>A weight matrix W ho transforms hidden vector h into output vector y ? R 2 . Two dimension output vector represent two classes in the data set, namely stressful and not stressful. The softmax layer then takes two-dimension output vector, y into output decision label Y ? {0, 1} represent two classes, 0 for stressful and 1 for not stressful. Thus the decision from softmax layer follows equation below.</p><formula xml:id="formula_1">Y = softmax(W ho h)<label>(2)</label></formula><p>The error function used in the model is cross-entropy error function. The model was trained using error back-propagation <ref type="bibr" target="#b1">[2]</ref> and optimised using Stochastic Gradient Descent (SGD) with momentum <ref type="bibr" target="#b9">[10]</ref> with learning rate 0.1, and momentum term 0.9. The model hyper-parameters were cross-validated on the training set. We trained the baseline model over 5000 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Feature Selection Techniques for Neural Network</head><p>Feature selection techniques aim to enhance the performance of feed-forward neural network by reducing the number of input features. We presented two techniques to reduce the number of features, namely filter method (magnitude measure) <ref type="bibr" target="#b2">[3]</ref> and embedded method ( -1 norm regularisation) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8]</ref>.</p><p>Magnitude Measure Technique. The magnitude measure technique takes into account contribution of absolute weight values that connects a hidden neuron j in the hidden layer into an output neuron k in the output layer <ref type="bibr" target="#b2">[3]</ref>. The following equation measures the contribution from an input feature neuron i to a hidden neuron j with input vector dimension din = 34.</p><formula xml:id="formula_2">P ij = |w ij | din p=1 |w pj | (3)</formula><p>The contribution from a hidden layer j with dimension dhid = 7 to an output neuron k is measured by following equation.</p><formula xml:id="formula_3">P jk = |w jk | dhid r=1 |w rk | (4)</formula><p>The total contribution from an input feature neuron i to an output neuron k, with hidden layer dimension dhid = 7 follows the equation below.</p><formula xml:id="formula_4">Q ik = dhid r=1 (P ir ? P rk )<label>(5)</label></formula><p>We computed the Q-values for all input features in fully-trained neural network based for the data set described in Sect. 2.1, and removed two features with the lowest Q-values as suggested by <ref type="bibr" target="#b2">[3]</ref> to produce more consistent results. The network was re-trained using reduced features. We trained the reduced model over 5000 epochs.</p><p>-1 Norm Regularisation. Regularisation technique is a technique to introduce additional error measure to the loss function by penalizing parameters with a big value, hence discouraging the model from over-fitting regularisation using -1 norm discourages parameters with high sum of absolute values of the parameters <ref type="bibr" target="#b8">[9]</ref>, thus creating a sparse weight (parameter) matrix solution. The capabilities of -1 norm to create this sparse solution hence bring some parameters to zero makes this technique a good candidate for feature selection. <ref type="bibr" target="#b8">[9]</ref>. We applied -1 penalty term using following equation.</p><formula xml:id="formula_5">error 1 = ? dhid i=0 din j=0 ||w i,j || 1<label>(6)</label></formula><p>The hyper-parameter ? is used to control how strong the penalty applied. This error term is added in the back-propagation error function, i.e., cross entropy error. By adding -1 penalty function to the hidden layer output defined in Eq. 1, we reduced the weight parameters from W ih into 0 and hence, removed input features contribution with 0 weight value to the hidden unit. We trained the -1 regularised model with SGD with momentum with learning rate 0.1 and momentum term 0.9. We set ? = 0.0005 and trained the model over 4500 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Long Short-Term Memory (LSTM) Model</head><p>Long Short-Term Memory (LSTM) aims to retain the information from timeseries inputs by connecting the output of previous state as the input for the next state. The LSTM layers were added in front of the neural network described in Sect. 2.2. The input patterns were presented to the model in sequence of 15 samples (i.e. 0.5 s).</p><p>After sequences presented to the LSTM cell (t = 14), the LSTM cell passed feature representation h to the fully-connected layers. The fully-connected layers performed down-sampling of the hidden vector h ? R 34 to R 2 as described in Sect. 2.2. The parameters in the LSTM cells were trained using Back-Propagation Through Time (BPTT). We trained our LSTM model using SGD with momentum with learning rate 0.01 and momentum terms 0.9. We trained the model over 1500 epochs. In order to stabilise the model performance, the model uses several modification from original fully-connected layers. Instead of ReLU activation function, the model uses LeakyReLU <ref type="bibr" target="#b6">[7]</ref> with negative slope 0.1 to avoid dying ReLU problem due to zero gradient during back-propagation. To address overfitting on the model, dropout layers <ref type="bibr" target="#b11">[12]</ref> are used in the LSTM layer (p = 0.1) and both hidden layers (p = 0.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Result and Discussion</head><p>Evaluation on the model described in Sect. 2 was done by an accuracy measure metric. We used vanilla feed-forward neural network model as the baseline model. Three models using magnitude measure, -1 norm and LSTM were evaluated against the baseline. Each model is trained using training set and evaluated using the test set five times using five different random seeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Improving Feed-Forward Neural Network with Magnitude Measure Technique</head><p>Magnitude measure aims to remove less informative features from the model with the intention to improve the performance of the model. Table <ref type="table" target="#tab_0">1</ref> summarises input removal result based on weights contribution measured using Eq. 5. We used the weights from the baseline model to measure the contribution from the features to the decision function. After computing the score using Eq. 5, we removed two least relevant features according to magnitude measure. We re-trained the network using 32 features to obtain reduced network model and performed an evaluation on this model. Table <ref type="table" target="#tab_0">1</ref> shows that using this method we obtained better results, with the exception of second random seed evaluation. The reduced models improved the performance especially when the baseline models did not have a good accuracy (i.e. less than or equal to 80% in this task). Table <ref type="table" target="#tab_0">1</ref> also shows that feature ID 14 always appears in different random seed setting, indicating that this feature was irrelevant for the task, based on magnitude measure algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Improving Feed-Forward Neural Network with -1 Norm Regularisation</head><p>The -1 norm regularisation method aims to improve the model's performance by selecting which features are relevant for the task during training time. Table <ref type="table" target="#tab_1">2</ref> summarises the evaluation on regularised model against the baseline model. Table <ref type="table" target="#tab_1">2</ref> shows the comparison between baseline model and regularised network model. Similar to the result in Sect. 3.1, the regularised model performed better, except for the second evaluation. The regularised models improved the performance especially when the baseline models did not have a good accuracy (i.e. less than or equal to 80% in this task). Figure <ref type="figure" target="#fig_0">1</ref> shows an example of how introducing -1 norm loss terms in the loss function forces some weights between inputs and hidden units to be 0. By forcing the weight into 0 during training, the model selects which features are relevant to the decision making in the hidden neuron and which ones are not. In the Fig. <ref type="figure" target="#fig_0">1</ref> input features ID 17 to 33 are not used by 1st hidden neuron to makes decisions. This may be related to the facts that input features with ID from 17 to 33 has low variance in the data set. Similarly, some feature weights connecting input feature to other hidden units are also 0, indicating that the features have less important information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Performance Evaluation</head><p>The Table <ref type="table" target="#tab_2">3</ref> summarises accuracy measurements from four models, namely the baseline, reduced network from magnitude measure, -1 regularised model and the LSTM model. The Table <ref type="table" target="#tab_2">3</ref> shows that on average feature selection techniques improve the baseline model by around 3 to 4%. While there were cases in which reducing features impair the performance of the model, on average, the feature selection enhanced model performance. The LSTM model produced a significant improvement due to its capability to retain the information from previous input state. The LSTM model improved the accuracy by around 10% from the baseline models. From the experiment, we concluded that LSTM is the right model for a time-series data set.</p><p>The LSTM has much more trainable parameters as compare to the feedforward neural network. The LSTM model described in this paper has 9781 trainable parameters as compared to 252 trainable parameters of the baseline model. The more trainable parameters mean the more training samples and computational resources needed to train the model. The LSTM is a data-hungry model and it may not be suitable for smaller data sets. As alternatives, we can use the FFNN model with feature selection technique, which has much less parameters with the expense of around 6-7% accuracy loss</p><p>The methods described in this paper are neural-based model. The paper in <ref type="bibr" target="#b5">[6]</ref> used Support Vector Machine (SVM) based model to perform the task and obtain reported accuracy of 89%. The SVM model requires feature engineering to perform prediction hence it works well. The neural-based model aims to reduce the feature engineering process since this process is expensive. In this paper, we have shown that neural-based models are competitive. They are less time consuming and therefore more cost effective then other models for video-based stress recognition task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Recommendation</head><p>In this paper, we performed extensive evaluation on the FFNN models with feature selection techniques and compare them with the LSTM model. The FFNN with feature selection techniques use much less parameters compare to the LSTM model with the expense off small accuracy loss. Our experimental results show that the NN models performed well for video-based stress recognition task, while reducing the needs of feature engineering process.</p><p>In the future, it would be interesting to use Convolutional Neural Network (CNN) to extract feature from each clip before we used RNN layer to process the video sequence. The other research direction would be to address the needs of huge training set to optimise the LSTM model using a transfer learning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Weight values that connect input features to 1st hidden unit. Several weights from input to 1st hidden unit are 0 due to -1 norm regularisation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Evaluation on the improved model using magnitude measure feature selection technique. The evaluation was done using five different random seed. The column feature pair id lists the feature ids that were removed by magnitude measure technique</figDesc><table><row><cell cols="4">Evaluation Baseline accuracy (%) Reduced network accuracy (%) Feature pair id</cell></row><row><cell>1</cell><cell>73.00</cell><cell>85.02</cell><cell>14 and 29</cell></row><row><cell>2</cell><cell>83.17</cell><cell>80.43</cell><cell>14 and 17</cell></row><row><cell>3</cell><cell>77.44</cell><cell>82.65</cell><cell>14 and 26</cell></row><row><cell>4</cell><cell>78.91</cell><cell>81.75</cell><cell>14 and 21</cell></row><row><cell>5</cell><cell>80.00</cell><cell>82.75</cell><cell>14 and 20</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Evaluation on the improved model using -1 norm technique. The evaluation was done using five different random seeds.</figDesc><table><row><cell cols="3">Evaluation Baseline accuracy (%) Regularised network accuracy (%)</cell></row><row><cell>1</cell><cell>73.00</cell><cell>84.33</cell></row><row><cell>2</cell><cell>83.17</cell><cell>82.26</cell></row><row><cell>3</cell><cell>77.44</cell><cell>78.58</cell></row><row><cell>4</cell><cell>78.91</cell><cell>82.43</cell></row><row><cell>5</cell><cell>80.00</cell><cell>81.67</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Accuracy Measurement on the baseline model, reduced network from magnitude measure, -1 regularised model and the LSTM model.</figDesc><table><row><cell>Model</cell><cell cols="6">1st Evaluation 2nd Evaluation 3rd Evaluation 4th Evaluation 5th Evaluation Average</cell></row><row><cell>Baseline</cell><cell>73.00</cell><cell>83.17</cell><cell>77.44</cell><cell>78.91</cell><cell>80.00</cell><cell>78.50</cell></row><row><cell cols="2">Magnitude measure 85.02</cell><cell>80.43</cell><cell>82.65</cell><cell>81.75</cell><cell>82.75</cell><cell>82.52</cell></row><row><cell>-1 norm</cell><cell>84.33</cell><cell>82.26</cell><cell>78.58</cell><cell>82.43</cell><cell>81.67</cell><cell>81.85</cell></row><row><cell>LSTM</cell><cell>85.94</cell><cell>90.10</cell><cell>87.15</cell><cell>90.45</cell><cell>90.10</cell><cell>88.75</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A survey on feature selection methods</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chandrashekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sahin</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.compeleceng.2013.11.024</idno>
		<ptr target="https://doi.org/10.1016/j.compeleceng.2013.11.024" />
	</analytic>
	<monogr>
		<title level="j">Comput. Electr. Eng</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="16" to="28" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning representations by back propagating errors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.1038/323533a0</idno>
		<ptr target="https://doi.org/10.1038/323533a0" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="page" from="533" to="536" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Data mining of inputs: analysing magnitude and functional measures</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Gedeon</surname></persName>
		</author>
		<idno type="DOI">10.1142/S0129065797000227</idno>
		<ptr target="https://doi.org/10.1142/S0129065797000227" />
	</analytic>
	<monogr>
		<title level="j">Int. J. Neural Syst</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="209" to="218" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Deep sparse rectifier neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>AIS-TATS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
		<ptr target="https://doi.org/10.1162/neco.1997.9.8.1735" />
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Thermal superpixels for bimodal stress recognition</title>
		<author>
			<persName><forename type="first">R</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nasrollahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dhall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Moeslund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gedeon</surname></persName>
		</author>
		<idno type="DOI">10.1109/IPTA.2016.7821002</idno>
		<ptr target="https://doi.org/10.1109/IPTA.2016.7821002" />
	</analytic>
	<monogr>
		<title level="m">Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA)</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshop on Deep Learning for Audio, Speech and Language Processing</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Combined SVM-based feature selection and classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schn?rr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Steidl</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10994-005-1505-9</idno>
		<idno>10994-005-1505-9</idno>
		<ptr target="https://doi.org/10.1007/s" />
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="129" to="150" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Feature selection, L1 vs. L2 regularization, and rotational invariance</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<idno type="DOI">10.1145/1015330.1015435</idno>
		<ptr target="https://doi.org/10.1145/1015330.1015435" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-First International Conference on Machine Learning, ICML 2004</title>
		<meeting>the Twenty-First International Conference on Machine Learning, ICML 2004<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">78</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On the momentum term in gradient descent learning algorithms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Qian</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0893-6080(98)00116-6</idno>
		<ptr target="https://doi.org/10.1016/S0893-6080(98)00116-6" />
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="151" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Thermal spatio-temporal data for stress recognition</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dhall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gedeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Goecke</surname></persName>
		</author>
		<idno type="DOI">10.1186/1687-5281-2014-28</idno>
		<ptr target="https://doi.org/10.1186/1687-5281-2014-28" />
	</analytic>
	<monogr>
		<title level="j">EURASIP J. Image Video Process</title>
		<imprint>
			<biblScope unit="volume">2014</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">28</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2627435.2670313" />
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
