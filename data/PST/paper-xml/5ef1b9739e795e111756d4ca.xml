<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Profiling Web users using big data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-03-22">22 March 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiaotao</forename><surname>Gu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hong</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
							<email>zhang-jing@ruc.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Renmin University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fanjin</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Debing</forename><surname>Liu</surname></persName>
							<email>debingliu@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wendy</forename><surname>Hall</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Huawei Technologies Co. Ltd</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiao</forename><surname>Fu</surname></persName>
							<email>xiao.fu@huawei.com</email>
							<affiliation key="aff3">
								<orgName type="department">Electronics and Computer Science</orgName>
								<orgName type="institution">University of Southampton</orgName>
								<address>
									<settlement>Southampton</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Profiling Web users using big data</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-03-22">22 March 2018</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1007/s13278-018-0495-0</idno>
					<note type="submission">Received: 16 January 2017 / Accepted: 16 February 2018 /</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information extraction</term>
					<term>Factor graph model</term>
					<term>User profiling</term>
					<term>Big data</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Profiling Web users is a fundamental issue for Web mining and social network analysis. Its basic tasks include extracting basic information, mining user preferences, and inferring user demographics (Tang et al. in ACM Trans Knowl Discov Data 5(1):2:1-2:44, 2010). Although methodologies for handling the three tasks are different, they all usually contain two stages: first identify relevant pages (data) of a user and then use machine learning models (e.g., SVM, CRFs, or DL) to extract/mine/ infer profile attributes from each page. The methods were successful in the traditional Web, but are facing more and more challenges with the rapid evolution of the Web each persons information is distributed over the Web and is changing dynamically. As a result, available data for a user on the Web is redundant, and some sources may be out-of-date or incorrect. The traditional two-stage method suffers from data inconsistency and error propagation between the two stages. In this paper, we revisit the problem of Web user profiling in the big data era and propose a simple but very effective approach, referred to as MagicFG, for profiling Web users by leveraging the power of big data. To avoid error propagation, the approach processes all the extracting/mining/inferring subtasks in one unified framework. To improve the profiling performance, we present the concept of contextual credibility. The proposed framework also supports the incorporation of human knowledge. It defines human knowledge as Markov logics statements and formalizes them into a factor graph model. The MagicFG method has been deployed in an online system AMiner.org for profiling millions of researchers-e.g., extracting E-mail, inferring Gender, and mining research interests. Our empirical study in the real system shows that the proposed method offers significantly improved (+ 4-6%; p â‰ª 0.01 , t test) profiling performance in comparison with several baseline methods using rules, clas- sification, and sequential labeling.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Web user profiling involves building a semantics-based user profile (consisting of contact information, educational history, demographics, and preferences/interests, etc.) from the Xiaotao Gu and Hong Yang have contributed equally to this work.</p><p>unstructured Web. It is a fundamental issue for understanding user behavior on the Web, and has long been viewed as an important and challenging problem in Web mining and social network analysis. The constructed user profiles can be applied to many applications, and the extraction process has become a necessary part of most online systems. For example, in a recommender system, with a large and highquality profile database, we can make accurate recommendations to a user on what kind of information she/he would be interested in. In e-commerce, user profiles are extremely important for locating customers for a new product.</p><p>The basic tasks for profiling Web users include extracting basic information, mining user preferences, and inferring user demographics <ref type="bibr">(Tang et al. 2010</ref>). As the Web may have various unstructured pages to introduce a user, the goal of extracting basic information is to extract structured profile attributes from the unstructured pages <ref type="bibr" target="#b2">(Banko et al. 2007;</ref><ref type="bibr">Tang et al. 2007;</ref><ref type="bibr">Weninger et al. 2010;</ref><ref type="bibr">Wu et al. 2015)</ref>. To understand user behavior, one common situation is that a system has collected a lot of user behavioral data for mining users' preferences/interests <ref type="bibr">(Brajnik et al. 1987;</ref><ref type="bibr">Ikeda et al. 2013;</ref><ref type="bibr">Li et al. 2014;</ref><ref type="bibr">Pazzani and Billsus 1997;</ref><ref type="bibr">Soltysiak and Crabtree 1998;</ref><ref type="bibr">Wu et al. 2016)</ref>. Demographics play an important role in revealing the reasons behind users' behavior and recently have attracted a lot of attention from both academic and industrial communities <ref type="bibr">(Sarraute et al. 2015;</ref><ref type="bibr">Dong et al. 2014;</ref><ref type="bibr">Krulwich 1997)</ref>. The three tasks were usually studied and many different methods have been proposed to deal with each of them, separately.</p><p>Despite slight differences, the general process of the different methods consists of two stages: first, identify relevant user pages (information), and then use machine learning models (e.g., SVM, CRFs, or DL) to extract/mine/infer profile attributes from the page. However, such two-stage methods suffer from data inconsistency and error propagation between the two stages. The problem of data inconsistency has become more and more critical due to the rapid evolution of the Web. As a result, a given persons information may be distributed on the Web and changing dynamically. The error propagation problem is due to the two stages of the methods; an error in the first stage will be propagated to the second stage. Figure <ref type="figure" target="#fig_0">1</ref> gives an example of building a researcher ("Jiawei Han") profile from the Web. A usual approach is to first find relevant Web pages such as homepage of Dr. Jiawei Han's homepage from the Web, and then use machine learning models (e.g., CRFs) to extract profile attributes from the pages. State-of-the-art accuracy achieved in the two stages is around 90.0%, respectively. For example, an F1 score of 92% is reported for the task of homepage finding conducted by <ref type="bibr">Tang et al. (2008)</ref>, and 87% for extracting the profile attributes from the homepage <ref type="bibr">(Tang et al. 2010</ref>). However, taking error propagation into consideration, the overall accuracy of the approach that combines the two stages drops to 80%. More seriously, with the rapid growth of the Web, the problem becomes even more critical, as the big Web contains much more noisy data.</p><p>In this paper, we conduct a systematic study to revisit this problem from the perspective of big data. The essential question we want to answer is whether and how we can avoid error propagation by leveraging the power of big data. This is very challenging and raises a set of unique challenges.</p><p>â€¢ First, to avoid error propagation, we need to combine the two stages in traditional methods into one step. It is unclear how to develop a unified approach framework for processing all the profiling tasks together in one step. â€¢ Second, though the data volume in the big Web is huge, it is unclear how to leverage its power wisely. The approach of first collecting all Web data and then processing it offline is obviously infeasible. â€¢ Last, how to incorporate human knowledge into the profiling procedure. Numerous studies <ref type="bibr">(Finkel et al. 2005;</ref><ref type="bibr">Tang et al. 2013)</ref> have shown that human knowledge can play a very important role in information extraction and also other data mining tasks. It would be very helpful if the profiling approach were flexible enough to incorporate human prior knowledge.</p><p>The technical contribution of this work lies in the proposal of a novel approach framework, referred to as MagicFG, for profiling Web users. MagicFG offers a simple but very effective way to process all the profiling subtasks together, by leveraging the power of big Web data. One key idea here is that we do not collect original data from the Web. Instead we use a search engine to retrieve important snippets. For each retrieved snippet, we design contextual features to model its credibility. To further incorporate human knowledge, Mag-icFG provides a mechanism of formalizing human knowledge as Markov logics into a factor graph.</p><p>The MagicFG method has already been deployed in an online system AMiner.org,<ref type="foot" target="#foot_0">1</ref> for profiling millions of researchers-e.g., extracting E-mail, inferring Gender, and mining research interests. Our empirical study in the real system shows that the proposed method significantly improves (+ 4-6%; p â‰ª 0.01 , t test) the profiling perfor- mance in comparison with several state-of-the-art methods using rules, classification, and sequential labeling (Cf. Sect. 4 for detailed comparisons). Figure <ref type="figure" target="#fig_1">2</ref> shows an example. We can see that our approach significantly outperforms the comparison methods for the tasks of E-mail extraction and Gender inference.</p><p>Besides directly integrating the profiling function into the AMiner system, we also developed and deployed a separate Web application for scholar Gender prediction based on the proposed MagicFG model. Figure <ref type="figure" target="#fig_1">2c</ref> shows a screenshot of the scholar Gender prediction system. The system trains a MagicFG model off-line using existing labeled data in our dataset. When a user inputs a scholar name with her/his affiliation, the system calls three analyzers face analyzer, Google analyzer, and name analyzer and finally make prediction based on their weighted votes.</p><p>Organization In Sect. 2, we review the related work. In Sect. 3, we describe the proposed approach to user profiling. In Sect. 4, we present experimental results to evaluate the effectiveness of the proposed approach. Finally, Sect. 5 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>As a key component in Web mining and social network analysis, the problem of profiling Web users has attracted considerable attention from both industry and academia. For example, E-mail Breaker,<ref type="foot" target="#foot_2">2</ref> E-mail Hunter,<ref type="foot" target="#foot_3">3</ref> and Sidekick<ref type="foot" target="#foot_4">4</ref> are three online services offering services to find E-mail addresses of requested people from the Web. Gender API<ref type="foot" target="#foot_5">5</ref> and Genderize<ref type="foot" target="#foot_6">6</ref> are two online APIs offering services to determine the Gender of a name. In this section, we review related scientific literature on the three profiling tasks: profile extraction, demographics inference, and user preference mining.  <ref type="bibr">et al. 2004</ref>). See also <ref type="bibr">Balog et al. (2006)</ref>. However, this thread of research is limited by the input documents and the proposed method is more or less ad hoc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Profile extraction</head><p>Recently, more and more attention has been paid to extracting profiles from the generic Web. For instance, <ref type="bibr">Michelson and Knoblock (2007)</ref> propose a unsupervised method to extract information from the Web. Tang et al. ( <ref type="formula">2010</ref>) employ a classification model to identify relevant pages for Web users and then use Tree-structured Conditional Random Fields (TCRF) <ref type="bibr">(Tang et al. 2006)</ref> to tag tokens in profile pages and extract profile information. <ref type="bibr">Weninger and Han (2013)</ref> viewed the Web as a massive and decentralized database and propose a method called CETR to improve information extraction with the Web. Several other similar studies can be also found in <ref type="bibr" target="#b2">Banko et al. (2007)</ref> and <ref type="bibr">Ritze et al. (2016)</ref>. Despite slight differences, the general process of the different methods consists of two stages: first identify relevant pages (information) of a user and then use machine learning models (e.g., SVM, CRFs, or DL) to extract/mine/infer profile attributes from the page. However, most of aforementioned methods perform the extraction in two stages, and thus suffer from error propagation between the two stages.</p><p>Regarding the extraction models, many have been proposed in the past 30 years. Hidden Markov Model (HMM) <ref type="bibr">(Ghahramani and Jordan 1997)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Demographics inference</head><p>User demographics offer the potential to better understand user behavior and the interactions between users. However, in practice, the available demographic information in many online systems is very limited. There are several works attempting to inferring user demographics automatically, for example, based on their online browsing <ref type="bibr">(Hu et al. 2007)</ref>, gaming (Szell and Thurner 2012) and search <ref type="bibr" target="#b4">(Bi et al. 2013)</ref> behaviors. In social network analysis, several efforts have been also made to infer Age <ref type="bibr">(Sarraute et al. 2015)</ref>, location <ref type="bibr">(Li et al. 2012;</ref><ref type="bibr">Efstathiades et al. 2016</ref><ref type="bibr">), and identity (Joseph et al. 2016</ref><ref type="bibr">). Dong et al. (2014)</ref> propose employing a factor graph model to simultaneously predict Age and Gender based on user communication patterns in mobile networks. However, all these works study the demographics inference problem on a specific dataset.</p><p>A few other studies aiming to improve the inference accuracy of demographics using multiple sources. For example, <ref type="bibr">Li et al. (2012</ref><ref type="bibr">, 2014</ref><ref type="bibr">), and Ikeda et al. (2013)</ref> use Facebook, Google Plus, and Twitter to improve the accuracy of demographics inference. Compared to these works, the problem studied in this work is more open-we attempt to infer user demographics using only person name and the potential information from the Web. In terms of this, the most similar work is Tang et al. <ref type="bibr">(2011)</ref>, which presents a name-centric approach to make Gender inference. Their idea is to create a comprehensive and contemporary name list from Facebook, and then use the name list to help improve Gender inference performance. Another similar research can be also found in <ref type="bibr">Eltaher and Lee (2015)</ref>. The proposed approach in this work does not heavily reply on the quality of a name list. It combines all the available information from the big Web and achieves a much better inference performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">User preference mining</head><p>The other type of research is to learn user preference from user behavioral data (e.g., behavioral logs) or user-associated documents. For example, Pazzani and Billsus (1997) propose algorithms for learning user profiles and use the profile to determine whether a user would be interested in World Wide Web sites on a specific topic. Chan (1999) has developed a personalized Web browser. It learns a user profile, and aims at helping users navigating the Web by searching for potentially interesting pages for recommendations. Soltysiak and Crabtree (1998) describes an experimental work to study whether user interests can be automatically classified through heuristics. More recently, <ref type="bibr">Makazhanov et al. (2014)</ref> propose a method to predict user interests from Twitter data. <ref type="bibr">Figueiredo et al. (2016)</ref> aim to mine user preferences from the trajectory data. <ref type="bibr">Wu et al. (2016)</ref> jointly model users' temporal behaviors that indicate their preferences and social links in a probabilistic approach. Our proposed approach can be applied to not only user preference mining, but also the other tasks (profile extraction and demographics inference) for Web user profiling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Data redundancy</head><p>Data redundancy is another relevant research area relevant to this work. The correlation between data redundancy and the probability of correctness in information extraction has been studied in <ref type="bibr">Downey et al. (2005)</ref>. Later, <ref type="bibr">Pedro et al. (2011)</ref> analyzed the dependencies between overlapping or duplicated content in videos and propose a novel tag propagation method for automatically obtaining richer video annotations. <ref type="bibr" target="#b5">Blanco et al. (2010)</ref> exploit the data redundancy to automatically extract and integrate data from the Web and validate the feasibility and effectiveness of this approach. In general, most existing works on data redundancy try to remove the redundant information. In this work, we attempt to utilize data redundancy to support Web user profiling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach framework</head><p>In this section, we first give the basic idea of the proposed framework to solve the profiling problem. In particular, we focus on how to profile researchers on the Web. We introduce three methods to extract profile attributes from the Web.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Basic idea</head><p>Given a person v, referred to as a query person, our goal is to extract profile attributes of the person and construct a researcher profile. For example, in an academic search system, e.g., AMiner.org <ref type="bibr">(Tang et al. 2008)</ref>, the researcher profile consists of Position, picture, address, phone, E-mail, homepage, research interest, etc. A detailed definition can be found in <ref type="bibr">Tang et al. (2010)</ref>. Our goal is to design a general method to automatically extract the profile attributes from the Web with high accuracy. Meanwhile, the method should be also flexible enough to be extended to handle new profile attributes.</p><p>Traditional methods usually deal with the problem by first finding relevant Web pages for the query person from the Web, and then using models such as SVM or CRF to extract the required profile attributes from the pages. In both steps, the state-of-the-art performances achieved by traditional methods are around 90% <ref type="bibr">(Tang et al. 2010;</ref><ref type="bibr">Tang et al. 2008</ref>). However, the overall accuracy achieved when combining the two steps inevitably drops to 80%, due to error propagation between the steps. Meanwhile, the required profile attributes may be distributed over different Web pages, which results in two new problems how to perform extraction from distributed pages and how to perform extraction with data redundancy.</p><p>To tackle the problem of error propagation and data redundancy, we propose a unified framework to process all the extraction subtasks together from the big Web data. The approach is simple but very effective. Specifically, for each profile attribute, we first construct a "smart" query and use a search engine to retrieve relevant snippets with the query. Then an extraction model is applied to the returned snippets to extract the profile attributes. The idea behind is to leverage data redundancy to support the extraction. Suppose we are going to extract the affiliation of "Philip S. Yu." The constructed query can be "Philip S. Yu affiliation." Similarly, to extract the E-mail address of "Philip S. Yu," we can construct "Philip S. Yu E-mail." Figure <ref type="figure" target="#fig_3">3</ref> shows two example snippets returned by Google with two constructed queries. We see that we can easily identify two different affiliations: "University of Illinois at Chicago" and "IBM T. J. Watson Research Center" (after normalization) from Fig. <ref type="figure" target="#fig_3">3a</ref>, and two E-mail addresses: "psyu@cs.uic.edu" and "hanj[at]cs.uiuc. edu" from Fig. <ref type="figure" target="#fig_3">3b</ref>. We call the identified affiliations/E-mails from the snippets as candidate affiliations/E-mails. Now the problem becomes how to recognize which candidate is correct and which one is not. We formalize this problem as a ranking problem. Specifically, our idea here is to leverage the redundancy information-e.g., "University of Illinois It is noteworthy that we are not restricted to the two example attributes. The proposed method itself is in general flexible. To extract a new profile attribute, what we need to do is to construct the "smart" query and to train the MagicFG model. For some profile attributes, it is easy to construct the query. For example, we found that for E-mail, we can achieve a high accuracy by simply using name + E-mail. For some other profile attributes-for example, Gender and Position-the situation may be more complicated. We will introduce how we construct a smart query for general profile attributes in Sect. 3.2. Please also note that there are generally two types of profile attributes: categorical attributes and non-categorical attributes. For example, Gender is a categorical attribute. Position is also a categorical attribute with multiple values, such as professor, student, researcher, and engineer, while E-mail and Age are non-categorical attributes.</p><p>The two different types of attributes will be treated slightly differently in the proposed framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Smart query construction</head><p>For categorical attributes, we construct the query by automatically identifying representative keywords in each candidate category and combining them together to form a query. To find the representative keywords for each category, we first collect a number of person names (e.g., 1000) for each category from professional websites such as AMiner and LinkedIn. We then submit the corresponding person names as queries to search engines like Google to obtain top k (e.g., 10) snippets. Among all the words in the snippets, we identify the most representative keyword as that with the highest TF-IDF scores (Baeza-Yates and Ribeiro-Neto 1999). The TF-IDF score of a word w in a category c is calculated as follows:</p><p>where S c denotes the snippets that belongs to category c. Notation n(S c , w) denotes the number of snippets in category c that contains the word w. Notation n(S, w) indicates the number of snippets in all the categories that contains the word w and |S| is the number of all the snippets in all the categories. Take Gender as an example. Using the above method, we found that the most representative keyword is "her" for females, and is "his" for males. The query is then constructed as "name his|her."</p><formula xml:id="formula_0">(1) TF-IDF(w, c) = (1 + log n(S c , w)) log 1 + |S| n(S, w)</formula><p>For a non-categorical attribute, we directly use the keywords in the attribute name to construct the query. For example, the query for E-mail extraction can be "name E-mail|mail."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Baseline models</head><p>We first introduce two baseline models for extracting the profile attributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Rule-based model</head><p>In the rule-based model, for extracting the E-mail of the query person v, we simply construct the query by combining the person name and the word "E-mail." After obtaining the returned snippets from a search engine (e.g., Google), we can use rule-based heuristics to extract the E-mail of the query person. Specifically, we first extract the candidate E-mail addresses from the searched snippets; if the first name or the last name of the query person is contained in the prefix of a candidate E-mail address, then the extracted E-mail will be selected as the result. To recognize the E-mail addresses, we define a regex pattern.<ref type="foot" target="#foot_7">7</ref> This is because in many Web pages, especially on some person's homepages, the E-mail addresses may be encoded in different ways such as "firstname [dot] lastname [at] cmu [dot] edu."</p><p>Our preliminary experiments show that such a simple method could result in an accuracy of 88%-comparable with the state-of-the-art performance obtained by a traditional two-step approach (Cf. Sect. 4 for detailed comparisons).</p><p>Limitations The rule-based method usually results in a high precision, but low recall. Moreover it cannot distinguish the importances of different patterns (rules).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Classification-based model</head><p>We can train a classification model to learn the weights of different rules/patterns, if we define more than one rule.</p><p>Let us first consider a two class classification problem. Let {(x 1 , y 1 ), â€¦ , (x N , y N )} be a training data set, in which x i denotes a feature vector of a candidate information packet and y i âˆˆ {âˆ’1, +1} denotes a classification label (whether the candidate is correct or not). The classification-based extraction model consists of two stages: learning and extraction. In learning, one attempts to find an optimal weight configuration to maximize the log-likelihood function of the observed instances). In extraction, we use the learned model to classify which candidate information is what we want to extract.</p><p>Regarding features in the classification model, we use the same attribute features as the attribute factors defined in our proposed model (Cf. Sect. 3.4 for details). In our experiments, we use logistic regression (LR) as the classification model. The classification can adjust the weights of different features (patterns) and combine the feature together, thus obtains a better performance (90% in terms of F1-score) than the rule-based method.</p><p>Limitations The classification-based method still does not consider the correlations between different candidates. As shown in Fig. <ref type="figure" target="#fig_3">3</ref>, the returned snippets usually contain redundant information that might be helpful for the extraction. Both the rule-based and the classification-based models consider each candidate independently, and thus cannot leverage such redundant information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Markov logic factor graph (MagicFG) model</head><p>In practice, the redundant information resided in the snippets can be very helpful for improving the extraction accuracy.</p><p>For example, in Fig. <ref type="figure" target="#fig_3">3b</ref>, for E-mail extraction, the same prefix "psyu" before "@" in the two candidate E-mail addresses, "psyu@cs.uic.edu" and "psyu@uic.edu," indicates that the two E-mail addresses belong to the same person.</p><p>To model and incorporate the redundancy-based correlation into a unified profiling model, we propose a Markov logic factor graph (MagicFG) model by formalizing the correlations as first-order logic statements. We now introduce how to model the data redundancy for the non-categorical and categorical attributes, respectively.</p><p>Modeling non-categorical attributes For each query person, we construct a factor graph model with each node representing a candidate instance, and each edge corresponding to a dependency between two candidates. We optimize the factor graph model for all query persons simultaneously. We explain the modeling process of categorical attributes using E-mail as an example. For query person v, we denote each candidate E-mail as e i . As the example in Fig. <ref type="figure" target="#fig_4">4</ref>, we could extract four candidates {e 1 , e 2 , e 3 , e 4 } . For each candidate E-mail, we create an instance (e i , v) and associate it with a 24 Page 8 of 17 latent variable y i . To model the correlations between candi- date instances, we construct a factor graph model as illustrated in Fig. <ref type="figure" target="#fig_4">4</ref>. The model is referred to as a Markov logic factor graph (MagicFG) model. In MagicFG, each correlation is represented as a first-order logic statement. The correlation can be prior knowledge or any other human-defined correlations. We will explain how we define the first-logic based correlation later. At the higher level, in MagicFG, we define two types of factor functions.</p><p>â€¢ Attribute factor function Captures characteristics of the E-mail-person pair and is defined as an exponential function:</p><p>where k (.) is the kth feature function defined between v and e i with respect to the value of y i ; k is the weight of the corresponding attribute feature; x i is the ith feature vector. Z a is the normalization factor. â€¢ Logic factor function Captures the correlations between latent variables. It is also defined as an exponential function:</p><p>(2)</p><formula xml:id="formula_1">f (v, e i , y i ) = 1 Z a exp âˆ‘ k k k (y i , x i ) , (3) g(y i , y j ) = 1 Z b exp âˆ‘ m m m (y i , y j ) ,</formula><p>where m (.) is the mth correlation factor function defined between y i and y j according to a first-order logic knowl- edge base; m is the weight of the corresponding correlation factor. For the attribute factor function, we can define multiple feature functions { k (y i , x i )} k to characterize each candidate instance. For extracting E-mail, we define features such as whether v's first name, last name or full name is contained in e i 's prefix. <ref type="foot" target="#foot_8">8</ref> Another kind of feature is defined between person v and the context c i from which the candidate e i is extracted. For example, whether v's first name, last name or full name is contained in context c i , and whether v's affili- ation is contained in context c i . Here we use the affiliation information to disambiguate persons with the same names.</p><p>Regarding the logic factor function, we mainly consider three kinds of first-order logic relationships between latent variables: complete consistency, partial consistency and prior knowledge. First-order logic is the standard for the formalization of mathematics into axioms and is studied in the foundations of mathematics. In our problem, we use first-order logic to encode user-specific correlations between candidate instances and human domain human knowledge about the extraction. For a general introduction to first-order logic, please refer to <ref type="bibr">Richardson and Domingos (2006)</ref>. Complete consistency describes the requirements that the values of two latent variables y i and y j should be consistent under some given conditions. For example, the following first-order logic statement indicates that y i equals y j if the corresponding E-mail can- didates are the same with each other. The logic is straightforward because two identical E-mail addresses are highly likely to be credible or not at the same time. Correspondingly, we define the factor function as Partial consistency describes a situation in which the values of two latent variables y i and y j are partially consistent under some given conditions. For example, the following first-order logic statement indicates that y i and y j are both equal to 1 if their prefixes are the same. This statement can be explained as follows.</p><p>When two E-mail addresses share the same prefix, they are very likely to mention the same person, because people usually use the same prefix in different E-mail addresses. In this case, if one E-mail address is correct, the other one is also likely to be correct. We define the corresponding factor function as</p><p>Prior knowledge referes to knowledge that can be formalized into useful first-order logics for a specific task. For example, when we search for someone's E-mail address using Google, we find that many candidates starting with "E-mail" like "email@gmail.com." This is due to the security policy of the search engine, which hide the actual E-mail address (called a blocked candidate). Fortunately, we can still observe the domain information.</p><p>We found that when another candidate shares the same domain with a blocked candidate, it is very likely that the other candidate is a correct E-mail-we use the redundant Equals(e i , e j ) â‡’ Equals(y i , y j )</p><formula xml:id="formula_2">(y i , y j ) =</formula><p>1, e i = e j and y i = y j 0. otherwise SamePrefix(e i , e j ) â‡’ True(y i ) âˆ§ True(y j )</p><formula xml:id="formula_3">(y i , y j ) = âŽ§ âŽª âŽ¨ âŽª âŽ©</formula><p>1, e i and e j have the same prefix and y i = y j = 1 0. otherwise domain information to enhance the confidence. We define the corresponding first-order logic as</p><p>The corresponding factor function is defined as For each profiling task, we build a knowledge base according to the defined first-order logics and summarize it in Table <ref type="table" target="#tab_2">1</ref>. In general, the attribute factors capture the characteristics on each potential person-E-mail pair and the logic correlation factors capture the dependencies between two person-Email pairs.</p><p>Modeling categorical attributes When dealing with categorical attributes, for all the queried persons, we build one factor graph with each node representing a query person, and each edge representing the dependency between two query persons. We use Gender as the example to explain the modeling process for the categorical attributes.</p><p>Different from the non-categorical attributes, each person can only have one Gender-either male or female. Thus in this task, we directly assign a label to each query person. We construct a query by combining the person name and the representative keywords for each Gender("his" for male and "her" for female, as mentioned before). The query finally looks like â€³name his|her." Then we formulate the MagicFG based on the returned snippets.</p><p>The formulation of MagicFG model is also a little different from that of non-categorical attributes. We feed the model with each observation variable as a person v i . The corresponding latent variable y i to each person v i represents v i 's attribute values, e.g., whether v i is male or female.</p><p>For attribute factor functions, we first extract features for each person from his/her search context. For example, whether a snippet in the search results contains both the person name and the word "his/her," whether a snippet contains both the affiliation and the word "his/her," whether "his/her" IsBlocked(e j ) âˆ§ SameDomain(e i , e j ) â‡’ True(y i ) âˆ§ False(y j ).</p><formula xml:id="formula_4">(y i , y j ) = âŽ§ âŽª âŽ¨ âŽª âŽ©</formula><p>1, c j is blocked, c i and c j have the same domain, y i = 1 and y j = 0 0. otherwise appears in the snippets of the top 3 returned search results, and the number "his/her" in all the search results. For logic factor functions, we define a correlation feature of the type of complete consistency logic as follows:</p><p>The logic indicates that the Gender of two persons are more likely to be the same if they share the same first name. In summary, the factor graphs built for the non-categorical and categorical attributes are slightly different. For non-categorical attributes, we build multiple graphs, where each graph corresponds to a person with a node in the graph representing a candidate attribute and an edge representing the dependency between two connected candidate attributes. While for categorical attributes, we build only one graph, where a node represents a person and an edge represents the dependency between two persons. where Z is the normalization factor; e i âˆ¼e j indicates that there is a (direct or indirect) correlation between e i and e j ; = ( , ) are parameters to estimate, representing the weights of the defined feature functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model training and extraction</head><p>Training a MagicFG involves estimating a parameter configuration = ( , ) from a given historical dataset, such that the log-likelihood objective function L( ) can be maximized, We use a gradient ascent algorithm to solve the objective function. The gradient for parameter k can be written as:</p><p>The parameter m can be obtained in the same way. In the above equation, the first term [ (y i , x i )] , representing the expectation of features values under the uniform distribution, can be easily calculated, while it is usually intractable to directly estimate the marginal probability in the second term as the graphical structure can be arbitrary and may</p><formula xml:id="formula_5">SameFirstname(v i , v j ) â‡’ Equals(y i , y j ) (4) L( ) = log P(Y|X, ) = âˆ‘ y i âˆˆY âˆ‘ k k k (y i , x i ) + âˆ‘ e i âˆ¼e j âˆ‘ m m m (y i , y j ) âˆ’ log Z,</formula><p>(5) * = arg max log P(Y|X, ).</p><formula xml:id="formula_6">(6) L( ) k = [ (y i , x i )] âˆ’ P (y i , x i )[ (y i , x i )].</formula><p>contain cycles. In this work, we use loopy belief propagation (LBP) <ref type="bibr">(Yedidiaet al. 2000)</ref> to approximate the marginal probability in the second term and accordingly calculate the gradient. The learning algorithm can be divided into two steps: we first perform the LBP algorithm to calculate marginal distribution for each latent variable, and then update each parameter to maximize the objective log-likelihood function by : where is the learning step. The process repeats updating marginal probabilities and parameters until the convergence or until the number of iterations is large enough.</p><p>Given the observed feature vectors X v for all candidates of person v and the learned parameter configuration , the extraction can be done by finding the most likely configuration of Y v = {y 1 , â€¦ , y I } for all the person-E-mail pairs {(e i , v)}:</p><p>where the LBP algorithm is again used to solve this problem.</p><p>Discussions Different from traditional methods that crawled each of the relevant pages, we only use the snippet information to extract the profile attributes. It is much faster and more stable, as different servers that host the relevant pages may have very different network speed. Also we found with the constructed "smart" queries, more than 90% of the profile attributes are already contained in the snippets returned by the search engine. One additional advantage is that we do not need to maintain a large database to record all the relevant pages for all the query persons. This is very important, as, for example, in AMiner, we have more than 130,000,000 researchers-maintaining such a big database for all researchers is a challenging task itself. Moreover, the profile information is very dynamic. Our method avoids this problem by directly querying the search engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Enhancement for Gender inference</head><p>The proposed MagicFG framework is very flexible and can be easily extended (enhanced) for particular tasks. We use Gender inference as an example to explain how we enhance the MagicFG model by various additional information. We have developed a Gender prediction system by enhancing MagicFG with several new features.</p><formula xml:id="formula_7">(7) new = old + â‹… L( ) , (8) Y * v = arg max Y v P(Y v |X v , ),</formula><p>Page 11 of 17 24</p><p>Face recognizer (FR) Besides searching only Google snippets, we also use Google Images to retrieve redundant image information. Then we apply a face recognition tool to recognize if there is a male/female face in the image(s).<ref type="foot" target="#foot_9">9</ref> </p><p>Facebook generated name list (FGNL) We also consider the Facebook Gender list. The list was collected by <ref type="bibr">Tang et al. (2011)</ref>. The method is also one of comparison methods in our experiments. To enhance our method for Gender inference, we define FGNL as a factor function in our MagicFG model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Super name list (SNL) This is a refined version of FGNL.</head><p>From all listed names in FGNL, we first extract all n-gram subwords {s ni |i = 1, 2, â€¦ , m} . We denote S c n as the pool of subwords appearing in the name list for Gender c âˆˆ {male, female} , and count(s c ni ) as the number of appear- ances of s ni in S c n . The subword density (s ni , c) is calculated as For the target user v with full name f v , the prediction is made by where In summary, SNL tries to capture local patterns of a name that may contain Gender information.</p><p>MagicFG++ We combine all the defined factor functions together. To distinguish from the general MagicFG model, we call this enhanced method for Gender inference as MagicFG++.</p><p>In our experiments, we will evaluate the enhancement method and compare the different methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and discussions</head><p>In this section, we demonstrate the effectiveness of our approach for both categorical and non-categorical attributes. For quantitative evaluation, we take Gender as an example</p><formula xml:id="formula_8">(9) (s ni , c) = count(s c ni ) âˆ‘ m j=1 count(s c nj ) . (10) g(v) = male, if score(male) &gt; score(female) female, otherwise (11) score(c) = |S c n | âˆ‘ i=1,s ni âˆˆf v (s ni , c), c âˆˆ {male, female}</formula><p>of categorical attributes, and E-mail as an example of noncategorical ones. Please note that our framework is very flexible and have already been applied to an online academic search and mining system AMiner.org to extract the profiles for researchers. All datasets and codes used in this work are publicly available.<ref type="foot" target="#foot_10">10</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment setup</head><p>Dataset To construct a ground-truth dataset for quantitative evaluation, we randomly choose 2000 researchers from AMiner.org <ref type="bibr">(Tang et al. 2008)</ref>. Specifically, for extracting the E-mail of each researcher, we search the Web using a search engine by querying the person name and the word "E-mail." This way results in 4528 E-mail candidates.</p><p>Human annotations are applied to identify correct E-mail addresses. Analogously, for inferring Gender, we search the Web by querying the person name and the word "his" or "her." Human annotations are also used to identify the Gender of 2700 researchers. For disagreements in the annotation, we conduct "majority voting." We found that, among the 2700 researchers, 47.5% are female researchers;<ref type="foot" target="#foot_11">11</ref> and about 40% of the E-mail candidates are correct E-mails.</p><p>Evaluation metrics To quantitatively evaluate the proposed model, we perform fivefold cross-validation and report the average extraction performance in terms of precision, recall, and F1-score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison methods</head><p>We compare our MagicFG method with following methods for extracting E-mail and Gender on the ground-truth dataset.</p><p>â€¢ Rule We use several pre-defined rules to extract profile attributes. For example, for extracting Gender, we count the number of common names for girls and boys. For extracting E-mails, we find whether the prefix of the E-mail contains the person name. â€¢ Random forest (RF) We use the same attribute factors as features and employs sklearn package to conduct train and predict. â€¢ Logistic regression (LR) We use the same attribute factors as features and employs sklearn package to conduct train and predict. â€¢ Support vector machine (SVM) We use the same attribute factors as features and employs the sklearn package to conduct train and predict.</p><p>â€¢ Tree-structured conditional random field For E-mail extraction, we use the method proposed in Tang et al.</p><p>(2010) as the baseline (to hereafter referred to as: TCRF), which is one of the state-of-the-art approaches to extracting homepages and E-mails from the Web. This method has two steps, where it first finds the user's homepage and then extracts E-mail from the homepage with a high precision using the TCRF model. â€¢ Facebook generated name list predictor (FGNL) For Gender inference, we use a method proposed by Tang et al. ( <ref type="formula">2011</ref>) as the baseline (to hereafter referred to as: FGNL). Most state-of-the-art methods for inferring Gender depend on a list of common names for males and females. In <ref type="bibr">Tang et al. (2011)</ref>, the authors proposed an approach that used data from Facebook to construct an expanded and high-quality name list. They match the user's first name with the list to make the inference. If the first name is matched with a male name, the user is treated as a male, and similarly for females. If the first name is found in neither the male names nor the female names, or in both the name lists, they make a random guess about the user's Gender.</p><p>The MagicFG model is implemented in C++. All experiments are conducted on a Macbook Pro with Intel Core i5 CPU 2.9GHz(2 cores) and 8 GB memory. In all the experiments, we set L = 10 and search top 10 results by Google, and conduct a fivefold cross validation for each method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Feature definition</head><p>We now turn to the definition of attribute factor functions.</p><p>For the problem of Web user profiling, there are mainly two types of features. The first are domain-specific features, which differ in different extraction subtasks. For example, in E-mail extraction, we could define binary-valued features to describe whether the query person's first or last name is contained in the E-mail address. In Gender inference, we could use term frequencies of keywords "his/her" among search snippets as real-valued features.</p><p>The second type of features are contextual features to model contextual credibility of search snippets from which we extract all domain-specific features. These features try to model whether these snippets are relevant to the query person. Contextual features mainly consist of the ranking Position of the search snippet as an integer or as the ratio of its ranking to the total number of shown snippets in one search page, and whether the snippet contains key information about the query person, such as her name or affiliation terms.</p><p>Tables <ref type="table" target="#tab_4">2 and 3</ref> give more details on how we define these features, where "*k" indicates there are k features from different combinations of alternative factors in the description. <ref type="table">4</ref> lists the performance comparison of E-mail extraction. Our methods consistently ourperform the baseline. Among all methods, MagicFG with full features (Magic-C) significantly stands out in AUC and F1-score (achieves an improvement of + 6.68% compared with TCRF, p â‰ª 0.01 with t test). It is noteworthy that, aside from achieving better precision, our method shows clearly better recall performance (+ 9.07%) than the baseline. This is due to its ability to find more relevant candidates through efficient query construction (Cf. Sect. 3.2), and to leverage the correlations between candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Profiling performance</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E-mail extraction Table</head><p>Gender inference Table <ref type="table">5</ref> lists the performance comparison of Gender inference. The proposed MagicFG outperforms the baseline (FGNL) in terms of F1-score by + 8.33%. The significant improvement comes mainly from the improvement on recall (+ 12.81%). The reason is that the FGNL method depends heavily on the quality of the name list and is thus limited by its coverage. On the other hand, our approach automatically identifies representative keywords for documents describing a user with specific Gender, and infer Gender from the big Web data with better generalization.</p><p>Effect of contextual features Figure <ref type="figure">5</ref> shows performances of SVM and MagicFG when they use or ignore contextual features. It is clear that contextual features are very useful in improving profiling performance, especially F1-score and AUC. This is done by reducing noises in Web data, such as basic information or demographical keywords extracted from irrelevant search snippets.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Discussion</head><p>Here we analyze the connection between MagicFG and several related models that can also be used for this extraction task for candidate verification. <ref type="bibr">Cox (1958)</ref> is widely used for classification problems. However, such models can hardly describe relationships between data points, which prove to be helpful in web information extraction tasks. In essence, MagicFG leverages logic factor functions to model such relationships among redundant data. Without the logic factor functions, MagicFG would be reduced to a naive logistic regression model. <ref type="bibr" target="#b3">Basu et al. (2004)</ref> aims at incorporating supervision into prototype-based clustering by defining â€³must-linkâ€³ and â€³cannot-linkâ€³ relationships between data points. Despite the similar idea of adding constraints to a probability framework, logical formulas are limited to describing exactly two types of relationships. Our proposed MagicFG model can handle a much wider range of logical relationships and can be easily generalized to higher-order logics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Logistic regression</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HMRF-KMEANS</head><p>Markov logic network (MLN) Richardson and Domingos ( <ref type="formula">2006</ref>) is a classical model to combine a first-order logic knowledge base and probabilistic graphical models. It constructs a graph purely consisting of weighted formulas and can make inferences for unknown labels and relationships in an elegantly and powerfully way. However, logical formulas alone are insufficient for capturing complicated features. Consider Gender inference, for instance. We can design logic rules like: In all relevant Google snippets, if â€³hisâ€³ appears more frequently than â€³her,â€³ the user is labeled as a male one, or in the form of a first-order logic formula:</p><p>Though seeming natural and intuitive, this rule is too simple to cover real scenarios. In fact, â€³hisâ€³ is relatively more common in Web pages, and up to 16% of pages standing for female users showed more instances of â€³hisâ€³ than â€³her.â€³ MagicFG, however, is able to learn separate weights for these numerical features. In this case, MagicFG can find out how many â€³herâ€³s do we need to vote for â€³female,â€³ while MLN cannot. MagicFG can be transformed into MLN when all attribute features are only described in first-order logic formulas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Prototype system</head><p>We applied the proposed MagicFG model to the online system AMiner.org to extract researcher profiles. We have also developed several prototype systems. Here, we introduce one of them-Scholar Gender Prediction. 12 Figure <ref type="figure" target="#fig_1">2c</ref> shows a screenshot of the scholar Gender prediction system. The system trains a MagicFG model off-line using existing labeled data in our dataset. The user inputs a scholar name ("Jiawei Han") and his affiliation ("UIUC"), and the system returns the prediction results (Male-99.01% and Female-0.99%). If the user is interested in more details, isGreater(#his, #her) â†’ isMale(user). the system can display the results of different analyzers (factor functions) in MagicFG. We also provide related APIs, which offer programming-friendly interfaces for the AMiner system to access detailed profiles of scholars.</p><p>We now compare the system with two commercial systems: Gender API and Genderize.io. Both are popular Gender services. Genderize.io claims to have over 20 million distinct names across 79 countries and 89 languages. Table <ref type="table">6</ref> lists the performance comparison between different systems using the same dataset used in our experiments. All the results are based on fivefold cross-validation. We also report results of the enhanced Gender inference (MagicFG++) and different Gender inference methods (Cf. Sect. 3.5). It seems that Genderize. io is better than FGNL, but still underperforms our proposed MagicFG model. By incorporating the enhanced factors, Mag-icFG++ can further improve the prediction accuracy.</p><p>In Fig. <ref type="figure">7</ref>, we further give an example to demonstrate the generalization of proposed MagicFG model and to explain the unique advantages of MagicFG compared with the other systems (e.g., Genderize.io). In the example, we are trying to predict the Gender of "Tracy McGrady from Houston Rockets," who is a famous male basketball player. First the name is not in our AMiner database. When we try Genderize.io, the result is female, possibly because the first name or the last name is also common in females. Our model outputs a percentage of 33.62% to be female and 66.38% to be male. More importantly, our model can give a detailed explanation on the prediction result, as shown in Fig. <ref type="figure">7</ref>. By both search engine and face recognition, the prediction results are male, while by only names, the prediction result is indeed female-this is probably why Genderize.io made an incorrect prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we revisited the problem of Web user profiling in the big data era and propose a simple but very effective approach, referred to as MagicFG, for profiling Web users by leveraging the redundant information on the Web. MagicFG also provides a mechanism to incorporate human knowledge as Markov logics into a factor graph. Experiments on two data sets show that the proposed method significantly improves the profiling accuracy in comparison with several comparison methods. The approach has been already deployed in an online system AMiner.org for profiling millions of researchers and mining research interests.</p><p>The proposed framework (MagicFG) has many potential applications. For example, we can apply the approach to help identify relationships between entities with the same idea. We can also extend the framework to extract entity attributes for building large-scale knowledge graphs. The general problem of profiling Web users represents an interesting research direction in Web mining and social network analysis. There are many potential future directions of this work. First, the information on the Web changes very quickly. How to recognize what is out-of-date and what is still valid is a challenging problem. Next, it is interesting to further study how incrementally learning the proposed model so that we can directly involve online user interactions in the learning process. Another potential direction is to study the profiling task using social data such as Facebook and Twitter data. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 Example of researcher profile. The profile contains extracted basic information such as affiliation, Position, picture, E-mail, etc., in blue rectangles; mined research interests in red rectangles; and inferred demographics in green rectangles (color figure online)</figDesc><graphic url="image-7.png" coords="2,53.44,57.76,488.40,134.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2</head><label>2</label><figDesc>Fig. 2 Performance comparison between our approach and existing methods. a Comparison with TCRF (Tang et al. 2010), a two-step method for E-mail extraction. b Comparison with FGNL (Tang et al. 2011) for Gender inference (Cf. Sect. 4 for detailed comparisons). c A screenshot of the the scholar Gender prediction system</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>24</head><label></label><figDesc>Page 6 of 17 at Chicago" occurs four times in the snippets and "IBM T. J. Watson Research Center" occurs twice. More precisely, we propose a MArkov loGIC factor graph (MagicFG) to rank the obtained candidates by leveraging the redundancy information. The model is flexible and can easily incorporate any domain human knowledge to improve the extraction accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3</head><label>3</label><figDesc>Fig. 3 Snippets returned by Google by the two constructed queries. From (a) we can easily identify two affiliations and from (b) we can also identify two E-mail addresses</figDesc><graphic url="image-15.png" coords="6,53.44,57.76,488.40,304.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 Graphical representation of a logic factor graph model based on a real search example. Notation (e i , v) represents an E-mail-person pair, and y i indicates its corresponding label; notations f(.) and g(.) represent the attribute factor function and logic factor function, respectively</figDesc><graphic url="image-16.png" coords="8,86.26,57.76,422.76,248.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Once we formulated the MagicFG model for either non-categorical or categorical attributes, we can combine the defined factor functions and define the following log-likelihood objective function by following the Markov assumption (Hammersley and Clifford 1971):</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6</head><label>6</label><figDesc>Fig. 6 Effect of logic correlation factors in E-mail extraction and Gender inference. Basic stands for the MagicFG model that only considers the attribute factors. +CC stands for adding the factors of complete consistency logic. +PC adds factors of partial consistency logic. +PK adds the factors of prior knowledge logic</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>24</head><label></label><figDesc>Page 16 of 17   Brajnik G, Guida G, Tasso C (1987)  User modeling in intelligent information retrieval. Inf Process Manag 23(4):305-320 Chan PK (1999) Constructing web user profiles: a non-invasive learning approach. In: KDD-99 workshop on web usage analysis and user profiling, pp 39-55 CollinsM (2002)  Ranking algorithms for named-entity extraction: boosting and the voted perceptron. In: Proceedings of the 40th annual meeting on association for computational linguistics, pp 489-496 Cortes C, Vapnik V (1995) Support-vector networks. Mach Learn 20(3):273-297 Cox DR (1958) The regression analysis of binary sequences. J Roy Stat Soc Ser B (Methodol) 20(2):215-242 Cunningham H, Maynard D, Bontcheva K, Tablan V (2002) GATE: a framework and graphical development environment for robust NLP tools and applications. In: Proceedings of the 40th annual meeting of the association for computational linguistics, pp 168-175 Dong Y, Yang Y, Tang J, Yang Y, Chawla NV (2014) Inferring user demographics and social strategies in mobile social networks. In: Proceedings of the 20th ACM SIGKDD international conference on knowledge discovery and data mining, pp 15-24 Downey D, Etzioni O, Soderland S (2005) A probabilistic model of redundancy in information extraction. In: Proceedings of the 19th international joint conference on artificial intelligence, pp 1034-1041 Efstathiades H, Antoniades D, Pallis G, Dikaiakos MD (2016) Users key locations in online social networks: identification and applications. Soc Netw Anal Min 6(1):66:1-66:17 Eltaher M, Lee J (2015) User profiling of Flickr: integrating multiple types of features for gender classification. J Adv Inf Technol 6(2):84-87 Figueiredo F, Ribeiro B, Almeida JM, Faloutsos C (2016) TribeFlow: mining and predicting user trajectories. In: Proceedings of the 25th international conference on world wide web, pp 695-706 Finkel JR, Grenager T, Manning C (2005) Incorporating non-local information into information extraction systems by Gibbs sampling. In: Proceedings of the 43rd annual meeting on association for computational linguistics, pp 363-370 Ghahramani Z, Jordan MI (1997) Factorial hidden Markov models. Mach Learn 29(2-3):245-273 Hammersley JM, Clifford P (1971) Markov fields on finite graphs and lattices Hu J, Zeng HJ, Li H, Niu C, Chen Z (2007) Demographic prediction based on user's browsing behavior. In: Proceedings of the 16th international conference on world wide web, pp 151-160 Ikeda K, Hattori G, Ono C, Asoh H, Higashino T (2013) Twitter user profiling based on text and community mining for market analysis. Knowl Based Syst 51(1):35-47 Joseph K, Wei W, Carley KM (2016) Exploring patterns of identity usage in tweets: a new problem, solution and case study. In: Proceedings of the 25th international conference on world wide web, pp 401-412 Kristjansson T, Culotta A, Viola P, McCallum A (2004) Interactive information extraction with constrained conditional random fields. In: Proceedings of the 19th national conference on artificial intelligence, pp 412-418 Krulwich B (1997) Lifestyle finder: intelligent user profiling using large-scale demographic data. AI Mag 18(2):37-45 Lafferty JD, McCallum A, Pereira FCN (2001) Conditional random fields: probabilistic models for segmenting and labeling sequence data. In: Proceedings of the 18th international conference on machine learning, pp 282-289 Li R, Wang S, Deng H, Wang R, Chang KCC (2012) Towards social user profiling: unified and discriminative influence model for inferring home locations. In: Proceedings of the 18th ACM Page 17 of 17 24 Proceedings of the 6th ACM international conference on web search and data mining, pp 779-780 Weninger T, Hsu WH, Han J (2010) CETR: content extraction via tag ratios. In: Proceedings of the 19th international conference on world wide web, pp 971-980 Wu S, Liu J, Fan J (2015) Automatic web content extraction by combination of learning and grouping. In: Proceedings of the 24th international conference on world wide web, pp 1264-1274 Wu L, Ge Y, Liu Q, Chen E, Long B, Huang Z (2016) Modeling users' preferences and social links in social networking services: a joint-evolving perspective. In: Proceedings of the 30th AAAI conference on artificial intelligence, pp 279-286 Yedidia JS, Freeman WT, Weiss Y (2000) Generalized belief propagation. In: Proceedings of the 13th neural information processing systems, pp 689-695 Yu K, Guan G, Zhou M (2005) Resume information extraction with cascaded hybrid model. In: Proceedings of the 43rd annual meeting on association for computational linguistics, pp 499-506</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>First-order logic knowledge baseFirst-order logic ExampleComplete consistencyEquals(e i , e j ) â‡’ Equals(y i , y j ) Partial consistencySamePrefix(e i , e j ) â‡’ True(y i ) âˆ§ True(y j ) Prior knowledgeIsBlocked(e j ) âˆ§ SameDomain(e i , e j ) â‡’ True(y i ) âˆ§ False(y j )</figDesc><table><row><cell>24 Page 10 of 17</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc>The ranking Position of the source page snippet (*2) Whether the source page snippet/title contains v's affiliation (*4) Whether the source page snippet/title contains v's last/first name</figDesc><table><row><cell>Feature definition of E-mail extraction</cell><cell>Feature type</cell><cell>Description</cell></row><row><cell></cell><cell>Domain-specific</cell><cell>(*2) Whether the E-mail username contains v's last/first name</cell></row><row><cell></cell><cell>Contextual</cell><cell>(*1)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>Feature definition of Gender inference</figDesc><table><row><cell></cell><cell></cell><cell cols="4">Table 4 Performance comparison of E-mail extraction (%)</cell><cell></cell></row><row><cell>Feature type</cell><cell>Description</cell><cell>Method</cell><cell>Precision</cell><cell>Recall</cell><cell>F1-score</cell><cell>AUC</cell></row><row><cell cols="2">Domain-specific (*2) Term frequency of "his/her" among all snip-</cell><cell>TCRF</cell><cell>90.20</cell><cell>83.83</cell><cell>86.90</cell><cell>-</cell></row><row><cell></cell><cell>pets</cell><cell>Rule</cell><cell>87.81</cell><cell>89.64</cell><cell>88.72</cell><cell>-</cell></row><row><cell>Contextual</cell><cell>(*2) Document frequency of "his/her" among all snippets (*2) Whether "his/her" appeared in top k snippets (*4) Co-occurrences of "his/her" and v's affiliation in the source page snippet/title</cell><cell>RF LR SVM MagicFG</cell><cell>90.05 91.97 90.58 94.27</cell><cell>89.42 89.83 90.21 92.90</cell><cell>89.74 90.89 90.40 93.58</cell><cell>93.09 94.42 93.14 97.38</cell></row><row><cell></cell><cell>(*8) Co-occurrences of "his/her" and v's last/first</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>name in the source page snippet/title</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https ://amine r.org, AMiner aims to understand scientific text and networks. The system extracts researchers profiles automatically from the Web. So far, the system has built more than 130,000,000 researcher profiles and provides a set of unique functions, including expert search, social influence analysis, collaboration recommendation, and community evolution. The system has been in operation</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2006" xml:id="foot_1">since 2006 and has attracted more than 8,320,000 independent IP accesses from over 220 countries/regions.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2">http://email break er.com.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3">https ://email hunte r.com.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4">http://www.getsi dekic k.com.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5">https ://www.gende r-api.com/.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6">https ://gende rize.io/.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_7">One example of the heuristic rule: " (([a âˆ’ z0 âˆ’ 9]+)(ï¿½.|dot|ï¿½.)?)+(@|at|ï¿½[atï¿½]|ï¿½[atï¿½])(([a âˆ’ z0 âˆ’ 9ï¿½]+)(ï¿½.|dot|ï¿½.ï¿½[dotï¿½])) + ([a âˆ’ z]+)".</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_8">We call the string before "@" of an E-mail candidate as the prefix of the E-mail, and the string after "@" as its domain.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_9">In our experiments, we use Face++, http://www.facep luspl us.com/.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_10">https ://amine r.org/profi ling/.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_11">The Gender dataset is larger than the previously released one with more balanced distribution of two Genders.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The work is supported by the National Basic Research Program of China (2014CB340506), National Natural Science Foundation of China (61631013, 61561130160), a research fund supported by MSRA, and the Royal Society-Newton Advanced Fellowship Award. SIGKDD international conference on knowledge discovery and data mining, pp 1023-1031 Li J, Ritter A, Hovy E (2014) Weakly supervised user profile extraction from Twitter. In: Proceedings of the 52nd annual meeting of the association for computational linguistics, pp 165-174 Makazhanov A, Rafiei D, Waqar M (2014) Predicting political preference of Twitter users. Soc Netw Anal Min 4(1):193:1-193:15 McCallum A, Freitag D, Pereira FCN (2000) Maximum entropy Markov models for information extraction and segmentation. In: Proceedings of the 17th international conference on machine learning, pp 591-598 Michelson M, Knoblock C (2007) Unsupervised information extraction from unstructured, ungrammatical data sources on the world wide web. Int J Doc Anal Recogn 10(3):211-226 Pazzani M, Billsus D (1997) Learning and revising user profiles: the identification of interesting web sites. Mach Learn 27(3):313-331 Pedro JS, Siersdorfer S, Sanderson M (2011) Content redundancy in YouTube and its application to video tagging. ACM Trans Inf Syst 29(3):13:1-13:31 Richardson M, Domingos P (2006) Markov logic networks. Mach Learn 62(1-2):107-136 Ritze D, Lehmberg O, Oulabi Y, Bizer C (2016) Profiling the potential of web tables for augmenting cross-domain knowledge bases. In: Proceedings of the 25th international conference on world wide web, pp 251-261 Sarawagi S, Cohen WW (2004) Semi-Markov conditional random fields for information extraction. In: Proceedings of the 17th neural information processing systems, pp 1185-1192 Sarraute C, Brea J, Burroni J, Blanc P (2015) Inference of demographic attributes based on mobile phone usage patterns and social network topology. Soc Netw Anal Min 5(1):39:1-39:18 Soltysiak SJ, Crabtree IB (1998) Automatic learning of user profiles-towards the personalisation of agent services. BT Technol J 16(3):110-117 Szell M, Thurner S (2012) How women organize social networks different from men. ArXiv preprint arXiv :1205.4683 Tang J, Hong M, Li J, Liang B (2006) Tree-structured conditional random fields for semantic annotation. In: Proceedings of the 5th international conference on the semantic web, pp 640-653 Tang J, Hong M, Zhang D, Liang B, Li J (2007a) Emerging technologies of text mining: techniques and applications. Chap. Information extraction: methodologies and applications, pp 1-33. Idea Group Inc. Tang J, Zhang D, Yao L (2007b) Social network extraction of academic researchers.</p><p>In: Proceedings of the 7th IEEE international conference on data mining, pp 292-301 Tang J, Zhang J, Yao L, Li J, Zhang L, Su Z (2008) Arnetminer: extraction and mining of academic social networks. In: Proceedings of the 14th ACM SIGKDD international conference on knowledge discovery and data mining, pp 990-998 Tang J, Yao L, Zhang D, Zhang J (2010) A combination approach to web user profiling. ACM Trans Knowl Discov Data 5(1):2:1-2:44 Tang W, Zhuang H, Tang J (2011a) Learning to infer social ties in large networks. In: ECML/PKDD'11, pp 381-397 Tang C, Ross K, Saxena N, Chen R (2011b) What's in a name: a study of names, gender inference, and gender behavior in Facebook.</p><p>In: Proceedings of the 16th international conference on database systems for advanced applications, pp 344-356 Tang J, Fang Z, Sun J (2013) Incorporating social context and domain knowledge for entity recognition. In: Proceedings of the 24th international conference on world wide web, pp 517-526 Tang J, Lou T, Kleinberg J, Wu S (2016) Transfer learning to infer social ties across heterogeneous networks. ACM Trans Inf Syst 34(2):7:1-7:43 Weninger T, Han J (2013) Exploring structure and content on the web: extraction and integration of the semi-structured web. In:</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automatic ontology-based knowledge extraction from web documents</title>
		<author>
			<persName><forename type="first">H</forename><surname>Alani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Millard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Weal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Shadbolt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intell Syst</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="21" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Formal models for expert finding in enterprise corpora</title>
		<author>
			<persName><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ribeiro-</forename><surname>Neto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th annual international ACM SIGIR conference on research and development in information retrieval</title>
				<editor>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</editor>
		<meeting>the 29th annual international ACM SIGIR conference on research and development in information retrieval<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1999">1999. 2006</date>
			<biblScope unit="page" from="43" to="55" />
		</imprint>
	</monogr>
	<note>Modern information retrieval</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Open information extraction from the web</title>
		<author>
			<persName><forename type="first">M</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Broadhead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international joint conference on artificial intelligence</title>
				<meeting>the 20th international joint conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="2670" to="2676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A probabilistic framework for semi-supervised clustering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bilenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM SIGKDD international conference on knowledge discovery and data mining</title>
				<meeting>the 10th ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="59" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Inferring the demographics of search users: social data meets search queries</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shokouhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kosinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on world wide web</title>
				<meeting>the 22nd international conference on world wide web</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="131" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Redundancy-driven web data extraction and integration</title>
		<author>
			<persName><forename type="first">L</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bronzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Crescenzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Merialdo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Papotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Procceedings of the 13th international workshop on the web and databases</title>
				<meeting>ceedings of the 13th international workshop on the web and databases</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Case study: Gender prediction for</title>
		<imprint>
			<publisher>Tracy McGrady from Rockets</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
