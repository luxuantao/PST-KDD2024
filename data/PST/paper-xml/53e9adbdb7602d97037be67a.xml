<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Effective profiling of consumer information retrieval needs: a unified framework and empirical comparison</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2004-03-08">8 March 2004</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Weiguo</forename><surname>Fan</surname></persName>
							<email>wfan@vt.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Accounting and Information Systems</orgName>
								<orgName type="institution">Virginia Tech</orgName>
								<address>
									<addrLine>3007 Pamplin Hall 24061</addrLine>
									<settlement>Blacksburg</settlement>
									<region>VA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><forename type="middle">D</forename><surname>Gordon</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Praveen</forename><surname>Pathak</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Florida</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Effective profiling of consumer information retrieval needs: a unified framework and empirical comparison</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2004-03-08">8 March 2004</date>
						</imprint>
					</monogr>
					<idno type="MD5">717CE4D281ADBD5DA6F1A915D7647DC4</idno>
					<idno type="DOI">10.1016/j.dss.2004.02.003</idno>
					<note type="submission">Received 17 April 2003; received in revised form 23 January 2004; accepted 3 February 2004</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Personalization</term>
					<term>Profiling</term>
					<term>Information push</term>
					<term>Information routing</term>
					<term>Selective dissemination of information</term>
					<term>Information retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Due to the overwhelming volume of information that is increasingly available, many people rely on current awareness systems to keep abreast of the latest developments in the fields that they are interested in, as evidenced in the popularity of subscriptions to news-monitoring and digital library services. The success of these services, however, often requires effective acquisition of users' personal standing interests as represented in personal profiles. Our objective in this paper is twofold. First, we have introduced a new method for profile generation and compared it against other well-known methods. We have found promising results. Second, although there are various methods proposed in information retrieval and machine learning literature to address the issue of profiling, a unified framework and systematic cross-system comparison to help users, especially service providers, to determine the most effective way of profiling consumers is still lacking in the literature. In this paper, we try to fill the gap by looking at these methods from a more integrated point of view based on statistical contingency theory. Variations of these methods are then systematically tested on three well-known routing systems and results are analyzed and reported.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Successful decision making calls for timely information. Business managers need to continue gathering information about consumers, competitors, and markets to formulate and modify their business plan and business strategies. Scientists require current awareness systems from digital libraries to keep abreast of the latest developments in their corresponding fields and to avoid replicating the work done by other peers. Even common people who invest in stocks rely on all kinds of research reports from financial investing institutions to monitor companies' financial performance and breaking news.</p><p>All in all, there is huge demand of information from all sectors of business. In order to fulfill the needs of information from such a large group of customers, web portals, information service providers, digital libraries, news-wire companies, etc., are build-0167-9236/$ -see front matter D 2004 Elsevier B.V. All rights reserved. doi:10.1016/j.dss.2004.02.003 ing large-scale systems that can help them distribute or deliver timely information to their customers' email boxes, and mobile devices like digital cellular phone, and PDAs. This kind of service is commonly called Selective Dissemination of Information (SDI) <ref type="bibr" target="#b15">[16]</ref> or Information Routing. In the current e-Business era, it is often referred to as Push Technology <ref type="bibr" target="#b6">[7]</ref>. <ref type="foot" target="#foot_0">1</ref> The technique that enables companies to deliver these highly customized and personalized information to consumers is the so-called personalization technology. The core of the personalization technology is the management of user profiles. These profiles can be implicit profiles that are built from consumers' purchase history, such as the categories of products that consumers purchased recently. Or they could be profiles specified by users explicitly when they initially register or subscribe to the services.</p><p>We look at the problem of pushing personalized information goods (news, abstracts, etc.) in this paper. Unlike the physical goods, information goods are intangible and the cost of ownership is often very low (even free). The lack of structure and regularity of online information makes the problem of information push really hard. Without careful design and implementation, the large amount of irrelevant information pushed to these users will often frustrate the users, possibly turning them away from using the services.</p><p>Similar to user profiles for tangible goods, there are two different ways of creating user profiles for information goods: an explicit profile which is provided by a user directly, or an implicit profile which is built by a push system based on a user's feedback and behavior tracking (with appropriate user consent). Instead of having past purchase history (constituting explicit profile), past reading history, bookmarks, and news folders are available for implicit user profile generation.</p><p>We concentrate our effort on implicit profile generation methods because explicit profiles in information push suffer the same problem as in traditional online information search using generic search engines (Google, Yahoo, etc.): the vocabulary problem <ref type="bibr" target="#b7">[8]</ref>, where a user often has problem expressing his/her interest using the right words in getting the information (s)he wants. Often, the words are too few and not expressive enough to represent his/her interests as in most web search scenarios, where the average number of words in search queries is only 2-3 <ref type="bibr" target="#b9">[10]</ref>. Also, users often express the conceptual content of his/her interests with query words that do not match the words in relevant documents.</p><p>This paper is concerned with implicit profile building used in online push services or information routing, in which a set of keywords built from a user's feedback or past history is used to represent the interests of consumers. Other ways of representing profiles, like using categories or subject headings, are not of our concern in this paper. Moreover, we will look at the profile learning problem from information retrieval perspective since most of the push or routing techniques originated from the information retrieval research.</p><p>To create a user profile, most routing algorithms learn a set of features that may potentially help distinguish relevant documents from non-relevant documents. Based on the occurrences of these features in a new document, the new document either can be considered potentially useful and is routed to the user or can be considered non-relevant and is discarded. Most current systems also assign weights to these features to indicate the importance of these features for relevance estimation.</p><p>It is to be noted that in traditional information retrieval research the routing task is split into (1) selecting the terms for the profile and (2) using the profile through routing functions. Some recent approaches <ref type="bibr" target="#b2">[3]</ref> using support vector machines do not need such splitting of tasks. But in this paper we follow the task splitting model utilized in traditional information retrieval.</p><p>To learn the features and their weights, most routing algorithms typically use the probability of occurrences (or some variations of it) of a feature in the documents marked relevant (and non-relevant) by a user in the training corpus <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b28">29]</ref>. The idea is that if a feature occurs with a high probability in the relevant documents but with a low probability in the non-relevant documents, then this feature is a good indicator of relevance and should be assigned a high weight in the profile. Conversely, if such a feature occurs with a low probability in the relevant docu-ments but with a high probability in the non-relevant documents, then this feature is not a good indicator of relevance and should be assigned a low weight in the profile or should not even be included in the profile.</p><p>Our contribution in this paper is many-fold. First, a major contribution is that we have introduced a new method for profile generation based on the vector space model in Information Retrieval (IR). We have systematically studied and compared the proposed new method with well known existing profiling methods across various routing/matching systems, and have found good results. Second, we unify existing well-known profiling methods with statistical contingency theory. Such unification would ease profile methods implementation in computer programs. Third, we reinforce the importance of good ranking/matching function for the routing performance, i.e. we show that even if we use the best profile, the ranking function still makes a lot of difference in terms of performance.</p><p>The rest of the paper is organized as follows. Section 2 summarizes the various profile generation methods and their mathematical representations. It also introduces a new method for profile generation. Section 3 reviews three well-known matching functions to match incoming documents against profiles. Section 4 brings up the research questions and corresponding hypotheses. Section 5 describes the experimental setup for data, performance measures and procedures. The results of these experiments are discussed in Section 6. Section 7 offers conclusions and directions for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Approaches to profile generation</head><p>Information routing/filtering has been studied by computer scientists and information scientists for a long time. Basically, there are two approaches commonly used in the user modeling for profile learning: one is the traditional information retrieval approach using relevance feedback; the other is the machine learning approach using various feature selection methods. The approaches reviewed in this section can all be applied independently of the matching functions (described in the next section). The discussions throughout the study will be based on the statistical contingency table discussed below. We show in this section that all of the profile generation methods examined in this paper can be unified using a simple notation based on contingency table. 2  Before we discuss the various approaches to selecting words to include in the user's profile, we briefly review some of the prerequisite background on contingency tables, one of the widely used statistical techniques for categorical data analysis.</p><p>A contingency table for word j in the training data set is defined in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Here A is the number of relevant documents in which word j appears, B is the number of non-relevant documents in which word j appears, C is the number of relevant documents in which word j does not appear, D is the number of non-relevant documents in which word j does not appear. N is defined to be = (A + B + C + D).</p><p>Now we proceed to describe the approaches to profile learning and see how these approaches can be cast using the contingency tables just described. As stated earlier the first broad category is the approach based on traditional information retrieval techniques using relevance feedback. In this we will first discuss the Robertson's Selection Value (RSV) method and then introduce our own new method for profile learning. Next we will describe two prominent methods in the second approach of machine learning using feature selection. We have chosen these methods (RSV and the two machine learning ones) to review as they have made substantial theoretical and empirical contributions. 2 Our comparative study will not include the classic Rocchio relevance feedback framework <ref type="bibr" target="#b23">[24]</ref> because of its dependence on matching function and inferior performance in some evaluation studies <ref type="bibr" target="#b25">[26]</ref>. </p><formula xml:id="formula_0">RSV ¼ ðp i À q i ÞRW i<label>ð1Þ</label></formula><p>where p i = P(w i = 1AR) is the probability of the presence of word i given that a document is relevant, and q i = P(w i = 1AR ¯), which is the probability of the presence of word i given that a document is nonrelevant. Relevance weights for word i, RW i , is calculated by</p><formula xml:id="formula_1">RW i ¼ log p i ð1 À q i Þ q i ð1 À p i Þ<label>ð2Þ</label></formula><p>RW i can be obtained based on the probabilistic binary independent model and Bayesian decision rule (Refs. <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b27">28]</ref>). According to Ref. <ref type="bibr" target="#b20">[21]</ref>, q i can be safely ignored in Eq. (1) since q i is either much smaller than p i or RW i is much smaller for large q i . So the final RSV formula can be simplified as:</p><formula xml:id="formula_2">RSV ¼ p i RW i ¼ p i log p i ð1 À q i Þ q i ð1 À p i Þ<label>ð3Þ</label></formula><p>Considering the convention of contingency table as shown in Table <ref type="table" target="#tab_0">1</ref>, p i = A/(A + C) and q i = B/(B + D), and ignoring A + C, which is a constant for all words, RSV can be simplified to:</p><formula xml:id="formula_3">RSV ¼ Alog A Â D B Â C<label>ð4Þ</label></formula><p>All the words from relevant documents are sorted in descending order by their RSV value. For a given profile size (say 200) the top 200 words along with the RSV values as their weights are included in the user profile for routing experiments. The profile size here refers to the number of words (along with their weights) that need to be included to best describe the user's preferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2.">Document and Relevance Correlation (DRC)</head><p>Inspired by the RSV method discussed above and the cosine similarity measure in the Vector Space model <ref type="bibr" target="#b24">[25]</ref>, we designed a new profile generation method called the DRC method.</p><p>Suppose we have the following indicator function</p><formula xml:id="formula_4">I ij ¼ 1 if word j is in document i 0 otherwise 8 &lt; :</formula><p>For a given word j, its binary distribution in all training data can be represented using the following vector (assume we have only six documents):</p><formula xml:id="formula_5">I j ¼ h1 1 0 0 1 1i ð<label>5Þ</label></formula><p>Now suppose we have the following relevance information about the six documents</p><formula xml:id="formula_6">Rel ¼ h1 0 0 0 1 0i ð<label>6Þ</label></formula><p>where 0 means non-relevant and 1 means relevant. Then the similarity between word j's binary distribution in training data and the relevance judgment can be calculated following the Cosine similarity measure as follows:</p><formula xml:id="formula_7">S ¼ 1 þ 1 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi 1 þ 1 þ 1 þ 1 p Â ffiffiffiffiffiffiffiffiffiffiffi 1 þ 1 p ¼ 0:702<label>ð7Þ</label></formula><p>Mathematically, the above calculation can be generally represented as</p><formula xml:id="formula_8">RCV j ¼ X N i¼1 I ij Rel i ffiffiffiffiffiffiffiffiffiffiffiffi X N i¼1 I 2 ij s ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi X N i¼1 Rel 2 i s<label>ð8Þ</label></formula><p>We call this new criteria Relevance Correlation Value (RCV). Here ja1; 2; N M , where N M is the total number of unique words in the relevant training documents. I ij is an indicator function as defined above. Rel i is the relevance judgment (0 or 1) for document i.</p><p>Because I ij is either 1 or 0, and if we follow the conventional contingency table as shown in Table <ref type="table" target="#tab_0">1</ref> and drop the subscript j for simplification, then Eq. ( <ref type="formula" target="#formula_8">8</ref>) can be simplified to:</p><formula xml:id="formula_9">RCV ¼ A ffiffiffiffiffiffiffiffiffiffiffiffi A þ B p ffiffiffiffiffiffiffiffiffiffiffiffi ffi A þ C p<label>ð9Þ</label></formula><p>Following the design of RSV defined in Eq. ( <ref type="formula" target="#formula_2">3</ref>), DRC is defined to be</p><formula xml:id="formula_10">DRC ¼ p i RCV<label>ð10Þ</label></formula><p>where p i = P(w i = 1AR), which is the probability of the presence of word i given that a document is relevant. Note that the difference between DRC and RSV is that we replace the RW in the RSV formula with RCV in the DRC formula. The rationale is that the cosine measure can also be used to assign relevance weights for document terms based on relevance feedback information.</p><p>Making appropriate substitutions and simplification as done previously, Eq. ( <ref type="formula" target="#formula_10">10</ref>) can be reduced to:</p><formula xml:id="formula_11">DRC ¼ A 2 ffiffiffiffiffiffiffiffiffiffiffiffi A þ B p<label>ð11Þ</label></formula><p>We call the criteria defined in Eq. ( <ref type="formula" target="#formula_11">11</ref>) as the DRC method. This method combines the information of the word frequency in relevant documents and the association between the word's distribution information with the user's relevance judgments. As with RSV, all the words from the relevant documents are sorted in a decreasing order of DRC and the top ranked (profile size) words form the user profile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Machine learning approach using feature selection methods</head><p>The representative feature selection methods in machine learning, which have been found successful in various text routing and categorization experiments, include Information Gain used in decision tree learning, Chi-Square test used in categorical attribute independence test, and correlation coefficient, a variation of the Chi-Square test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">Information gain</head><p>Information gain is widely used as a feature selection tool in machine learning <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b29">30]</ref>. Features are the attributes in a data set. In our case, they refer to words in the training data set. Information gain is derived based on entropy measure in information theory.</p><p>Given a collection S, containing positive (relevant) examples and negative (non-relevant) examples, the entropy of S relative to this Boolean classification is</p><formula xml:id="formula_12">EntropyðSÞ ¼ Àplog 2 p À qlog 2 q<label>ð12Þ</label></formula><p>where p is the proportion of positive examples, q is the proportion of negative examples and p + q = 1. Entropy measures the impurity of an arbitrary collection of examples. Another interpretation of entropy from information theory is that it specifies the minimum number of bits of information needed to encode the classification (membership) of an arbitrary member of S. For example, if p = 1, then entropy is zero and no bits are required. If p = 0.5, then entropy is 1 and 1 bit is required to indicate the membership of a randomly drawn example. With the entropy defined as above, we can proceed to define information gain (IG). As a measure on the effectiveness of an attribute in classifying training examples, information gain is simply the expected reduction in entropy caused by partitioning the training examples according to this attribute. In other words using information theory, it also measures the number of bits of information obtained for relevance prediction by knowing the presence or absence of a word in a document. The bigger the IG value of a word, the higher the chance that the resence of such a word would help for relevance prediction.</p><p>The information gain of a word for relevance prediction is defined as follows:</p><formula xml:id="formula_13">IGðtÞ ¼ EntropyðSÞ À X vaðt;tÞ AS v A ASA EntropyðS v Þ<label>ð13Þ</label></formula><formula xml:id="formula_14">IGðtÞ ¼ ÀPðRÞlogPðRÞ À Pð RÞlogPð RÞ þ PðtÞðPðR j tÞlogPðR j tÞ þ Pð R j tÞlogPð R j tÞÞ þ Pð tÞðPðR j tÞlogPðR j tÞ þ Pð R j tÞlogPð R j tÞÞ<label>ð14Þ</label></formula><p>where P is the probability function. S t is the collection of documents containing word t and S t ¯is the collection of documents not containing word t. Note that À P(R)logP(R) À P(R ¯)logP(R ¯) is a constant and is the same for all words in Eq. ( <ref type="formula" target="#formula_13">13</ref>). So the equation can be simplified as follows:</p><formula xml:id="formula_15">IGðtÞ ¼ PðtÞðPðR j tÞlogPðR j tÞ þ Pð R j tÞlogPð R j tÞÞ þ Pð tÞðPðR j tÞlogPðR j tÞ þ Pð R j tÞlogPð R j tÞÞ<label>ð15Þ</label></formula><p>After making appropriate substitutions based on Table <ref type="table" target="#tab_0">1</ref>, this equation can be reduced to:</p><formula xml:id="formula_16">IGðtÞg 1 N Alog A A þ B þ Blog B A þ B þ Clog C C þ D þ Dlog D C þ D<label>ð16Þ</label></formula><p>The procedure of profile construction using information gain is similar to that of the previous two methods. For each unique word in the relevant training documents, we compute the information gain for that word. All the words are arranged in the decreasing value of IG and the top ranked (based on profile length) words form the user profile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2.">Correlation coefficient</head><p>Correlation coefficient C was first proposed by Ng et al. <ref type="bibr" target="#b13">[14]</ref> as a replacement of v 2 as a feature selection method for information retrieval experiments. Recall that in classical statistics, the v 2 is used to measure the independence between two categorical variables, which are word t and relevance R in our case. Higher Chi-Square values above the upper-tailed critical values (3.841 for a = 0.05) means there is a relationship between the word t and relevance R. Based on the definition in Ref. <ref type="bibr" target="#b13">[14]</ref> and using Table <ref type="table" target="#tab_0">1</ref>, the v 2 can be reduced to:</p><formula xml:id="formula_17">v 2 ¼ N Â ðAD À CBÞ 2 ðA þ CÞ Â ðB þ DÞ Â ðA þ BÞ Â ðC þ DÞ<label>ð17Þ</label></formula><p>Though v 2 has been widely used in machine learning for feature selection, recently it has been found that v 2 not only selects words that are indicative of relevance of a document, but also those that are indicative of non-relevance of a document as well. The empirical study by Ng et al. <ref type="bibr" target="#b13">[14]</ref> stated clearly this side effect. As a remedy for this side effect, they proposed a variation of v 2 as defined in Eq. ( <ref type="formula" target="#formula_17">17</ref>), called correlation coefficient C, as follows: <ref type="bibr" target="#b13">[14]</ref>. Ng et al. claimed that the new C can help pick up those words that only come from relevant documents and are indicative of relevance of a document. Now since A + C and B + D are constants for all words, they are omitted from calculation. Eq. ( <ref type="formula" target="#formula_18">18</ref>) can be simplified as</p><formula xml:id="formula_18">C ¼ ffiffiffiffi N p Â ðAD À CBÞ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ðA þ CÞ Â ðB þ DÞ Â ðA þ BÞ Â ðC þ DÞ p<label>ð18Þ</label></formula><formula xml:id="formula_19">It is not difficult to see that C 2 ¼ v 2 . So C can be viewed as a ''one-sided'' v 2 metric</formula><formula xml:id="formula_20">C ¼ ffiffiffiffi N p Â ðAD À CBÞ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ðA þ BÞ Â ðC þ DÞ p<label>ð19Þ</label></formula><p>Similar to the procedure of building profile using information gain, we can calculate the C value for every unique word in relevant documents and only the top few words (the profile size) can be selected to represent the user profile. There are also other related research areas in user modeling and personal browser/search agent <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b17">18]</ref>. These approaches are often modifications of the above mentioned research in terms of profile representation.</p><p>In summary, the above reviewed methods (except DRC, which is our own design) are the dominant profile construction methods in IR. Shutze et al. <ref type="bibr" target="#b25">[26]</ref> did a limited comparison between Chi-Square and Rocchio relevance feedback framework. No existing routing or push literature can be found to help vendors decide which method works best among methods examined in this paper. We seek to bridge the gap by doing a comparative study of these methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approaches to match incoming documents with profiles</head><p>In order to systematically test the efficacy of the four profile generation methods discussed in Section 2, three well-known (considered universally good) routing systems are deployed to perform this cross-system empirical study: Okapi system <ref type="bibr" target="#b22">[23]</ref>, INQUERY system <ref type="bibr" target="#b28">[29]</ref> and SMART system <ref type="bibr" target="#b26">[27]</ref>. These systems differ mainly on the matching functions. The matching functions utilized by these three systems are summarized as follows:</p><p>1. Okapi BM25 <ref type="bibr" target="#b22">[23]</ref> Sim O ðP; DÞ ¼ X</p><formula xml:id="formula_21">T aP 3 Â tf 0:5 þ 1:5 Â length length avg þ tf Â log N À df þ 0:5 df þ 0:5 Â QTW<label>ð20Þ</label></formula><p>2. Pivoted TFIDF <ref type="bibr" target="#b26">[27]</ref> Sim P ðP; DÞ ¼ X</p><formula xml:id="formula_22">TaP 1 þ logðtf Þ 1 þ logðtf avg Þ Â log N þ 1 df Â 1 0:8 þ 0:2 Â length length avg Â QTW<label>ð21Þ</label></formula><formula xml:id="formula_23">3. INQUERY [29] Sim I ðP; DÞ ¼ X TaP 0:4 þ 0:6 Â 0:4 Â H þ 0:6 Â logðtf þ 0:5Þ logðtf max þ 1:0Þ Â log N df À Á logðN Þ Â QTW<label>ð22Þ</label></formula><p>where tf is the term frequency of a term (word) in the document text; QTW is the term weighting strategy of a term (word) in the query text. tf is commonly used as the default weighting strategy. N is the total number of documents in the collection; df is the number of documents in the collection in which the term under consideration is present; 'length' is the length of the document (in words); length avg is the average document length in the collection (in words); tf avg is the average term frequency of all the terms in the collection; tf max is the maximum term frequency of all the terms in the collection; H = 1.0 if tf max V 25, 25/tf max otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Research questions</head><p>We seek to answer the following questions in this paper:</p><p>(1) Which profile method performs better for the same individual matching function? ( <ref type="formula" target="#formula_1">2</ref>) Is the answer in (1) generalizable to different matching functions? That is, is there such a profile generation method that gives the optimal performances for all matching functions? (3) What is the best way to assign weights for user profile terms?</p><p>Various studies <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22]</ref> suggest that the weight assignment for profile terms is very important for the routing performance. Two obvious ways of assigning weights will be studied: the simple term frequency of terms in user-provided topics/queries or the obtained weights from the various profiling method formulae. (4) Should a user's profile contain a fixed number of terms or varying number of terms?</p><p>In TREC conference <ref type="bibr" target="#b8">[9]</ref>, several participants use a fixed number of term representation scheme for profile representation, which is also adopted in other comparative studies <ref type="bibr" target="#b25">[26]</ref>. The fixed number scheme is obviously a simplification of the profile representation task to reduce the learning overhead involved in largescale applications. It is of interest to know and test empirically what is the performance penalty using this scheme and would this penalty warrant its wide application for profile representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Data</head><p>Following the suggestion of the TREC 7 routing track <ref type="bibr" target="#b8">[9]</ref>, we use the text corpus from Associate Press, which consists of 3 years (1988 -1990) news-wire <ref type="bibr" target="#b8">[9]</ref>. The AP news-wire covers a broad variety of domains and the documents average roughly 450 words in length. A sample document is shown in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>We use AP88 data set (79,919 documents) as the training data to learn the profiles, AP89 and AP90 (162,999 documents) data sets as the test data to test the efficacy of these profile generation methods and perform cross-system comparison. These data sets were chosen as they follow the time sequence, i.e. AP88 is for the year 1988, AP89, and AP90 are for the years 1989, and 1990, respectively. Hence training is done on 1988 data, while testing is done on the 1989 and 1990 data.</p><p>There are a total of 50 different user-provided topics/queries used in the TREC 7 routing experiment. One sample topic is shown in Fig. <ref type="figure">2</ref>. All the 242,918 documents in the AP collection were judged for relevance by experts for these 50 topics.</p><p>A total of 42 (out of 50) topics are chosen for the profile learning experiment because there are less than 4 (6 of 8 even have 0 relevant documents for training) relevant documents available for training for the remaining 8 (out of 50) topics. Such a small number of relevant documents in these eight topics will not help profile learning method to learn representative profiles. So all results reported in profile learning studies are for those remaining 42 topics, each of which has more than 3 (&gt; = 4) relevant documents in the training data. We leave the examination of effect of very few relevant documents for future studies. A possible (although approximate) way around this problem of very few relevant documents is to include semantically similar documents in the relevant set.</p><p>These 42 topics are the original questions raised from users to represent their interests and thus they can be used to generate explicit profiles as discussed in Section 1. We are going to treat these explicit profiles as baselines and compare their performance with those implicit profiles constructed by the 4 profile generation methods (RSV, IG, DRC, and CC) discussed in Section 2.</p><p>Two different versions of these 42 topics were indexed. In one version, only the title portion of the topics is indexed. These profiles are called short user-provided profiles or short explicit profiles. This is to simulate a scenario in which the query length is very short <ref type="bibr" target="#b9">[10]</ref> possibly due to users unwillingness to provide a lengthy description about his/her information needs. The number of title terms contained in the 42 short user-provided profiles varies from 4 to 18. In the other version, we indexed all the components of the 42 topics (title, description, narrative, and concepts). Correspondingly, these longer profiles are called long user-provided profiles or long explicit profiles. The number of terms for 42 long userprovided profiles varies from 17 to 96. This represents those situations when a user is willing to provide a lengthy description about his/her information need.</p><p>The topics and the relevant document distribution information for the experiment is summarized in Table <ref type="table" target="#tab_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Performance measure</head><p>Following the convention of TREC 7 routing system evaluation procedures, the performance of various routing systems is also evaluated using the standard performance measure called Average Precision (P _ avg), which is calculated as follows:</p><p>The average of precision score is calculated every time a relevant document is found, normalized by total number of relevant documents in the entire collection. Mathematically it can be expressed as:</p><formula xml:id="formula_24">P avg ¼ X TRel i¼1 P i =TRel; where P i ¼ i=Rank i<label>ð23Þ</label></formula><p>Here TRel is the total number of relevant documents for a given query, and Rank i is the ranking position for the ith relevant document. All results reported in the following result section are based on P _ avg.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Experimental design</head><p>As mentioned above, the purpose of our experiments is to empirically compare different profile learning approaches and see their performance in real text routing experiments under various control conditions. We follow a full factorial design to test for statistical significance. The configuration of the experiment is summarized in Table <ref type="table">3</ref>.</p><p>As shown in Table <ref type="table">3</ref>, there are four main factors in our study: profile, weight, system and size. Taking into account various levels for each factor, there are total 4 Â 2 Â 3 Â 20 = 480 configu-Fig. <ref type="figure">2</ref>. Sample topic description in TREC 7. rations of experimental conditions. For each configuration of experimental condition, all 42 queries are run and results are recorded for data analysis. So in total there are 21,060 data points collected for analysis.</p><p>The description of each factor follows. Four different profile learning methods (RSV, IG, DRC, and CC), as discussed in Section 2, are used. Three different routing/matching functions (Okapi BM25, INQUERY, and SMART Ptfidf) as discussed in Section 3 are used. Profile Weighting means how the weights are assigned for each term in the profile. There are 2 ways of assigning term weights for profile terms: Query Term Frequency (QTF) and Obtained Weights (OW) <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b19">20]</ref>. QTF means that the original term frequency from the user-provided profile is used to assign weights for profile terms. If the profile term in the learned profile is from the relevant documents and is not provided by the user, its QTF is assigned 1. A second way to assign weights to the profile terms is to use the relevance weights obtained by the various term selection formula discussed in Section 2. These weights are called OW in Table <ref type="table">3</ref>. The factor P _ size refers to the size of the profile, i.e. how many terms are there in each profile. For experimental purpose this is varied from 10 to 200 in increments of 10. A very low value means the profile is very selective while a high value means the profile is very general. A selective profile is desired for a narrow focused search and retrieval, while a more general profile is desired when the search can be broad but still within the overall context of the subject topic.</p><p>In order to answer the research questions raised above, the performance of user-provided profiles (explicit profiles) is used as a baseline for benchmark comparison with that of implicit profiles learned by best profile methods for each routing system. These best profile generation methods are identified based on the performance results of various profiling methods on the training data for each routing system. Since there are three routing systems used: Okapi, SMART and INQUERY, three best profiling methods will be identified (one for each routing system). A final comparison of these three profiling methods will help answer the research questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results and discussions</head><p>All experiments were run on an IBM Linux server. All programs were coded in C. Analysis of variance (ANOVA) statistical analysis was applied to the experimental data to help answer some of the research questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">ANOVA analysis</head><p>The model is set up as follows (in SAS syntax):</p><formula xml:id="formula_25">Full Model: p avg ¼ systemAprofileAweightAp size<label>ð24Þ</label></formula><p>Basically, we use p _ avg as the dependent variable and those main factors and their full factorial interaction are used as independent variables.</p><p>The results of ANOVA analysis are summarized in Table <ref type="table" target="#tab_2">4</ref>.</p><p>As can be easily seen from Table <ref type="table" target="#tab_2">4</ref>, all the main factors-system, profile, weight and p _ size-have significant impacts on the overall routing performance results ( p &lt; 0.0001). However, because most of the higher-order interactions are significant ( p &lt; 0.05), these main effects really do not convey any more meaningful information since these highorder interactions suggests that the performance under one factor is also under the influence of another factor and these influences do not work consistently <ref type="bibr" target="#b18">[19]</ref>.</p><p>We begin with the highest interaction term. The four-way interaction between these four factors are non-significant ( F = 0.10, p( = 1.0000)&gt;0.05), suggesting that such four-way interaction among these factors does not exist overall. All the three-way interactions are not significant except for profile Â weight Â system, which suggests that selecting appropriate profiling methods along with the weighting strategies will greatly impact the routing systems' performance. Profile size (p _ size), though, does not have interaction impacts with the weighting strategies used ( p = 0.2176&gt;0.05), it does impact the performances for different profiles ( p(profile Â p _ size) &lt;0.0001) and for different systems ( p(system Â p _ size) &lt; 0.0001).</p><p>The strong statistical significance of the main effects and those interaction effects of the main factors again statistically warrants the main argument of our research: the selection of appropriate profiling methods is a key factor for the success of a routing system. However, it is not clear from the above analysis how the scales of these impacts look like in real routing performance. We will next look at these issues in more detail by performing graphical and statistical analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">A look from the perspective of profiling methods</head><p>The performance of the four profile generation methods under different experimental conditions is summarized in Figs. <ref type="figure">3</ref><ref type="figure" target="#fig_1">4</ref><ref type="figure">5</ref><ref type="figure">6</ref>. In each figure, each point represents the performance result measured by P _ avg, averaged over all 42 profiles. These results are reported for various profile sizes by using different combinations of routing systems and profile weighting strategies.</p><p>As can be seen from these four figures, various profile generation methods indeed produce different performance results for routing experiments. The magnitude of these impacts can be easily seen after   examining these diagrams. There are several observations that can be made from these four figures:</p><p>(a) One thing that is consistent in these four figures is that all profiling methods work best when combined with Okapi system (Multiple comparison tests (Tukey) also show that these differences between Okapi and other systems for the same profiling methods are all statistically significant ( p's &lt; 0.001)). This can be clearly verified by the dramatic performance gap between Okapi with other routing systems. This result concurs with past TREC results and re-confirms that Okapi BM25 matching function certainly has a huge advantage in routing experiments. (b) RSV, IG, and DRC profiling methods when used with Okapi system show that the performance is not affected by the number of terms in a profile when the number reaches a certain value (range of 60 to 80). CC seems to be very different from other profile generation methods in that it requires more terms in its profiles to gain in performance.</p><p>As can be seen from Fig. <ref type="figure">5</ref>, as the number of terms increase in user profiles, its performance in Okapi system also improves and stabilizes when the number of terms is near 190. (c) One point that deserves further attention here is the performance of the DRC profiling method, which is our own design. When QTF is used to assign values for profile terms, it has similar performance as compared with RSV and IG profiling methods when Okapi system is used. A follow-up t-test does not show any statistical difference. But when OW is the default profile value assignment method, its performance on all three routing systems is more stable (the least variance) than any other profile generation method when the number of terms in profile is above a threshold. Its performance is very similar to RSV in overall. IG seems to have the biggest performance drop when used in routing system other than Okapi. (d) It can be seen from these figures that the P _ avg value increases initially, remains steady for some time, and then decreases with increasing values of P _ size. The decrease in performance with increasing profile size may seem counter-intuitive. The reason why this happens is that when profile size is too large then there is higher likelihood of introducing noise words in the profile just to maintain the profile size. Presence of such noise words eventually leads to decreasing performance. Later in the paper we examine if there is a performance penalty to have a fixed profile size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.</head><p>3. An examination from the perspective of the routing systems</p><p>Figs. 3 -6 look at the performance comparisons for each profiling method. Another angle to look at the performance comparisons is from the routing systems perspective. This type of analysis will have more practical implications since it will help us understand better the practical impacts of different profiling methods given a routing system and help us better choose the best profiling method. The results of all profiling methods for each routing system are illustrated in Figs. <ref type="figure">7</ref><ref type="figure">8</ref><ref type="figure">9</ref>.</p><p>For Okapi system using the BM 25 formula, RSV QTF is the best overall profiling method when the number of terms in a profile varies from 10 to 200, as shown in Fig. <ref type="figure">7</ref>. However, the differences between RSV QTF, IG QTF, and DRC QTF are not significant (multiple comparison tests show that all pair-wise comparisons have p = 1.000&gt;0.05). CC profiling method is the worst method among the four examined, which is true especially when a small number of terms ( &lt; 90) are included in the profiles. As the number of terms included in the profiles increases, the performance gap between CC and other profiling methods decreases accordingly. Overall, RSV, IG and DRC, combined with QTF, do not see any performance gain as the number of terms in profiles increases.</p><p>INQUERY and SMART seem to display very similar patterns if we examine the performance results in Figs. <ref type="figure">8</ref> and<ref type="figure">9</ref>. Both figures show a falling trend as the number of terms in profiles increase, which is quite different from that of Okapi. RSV, IG and DRC, when combined with QTF, perform well when the number of terms in a profile is small (30 to 50). However, their performance begins to fall off when the number of terms in profiles increases. The OW term weight assignment seems to work well for larger profiles. DRC OW performs very consistently even with the variation of profile size, though its performance may not be the best among all methods. of terms in the user profiles that obtain the best performance value. This table clearly shows the advantage of RSV over other profile generation methods. For example, RSV + QTF and RSV + OW perform almost equally well for all three routing systems examined. This is consistent with the conclusions we got earlier. However, this conclusion is not applicable to other methods. When QTF is used, both RSV and DRC require a small number of terms in profiles to gain optimal performance. Among the methods examined, CC performs the worst across the board. Its performance gains over the baselines are even negative in INQUERY and SMART. Overall, RSV + QTF is the best profile generation method in all three routing systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.">Aggregation results</head><p>One result that appears to emerge from Table <ref type="table">5</ref> is that QTF appears to be better than OW for all the combinations of profile generation methods (except CC) and routing systems. To take a closer look at this issue, an aggregated result for all these profile methods across systems are summarized in Table <ref type="table" target="#tab_3">6</ref> using results from Table <ref type="table">5</ref>. As can be seen from this table, QTF clearly has advantages over OW for DRC method, with 0.02 difference. However, the edge of QTF over OW is not very significant for RSV and IG. So if we leave out CC from our discussion, we can say that QTF term weighting strategy is better overall than OW term weighting strategy.</p><p>Another aggregation across profile generation methods for all three routing systems is done to see which system gives the best performance. The results are shown in Table <ref type="table">7</ref>. The column ''Average'' is obtained by averaging results in Table <ref type="table">5</ref> by row. Column ''Maximum'' is also derived from Table <ref type="table">5</ref> and corresponds to the maximum performance results among all profile methods for each row. ''Method Used'' is the profile method used to obtain the maximum performance in column ''Maximum''. An obvious conclusion that can be made from this table is that Okapi is superior to other routing systems in terms of both average and maximum performance and RSV + QTF is the overall best profile generation method. A follow-up multiple comparison test with Tukey grouping on system factor has shown that the difference between the performance figures of the routing systems is statistically significant with Okapi being the best routing system overall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6.">The effect of query difficulty</head><p>It is clear from above results and discussions that RSV + QTF is the overall best profile generation method. The above analysis is done mainly from a macro level by analyzing the averaged or aggregated results. One of the interesting questions to ask on a micro level is: How is profile learning affected by the query difficulty? It is known in IR and common practice that for some topics/queries it is very hard to find any relevant documents, while for others it may be very easy to locate new relevant documents. We call this a phenomenon of query difficulty. In order to study the query difficulty and its effects on the routing performance, we compare the performance results of RSV + QTF with that of baseline, i.e. long queries provided by the user. For any given query, the query difficulty can be measured by the magnitude of its routing performance measured in P _ avg. If P _ avg is very high, then it means the query is relatively easy. If P _ avg is very low, then it means high query difficulty. The results are illustrated in Fig. <ref type="figure" target="#fig_0">10</ref>.</p><p>In Fig. <ref type="figure" target="#fig_0">10</ref>, each circle represents 1 of the 42 queries. If the circle is above (below) the bisecting line, then performance obtained by profile learning over original user provided profile (explicit profile/query) is better  (worse). The query difficulty decreases as we move away from the origin (0.0, 0.0). A closer examination of Fig. <ref type="figure" target="#fig_0">10</ref> does not reveal any strong pattern. For difficult queries, which are closer to the origin, profile learning shows some mixed results. As the query difficulty decreases when we move away from the origin, however, we can achieve a significant amount of improvement in performance. This is due to the fact that more relevant training documents are easily available for less difficult queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7.">Fixed number of terms in a profile?</head><p>Another interesting question to ask on the micro level is: How does the overall best performing profile generation method fare against manually selected best performance for each individual query? We know from Table <ref type="table">5</ref> that RSV + QTF obtained the best performance with 80 terms selected in user profiles for all 42 queries. Even though RSV + QTF 80 is the best performing method overall, it may not be best for each individual query. For example, there is a high probability that the number of terms included in a profile, which obtains the best performance for this particular query, is not 80. The answer to this question has significant impact for routing experiment strategies. Is it really worthwhile to find the optimal number of terms to be included in each profile? Can we not use a fixed number, like 80, for all profile representation? A comparison between the performance of RSV + QTF 80 and the maximum performances for each individual query is done and the results are summarized in Fig. <ref type="figure" target="#fig_4">11</ref>.</p><p>Similar interpretation, as in Fig. <ref type="figure" target="#fig_0">10</ref>, can be used here. Any circle close to the bisecting line means very close performance. It is not difficult to see that these two maxima obtained in different ways are close to each other, with certain exceptions. This argues for using fixed number of terms in profile representation simply because it is simple and there is not much performance penalty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions and future research directions</head><p>In this paper, we systematically compared profile generation methods and their variations using three well-known routing systems. The following conclusions can be drawn:</p><p>-Implicit profiles generated by profile learning methods are generally superior to explicit profiles specified by users. -Among the four methods for profile generation, RSV combined with QTF gives the best performance on average for all 42 queries for a given routing system. This result is also generalizable to other routing systems. -In general, the term weights assigned to profile terms using original term frequency are better than those assigned using the weights calculated from profile generation formula. -Among the four methods for profile generation, profile generated by RSV is the most robust one. It is not very sensitive to the weight assigning methods: QTF or OW. -Although overall RSV is the most robust and best performing method, the difference between RSV and IG, and RSV and DRC are not statistically significant when QTF is used as the term weighting strategy for profile terms. In particular, both DRC and IG perform equally well when combined with QTF weighting strategy for terms included in the profiles. -Given the same profiles, there are still huge statistical performance differences when different routing systems are used. The performance of Okapi BM25 formula is statistically significantly better than that of INQUERY formula and SMART Ptfidf formula for all different profiles.</p><p>These conclusions can help push system vendors or designers to better capture and represent users' information needs. We believe the success of the profile representation will be a key step towards improving push(routing) service quality without overloading consumers with non-relevant information.</p><p>This work can be extended in several directions.</p><p>One of the conclusions that can be inferred from above discussions is that these profile generation methods select different terms to be included in the profiles. One way of extending this work is to apply the majority-voting strategy or other ensem-bling techniques <ref type="bibr" target="#b1">[2]</ref> to choose terms to be included in user profiles. This deserves more study. It is well known in IR literature that matching function has a dramatic impact on the performance of search engines, as well as routing systems as shown above. Okapi formula seems to be very robust in overall performance, but it is still questionable whether Okapi BM 25 is the single best ranking function for each individual user profile. One interesting question to study is to see whether profile learning methods, such as RSV with QTF, can be complemented by other matching function adaptation algorithms, like GA <ref type="bibr" target="#b16">[17]</ref> and GP <ref type="bibr">[4 -6]</ref> to further improve the routing performance. We leave this for future research. We can explore the effect of type of retrieval task. Some tasks might be more difficult to retrieve than others because of the involved structure and semantics.</p><p>It would be interesting to see how to combine the implicit profiles with the explicit profiles that the customer has. Such a combination would hopefully lead to enhanced routing performance. One way this could be done is to map categories from both implicit and explicit profiles and elevate the weight associated with such overlapped words.</p><p>In this paper we have utilized well-known routing functions. Future research can attempt to explore how other techniques like natural language processing, name entity extraction, and information extraction could be applied in the context of profile generation and maintenance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Sample document from AP news-wire collection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Effects of IG variations on routing performance measured by P _ avg.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Fig. 5. Effects of CC variations on routing performance measured by P _ avg.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 7 .Fig. 8 .</head><label>78</label><figDesc>Fig. 7. Effects of profiling methods on Okapi routing performance measured by P _ avg.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Maximum performance (P _ avg) by RSV versus fixed RSV 80.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Contingency table for word j</figDesc><table><row><cell></cell><cell>Relevant</cell><cell>Non-relevant</cell><cell></cell></row><row><cell>Word j = 1</cell><cell>A</cell><cell>B</cell><cell>A + B</cell></row><row><cell>Word j = 0</cell><cell>C</cell><cell>D</cell><cell>C + D</cell></row><row><cell></cell><cell>A + C</cell><cell>B + D</cell><cell>N</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Data set used for routing experiments</figDesc><table><row><cell>Topic</cell><cell>Number of</cell><cell>Number of</cell><cell></cell><cell></cell><cell></cell></row><row><cell>number</cell><cell>relevant documents</cell><cell>relevant documents</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>(Training)</cell><cell>(Test)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>122</cell><cell>344</cell><cell></cell><cell></cell><cell></cell></row><row><cell>2</cell><cell>260</cell><cell>459</cell><cell></cell><cell></cell><cell></cell></row><row><cell>3</cell><cell>60</cell><cell>220</cell><cell></cell><cell></cell><cell></cell></row><row><cell>4</cell><cell>3 0</cell><cell>9 4</cell><cell></cell><cell></cell><cell></cell></row><row><cell>5</cell><cell>2 8</cell><cell>6 8</cell><cell></cell><cell></cell><cell></cell></row><row><cell>6</cell><cell>71</cell><cell>270</cell><cell></cell><cell></cell><cell></cell></row><row><cell>7</cell><cell>116</cell><cell>311</cell><cell></cell><cell></cell><cell></cell></row><row><cell>8</cell><cell>2 8</cell><cell>6 6</cell><cell></cell><cell></cell><cell></cell></row><row><cell>9</cell><cell>28</cell><cell>107</cell><cell></cell><cell></cell><cell></cell></row><row><cell>10</cell><cell>85</cell><cell>265</cell><cell></cell><cell></cell><cell></cell></row><row><cell>11</cell><cell>125</cell><cell>427</cell><cell></cell><cell></cell><cell></cell></row><row><cell>12</cell><cell>180</cell><cell>624</cell><cell></cell><cell></cell><cell></cell></row><row><cell>13</cell><cell>8</cell><cell>86</cell><cell></cell><cell></cell><cell></cell></row><row><cell>14</cell><cell>43</cell><cell>116</cell><cell></cell><cell></cell><cell></cell></row><row><cell>15</cell><cell>59</cell><cell>107</cell><cell></cell><cell></cell><cell></cell></row><row><cell>16</cell><cell>28</cell><cell>142</cell><cell></cell><cell></cell><cell></cell></row><row><cell>17</cell><cell>89</cell><cell>224</cell><cell></cell><cell></cell><cell></cell></row><row><cell>18</cell><cell>62</cell><cell>130</cell><cell></cell><cell></cell><cell></cell></row><row><cell>19</cell><cell>59</cell><cell>269</cell><cell></cell><cell></cell><cell></cell></row><row><cell>20</cell><cell>47</cell><cell>158</cell><cell></cell><cell></cell><cell></cell></row><row><cell>21</cell><cell>21</cell><cell>29</cell><cell></cell><cell></cell><cell></cell></row><row><cell>22</cell><cell>395</cell><cell>1238</cell><cell></cell><cell></cell><cell></cell></row><row><cell>23</cell><cell>77</cell><cell>237</cell><cell></cell><cell></cell><cell></cell></row><row><cell>24</cell><cell>111</cell><cell>300</cell><cell></cell><cell></cell><cell></cell></row><row><cell>25</cell><cell>23</cell><cell>65</cell><cell></cell><cell></cell><cell></cell></row><row><cell>26</cell><cell>7</cell><cell>61</cell><cell></cell><cell></cell><cell></cell></row><row><cell>27</cell><cell>7</cell><cell>20</cell><cell></cell><cell></cell><cell></cell></row><row><cell>28</cell><cell>7</cell><cell>66</cell><cell></cell><cell></cell><cell></cell></row><row><cell>29</cell><cell>4</cell><cell>7</cell><cell></cell><cell></cell><cell></cell></row><row><cell>36</cell><cell>4</cell><cell>10</cell><cell></cell><cell></cell><cell></cell></row><row><cell>38</cell><cell>43</cell><cell>276</cell><cell></cell><cell></cell><cell></cell></row><row><cell>40</cell><cell>74</cell><cell>236</cell><cell></cell><cell></cell><cell></cell></row><row><cell>41</cell><cell>12</cell><cell>74</cell><cell></cell><cell></cell><cell></cell></row><row><cell>42</cell><cell>66</cell><cell>151</cell><cell></cell><cell></cell><cell></cell></row><row><cell>43</cell><cell>25</cell><cell>102</cell><cell></cell><cell></cell><cell></cell></row><row><cell>44</cell><cell>28</cell><cell>152</cell><cell></cell><cell></cell><cell></cell></row><row><cell>45</cell><cell>51</cell><cell>52</cell><cell></cell><cell></cell><cell></cell></row><row><cell>46</cell><cell>26</cell><cell>74</cell><cell></cell><cell></cell><cell></cell></row><row><cell>47</cell><cell>26</cell><cell>89</cell><cell></cell><cell></cell><cell></cell></row><row><cell>48</cell><cell>6</cell><cell>30</cell><cell></cell><cell></cell><cell></cell></row><row><cell>49</cell><cell>15</cell><cell>55</cell><cell>Table 3</cell><cell></cell><cell></cell></row><row><cell>50</cell><cell>5</cell><cell>6</cell><cell cols="4">Profile learning experimental setup</cell></row><row><cell>Sum.</cell><cell>2561</cell><cell>7817</cell><cell>Factor</cell><cell>Meaning</cell><cell cols="2">Levels Values</cell></row><row><cell>Avg.</cell><cell>61</cell><cell>186</cell><cell>label</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Profile</cell><cell>Profiling</cell><cell>4</cell><cell>RSV, IG, DRC and CC</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>method</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Weight Profile</cell><cell>2</cell><cell>Query Term Frequency</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>weighting</cell><cell></cell><cell>(QTF), Obtained Weights (OW)</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">System Matching</cell><cell>3</cell><cell>Okapi, INQUERY, SMART</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>function</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>p _ size</cell><cell cols="2">Profile size 20</cell><cell>10, 20, 30, . . ., 200</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>ANOVA analysis results</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Source</cell><cell>df</cell><cell>F value</cell><cell>Pr&gt;F</cell></row><row><cell>System</cell><cell>2</cell><cell>597.33</cell><cell>&lt; 0.0001</cell></row><row><cell>Profile</cell><cell>3</cell><cell>410.29</cell><cell>&lt; 0.0001</cell></row><row><cell>Weight</cell><cell>1</cell><cell>17.08</cell><cell>&lt; 0.0001</cell></row><row><cell>p_size</cell><cell>19</cell><cell>9.27</cell><cell>&lt; 0.0001</cell></row><row><cell>Profile Â system</cell><cell>6</cell><cell>57.23</cell><cell>&lt; 0.0001</cell></row><row><cell>Weight Â system</cell><cell>2</cell><cell>15.88</cell><cell>&lt; 0.0001</cell></row><row><cell>Profile Â weight</cell><cell>3</cell><cell>16.18</cell><cell>&lt; 0.0001</cell></row><row><cell>System Â p_size</cell><cell>38</cell><cell>7.73</cell><cell>&lt; 0.0001</cell></row><row><cell>Profile Â p_size</cell><cell>57</cell><cell>2.12</cell><cell>&lt; 0.0001</cell></row><row><cell>Weight Â p_size</cell><cell>19</cell><cell>1.24</cell><cell>0.2176</cell></row><row><cell>Profile Â weight Â system</cell><cell>6</cell><cell>4.31</cell><cell>0.0002</cell></row><row><cell>Profile Â system Â p_size</cell><cell>114</cell><cell>0.72</cell><cell>0.9902</cell></row><row><cell>Weight Â system Â p_size</cell><cell>38</cell><cell>0.47</cell><cell>0.9975</cell></row><row><cell>Profile Â weight Â p_size</cell><cell>57</cell><cell>0.64</cell><cell>0.9835</cell></row><row><cell>Profile Â weight Â system Â p_size</cell><cell>114</cell><cell>0.10</cell><cell>1.0000</cell></row></table><note><p>Fig. 3. Effects of RSV variations on routing performance measured by P _ avg.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell cols="8">Aggregated cross-system results for different profile generation</cell></row><row><cell>methods</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>RSV</cell><cell></cell><cell>IG</cell><cell></cell><cell>CC</cell><cell></cell><cell>DRC</cell><cell></cell></row><row><cell>QTF</cell><cell>OW</cell><cell>QTF</cell><cell>OW</cell><cell>QTF</cell><cell>OW</cell><cell>QTF</cell><cell>OW</cell></row><row><cell cols="8">0.3444 0.3417 0.3389 0.3339 0.2379 0.2411 0.3379 0.3171</cell></row></table><note><p>Fig. 10. Performance (P _ avg) of RSV 80 versus initial query difficulty.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We will use push and routing interchangeably.W. Fan et al. / Decision Support Systems 40 (2005)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p> </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>W. Fan et al. / Decision Support Systems 40 (2005) 213-233</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Weiguo Fan is an assistant professor of information systems and computer science at the Virginia Polytechnic Institute and State University. He recieved his Ph.D. in Information Systems from the University of Michigan Business School, Ann Arbor, in July 2002. His research interests include personalization, data mining, text/web mining, web computing, business intelligence, digital library, and knowledge sharing and individual learning in online communities. His research has appeared in many prestigious information technology journals such as Information Processing and Management (IP&amp;M), IIEE Transactions on knowlegde and Data Engineering (TKDE), Information Systems (IS), Decision Support Systems (DSS), ACM Transactions on Internet Technology (TOIT), Journal of the American Society for Information Science and Technology (JASIST), Journal of Classification, International Journal of Electronic Business, and in leading information technology conference such as ICIS, HICSS, AMCIS, WWW, CIKM, DS, ICOTA, etc. Michael Gordon is a professor of business information technology and associate dean for information technology at the University of Michigan Business School. His research interests include information retrieval, especially adaptive methods and methods that support knowledge sharing among groups; information and communication technology in the service of social enterprise (promoting economic development, providing health care delivery, and improving educational oppurtunities for the poor); and using information technology along with social methods to support business education. He publishes extensively in leading IT journals such as Information Processing and Management (IP&amp;M), IEEE Transactions on the Knowledge and Data Engineering (TKDE), Decision Support Systems (DSS), ACM Transactions on Internet Technology (TOIT), Journal of the American Society for Information Science and Technology (JASIST), Information Systems Research, Communication of ACM. Dr. Praveen Pathak is an Assistant Professor of Decision and Information Sciences at the Warrington College of Business at the University of Florida. He recieved his Ph.D. in Computer and Information Systems from the University of Michigan Business School, Ann Arbor, in 2000. He also holds a MBA (PGDM) from Indian Institute of Management, Calcutta, and a Engineering degree, B. Tech. (Hons.), from the Indian Institute of Technology, Kharagpur. His research interests include information retrival, text mining, business intelligence, and knowledge management. His research has appeared in many prestigious journals such as Decision Support Systems (DSS), IEEE Transactions on Knowledge and Data Engineering (TKDE), Information Proceesing and Management (IP&amp;M), Journal of the American Society for Information Science and Technology (JASIST), and in leading information technology conferences such as ICIS, HICSS, WITS, etc.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Overall, the best performance results are still obtained by RSV QTF with profiles of very small size (30 to 40) for both INQUERY and SMART matching functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Benchmark comparison with the baseline</head><p>In order to see more clearly how the four implicit profile generation methods fare against each other and the baseline using user-provided long query (explicit profile), numerical results on these perfor-mance comparisons are summarized in Table <ref type="table">5</ref>. In this table, first column is the routing systems used in our experiments, where O stands for Okapi, I for INQUERY, and S for SMART. In each cell of the table starting column 3, three values are reported. The first value is the maximum P _ avg averaged over 42 queries among 20 different configurations (P _ avg from 10 to 200) of profile representation. The second value is the performance gain over baseline (reported in column 2 of the table) in percentage under the same routing system. The third value is the number Fig. <ref type="figure">9</ref>. Effects of profiling methods on SMART routing performance measured by P _ avg. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Webmate: a personal agent for browsing and searching</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sycara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Autonomous Agents (Agents&apos;98)</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Sycara</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Wooldridge</surname></persName>
		</editor>
		<meeting>the 2nd International Conference on Autonomous Agents (Agents&apos;98)<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="132" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Machine learning research: four directions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Al Magazine</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="97" to="135" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Using SVMs for text categorization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="21" to="23" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Personalization of search engine services for effective retrieval and knowledge management</title>
		<author>
			<persName><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pathak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2000 International Conference on Information Systems (ICIS)</title>
		<meeting>2000 International Conference on Information Systems (ICIS)<address><addrLine>Brisbane, Australia. AIS, Atlanta, GA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="20" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Discovery of context-specific ranking functions for effective information retrieval using genetic programming</title>
		<author>
			<persName><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pathak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="523" to="527" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A generic ranking function discovery framework by genetic programming for information retrieval</title>
		<author>
			<persName><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pathak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Data in your face: push technology in perspective</title>
		<author>
			<persName><forename type="first">M</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zdonik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1998 ACM SIGMOD Conference</title>
		<meeting>the 1998 ACM SIGMOD Conference<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="516" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The vocabulary problem in human -system communication</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="947" to="971" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The TREC-7 filtering track: description and analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Text Retrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>the Seventh Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">500</biblScope>
			<biblScope unit="page" from="33" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Real life, real users, and real needs: a study and analysis of user queries on the web</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Spink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Saracevic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="227" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Adaptive retrieval agents: internalizing local context and scaling up to the web</title>
		<author>
			<persName><forename type="first">F</forename><surname>Menczer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Belew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2/3</biblScope>
			<biblScope unit="page" from="203" to="242" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
		<title level="m">Machine Learning</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Experience with a learning personal assistant</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zabowsk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="81" to="91" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Feature selection, perceptron learning, and a usability case study for text categorization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Low</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 20th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM press</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="67" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">DSO at TREC-8: a hybrid algorithm for the routing task</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Ang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Soon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eighth Text Retrieval Conference (TREC-8)</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Harman</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">500</biblScope>
			<biblScope unit="page" from="267" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The importance of SDI for current awareness in fields with severe scatter of information</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Packer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Soergel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="125" to="135" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Effective information retrieval using genetic algorithms based matching function adaptation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Hawaii International Conference on System Science (HICSS)</title>
		<meeting>the 33rd Hawaii International Conference on System Science (HICSS)<address><addrLine>Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning and revising user profiles: the identification of interesting web sites</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Pazzani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Billsus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="313" to="331" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Measurement, Design, and Analysis: An Integrated Approach</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Pedhazur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Schmelkin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<pubPlace>Hillsdale, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On relevance weight estimation and query expansion</title>
		<author>
			<persName><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="182" to="188" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On term selection for query expansion</title>
		<author>
			<persName><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="359" to="364" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Relevance weighting of search terms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Document Retrieval Systems</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Willett</surname></persName>
		</editor>
		<imprint>
			<publisher>Taylor Graham</publisher>
			<date type="published" when="1976">1976. 1988</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="143" to="160" />
		</imprint>
	</monogr>
	<note>Reprinted in</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Text Retrieval Conference</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>the Fourth Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">500</biblScope>
			<biblScope unit="page" from="73" to="97" />
		</imprint>
	</monogr>
	<note>Okapi at TREC-4</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Relevance feedback in information retrieval</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Rocchio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The SMART Retrieval System-Experiments in Automatic Document Processing</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Salton</surname></persName>
		</editor>
		<meeting><address><addrLine>Prentice-Hall, Englewood Cliffs, NJ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<title level="m">The SMART Retrieval System: Experiments in Automatic Document Processing</title>
		<meeting><address><addrLine>New Jersey</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A comparison of classifiers and document representations for the routing problem</title>
		<author>
			<persName><forename type="first">H</forename><surname>Schutze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of of the 16th ACM SIGIR&apos;95</title>
		<meeting>of the 16th ACM SIGIR&apos;95<address><addrLine>Seattle, USA; New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="229" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Document length normalization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="619" to="633" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<date type="published" when="1979">1979</date>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
	<note>Butterworth</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Query expansion using local and global document analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="4" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A comparative study on feature selection in text categorization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th International Conference on Machine Learning</title>
		<meeting>14th International Conference on Machine Learning<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="412" to="420" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
