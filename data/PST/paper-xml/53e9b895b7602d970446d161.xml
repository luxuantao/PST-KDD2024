<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Comparative Study on Classification of Sleep Stage Based on EEG Signals Using Feature Selection and Classification Algorithms</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-03-09">9 March 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Baha</forename><surname>Şen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Musa</forename><surname>Peker</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Abdullah</forename><surname>Çavuşoğlu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">V</forename><surname>Fatih</surname></persName>
						</author>
						<author>
							<persName><surname>Çelebi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Çelebi</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Computer Engineering Department</orgName>
								<orgName type="institution">Yıldırım Beyazıt University</orgName>
								<address>
									<settlement>Ulus, Ankara</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Computer Engineering Department</orgName>
								<orgName type="institution">Karabuk University</orgName>
								<address>
									<postCode>78050</postCode>
									<settlement>Karabuk</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Comparative Study on Classification of Sleep Stage Based on EEG Signals Using Feature Selection and Classification Algorithms</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-03-09">9 March 2014</date>
						</imprint>
					</monogr>
					<idno type="MD5">9B4BCDABC668DD5EB23982FD1CCD5AA0</idno>
					<idno type="DOI">10.1007/s10916-014-0018-0</idno>
					<note type="submission">Received: 19 September 2013 / Accepted: 23 February 2014 /</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>EEG signals</term>
					<term>Classification algorithms</term>
					<term>Feature selection algorithms</term>
					<term>Classification of sleep stage</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Sleep scoring is one of the most important diagnostic methods in psychiatry and neurology. Sleep staging is a time consuming and difficult task undertaken by sleep experts. This study aims to identify a method which would classify sleep stages automatically and with a high degree of accuracy and, in this manner, will assist sleep experts. This study consists of three stages: feature extraction, feature selection from EEG signals, and classification of these signals. In the feature extraction stage, it is used 20 attribute algorithms in four categories. 41 feature parameters were obtained from these algorithms. Feature selection is important in the elimination of irrelevant and redundant features and in this manner prediction accuracy is improved and computational overhead in classification is reduced. Effective feature selection algorithms such as minimum redundancy maximum relevance (mRMR); fast correlation based feature selection (FCBF); ReliefF; t-test; and Fisher score algorithms are preferred at the feature selection stage in selecting a set of features which best represent EEG signals. The features obtained are used as input parameters for the classification algorithms. At the classification stage, five different classification algorithms (random forest (RF); feed-forward neural network (FFNN); decision tree (DT); support vector machine (SVM); and radial basis function neural network (RBF)) classify the problem. The results, obtained from different classification algorithms, are provided so that a comparison can be made between computation times and accuracy rates. Finally, it is obtained 97.03 % classification accuracy using the proposed method.</p><p>The results show that the proposed method indicate the ability to design a new intelligent assistance sleep scoring system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Healthy sleep habits affect our daily lives in different ways. Performance at work, morale, mood and relationships with other individuals are but a few of them. In the medical world, sleep analysis is of vital importance in the identification of problems related to sleep. Sleep analysis leads to various psycho-physiological analyses. In human physiology, a healthy deep sleep stage is known to accelerate physical recuperation <ref type="bibr" target="#b0">[1]</ref>. In addition, a healthy rapid eye movement (REM) stage enhances learning skills and memory. In the identification of possible sleep problems, a sleep scoring process is needed in almost all procedures. Sleep scoring is the identification of sleep stages with the help of polysomnographic recording (PSG) during sleep. There have been a number of examinations of patients' PSG recordings; these include electroencephalogram (EEG); electrooculogram (EOG); and electromyogram (EMG) data <ref type="bibr" target="#b0">[1]</ref>. An expert evaluated these records by following the Rechtschaffen &amp; Kales (R&amp;K) rules which were identified in 1968. According to R&amp;K rules, each epoch (30-second data) is classified as awake (W); non-rapid eye movement (N-REM stage 1, N-REM stage 2, N-REM stage 3 and N-REM stage 4: from light to deep sleep); and REM.</p><p>Amongst the physiological signals, EEG signals are the signals used most often since they best represent the brain's activity <ref type="bibr" target="#b1">[2]</ref>. EEG waves (alpha, beta, delta and theta) show different characteristics during different sleep stages. Low amplitude, mixed EEG frequency, saw-tooth wave-like pattern, low amplitude EMG and high level EOG signals from both eyes, are apparent during the REM stage. During the N-REM stage 1, the highest amplitude with a frequency range of 2-7 Hz and the existence of alpha waves are found in EEG signal. The EMG level is lower when compared to the awake stage. Sleep spindles <ref type="bibr" target="#b11">(12)</ref><ref type="bibr" target="#b12">(13)</ref><ref type="bibr" target="#b13">(14)</ref> and k-complexes are observed during the N-REM stage 2. N-REM stage 3-4, the deep sleep stage, may consist of low frequency waves which are lower than 2 Hz, sleep spindles and k-complexes <ref type="bibr" target="#b2">[3]</ref>. Figure <ref type="figure" target="#fig_0">1</ref> represents the EEG signals obtained during the different sleep stages.</p><p>EEG data has highly complicated transformation patterns. These signals are not periodic and their amplitude, phase and frequencies constantly change. Therefore, extended periods are required for the measurements in order to obtain meaningful data <ref type="bibr" target="#b1">[2]</ref>. EEG data recorded for hours is analyzed by the doctors while it is played on the screen in 5-10 second frames <ref type="bibr" target="#b3">[4]</ref>. This process is rather exhaustive and hard. As can be seen, interpreting visual analysis and complex EEG signals for sleep staging is a difficult problem. Therefore, analyzing EEG signals with the help of a consistent and suitable method is necessary to obtain an effective and speedy sleep staging system. In order to assist the experts in their studies, a current study proposes an effective feature selection based method that will automatically undertake the sleep staging process.</p><p>The paper is organized in the following manner: Section 2 presents a brief literature review about classification of the sleep stages including information regarding the method suggested in the current study. Section 3 describes briefly the data set of the EEG signals employed in our research. This section presents information regarding the methods used in this study. You can find, also, information related to the performance evaluation criteria employed in the study. Section 4 provides the experiments undertaken in the framework of the study, the assessment procedures used and the experimental results obtained. Finally, Section 5 describes the conclusions derived from the study and some thoughts with regard to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related work</head><p>Recently, various models have been proposed for the classification of sleep stage. Feature extraction and classification algorithms commonly used in the literature are examined. Some of the studies with a high rate of classification accuracy have been listed below.</p><p>Algorithms such as standard deviation <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>, median <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>, arithmetic mean <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>, skewness <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>, kurtosis <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>, zero crossing value <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7]</ref>, variance value <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b10">11]</ref>, values of maximum and minimum <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7]</ref>, mean energy <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13]</ref>, mean teager energy <ref type="bibr" target="#b11">[12]</ref>, petrosian fractal dimension <ref type="bibr" target="#b12">[13]</ref>, rényi entropy <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b12">13]</ref>, spectral entropy <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14]</ref>, permutation entropy <ref type="bibr" target="#b14">[15]</ref>, approximate entropy <ref type="bibr" target="#b15">[16]</ref>, wigner ville coefficients <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11]</ref>, wavelet transform <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18]</ref>, mean curve length <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>, hurst exponent <ref type="bibr" target="#b15">[16]</ref> and Hjorth parameters <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b16">17]</ref> are commonly used for extracting features from EEG data.</p><p>In Holzmann et al. <ref type="bibr" target="#b18">[19]</ref> developed an expert system by using ganglionar lattices for infants. In this regard, they obtained a 96.4 % accuracy rate from data which did not contain artifacts. In their studies, the same authors also obtained a 84.9 % accuracy rate which included data consisting of artifacts. By using discrete wavelet transform for sleep staging, Oropesa et al. <ref type="bibr" target="#b19">[20]</ref> divided EEG waves into 7 specific frequency bands. The authors computed the energy of the bands and obtained a 76.6 % accuracy rate by transferring the obtained values into an artificial neural network (ANN) environment. In another study, Agarval and Gotman <ref type="bibr" target="#b20">[21]</ref> employed segmentation and clustering strategies that included the active participation of the sleep operator in the implementation and obtained an 80.6 % accuracy rate. In their studies, Estrada et al. <ref type="bibr" target="#b21">[22]</ref> utilized EEG signals and employed three different algorithms identified as relative spectral band energy, harmonic parameters and itakura distance. By using a different application from the other studies which used linear measurement, the authors undertook non-linear analysis of the EEG signals. These studies showed that non-linear measures could also be used effectively in the scoring process. Becq et al. <ref type="bibr" target="#b22">[23]</ref> investigated which classifier was most effective in sleep scoring, and compared 5 classification algorithms. These were: linear and quadratic classifiers; k nearest neighbors; parzen kernels; and neural networks algorithms. According to their findings, the best classifier was found to be neural networks with a 72 % scoring accuracy. Sinha <ref type="bibr" target="#b23">[24]</ref> classified three stages of a) sleep spindles b) REM sleep and c) awake stages, and obtained a 95.55 % classification rate in a study which employed the use of wavelet transform and ANN. On the other hand, Šušmáková and Krakovská <ref type="bibr" target="#b24">[25]</ref> used discriminant analysis using Fisher's quadratic classifier to study 73 characteristic measures in the sleep staging process. Chapotot and Becq <ref type="bibr" target="#b25">[26]</ref> proposed a new method which combined robust feature extraction, artificial neural network classification and flexible decision rules. They obtained an average accuracy rate of 78 %. In order to classify alert vs. drowsy states in arbitrary subjects, Subasi et al. <ref type="bibr" target="#b26">[27]</ref> used 5-s long sequences of full-spectrum EEG recordings and employed a wavelet-based neural network model, trained with the Levenberg-Marquardt algorithm, to discriminate the alertness level of the subject. This study's classification results were found to be 93.3 % for alert, 96.6 % for drowsy and 90 % for sleep states. Zoubek et al. <ref type="bibr" target="#b27">[28]</ref> used feed-forward neural network structure for the classification of sleep stages. They used EEG, electromyogram (EMG) and electrooculogram (EOG) data as input data to the neural network. By obtaining Fourier transform coefficients, entropy values, kurtosis value and standard deviation values from these signals, they presented as input to the network. Doroshenkov et al. <ref type="bibr" target="#b28">[29]</ref> developed a classification algorithm based on hidden Markov models using only EEG signals. Authors achieved best result in the classification of REM stage. Ebrahimi et al. <ref type="bibr" target="#b29">[30]</ref> used neural networks and wavelet packet coefficients to differentiate between different sleep stages. The authors have achieved a success rate of % 93 in the study of the 5 classified stages. Jo et al. <ref type="bibr" target="#b30">[31]</ref> obtained an accuracy rate of 84.6 % by using a 4 stage genetic fuzzy classifier. As a novel data pre-processing method, Gunes et al. <ref type="bibr" target="#b31">[32]</ref> proposed the combination of k-means clustering based feature weighting (KMCFW) with C4.5 decision tree in the classification of sleep stages. Whilst classifying sleep stages with ten-fold cross validation by using frequency domain features belonging to EEG signals, a decision tree was obtained with a classification accuracy rate of 37.84 %. Sleep stages were classified, with a 41.85 % accuracy rate, by employing a decision tree based on frequency domain features which belonged to EEG and chin EMG signals. A 92.40 % classification accuracy rate was achieved with regard to sleep stage classification using a decision tree in weighted frequency domain features belonging to an EEG signal using KMCFW. Tagluk et al. <ref type="bibr" target="#b32">[33]</ref> used feed-forward neural network structure for the classification of sleep stages. As an input to the neural network, they preferred EEG, EMG and (EOG) data. The authors have achieved a success rate of 74.7 % in the study of the 5 classified stages. Fraiwan et al. <ref type="bibr" target="#b33">[34]</ref> used timefrequency entropy values as an attribute in different frequency bands. They preferred linear discriminant analysis algorithm for the classification stage. The authors have achieved a success rate of % 84 in the study of the 6 classified stages. Ozsen <ref type="bibr" target="#b8">[9]</ref> used EEG, EMG and EOG data to classify the sleep stages. First, she obtained the time-frequency based attributes to represent this data. In the next step, to determine the effective attributes, sequential class-dependent feature selection algorithm was used. He presented the selected attributes as input to the neural network. In the study of the 5 classified stages, a success rate of % 90.93 was achieved. Hsu et al. <ref type="bibr" target="#b34">[35]</ref> obtained energy-based features from EEG signals to classify sleep data. These attributes were presented as input to feedback neural network. The authors have achieved a success rate of % 87.2 in the study of the 5 classified stages.</p><p>A different approach in classification of sleep stage is proposed by this study. One of the most important problems in classifying sleep stages is the identification of the features that will represent the data. Various algorithms used for the identification of features represent data, but most of the time, determining which algorithms identify the effective features for the specified problem depends on the trial and error method. A system that will automatically generate the identification of effective features will facilitate the works of the researchers to a great extent. A current study seeks to determine a method that will ensure the identification of features that can best represent data. Previous studies in literature were researched with this purpose in mind and 41 features that have previously been used in the classification of sleep stage were extracted. Feature selection algorithms are used to identify the features that provide the highest effect. Identification of the classification algorithm that provided the highest accuracy rates was possible with the features selected in the last stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data set</head><p>The data set used in the study was provided by St. Vincent's University Hospital and University College Dublin <ref type="bibr" target="#b35">[36]</ref>. Data from 25 individuals was selected from the database. The demographic characteristics of the individuals whose data was used are as follows: 21 males and 4 females, age: 50± 10 years, range 28-68 years; BMI: 31.6±4.0 kg/m 2 , range 25.1-42.5 kg/m 2 ; AHI: 24.1 ± 20.3, range 1.7-90.9. Polysomnogram recordings were obtained by utilizing the Jaeger-Toennies system. By using a 10-20 electrode placements system, each of these acquisitions consisted of 2 EEG channels (C3-A2 and C4-A1), 2 EOG channels and 1 EMG channel. Only one of the EEG channels (C3-A2) was used in this work. The sample rate was 256 Hz. By employing a 10point noncausal moving average filter, the pre-processing stage was used to smooth the EEG signal. A 10th order IIR Butterworth bandpass filter, at the frequency ranges of 0.1-60 Hz, was applied to the EEG signals in order to remove the noise and artifacts from EEG signals. In addition, a 12th order stopband butterworth notchfilter at a frequency of 50 Hz was applied to the EEG signals in order to remove 50 Hz power line interference. Then, the EEG signal was segmented (divided) into epochs of 30 s., each epoch corresponding to a single sleep stage. Each segment was windowed using the Hamming Window. Table <ref type="table" target="#tab_0">1</ref> shows the distribution of the sleep epochs belonging to 25 subjects. The average recording time was 6.9 h. Sleep experts performed the sleep scoring. Table <ref type="table" target="#tab_0">1</ref> presents the distribution of the selected sleep stages from the data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature extraction</head><p>Features in 4 different categories (time, non-linear, frequencybased and entropy) were identified in the feature extraction phase. A total of 21 feature algorithms were used; 10 in the time category, 5 in the non-linear category, 2 in the frequencybased category and 4 in the entropy category. 41 feature values were obtained out of 21 feature algorithms. The obtained features are displayed in Table <ref type="table">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Time domain features</head><p>Statistical measures In this phase, the statistical attributes of EEG signals are obtained. Short explanations of the attributes are provided in Table <ref type="table" target="#tab_1">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of zero crossings (ZC)</head><p>Zero-crossing is a time based feature widely used in electronics, mathematics, image processing and signal processing. It expresses the number of zero crossings generated in a segment. Zero crossing occurs when there is a difference in the signals in samples. This feature can be used as a measure that expresses the noise rate in the signal <ref type="bibr" target="#b36">[37]</ref>. Researchers have observed that the number of zero crossings in EEG signals change during brain activities and different sleep stages <ref type="bibr" target="#b37">[38]</ref>. ZC is defined as (x n-1 &lt;0 and x n &gt; 0) or (x n-1 &gt;0 and x n &lt;0) or (x n-1 ≠0 and x n =0).</p><p>Hjorth parameters Hjorth parameters (i.e., activity, mobility and complexity) are features that are often used in the analysis of EEG signals <ref type="bibr" target="#b38">[39]</ref>. First and second derivatives of signals are used in calculating Hjorth parameters that are defined in Table <ref type="table" target="#tab_2">4</ref>. where σ 0 is the variance or mean power of the signal, σ 1 is the variance of the first derivative and σ 2 is the variance of the second derivative of the signal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Nonlinear-based features</head><p>Petrosian fractal dimension (PFD) Fractal dimension is a chaotic method that calculates the complexity of a signal <ref type="bibr" target="#b39">[40]</ref>. PFD facilitates the speedy calculation of a fractal dimension. PFD undertakes this process by transforming the signal into binary sequences. It can be estimated by the following expression:</p><formula xml:id="formula_0">PFD ¼ log 10 k= log 10 k þ log 10 k= k þ 0:4N δ ð Þ ð Þ ð Þ ð<label>10Þ</label></formula><p>where k is the number of signal's samples and N δ is the number of sign changes in the signal derivative.</p><p>Mean teager energy (MTE) MTE is a feature value that is widely used in EEG research <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b40">41]</ref>. MTE first proposed in <ref type="bibr" target="#b40">[41]</ref> and is defined as;</p><formula xml:id="formula_1">MTE k ½ ¼ 1 N X m¼k-N þ3 k x m-1 ½ 2 -x m ½ x m-2 ½<label>ð11Þ</label></formula><p>where x[m] is an EEG time series, N is the window length and k is the last sample in the epoch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean energy (ME)</head><p>Energy values in signals increase along with increases in activity. When different activities in different sleep stages are considered, it is believed that the mean energy is a good indicator. It is calculated as the average of the squares of all samples in the signal. ME is defined as;</p><formula xml:id="formula_2">ME n ½ ¼ 1 N X m¼k-N þ1 k x m ½ 2<label>ð12Þ</label></formula><p>where x[m] is an EEG time series, N is the window length and k is the last sample in the epoch.</p><p>Mean curve length (MCL) MCL was proposed by Esteller et al. <ref type="bibr" target="#b41">[42]</ref> to provide an estimate for the Katz fractal dimension <ref type="bibr" target="#b42">[43]</ref>. It is commonly used in the identification of activity in EEG signals. MCL is defined as;</p><formula xml:id="formula_3">CL n ½ ¼ 1 N X m¼k-N þ1 k x m ½ -x m-1 ½<label>ð13Þ</label></formula><p>where x[m] is an EEG time series, N is the window length and k is the last sample in the epoch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hurst exponent (H)</head><p>The Hurst exponent is used as a measure of long-range dependence within a signal, with a range of 0-1. H is used in EEG time-series analysis to present the nonstationary/antistatic EEG states observed in sleep. H is identified as:</p><formula xml:id="formula_4">H ¼ log R=S ð Þ=log T ð Þ<label>ð14Þ</label></formula><p>Here, T is the time of the data sample and R/S is the value of the range which was rescaled. In the Hurst exponent, a value of 0.5 represents a signal with the attributes of a standard casual walk or Brownian motion. Values H &lt;0.5 show negative correlations between the increments or anti-persistent :</p><formula xml:id="formula_5">MaxV=max[x n ] ( 2 ) Standard deviation(SD) : SD ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi ∑ N n¼1 x n -AM ð Þ q 2 N -1<label>(3)</label></formula><p>Arithmetic Mean (AM) :</p><formula xml:id="formula_6">AM ¼ 1 N ∑ n¼1 N x n<label>(4)</label></formula><p>Variance (V) :</p><formula xml:id="formula_7">V ¼ ∑ N n¼1 x n -AM ð Þ 2 N -1<label>(5)</label></formula><p>Skewness (S) :</p><formula xml:id="formula_8">S ¼ ∑ N n¼1 x n -AM ð Þ 3 N -1 ð Þ SD 3 (6) Kurthosis (K) : K ¼ ∑ N n¼1 x n -AM ð Þ 4 N -1 ð Þ SD 4<label>(7)</label></formula><p>Median (MN) :</p><formula xml:id="formula_9">MN ¼ N þ1 2 À Á th (8)</formula><p>If the number of values is odd then</p><formula xml:id="formula_10">MN ¼ N 2 ð Þ th valueþ N 2 þ1 ð Þ th value 2 (9)</formula><p>If number of values is even then (where N=number of items) </p><formula xml:id="formula_11">HM=σ 1 /σ 0 HC ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi σ 2 =σ 1 ð Þ p 2 -σ 1 =σ 0 ð Þ 2</formula><p>time series, while values H &gt;0.5 reflect a positive correlation between the increments or persistent natural series.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Frequency and time-frequency based features</head><p>Wigner-Ville distribution (WV) WV is a time frequency distribution and a useful method in the analysis of signals that potentially changes through time. WV is defined as;</p><formula xml:id="formula_12">WV t; ω ð Þ ¼ X t¼-∞ ∞ f t þ t 0 2 f Ã t- t 0 2 e -jt 0 ω dω 0<label>ð15Þ</label></formula><p>where WV(t,ω), is the energy distribution of f(t) signal in t time and f frequency. * represents the complex conjugate of the signal and ω is the frequency. Features are also extracted from the time-frequency plane obtained through the application of a Wigner-Ville transformation to the signal. The largest frequency that corresponds to the time values in the plane is used while features are extracted. The function formed by these frequency values was modelled with a polynomial, from the third degree in the current study and the coefficients of this polynomial were used as features <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b43">44]</ref>. As a result, 4 features composed of the coefficients of the polynomial (WV-1, WV-2, WV-3 and WV-4) were extracted.</p><p>Discrete wavelet transform (DWT) and wavelet coefficients This is a transformation method developed to overcome the deficiencies of the Fourier transformation over non-stationary signals <ref type="bibr" target="#b44">[45]</ref> and this method is less sensitive towards noise and can be easily applied to non-stationary signals. The load is rather heavy in continuous wavelet transformation and in order to decrease the load, DWT is used. DWT is defined as:</p><formula xml:id="formula_13">DWT j; k ð Þ ¼ 1 ffiffiffiffiffiffiffi ffi 2 j q Z -∞ ∞ x t ð Þ ψ t-2 j k 2 j dt<label>ð16Þ</label></formula><p>Here x(t) is the signal itself and ψ is the main wavelet function. A low-pass filter is used to obtain the approximation coefficient of the signal which has a low frequency and a highpass filter is used to obtain the detailed coefficient of the signal which has a high frequency. A sufficient number of coefficients should be calculated to obtain the most appropriate structure of the signal. Figure <ref type="figure" target="#fig_13">2</ref> displays the extrication procedure of the x(n) signal.</p><p>As can be seen in the figure, the discrete x(n) signal crosses through the high-pass filter to generate detail coefficients (D i [n]) and crosses through the low-pass filter to obtain approximation coefficients (A i [n]). In each extraction level, half band filters facilitate the formation of the signals that forms half of the frequency band.</p><p>For the DWT, which is frequently used in the analysis of EEG signals, it is important to identify appropriate wavelet type and determining the level of decomposition. The number of levels of decomposition is chosen based on the dominant frequency components of the signal. The levels are chosen such that those parts of the signal that correlate well with the frequencies required for classification of the signal are retained in the wavelet coefficients. EEG signals have significant information in the range of 0-30 Hz. Therefore decomposition level is set at 5. In the case of decomposition level selected below 5, selected sensitivity for low frequency band will be lost. For instance, the representation of the delta band will be difficult. Selecting the decomposition level above 5 would be unnecessary. Because, with the fifth level, representation of all EEG bands is possible. Thus, the signal is decomposed into the details of D1-D5 and one final approximation, A5.</p><p>Frequency range of sub-bands obtained by fifth level of DWT decomposition of EEG data is given in Fig. <ref type="figure">3</ref>. It can be seen from Fig. <ref type="figure">3</ref> that the components A5 decomposition is within the delta range (1-4 Hz), D5 decomposition is within the theta range (4-8 Hz), D4 decomposition is within the alpha range (8-13 Hz) and D3 decomposition is within the beta range <ref type="bibr" target="#b12">(13)</ref><ref type="bibr" target="#b13">(14)</ref><ref type="bibr" target="#b14">(15)</ref><ref type="bibr" target="#b15">(16)</ref><ref type="bibr" target="#b16">(17)</ref><ref type="bibr" target="#b17">(18)</ref><ref type="bibr" target="#b18">(19)</ref><ref type="bibr" target="#b19">(20)</ref><ref type="bibr" target="#b20">(21)</ref><ref type="bibr" target="#b21">(22)</ref><ref type="bibr" target="#b22">(23)</ref><ref type="bibr" target="#b23">(24)</ref><ref type="bibr" target="#b24">(25)</ref><ref type="bibr" target="#b25">(26)</ref><ref type="bibr" target="#b26">(27)</ref><ref type="bibr" target="#b27">(28)</ref><ref type="bibr" target="#b28">(29)</ref><ref type="bibr" target="#b29">(30)</ref>. Because D1 and D2 bands have the frequency knowledge above 30 Hz, it can be said that these sub-bands have less meaning comparing the others. Therefore in this study, D3-D5 detail sub-bands and A5 approximation band were used.</p><p>In choosing the appropriate wavelet, different wavelets were tested and it was observed that the best results were obtained at fourth level of Daubechies wavelet. In order to investigate the effect of other wavelets on classifications accuracy, tests were also carried out using other wavelets. Apart from Daubechies of order 4 (db4), Symmlet of order 10</p><formula xml:id="formula_14">x[n] g[n] h[n] 2 D1 A1 …… g[n] h[n] 2 2 D2 A2 g[n] h[n] D3 A3 2 2 2 Fig. 2 Sub-band decomposition of DWT implementation; h[n] is the high-pass filter, g[n]</formula><p>the lowpass filter (sym10), Coiflet of order 4 (coif4), and Daubechies of order 2 (db2) were also tried. It was noticed that the Daubechies wavelet gives better accuracy than the others, and db4 is slightly better than db2. In several successful studies related to EEG, it is seen that, 5 is selected as the level of decomposition and db4 is preferred as the wavelet type <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47]</ref>.</p><p>For example, Fig. <ref type="figure" target="#fig_12">4</ref> shows approximation (A5) and details (D1-D5) of an Awake EEG signal.   Features 1-2 show the frequency distribution of the signal, whereas features 3-4 display the amount of transformation in the distribution of the frequency <ref type="bibr" target="#b47">[48]</ref>. 16 features are obtained in this manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entropy-based features</head><p>Spectral entropy (SpEn) SpEn is a feature that allows the identification of the degree of regularity in the complex signals. The entropy of the data with regular probability distribution will be higher. On the same line, the entropy of the data with irregular probability distribution will be low <ref type="bibr" target="#b48">[49]</ref>. Different from the normal entropy estimates, spectral entropy is calculated by using the probability values of the power spectrum of the signal. SpEn is defined as;</p><formula xml:id="formula_15">H sp ¼ - X a¼ f a f b P i log 1 P a<label>ð17Þ</label></formula><p>where P is the power density over a defined frequency band of the signal, f a and f b are the lower and upper frequency and power is normalized such that ∑P n =1 <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b48">49]</ref>. H sp is also used in the normalized form as;</p><formula xml:id="formula_16">SpEn ¼ H sp =logN f<label>ð18Þ</label></formula><p>where N f is the number of frequencies within the defined band [f a ,f b ]. In this work the frequency band is specified as [0, 50] Hz.</p><p>Rényi entropy (RE) Rényi entropy, introduced by Rényi <ref type="bibr" target="#b49">[50]</ref>, is a special case of spectral entropy based on the concept of generalized entropy of a probability distribution. If p is a probability distribution on a finite set, its RE of order q is defined to be:</p><formula xml:id="formula_17">S q ¼ 1 1-q ln X i p q i q≠1 and q &gt; 0 ð Þ ð<label>19Þ</label></formula><p>RE is calculated as q=2 in this study.</p><p>Approximate entropy (ApEn) ApEn is a statistical parameter which allows us to grasp the regularity of the time series <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b51">52]</ref>. ApEn uses a non-negative number to quantify the complexity of the data and the formation of information in the time series. The higher the number, the more complex and irregular are the data in the time series. ApEn was applied to classify EEG in psychiatric diseases such as schizophrenia <ref type="bibr" target="#b48">[49]</ref> and epilepsy <ref type="bibr" target="#b52">[53]</ref>.</p><p>For N data points x(1),x(2),…,x(N) with an embedding space of ℜ n , the ApEn measure was given by:</p><formula xml:id="formula_18">ApEn n; l; N ð Þ¼ 1 N -n þ 1 X N -nþ1 i¼1 logC n i l ð Þ- 1 N -n X N-n i¼1 logC n i l ð Þ<label>ð20Þ</label></formula><p>where:</p><formula xml:id="formula_19">C n i l ð Þ ¼ 1 N -nþ1 ∑ N-nþ1 j¼1 θ l-x i -x j À Á</formula><p>was the correlation integral <ref type="bibr" target="#b53">[54]</ref>.</p><p>In this study, n was chosen as 2 and l was chosen as 0.15 times the standard deviation of the original data sequence. The n and l values were selected based on Pincus' results in previous studies. These indicated good statistical validity for ApEn <ref type="bibr" target="#b54">[55]</ref>.</p><p>Permutation entropy (PEn) PEn was developed by Bandt and Pompe <ref type="bibr" target="#b55">[56]</ref>. PEn is a complexity measure for time series based on comparing neighboring values. It has the quality of simplicity, sturdiness and very low computational cost <ref type="bibr" target="#b56">[57]</ref>. Given a scalar time series (x t ,t=1,2,…, T), an embedding procedure forms a vector: X t =[x t ,x t +1, …,x t +(n -1)l ] with the embedding dimension, n, and the lag, l (here l=1). Then, X t is arranged in an increasing order:</p><formula xml:id="formula_20">x tþ j 1 -1 ð Þl ≤ x tþ j 2 -1 ð Þl ≤ … ≤ x tþ j n -1 ð Þl Â Ã .</formula><p>For n different numbers, there will be n! possible order patterns π, which are also called permutations. Let f(π) denote its frequency in the time series, its relative frequency is p(π)=f(π)/(T -(n-1)l). The permutation entropy is defined as <ref type="bibr" target="#b56">[57]</ref> </p><formula xml:id="formula_21">H p n ð Þ ¼ - X n! n¼1 p π ð Þlnp π ð Þ<label>ð21Þ</label></formula><p>More details can be found in <ref type="bibr" target="#b55">[56]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature selection algorithms</head><p>The feature selection process, which is an important part of pattern recognition and machine learning, reduces computation costs and increases classification performance. A suitable representation of data, from all features, is an important obstacle in machine learning and data mining problems. All original features are not always useful for classification or for regression tasks since, in the distribution of the dataset, some features may be irrelevant/redundant or noisy and they reduce the classification performance. Therefore, the feature selection process ought to be used in classification or regression problems so that classification performance is enhanced and the computation cost of classifiers is reduced <ref type="bibr" target="#b57">[58]</ref>. This study preferred to use FCBF, t-test, ReliefF, Fisher score, mRMR algorithms and efficient feature selection algorithms. Brief information about these algorithms is provided below:</p><p>Fast correlation based filter (FCBF)</p><p>FCBF was developed based on the relevance and redundancy criteria among the features <ref type="bibr" target="#b58">[59]</ref>. A Symmetrical Uncertainty (SU) value is used in the assessment of relationships and redundancy between 2 features and 2 classes. SU is based on entropy and is a measure of a non-linear correlation. The SU value is calculated for A and B variables as shown in Eq. 22. Here A and B express a feature or a class label couple or any 2 features.</p><formula xml:id="formula_22">SU A; B ð Þ ¼ 2 IG A B = H A ð Þ þ H B ð Þ ð Þ h i<label>ð22Þ</label></formula><formula xml:id="formula_23">IG A B ¼ H A ð Þ-H A B<label>ð23Þ</label></formula><formula xml:id="formula_24">H A ð Þ ¼ - X i P a i ð Þlog 2 P a i ð Þ ð Þ<label>ð24Þ</label></formula><p>Here IG(A | B) is the information gain of A after observing variable B <ref type="bibr" target="#b58">[59]</ref>. The entropy of variable A and B are H(A) and H(B), respectively. P(a i ) is the probability of variable A and the entropy (H(A | B)) of A after observing values of another variable B is defined as;</p><formula xml:id="formula_25">H A B ¼ - X j P b j À Á X i P a i b j log 2 P a i b j<label>ð25Þ</label></formula><p>where P(a i ) are the prior probabilities for all values of A and P(a i | b j ) is the posterior probabilities of A given the values of B <ref type="bibr" target="#b58">[59]</ref>.</p><p>The FCBF algorithm is composed of two stages. First, SU values are calculated to evaluate the correlation between each feature and class labels. Features whose correlation values are, equal to or under a specific threshold value are eliminated. In the second stage, redundant features are identified by using the rest of the features to identify the ones that are most related with the class labels. The features identified this way are also eliminated. The features that are not eliminated in the two stages are identified as the features that are most related to the class labels and with the least amount of redundancy among themselves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>mRMR algorithm</head><p>The mRMR algorithm is a feature extraction method which selects the most relevant features, with class labels, whilst trying to minimize redundancy amongst the selected features <ref type="bibr" target="#b59">[60]</ref>. mRMR uses mutual information to compute featurefeature and feature-label similarity scores. For a and b features, p(a) and p(b) are marginal probability functions and p(a,b) is the connected probability distribution while I(a,b) is the amount of mutual information of a and b:</p><formula xml:id="formula_26">I a; b ð Þ ¼ X i; j p a i ; b j À Á log p a i ; b j À Á p a i ð Þp b j À Á<label>ð26Þ</label></formula><p>The mutual information function allows speedy computation of non-linear similarities amongst the features. In terms of the mRMR method, it aims to minimize redundancy (Rd) whilst maximizing relevance (Re) amongst the features.</p><formula xml:id="formula_27">Rd ¼ 1 S j j 2 X i; j∈S I i; j ð Þ<label>ð27Þ</label></formula><formula xml:id="formula_28">Re ¼ 1 S j j X i∈S I h; i ð Þ<label>ð28Þ</label></formula><p>Here, S is the set of features, h is target class, and I(i,j) is mutual information between features i and j. Both equations use mutual information difference (MID) and mutual information quotient (MIQ) values to minimize redundancy and maximize relevance which were class labels. Definitions of the MID and MIQ, are shown in Eqs. ( <ref type="formula" target="#formula_29">29</ref>) and <ref type="bibr" target="#b29">(30)</ref>.</p><formula xml:id="formula_29">MID ¼ max Rd-Re ð Þ<label>ð29Þ</label></formula><formula xml:id="formula_30">MIQ ¼ max Rd=Re ð Þ<label>ð30Þ</label></formula><p>Fisher score algorithm (FS)</p><p>Fisher score is an efficient and simple method which measures the distinctiveness between two classes. Using this method, the Fisher score value of each feature in the data set is computed, according to Eq. 31, and, in order to select the efficient features from the data set, the threshold value is obtained by calculating the average Fisher score values of all features If the feature's Fisher score value is higher than the threshold value, this feature is included in the attribute space of the feature data set. The Fisher score was calculated using the formula:</p><formula xml:id="formula_31">FS ¼ X b a¼1 n a μ i;a -μ i À Á 2 X b a¼1 n a σ 2 i;a<label>ð31Þ</label></formula><p>where μ i was the mean of features; n a was the number of samples in the a th class; μ i,a was the mean of the features in the a th class; and σ i,a 2 was the variance of the features in the a th class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T-test algorithm</head><p>The t-test is a widely applied method used to determine whether or not the means of two groups differ statistically. The t-test formula is the ratio given below. The upper half of the formula is the difference between two means or averages, and the lower part is the variability measure or distribution of the scores.</p><formula xml:id="formula_32">t ¼ μ 0 -μ 1 j j . ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi 1 n 0 þ 1 n 1 n 0 -1 ð Þσ 2 0 -n 1 -1 ð Þσ 2 1 n 0 þ n 1 -2 s<label>ð32Þ</label></formula><p>where μ i , σ i 2 and n i denoted the mean; variance; and sample size of class i, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ReliefF algorithm (RF)</head><p>ReliefF is the supervised feature weighting algorithms of the filter model. This determines the extent to which feature values discriminate the instances amongst different classes and is used in estimating the quality of the features according to this criterion. The ReliefF algorithm has the advantage of dealing with noisy and unknown data <ref type="bibr" target="#b60">[61]</ref>. The ReliefF algorithm is calculated using the following formula:</p><formula xml:id="formula_33">RF ¼ 1 2 X a¼1 b dm f a;t -fPQ x a ð Þ; t À Á -dm f a;t -fPR x a ð Þ; t À Á<label>ð33Þ</label></formula><p>where f a,t represents the value of instances x a ; fPQ(x a ),t and x a ; fPR(x a );t represents the value on the t th features of the nearest points to x a and dm represents the distance measurement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classifier algorithms</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Decision trees (DT)</head><p>Since decision tress are easier to structure and comprehend compared to other algorithms, they are most often used in the solution of classification problems <ref type="bibr" target="#b61">[62]</ref>. The reason why this method is widely used is related to the simplicity and ease of understanding regarding the rules used in tree structures. Decision trees use a multi-stage or consecutive approach in the classification procedure <ref type="bibr" target="#b62">[63]</ref>. The tree is generated in the first stage of the classification. Data is applied one by one to the tree to undertake a classification process in the second stage. There are many algorithms developed in relation to decision trees. The most widely known algorithms in the literature are ID3, C4.5 and C5. A Current study utilizes the C4.5 algorithm. The C4.5 algorithm, calculated based on entropy value, was developed by Quinlan <ref type="bibr" target="#b63">[64]</ref>. The C4.5 algorithm was developed based on the ID3 algorithm in order to overcome some deficiencies and problems in ID3. It generates top to bottom decision trees just like the ID3 algorithm. The ID3 algorithm calculates the knowledge acquisition values for each node in the decision tree <ref type="bibr" target="#b64">[65]</ref>. C4.5 calculates knowledge acquisition rates for the characteristics in the lower set along with knowledge acquisitions. It selects the characteristics with the highest knowledge acquisition rate as the node. The procedure continues until each branch of the tree corresponds to a single class <ref type="bibr" target="#b64">[65]</ref>. Later, the decision tree is transformed into a rule set. For more information on C4.5 decision tree learning, the readers can refer to <ref type="bibr" target="#b61">[62]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feed-forward neural network (FFNN)</head><p>Artificial neural networks (ANNs) are mathematical systems that are composed of many operation units (neurons) connected to each other in a weighted manner <ref type="bibr" target="#b65">[66]</ref>. The operation unit receives the signals from other neurons, combines them and generates a numerical result. In general, operation units roughly correspond to real neurons and they are combined with each other in a network <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b67">68]</ref>. This structure forms the neural networks. The current study uses feed-forward neural networks, one of the neural network models. There are mainly three layers in feed-forward artificial neural networks. These layers are, the input layer that receives the data entering the neural network, the hidden layer where operations are undertaken and which trains itself according to the desired result and the output layer which displays the output results. The Sigmoid activation function which produced good results in activation functions was preferred in the current study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Radial basis network (RBF)</head><p>RBF were developed and inspired by action and reaction behaviours observed in biological neural cells. Training of RBF models can be regarded as a curve fitting approach in multidimensional space <ref type="bibr" target="#b68">[69]</ref>. Therefore, the training performance of RBF models turns into an interpolation problem through finding the most appropriate surface for the data in output vector space. RBF models are defined in three layers, as in the ANN structure and include input, hidden and output layers. However, contrary to classical ANN structures, RBF models use radial based activation functions and non-linear cluster analysis in entering the hidden layer forms the input layer. Many types of activation functions (linear, cubic, Gauss, multi-quadratic and reverse multi-quadratic) are used in RBF models. The Gauss function was preferred in the current study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Support vector machine (SVM)</head><p>SVM is a machine learning method based on statistical learning theory <ref type="bibr" target="#b69">[70]</ref>. SVM is a classification and regression method that easily classifies the difficult data sets (linear and nonlinear) with the help of kernel functions. It has been widely used recently since it has a strong theoretical foundation; it can be used with large data sets, it has a flexible algorithm along with kernel functions and it generates high accuracy rates in results. The method determines the linear function with the highest margin from among many linear functions, in order to differentiate the data that can be classified linearly <ref type="bibr" target="#b70">[71]</ref>. It transmits the data that cannot be linearly classified to the higher plane by using kernel functions and finds the multi lanes with the highest margins. Polynomial, radial based function (RBF), Pearson VII (PUK) and normalized polynomial kernels are used as kernel functions. RBF was used in the current study as the kernel function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random forest algorithm (RF)</head><p>RF more than one decision tree is used in the classification procedure to increase the classification value. Breiman <ref type="bibr" target="#b71">[72]</ref> suggests combining multiple trees with multi variables, each of which can be trained with different training clusters instead of generating a single decision tree. Different training clusters are generated from the original training set by using bootstrap and random feature selection. First, each decision tree reaches a decision and the class which receives the maximum votes in the decision forest, is regarded as the final decision and the input data is included in this class. The number of trees was determined to be 25 in the current study, based on good results obtained in precious studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance evaluation methods</head><p>Five methods for the performance evaluation were used. These methods are classification accuracy, confusion matrix, analysis of sensitivity and specificity, and k-fold cross-validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classification accuracy, sensitivity and specificity</head><p>The following expressions for classification accuracy, sensitivity and specificity analysis are used: </p><formula xml:id="formula_34">Classification accuracy ¼ TP þ TN TP þ FN þ FP þ TN % ð Þ ð34Þ</formula><formula xml:id="formula_35">sensitivity ¼ TP TP þ FN % ð Þ<label>ð35Þ</label></formula><formula xml:id="formula_36">specificity ¼ TN FP þ TN % ð Þ<label>ð36Þ</label></formula><p>where TP,TN,FP and FN denotes true positives, true negatives, false positives and false negatives, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>k-Fold cross-validation</head><p>As a first step, data set is divided into k times sub clusters in a k-fold cross validation test. (k-1) times sub clusters are used in training, whereas 1 sub cluster is used for testing the trained network. The process is continued until all sub clusters are left outside training and tested. The success achieved in tested data sets, provides the reliability and validity degree of the employed method. Average testing success for k-times data set is obtained to arrive at a single validity value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental results and discussion</head><p>A computer with an Intel(R) Core™ i7-2670QM 2.20 GHz microprocessor and 8 GB RAM was used to solve the problems. Figure <ref type="figure">6</ref>      Figure <ref type="figure">7a</ref> displays that even with only one feature value in some of the algorithms, might allow high classification accuracies to be obtained. This shows that the selected feature clusters are efficient. The graph shows that, with the help of the RF, DT and RBF algorithms, the feature cluster, which includes the first three feature values, obtain accuracy values higher than 80 %. It can be seen that the best results were obtained using the RF algorithm. The investigation of the other algorithms show that, in terms of success, the RBF algorithm is more efficient in the first three features. After the first three feature clusters, the DT algorithm is more advantageous and continues to be so for the first 23 features. After the first 23 features, the SVM is advantageous and, in general, the lowest success level is seen with the FFNN algorithm.</p><p>Table <ref type="table" target="#tab_3">5</ref> shows the best result for each method together with the corresponding size of selected feature subset cardinalities. It is identified that, with the use of the RF algorithm, the feature cluster, which has 12 feature values with a 96.39 % accuracy rate, obtains the highest accuracy classification rate. The ordering, of efficient features obtained through the use of the RF algorithm, is found to be: 27 (D5-1); 13 (PEn); 29 (D5-3); 21 (D3-3); 38 (MCL); 10 (PFD); 25 (D4-3); 28 (D5-2); 41 (MTE); 24 (D4-2); 4 (SD) and 39 (HE). After the RF algorithm, the best score was obtained with the DT; SVM; RBF; and FFNN algorithms respectively.</p><p>Investigation of Fig. <ref type="figure">7b</ref> shows that the computation time increases with the increase in the number of features. The algorithm which worked the fastest, is the DT algorithm. In general, the DT algorithm is followed by the RF, SVM, FFNN and RBF algorithms respectively. The RBF algorithm is found to require the highest computation time. It can be seen that neural network based algorithms require high computation times.</p><p>Experiment 2: mRMR feature selection algorithm During experiment 2, the mRMR algorithm was carried out with regard to the feature cluster. The ordering of efficient features obtained through the use of the mRMR algorithm, was found to be: PFD, PEn, HE, D5-1, WV-1, AM, WV-2, WV-3, WV-4, MaxV, D4-1, D4-3, D5-2, D4-2, D5-4, MN, MinV, D5-3, D3-3, D3-2, D3-1, MCL, A5-1, HC, SpEn, MTE, ME, HA, A5-2, ZC, V, SK, KT, A5-3, A5-4, SD, D3-4, ApEn, REn, D4-4 and HM. Figure <ref type="figure" target="#fig_6">8</ref> displays the classification accuracy rates and the computation times of the feature clusters identified by the mRMR algorithm.</p><p>Figure <ref type="figure" target="#fig_6">8a</ref> indicates that the classification accuracy rate is low with regard to the first five feature values and that it increases above 80 % in some of the sub-clusters which consist of 5 and more feature values. In terms of success, the SVM algorithm is found to be more efficient in the first five features. After the first five features, the RF algorithm becomes more advantageous. In general, the best results are obtained with the help of the RF algorithm. In terms of success, for the first 20 features,  the RF algorithm is followed by the and RBF algorithms. Following the first 20 features, the SVM algorithm becomes more advantageous. The lowest success level is found to be with the FFNN algorithm. Table <ref type="table" target="#tab_4">6</ref> shows the best result for each method together with the corresponding size of selected feature subset cardinalities. It is identified that, with the use of the RF algorithm, the feature cluster, which has 37 feature values with a 96.33 % accuracy rate, obtains the highest accuracy classification rate. The ordering, of efficient features obtained through the use of the RF algorithm, is found to be: Investigation of Fig. <ref type="figure" target="#fig_6">8b</ref> shows that the computation time increases with the increase in the number of features. The algorithm which worked the fastest, is the DT algorithm. In general, the DT algorithm is followed by the RF, SVM, FFNN and RBF algorithms respectively. The RBF algorithm is found to require the highest computation time. It can be seen that neural network based algorithms require high computation times.</p><p>Experiment 3: t-test feature selection algorithm During experiment 3, the t-test algorithm was carried out with regard to the feature cluster. The ordering of efficient features obtained through the use of the t-test algorithm, was found to be: PFD, HM, WV-4, A5-4, D5-1, MaxV, HE, ZC, MTE, D4-4, SK, KT, SD, HC, MinV, REn, WV-1, D3-1, WV-3, V, SpEn, D4-1, ME, AM, MN, A5-1, D3-2, WV-2, D5-4, ApEn, A5-2, D3-4, D4-2, D5-2, A5-3, D3-3, D5-3, HA, PEn, D4-3, MCL. Figure <ref type="figure" target="#fig_8">9</ref> displays the classification accuracy rates and the computation times of the feature clusters identified by the t-test algorithm.</p><p>Figure <ref type="figure" target="#fig_8">9a</ref> indicates that the classification accuracy rate is low with regard to the first four feature values, and it increases above 80 % in some of the sub-clusters which consist of 4 and more feature values. In terms of success, the DT algorithm is found to be more efficient in the first five features. After the first five features, the RF algorithm becomes more advantageous. In general, the best results are obtained with the help of the RF algorithm. In terms of success, for the first 23 features, the RF algorithm is followed by the DT algorithm until, following the first 23 features, the SVM algorithm becomes more advantageous. The lowest success level is found to be with the FFNN algorithm.</p><p>Table <ref type="table" target="#tab_5">7</ref> shows the best result for each method together with the corresponding size of selected feature subset cardinalities. It is identified that, with the use of the RF algorithm, the feature cluster, which has 31 feature values with a 96.22 % accuracy rate, obtains the highest accuracy classification rate. The ordering, of efficient features obtained through the use of the RF algorithm, is found to be: 10 (PFD), 36 (HM), 18 (WV-4), 34 (A5-4), 27 (D5-1), 2 (MaxV), 39 (HE), 7 (ZC), 41 (MTE), 26 (D4-4), 8 (SK), 9 (KH), 4 (SD), 37 (HC), 3 (MinV), 11 (REn), 15 (WV-1), 19 (D3-1), 17 (WV-3), 5 (V), 12 (SpEn), 23 (D4-1), 40 (ME), 1 (AM), 6 (MN), 31 (A5-1), 20 (D3-2), 16 (WV-2), 30 (D5-4), 14 (ApEn), 32 (A5-2).</p><p>Investigation of Fig. <ref type="figure" target="#fig_8">9b</ref> shows that the computation time increases with the increase in the number of features. The   algorithm which worked the fastest, is the DT algorithm. In general, the DT algorithm followed by the RF, SVM, FFNN and RBF algorithms respectively. The RBF algorithm is found to require the highest computation time. It can be seen that neural network based algorithms require high computation times. Figure <ref type="figure" target="#fig_11">10a</ref> indicates that the classification accuracy rate is low until the first 3 feature values. It then increased above 80 % in some of the sub-clusters which consisted of 3 and more feature values. In general, the best results are obtained by using the RF algorithm. In terms of success, the RF algorithm is followed by the DT, RBF and SVM algorithms. The SVM algorithm's success is found to increase, especially after 15 features. The lowest success level is found to be with the FFNN algorithm.</p><p>Table <ref type="table" target="#tab_6">8</ref> shows the best result for each method together with the corresponding size of selected feature subset cardinalities. It is identified that, with the use of the RF algorithm, the feature cluster, which has 32 feature values with a 96.22 % accuracy rate, obtains the highest accuracy classification rate. The ordering, of efficient features obtained through the use of the RF algorithm, is found to be: 10 (PFD), 39 (HE), 13 (PEn), Investigation of Fig. <ref type="figure" target="#fig_11">10b</ref> shows that the computation time increases with the increase in the number of features. The algorithm which worked the fastest, is the DT algorithm. In general, the DT algorithm is followed by the RF, SVM, FFNN and RBF algorithms respectively. The RBF algorithm is found to require the highest computation time. It can be seen that neural network based algorithms require high computation times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 5: FCBF feature selection algorithm</head><p>The FCBF feature selection algorithm, an efficient feature extraction method, was carried out during Experiment 5. As mentioned in Section 3.3.1, the FCBF algorithm works with the element of elimination and, therefore, as compared to the other feature selection algorithms, only one feature cluster was obtained. The ordering of efficient features obtained with the implementation of this algorithm, was as follows: 10 (PFD); 13 (PEn); 27 (D5-1); 31 (A5-1); and 8 (SK). Figure <ref type="figure" target="#fig_0">11</ref> displays the classification accuracy rates and computation times for the feature cluster identified by the FCBF algorithm.</p><p>Figure <ref type="figure" target="#fig_0">11a</ref> shows that the RF algorithm obtains the best result and, with the use of the RF algorithm, the feature cluster, which obtains 5 feature values identified with a 94.65 % accuracy rate, reaches the highest level of classification accuracy. In terms of success, the RF algorithm is followed by the DT (%88.5), RBF (87.92 %), the SVM (72.07 %) and FFNN (62.94 %). Investigation of Fig. <ref type="figure" target="#fig_0">11b</ref> shows that computation time increased with the increase in the number of features. The algorithm, which worked the fastest, was found to be the DT algorithm. In general, the DT algorithm was followed the RF; SVM; FFNN; and RBF algorithms respectively. The RBF algorithm was found to require the highest computation time. It was seen that neural network based algorithms required high computation times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 6: A Hybrid Approach</head><p>In the first five experiments, effective attribute rankings were obtained according to the 5 different attribute selection algorithms. Experiments were carried out depending on these rankings. More functional approach aimed at the sixth experimental stage. At this stage, the most effective attributes obtained as a result of 5 different experiments were determined. Accordingly, first 10 attributes obtained as a result of each algorithm are noted. To view the repetition frequency of selected attributes, a histogram graph was plotted. According to the histogram chart, a new set of attributes were obtained by selecting 3 or more selected attributes. Experiments were carried out according to these set of attributes. The obtained attributes and histogram graph showing the number of times they were selected are shown in Fig. <ref type="figure" target="#fig_13">12</ref>.</p><p>As can be seen in Fig. <ref type="figure" target="#fig_13">12</ref>, during the stage of experiment 6, 5 attributes algorithm was selected. These are 27 (D5-1), 10 (PFD), 13 (PEn), 2 (MaxV) and 39 (HE) attribute values, respectively. These six attributes algorithm are presented as input to 5 different classification algorithms. Success rates obtained are presented in Fig. <ref type="figure" target="#fig_15">13</ref>.</p><p>Figure <ref type="figure" target="#fig_15">13a</ref> shows that the RF algorithm obtains the best result and, with the use of the RF algorithm, the feature cluster, which obtains 5 feature values identified with a 97.03 % accuracy rate, reaches the highest level of classification accuracy. In terms of success, the RF algorithm is followed by the DT (%92.35), the RBF (89.45 %), the SVM (93.21 %) and the FFNN (71.88 %).</p><p>Investigation of Fig. <ref type="figure" target="#fig_15">13b</ref> shows that computation time increased with the increase in the number of features. The algorithm, which worked the fastest, was found to be the DT algorithm. In general, the DT algorithm was followed the RF; SVM; FFNN; and RBF algorithms respectively. The RBF algorithm was found to require the highest computation time. It was seen that neural network based algorithms required high computation times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General assessment</head><p>Based on the results, the RF algorithm was found to be the best algorithm in terms of success. Following that, the RF, SVM, DT and RBF algorithms were found to be effective in different feature clusters. Similar results were obtained in  different experiments relating to the identification of computation time. The DT algorithm was found to be the one with the lowest computation It appear that, in general, this algorithm followed by the RF, SVM, FFNN and RBF algorithms respectively. Table <ref type="table" target="#tab_7">9</ref> presents the best results obtained through each experiment. The best result was obtained through using the feature cluster which included 5 feature values obtained by combining the hybrid approach and RF algorithms.</p><p>The best method's success was evaluated according to performance evaluation criteria mentioned in Section 3.5 (see Fig. <ref type="figure" target="#fig_16">14</ref>). These statistics were calculated based on a one-versus-all classification (where the analyzed stage was positive and all other combined stages were negative). The highest classification accuracy was obtained in the wake stage and, in terms of classification accuracy, N-REM stage 1, N-REM stage 4, REM, N-REM stage 3 and N-REM stage 2 were found to follow the wake stage. Efficient results were observed, also, in terms of other statistical parameters. The proposed method was found to produce efficient results in terms of both success and speed performance.</p><p>The errors, in each stage, can be investigated by exploring the confusion matrix, as shown in Table <ref type="table" target="#tab_9">10</ref>. This indicates the agreement between the proposed method and the experts' scores. The expert score was obtained by the consensus of the three experts. Also, the proposed method substantially solved the problem of combining Stages 3 and 4, an aspect that the literature regarded as an important problem.</p><p>The above-mentioned analyses, carried out in terms of the classification problem, were developed by taking into consideration R&amp;K criteria as specified in the study's introduction. There was also an assessment of the success of the proposed method's classification regarding sleep stages identified according to the American Academy of Sleep Medicine (AASM) standards <ref type="bibr" target="#b72">[73]</ref>   As far as the AASM standards were concerned, an accuracy rate of 98.02 % was obtained. This value was found to be higher than that of the results obtained by RF standards. This difference in accuracy rates, was due mainly to the N-REM levels' similarity of in the RF standards, and this similarity reduced the success of the classification. Combining S3 and S4, based on the AASM recommendations, enabled us to obtain better results.</p><p>The performance of the proposed procedure was compared with the recent work available from the literature listed in Table <ref type="table" target="#tab_11">12</ref>.</p><p>Table <ref type="table" target="#tab_11">12</ref> shows the performance of automatic sleep stage classification implementations including 6 sleep stages, were generally in the range of 70-93 %. Many of the studies, which obtain 90 % or higher compatibility, were studies which generalized the stages in 3-4 stages. In this sense, it is believed that this study has contributed substantially to the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>It is a difficult task to classify a patient's sleep stages. This requires the observation of the patient, an EEG, and the collection of additional clinical information. This study proposes an efficient model to help neurologists to analyze EEG signals with high rates of accuracy. The key parts of the study are as follows:</p><p>&amp; The effect of the features as selected by the feature selection algorithm on performance, are found to be more positive and higher when compared to the use of all features. &amp; Investigation of the literature about EEG classification, shows that many feature extraction algorithms have been used in studies, but the major problem is the identification of the effective features. This study is important also, in the sense that it will prove to be a guide to researchers in the field of sleep study. The same method could be used in the diagnosis and scoring of epilepsy, the identification of depth in terms of anesthesia, migraine, etc. all of which use EEG signals, and efficient features could be identified. &amp; This study presents a unique analysis, both in the identification of the most effective features, and in the identification of the most efficient algorithm in the classification of the problem. In the study, features were selected from amongst the features used for the representation of the problem, and the algorithm was chosen from amongst the 6 most popular classification algorithms. High levels of classification accuracy were obtained during the identification of efficient features and classification algorithms. Whilst using other biomedical signals, the same method could be used to achieve high rates of accuracy. Studies such as this one, might be of service in discovering effective solutions to the question "Which feature algorithm should be employed to obtain the feature that best represents the data?" &amp; The method proposed in this study, could be implemented, without difficulty, with other medical data, and it could be used in areas other than the classification of sleep stages. After establishing the algorithms used previously for the problems under consideration, researchers who were willing to employ the proposed method could easily identify the effective features. It was not at all difficult to create the format which the model required. After the data feed, the system administered automatically, in turn, the implementation of the feature algorithms, the feature selection algorithm and the classification algorithms. Also, the results of the analysis were provided graphically. Analysis shows that an important benefit was being able to obtain results in a relatively short time. In future studies, it is planned to prepare a visual interface for the model. The application of such an interface might increase its applicability. &amp; The effective features employed in this study were selected from amongst the 41 feature parameters mentioned previously. Undoubtedly, different features were used, also, in the classification of EEG data. A future proposal is planned to undertake a more comprehensive study in the future that will expand the feature cluster.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 EEG signal for the different stages of sleep: Awake, N-REM stage 1, N-REM stage 2, N-REM stage 3, N-REM stage 3 and REM</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 5 shows approximation (A5) and details (D1-D5) of a N-REM stage 2 EEG signal. Statistical characteristics were calculated on the wavelet coefficients in order to decrease the dimensions of the extracted feature vectors. Statistical characteristics used to</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 Fig. 4</head><label>34</label><figDesc>Fig. 3 Frequency range of subbands obtained by fifth level of DWT decomposition of EEG data</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5</head><label>5</label><figDesc>Fig. 5 EEG signal belonging to N-REM stage 2 with a 30 seconds epoch from PSG recordings</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 Fig. 7</head><label>67</label><figDesc>Fig.6The applied methods for classification of sleep stages</figDesc><graphic coords="11,176.29,55.22,367.48,128.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>gives the block diagram of the proposed structure. The preprocessing of the EEG signals was completed in the first phase. In this phase, a band-pass filter, a Savitzky-Golay filter and the windowing and segmentation processes mentioned in Section 3.1, were undertaken respectively. In the next phase, features of the data were extracted. For 6 sleep stages, 6 separate matrices were created using Matlab R2009a. The size of these matrices for Awake, N-REM stage 1, N-REM stage 2, N-REM stage 3, N-REM stage 4 and REM stages, were 1109×3840; 897×3840; 988×3840; 1078×3840; 764×3840; and 324×3840 respectively. Here, matrix dimensions denoted the epoch number x sample number in each epoch. 41 separate feature parameters, mentioned in Section 3, were obtained for each column in the matrices. The next phase aimed to identify the efficient features from amongst the feature cluster. In order to achieve this aim, the best m features, as selected by the five feature selection methods, were used in each experiment (m=1, 2, …, 41). By using the 10-fold cross validation method on the RF; DT; FFNN; RBF; and SVM classifiers, the best m features were evaluated for each feature selection method. Comparative analyses of the experiments and the obtained results are provided below: Experiment 1: Fisher score feature selection algorithm During experiment 1, the Fisher score algorithm was carried out with regard to the feature cluster. The ordering of efficient</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8</head><label>8</label><figDesc>Fig. 8 Variation in classification accuracy and computation time with increasing number of selected features in results from Experiment 2</figDesc><graphic coords="12,342.43,559.43,166.12,108.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>features obtained through the use of the Fisher score algorithm was found to be: D5-1, PEn, D5-3, D3-3, MCL, PFD, D4-3, D5-2, MTE, D4-2, SD, HE, A5-4, A5-1, D4-1, A5-3, D3-2, MaxV, D3-1, MinV, HC, HM, V, ME, HA, ApEn, ZC, A5-2, SpEn, KT, SK, WV-4, D5-4, REn, MN, D4-4, WV-3, D3-4, WV-1, AM and WV-2.Figure 7 displays the classification accuracy rates and the computation times of the feature clusters identified by the Fisher score algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9</head><label>9</label><figDesc>Fig. 9 Variation in classification accuracy and computation time with increasing number of selected features in results from Experiment 3</figDesc><graphic coords="13,340.60,71.93,168.04,104.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>10 (PFD), 13 (PEn), 39 (HE), 27 (D5-1), 15 (WV-1), 1 (AM), 16 (WV-2), 17 (WV-3), 18 (WV-4), 2 (MaxV), 23 (D4-1), 25 (D4-3), 28 (D5-2), 24 (D4-2), 30 (D5-4), 6 (MN), 3 (MinV), 29 (D5-3), 21 (D3-3), 20 (D3-2), 19 (D3-1), 38 (MCL), 31 (A5-1), 37 (HC), 12 (SpEn), 41 (MTE), 40 (ME), 35 (HA), 32 (A5-2), 7 (ZC), 5 (V), 8 (SK), 9 (KT), 33 (A5-3), 34 (A5-4), 4 (SD), 22 (D3-4).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 10</head><label>10</label><figDesc>Fig. 10 Variation in classification accuracy and computation time with increasing number of selected features in results from Experiment 4</figDesc><graphic coords="14,337.33,70.16,171.16,113.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Experiment 4 :</head><label>4</label><figDesc>ReliefF feature selection algorithm During experiment 4, the ReliefF algorithm was carried out with regard to the feature cluster. The ordering of efficient features obtained through the use of the ReliefF algorithm, was found to be: PFD, HE, PEn, MaxV, D5-1, ZC, SK, MinV, SpEn, D5-4, D5-3, AM, D4-1, D5-2, MN, HC, KT, D4-3, REn, WV-3, WV-2, D3-1, WV-1, D4-2, D3-3, MCL, ApEn, A5-1, D3-2, MTE, A5-3, WV-4, A5-4, HM, SD, D4-4, A5-2, ME, HA, V, D3-4. Figure 10 displays the classification accuracy rates and the computation times of the feature clusters identified by the ReliefF algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>2 (</head><label>2</label><figDesc>MaxV), 27 (D5-1),7 (ZC), 8 (SK), 3 (MinV), 12 (SpEn), 30 (D5-4), 29 (D5-3), 1 (AM), 23 (D4-1), 28 (D5-2), 6 (MN), 37 (HC), 9 (KT), 25 (D4-3), 11 (REn), 17 (WV-3), 16 (WV-2), 19 (D3-1), 15 (WV-1), 24 (D4-2), 21 (D3-3), 38 (MCL), 14 (ApEn), 31 (A5-1), 20 (D3-2), 41 (MTE), 33 (A5-3), 18 (WV-4).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 11 Fig. 12 5</head><label>1112</label><figDesc>Fig.11The classification accuracy rates and computation times for the feature cluster identified by the FCBF algorithm</figDesc><graphic coords="15,206.80,67.52,142.60,89.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 13</head><label>13</label><figDesc>Fig.13The classification accuracy rates and computation times for the cluster feature identified by the hybrid approach</figDesc><graphic coords="16,206.08,58.49,149.56,94.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 14</head><label>14</label><figDesc>Fig. 14 Performance statistics for each sleep stage</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>et al. [29] W, N-REM 1, N-REM 2, N-REM 3, N-REM 4, REM EEG signals: Welch spectral analysis, k-means clustering based feature weighting Decision tree (C4.5) 92.40 % Ozsen [9] W, N-REM 1, N-REM 2, N-REM 3, REM EEG, EOG and EMG signals: Class-dependent sequential feature selection ANN 90.93 % Hsu et al. [71] W, N-REM 1, N-REM 2, SWS, REM EEG signals: Energy features Elman recurrent neural classifier 87.2 % Proposed method W, N-REM 1, N-REM 2, N-REM 3, N-REM 4, REM EEG Signals: 27 (D5-1), 10 (PFD), 13 (PEn), 2 (MaxV) and 39 (HE)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>The distribution of sleep stages on dataset</figDesc><table><row><cell>Sleep stages</cell><cell>Awake</cell><cell>N-REM stage 1</cell><cell>N-REM stage 2</cell><cell>N-REM stage 3</cell><cell>N-REM stage 4</cell><cell>REM</cell><cell>Total</cell></row><row><cell>Number of epochs in stages</cell><cell>1,109</cell><cell>897</cell><cell>988</cell><cell>1,078</cell><cell>764</cell><cell>324</cell><cell>5,160</cell></row><row><cell cols="2">The duration of each epoch is 30 s</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3</head><label>3</label><figDesc>Short explanations of the statistical attributes =1,2,3…n is a time series, N is the number of data points, AM is the mean of the sample. Maximum value(MaxV)</figDesc><table><row><cell>Feature name</cell><cell></cell><cell>Formula</cell><cell></cell><cell>Explanation</cell></row><row><cell>Minimum value (MinV)</cell><cell>:</cell><cell>MinV=min[x n ]</cell><cell>(1)</cell><cell>where x n</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4</head><label>4</label><figDesc>Parameters of Hjorth.</figDesc><table><row><cell cols="2">Feature name Activity</cell><cell>Mobility</cell><cell>Complexity (HC)</cell></row><row><cell></cell><cell>(HA)</cell><cell>(HM)</cell></row><row><cell>Equation</cell><cell>HA=σ 0 2</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5</head><label>5</label><figDesc>The best result of all methods and their corresponding size of selected feature subsets</figDesc><table><row><cell>Method</cell><cell>Feature number</cell><cell>Classification rate (%)</cell></row><row><cell>RF</cell><cell>12</cell><cell>96.39</cell></row><row><cell>DT</cell><cell>38</cell><cell>93.30</cell></row><row><cell>RBF</cell><cell>20</cell><cell>89.25</cell></row><row><cell>FFNN</cell><cell>39</cell><cell>71.53</cell></row><row><cell>SVM</cell><cell>34</cell><cell>93.27</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6</head><label>6</label><figDesc>The best result of all methods and their corresponding size of selected feature subsets</figDesc><table><row><cell>Method</cell><cell>Feature number</cell><cell>Classification rate (%)</cell></row><row><cell>RF</cell><cell>37</cell><cell>96.33</cell></row><row><cell>DT</cell><cell>24</cell><cell>92.32</cell></row><row><cell>RBF</cell><cell>37</cell><cell>89.36</cell></row><row><cell>FFNN</cell><cell>36</cell><cell>71.14</cell></row><row><cell>SVM</cell><cell>30</cell><cell>93.26</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7</head><label>7</label><figDesc>The best result of all methods and their corresponding size of selected feature subsets</figDesc><table><row><cell>Method</cell><cell>Feature number</cell><cell>Classification rate (%)</cell></row><row><cell>RF</cell><cell>31</cell><cell>96.22</cell></row><row><cell>DT</cell><cell>39</cell><cell>92.73</cell></row><row><cell>RBF</cell><cell>37</cell><cell>89.36</cell></row><row><cell>FFNN</cell><cell>36</cell><cell>71.08</cell></row><row><cell>SVM</cell><cell>39</cell><cell>92.88</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8</head><label>8</label><figDesc>The best result of all methods and their corresponding size of selected feature subsets</figDesc><table><row><cell>Method</cell><cell>Feature number</cell><cell>Classification rate (%)</cell></row><row><cell>RF</cell><cell>32</cell><cell>96.22</cell></row><row><cell>DT</cell><cell>36</cell><cell>92.61</cell></row><row><cell>RBF</cell><cell>37</cell><cell>89.36</cell></row><row><cell>FFNN</cell><cell>38</cell><cell>71.49</cell></row><row><cell>SVM</cell><cell>26</cell><cell>93.12</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 9</head><label>9</label><figDesc></figDesc><table><row><cell>The best result of all</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>experiments</cell><cell>Experiment Type</cell><cell>Feature selection</cell><cell>Classification</cell><cell>Feature</cell><cell>Classification</cell></row><row><cell></cell><cell></cell><cell>algorithm</cell><cell>algorithm</cell><cell>number</cell><cell>rate (%)</cell></row><row><cell></cell><cell>Experiment 1</cell><cell>Fisher score</cell><cell>RF</cell><cell>12</cell><cell>96.39</cell></row><row><cell></cell><cell>Experiment 2</cell><cell>mRMR</cell><cell>RF</cell><cell>37</cell><cell>96.33</cell></row><row><cell></cell><cell>Experiment 3</cell><cell>t-test</cell><cell>RF</cell><cell>31</cell><cell>96.22</cell></row><row><cell></cell><cell>Experiment 4</cell><cell>ReliefF</cell><cell>RF</cell><cell>32</cell><cell>96.22</cell></row><row><cell></cell><cell>Experiment 5</cell><cell>FCBF</cell><cell>RF</cell><cell>5</cell><cell>94.65</cell></row><row><cell></cell><cell>Experiment 6</cell><cell>A hybrid approach</cell><cell>RF</cell><cell>5</cell><cell>97.03</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>. Under Dr. Iber Conrad's chairmanship, in 2007 the AASM determined new rules for scoring sleep, and these new rules were employed in sleep staging. There are the following changes in sleep stages definition: S1,</figDesc><table><row><cell></cell><cell>Accuracy</cell><cell>Sensitivity</cell><cell>Specificity</cell></row><row><cell>Wake</cell><cell>0,100</cell><cell>0,100</cell><cell>0,100</cell></row><row><cell>Stage 1</cell><cell>098</cell><cell>096</cell><cell>099</cell></row><row><cell>Stage 2</cell><cell>094</cell><cell>095</cell><cell>099</cell></row><row><cell>Stage 3</cell><cell>096</cell><cell>096</cell><cell>099</cell></row><row><cell>Stage 4</cell><cell>097</cell><cell>097</cell><cell>099</cell></row><row><cell>REM</cell><cell>097</cell><cell>095</cell><cell>100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 10</head><label>10</label><figDesc>REM stage 3 and N-REM stage 4, respectively<ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b72">73]</ref>. Since the characteristics stages N-REM stage 3 and N-REM 4 are very similar, the AASM combined stages S3 and S4 into the deep sleep, or slow wave sleep (SWS), stage. This was done, to facilitate simple and accurate sleep staging. The term, SWS, was used to reinforce this stage's physical meaning. In the same vein, the current study utilizes the fivestage classification: Awake, S1; S2; SWS; and REM. During the study, experts undertook the sleep scoring process by following AASM standards. Table11displays the results obtained from the confusion matrix table and the accuracy rates obtained in each stage.</figDesc><table><row><cell>Scoring agreement be-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>tween manual scoring and the</cell><cell cols="2">Expert's score</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>proposed method (according to</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>R&amp;K rules)</cell><cell>Stage</cell><cell>Awake</cell><cell>Stage 1</cell><cell>Stage 2</cell><cell>Stage 3</cell><cell>Stage 4</cell><cell>REM</cell></row><row><cell>Proposed method</cell><cell>Awake</cell><cell>1,109</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell>Stage 1</cell><cell>0</cell><cell>875</cell><cell>25</cell><cell>7</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell>Stage 2</cell><cell>0</cell><cell>15</cell><cell>931</cell><cell>25</cell><cell>5</cell><cell>0</cell></row><row><cell></cell><cell>Stage 3</cell><cell>0</cell><cell>7</cell><cell>15</cell><cell>1,037</cell><cell>15</cell><cell>3</cell></row><row><cell></cell><cell>Stage 4</cell><cell>0</cell><cell>0</cell><cell>7</cell><cell>5</cell><cell>742</cell><cell>8</cell></row><row><cell></cell><cell>REM</cell><cell>0</cell><cell>0</cell><cell>10</cell><cell>4</cell><cell>2</cell><cell>313</cell></row><row><cell>Accuracy (%)</cell><cell></cell><cell>100</cell><cell>97.55</cell><cell>94.23</cell><cell>96.20</cell><cell>97.12</cell><cell>96.60</cell></row><row><cell>Overall Accuracy (%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>97.03</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 11</head><label>11</label><figDesc>Scoring agreement between manual scoring and the proposed method (according to AASM rules)</figDesc><table><row><cell cols="2">Expert's score</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Stage</cell><cell cols="5">Awake Stage 1 Stage 2 SWS REM</cell></row><row><cell cols="3">Proposed method Awake 1,109 0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell cols="2">Stage 1 0</cell><cell>881</cell><cell>18</cell><cell>10</cell><cell>0</cell></row><row><cell cols="2">Stage 2 0</cell><cell>9</cell><cell>947</cell><cell>16</cell><cell>4</cell></row><row><cell>SWS</cell><cell>0</cell><cell>7</cell><cell>17</cell><cell cols="2">1,804 3</cell></row><row><cell>R E M</cell><cell>0</cell><cell>0</cell><cell>6</cell><cell>1 2</cell><cell>3 1 7</cell></row><row><cell>Accuracy (%)</cell><cell>100</cell><cell>98.21</cell><cell>95.85</cell><cell cols="2">97.93 97.83</cell></row><row><cell>Overall Accuracy (%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>98.02</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 12</head><label>12</label><figDesc>Recent works for automatic sleep stage scoring Shannon entropy, Hjorth activity, mobility and complexity, Hurst exponent, spectral edge frequency 95 %, relative power: delta, theta, alpha, sigma, beta and gamma;EMG signals: Shannon entropy, spectral edge frequency 95 %, gamma relative power .</figDesc><table><row><cell>Accuracy rate</cell><cell>Classification error: 23 %</cell><cell></cell><cell>W: 34 %, N1: 43 %,</cell><cell>N2: 51 %, N3: 82 %,</cell><cell>REM: 82 %, MT: 13 %</cell><cell>71 % (EEG only), 80 % (EEG, EOG</cell><cell>and EMG): 84.57 %: W, 64.56 %:</cell><cell>S1, 85.55 %: S2, 92.90 %: SWS,</cell><cell>72.81 %: REM</cell><cell>74.7 %</cell><cell></cell><cell>95.35 %</cell><cell></cell><cell></cell><cell>84 %</cell><cell></cell><cell>94,03 %</cell><cell>93 %</cell></row><row><cell>Extracted features Model</cell><cell>EEG, EMG, EOG ECG signals: Fractal exponent and analysis</cell><cell>fractal dimension</cell><cell>EEG signals: 2 FFNN (with back propagation</cell><cell>algorithm)</cell><cell></cell><cell>EEG signals: FT coefficients, EMG signals: entropy, EOG FFNN (with back propagation</cell><cell>signals: entropy, kurtosis number and standard deviation. algorithm)</cell><cell></cell><cell></cell><cell>EEG signals: 5 s segments of 0.3-50 Hz, EMG signals: FFNN (with back propagation</cell><cell>40-4,000 Hz, LEOG and REOG signals: 0.5-100 Hz algorithm)</cell><cell>EEG signals: Wavelet transform coefficients FFNN (with back propagation</cell><cell>algorithm), combined with</cell><cell>content rules</cell><cell>EEG signals: Time frequency entropy at different Linear discriminant analysis</cell><cell>frequency bands</cell><cell>EEG signals: Wavelet transform FFNN (with Levenberg-</cell><cell>Marquardt algorithm)</cell><cell>EEG signals: Wavelet packet coefficients FFNN (with back propagation</cell><cell>algorithm)</cell></row><row><cell>Sleep stages</cell><cell>W, S1, S2, SWS, REM</cell><cell></cell><cell>W, transitional sleep(N1), shallow</cell><cell>sleep(N2), deep sleep(N3), REM,</cell><cell>movement time (MT)</cell><cell>W, S1, S2, SWS, REM</cell><cell></cell><cell></cell><cell></cell><cell>REM, S1 (Drowsy), S2 (light sleep),</cell><cell>S3 and S4 (deep sleep)</cell><cell>W, Sleep spindles, REM</cell><cell></cell><cell></cell><cell>W, N-REM 1, N-REM 2, N-REM 3,</cell><cell>N-REM 4, REM</cell><cell>Alert, drowsy, sleep</cell><cell>W, S1, S2, SWS, REM</cell></row><row><cell>Authors</cell><cell>Šušmáková and</cell><cell>Krakovská [25]</cell><cell>Chapotot and Becq</cell><cell>[26]</cell><cell></cell><cell>Zoubek et al. [66]</cell><cell></cell><cell></cell><cell></cell><cell>Tagluk et al. [67]</cell><cell></cell><cell>Sinha [24]</cell><cell></cell><cell></cell><cell>Fraiwan et al. [68]</cell><cell></cell><cell>Subasi et al. [27]</cell><cell>Ebrahimi et al. [69]</cell><cell>Doroshenkov et al.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>J Med Syst (2014) 38:18</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>18, Page 10 of 21 J Med Syst (2014) 38:18</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A transitionconstrained discrete hidden Markov model for automatic sleep staging</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioMedical Eng OnLine</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="52" to="71" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Novel approaches for automated epileptic diagnosis using feature selection and classification algorithms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><surname>Peker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Turk. J. Electr. Eng. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="2092" to="2109" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automated sleep stage identification system based on time-frequency analysis of a single EEG channel and random forest classifier</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fraiwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lweesy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Khasawneh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dickhaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Methods Prog Biomed</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="19" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Epileptic seizure detection from SEEG data by using higher order statistics and spectra</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Artan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Yazgan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="102" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Wavelet based features for epileptic seizure detection</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fathima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bedeeuzzaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Farooq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">U</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MES J of Technol and Manag</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="108" to="112" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Classification of human emotions from EEG signals using statistical features and neural network</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>San</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rizoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Seong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J Integr Eng</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="71" to="79" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The detection of an epileptiform activity on EEG signals by using data mining process</title>
		<author>
			<persName><forename type="first">M</forename><surname>Albayrak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Koklukaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of New World Sci. Acad</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">EEG signal classification using wavelet feature extraction and a mixture of expert model</title>
		<author>
			<persName><forename type="first">A</forename><surname>Subasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst Appl</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1084" to="1093" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Classification of sleep stages using class-dependent sequential feature selection and artificial neural network</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ozsen</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00521-012-1065-4</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Comput. &amp; Applic</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Discrete harmony search based expert model for epileptic seizure detection in electroencephalography</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Panigrahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst Appl</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="4055" to="4062" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Seizure detection in EEG signals: A comparison of different approaches. IEEE EMBS&apos;06</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Mohseni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maghsoudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Shamsollahi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="6724" to="6727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A genetic approach to selecting the optimal feature for epileptic seizure prediction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Alessandro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Vachtsevanos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Esteller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Echauz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Litt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1703" to="1706" />
		</imprint>
	</monogr>
	<note>IEEE EMBC&apos;01</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Entropies for detection of epilepsy in EEG</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kannathal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sadasivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Methods Prog Biomed</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="187" to="194" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Artificial neural network based epileptic detection using time domain and frequency domain features</title>
		<author>
			<persName><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Eswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sriraam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Med Syst</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="647" to="660" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Permutation entropy to detect vigilance changes and preictal states from scalp EEG in epileptic patients-A preliminary study</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Bruzzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gesierich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Santi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Tassinari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Birbaumer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rubboli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurol Sci</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="9" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">EEG non-linear feature extraction using correlation dimension and Hurst exponent</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurol Res</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="908" to="912" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A new approach to automated epileptic diagnosis using EEG and probabilistic neural network. ICTAI&apos;08</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Y</forename><surname>Lie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="482" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Employment and comparison of different Artificial Neural Networks for epilepsy diagnosis from EEG signals</title>
		<author>
			<persName><forename type="first">E</forename><surname>Sezer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Isik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Saracoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Med Syst</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="347" to="362" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Expert-system classification of sleep/waking states in infants</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Holzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Pe´rez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Held</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Martı´n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pizarro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Pe´rez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Garrido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pierano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med Biological Biol. Eng. Comput</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="466" to="476" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Sleep stage classification using wavelet transform and neural network</title>
		<author>
			<persName><forename type="first">E</forename><surname>Oropesa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Cycon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jobert</surname></persName>
		</author>
		<idno>TR-99-008</idno>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
	<note type="report_type">ICSI Technical Report</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Computer-assisted sleep staging</title>
		<author>
			<persName><forename type="first">R</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gotman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Biomed Eng</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="1412" to="1423" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">EEG feature extraction for classification of sleep stages</title>
		<author>
			<persName><forename type="first">E</forename><surname>Estrada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nazeran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Behmehani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Burk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lucas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual conference of the IEEE EMBS</title>
		<meeting>the 26th annual conference of the IEEE EMBS<address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="196" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Comparison between five classifiers for automatic scoring of human sleep recordings</title>
		<author>
			<persName><forename type="first">G</forename><surname>Becq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Charbonnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chapotot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buguet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bourdon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baconnier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stud Comput Intell</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="113" to="127" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Artificial neural network and wavelet based automated detection of sleep spindles, REM sleep and wake states</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Sinha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Med Syst</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="291" to="299" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Discrimination ability of individual measures used in sleep stages classification</title>
		<author>
			<persName><forename type="first">K</forename><surname>Šušmáková</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krakovská</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif Intell Med</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="261" to="277" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Automated sleep-wake staging combining robust feature extraction, artificial neural network classification, and flexible decision rules</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chapotot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Becq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Adapt Control and Signal Process</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="409" to="423" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automatic recognition of vigilance state by using wavelet-based artificial neural network</title>
		<author>
			<persName><forename type="first">A</forename><surname>Subasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Kiymik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Akin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Erogul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput Appl</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="55" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Feature selection for sleep/wake stages classification using data driven methods</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zoubek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Charbonnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lesecq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buguet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chapotot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed Signal Process Control</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="171" to="179" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Classification of human sleep stages based on EEG processing using hidden markov models</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Doroshenkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Konyshev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Selishchev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed Eng</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="25" to="28" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Automatic sleep stage classification based on EEG signals using neural networks and wavelet packet coefficients. Proceeding of IEEE EMBC</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mikaeili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Estrada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nazeran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1151" to="1154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Genetic fuzzy classifier for sleep stage identification</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Biol Med</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="629" to="634" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">A novel data pre-processing method on automatic determining of sleep stages: Kmeans clustering based feature weighting. Complex Systems and Applications-ICCSA</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gunes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Polat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yosunkaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dursun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Le Havre-France</publisher>
			<biblScope unit="page" from="112" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Estimation of sleep stages by an artificial neural network employing EEG, EMG and EOG</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Tagluk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sezgin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Akin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Med Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="717" to="725" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Classification of sleep stages using multiwavelet time frequency entropy and LDA</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fraiwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lweesy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Khasawneh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fraiwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dickhaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods Inf Med</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="230" to="237" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Automatic sleep stage recurrent neural classifier using energy features of EEG signals</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="105" to="114" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">PhysioBank, PhysioToolkit, and PhysioNet: components of a new research resource for complex physiologic signals</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Circulation</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="215" to="220" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Automated EEG analysis with microcomputers</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Karacan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sleep</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="435" to="443" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Anticipating epileptic seizures in real time by a non-linear analysis of similarity between EEG recordings</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L V</forename><surname>Quyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martinerie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Baulac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Varela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroreport</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="2149" to="2215" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Time domain descriptors and their relation to a particular model for generation of EEG activity</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hjorth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CEAN -Computerized EEG analysis</title>
		<imprint>
			<biblScope unit="page" from="3" to="8" />
			<date type="published" when="1975">1975</date>
			<publisher>Gustav Fischer Verlag</publisher>
			<pubPlace>Stuttgart</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Kolmogorov complexity of finite sequences and recognition of different preictal EEG patterns. IEEE CBMS&apos; 95</title>
		<author>
			<persName><forename type="first">A</forename><surname>Petrosian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="212" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Oneclass novelty detection for seizure analysis from intracranial EEG</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Vachtsevanos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Litt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Learn Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1025" to="1044" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Line length: an efficient feature for seizure onset detection. IEEE EMBS&apos;01</title>
		<author>
			<persName><forename type="first">R</forename><surname>Esteller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tcheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Litt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pless</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1707" to="1710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Fractals and the analysis of waveforms</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Biol Med</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="145" to="156" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Epileptic EEG signal classification using one-class support vector machines, Istanbul Technical University</title>
		<author>
			<persName><forename type="first">E</forename><surname>Avsar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">M.Sc. Thesis</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Rotation-Invariant texture analysis and classification by artificial neural networks and wavelet transform</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hasiloglu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Application of adaptive neuro-fuzzy inference system for epileptic seizure detection using wavelet feature extraction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Subasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Biol Med</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="227" to="244" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Classification of EEG using PCA, ICA and Neural Network</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Vargantwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Rajput</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Eng Adv. Technol. (IJEAT)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A new complex-valued intelligent system for automated epilepsy diagnosis using EEG signals</title>
		<author>
			<persName><forename type="first">M</forename><surname>Peker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Glob J Technol: 3rd World Conference on Inf Technol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1121" to="1128" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Entropy and complexity measures for EEG signal classification of schizophrenic and control participants</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sabeti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katebi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Boostani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif Intell Med</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="263" to="274" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">On a new axiomatic theory of probability</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rényi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Math Hung</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="285" to="335" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title/>
		<ptr target="http://en.wikipedia.org/wiki/Approximate_entropy" />
	</analytic>
	<monogr>
		<title level="j">Approximate entropy</title>
		<imprint>
			<date type="published" when="2012-10-10">10.10.2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Morphology variability analysis of wrist pulse waveform for assessment of arteriosclerosis status</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Q H</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Med Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="331" to="339" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Epileptic EEG classification based on extreme learning machine and nonlinear features</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Epilepsy Res</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="29" to="38" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Heart rate variability: a review</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">R</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kannathal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Suri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med Biol Eng Comput</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="1031" to="1051" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Physiological time-series analysis: what does regularity quantify?</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Pincus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Goldberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am Physiol. Soc</title>
		<imprint>
			<biblScope unit="volume">266</biblScope>
			<biblScope unit="page" from="1643" to="1656" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Permutation entropy: a natural complexity measure for time series</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pompe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys Rev Lett</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="1" to="4" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Fine-grained permutation entropy as a measure of natural complexity for time series</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chinese Phys B</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="2690" to="2695" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Feature selection in a kernel Space. 24th Annual International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="121" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Feature selection for high-dimensional data: A fast correlation-based filter solution</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML&apos;03</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="856" to="863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Minimum redundancy feature selection from microarray gene expression data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second IEEE Computational Systems Bioinformatics Conference</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="523" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Estimating attributes: Analysis and extensions of RELIEF</title>
		<author>
			<persName><forename type="first">I</forename><surname>Kononenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML&apos;94</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="171" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Predicting and analyzing secondary education placement-test scores: A data mining approach</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ucar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Delen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst Appl</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="9468" to="9476" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Classification of satellite images using decision trees: Kocaeli case</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kavzoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Colkesen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electron. J Map Technol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="36" to="45" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">C4.5: Programs for machine learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Quinlan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Mateo</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Application of inductive learning to gain knowledge of an expert system. VI</title>
		<author>
			<persName><forename type="first">O</forename><surname>Akgobek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Production Research Symposium</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Optical gain model proposed with the use of artificial neural networks optimised by artificial bee colony algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yigit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eryigit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Celebi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optoelectronics Adv Mater Rapid Commun</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1026" to="1029" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A proposed CAD model based on amplified spontaneous emission spectroscopy</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Celebi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Optoelectron Adv Mater</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1573" to="1579" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">The use of artificial neural networks in simulation of mobile ground vehicles</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goktas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cavusoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Toktas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math Comput Appl</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="87" to="96" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">An accurate single CAD model based on radial basis function network</title>
		<author>
			<persName><forename type="first">N</forename><surname>Celebi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optoelectron. Adv. Mater Rapid Commun</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="498" to="501" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Support vector networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach Learn</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">A medical decision support system based on support vector machines and the genetic algorithm for the evaluation of fetal wellbeing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ocak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Med Syst</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">American academy of sleep medicine task force, Sleep related breathing disorders in adults: recommendations for syndrome definition and measurement techniques in clinical research</title>
	</analytic>
	<monogr>
		<title level="j">Sleep</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="667" to="689" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
