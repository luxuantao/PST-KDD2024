<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Asking Effective and Diverse Questions: A Machine Reading Comprehension based Framework for Joint Entity-Relation Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tianyang</forename><surname>Zhao</surname></persName>
							<email>tyzhao@buaa.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Lab of Software Development Environment</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhao</forename><surname>Yan</surname></persName>
							<email>zhaoyan@tencent.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Tencent Cloud Xiaowei</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yunbo</forename><surname>Cao</surname></persName>
							<email>yunbocao@tencent.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Tencent Cloud Xiaowei</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhoujun</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Lab of Software Development Environment</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Asking Effective and Diverse Questions: A Machine Reading Comprehension based Framework for Joint Entity-Relation Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent advances cast the entity-relation extraction to a multi-turn question answering (QA) task and provide an effective solution based on the machine reading comprehension (MRC) models. However, they use a single question to characterize the meaning of entities and relations, which is intuitively not enough because of the variety of context semantics. Meanwhile, existing models enumerate all relation types to generate questions, which is inefficient and easily leads to confusing questions. In this paper, we improve the existing MRCbased entity-relation extraction model through diverse question answering. First, a diversity question answering mechanism is introduced to detect entity spans and two answering selection strategies are designed to integrate different answers. Then, we propose to predict a subset of potential relations and filter out irrelevant ones to generate questions effectively. Finally, entity and relation extractions are integrated in an end-to-end way and optimized through joint learning. Experiment results show that the proposed method significantly outperforms baseline models, which improves the relation F1 to 62.1% (+1.9%) on ACE05 and 71.9% (+3.0%) on CoNLL04. Our implementation is available at https://github.com/TanyaZhao/MRC4ERE.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Identifying entity mentions and their relations from unstructured texts is a fundamental and challenging task in information extraction, which has received growing interests recently. Given an input context, the task aims to recognize the entity spans and detect the relations between every head and tail entity pairs, i.e.,(New York, PART-WHOLE, U.S.).</p><p>Existing advances in entity-relation extraction fall into two groups: pipeline approaches and joint approaches. Traditional methods employ a pipelined structure which divides the task into two sub-tasks, recognizing entity spans and predicting relations of any entity pairs. The limitation of these soldiers Baghdad U.S.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PER GPE GPE ORF-AFF PHYS</head><p>Step 1: Head Entity Extraction Q1: Find people mentioned in the text. A1: soldiers. Q2: Find organizations mentioned in the text. A2: NONE Q3: Find geo-political entities mentioned in the text. A3: U.S. , Baghdad Q4: Find facilities mentioned in the text. A4: NONE ‚Ä¶‚Ä¶</p><p>Step 2: Relation Prediction</p><p>Universal Relation Set: {ORF-AFF, ART, PHYS, GEN-AFF, PAER-WHOLE, PER-SOC} Candidate Relation Set: : {ORF-AFF, PHYS}</p><p>Step 3: Tail Entity Extraction Q1: Find geo-political entities that soldiers is employed. A1: U.S. Q2: Find geo-political entities which are invested by soldiers. A2: NONE Q3: Find geo-political entities near soldiers. A2: Baghdad approaches is obvious -they neglect the potential interactions of the sub-tasks and may suffer from error propagation. Joint approaches integrate entity extraction and relation extraction into a unified model. Various mechanisms for joint learning have been explored, such as parameters sharing <ref type="bibr" target="#b4">[Katiyar and Cardie, 2017]</ref>, global normalization <ref type="bibr" target="#b13">[Zhang et al., 2017]</ref> and joint type decoding <ref type="bibr" target="#b11">[Sun et al., 2019]</ref>. They treat relation extraction as a multi-classification task and use multiclassification models to predict the relation of each pair of entities. However, as stated in <ref type="bibr" target="#b12">[Zeng et al., 2018]</ref>, these models capture only the features based on the input contexts and the entity pairs, which are insufficient to extract all lexical and semantic information.</p><p>Recently, with the boost of machine reading comprehension (MRC), several works propose to address entity-relation extraction task with MRC-based method. <ref type="bibr" target="#b5">Levy et al. [2017]</ref> firstly reduce relation extraction to the problem of answering simple questions. Later, <ref type="bibr" target="#b6">Li et al. [2019a]</ref> improve the framework and propose to transform entity-relation extraction into a multi-turn question answering (QA) task. Their method first detects head entities from the context by answering entity-specific questions using the machine reading comprehension model. Then, it goes through the universal rela-tion set to generate a relation-specific question based on the head entity. Finally, tail entities are obtained by answering the question, as shown in step 3 of Figure <ref type="figure" target="#fig_0">1</ref>. Advantages of the MRC-based framework are as follows. (1) The question provides external prior evidences, i.e.,entity and relation types.</p><p>(2) The MRC model can better capture the semantic information based on the interaction between question and context. Both above contribute to entity and relation extraction. In this paper, we also focus on the MRC-based framework.</p><p>Although previous works for MRC-based entity-relation extraction have achieved great success, these methods still face two challenges. Intuitively, due to the variety of context semantics, using just one question can not well characterize the exact meaning of entities and relations. Meanwhile, it easily leads to confusing questions. For example, the relation ORG-AFF (organization-affiliation) contains a broad sub-types, such as investor-shareholder, ownership, employment, etc. Consider the example in Figure <ref type="figure" target="#fig_0">1</ref>, if we represent ORG-AFF only with one question as in <ref type="bibr" target="#b7">[Li et al., 2019b]</ref>: Find geo-political entities which is invested by soldiers, it is difficult for the MRC model to capture the meaning of employment in this case. Generally, multiple explanations can make a complex problem clearer. Therefore, it is necessary to introduce diverse questions to better formalize entities and relations. Second, existing work needs to enumerate all relation types when generating relation-specific questions. That would lead to a large set of question samples. In addition, most of the questions are negative samples and thus result in a serious bias issue and make the extraction less inefficient.</p><p>In this paper, we present a novel end-to-end solution to enhance the existing MRC-based entity-relation extraction. To address the first issue, we design a diverse question answering (DQA) mechanism. It exploits multiple simple questions to extract corresponding answers successively. Then, an answer ensemble strategy based on weighted voting is proposed to combine the different answers. As for the second issue, we present to conduct relation prediction (RP) as a prior to obtain a subset of most relevant relations and filter out the useless ones. Hence, questions can be generated effectively based on the relevant relations, rather than traversing the entire set of relations exhaustively, as shown in step 2 of Figure <ref type="figure" target="#fig_0">1</ref>. Additionally, to better capture the inherent interaction among the proposed procedures, we combine all the components into an end-to-end structure and optimize the model jointly. Extensive experiments on ACE05 and CoNLL04 datasets demonstrate the effectiveness of the proposed method. To summarize, the main contributions of this work are:</p><p>‚Ä¢ We design a diverse question answering mechanism to better characterize entities and relations, and obtain the proper answer based on the answer ensemble strategy.</p><p>‚Ä¢ We propose to apply relation prediction to select most potential relations and filter out irrelevant ones so as to generate relation questions in an effective way.</p><p>‚Ä¢ By training jointly, the proposed method significantly outperforms the baseline models on both ACE05 and CoNLL04 datasets, which well demonstrates its effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>This work relates to three lines of research: relation extraction, machine reading comprehension (MRC) and MRCbased methods for NLP tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Relation Extraction</head><p>Traditional works on relation extraction (RE) adopt pipelined methods that recognize entities first and then predict their relations <ref type="bibr" target="#b9">[Miwa et al., 2009;</ref><ref type="bibr" target="#b1">Chan and Roth, 2011;</ref><ref type="bibr" target="#b8">Lin et al., 2016]</ref>. This separation makes the RE task easy to handle, but ignores the inherent interaction between the sub-tasks and is affected by error propagation. To alleviate this limitation, later works propose to extract entities and relations jointly.</p><p>Earlier joint models are built on hand-crafted features or external parsers which and thus introduce additional complexity. With the success of deep learning models, several neuralnetwork based methods have been presented to address this issue. For example, <ref type="bibr" target="#b9">Miwa et al. [2016]</ref> propose to extract entities and relations with tree-structured BiLSTM based on parameter sharing. Then <ref type="bibr" target="#b4">Katiyar and Cardie [2017]</ref> replace it with a attention-based network to better model the semantic relations between entities. Later, <ref type="bibr" target="#b12">Zeng et al. [2018]</ref> introduce a seq2seq structure to generate entity-relation triples naturally. However, as stated in <ref type="bibr" target="#b11">[Sun et al., 2019]</ref>, existing joint models can predict entity spans correctly, but predict their types less correctly. So far, to better tackle the joint inference on entity types and relation types, the graph convolutional network is used in <ref type="bibr" target="#b2">[Fu et al., 2019]</ref> and <ref type="bibr">[Sun et al., 2019]</ref>. Specifically, the proposed model predicts entities and all corresponding relations jointly through a MRC-based method in an end-to-end way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Machine Reading Comprehension</head><p>In recent years, the boost of large-scale corpora <ref type="bibr">[Rajpurkar et al., 2016;</ref><ref type="bibr" target="#b3">Joshi et al., 2017;</ref><ref type="bibr" target="#b1">Dua et al., 2019]</ref> have led to the rapid progress on machine reading comprehension. SQUAD <ref type="bibr">[Rajpurkar et al., 2016]</ref> is an extractive MRC benchmark to detect the answer span from the context. A majority of neural-based models tackle the task by predicting the start and the end position of the answer based on the attention mechanism, such as BiDAF <ref type="bibr" target="#b10">[Seo et al., 2017]</ref>, <ref type="bibr">QANet [Yu et al., 2018]</ref> and SAN <ref type="bibr" target="#b9">[Liu et al., 2018]</ref>. More recently, the work by <ref type="bibr" target="#b3">Hu et al. [2019]</ref> achieves excellent performance by enhancing with the pre-trained contextual embeddings like BERT <ref type="bibr">[Devlin et al., 2019]</ref>. However, these models are defective for multi-answer-typed MRC. To address this issue, some existing works propose to validate the answerability of a question first and then predict the candidate answers <ref type="bibr">[Clark and Gardner, 2017]</ref>. In this work, instead of extracting the start and end position from context, we predict the answer boundary of every token based on the BIOES tagging scheme. In this way, multiple entity spans can be detected from the context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">MRC-based Methods for NLP Tasks</head><p>Recently, several attempts of addressing NLP tasks with MRC-based methods have been made. For example, <ref type="bibr" target="#b5">Levy et al. [2017]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>In this section, we introduce each component of the proposed method in detail. A key motivation behind this is that, generally different perspectives of descriptions can make a complex problem clearer. And we find that exploiting different questions helps to extract multiple answers. Additionally, enumerating all relations for question generation is not only costly but can also lead to confusing samples. Therefore, we consider generating effective questions by predicting potential relations and filtering out irrelevant ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Definition</head><p>Formally, denote E and R as the set of pre-defined entity types and relation categories, respectively. Given an input context with N c tokens c = {c 1 , c 2 , . . . , c Nc }, the entity-relation extraction task aims to extract a set of entities mentions e = {e 1 , e 2 , . . . , e M } with specific types y = {y 1 , y 2 , . . . , y M }, and predict the relation r ij for each entity pair (e i , e j ), where y i ‚àà E and r ij ‚àà R. Triplets such as (e i , r ij , e j ) are formulated as the output, where e i is the head entity and e j is the tail entity, e.g.,(New York, PART-WHOLE, U.S.).</p><p>In this work, we reduce the entity-relation extraction to the problem of answering simple questions. Specifically, the extraction of triplet (e i , r ij , e j ) is transformed into two QA steps as follows. First, the head entity e i is detected from the context by answering questions such as "Find y i that mentioned in the text". Then, relation r ij is mapped to questions that are parameterized by e i , y j , and with e j as the answer. For example, the relation PART-WHOLE corresponds to questions like "Find y j that e i geographically relates to". In this way, answer spans can be extracted from the context based on the the MRC model.</p><p>Overall, the MRC-based entity-relation extraction consists of three steps as follows.</p><p>(1) The head entity extraction step. As shown in Figure <ref type="figure" target="#fig_1">2</ref>, we generate diverse questions for every entity type. Then, each question is combined with the context and is fed into the MRC-based entity extractor successively. After obtaining corresponding answers, we select the final answer based on the answer ensemble strategy. If no answer is detected, it means this type of entity is not included in the context. Find geo-political entities to which soldiers belongs.</p><p>Find geo-political entities that is found by soldiers.</p><p>Find geo-political entities that soldiers is employed. (2) The relation prediction step. In this step, for each extracted head entity e i , we filter out the low probability relations irrelevant to e i and predict a potential subset R i ‚àà R to keep the useful ones. In this way, most of the negative samples can be discarded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relation Questions Generation</head><formula xml:id="formula_0">q1 q2 q3 ‚Ä¢‚Ä¢‚Ä¢ a1 a2 a3 ùëé * ‚Ä¢‚Ä¢‚Ä¢ ‚Ñé " # $ ‚Ñé % # $ ‚Ñé &amp; ) # $ Entity label embedding - ‚Ñé "</formula><p>( </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">BERT-based MRC model for Entity Extraction</head><p>BERT <ref type="bibr">[Devlin et al., 2019]</ref> is known as a language representations built on the deep bidirectional transformers. It outperforms state-of-the-art models on a wide-range of NLP tasks, including machine reading comprehension. We use the pretrained BERT as the main structure for the MRC model. As illustrated in Figure <ref type="figure" target="#fig_1">2</ref>, given a question q = {q 1 , q 2 , . . . , q Nq } and an context c = {c 1 , c 2 , . . . , c Nc }, the input of the MRC model are the concatenation as</p><formula xml:id="formula_2">x = [CLS, x q 1 , . . . , x q Nq , SEP, x c 1 , . . . , x c Nc , SEP],<label>(1)</label></formula><p>where {x q 1 , . . . , x q Nq } and {x c 1 , . . . , x c Nc } are the word piece embeddings of the question Q and the context C, respectively. CLS denotes a special token and SEP denotes a separator. Encoded by the multi-layer self-attention structure, BERT outputs the contextual representation for each context token as h = {h 1 , h 2 , . . . , h Nc }, h i ‚àà R d h , where d h denotes the dimension of the last hidden layer of BERT.</p><p>Then, considering that the context might have multiple answers, we apply a softmax classification layer to the hidden outputs h and predict the BIOES boundary labels. For each input x i , the probability of the candidate BIOES label can be calculated as</p><formula xml:id="formula_3">Pr(label = √¢|x i ) = softmax(W b ‚Ä¢ h i + b b ),<label>(2)</label></formula><p>where </p><formula xml:id="formula_4">W b ‚àà R d h √ód b , b b ‚àà R d b are learned</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Diverse Question Answering</head><p>Intuitively, explaining a problem from different perspectives can make it more clear. As an inspiration, we generate a group of questions for each entity and relation type based on the pre-defined question templates. Questions within a group share the same meanings but they are expressed in different ways. For example, to identify the PER (person) entities in a context, three questions with the same semantics but diverse expressions can be generated as follows.</p><p>‚Ä¢ q1: Who is mentioned in the context?</p><p>‚Ä¢ q2: Find people mentioned in the context?</p><p>‚Ä¢ q3: Which words are person entities? Specifically, we use T questions as Q = {q 1 , q 2 , . . . , q T } for entity extraction. As shown in Figure <ref type="figure" target="#fig_1">2</ref>, T questions are combined with the context c as the input to the MRC model. Then T corresponding answers are obtained as A = {a 1 , a 2 , . . . , a T }, where a t = {a t1 , a t2 , . . . , a tNc } is the boundary sequence obtained by the MRC model (Eq.2). Answer Ensemble Strategy. To ensemble different answers, we propose a weighted voting scheme to obtain the proper answer dynamically. Consider w t as the weight for each question q t ‚àà Q, which is initialized as 1.0. At the end of each training epoch, we calculate the F1 score f t for question q t on the development set and update the weight w t as</p><formula xml:id="formula_5">w t = œÉ(f t ) * T,</formula><p>(3) where œÉ(‚Ä¢) is the sigmoid function and * is the element-wise multiplication. Note that, the higher the F1 score, the higher the weight. Hence, the weight w t showcases the quality of the question q t . Based on the learned weight, the final ensemble answer a = {a 1 , a 2 , . . . , a N } is obtained by weighted voting on the token-level. Specifically, the boundary label of the i-th token is selected as</p><formula xml:id="formula_6">a i = arg max B t w t ‚Ä¢ a ti . (<label>4</label></formula><formula xml:id="formula_7">)</formula><p>To this end, the final extracted entities can be inferred based on the ensemble answer a .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Relation Prediction</head><p>Relation prediction aims to identify for each extracted head entity e i , i ‚àà {1, 2, . . . , M } the set of most probable relation types R i ‚äÜ R. This is different from previous work <ref type="bibr" target="#b7">[Li et al., 2019b]</ref> which need to enumerate every relation type in R to generate relation questions. We predict a prior relation types for each head entity and thus those irrelevant relations will be filtered out. Specifically, denote h qt i as the BERT contextual representation for the start token of the head entity e i , q t denotes the t-th question, and x l i the corresponding entity label embedding, the input to the relation predictor is the concatenation of ƒ•i and x l i as ƒ•i = avg t‚ààT h qt i</p><formula xml:id="formula_8">l i = [ ƒ•i , x l i ],<label>(5)</label></formula><p>where x l i is initialized by random sampling and will be finetuned during training. Then, this input is fed to a softmax classifier to yield the probability for entity e i with each relation type r k ‚àà R as</p><formula xml:id="formula_9">Pr(label = r k |e i ) = œÉ(W r ‚Ä¢ l i + b r ),<label>(6)</label></formula><p>where And those labels with scores lower than Œ¥ will be discarded.</p><formula xml:id="formula_10">œÉ(‚Ä¢) is the sigmoid function, W r ‚àà R (d h +d l )√ó|R| , b r ‚àà R |R| ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Joint Training</head><p>To train the model jointly, we optimize the combined objective function during training:</p><formula xml:id="formula_11">L = L head + L rel + L tail ,<label>(7)</label></formula><p>where L head and L tail denote the cross-entropy loss for head entity and tail entity extraction, respectively. L rel denotes the binary cross-entropy loss over relation types for relation prediction. The head and tail entity extractor are built on the standard BERT model and share the parameters for training.</p><p>L is averaged over samples for each batch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head><p>In this section, we empirically demonstrate the effectiveness of diverse question answering and relation prediction strategies for MRC-based entity-relation extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We evaluate the proposed method on two widely-used benchmarks for entity relation extaction: ACE05 and CoNLL04.</p><p>‚Ä¢ ACE05 contains 7 entity types LOC, ORG, PER, GPE, VEH, FAC, WEA and 6 relation types ORG-AFF, PER-SOC, ART, PART-WHOLE, GEN-AFF, PHYS.</p><p>We adopt the same data splits as previous work <ref type="bibr">[Miwa and Bansal, 2016]</ref>. 89.3 (¬± 0.2) 88.5 (¬± 0.5) 88.9 (¬± 0.3) 72.2 (¬± 0.4) 71.5 (¬± 0.3) 71.9 (¬± 0.2) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>We adopt the BERT base (cased) <ref type="bibr">[Devlin et al., 2019]</ref> as the MRC model for our experiments. We apply the BIOES tagging scheme for boundary classification. The entity type embedding is initialized randomly with a uniform distribution and the size d l is set as 50. We generate 3 different questions with a simple natural language-based template for the diverse question answering. The threshold Œ¥ for the relation prediction is set as 0.3. During training, we use the early stopping to avoid overfitting based on the performance on the development set. For evaluation, precision (P), recall (R) and micro-F1 score (F1) are used as metrics in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Result and Analysis</head><p>Baselines. We consider the following strong baselines for comparison. Model <ref type="bibr" target="#b6">[Li and Ji, 2014]</ref> adopts an incremental beam-search framework to extract entities and relations. Models <ref type="bibr" target="#b9">[Miwa and Sasaki, 2014]</ref> and <ref type="bibr" target="#b13">[Zhang et al., 2017]</ref> treat relation extraction as a table-filling problem, the later enhance it with global optimization. <ref type="bibr">Miwa and Bansal [2016]</ref> present a tree-based LSTM to capture dependency information. Models <ref type="bibr" target="#b4">[Katiyar and Cardie, 2017]</ref> and <ref type="bibr" target="#b0">[Adel and Sch√ºtze, 2017]</ref> replace the tree structure with the attentional LSTMs and the globally normalized CNNs, respectively. <ref type="bibr" target="#b1">Bekoulis et al. [2018]</ref> address the relation extraction task with a multi-head selection model. <ref type="bibr" target="#b11">Sun et al. [2019]</ref> explore the graph convolutional network for entity relation extraction Model <ref type="bibr" target="#b7">[Li et al., 2019b]</ref> is MRC-based but uses one question for extraction and enumerates all the relation types.</p><p>Experimental Results. Meanwhile, our method is stable with all F1 standard deviations are no more than 0.3. We perform a significant test with the best baseline suggesting that performance is statistically significant (p &lt; 0.05). We highlight the improvement benefits from two scientific contributions: the diverse question answering and the relation prediction, which enhance the formation of MRC-based entity-relation extraction obviously. In addition, the performance of MRC-based models is remarkably superior to non-MRC-based baselines, which verifies its effectiveness. We consider the reasons are: (1) The question provides important prior type information.</p><p>(2) The MRC model can better capture the interaction between the question and the context based on the self-attention structure.</p><p>Ablation Study. We further study the effects of each proposed components: the diverse question answering (DQA), the relation prediction (PR) and the weighted voting strategy. Results are listed in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Effects of Question Generating Template</head><p>Questions used in the full model are generated with a simple natural language-based template. It is also possible to obtain them using auto-generated pseudo-questions. Therefore, we study the effects of the two question generation ways. Specifically, we generated the entity-specific pseudoquestions based on different descriptions of the entity type. Examples for the person entity are (1) person; (2) entity:person, (3) find person. The relation-specific pseudoquestions are the combinations of head entity text, relation type and tail entity type such as (1) soldier;organizationaffiliation;geo-political entity; (2) soldier;employment;geopolitical entity; (3) soldier;ownership;geo-political entity.</p><p>In Table <ref type="table" target="#tab_8">3</ref>, models using pseudo-questions are obviously inferior to models using natural language. The reason is that natural language can provide more semantic information. But the pseudo-questions lack auxiliary words that contain structural information of entities so that it is difficult for models to understand. However, by using diverse pseudo-questions, the performance of MRC4ERE++ P is improved and the results are strongly competitive to model MRC4ERE N that uses one natural language question. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Golden Entity Results on ACE05</head><p>To better evaluate the performance of our model in relation extraction, we conduct test with golden head entities on ACE05 datasets, which showcases the upper bound result that our model can achieve for relation extraction. Specifically, we keep the same experimental setting with the baseline models <ref type="bibr">[Miwa and Bansal, 2016;</ref><ref type="bibr" target="#b11">Sun et al., 2019]</ref>. The result in Table <ref type="table" target="#tab_9">4</ref> shows that, the proposed method outperforms existing relation classification models by a large margin. This indicates that our method is able to capture the relevant information of given head entities which helps to improve the performance of relation extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Conclusion</head><p>In this paper, we propose an end-to-end solution to improve the existing MRC-based entity-relation framework. First, we present a diverse question answering mechanism and an answer ensemble strategy to extract the proper answer from different perspectives. Then, we introduce the relation prediction method to obtain useful relations for question generation. Finally, the model is combined and optimized through joint learning. Extensive experiments show that the proposed model is effective for entity-relation extraction and achieves significant improvement on ACE05 and CoNLL04 datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An illustration of the entity-relation extraction of the proposed MRC-based framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The framework of the proposed MRC-based model for entity-relation extraction. T questions are combined with the context successively as the input of the BERT. Then, T answers are generated and integrated to extract head entities using the answer ensemble strategy. After that, the relation predictor is used to predict the relation prior. Finally, relation questions are generated for tail entity extraction based on the head entities and predicted relations. The blue dotted lines indicate the relation extraction process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>) The tail entity extraction. Given the extracted head entity, we generate diverse relation-specific questions for each relation r ij ‚àà R i . Examples are shown in the left part of Figure 2. Then, similar to the head entity extraction step, the questions are integrated with the context and fed into the MRC model to extract potential tail entity e j . Therefore, the entity-relation extraction problem can effectively be addressed by the MRC-based framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>d l is the dimension of the entity label embedding and |R| is the size of the relation set. The high score in the classifier denotes the corresponding relation holds for entity e i . Consider a confidence threshold Œ¥, we keep any relation label with a score exceeding Œ¥.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>, sentiment analysis and relation extraction, into a question answering (QA) paradigm and propose to train all tasks jointly. Different from works above,<ref type="bibr" target="#b6">Li et al. [2019a]</ref> present a unified MRC framework and apply it to named entity recognition problem. The latest work<ref type="bibr" target="#b7">[Li et al., 2019b]</ref> introduces a multi-turn QA formalization for entity and relation extraction. Our work is significantly inspired by<ref type="bibr" target="#b7">[Li et al., 2019b]</ref>, but enjoys new features as follows. First, instead of using one question template for extraction, we consider diverse questions to obtain answers from multiple perspectives. Second, during the question generation step, Li et al.'s work traverses all relation types, while we manage to select a subset of relations by filtering out the irrelevances. Finally, we propose an answer ensemble strategy to select the most proper answer. Together these new features improve the extraction performance remarkably.</figDesc><table /><note>firstly reduce the relation extraction to the problem of reading comprehension and effectively generalize to zeroshot scenarios. McCann et al. [2018] transform ten tasks, such as summarization</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>S. } Relation Prediction {ORG-AFF, PHYS} Mean Pooling For ORG-AFF Concatenation</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">{ soldiers } { U.Head Entity Tail Entity</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>S</cell><cell>O</cell><cell>‚Ä¢‚Ä¢‚Ä¢</cell><cell>O</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Answer Ensemble</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Entity Extraction</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">B E R T</cell><cell></cell><cell></cell><cell></cell></row><row><cell>CLS</cell><cell cols="2">ùë• " # $</cell><cell>ùë• % # $</cell><cell>‚Ä¢‚Ä¢‚Ä¢</cell><cell>ùë• &amp; ' # $</cell><cell>SEP</cell><cell>ùë• " (</cell><cell>ùë• % (</cell><cell>‚Ä¢‚Ä¢‚Ä¢</cell><cell>ùë• &amp; ) (</cell></row><row><cell cols="2">Questions q1 q2 Diverse q3</cell><cell cols="5">Who is mentioned in the context? Find people mentioned in the context? Which words are person entities?</cell><cell cols="4">Context So far U.S. soldiers have discovered nearly $600 million hidden around</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>parameters, d b is the size of boundary label set B, and √¢ denotes the predicted boundary label. Consequently, candidate entities e = {e 1 , e 2 , . . . , e M } can be extracted from the label sequence by identifying the boundaries.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Performance comparisons on ACE05 and CoNLL04. Here, we report the average result and the standard deviation (scores in brackets) when re-training with 5 random seeds. MRC4ERE uses only one question for entity and relation extraction and enumerates universal relation set to generate questions. MRC4ERE++ is the full model presented in Section 3 embedded with the diverse question answering and relation prediction mechanisms. * denotes baselines based on the MRC framework. ‚Ä¢ CoNLL04 defines 4 entity types including LOC, ORG, PER and Other and 5 relation categories as Located-In, OrgBased-In, Live-In, Kill and Work-For. We use the data split by Gupta et al. [2016]. To tune hyperparameters, 20% of the training set is selected as the development set.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Table 1 illustrates the performance of the proposed method against previous state-of-the-arts on ACE05 and CoNLL04 dataset. The first block of subtable lists the published results of previous models. As shown in Table 1, MRC4ERE++ significantly outperforms all the baselines for both entity and relation extraction on the two datasets. Specifically, the relation F1 scores of MRC4ERE++ advances the best model [Li et al., 2019b] by +1.9% and +3.0% on ACE05 and CoNLL04, respectively.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>. Specifically, using di-</cell></row></table><note>tions increases the relation F1 from 59.8% to 60.4% on the ACE05 (MRC4ERE + RP v.s. MRC4ERE). The performance of this setting is comparable with the full model on the CoNLL04. We attribute the results to that, the entity-</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 2 :</head><label>2</label><figDesc>Ablation Study on ACE05 and CoNLL04. MRC4ERE is the simplified model with neither diverse question answering (DQA) and relation prediction (RP) included. MRC4ERE + DQA adopts DQA but without RP. MRC4ERE + RP uses RP but without DQA. MRC4ERE + RP + OBQ replace the weighted voting answer ensemble strategy by selecting answers corresponding to the one best question with highest weight. MRC4ERE++ is the full model.</figDesc><table><row><cell>relation mapping is much simpler for CoNLL04 than ACE05,</cell></row><row><cell>e.g.,almost one-to-one mapping, and thus there would be</cell></row><row><cell>much less noise. Hence, the relation prediction mechanism</cell></row><row><cell>plays an essential role for complicated datasets. Furthermore,</cell></row><row><cell>with both DQA and RP integrated, MRC4ERE++ achieves</cell></row><row><cell>further +2.3% and +3.4% boosts for the relation F1 on the</cell></row><row><cell>two datasets. Finally, simply selecting the best answer is</cell></row><row><cell>not as effective as the proposed weighted voting strategy</cell></row><row><cell>(MRC4ERE + RP + OBQ v.s. MRC4ERE++). By vot-</cell></row><row><cell>ing dynamically, the model can integrate more confidential</cell></row><row><cell>answers, which is also crucial to entity-relation extraction.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3 :</head><label>3</label><figDesc>Li et al., 2019b] P 83.6 / 84.7 / 84.2 60.4 / 55.9 / 58.1 MRC4ERE P 83.3 / 85.0 / 84.2 57.8 / 59.8 / 58.8 MRC4ERE++ P 84.5 / 85.6 / 85.0 58.8 / 61.1 / 59.9 [Li et al., 2019b] N 84.7 / 84.9 / 84.8 64.8 / 56.2 / 60.2 MRC4ERE N 85.4 / 84.2 / 84.7 57.8 / 61.9 / 60.0 MRC4ERE++ N85.9 / 85.2 / 85.5 62.0 / 62.2 / 62.1 Comparison between models using natural language questions (N ) and models using pseudo-questions (P ) on ACE05.</figDesc><table><row><cell>Entity</cell><cell></cell><cell cols="2">Relation</cell></row><row><cell>P / R / F1</cell><cell></cell><cell cols="2">P / R / F1</cell></row><row><cell>[Model</cell><cell>P</cell><cell>Relation R</cell><cell>F1</cell></row><row><cell>[Miwa and Bansal, 2016]</cell><cell cols="3">70.1 61.2 65.3</cell></row><row><cell cols="4">[Christopoulou et al., 2018] 69.7 59.5 64.2</cell></row><row><cell>[Sun et al., 2019]</cell><cell cols="3">68.7 65.4 67.0</cell></row><row><cell>MRC4ERE++</cell><cell cols="3">67.7 70.1 68.7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 :</head><label>4</label><figDesc>Relation Extraction results on ACE05 with golden entity.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence </note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported in part by the National Natural Science Foundation of China (Grant Nos.U1636211, 61672081, 61370126),the Beijing Advanced Innovation Center for Imaging Technology (Grant No.BAICIT-2016001), and the Fund of the State Key Laboratory of Software Development Environment (Grant No.SKLSDE-2019ZX-17). We also thank Yu Wu for his valuable advice and anonymous reviewers for their helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Heike Adel and Hinrich Sch√ºtze. Global normalization of convolutional neural networks for joint entity and relation classification</title>
		<author>
			<persName><forename type="first">Sch√ºtze</forename><surname>Adel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="1723" to="1729" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Joint entity recognition and relation extraction as a multi-head selection problem</title>
		<author>
			<persName><surname>Bekoulis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10723</idno>
	</analytic>
	<monogr>
		<title level="m">Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner. Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs</title>
				<editor>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</editor>
		<imprint>
			<publisher>Chan and Roth</publisher>
			<date type="published" when="2011">2018. 2018. 2011. 2011. 2018. 2018. 2017. 2019. 2019. 2019</date>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="2368" to="2378" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>NAACL</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Table filling multi-task recurrent neural network for joint entity and relation extraction</title>
		<author>
			<persName><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hinrich Sch√ºtze, and Bernt Andrassy</title>
				<imprint>
			<publisher>Pankaj Gupta</publisher>
			<date type="published" when="2016">2019. 2019. 2016. 2016</date>
			<biblScope unit="page" from="2537" to="2547" />
		</imprint>
	</monogr>
	<note>COL-ING</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2017">2019. 2019. 2017. 2017</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1601" to="1611" />
		</imprint>
	</monogr>
	<note>ACL</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Going out on a limb: Joint extraction of entity mentions and relations without dependency trees</title>
		<author>
			<persName><forename type="first">Cardie</forename><surname>Katiyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arzoo</forename><surname>Katiyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="917" to="928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Zero-shot relation extraction via reading comprehension</title>
		<author>
			<persName><surname>Levy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.04115</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Incremental joint extraction of entity mentions and relations</title>
		<author>
			<persName><forename type="first">Ji</forename><forename type="middle">;</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.11476</idno>
	</analytic>
	<monogr>
		<title level="m">A unified mrc framework for named entity recognition</title>
				<imprint>
			<date type="published" when="2014">2014. 2014. 2019a. 2019</date>
			<biblScope unit="page" from="402" to="412" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>ACL</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Entity-relation extraction as multi-turn question answering</title>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.05529</idno>
		<imprint>
			<date type="published" when="2019">2019b. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural relation extraction with selective attention over instances</title>
		<author>
			<persName><forename type="first">Lin</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
				<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="2124" to="2133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Makoto Miwa, Rune Saetre, Yusuke Miyao, and Jun&apos;ichi Tsujii. A rich feature vector for protein-protein interaction extraction from multiple corpora</title>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.08730</idno>
		<idno>arXiv:1606.05250</idno>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<editor>
			<persName><forename type="first">Sasaki</forename><surname>Miwa</surname></persName>
		</editor>
		<imprint>
			<publisher>Konstantin Lopyrev, and Percy Liang</publisher>
			<date type="published" when="2009">2018. 2018. 2018. 2018. 2016. 2014. 2014. 2009. 2016</date>
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>EMNLP. Rajpurkar et al., 2016. Squad: 100,000+ questions for machine comprehension of text</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName><surname>Seo</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Qanet: Combining local convolution with global self-attention for reading comprehension</title>
		<author>
			<persName><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2018">2019. 2019. 2018. 2018</date>
			<biblScope unit="page" from="1361" to="1370" />
		</imprint>
	</monogr>
	<note>ACL</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Extracting relational facts by an end-to-end neural model with copy mechanism</title>
		<author>
			<persName><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">End-to-end neural relation extraction with global optimization</title>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="1730" to="1740" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
