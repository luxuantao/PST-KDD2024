<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">State Key Laboratory of Management and Control for Complex Systems</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">Key Laboratory of Management and Control for Complex Systems</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">85E1059705270E916567A7189BE17DDC</idno>
					<idno type="DOI">10.1109/TCYB.2014.2357896</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>He is currently with the University of Chinese Academy of Sciences. His current research interests include machine learning, reinforcement learning, neural networks, intelligent control, and smart grid.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abstract-In this paper, the infinite horizon optimal robust guaranteed cost control of continuous-time uncertain nonlinear systems is investigated using neural-network-based online solution of Hamilton-Jacobi-Bellman (HJB) equation. By establishing an appropriate bounded function and defining a modified cost function, the optimal robust guaranteed cost control problem is transformed into an optimal control problem. It can be observed that the optimal cost function of the nominal system is nothing but the optimal guaranteed cost of the original uncertain system. A critic neural network is constructed to facilitate the solution of the modified HJB equation corresponding to the nominal system. More importantly, an additional stabilizing term is introduced for helping to verify the stability, which reinforces the updating process of the weight vector and reduces the requirement of an initial stabilizing control. The uniform ultimate boundedness of the closed-loop system is analyzed by using the Lyapunov approach as well. Two simulation examples are provided to verify the effectiveness of the present control approach.</p><p>Index Terms-Adaptive critic designs, adaptive/approximate dynamic programming (ADP), Hamilton-Jacobi-Bellman (HJB) equation, neural networks, optimal robust guaranteed cost control, uncertain nonlinear systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>T HE adaptive or approximate dynamic program- ming (ADP) algorithm was first proposed by Werbos <ref type="bibr" target="#b0">[1]</ref> as an effective method to solve optimization and optimal control problems. In general, it is implemented by solving the Hamilton-Jacobi-Bellman (HJB) equation based on function approximators, such as neural networks. It is one of the key directions for future researches in intelligent control and understanding brain intelligence <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>. As a result, the ADP and related research have gained much attention from scholars across many disciplines (see <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b13">[14]</ref> and the numerous references therein). Significantly, the ADP method has been often used in feedback control applications, both for discrete-time systems <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b35">[36]</ref> and for continuous-time systems <ref type="bibr" target="#b36">[37]</ref>- <ref type="bibr" target="#b53">[54]</ref>. Besides, various traditional control problems, like robust control <ref type="bibr" target="#b54">[55]</ref>, <ref type="bibr" target="#b55">[56]</ref>, decentralized control <ref type="bibr" target="#b56">[57]</ref>, networked control <ref type="bibr" target="#b57">[58]</ref>, power system control <ref type="bibr" target="#b58">[59]</ref>, are studied under the new framework, which greatly extends the application scope of ADP methods. Unavoidable discrepancies between system models and real-world dynamics may result in degradation of system performance including instability <ref type="bibr" target="#b59">[60]</ref>- <ref type="bibr" target="#b61">[62]</ref>. In this sense, the feedback control should be designed to be robust with respect to system uncertainties. The importance of robust control has been recognized by control scientists for several decades and various approaches have been proposed. In <ref type="bibr" target="#b62">[63]</ref>, it was shown that the robust control problem can be solved by studying the corresponding optimal control problem, hence the optimal control method can be employed to design robust controllers. However, the results are restricted to a class of systems with special form of uncertainties. Though Adhyaru et al. <ref type="bibr" target="#b54">[55]</ref>, <ref type="bibr" target="#b55">[56]</ref> proposed an HJB equation-based optimal control algorithm to deal with the nonlinear robust control problem, the algorithm was constructed using the least square method and performed offline, not to mention the stability analysis of the closed-loop optimal control system was not conducted. On the other hand, when controlling a real plant, it is desirable to design a controller, which not only makes the closed-loop system asymptotically stable but also guarantees an adequate level of performance. The so-called guaranteed cost control approach <ref type="bibr" target="#b63">[64]</ref> has the advantage of providing an upper bound on a given cost and thus the system performance degradation incurred by the model parameter uncertainties is guaranteed to be less than this bound <ref type="bibr" target="#b64">[65]</ref>, <ref type="bibr" target="#b65">[66]</ref>. The optimal robust guaranteed cost control problem arises when discussing optimality of the guaranteed cost function. To the best of our knowledge, however, there are no results on optimal robust guaranteed cost control of uncertain 2168-2267 c 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.</p><p>See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p><p>nonlinear systems using online ADP strategy. These motivate our research. From a structural perspective, in many ADP-related literature, the main control strategy is implemented based on the actor-critic architecture, where two neural networks referred to as critic network and action network are taken to approximate the optimal cost function and the optimal control, respectively. In addition, from an algorithmic point of view, the value iteration and policy iteration are two important algorithms when designing the ADP-based optimal feedback control. It should be pointed out that the initial admissible control is necessary when employing the policy iteration algorithm. However, in many situations, finding the initial admissible control is not an easy task. Therefore, how to simplify the structure of ADP and relax the need for an initial stabilizing control are of great significance.</p><p>In this paper, we investigate the optimal robust guaranteed cost control of continuous-time uncertain nonlinear systems using neural-network-based online solution of HJB equation. The optimal robust guaranteed cost control problem is transformed into an optimal control problem by introducing an appropriate cost function. It can be proved that the optimal cost function of the nominal system is the optimal guaranteed cost of the controlled uncertain system. Then, a critic network is constructed for facilitating the solution of modified HJB equation. Moreover, inspired by the work of <ref type="bibr" target="#b44">[45]</ref> and <ref type="bibr" target="#b45">[46]</ref>, an additional stabilizing term is introduced to verify the stability, which relaxes the need for an initial stabilizing control. The uniform ultimate boundedness (UUB) of the closed-loop system is also proved by using the well-known Lyapunov approach. The approximate control input can converge to the optimal control within a small bound.</p><p>In summary, the main contributions of this paper are as follows.</p><p>1) It is the first time that the infinite horizon optimal robust guaranteed cost control of uncertain nonlinear systems is investigated using the neural-network-based online HJB solution. The bounded function is introduced and the proper cost function is defined, then the optimal cost function of the nominal system is related to the optimal guaranteed cost of the original system. 2) Since the system uncertainties are not always considered in ADP-related literature, the control strategy established in this paper is significant to design robust controllers for uncertain nonlinear systems. In this sense, the conducted research extends the application scope of ADP method. The rest of this paper is organized as follows. In Section II, the optimal robust guaranteed cost control problem of uncertain nonlinear systems is stated. In Section III, the studied problem is transformed into an optimal control problem with a modified cost function. In Section IV, a neural network is constructed to solve the modified HJB equation approximately. Then, the stability of the overall closed-loop system is proved. In Section V, two numerical examples are given to demonstrate the effectiveness of the established approach. In Section VI, concluding remarks and the discussion of future work are presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROBLEM STATEMENT</head><p>In this paper, we study a class of continuous-time uncertain nonlinear systems given by</p><formula xml:id="formula_0">ẋ(t) = F(x(t), u(t)) = f (x(t)) + g(x(t))u(t) + f (x(t)) (1)</formula><p>where x(t) ∈ R n is the state vector and u(t) ∈ R m is the control input. The known functions f (•) and g(•) are differentiable in their arguments with f (0) = 0, and f (x(t)) is the nonlinear perturbation of the corresponding nominal system</p><formula xml:id="formula_1">ẋ(t) = F(x(t), u(t)) = f (x(t)) + g(x(t))u(t). (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>Here, we let x(0) = x 0 be the initial state. In addition, as in many other literature, we assume that f + gu is Lipschitz continuous on a set in R n containing the origin and that the system (2) is controllable.</p><p>Before proceeding, we assign an explicit structure to the system uncertainty. The following assumption is given, which has been used in <ref type="bibr" target="#b60">[61]</ref> and <ref type="bibr" target="#b61">[62]</ref>.</p><p>Assumption 1: Assume that the uncertainty f (x) has the form</p><formula xml:id="formula_3">f (x) = G(x)d(ϕ(x))<label>(3)</label></formula><p>where</p><formula xml:id="formula_4">d T (ϕ(x))d(ϕ(x)) ≤ h T (ϕ(x))h(ϕ(x)).<label>(4)</label></formula><p>In ( <ref type="formula" target="#formula_3">3</ref>) and (4), G(•) ∈ R n×r and ϕ(•) satisfying ϕ(0) = 0 are known functions denoting the structure of the uncertainty, d(•) ∈ R r is an uncertain function with d(0) = 0, and h(•) ∈ R r is a given function with h(0) = 0.</p><p>Consider system (1) with infinite horizon cost function</p><formula xml:id="formula_5">J(x 0 , u) = ∞ 0 U(x(τ ), u(τ ))dτ<label>(5)</label></formula><p>where</p><formula xml:id="formula_6">U(x, u) = Q(x) + u T Ru, Q(x) ≥ 0, and R = R T &gt; 0 is a constant matrix.</formula><p>In this paper, the aim of solving the robust guaranteed cost control problem is to find a feedback control function u(x) and determine a finite upper bound function (u), i.e., (u) &lt; +∞, such that the closed-loop system is robustly stable and the cost function (5) satisfies J ≤ . Here, the upper bound function (u) is termed as a robust guaranteed cost function. Only when (u) is minimized, it is named as the optimal robust guaranteed cost and is denoted as * , i.e., * = min u (u). Additionally, the corresponding control function ū * is called the optimal robust guaranteed cost control, i.e., ū * = arg min u (u).</p><p>In this paper, we will prove that the optimal robust guaranteed cost control problem of system (1) can be transformed into the optimal control problem of nominal system <ref type="bibr" target="#b1">(2)</ref>. The ADP technique can be employed to deal with the optimal control problem of system <ref type="bibr" target="#b1">(2)</ref>. Note that in this paper, the feedback control u(x) is often written as u for simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. OPTIMAL ROBUST GUARANTEED COST CONTROL</head><p>OF UNCERTAIN NONLINEAR SYSTEMS VIA HJB SOLUTION In this section, we show that the guaranteed cost of the uncertain nonlinear system is closely related to the modified cost function of the nominal system. The next theorem is derived by rechecking <ref type="bibr" target="#b59">[60]</ref> with relaxed conditions.</p><p>Theorem 1: Assume that there exist a continuously differentiable and radially unbounded cost function V(x) satisfying V(x) &gt; 0 for all x = 0 and V(0) = 0, a bounded function (x) satisfying (x) ≥ 0, and a feedback control function u(x) such that</p><formula xml:id="formula_7">(∇V(x)) T F(x, u) ≤ (∇V(x)) T F(x, u) + (x) (6) (∇V(x)) T F(x, u) + (x) &lt; 0, x = 0 ( 7 ) U(x, u) + (∇V(x)) T F(x, u) + (x) = 0 (<label>8</label></formula><formula xml:id="formula_8">)</formula><p>where the symbol ∇V(x) denotes the partial derivative of the cost function V(x) with respect to x, i.e., ∇V(x) = ∂V(x)/∂x. Then, with the feedback control function u(x), there exists a neighborhood of the origin such that system (1) is locally asymptotically stable. Furthermore</p><formula xml:id="formula_9">J(x 0 , u) ≤ V(x 0 ) = J(x 0 , u)<label>(9)</label></formula><p>where J(x 0 , u) is defined as <ref type="bibr" target="#b9">(10)</ref> and is termed as the modified cost function of system <ref type="bibr" target="#b1">(2)</ref>.</p><formula xml:id="formula_10">J(x 0 , u) = ∞ 0 U(x(τ ), u(x(τ ))) + (x(τ )) dτ</formula><p>Proof: First, we show the asymptotic stability of system (1) under the feedback control u(x). Let</p><formula xml:id="formula_11">V(x) dV(x) dt = (∇V(x)) T F(x, u). (<label>11</label></formula><formula xml:id="formula_12">)</formula><p>Considering ( <ref type="formula">6</ref>) and ( <ref type="formula">7</ref>), we obtain V(x(t)) &lt; 0 for any x = 0. This implies that V(•) is a Lyapunov function for system <ref type="bibr" target="#b0">(1)</ref>, which proves the local asymptotic stability.</p><p>Then, we show J(x 0 , u) is upper bounded by a modified cost function corresponding to the nominal system (2).</p><p>For system (1), considering the fact that <ref type="formula">6</ref>) and ( <ref type="formula" target="#formula_7">8</ref>), we have</p><formula xml:id="formula_13">V(x) = (∇V(x)) T F(x, u), we have U(x, u) = -V(x) + (∇V(x)) T F(x, u) + U(x, u). According to (</formula><formula xml:id="formula_14">U(x, u) = -V(x) + U(x, u) + (∇V(x)) T F(x, u) ≤ -V(x) + U(x, u) + (∇V(x)) T F(x, u) + (x) = -V(x).<label>(12)</label></formula><p>Integrating over [0, t) yields</p><formula xml:id="formula_15">t 0 U(x, u)dτ ≤ -V(x(t)) + V(x 0 ). (<label>13</label></formula><formula xml:id="formula_16">)</formula><p>Letting t → ∞ and noting that V(x(t)) → 0, we can obtain</p><formula xml:id="formula_17">J(x 0 , u) ≤ V(x 0 ). (<label>14</label></formula><formula xml:id="formula_18">)</formula><p>When f (x) = 0, we can still find that ( <ref type="formula">6</ref>)-( <ref type="formula" target="#formula_7">8</ref>) are true since (x) ≥ 0. In this case, we derive that</p><formula xml:id="formula_19">V(x) = (∇V(x)) T F(x, u). Then, U(x, u) + (x) = -V(x) + (∇V(x)) T F(x, u) + U(x, u) + (x).</formula><p>Based on (8), we obtain</p><formula xml:id="formula_20">U(x, u) + (x) = -V(x) + U(x, u) + (∇V(x)) T F(x, u) + (x) = -V(x).<label>(15)</label></formula><p>Similarly, by integrating over [0, t), we have</p><formula xml:id="formula_21">t 0 U(x, u) + (x) dτ = -V(x(t)) + V(x 0 ). (<label>16</label></formula><formula xml:id="formula_22">)</formula><p>Here, letting t → ∞ yields</p><formula xml:id="formula_23">J(x 0 , u) = V(x 0 ). (<label>17</label></formula><formula xml:id="formula_24">)</formula><p>Based on ( <ref type="formula" target="#formula_17">14</ref>) and ( <ref type="formula" target="#formula_23">17</ref>), we can easily find that ( <ref type="formula" target="#formula_9">9</ref>) is true. This completes the proof.</p><p>Theorem 1 shows that the bounded function (x) takes an important role in deriving the guaranteed cost of the controlled system. The following lemma presents a specific form of (x).</p><p>Lemma 1: For any continuously differentiable and radially unbounded function V(x), define</p><formula xml:id="formula_25">(x) = h T (ϕ(x))h(ϕ(x)) + 1 4 (∇V(x)) T G(x)G T (x)∇V(x).<label>(18)</label></formula><p>Then, we have</p><formula xml:id="formula_26">(∇V(x)) T f (x) ≤ (x). (<label>19</label></formula><formula xml:id="formula_27">)</formula><p>Proof: Considering (3), (4), and ( <ref type="formula" target="#formula_25">18</ref>), since</p><formula xml:id="formula_28">0 ≤ d(ϕ(x)) - 1 2 G T (x)∇V(x) T d(ϕ(x)) - 1 2 G T (x)∇V(x) = d T (ϕ(x))d(ϕ(x)) + 1 4 (∇V(x)) T G(x)G T (x)∇V(x) -(∇V(x)) T G(x)d(ϕ(x)) ≤ h T (ϕ(x))h(ϕ(x)) + 1 4 (∇V(x)) T G(x)G T (x)∇V(x) -(∇V(x)) T f (x) = (x) -(∇V(x)) T f (x) (<label>20</label></formula><formula xml:id="formula_29">)</formula><p>we can see that <ref type="bibr" target="#b18">(19)</ref> holds. Remark 1: For any continuously differentiable and radially unbounded function V(x), since</p><formula xml:id="formula_30">(∇V(x)) T F(x, u) = (∇V(x)) T F(x, u) + (∇V(x)) T f (x) (21)</formula><p>we can easily find that the bounded function ( <ref type="formula" target="#formula_25">18</ref>) satisfies <ref type="bibr" target="#b5">(6)</ref>. Note that the Lemma 1 seems only imply <ref type="bibr" target="#b5">(6)</ref>, but in fact, it presents a specific form of (x) satisfying ( <ref type="formula">6</ref>)-( <ref type="formula" target="#formula_7">8</ref>). The reason is that ( <ref type="formula">7</ref>) and ( <ref type="formula" target="#formula_7">8</ref>) are implicit assumptions of Theorem 1, noticing the framework of the generalized HJB equation <ref type="bibr" target="#b66">[67]</ref> and the fact that (∇V(x)) T F(x, u) + (x) = -U(x, u) &lt; 0 when x = 0. Hence, it can be used for problem transformation. In fact, based on ( <ref type="formula">6</ref>) and ( <ref type="formula">21</ref>), we can find that the positive semi-definite bounded function (x) gives an upper bound of the term (∇V(x)) T f (x), which facilitates us to solve the optimal robust guaranteed cost control problem of a class of nonlinear systems with uncertainties.</p><p>Remark 2: It is important to note that Theorem 1 indicates the existence of the guaranteed cost of the uncertain nonlinear system (1). In addition, in order to derive the optimal guaranteed cost controller, we should minimize the upper bound J(x 0 , u) with respect to u. Therefore, we should solve the optimal control problem of system (2) with V(x 0 ) considered as the cost function.</p><p>For optimal control problem, the designed feedback control must not only stabilize the controlled system on but also guarantee that the cost function is finite. In other words, the control function must be admissible.</p><p>Definition 1: A control function u(x) is said to be admissible with respect to <ref type="bibr" target="#b9">(10)</ref> on , denoted by u ∈ ( ) ( ( ) is the set of admissible controls on ), if u(x) is continuous on , u(0) = 0, u(x) stabilizes system (2) on , and J(x 0 , u) is finite for all x 0 ∈ .</p><p>For system (2), observing that</p><formula xml:id="formula_31">V(x 0 ) = ∞ 0 U(x, u) + (x) dτ = T 0 U(x, u) + (x) dτ + V(x(T)) (<label>22</label></formula><formula xml:id="formula_32">)</formula><p>we have lim</p><formula xml:id="formula_33">T→0 1 T V(x(T)) -V(x 0 ) + T 0 {U(x, u) + (x)} dτ = 0.<label>(23)</label></formula><p>Clearly, ( <ref type="formula" target="#formula_33">23</ref>) is equivalent to <ref type="bibr" target="#b7">(8)</ref>. Hence, ( <ref type="formula" target="#formula_7">8</ref>) is an infinitesimal version of the modified cost function <ref type="bibr" target="#b21">(22)</ref> and is the so-called nonlinear Lyapunov equation.</p><p>For system (2) with modified cost function <ref type="bibr" target="#b21">(22)</ref>, define the Hamiltonian function of the optimal control problem as</p><formula xml:id="formula_34">H(x, u, ∇V(x)) = U(x, u) + (∇V(x)) T F(x, u) + (x). (<label>24</label></formula><formula xml:id="formula_35">)</formula><p>Define the optimal cost function of system (2) as J * (x 0 ) = min u∈ ( ) J(x 0 , u), where J(x 0 , u) is given in <ref type="bibr" target="#b9">(10)</ref>. Note that J * (x) satisfies the modified HJB equation</p><formula xml:id="formula_36">0 = min u∈ ( ) H(x, u, ∇J * (x)) (<label>25</label></formula><formula xml:id="formula_37">)</formula><p>where ∇J * (x) = ∂J * (x)/∂x. Assume that the minimum on the right hand side of (25) exists and is unique. Then, the optimal control of system (2) is</p><formula xml:id="formula_38">u * (x) = arg min u∈ ( ) H(x, u, ∇J * (x)) = - 1 2 R -1 g T (x)∇J * (x). (<label>26</label></formula><formula xml:id="formula_39">)</formula><p>Hence, the modified HJB equation becomes</p><formula xml:id="formula_40">0 = U(x, u * ) + (∇J * (x)) T F(x, u * ) + h T (ϕ(x))h(ϕ(x)) + 1 4 (∇J * (x)) T G(x)G T (x)∇J * (x) (<label>27</label></formula><formula xml:id="formula_41">)</formula><p>with J * (0) = 0.</p><p>Substituting <ref type="bibr" target="#b25">(26)</ref> into <ref type="bibr" target="#b26">(27)</ref>, we can obtain the formulation of the modified HJB equation in terms of ∇J * (x) as follows:</p><formula xml:id="formula_42">0 = Q(x) + (∇J * (x)) T f (x) + h T (ϕ(x))h(ϕ(x)) - 1 4 (∇J * (x)) T g(x)R -1 g T (x)∇J * (x) + 1 4 (∇J * (x)) T G(x)G T (x)∇J * (x) (28)</formula><p>with J * (0) = 0. Now, we give the following assumption, which is helpful to derive the optimal control with regard to system (2) and prove the stability of the closed-loop system.</p><p>Assumption 2: Consider system (2) with cost function ( <ref type="formula" target="#formula_31">22</ref>) and the optimal feedback control function <ref type="bibr" target="#b25">(26)</ref>. Let J s (x) be a continuously differentiable Lyapunov function candidate formed as a polynomial and satisfying</p><formula xml:id="formula_43">Js (x) = (∇J s (x)) T ẋ = (∇J s (x)) T ( f (x) + g(x)u * ) &lt; 0 (29)</formula><p>where ∇J s (x) = ∂J s (x)/∂x. Assume there exists a positive definite matrix (x) such that the following relation holds:</p><formula xml:id="formula_44">(∇J s (x)) T ( f (x) + g(x)u * ) = -(∇J s (x)) T (x)∇J s (x). (30)</formula><p>Remark 3: This is a common assumption that has been used in the literature, for instance <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b44">[45]</ref>, and <ref type="bibr" target="#b45">[46]</ref>, to facilitate discussing the stability issue of closed-loop system. According to <ref type="bibr" target="#b44">[45]</ref>, we assume that the closed-loop dynamics with optimal control can be bounded by a function of system state on the compact set of this paper. Without loss of generality, we assume that f (x) + g(x)u * ≤ η ∇J s (x) with η &gt; 0. Hence, we can further obtain (∇J s (x)) T  2 . Let λ m and λ M be the minimum and maximum eigenvalues of matrix (x), then we have</p><formula xml:id="formula_45">( f (x) + g(x)u * ) ≤ η ∇J s (x)</formula><formula xml:id="formula_46">λ m ∇J s (x) 2 ≤ (∇J s (x)) T (x)∇J s (x) ≤ λ M ∇J s (x) 2 . (31)</formula><p>Therefore, by noticing ( <ref type="formula">29</ref>) and <ref type="bibr" target="#b30">(31)</ref>, we can conclude that the Assumption 2 is reasonable. Specifically, in this paper, J s (x) can be obtained by properly selecting a polynomial when implementing the ADP method.</p><p>The following theorem illustrates how to develop the optimal robust guaranteed cost control scheme for system <ref type="bibr" target="#b0">(1)</ref>.</p><p>Theorem 2: Consider system (1) with cost function <ref type="bibr" target="#b4">(5)</ref>. Suppose the modified HJB equation ( <ref type="formula">28</ref>) has a continuously differentiable solution J * (x). Then, for any admissible control function u, the cost function (5) satisfies</p><formula xml:id="formula_47">J(x 0 , u) ≤ (u) (<label>32</label></formula><formula xml:id="formula_48">)</formula><p>where</p><formula xml:id="formula_49">(u) J * (x 0 ) + ∞ 0 (u -u * ) T R(u -u * )dτ. (<label>33</label></formula><formula xml:id="formula_50">)</formula><p>Moreover, the optimal robust guaranteed cost of the controlled uncertain nonlinear system is given by * = (u * ) = J * (x 0 ). Accordingly, the optimal robust guaranteed cost control is given by ū * = u * .</p><p>Proof: For any admissible control function u(x), the cost function ( <ref type="formula" target="#formula_5">5</ref>) can be written as the following form:</p><formula xml:id="formula_51">J(x 0 , u) = J * (x 0 ) + ∞ 0 U(x, u) + J * (x) dτ. (<label>34</label></formula><formula xml:id="formula_52">)</formula><p>Along the closed-loop trajectories of system (1) and according to <ref type="bibr" target="#b27">(28)</ref>, we find that</p><formula xml:id="formula_53">U(x, u) + J * (x) = Q(x) + u T Ru + ∇J * (x) T ( f (x) + g(x)u + f (x)) = u T Ru + ∇J * (x) T (g(x)u + f (x)) -h T (ϕ(x))h(ϕ(x)) - 1 4 ∇J * (x) T G(x)G T (x)∇J * (x) + 1 4 ∇J * (x) T g(x)R -1 g T (x)∇J * (x). (<label>35</label></formula><formula xml:id="formula_54">)</formula><p>For the optimal cost function J * (x), in light of Lemma 1, we have the following inequality holds:</p><formula xml:id="formula_55">∇J * (x) T f (x) ≤ h T (ϕ(x))h(ϕ(x)) + 1 4 ∇J * (x) T G(x)G T (x)∇J * (x). (<label>36</label></formula><formula xml:id="formula_56">)</formula><p>Substituting ( <ref type="formula" target="#formula_55">36</ref>) into <ref type="bibr" target="#b34">(35)</ref>, we can further obtain</p><formula xml:id="formula_57">U(x, u) + J * (x) ≤ u T Ru + ∇J * (x) T g(x)u + 1 4 ∇J * (x) T g(x)R -1 g T (x)∇J * (x). (<label>37</label></formula><formula xml:id="formula_58">)</formula><p>Considering the expression of the optimal control in (26), the <ref type="bibr" target="#b36">(37)</ref> is in fact</p><formula xml:id="formula_59">U(x, u) + J * (x) ≤ (u -u * ) T R(u -u * ).<label>(38)</label></formula><p>Thus, combining <ref type="bibr" target="#b33">(34)</ref> with <ref type="bibr" target="#b37">(38)</ref>, we can find that</p><formula xml:id="formula_60">J(x 0 , u) ≤ J * (x 0 ) + ∞ 0 (u -u * ) T R(u -u * )dτ<label>(39)</label></formula><p>holds. Clearly, the optimal robust guaranteed cost can be obtained when setting u = u * , i.e., (u * ) = J * (x 0 ). Furthermore, we can derive that * = min u (u) = J * (x 0 ) and ū * = arg min u (u) = u * . This completes the proof. Remark 4: According to Theorem 2, the optimal robust guaranteed cost control of uncertain nonlinear system is transformed into the optimal control of nominal system, where the modified cost function is considered as the upper bound function. In other words, once the solution of the modified HJB equation ( <ref type="formula">28</ref>) corresponding to nominal system (2) is derived, we can establish the optimal robust guaranteed cost control scheme of system (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. ONLINE HJB SOLUTION OF THE TRANSFORMED</head><p>OPTIMAL CONTROL PROBLEM For nonlinear system (2), the solution of optimal control problem can be obtained by solving the modified HJB equation (28) <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b37">[38]</ref>. However, it is always difficult or even impossible to obtain the analytical solution. Thus, in many literature, the value iteration and policy iteration-based approaches are employed to get its approximate solution. The traditional ADP-based design methodology often utilizes critic network and action network without considering uncertainties of the controlled system. Besides, the design procedure is often performed with the requirement of an initial stabilizing control.</p><p>In this section, inspired by the excellent work of <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>, and <ref type="bibr" target="#b44">[45]</ref>, an improved online technique without utilizing the iterative strategy and an initial stabilizing control is developed by constructing a single network, namely, the critic network. Here, the ADP method is introduced to the framework of infinite horizon optimal robust guaranteed cost control of nonlinear systems with uncertainties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Neural Network Implementation</head><p>Assume that the cost function V(x) is continuously differentiable. According to the universal approximation property of neural networks, V(x) can be reconstructed by a single-layer neural network on a compact set as</p><formula xml:id="formula_61">V(x) = ω T c σ c (x) + ε c (x) (<label>40</label></formula><formula xml:id="formula_62">)</formula><p>where ω c ∈ R l is the ideal weight, σ c (x) ∈ R l is the activation function, l is the number of neurons in the hidden layer, and ε c (x) is the unknown approximation error of the neural network. Then</p><formula xml:id="formula_63">∇V(x) = ∇σ c (x) T ω c + ∇ε c (x) (<label>41</label></formula><formula xml:id="formula_64">)</formula><p>is also unknown, where ∇σ c (x) = ∂σ c (x)/∂x and ∇ε c (x) = ∂ε c (x)/∂x are the gradient of the activation function and neural network approximation error, respectively. Based on (41), the Lyapunov equation ( <ref type="formula" target="#formula_7">8</ref>) takes the following form:</p><formula xml:id="formula_65">0 = U(x, u) + ω T c ∇σ c (x) + (∇ε c (x)) T F(x, u) + h T (ϕ(x))h(ϕ(x)) + 1 4 ω T c ∇σ c (x) + (∇ε c (x)) T × G(x)G T (x) (∇σ c (x)) T ω c + ∇ε c (x) . (<label>42</label></formula><formula xml:id="formula_66">)</formula><p>Following the framework of <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>, and <ref type="bibr" target="#b44">[45]</ref>, we assume that the weight vector ω c , the gradient ∇σ c (x), and the approximation error ε c (x) and its derivative ∇ε c (x) are all bounded on a compact set .</p><p>Since the ideal weights are unknown, a critic neural network can be built in terms of the estimated weights as</p><formula xml:id="formula_67">V(x) = ωT c σ c (x)<label>(43)</label></formula><p>to approximate the cost function. Under the framework of ADP method, the selection of the activation function of the critic network is often a natural choice guided by engineering experience and intuition <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b66">[67]</ref>. Then, we have</p><formula xml:id="formula_68">∇ V(x) = (∇σ c (x)) T ωc<label>(44)</label></formula><p>where</p><formula xml:id="formula_69">∇ V(x) = ∂ V(x)/∂x.</formula><p>According to ( <ref type="formula" target="#formula_38">26</ref>) and ( <ref type="formula" target="#formula_63">41</ref>), we have</p><formula xml:id="formula_70">u(x) = - 1 2 R -1 g T (x) (∇σ c (x)) T ω c + ∇ε c (x) (45)</formula><p>which, in fact, represents the expression of optimal control u * (x) if the cost function in <ref type="bibr" target="#b39">(40)</ref> is considered as the optimal one J * (x). Besides, in light of ( <ref type="formula" target="#formula_38">26</ref>) and ( <ref type="formula" target="#formula_68">44</ref>), the approximate control function can be given as</p><formula xml:id="formula_71">û(x) = - 1 2 R -1 g T (x)(∇σ c (x)) T ωc . (<label>46</label></formula><formula xml:id="formula_72">)</formula><p>Applying <ref type="bibr" target="#b45">(46)</ref> to system (2), the closed-loop system dynamics is expressed as</p><formula xml:id="formula_73">ẋ = f (x) - 1 2 g(x)R -1 g T (x)(∇σ c (x)) T ωc . (<label>47</label></formula><formula xml:id="formula_74">)</formula><p>Recalling the definition of the Hamiltonian function ( <ref type="formula" target="#formula_34">24</ref>) and the modified HJB equation ( <ref type="formula" target="#formula_36">25</ref>), we can easily obtain that H(x, u * , ∇J * ) = 0. The neural network expressions <ref type="bibr" target="#b40">(41)</ref> and <ref type="bibr" target="#b44">(45)</ref> imply that u * and ∇J * can be formulated based on the ideal weight of the critic network, i.e., ω c . As a result, the Hamiltonian function becomes H(x, ω c ) = 0, which specifically, can be written as</p><formula xml:id="formula_75">H(x, ω c ) = Q(x) + ω T c ∇σ c (x)f (x) - 1 4 ω T c ∇σ c (x)g(x)R -1 g T (x)(∇σ c (x)) T ω c + h T (ϕ(x))h(ϕ(x)) + 1 4 ω T c ∇σ c (x)G(x)G T (x)(∇σ c (x)) T ω c + e cH = 0<label>(48)</label></formula><p>where</p><formula xml:id="formula_76">e cH = (∇ε c (x)) T f (x) - 1 2 (∇ε c (x)) T g(x)R -1 g T (x)(∇σ c (x)) T ω c - 1 4 (∇ε c (x)) T g(x)R -1 g T (x)∇ε c (x) + 1 2 (∇ε c (x)) T G(x)G T (x)(∇σ c (x)) T ω c + 1 4 (∇ε c (x)) T G(x)G T (x)∇ε c (x).<label>(49)</label></formula><p>In ( <ref type="formula" target="#formula_76">49</ref>), e cH denotes the residual error generated due to the neural network approximation.</p><p>Then, using the estimated weight vector, the approximate Hamiltonian function can be derived as</p><formula xml:id="formula_77">Ĥ(x, ωc ) = Q(x) + ωT c ∇σ c (x)f (x) - 1 4 ωT c ∇σ c (x)g(x)R -1 g T (x)(∇σ c (x)) T ωc + h T (ϕ(x))h(ϕ(x)) + 1 4 ωT c ∇σ c (x)G(x)G T (x)(∇σ c (x)) T ωc . (<label>50</label></formula><formula xml:id="formula_78">)</formula><p>Letting e c = Ĥ(x, ωc ) -H(x, ω c ) and considering <ref type="bibr" target="#b47">(48)</ref>, we have e c = Ĥ(x, ωc ). Let the weight estimation error of the critic network be</p><formula xml:id="formula_79">ωc = ω c -ωc . (<label>51</label></formula><formula xml:id="formula_80">)</formula><p>Then, based on (48), <ref type="bibr" target="#b49">(50)</ref>, and (51), we can obtain the formulation of e c in terms of ωc as follows:</p><formula xml:id="formula_81">e c = Ĥ(x, ωc ) -H(x, ω c ) = -ωT c ∇σ c (x)f (x) - 1 4 ωT c ∇σ c (x)g(x)R -1 g T (x)(∇σ c (x)) T ωc + 1 2 ωT c ∇σ c (x)g(x)R -1 g T (x)(∇σ c (x)) T ω c + 1 4 ωT c ∇σ c (x)G(x)G T (x)(∇σ c (x)) T ωc - 1 2 ωT c ∇σ c (x)G(x)G T (x)(∇σ c (x)) T ω c -e cH . (<label>52</label></formula><formula xml:id="formula_82">)</formula><p>For training the critic network, it is desired to design ωc to minimize the objective function</p><formula xml:id="formula_83">E c = 1 2 e T c e c . (<label>53</label></formula><formula xml:id="formula_84">)</formula><p>Here, the weights of the critic network are tuned based on the standard steepest descent algorithm with an additional term introduced to assure the boundedness of system state, that is</p><formula xml:id="formula_85">ωc = -α c ∂E c ∂ ωc + 1 2 α s (x, û)∇σ c (x)g(x)R -1 g T (x)∇J s (x) (54)</formula><p>where α c &gt; 0 is the learning rate of the critic network, α s &gt; 0 is the learning rate of the additional term, and J s (x) is the Lyapunov function candidate given in Assumption 2. In (54), the (x, û) is the additional stabilizing term defined as</p><formula xml:id="formula_86">(x, û) = 0, if Js (x) = (∇J s (x)) T F(x, û) &lt; 0 1, else. (<label>55</label></formula><formula xml:id="formula_87">)</formula><p>Remark 5: From the definition of the additional stabilizing term (x, û), the second term in ( <ref type="formula">54</ref>) is removed when the nonlinear system exhibits stable behavior. Hence, minimizing the approximate Hamiltonian becomes the primary objective of the weight update process. In contrast, when the controlled system exhibits signs of instability, i.e., (∇J s (x)) T F(x, û) &gt; 0, the second term of ( <ref type="formula">54</ref>) is activated and is used to reinforce the training process of the weight vector until the system exhibits stable behavior. Hence, it can be seen that the term (x, û) is defined based on the Lyapunov condition for stability. In this paper, we can obtain <ref type="bibr" target="#b55">(56)</ref> which shows that the reinforced training process is carried out along the negative gradient direction of (∇J s (x)) T F(x, û).</p><formula xml:id="formula_88">- ∂ (∇J s (x)) T F(x, û) ∂ ωc = - ∂ û ∂ ωc T ∂ (∇J s (x)) T F(x, û) ∂ û = 1 2 ∇σ c (x)g(x)R -1 g T (x)∇J s (x)</formula><p>When the case (∇J s (x)) T F(x, û) &gt; 0 occurs, the reinforced training process reduces the value of (∇J s (x)) T F(x, û) to make it negative. To summarize, the second term in ( <ref type="formula">54</ref>) is chosen for ensuring the stability of closed-loop system, and meanwhile, for facilitating the stability proof given in the sequel. Actually, it is in this sense that the requirement of an initial stabilizing control is relaxed. Therefore, the weight vector of critic network is initialized to zero during the neural network implementation process. The structural diagram of the implementation process using neural network is displayed in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>Next, we will find the dynamics of the weight estimation error ωc . According to <ref type="bibr" target="#b49">(50)</ref>, we have In light of ( <ref type="formula" target="#formula_79">51</ref>), <ref type="bibr" target="#b52">(53)</ref>, and ( <ref type="formula">54</ref>), the dynamics of the weight estimation error is</p><formula xml:id="formula_89">∂e c ∂ ωc = ∇σ c (x)f (x) - 1 2 ∇σ c (x)g(x)R -1 g T (x)(∇σ c (x)) T ωc + 1 2 ∇σ c (x)G(x)G T (x)(∇σ c (x)) T ωc . (<label>57</label></formula><formula xml:id="formula_90">)</formula><formula xml:id="formula_91">ωc = -ωc = α c e c ∂e c ∂ ωc - 1 2 α s (x, û)∇σ c (x)g(x)R -1 g T (x)∇J s (x). (<label>58</label></formula><formula xml:id="formula_92">)</formula><p>Then, combining ( <ref type="formula" target="#formula_79">51</ref>), <ref type="bibr" target="#b51">(52)</ref>, and ( <ref type="formula" target="#formula_89">57</ref>), the error dynamics <ref type="bibr" target="#b57">(58)</ref> becomes</p><formula xml:id="formula_93">ωc = α c -ωT c ∇σ (x)f (x) - 1 4 ωT c ∇σ c (x)g(x)R -1 g T (x)(∇σ c (x)) T ωc + 1 2 ωT c ∇σ c (x)g(x)R -1 g T (x)(∇σ c (x)) T ω c + 1 4 ωT c ∇σ c (x)G(x)G T (x)(∇σ c (x)) T ωc - 1 2 ωT c ∇σ c (x)G(x)G T (x)(∇σ c (x)) T ω c -e cH × ∇σ c (x)f (x) - 1 2 ∇σ c (x)g(x)R -1 g T (x)(∇σ c (x)) T ω c + 1 2 ∇σ c (x)g(x)R -1 g T (x)(∇σ c (x)) T ωc + 1 2 ∇σ c (x)G(x)G T (x)(∇σ c (x)) T ω c - 1 2 ∇σ c (x)G(x)G T (x)(∇σ c (x)) T ωc - 1 2 α s (x, û)∇σ c (x)g(x)R -1 g T (x)∇J s (x). (<label>59</label></formula><formula xml:id="formula_94">)</formula><p>In the following, the stability analysis of the neural-networkbased feedback control system is presented by using the Lyapunov theory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Stability Analysis</head><p>In this section, the error dynamics of the critic network and the closed-loop system based on the approximate optimal control will be proved to be UUB.</p><p>Theorem 3: Consider the nonlinear system given by ( <ref type="formula" target="#formula_1">2</ref>). Let the control input be provided by <ref type="bibr" target="#b45">(46)</ref> and the weights of the critic network be tuned by <ref type="bibr" target="#b53">(54)</ref>. Then, the state x of the closed-loop system and the weight estimation error ωc of the critic network are UUB.</p><p>Proof: See the Appendix.</p><p>Corollary 1: The approximate control input û in (46) converges to a neighborhood of optimal control input u * with finite bound. Proof: According to ( <ref type="formula">45</ref>) and ( <ref type="formula" target="#formula_71">46</ref>), we have</p><formula xml:id="formula_95">u * -û = - 1 2 R -1 g T (x)(∇σ (x)) T ωc - 1 2 R -1 g T (x)∇ε c (x). (<label>60</label></formula><formula xml:id="formula_96">)</formula><p>In light of Theorem 3, we have ωc &lt; A , where A is defined in the Appendix. Then, the terms R -1 g T (x)(∇σ (x)) T ωc and R -1 g T (x)∇ε c (x) are all bounded. Thus, we can further determine that</p><formula xml:id="formula_97">u * -û ≤ 1 2 R -1 M g M σ dM A + 1 2 R -1 M g M λ 10 ε u (<label>61</label></formula><formula xml:id="formula_98">)</formula><p>where λ 10 is given in the Appendix and ε u is the finite bound. This completes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Design Procedure of the Optimal Robust Guaranteed Cost Control</head><p>For continuous-time uncertain nonlinear systems (1) satisfying ( <ref type="formula" target="#formula_3">3</ref>) and ( <ref type="formula" target="#formula_4">4</ref>), we summarize the design procedure of optimal robust guaranteed cost control as follows.</p><p>Step 1: Select G(x) and ϕ(x), determine h(ϕ(x)), and conduct the problem transformation based on the bounded function (x).</p><p>Step 2: Choose the Lyapunov function candidate J s (x), construct a critic network as <ref type="bibr" target="#b42">(43)</ref>, and set its initial weights to zero. Step 3: Solve the transformed optimal control problem via online solution of the modified HJB equation, using the expressions of approximate control function <ref type="bibr" target="#b45">(46)</ref>, approximate Hamiltonian function <ref type="bibr" target="#b49">(50)</ref>, and weights update criterion <ref type="bibr" target="#b53">(54)</ref>.</p><p>Step 4: Derive the optimal robust guaranteed cost and optimal robust guaranteed cost control of original uncertain nonlinear system based on the converged weights of critic network. Remark 6: It is observed from ( <ref type="formula" target="#formula_67">43</ref>) and ( <ref type="formula" target="#formula_77">50</ref>), both the approximate cost function and the approximate Hamiltonian become zero when x = 0. In this case, we can find that ωc = 0. Thus, when the system state converges to zero, the weights of the critic network are no longer updated. This can be viewed as a persistency of excitation requirement of the neural network inputs. In other words, the system state must be persistently exciting long enough in order to ensure the critic network to learn the optimal cost function as accurately as possible. In this paper, the persistency of excitation condition is satisfied by adding an exploration noise to the control input. The condition can be removed once the weights of the critic network converge to their target values. Actually, it is for this reason that there always exists a tradeoff between computational accuracy and time consumption for practical realization. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. SIMULATION STUDIES</head><p>In this section, two simulation examples are provided to demonstrate the effectiveness of the optimal robust guaranteed cost control strategy derived based on the online HJB solution. We first consider a continuous-time linear system and then a nonlinear system, both with system uncertainty.</p><p>Example 1: Consider the continuous-time linear system</p><formula xml:id="formula_99">ẋ = -1 -2 1 -4 x + 1 -3 u + f (x)<label>(62)</label></formula><p>where x = [x 1 , x 2 ] T and f (x) = [px 1 sin x 2 , 0] T with p ∈ [ -0.5, 0.5]. According to the form of system uncertainty, we choose G(x) = [1, 0] T and ϕ(x) = x. Then, we have d(ϕ(x)) = px 1 sin x 2 . Besides, we select h(ϕ(x)) = 0.5x 1 sin x 2 .</p><p>In this example, we first choose Q(x) = x T x, R = I, where I is an identity matrix with suitable dimension. In order to solve the transformed optimal control problem, a critic network is constructed to approximate the modified cost function as</p><formula xml:id="formula_100">V(x) = ωc1 x 2 1 + ωc2 x 1 x 2 + ωc3 x 2 2 . (<label>63</label></formula><formula xml:id="formula_101">)</formula><p>Let the initial state of the controlled plant be x 0 = [1, -1] T . Select the Lyapunov function candidate of the weights tuning criterion as J s (x) = (1/2)x T x. Let the learning rate of the critic network and the additional term be α c = 0.8 and α s = 0.5, respectively. During the neural network implementation process, we bring in an exploration noise N (t) = sin 2 (t) cos(t) + sin 2 (2t) cos(0.1t) + sin 2 (-1.2t) cos(0.5t) + sin 5 (t) + sin 2 (1.12t) + cos(2.4t) sin 3 (2.4t) to satisfy the persistency of excitation condition. It is introduced into the control input and thus affects the system state. After a learning session, the weights of the critic network converge to [0.3461, -0.1330, 0.1338] T as shown in Fig. <ref type="figure" target="#fig_1">2</ref>. Here, it is important to note that the initial weights of the critic network are all set as zero, which implies that no initial stabilizing control is needed for implementing the control strategy. This can be verified by observing Fig. <ref type="figure" target="#fig_2">3</ref>, which displays the updating process of weight vector during the first 10 s.  Based on the converged weight vector, the optimal robust guaranteed cost of the controlled system is (u * ) = J * (x 0 ) = 0.6129. Next, the scalar parameter p = 0.5 is chosen for evaluating the control performance. Under the action of the obtained control function, the system trajectory during the first 20 s is presented in Fig. <ref type="figure" target="#fig_3">4</ref>, which shows the good performance of the control approach.</p><p>Next, we set Q(x) = 8x T x, R = 5I, and conduct the neural network implementation again by increasing the learning rates of the critic network and the additional term properly. In this case, the weights of the critic network converge to [5.4209, -3.5088, 1.2605] T , which is depicted in Fig. <ref type="figure" target="#fig_4">5</ref>. Similarly, the system trajectory during the first 20 s when choosing p = 0.5 is displayed in Fig. <ref type="figure" target="#fig_5">6</ref>. These simulation results show that the parameters Q(x) and R play an important role in the design process. In addition, the power of the present control technique is demonstrated again.  Example 2: Consider the following continuous-time nonlinear system:</p><formula xml:id="formula_102">ẋ = ⎡ ⎣ -x 1 + x 2 0.1x 1 -x 2 -x 1 x 3 x 1 x 2 -x 3 ⎤ ⎦ + ⎡ ⎣ 0 1 0 ⎤ ⎦ u + f (x) (<label>64</label></formula><formula xml:id="formula_103">)</formula><p>where</p><formula xml:id="formula_104">x = [x 1 , x 2 , x 3 ] T , f (x) = [0, 0, px 1 sin x 2 cos x 3 ] T , and p ∈ [ -1, 1]</formula><p>. Similarly, if we choose G(x) = [0, 0, 1] T and ϕ(x) = x based on the form of system uncertainty, then d(ϕ(x)) = px 1 sin x 2 cos x 3 . Clearly, we can select h(ϕ(x)) = x 1 sin x 2 cos x 3 .</p><p>In this example, Q(x) and R are chosen the same as the first case of Example 1. However, the critic network is constructed using the following form: Here, let the initial state of the controlled system be x 0 = [1, -1, 0.5] T . Besides, let the learning rate of the critic network and the additional term be α c = 0.3 and α s = 0.5, respectively. Same as above, an exploration noise is added to satisfy the persistency of excitation condition during the neural network implementation process. Besides, all the elements of the weight vector of critic network are initialized to zero. After a sufficient learning session, the weights of the critic network converge to [0.4759, 0.5663, 0.1552, 0.4214, 0.0911, 0.0375, 0.0886, -0.0099, 0.0986, 0.1539, 0.0780, -0.0192, -0.1335, -0.0052, -0.0639, -0.1583, 0.0456, 0.0576, -0.0535, 0.0885, -0.0227] T .</p><formula xml:id="formula_105">V(x) = ωc1 x 2 1 + ωc2 x 2 2 + ωc3 x 2 3 + ωc4 x 1 x 2 + ωc5 x 1 x 3 + ωc6 x 2 x 3 + ωc7 x 4 1 + ωc8 x 4 2 + ωc9 x 4 3 + ωc10 x 2 1 x 2 2 + ωc11 x 2 1 x 2 3 + ωc12 x 2 2 x 2 3 + ωc13 x 2 1 x 2 x 3 + ωc14 x 1 x 2 2 x 3 + ωc15 x 1 x 2 x 2 3 + ωc16 x 3 1 x 2 + ωc17 x 3 1 x 3 + ωc18 x 1 x 3 2 + ωc19 x 3 2 x 3 + ωc20 x 1 x 3 3 + ωc21 x 2 x 3 3 . (<label>65</label></formula><formula xml:id="formula_106">)</formula><p>Similarly, the optimal robust guaranteed cost of the nonlinear system is (u * ) = J * (x 0 ) = 1.1841. In this example, the scalar parameter p = -1 is chosen for evaluating the robust control performance. The system trajectory is depicted in Fig. <ref type="figure" target="#fig_6">7</ref> when applying the obtained control to system (64) for 20 s. These simulation results verify the effectiveness of the developed control approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>A novel strategy is developed to derive the optimal robust guaranteed cost control of uncertain nonlinear systems. This is accomplished by properly modifying the cost function to account for system uncertainty, so that the solution of the transformed optimal control problem serves as the optimal robust guaranteed cost of the original system. A critic network is constructed to solve the modified HJB equation online. Two simulation examples are presented to reinforce the theoretical results as well.</p><p>As for future works, we will study the optimal robust guaranteed cost control of uncertain nonlinear systems with constrained inputs based on single network ADP approach. In this case, we let all the elements of control input u(t) in system (1) have lower and upper bounds, i.e., u imin ≤ u i ≤ u imax , i = 1, 2, . . . , m, where u imin and u imax are constants. Besides, how to deal with the problem when the dynamic knowledge of nominal system is unknown serves as another interesting direction of future research. Under such circumstance, functions f (x) and g(x) are assumed to be unknown, hence the system identification will be employed by constructing neural networks. Remarkably, as an important part of machine learning community, reinforcement learning is characterized by finding optimal actions in unknown environment <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>. Thus, it is of great significance to use more advanced idea of reinforcement learning to handle the optimal control problems under uncertain and unknown environment. Moreover, how to relax the restrictive condition of system uncertainty is also one of the directions of our future works. Additionally, the inverse optimal control <ref type="bibr" target="#b67">[68]</ref>, <ref type="bibr" target="#b68">[69]</ref>, which is featured by the fact that the meaningful cost function is determined from the stabilizing feedback control, serves as another effective strategy aimed at circumventing the challenging task of solving the HJB equation. Thus, the inverse optimal control approach will also be helpful for our future study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>Proof of Theorem 3: We choose the following Lyapunov function candidate:</p><formula xml:id="formula_107">L(t) = 1 2α c ωT c ωc + α s α c J s (x) (A.1)</formula><p>where J s (x) is presented in Assumption 2. The derivative of the Lyapunov function candidate (A.1) with respect to time along the dynamics of ( <ref type="formula" target="#formula_73">47</ref>) and ( <ref type="formula" target="#formula_93">59</ref>) is</p><formula xml:id="formula_108">L(t) = 1 α c ωT c ωc + α s α c (∇J s (x)) T ẋ. (A.2)</formula><p>Substituting ( <ref type="formula" target="#formula_73">47</ref>) and ( <ref type="formula" target="#formula_93">59</ref>) into (A.2), we obtain</p><formula xml:id="formula_109">L(t) = ωT c -ωT c ∇σ c (x)f (x) - 1 4 ωT c ∇σ c (x)g(x)R -1 g T (x)(∇σ c (x)) T ωc + 1 2 ωT c ∇σ c (x)g(x)R -1 g T (x)(∇σ c (x)) T ω c + 1 4 ωT c ∇σ c (x)G(x)G T (x)(∇σ c (x)) T ωc - 1 2 ωT c ∇σ c (x)G(x)G T (x)(∇σ c (x)) T ω c -e cH × ∇σ c (x)f (x) - 1 2 ∇σ c (x)g(x)R -1 g T (x)(∇σ c (x)) T ω c + 1 2 ∇σ c (x)g(x)R -1 g T (x)(∇σ c (x)) T ωc + 1 2 ∇σ c (x)G(x)G T (x)(∇σ c (x)) T ω c - 1 2 ∇σ c (x)G(x)G T (x)(∇σ c (x)) T ωc - α s 2α c (x, û) ωT c ∇σ c (x)g(x)R -1 g T (x)∇J s (x) + α s α c (∇J s (x)) T ẋ. (A.3)</formula><p>For simplicity, we denote</p><formula xml:id="formula_110">A = ∇σ c (x)g(x)R -1 g T (x)(∇σ c (x)) T (A.4) B = ∇σ c (x)G(x)G T (x)(∇σ c (x)) T . (A.5)</formula><p>Then, (A.3) becomes</p><formula xml:id="formula_111">L(t) = -ωT c ∇σ c (x)f (x) + 1 4 ωT c A ωc - 1 2 ωT c Aω c - 1 4 ωT c B ωc + 1 2 ωT c Bω c + e cH × ωT c ∇σ c (x)f (x) + 1 2 ωT c A ωc - 1 2 ωT c Aω c - 1 2 ωT c B ωc + 1 2 ωT c Bω c - α s 2α c (x, û) ωT c ∇σ c (x)g(x)R -1 g T (x)∇J s (x) + α s α c (∇J s (x)) T ẋ. (A.6)</formula><p>Considering ( <ref type="formula" target="#formula_73">47</ref>), we have</p><formula xml:id="formula_112">L(t) = -ωT c ∇σ c (x)ẋ - 1 4 ωT c A ωc - 1 4 ωT c B ωc + 1 2 ωT c Bω c + e cH × ωT c ∇σ c (x)ẋ - 1 2 ωT c B ωc + 1 2 ωT c Bω c - α s 2α c (x, û) ωT c ∇σ c (x)g(x)R -1 g T (x)∇J s (x) + α s α c (∇J s (x)) T ẋ. (A.7)</formula><p>Noticing that ẋ * = f (x) + g(x)u * , where u * is given by ( <ref type="formula">45</ref>), we can further obtain that</p><formula xml:id="formula_113">L(t) = -ωT c ∇σ c (x)ẋ * + 1 4 ωT c A ωc + 1 2 ωT c ∇σ c (x)g(x)R -1 g T (x)∇ε c (x) - 1 4 ωT c B ωc + 1 2 ωT c Bω c + e cH × ωT c ∇σ c (x)ẋ * + 1 2 ωT c A ωc + 1 2 ωT c ∇σ c (x)g(x)R -1 g T (x)∇ε c (x) - 1 2 ωT c B ωc + 1 2 ωT c Bω c - α s 2α c (x, û) ωT c ∇σ c (x)g(x)R -1 g T (x)∇J s (x) + α s α c (∇J s (x)) T ẋ. (A.8)</formula><p>As in <ref type="bibr" target="#b44">[45]</ref>, we assume that λ 1m &gt; 0 and λ 1M &gt; 0 are the lower and upper bounds of the norm of matrix A. Similarly, assume that λ 2m &gt; 0 and λ 2M &gt; 0 are the lower and upper bounds of the norm of matrix B. Assume that R -1 ≤ R -1 M , g(x) ≤ g M , ∇σ (x) ≤ σ dM , Bω c ≤ λ 4 , ∇ε c (x) ≤ λ 10 , and e cH ≤ λ 12 , where R -1 M , g M , σ dM , λ 4 , λ 10 , and λ 12 are positive constants. In addition, assume that ∇σ c (x)ẋ * ≤ λ 3 , where λ 3 is a positive constant. Let λ 5 = ( √ 6/2)λ 12 , λ 9 = g 2 M R -1 M , and λ 11 = σ dM g 2 M R -1 M λ 10 , then g(x)R -1 g T (x) ≤ λ 9 and ∇σ (x)g(x)R -1 g T (x)∇ε c (x) ≤ λ 11 . Using the relations and φ i , i = 1, 2, . . . , 6, are nonzero constants chosen for the design purpose. Note that under the action of φ i , i = 1, 2, . . . , 6, the relation λ 7 &gt; 0 can be guaranteed.</p><formula xml:id="formula_114">ab = 1 2 -φ + a - b φ + 2 + φ 2 + a 2 + b 2 φ 2 + (A.9) -ab = - 1 2 φ -a + b φ - 2 -φ 2 -a 2 -</formula><p>In the following, the cases of (x, û) = 0 and (x, û) = 1 will be considered, respectively.</p><p>Case 1: (x, û) = 0. Since (∇J s (x)) T ẋ &lt; 0, we have -(∇J s (x)) T ẋ &gt; 0. According to the density property of real numbers, there exists a positive constant λ 6 such that 0 &lt; λ 6 ∇J s (x) ≤ -(∇J s (x)) T ẋ holds for all x ∈ , i.e., (∇J s (x)) T ẋ ≤ -λ 6 ∇J s (x) . Hence, the inequality (A. holds, we obtain L(t) &lt; 0.</p><p>To summarize, if the inequality ωc &gt; max(A 1 , A 2 ) = A or ∇J s (x) &gt; max(B 1 , B 2 ) = B holds, then L(t) &lt; 0. Considering the fact that J s (x) is chosen as a polynomial and in accordance with the standard Lyapunov extension theorem <ref type="bibr" target="#b69">[70]</ref>, we can derive the conclusion that the state x and the weight estimation error ωc are UUB. This completes the proof.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Structural diagram of neural network implementation (the solid line represents the signal and the dashed line represents the back-propagating path).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Convergence of weight vector of the critic network (ω ac1 , ω ac2 , and ω ac3 represents ωc1 , ωc2 , and ωc3 , respectively).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Updating process of weight vector during the first 10 s (ω ac1 , ω ac2 , and ω ac3 represent ωc1 , ωc2 , and ωc3 , respectively).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. System state (p = 0.5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Convergence of weight vector of the critic network (ω ac1 , ω ac2 , and ω ac3 represents ωc1 , ωc2 , and ωc3 , respectively).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. System state (p = 0.5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. System state (p = -1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>+ , φ -, and φ 1 are nonzero constants. Other terms of (A.8) can be handled the same way. Then, we can find that L(t) ≤ -λ 7 ωc 4 + λ 8 ωc 2 + λ 2</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>b 2 -φ 2</cell><cell>(A.10)</cell></row><row><cell cols="3">we have</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-</cell><cell>3 4</cell><cell>( ωT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">= -</cell><cell>3 8</cell><cell></cell><cell></cell><cell cols="2">φ 1</cell><cell>ωT c ∇σ c (x)ẋ  *  +</cell><cell>φ 1 ωT c A ωc</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-φ 2 1 ( ωT c ∇σ c (x)ẋ  *  ) 2 -</cell><cell>( ωT c A ωc ) 2 φ 2 1</cell></row><row><cell></cell><cell></cell><cell>≤</cell><cell cols="2">3 8</cell><cell cols="5">φ 2 1 ( ωT c ∇σ c (x)ẋ  *  ) 2 +</cell><cell>( ωT c A ωc ) 2 φ 2 1</cell></row><row><cell></cell><cell></cell><cell>≤</cell><cell cols="3">3 8φ 2 1</cell><cell cols="4">λ 2 1M ωc</cell><cell>4 +</cell><cell>3 8</cell><cell>φ 2 1 λ 2 3 ωc</cell><cell>2</cell><cell>(A.11)</cell></row><row><cell cols="10">where φ 5 -α s (x, û) ωT 2α c + α s α c (∇J s (x)) T ẋ</cell><cell>(A.12)</cell></row><row><cell cols="3">where</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">λ 7 =</cell><cell>1 8</cell><cell cols="4">λ 2 1m +</cell><cell>1 8</cell><cell>λ 2 2m -</cell><cell>3 8φ 2 1</cell><cell>λ 2 1M -</cell><cell>3 8φ 2 2</cell><cell>λ 2 2M</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">-</cell><cell cols="2">3 16</cell><cell cols="3">φ 2 3 λ 2 1M -</cell><cell>3 16</cell><cell>φ 2 4 λ 2 1M -</cell><cell>3 16</cell><cell>φ 2 5 λ 2 11 -</cell><cell>3 16</cell><cell>φ 2 6 λ 2 2M</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(A.13)</cell></row><row><cell></cell><cell cols="2">λ 8 =</cell><cell>3 8</cell><cell cols="5">φ 2 1 λ 2 3 +</cell><cell>3 8</cell><cell>φ 2 2 λ 2 3 +</cell><cell>3 16φ 2 3</cell><cell>λ 2 11</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">+</cell><cell cols="3">3 16φ 2 4</cell><cell cols="2">λ 2 4 +</cell><cell>3 16φ 2 5</cell><cell>λ 2 11 +</cell><cell>3 16φ 2 6</cell><cell>λ 2 4</cell><cell>(A.14)</cell></row></table><note><p>c ∇σ c (x)ẋ * )( ωT c A ωc ) c ∇σ c (x)g(x)R -1 g T (x)∇J s (x)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Case 2: (x, û) = 1. Adding and subtracting α s (∇J s (x)) T g(x)R -1 g T (x)∇ε c (x)/(2α c ) to the right hand side of (A.12) and taking Assumption 2 into consideration yieldL(t) ≤ -λ 7 ωc 4 + λ 8 ωc 2 + λ 2 5 -α s 2α c ωT c ∇σ c (x)g(x)R -1 g T (x)∇J s (x)</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>+</cell><cell>α s α c</cell><cell>(∇J s (x)) T (f (x) + g(x)û)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">= -λ 7 ωc + α s (∇J s (x)) T (f (x) + g(x)u  *  ) 4 + λ 8 ωc 2 + λ 2 5 α c + α s 2α c (∇J s (x)) T g(x)R -1 g T (x)∇ε c (x)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">≤ -λ 7 ωc -α s α c λ m ∇J s (x) 2 + 4 + λ 8 ωc 2 + λ 2 5 α s 2α c λ 9 λ 10 ∇J s (x) . (A.18)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Therefore, given the following inequality:</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ωc ≥</cell><cell cols="2">λ 8 2λ 7</cell><cell>+</cell><cell>λ 2 5 λ 7</cell><cell>+</cell><cell>λ 2 8 4λ 2 7</cell><cell>+</cell><cell>α s λ 2 9 λ 2 10 16α c λ m λ 7</cell><cell>A 2 (A.19)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>or</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>∇J s (x) ≥</cell><cell cols="2">λ 9 λ 10 4λ m</cell><cell>+</cell><cell>α c 4λ 2 5 λ 7 + λ 2 8 4α s λ m λ 7</cell><cell>+</cell><cell>λ 2 9 λ 2 10 m 16λ 2</cell><cell>B 2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(A.20)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>12)</cell><cell></cell></row><row><cell>becomes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>L(t) ≤ -λ 7 ωc ≤ -λ 7 ωc</cell><cell cols="2">4 + λ 8 ωc 4 + λ 8 ωc</cell><cell>2 + λ 2 5 + 2 + λ 2 5 -</cell><cell>α s α c α s α c</cell><cell cols="3">(∇J s (x)) T ẋ λ 6 ∇J s (x) . (A.15)</cell><cell></cell></row><row><cell cols="6">Therefore, given the following inequality:</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">ωc ≥</cell><cell cols="4">λ 8 + 4λ 2 5 λ 7 + λ 2 8 2λ 7</cell><cell>A 1</cell><cell>(A.16)</cell><cell></cell></row><row><cell>or</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">∇J s (x) ≥</cell><cell cols="2">α c 4λ 2 5 λ 7 + λ 2 8 4α s λ 6 λ 7</cell><cell cols="2">B 1</cell><cell></cell><cell>(A.17)</cell><cell></cell></row></table><note><p>holds, we conclude L(t) &lt; 0.</p></note></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Natural Science Foundation of China under Grant 61034002, Grant 61233001, Grant 61273140, Grant 61304086, Grant 61374105, and Grant 71232006, in part by the Beijing Natural Science Foundation under Grant 4132078, and in part by the Early Career Development Award of State Key Laboratory of Management and Control for Complex Systems. This paper was recommended by Associate Editor D. Wang.</p><p>Fei-Yue Wang (S'87-M'89-SM'94-F'03) received the Ph.D. degree in computer and systems engineering from Rensselaer Polytechnic Institute, Troy, NY, USA, in 1990. He was with the University of Arizona, Tucson, AZ, USA, in 1990, where he became a Professor and a Director of the Robotics and Automation Laboratory and the Program for Advanced Research in Complex Systems. He is the Founder of the Intelligent Control and Systems Engineering Center with the Chinese Academy of Sciences (CAS), Beijing, China, under the support of the Outstanding Overseas Chinese Talents Program, in 1999. Since 2002, he has been the Director of the Key Laboratory of Complex Systems and Intelligence Science with the CAS, and is currently the Director of The State Key Laboratory of Management and Control for Complex Systems. His current research interests include social computing, web science, complex systems, and intelligent control. Dr. Wang was the recipient of the National Prize in Natural Sciences of China and was awarded the Outstanding Scientist by ACM for his work in intelligent control and social computing. He was an Editor-in-Chief of the International Journal of Intelligent Control and Systems and the World Scientific Series in Intelligent Control and Intelligent Automation, from 1995 to 2000. He is currently an Editor-in-Chief of the IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS. He has served as Chair for over 20 IEEE, ACM, Institute for Operations Research and the Management Sciences, and American Society of Mechanical Engineers (ASME) conferences. He was the President of the IEEE Intelligent Transportation Systems Society, from 2005 to 2007, the Chinese Association for Science and Technology, New York, NY, USA, in 2005, and the U.S. Zhu Kezhen Education Foundation from 2007 to 2008. He is currently the Vice President of the ACM China Council and Vice President/Secretary-General of Chinese Association of Automation. He is the member of Sigma Xi and an Elected Fellow of the International Council on Systems Engineering, International Federation of Automatic Control, ASME, and American Association for the Advancement of Science. Hongliang Li (S'13) received the B.S. degree in mechanical engineering and automation from the Beijing University of Posts and Telecommunications, Beijing, China, in 2010. He is currently pursuing the Ph.D. degree from The State Xiong Yang received the B.S. degree in mathematics and applied mathematics from Central China Normal University, Wuhan, China, the M.S. degree in pure mathematics from Shandong University, Jinan, China, and the Ph.D. degree in control theory and control engineering from the Institute of Automation, Chinese Academy of Sciences, Beijing, China, in 2008, 2011, and 2014, respectively. He is currently an Assistant Professor with the Institute of Automation, Chinese Academy of Sciences. His current research interests include adaptive dynamic programming, reinforcement learning, adaptive control, and neural networks.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Approximate dynamic programming for real-time control and neural modeling</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Intelligent Control: Neural, Fuzzy, and Adaptive Approaches</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>White</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Sofge</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Van Nostrand Reinhold</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
	<note>ch. 13</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">ADP: The key direction for future research in intelligent control and understanding brain intelligence</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="898" to="900" />
			<date type="published" when="2008-08">Aug. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Intelligence in the brain: A theory of how it works and how to build it</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="200" to="212" />
			<date type="published" when="2009-04">Apr. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adaptive critic designs</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Prokhorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Wunsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="997" to="1007" />
			<date type="published" when="1997-09">Sep. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Missile defense and interceptor allocation by neurodynamic programming</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Homer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Patek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Sandell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. A, Syst., Humans</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="42" to="51" />
			<date type="published" when="2000-01">Jan. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On-line learning control by association and reinforcement</title>
		<author>
			<persName><forename type="first">J</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="264" to="276" />
			<date type="published" when="2001-03">Mar. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Intelligent supply chain management using adaptive critic learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shervais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Shannon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Lendaris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. A, Syst., Humans</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="235" to="244" />
			<date type="published" when="2003-03">Mar. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automated web navigation using multiagent adaptive dynamic programming</title>
		<author>
			<persName><forename type="first">J</forename><surname>Varghese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mukhopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. A, Syst., Humans</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="412" to="417" />
			<date type="published" when="2003-05">May 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adaptive dynamic programming: An introduction</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Intell. Mag</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="39" to="47" />
			<date type="published" when="2009-05">May 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reinforcement learning and adaptive dynamic programming for feedback control</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vrabie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Circuits Syst. Mag</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="32" to="50" />
			<date type="published" when="2009-07">Jul. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Reinforcement learning and feedback control: Using natural decision methods to design optimal adaptive controllers</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vrabie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Vamvoudakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Control Syst. Mag</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="76" to="105" />
			<date type="published" when="2012-12">Dec. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An overview of research on adaptive dynamic programming</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Autom. Sinica</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="303" to="311" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Data-based self-learning optimal control: Research progress and prospects</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Autom. Sinica</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1858" to="1870" />
			<date type="published" when="2013-11">Nov. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Realization of an adaptive memetic algorithm using differential evolution and Q-learning: A case study in multirobot path planning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rakshit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern., Syst</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="814" to="831" />
			<date type="published" when="2013-07">Jul. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Discrete-time nonlinear HJB solution using approximate dynamic programming: Convergence proof</title>
		<author>
			<persName><forename type="first">A</forename><surname>Al-Tamimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abu-Khalaf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="943" to="949" />
			<date type="published" when="2008-08">Aug. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neural-network-based near-optimal control for a class of discrete-time affine nonlinear systems with control constraints</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1490" to="1503" />
			<date type="published" when="2009-09">Sep. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Adaptive dynamic programming for finite-horizon optimal control of discrete-time nonlinear systems with ε-error bound</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="36" />
			<date type="published" when="2011-01">Jan. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Finite-horizon neuro-optimal tracking control for a class of discrete-time nonlinear systems using adaptive dynamic programming approach</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="22" />
			<date type="published" when="2012-02">Feb. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neural-network-based optimal control for a class of unknown discrete-time nonlinear systems using globalized dual heuristic programming</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Sci. Eng</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="628" to="634" />
			<date type="published" when="2012-07">Jul. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Optimal control of unknown nonaffine nonlinear discrete-time systems based on adaptive dynamic programming</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1825" to="1832" />
			<date type="published" when="2012-08">Aug. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A neuralnetwork-based iterative GDHP approach for solving a class of nonlinear optimal control problems with control constraints</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="219" to="227" />
			<date type="published" when="2013-02">Feb. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Neural-network-based zero-sum game for discrete-time nonlinear systems via iterative adaptive dynamic programming algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="92" to="100" />
			<date type="published" when="2013-06">Jun. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Optimal control for discrete-time affine nonlinear systems using general value iteration</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Control Theory Appl</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="2725" to="2736" />
			<date type="published" when="2012-12">Dec. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Finite-horizon control-constrained nonlinear optimal control using single network adaptive critics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Heydari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="157" />
			<date type="published" when="2013-01">Jan. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Adaptive learning in tracking control based on the dual critic network design</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="913" to="928" />
			<date type="published" when="2013-06">Jun. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A three-network architecture for on-line learning and optimization based on adaptive dynamic programming</title>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="13" />
			<date type="published" when="2012-02">Feb. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Goal representation heuristic dynamic programming on maze navigation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2038" to="2050" />
			<date type="published" when="2013-12">Dec. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Kernel-based approximate dynamic programming for real-time online learning control: An experimental study</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Control Syst. Technol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="146" to="156" />
			<date type="published" when="2014-01">Jan. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Online optimal control of affine nonlinear discrete-time systems with unknown internal dynamics by using timebased policy update</title>
		<author>
			<persName><forename type="first">T</forename><surname>Dierks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1118" to="1129" />
			<date type="published" when="2012-07">Jul. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Data-driven neuro-optimal temperature control of water gas shift reaction using stable iterative adaptive dynamic programming</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="6399" to="6408" />
			<date type="published" when="2014-11">Nov. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Policy iterative adaptive dynamic programming algorithm for discrete-time nonlinear systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="621" to="634" />
			<date type="published" when="2014-03">Mar. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Neuro-optimal control for a class of unknown nonlinear dynamic systems using SN-DHP technique</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="218" to="225" />
			<date type="published" when="2013-12">Dec. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An iterative adaptive dynamic programming algorithm for optimal control of unknown discrete-time nonlinear systems with constrained inputs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="page" from="331" to="342" />
			<date type="published" when="2013-01">Jan. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An iterative -optimal control scheme for a class of discrete-time nonlinear systems with unfixed initial state</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="236" to="244" />
			<date type="published" when="2012-08">Aug. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Finite-approximation-error-based optimal control approach for discrete-time nonlinear systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="779" to="789" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Adaptive critic learning techniques for engine torque and air-fuel ratio control</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Javaherian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kovalenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="988" to="993" />
			<date type="published" when="2008-08">Aug. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Nearly optimal control laws for nonlinear systems with saturating actuators using a neural network HJB approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abu-Khalaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="779" to="791" />
			<date type="published" when="2005-05">May 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Neural network approach to continuoustime direct adaptive optimal control for partially unknown nonlinear systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Vrabie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="237" to="246" />
			<date type="published" when="2009-04">Apr. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Online actor-critic algorithm to solve the continuous-time infinite horizon optimal control problem</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Vamvoudakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="878" to="888" />
			<date type="published" when="2010-05">May 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A novel actor-critic-identifier architecture for approximate optimal control of uncertain nonlinear systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bhasin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="82" to="92" />
			<date type="published" when="2013-01">Jan. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Neural network based online simultaneous policy update algorithm for solving the HJI equation in nonlinear H ∞ control</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1884" to="1895" />
			<date type="published" when="2012-12">Dec. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Near-optimal control for nonzero-sum differential games of continuous-time nonlinear systems using singlenetwork ADP</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="206" to="216" />
			<date type="published" when="2013-02">Feb. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Adaptive optimal control for a class of continuous-time affine nonlinear systems with unknown internal dynamics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1843" to="1850" />
			<date type="published" when="2013-12">Dec. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Neural-network-observerbased optimal control for unknown nonlinear systems using adaptive dynamic programming</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Control</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1554" to="1566" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Optimal control of affine nonlinear continuous-time systems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Dierks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Amer. Control Conf</title>
		<meeting>Amer. Control Conf<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-06">Jun. 2010</date>
			<biblScope unit="page" from="1568" to="1573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Neural networkbased optimal adaptive output feedback control of a helicopter UAV</title>
		<author>
			<persName><forename type="first">D</forename><surname>Nodland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zargarzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1061" to="1073" />
			<date type="published" when="2013-07">Jul. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Decentralized stabilization for a class of continuous-time nonlinear interconnected systems using online learning optimal control approach</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="418" to="428" />
			<date type="published" when="2014-02">Feb. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Online synchronous approximate optimal learning algorithm for multi-player non-zero-sum games with unknown dynamics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern., Syst</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1015" to="1027" />
			<date type="published" when="2014-08">Aug. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Policy iteration algorithm for online design of robust control for a class of continuous-time nonlinear systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Sci. Eng</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="627" to="632" />
			<date type="published" when="2014-04">Apr. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Neural-network-based robust optimal control design for a class of uncertain nonlinear systems via adaptive dynamic programming</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">282</biblScope>
			<biblScope unit="page" from="167" to="179" />
			<date type="published" when="2014-10">Oct. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Reinforcement learning for adaptive optimal control of unknown continuous-time nonlinear systems with input constraints</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Control</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="553" to="566" />
			<date type="published" when="2014-03">Mar. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Integral reinforcement learning for linear continuous-time zero-sum games with completely unknown dynamics</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Sci. Eng</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="706" to="714" />
			<date type="published" when="2014-07">Jul. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Adaptive optimal control of unknown constrained-input systems using policy iteration and neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Modares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Naghibi-Sistani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1513" to="1525" />
			<date type="published" when="2013-10">Oct. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Off-policy reinforcement learning for H ∞ control design</title>
		<author>
			<persName><forename type="first">B</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint/>
	</monogr>
	<note>to be published</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Bounded robust control of nonlinear systems using neural network-based HJB solution</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Adhyaru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">N</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gopal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="103" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Fixed final time optimal control approach for bounded robust controller design using Hamilton-Jacobi-Bellman solution</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Adhyaru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">N</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gopal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Control Theory Appl</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1183" to="1195" />
			<date type="published" when="2009-09">Sep. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Decentralized optimal control of a class of interconnected nonlinear discrete-time systems by using online Hamilton-Jacobi-Bellman formulation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mehraeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1757" to="1769" />
			<date type="published" when="2011-11">Nov. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Stochastic optimal control of unknown linear networked control system in the presence of random delays and packet losses</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1017" to="1030" />
			<date type="published" when="2012-06">Jun. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Wide-area measurement based dynamic stochastic optimal power flow control for smart grids with high variability and uncertainty</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Venayagamoorthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Harley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Smart Grid</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="69" />
			<date type="published" when="2012-03">Mar. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Robust nonlinear feedback control for uncertain linear systems with nonquadratic performance criteria</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Haddad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Chellaboina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Fausz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Syst. Control Lett</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="327" to="338" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Optimal non-linear robust control for nonlinear uncertain systems</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Haddad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chellaboina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Fausz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leonessa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Control</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="329" to="342" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Nonlinear Dynamical Systems and Control: A Lyapunov-Based Approach</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Haddad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chellaboina</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Princeton Univ. Press</publisher>
			<pubPlace>Princeton, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Robust control of nonlinear systems: Compensating for uncertainty</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Brand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Control</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1453" to="1459" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Adaptive guaranteed cost control of systems with uncertain parameters</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S L</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K C</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="474" to="483" />
			<date type="published" when="1972-04">Apr. 1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Optimal guaranteed cost control of linear uncertain systems with input constraints</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">L</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">X</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Control Autom. Syst</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="397" to="402" />
			<date type="published" when="2005-09">Sep. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">An LMI approach to guaranteed cost control of linear uncertain time-delay systems</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1155" to="1159" />
			<date type="published" when="1999-06">Jun. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Galerkin approximations of the generalized Hamilton-Jacobi-Bellman equation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Beard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Saridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2159" to="2177" />
			<date type="published" when="1997-12">Dec. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Inverse optimal design of input-to-state stabilizing nonlinear controllers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Krstic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="336" to="350" />
			<date type="published" when="1998-03">Mar. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Inverse optimal stabilization of a rigid spacecraft</title>
		<author>
			<persName><forename type="first">M</forename><surname>Krstic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tsiotras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1042" to="1049" />
			<date type="published" when="1999-05">May 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Neural Network Control of Robot Manipulators and Nonlinear Systems</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yesildirek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Taylor &amp; Francis</publisher>
			<pubPlace>London, U.K.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
