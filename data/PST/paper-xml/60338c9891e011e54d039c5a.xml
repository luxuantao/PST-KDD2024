<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MolCLR: Molecular Contrastive Learning of Representations via Graph Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-02-19">19 Feb 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yuyang</forename><surname>Wang</surname></persName>
							<email>yuyangw@cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jianren</forename><surname>Wang</surname></persName>
							<email>jianrenwang.cs@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhonglin</forename><surname>Cao</surname></persName>
							<email>zhonglic@andrew.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Barati</forename><surname>Amir</surname></persName>
							<email>barati@cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><surname>Farimani</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">MolCLR: Molecular Contrastive Learning of Representations via Graph Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-02-19">19 Feb 2021</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2102.10056v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Molecular machine learning bears promise for efficient molecule property prediction and drug discovery. However, due to the limited labeled data and the giant chemical space, machine learning models trained via supervised learning perform poorly in generalization. This greatly limits the applications of machine learning methods for molecular design and discovery. In this work, we present MolCLR: Molecular Contrastive Learning of Representations via Graph Neural Networks (GNNs), a self-supervised learning framework for large unlabeled molecule datasets. Specifically, we first build a molecular graph, where each node represents an atom and each edge represents a chemical bond. A GNN is then used to encode the molecule graph. We propose three novel molecule graph augmentations: atom masking, bond deletion, and subgraph removal. A contrastive estimator is utilized to maximize the agreement of different graph augmentations from the same molecule. Experiments show that molecule representations learned by MolCLR can be transferred to multiple downstream molecular property prediction tasks. Our method thus achieves state-of-the-art performance on many challenging datasets. We also prove the efficiency of our proposed molecule graph augmentations on supervised molecular classification tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Molecular representation is fundamental and essential in design of functional and novel chemical compounds <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4]</ref>. Due to the enormous magnitude of possible stable chemical compounds, development of an informative representation to generalize among the entire chemical space can be challenging <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7]</ref>. Conventional molecular representations, like SMILES <ref type="bibr" target="#b7">[8]</ref> and ECFP <ref type="bibr" target="#b8">[9]</ref>, have became standard tools in computational chemistry. Recently with the development of machine learning methods, data-driven molecular representation learning and its applications, including chemical property prediction <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14]</ref>, chemical modeling <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref>, and drug discovery <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref>, have gathered growing attentions.</p><p>However, learning such representations can be difficult due to three major challenges. Firstly, it is hard to represent the molecular information thoroughly. For instance, string-based representations, like SMILES <ref type="bibr" target="#b7">[8]</ref>, SMARTS <ref type="bibr" target="#b22">[23]</ref>, and SELFIES <ref type="bibr" target="#b23">[24]</ref>, fail to encode the important topology information directly. To preserve the rich structural information, many recent works exploit Graph Neural Networks (GNNs) <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref>, and have shown promising results in molecular property prediction <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28]</ref> and virtual screening <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>. Secondly, the magnitude of chemical space is enormous <ref type="bibr" target="#b30">[31]</ref>, e.g., the size of potential pharmacologically active molecules is estimated to be in the order of 10 60 <ref type="bibr" target="#b31">[32]</ref>. This places a great difficulty for any molecular representations to generalize among the potential chemical compounds. Thirdly, labeled data for molecular learning tasks are expensive and far from sufficient, especially when compared with the size of potential chemical space. Obtaining labels of molecular property usually requires sophisticated and time-consuming lab experiments <ref type="bibr" target="#b32">[33]</ref>. The breadth of chemical research further complicates the challenges, since the properties of interest range from quantum mechanics to biophysics <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref>. Consequently, the number of labels in most molecular learning benchmarks is far from adequate. Machine learning models trained on such benchmarks can easily get over-fitting and perform poorly on molecules dissimilar to the training set.</p><p>In this work, we propose Molecular Contrastive Learning of Representations (MolCLR) via Graph Neural Networks to address all the above challenges. MolCLR is a self-supervised learning framework trained on the large unlabeled molecule dataset. Through contrastive loss <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37]</ref>, MolCLR learns the representations by contrasting positive molecule graph pairs against negative ones. Three molecule graph augmentation strategies are introduced: atom masking, bond deletion, and subgraph removal. Molecule graph pairs augmented from the same molecule are denoted as positive, while others are denoted as negative. A widely-used GNN model, Graph Isomorphism Network (GIN) <ref type="bibr" target="#b25">[26]</ref>, is pretrained through MolCLR to extract informative representation from the augmented molecule graph. The pre-trained model is then fine-tuned on the downstream molecular property prediction tasks. Experiments show that the performance of our MolCLR surpasses other self-supervised learning and pre-training strategies in multiple molecular benchmarks <ref type="bibr" target="#b33">[34]</ref>. Besides, in the downstream tasks, our MolCLR rivals or even exceeds supervised learning baselines, which include sophisticated graph convolution operations for molecules or domain-specific featurization. We also demonstrate that our molecule graph augmentation strategies improve the performance of supervised learning on molecular benchmarks when utilized as a direct data augmentation plug-in.</p><p>To summarize, <ref type="bibr" target="#b0">(1)</ref> We propose MolCLR, a self-supervised learning framework for molecular representation learning. <ref type="bibr" target="#b1">(2)</ref> We propose three molecule graph augmentation strategies to generate contrastive pairs, namely atom masking, bond deletion, and subgraph removal. Besides, we also demonstrate the improvement of implementing our proposed molecule graph augmentations in supervised molecular classifications. <ref type="bibr" target="#b2">(3)</ref> We achieve the state-of-the-arts on several downstream molecular classification tasks with fine-tuning. This indicates that the MolCLR is capable of learning informative molecular representations without domain knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>Contrastive Learning. Contrastive learning <ref type="bibr" target="#b37">[38]</ref> aims at learning representation through contrasting positive data pairs against negative ones. In <ref type="bibr" target="#b38">[39]</ref>, CNN is trained by discriminating between surrogate classes parameterized by feature vectors. Memory bank is then introduced in <ref type="bibr" target="#b39">[40]</ref> to store features of each instances. Several works have then adopted and improved the memory bank <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42]</ref>. MoCo <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44]</ref> proposes a moving-average momentum encoder, which builds an on-the-fly consistent dictionary. Instead of using memory bank, SimCLR <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b44">45]</ref> demonstrates contrastive learning can greatly benefits from the composition of data augmentations and large batch sizes. Based on InfoNCE loss <ref type="bibr" target="#b35">[36]</ref>, SimCLR proposes the normalized temperature-scaled cross entropy (NT-Xent) loss as given in Eq. 1:</p><formula xml:id="formula_0">L i,j = log exp(sim(z z z i , z z z j )/τ ) 2N k=1 1{k = i} exp(sim(z z z i , z z z k )/τ ) ,<label>(1)</label></formula><p>where z z z i and z z z j are latent vectors extracted from a positive data pair, N is the batch size, sim(•) measures the similarity between the two vectors, and τ is the temperature parameter.</p><p>Graph Neural Networks. Non-euclidean data represented in the form of graphs is common across various domains <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b46">47]</ref>, such as molecule structures we investigate in this work <ref type="bibr" target="#b47">[48]</ref>. A graph G is defined as G = (V, E), where V and E are nodes and edges respectively <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b49">50]</ref>. Modern Graph Neural Networks (GNNs) utilize a neighborhood aggregation operation, which update the node representation iteratively <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b24">25]</ref>. The aggregation update rule for a node feature on the k-th layer of a GNN is given in Eq. 2:</p><formula xml:id="formula_1">a a a (k) v = AGGREGATE (k) ({h h h (k−1) u : u ∈ N (v)}), h h h (k) v = COMBINE (k) (h h h (k−1) v , a a a (k) v ), (2) where h h h (k)</formula><p>v is the feature of node v at the k-th layer and h h h</p><formula xml:id="formula_2">(0)</formula><p>v is initialized by node feature x x x v . N (v) denotes the set of all the neighbors of node v. To further extract a graph-level feature h h h G , readout operation integrates all the node features among the graph G as given in Eq. 3:</p><formula xml:id="formula_3">h h h G = READOUT({h h h (k) u : v ∈ G}).<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cc1ccc(CCS)cc1F</head><p>Molecule graph 𝐺 1 Various aggregation operations have been proposed to improve the performance of GNN. GraphSAGE <ref type="bibr" target="#b53">[54]</ref> proposes a max-pooling operation over a ReLU <ref type="bibr" target="#b54">[55]</ref> activated linear transformation as the aggregation. GCN <ref type="bibr" target="#b24">[25]</ref> integrates the aggregation and combination operations by introducing a meanpooling over the node itself and its adjacencies before the linear transformation. GIN <ref type="bibr" target="#b25">[26]</ref> utilizes an MLP and weighted summation of node features in the aggregation. GAT <ref type="bibr" target="#b55">[56]</ref> performs the multi-head attention to increase the model's expressive capability. Various other aggregation operations include diffusion convolution <ref type="bibr" target="#b56">[57]</ref>, message passing <ref type="bibr" target="#b12">[13]</ref>, and Gaussian-kernelized weight function <ref type="bibr" target="#b57">[58]</ref>. Besides, incorporating edge features into the GNN has also been investigated <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b61">62]</ref>. For readout operations, common strategies can be a graph-level summation, averaging, and max pooling. Some works have also developed elaborate graph readout modules to improve predictive performance and computational efficiency of GNNs <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b64">65]</ref>.</p><formula xml:id="formula_4">CCn1ccc2cc[nH]c(=O)c21 Molecule graph 𝐺 𝑁 …… ℎ 1 ℎ 2 ℎ 2𝑁−1 ℎ 2𝑁 …… …… 𝑧 1 𝑧 2 𝑧 2𝑁−1 Contrastive Loss Augmentation 𝑧 2𝑁 Augmentation Graph Conv Graph Conv Readout Readout …… SMILES 𝑠 1 SMILES 𝑠 𝑁 ෨ 𝐺 2 ෨ 𝐺 1 ෨ 𝐺 2𝑁 ෨ 𝐺 2𝑁−1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">MolCLR Framework</head><p>Our MolCLR model is developed upon the contrastive learning framework <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b44">45]</ref>. Latent representations from positive augmented molecule graph pairs are contrasted with representations from negative pairs. As shown in Figure <ref type="figure" target="#fig_0">1</ref>, the whole pipeline is composed of four components: data processing and augmentation, GNN-based feature extractor, non-linear projection head, and an NT-Xent <ref type="bibr" target="#b36">[37]</ref> contrastive loss. In our case, we implement the commonly-used GIN <ref type="bibr" target="#b25">[26]</ref> aggregation operation and an average pooling as the readout operator to extract the molecular representations. A non-linear projection head g(•) is modeled by an MLP with one hidden layer, which maps the representations h i and h j into latent vectors z i and z j respectively. Contrastive loss, NT-Xent, is applied to the 2N latent vectors z's as given in Eq. 1, and cosine similarity is utilized to calculate sim(z i , z j ) =</p><formula xml:id="formula_5">z T i zj zi 2 zj 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Molecule Graph Augmentation</head><p>We employ three molecule graph data augmentation strategies (Figure <ref type="figure" target="#fig_1">2</ref>) as transformations for our MolCLR framework: atom masking, bond deletion, and subgraph removal.</p><p>Atom Masking Atoms in the molecule graph are randomly masked with a given ratio. When an atom is masked, its atom feature x x x v is replaced by a mask token m m m, which is distinguished from any atom features in the molecular graph. Shown by red shadows in Figure <ref type="figure" target="#fig_1">2</ref>(a), six atoms including two Hydrogen, two Carbon, a Nitrogen, and an Oxygen are masked in the molecule graph.</p><p>Bond Deletion Bond deletion randomly deletes chemical bonds between the atoms with a certain ratio. Unlike atom masking which substitutes the original feature with a mask token, bond deletion is a more rigorous augmentation as it removes the edges completely from the molecule graph. Such a stronger augmentation strategy forces the GNN feature extractor to learn more informative representations.</p><p>Subgraph Removal Subgraph removal can be considered as a combination of atom masking and bond deletion. Subgraph removal starts from a randomly picked origin atom. The removal process proceeds by masking the neighbors of the original atom, and then the neighbors of the neighbors, until the number of masked atoms reaches a given ratio of the total number of atoms in the molecular graph. The bonds between the masked atoms are then deleted, such that the masked atoms and deleted bonds form an induced subgraph <ref type="bibr" target="#b65">[66]</ref> of the original molecule graph. As shown in Figure <ref type="figure" target="#fig_1">2</ref>(c), the removed subgraph includes all the bonds between the masked atoms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>Pre-training Dataset. For MolCLR pre-training, we use 10 million unique unlabeled molecule SMILES from <ref type="bibr" target="#b66">[67]</ref>, which are collected from PubChem <ref type="bibr" target="#b67">[68]</ref>. RDKit <ref type="bibr" target="#b68">[69]</ref> is then utilized to add hydrogen atoms to molecule structure and then build the molecule graphs from the SMILES strings. Within the molecule graph, each node represents an atom and each edge represents a chemical bond.</p><p>We randomly split the pre-training dataset into training and validation set with a ratio of 95/5. Downstream Datasets. To benchmark the performance of our MolCLR framework, we use 7 datasets from MoleculeNet <ref type="bibr" target="#b33">[34]</ref>, containing in total 44 binary classification tasks. These tasks cover molecule properties of multiple domains, including physical chemistry, biophysics, and physiology. For each dataset, we use the scaffold split <ref type="bibr" target="#b69">[70]</ref> from DeepChem <ref type="bibr" target="#b70">[71]</ref> to create an 80/10/10 train/valid/test split as suggested in <ref type="bibr" target="#b59">[60]</ref>. Unlike the common random split, the scaffold split, which is based on molecular substructures, makes the prediction task more challenging yet realistic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baselines</head><p>Supervised learning models. We comprehensively evaluate the performance of our MolCLR model with supervised learning methods. For shallow machine learning models, Random Forest (RF) <ref type="bibr" target="#b71">[72]</ref> and Support Vector Machine (SVM) <ref type="bibr" target="#b72">[73]</ref> are implemented, which take molecular descriptors as the input. Besides, state-of-the-art graph-based neural networks are also included. Extended GIN <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b59">60]</ref> with edge feature involved in aggregation is compared. D-MPNN <ref type="bibr" target="#b27">[28]</ref> and MGCNN <ref type="bibr" target="#b73">[74]</ref>, which are graph neural network models designed specifically for molecule prediction tasks, are also included as the baselines.</p><p>Self-supervised learning models. To better demonstrate the power of our MolCLR framework, we further include other molecular self-supervised learning models in the baselines. HU. et.al <ref type="bibr" target="#b59">[60]</ref> with both node-level and graph-level pre-training is considered. It should be pointed out that though node-level pre-training is based on self-supervision, the graph-level pre-training is supervised on some molecule property labels <ref type="bibr" target="#b59">[60]</ref>. N-Gram graph <ref type="bibr" target="#b74">[75]</ref> is also implemented, which computes a compact representation directly through the molecule graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Training Details</head><p>Each atom on the molecule graph is embedded by its atomic number and chirality type <ref type="bibr" target="#b75">[76]</ref>, while each bond is embedded by its type and direction. We implement a 5-layer Graph Isomorphism Network (GIN) <ref type="bibr" target="#b25">[26]</ref> with ReLU activation <ref type="bibr" target="#b54">[55]</ref> as the GNN backbone, and follow the modification in <ref type="bibr" target="#b59">[60]</ref> to make GIN compatible with edge features. An average pooling is applied on each graph as the readout operation to extract the 512-dimension molecular representation. An MLP with one hidden layer maps the representation into a 256-dimension latent space. Adam <ref type="bibr" target="#b76">[77]</ref> optimizer with weight decay 10 −5 is used to optimize the NT-Xent loss. After the initial 10 epochs with learning rate 3 × 10 −4 , cosine annealing without restart <ref type="bibr" target="#b77">[78]</ref> decays the learning rate cyclically. The model is trained with batch size 512 for the total 100 epochs. The pre-training of MolCLR takes ~5 days on one NVIDIA Quadro RTX 6000.</p><p>For the downstream task fine-tuning, we add a randomly initialized 2-layer MLP with ReLU activation on top of the base feature extractor. For binary classification tasks, softmax cross-entropy loss is implemented. The learning rate of the MLP head is set to 3 × 10 −4 and the base GIN extractor is set to 3 × 10 −5 . The model is trained using Adam optimizer with batch size 32 for another 50 epochs. For each task, we fine-tune the pre-trained model three times using different random seeds for scaffold splitting to get the average and standard deviation of the performance. The whole framework is implemented based on Pytorch Geometric <ref type="bibr" target="#b78">[79]</ref>. The choice of the temperature parameter τ in Eq. 1 impacts the performance of contrastive learning <ref type="bibr" target="#b36">[37]</ref>. An appropriate τ benefits the model to learn from hard negative samples. To investigate τ for molecule representation learning, we train MolCLR with three different temperatures: 0.05, 0.1, and 0.5 as shown in Table <ref type="table" target="#tab_2">2</ref>. We report the averaged ROC-AUC over all the seven benchmarks using 25% subgraph removal as the augmentation strategy. It is demonstrated that τ = 0.1 performs the best in the downstream molecular tasks. Therefore, we use this temperature setting in the following experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2">Composition of Molecule graph Augmentations</head><p>To systematically investigate the effect of molecule graph augmentation strategies, we compare different compositions of atom masking, bond deletion, and subgraph removal. Shown in Figure <ref type="figure" target="#fig_2">3</ref> are the ROC-AUC mean and standard deviation of each data augmentation compositions on different benchmarks. Four augmentation compositions are considered. (1) Integration of atom masking and bond deletion with both ratios p set to 25%. (2) Subgraph removal with a random ratio p from 0% to 25%.</p><p>(3) Subgraph removal with a fixed 25% ratio. ( <ref type="formula">4</ref>) Composition of all the three augmentation strategies. Specifically, a subgraph removal with a random ratio 0% to 25% is first applied. Then if the ratio of masked atoms is smaller than 25%, we continue random atom masking until it reaches the ratio of 25%. Similarly, if the bond deletion ratio is smaller than 25%, more bonds are deleted to reach the set ratio. The four compositions are shown in yellow, gray, blue, and orange respectively in Figure <ref type="figure" target="#fig_2">3</ref>.</p><p>As Figure <ref type="figure" target="#fig_2">3</ref> illustrates, subgraph removal with a 25% ratio reaches the best performance on average among all the four compositions. This could because that subgraph removal is an intrinsic composition of atom masking and bond deletion, and that subgraph removal further disentangles the local substructures compared with strategy (1). However, subgraph removal with a fixed 25% ratio performs poorly in BBBP dataset, which can be attributed to that molecule structures in BBBP are sensitive, such that a slight topology change can cause great property difference. Besides, it is worth noticing that the composition of all three augmentations, (4), does not improve the performance. On the contrary, it hurts the ROC-AUC compared with single subgraph removal augmentation in most benchmarks. The composition of all the three augmentation strategies can remove a wide range of substructures within the molecule graph, thus eliminate the important topology information. The molecule graph augmentation strategies in our work, namely atom masking, bond deletion, and subgraph removal, can be implemented as a direct data augmentation plug-in for any graphbased molecular learning methods. To validate the effectiveness of molecule graph augmentations on supervised molecular tasks, we train GIN models with/without augmentations from scratch without pre-training. Specifically, subgraph masking with a fixed ratio 25% is implemented as the augmentation. Table <ref type="table" target="#tab_3">3</ref> documents the mean and standard deviation of test ROC-AUC over the seven molecular property classification benchmarks. On all the seven benchmarks, GINs trained with augmentations surpass the models without augmentations, and improve the averaged ROC-AUC score </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Molecule Graph Augmentation on Supervised Molecular Classifications</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">MolCLR Representation Visualization</head><p>We examine the representations learned by pre-trained MolCLR using t-SNE embedding <ref type="bibr" target="#b79">[80]</ref>. The t-SNE algorithm maps similar molecular representations to adjacent points. Shown in Figure <ref type="figure" target="#fig_3">4</ref> are 100K molecules from validation set of the pre-training data embedded to 2D via t-SNE, colored based on the molecular weights. We also include some randomly selected molecules in the figure to illustrate what are the similar/dissimilar molecules learned by MolCLR pre-training. As shown in Figure <ref type="figure" target="#fig_3">4</ref>, MolCLR learns close representations for molecules with similar topology structures and functional groups. For instance, the three molecules shown on the top possess carbonyl groups connected with aryls. The two molecules shown on the bottom left have similar structures, where a halogen atom (Fluorine or Chlorine) is connected to benzene. This demonstrates the potentials of MolCLR in application of drug search and drug discovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Works</head><p>Molecular representation learning has been growing rapidly over the last decade with the development and success of machine learning, especially deep learning driven by neural networks <ref type="bibr" target="#b80">[81,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b19">20]</ref>. In conventional cheminformatics, molecules are represented in unique fingerprint vectors, such as Extended-Connectivity Fingerprints (ECFP) <ref type="bibr" target="#b8">[9]</ref>. Given the fingerprints, deep neural networks are built to predict certain properties or classes <ref type="bibr" target="#b81">[82,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr" target="#b83">84]</ref>. Besides, SMILES <ref type="bibr" target="#b7">[8]</ref>, which maps the molecule into a string, is also widely-used for molecule representation <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b84">85]</ref>. Language models built upon RNNs are direct fit for learning representation from SMILES <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b85">86,</ref><ref type="bibr" target="#b86">87,</ref><ref type="bibr" target="#b87">88]</ref>.</p><p>With the recent success of transformer-based architectures, such language models have been also utilized in molecular representation learning from SMILES strings <ref type="bibr" target="#b88">[89,</ref><ref type="bibr" target="#b89">90]</ref>. Recently, GNNs, which naturally encode the structure information, have been introduced to molecular representation learning <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b90">91]</ref>. MPNN <ref type="bibr" target="#b12">[13]</ref> and D-MPNN <ref type="bibr" target="#b27">[28]</ref> implement a message-passing architecture to aggregate the information from molecule graphs. Further, SchNet <ref type="bibr" target="#b26">[27]</ref> models quantum interactions within molecules in the GNN. DimNet <ref type="bibr" target="#b60">[61]</ref> integrates the directional information by transforming messages based on the angle between atoms.</p><p>Benefiting from the growth of available molecule data <ref type="bibr" target="#b91">[92,</ref><ref type="bibr" target="#b92">93,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b67">68]</ref>, self-supervised/pre-trained molecular representation learning has also been investigated. Self-supervised language models, like BERT <ref type="bibr" target="#b93">[94]</ref>, has been implemented to learn molecular representation with SMILES as input <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b94">95]</ref>. On molecule graph, N-Gram Graph <ref type="bibr" target="#b74">[75]</ref> builds the representation for the graph by assembling the vertex embedding in short walks, which needs no training. HU. et.al <ref type="bibr" target="#b59">[60]</ref> propose both node-level and graph-level tasks for GNN pre-training. However, the graph-level pre-training is based on supervised-learning tasks, which is constraint by limited labels. Our MolCLR framework, on the contrary, learns graph-level features directly via contrastive loss without any property labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Works</head><p>In this work, we investigate self-supervised learning for molecular representation. Specifically, we propose Molecular Contrastive Learning of Representations (MolCLR) via GNNs and three molecular graph augmentations strategies: atom masking, bond deletion, and subgraph removal. Through contrasting positive pairs against negative pairs from augmentations, MolCLR learns informative representation with general GNN backbones. Experiments show that MolCLR pre-trained GNN models achieve great improvement on various molecular benchmarks, and show better generalizations compared with models trained in the supervised learning manner.</p><p>Molecular representations learned by MolCLR demonstrates the transferability to molecular tasks with limited data and the power of generalization on the large chemical space. There exist many promising directions to investigate as future works. For instance, improvement of the GNN backbones (e.g. transformer-based GNN architectures <ref type="bibr" target="#b95">[96]</ref>) can help extract better molecular representations. Besides, visualization and interpretation of self-supervised learned representations are of great interest <ref type="bibr" target="#b96">[97]</ref>. Such investigations can help researchers better understand chemical compounds and benefit drug discovery.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Molecular Contrastive Learning of Representations via Graph Neural Networks. A SMILES s n from a mini-batch of N molecule data is converted to a molecule graph G n . Two stochastic molecule graph data augmentation operators are applied to each graph, resulting two correlated masked graphs: G2n−1 and G2n . A base feature encoder built upon graph convolutions and the readout operation extracts the representation h 2n−1 , h 2n . Contrastive loss is utilized to maximize agreement between the latent vectors z 2n−1 , z 2n from the MLP projection head.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Three molecule graph augmentation strategies. (a) Atom masking randomly replaces the node feature x x x v of an atom feature with a mask token m m m. (b) Bond deletion randomly deletes the bond between two atoms, so that the they are not directly connected on the graph. (c) Subgraph removal randomly removes an induced subgraph [66] from the original molecule graph. Within the subgraph, all nodes are masked and all edges are deleted.</figDesc><graphic url="image-18.png" coords="4,361.98,151.40,74.48,54.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Test ROC-AUC (%) performance of pre-trained MolCLR model with different compositions of molecular graph augmentation strategies. Height of each bar represents the mean ROC-AUC on the benchmark, and length of each error bar represents the standard deviation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Two-dimensional t-SNE embedding of the molecular representations learned by our MolCLR pre-training. Representations are extracted from the validation set of the pre-training dataset, which contains 100k unique molecules. The color of each embedding point indicates its corresponding molecular weight.</figDesc><graphic url="image-19.png" coords="8,190.47,104.11,248.07,179.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Test ROC-AUC (%) performance comparison of different models, where the first five models are supervised learning methods and the last three are self-supervised/pre-training methods. Mean and standard deviation on each benchmark are reported.</figDesc><table><row><cell>Dataset</cell><cell>BBBP</cell><cell>Tox21</cell><cell>ClinTox</cell><cell>HIV</cell><cell>BACE</cell><cell>SIDER</cell><cell>MUV</cell></row><row><cell># Molecules</cell><cell>2039</cell><cell>7831</cell><cell>1478</cell><cell>41127</cell><cell>1513</cell><cell>1478</cell><cell>93087</cell></row><row><cell># Tasks</cell><cell>1</cell><cell>12</cell><cell>2</cell><cell>1</cell><cell>1</cell><cell>27</cell><cell>17</cell></row><row><cell>RF</cell><cell cols="7">71.4±0.0 76.9±1.5 71.3±5.6 78.1±0.6 86.7±0.8 68.4±0.9 63.2±2.3</cell></row><row><cell>SVM</cell><cell cols="7">72.9±0.0 81.8±1.0 66.9±9.2 79.2±0.0 86.2±0.0 68.2±1.3 67.3±1.3</cell></row><row><cell>MGCN [74]</cell><cell cols="7">85.0±6.4 70.7±1.6 63.4±4.2 73.8±1.6 73.4±3.0 55.2±1.8 70.2±3.4</cell></row><row><cell cols="8">D-MPNN [28] 71.2±3.8 68.9±1.3 90.5±5.3 75.0±2.1 85.3±5.3 63.2±2.3 76.2±2.8</cell></row><row><cell>HU. et.al [60]</cell><cell cols="7">70.8±1.5 78.7±0.4 78.9±2.4 80.2±0.9 85.9±0.8 65.2±0.9 81.4±2.0</cell></row><row><cell>N-Gram [75]</cell><cell cols="7">91.2±3.0 76.9±2.7 85.5±3.7 83.0±1.3 87.6±3.5 63.2±0.5 81.6±1.9</cell></row><row><cell>MolCLR</cell><cell cols="7">73.6±0.5 79.8±0.7 93.2±1.7 80.6±1.1 89.0±0.3 68.0±1.1 88.6±2.2</cell></row><row><cell cols="3">4.4 Results on Downstream Tasks</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>demonstrates the test ROC-AUC performance of our MolCLR model in comparison to baseline models. The average and standard deviation of three individual runs are reported. Bold cells denote the best performing method on each benchmark, either via supervised or self-supervised/pre-training strategy. Observations from Table1are the followings. (1) In comparison with other self-supervised learning or pre-training strategies, our MolCLR framework achieves the best performance on 5 out of 7 benchmarks, with an average improvement of 5.0%. Such improvement illustrates that our</figDesc><table><row><cell>4.5 Ablation Study</cell></row><row><cell>4.5.1 Temperature in Contrastive Loss</cell></row></table><note>MolCLR is a powerful self-supervised learning strategy, which is easy to implement and requires little domain-specific sophistication. (2) Compared with the supervised learning baselines, MolCLR also shows rival performance. In some benchmarks, our pre-training model even surpasses the SOTA supervised learning methods. For instance, on ClinTox, MolCLR improves the ROC-AUC by 2.9%.(3) Notably, MolCLR performs remarkably well on datasets with a limited number of molecules, like Clitox, BACE, and SIDER benchmarks. The performance validates that MolCLR learns informative representations that can be transferred among different datasets. Such capacity of generalization bears promise for predicting potential molecular properties in drug discovery and design.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Test ROC-AUC (%) performance comparison of different temperature parameter τ . Mean and standard deviation of all the seven benchmarks are reported.</figDesc><table><row><cell cols="2">Temperature (τ ) 0.05</cell><cell>0.1</cell><cell>0.5</cell></row><row><cell>ROC-AUC (%)</cell><cell cols="3">76.8±1.2 80.2±1.3 78.4±1.7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Test ROC-AUC (%) of GIN with/without molecule graph augmentations on all the seven supervised molecular classification benchmarks. GIN models are trained in the supervised learning manner without pre-training.</figDesc><table><row><cell>Dataset</cell><cell>BBBP</cell><cell>Tox21</cell><cell>ClinTox</cell><cell>HIV</cell><cell>BACE</cell><cell>SIDER</cell><cell>MUV</cell></row><row><cell cols="8">GIN w/o Aug 65.8±4.5 74.0±0.8 58.0±4.4 75.3±1.9 70.1±5.4 57.3±1.6 71.8±2.5</cell></row><row><cell>GIN w/ Aug</cell><cell cols="7">72.1±0.9 75.0±1.1 64.0±2.4 76.1±1.2 71.6±0.7 65.2±1.4 80.5±3.1</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On representing chemical environments</title>
		<author>
			<persName><forename type="first">Risi</forename><surname>Albert P Bartók</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gábor</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName><surname>Csányi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review B</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page">184115</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Big data of materials science: critical role of the descriptor</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Luca M Ghiringhelli</surname></persName>
		</author>
		<author>
			<persName><surname>Vybiral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudia</forename><surname>Sergey V Levchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Draxl</surname></persName>
		</author>
		<author>
			<persName><surname>Scheffler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review letters</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">105503</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Communication: Understanding molecular representations in machine learning: The role of uniqueness and target similarity</title>
		<author>
			<persName><forename type="first">Bing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Anatole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Von</forename><surname>Lilienfeld</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Molecular representations in ai-driven drug discovery: a review and practical guide</title>
		<author>
			<persName><forename type="first">Laurianne</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amol</forename><surname>Thakkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rocío</forename><surname>Mercado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ola</forename><surname>Engkvist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cheminformatics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Chemography: the art of navigating in chemical space</title>
		<author>
			<persName><forename type="first">I</forename><surname>Tudor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Oprea</surname></persName>
		</author>
		<author>
			<persName><surname>Gottfries</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of combinatorial chemistry</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="166" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Characteristics of known drug space. natural products, their derivatives and synthetic drugs</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Bade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jóhannes</forename><surname>Ho-Fung Chan</surname></persName>
		</author>
		<author>
			<persName><surname>Reynisson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European journal of medicinal chemistry</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5646" to="5652" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Stochastic voyages into uncharted chemical space produce a representative library of all possible drug-like compounds</title>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">M</forename><surname>Virshup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Contreras-García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Wipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weitao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">N</forename><surname>Beratan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Chemical Society</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page" from="7296" to="7303" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Smiles, a chemical language and information system. 1. introduction to methodology and encoding rules</title>
		<author>
			<persName><forename type="first">David</forename><surname>Weininger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and computer sciences</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="36" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Extended-connectivity fingerprints</title>
		<author>
			<persName><forename type="first">David</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathew</forename><surname>Hahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="742" to="754" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Convolutional networks on graphs for learning molecular fingerprints</title>
		<author>
			<persName><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dougal</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Aguilera-Iparraguirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Gómez-Bombarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alán</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Neural Information Processing Systems, NIPS&apos;15</title>
				<meeting>the 28th International Conference on Neural Information Processing Systems, NIPS&apos;15<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2224" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Stanisław</forename><surname>Jastrzębski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damian</forename><surname>Leśniak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><forename type="middle">Marian</forename><surname>Czarnecki</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.06289</idno>
		<title level="m">Learning to smile (s)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Grammar variational autoencoder</title>
		<author>
			<persName><forename type="first">Matt</forename><forename type="middle">J</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brooks</forename><surname>Paige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">José</forename><surname>Miguel Hernández-Lobato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1945" to="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">F</forename><surname>Samuel S Schoenholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">E</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Orbital graph convolutional neural network for material property prediction</title>
		<author>
			<persName><forename type="first">Mohammadreza</forename><surname>Karamad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishikesh</forename><surname>Magar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuting</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samira</forename><surname>Siahrostami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">D</forename><surname>Gates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Barati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farimani</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Materials</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">93801</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Towards exact molecular dynamics simulations with machine-learned force fields</title>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Chmiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Huziel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus-Robert</forename><surname>Sauceda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><surname>Tkatchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Realistic atomistic structure of amorphous silicon from machine-learning-driven molecular dynamics</title>
		<author>
			<persName><forename type="first">Noam</forename><surname>Volker L Deringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><forename type="middle">P</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Bartók</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><forename type="middle">N</forename><surname>Cliffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lauren</forename><forename type="middle">E</forename><surname>Kerber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clare</forename><forename type="middle">P</forename><surname>Marbella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">R</forename><surname>Grey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gábor</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName><surname>Csányi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The journal of physical chemistry letters</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2879" to="2885" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Coarse-graining auto-encoders for molecular dynamics</title>
		<author>
			<persName><forename type="first">Wujie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Gómez-Bombarelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">npj Computational Materials</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Low data drug discovery with one-shot learning</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Altae-Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bharath</forename><surname>Ramsundar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aneesh</forename><forename type="middle">S</forename><surname>Pappu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Pande</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACS central science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="283" to="293" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The rise of deep learning in drug discovery</title>
		<author>
			<persName><forename type="first">Hongming</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ola</forename><surname>Engkvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><surname>Olivecrona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Blaschke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Drug discovery today</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1241" to="1250" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Applications of machine learning in drug discovery and development</title>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Vamathevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominic</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Czodrowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Dunham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edgardo</forename><surname>Ferran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anant</forename><surname>Madabhushi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parantu</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michaela</forename><surname>Spitzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Drug Discovery</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="463" to="477" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Potential neutralizing antibodies discovered for novel corona virus using machine learning</title>
		<author>
			<persName><forename type="first">Rishikesh</forename><surname>Magar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prakarsh</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Barati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farimani</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2003.08447</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Cheng-Hao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maksym</forename><surname>Korablyov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanisław</forename><surname>Jastrzębski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paweł</forename><surname>Włodarczyk-Pruszyński</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marwin</forename><forename type="middle">Hs</forename><surname>Segler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.13042</idno>
		<title level="m">Retrognn: Approximating retrosynthesis by graph neural networks for de novo drug design</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Daylight Chemical Information Systems</title>
		<ptr target="https://www.daylight.com/dayhtml/doc/theory/theory.smarts.html" />
		<imprint>
			<date type="published" when="2021-02-13">Feb 13 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Self-referencing embedded strings (selfies): A 100% robust molecular string representation</title>
		<author>
			<persName><forename type="first">Mario</forename><surname>Krenn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Häse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshatkumar</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Friederich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning: Science and Technology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">45024</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Schnet-a deep learning architecture for molecules and materials</title>
		<author>
			<persName><surname>Kristof T Schütt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Huziel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P-J</forename><surname>Sauceda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K-R</forename><surname>Tkatchenko</surname></persName>
		</author>
		<author>
			<persName><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page">241722</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Analyzing learned molecular representations for property prediction</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wengong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Connor</forename><surname>Coley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Eiden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angel</forename><surname>Guzman-Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Hopper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miriam</forename><surname>Mathea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3370" to="3388" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Atomnet: a deep convolutional neural network for bioactivity prediction in structure-based drug discovery</title>
		<author>
			<persName><forename type="first">Izhar</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Dzamba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abraham</forename><surname>Heifets</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.02855</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Onionnet: a multiple-layer intermolecularcontact-based convolutional neural network for protein-ligand binding affinity prediction</title>
		<author>
			<persName><forename type="first">Liangzhen</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingrong</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuguang</forename><surname>Mu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACS omega</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="15956" to="15965" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Chemical space</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clare</forename><surname>Ellis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The art and practice of structurebased drug design: a molecular modeling perspective</title>
		<author>
			<persName><forename type="first">Regine</forename><forename type="middle">S</forename><surname>Bohacek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Mcmartin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">C</forename><surname>Guida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medicinal research reviews</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="50" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Guacamol: benchmarking models for de novo molecular design</title>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Fiscato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marwin</forename><forename type="middle">Hs</forename><surname>Segler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alain</forename><forename type="middle">C</forename><surname>Vaucher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1096" to="1108" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Moleculenet: a benchmark for molecular machine learning</title>
		<author>
			<persName><forename type="first">Zhenqin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bharath</forename><surname>Ramsundar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><forename type="middle">N</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caleb</forename><surname>Geniesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Aneesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Pappu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Leswing</surname></persName>
		</author>
		<author>
			<persName><surname>Pande</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemical science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="513" to="530" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Molecular sets (moses): a benchmarking platform for molecular generation models</title>
		<author>
			<persName><forename type="first">Daniil</forename><surname>Polykovskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Zhebrak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Sanchez-Lengeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Golovanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oktai</forename><surname>Tatanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanislav</forename><surname>Belyaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rauf</forename><surname>Kurbanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksey</forename><surname>Artamonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Aladinskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Veselov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in pharmacology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Representation learning with contrastive predictive coding</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Discriminative unsupervised feature learning with convolutional neural networks</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jost</forename><surname>Tobias Springenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3733" to="3742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05849</idno>
		<title level="m">Contrastive multiview coding</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Unsupervised embedding learning via invariant and spreading instance feature</title>
		<author>
			<persName><forename type="first">Mang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pong</forename><forename type="middle">C</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shih-Fu</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04297</idno>
		<title level="m">Improved baselines with momentum contrastive learning</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Big self-supervised models are strong semi-supervised learners</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.10029</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Geometric deep learning: going beyond euclidean data</title>
		<author>
			<persName><forename type="first">Joan</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="18" to="42" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Molecular graph convolutions: moving beyond fingerprints</title>
		<author>
			<persName><forename type="first">Steven</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Berndl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Pande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Riley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computer-aided molecular design</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="595" to="608" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A new model for learning in graph domains</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriele</forename><surname>Monfardini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franco</forename><surname>Scarselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 2005 IEEE International Joint Conference on Neural Networks</title>
				<meeting>2005 IEEE International Joint Conference on Neural Networks</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="729" to="734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">The graph neural network model</title>
		<author>
			<persName><forename type="first">Franco</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chung</forename><surname>Ah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriele</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName><surname>Monfardini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="61" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Spectral networks and locally connected networks on graphs</title>
		<author>
			<persName><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR2014)</title>
				<imprint>
			<date type="published" when="2014-04">April 2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">Mikael</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05163</idno>
		<title level="m">Deep convolutional networks on graph-structured data</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">Michaël</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.09375</idno>
		<title level="m">Convolutional neural networks on graphs with fast localized spectral filtering</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">Rex</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02216</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName><forename type="first">Awni</forename><forename type="middle">Y</forename><surname>Andrew L Maas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. icml</title>
				<meeting>icml</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">James</forename><surname>Atwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Don</forename><surname>Towsley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.02136</idno>
		<title level="m">Diffusion-convolutional neural networks</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Geometric deep learning on graphs and manifolds using mixture model cnns</title>
		<author>
			<persName><forename type="first">Federico</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davide</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emanuele</forename><surname>Rodola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Svoboda</surname></persName>
		</author>
		<author>
			<persName><surname>Michael M Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
				<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5115" to="5124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Exploiting edge features for graph neural networks</title>
		<author>
			<persName><forename type="first">Liyu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="9211" to="9219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Strategies for pre-training graph neural networks</title>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Pande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Directional message passing for molecular graphs</title>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Klicpera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janek</forename><surname>Groß</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.03123</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Nenn: Incorporate node and edge features in graph neural networks</title>
		<author>
			<persName><forename type="first">Yulei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="593" to="608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">An end-to-end deep learning architecture for graph classification</title>
		<author>
			<persName><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhicheng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marion</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Hierarchical graph representation learning with differentiable pooling</title>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.08804</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Universal readout for graph convolutional neural networks</title>
		<author>
			<persName><forename type="first">Nicolò</forename><surname>Navarin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dinh</forename><surname>Van Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sperduti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Joint Conference on Neural Networks (IJCNN)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Introduction to graph theory</title>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Brent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">West</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Prentice hall Upper Saddle River</publisher>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Chemberta: Large-scale selfsupervised pretraining for molecular property prediction</title>
		<author>
			<persName><forename type="first">Seyone</forename><surname>Chithrananda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabe</forename><surname>Grand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bharath</forename><surname>Ramsundar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.09885</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Pubchem 2019 update: improved access to chemical data</title>
		<author>
			<persName><forename type="first">Sunghwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiejun</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asta</forename><surname>Gindulyte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siqian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><forename type="middle">A</forename><surname>Shoemaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">A</forename><surname>Thiessen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">D1</biblScope>
			<biblScope unit="page" from="D1102" to="D1109" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Rdkit: Open-source cheminformatics</title>
		<author>
			<persName><forename type="first">Greg</forename><surname>Landrum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">The properties of known drugs. 1. molecular frameworks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">A</forename><surname>Bemis</surname></persName>
		</author>
		<author>
			<persName><surname>Murcko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of medicinal chemistry</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="2887" to="2893" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Karl Leswing, and Zhenqin Deep Learning for the Life Sciences</title>
		<author>
			<persName><forename type="first">Bharath</forename><surname>Ramsundar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Eastman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Walters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Pande</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<pubPlace>O&apos;Reilly Media</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Random decision forests</title>
		<author>
			<persName><forename type="first">Kam</forename><surname>Tin</surname></persName>
		</author>
		<author>
			<persName><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 3rd international conference on document analysis and recognition</title>
				<meeting>3rd international conference on document analysis and recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="278" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Support-vector networks</title>
		<author>
			<persName><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Molecular property prediction: A multilevel quantum interactions modeling perspective</title>
		<author>
			<persName><forename type="first">Chengqiang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenya</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peize</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lixin</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1052" to="1060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">N-gram graph: Simple unsupervised representation for graphs, with applications to molecules</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Demirel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingyu</forename><surname>Liang</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Compendium of chemical terminology</title>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">D</forename><surname>Mcnaught</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Wilkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Blackwell Science Oxford</title>
		<imprint>
			<biblScope unit="volume">1669</biblScope>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03983</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Fast graph representation learning with PyTorch Geometric</title>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Deep learning as an opportunity in virtual screening</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Mayr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Günter</forename><surname>Klambauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marvin</forename><surname>Steijaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jörg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Wegner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Ceulemans</surname></persName>
		</author>
		<author>
			<persName><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the deep learning workshop at NIPS</title>
				<meeting>the deep learning workshop at NIPS</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Deep neural nets as a method for quantitative structure-activity relationships</title>
		<author>
			<persName><forename type="first">Junshui</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">P</forename><surname>Sheridan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Svetnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="274" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Massively multitask networks for drug discovery</title>
		<author>
			<persName><forename type="first">Bharath</forename><surname>Ramsundar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Webster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Konerding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Pande</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.02072</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Generative recurrent networks for de novo drug design</title>
		<author>
			<persName><forename type="first">Anvita</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><forename type="middle">T</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Berend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jens</forename><forename type="middle">A</forename><surname>Huisman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petra</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gisbert</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Molecular informatics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page">1700111</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Seq2seq fingerprint: An unsupervised deep molecular embedding for drug discovery</title>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feiyun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM international conference on bioinformatics, computational biology, and health informatics</title>
				<meeting>the 8th ACM international conference on bioinformatics, computational biology, and health informatics</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="285" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Automatic chemical design using a data-driven continuous representation of molecules</title>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Gómez-Bombarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><forename type="middle">N</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">José</forename><surname>Miguel Hernández-Lobato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamín</forename><surname>Sánchez-Lengeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dennis</forename><surname>Sheberla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Aguilera-Iparraguirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">D</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alán</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACS central science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="268" to="276" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Bidirectional molecule generation with recurrent neural networks</title>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Grisoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Moret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Lingwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gisbert</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1175" to="1183" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Molecular transformer: a model for uncertainty-calibrated chemical reaction prediction</title>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Schwaller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teodoro</forename><surname>Laino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Théophile</forename><surname>Gaudin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bolgar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">A</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Costas</forename><surname>Bekas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alpha</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACS central science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1572" to="1583" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Molecule attention transformer</title>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Maziarka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomasz</forename><surname>Danel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sławomir</forename><surname>Mucha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krzysztof</forename><surname>Rataj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacek</forename><surname>Tabor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanisław</forename><surname>Jastrzębski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.08264</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Potentialnet for molecular property prediction</title>
		<author>
			<persName><forename type="first">Evan</forename><forename type="middle">N</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debnil</forename><surname>Sur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenqin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brooke</forename><forename type="middle">E</forename><surname>Husic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huanghao</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saisai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bharath</forename><surname>Ramsundar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><forename type="middle">S</forename><surname>Pande</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACS Central Science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1520" to="1530" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Chembl: a large-scale bioactivity database for drug discovery</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Gaulton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louisa</forename><forename type="middle">J</forename><surname>Bellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patricia</forename><surname>Bento</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne</forename><surname>Hersey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yvonne</forename><surname>Light</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaun</forename><surname>Mcglinchey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Michalovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bissan</forename><surname>Al-Lazikani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">D1</biblScope>
			<biblScope unit="page" from="D1100" to="D1107" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Zinc 15-ligand discovery for everyone</title>
		<author>
			<persName><forename type="first">Teague</forename><surname>Sterling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">J</forename><surname>Irwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2324" to="2337" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Smiles-bert: large scale unsupervised pre-training for molecular property prediction</title>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuzhi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongmao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM international conference on bioinformatics, computational biology and health informatics</title>
				<meeting>the 10th ACM international conference on bioinformatics, computational biology and health informatics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="429" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Graph transformer networks</title>
		<author>
			<persName><forename type="first">Seongjun</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minbyul</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raehyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyunwoo J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Alché-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Explainability methods for graph convolutional neural networks</title>
		<author>
			<persName><forename type="first">Soheil</forename><surname>Phillip E Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Kolouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Rostami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiko</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><surname>Hoffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="10772" to="10781" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
