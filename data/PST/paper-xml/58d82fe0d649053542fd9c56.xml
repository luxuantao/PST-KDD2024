<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Face Anti-Spoofing using Speeded-Up Robust Features and Fisher Vector Encoding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zinelabidine</forename><surname>Boulkenafet</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Machine Vision and Signal Analysis</orgName>
								<orgName type="institution">University of Oulu</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jukka</forename><surname>Komulainen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Machine Vision and Signal Analysis</orgName>
								<orgName type="institution">University of Oulu</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Abdenour</forename><surname>Hadid</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Machine Vision and Signal Analysis</orgName>
								<orgName type="institution">University of Oulu</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Face Anti-Spoofing using Speeded-Up Robust Features and Fisher Vector Encoding</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E35747DC39DE741EBA10BF5AA20B4867</idno>
					<idno type="DOI">10.1109/LSP.2016.2630740</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/LSP.2016.2630740, IEEE Signal Processing Letters</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The vulnerabilities of face biometric authentication systems to spoofing attacks have received a significant attention during the recent years. Some of the proposed countermeasures have achieved impressive results when evaluated on intra-tests i.e. the system is trained and tested on the same database. Unfortunately, most of these techniques fail to generalize well to unseen attacks e.g. when the system is trained on one database and then evaluated on another database. This is a major concern in biometric anti-spoofing research which is mostly overlooked. In this paper, we propose a novel solution based on describing the facial appearance by applying Fisher Vector encoding on Speeded-Up Robust Features (SURF) extracted from from different color spaces. The evaluation of our countermeasure on three challenging benchmark face spoofing databases, namely the CASIA Face Anti-Spoofing Database, the Replay-Attack Database and MSU Mobile Face Spoof Database, showed excellent and stable performance across all the three datasets. Most importantly, in inter-database tests, our proposed approach outperforms the state of the art and yields in very promising generalization capabilities, even when only limited training data is used.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>It is well known nowadays that face biometric systems are vulnerable to spoofing attacks e.g. when presenting fake faces using printed photos, video displays and masks. In a recent study <ref type="bibr" target="#b0">[1]</ref>, six commercial face recognition systems (Face Unlock, Facelock Pro, Visidon, Veriface, Luxand Blinkand FastAccess) were easily fooled with crude photo attacks using images of the targeted person downloaded from social networks.</p><p>To overcome the problem of spoofing attacks, many nonintrusive software-based countermeasures have been proposed <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>. While it is possible to exploit different visual cues for face spoofing detection such as motion <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref> and scene context <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b7">[8]</ref>, an approach solely based on single images of the face region is more appealing and also more challenging. It is appealing because the same information (i.e. the facial region) that is used for face recognition will also be used for spoofing detection. So, the two tasks can easily be coupled.</p><p>The methods solely based on single images of the face region exploit the fact that fake face images captured from printed photos, video displays and masks usually suffer from various quality and texture issues related to the spoofing medium or the manufacturing process. This includes lack of details, printing artifacts, specular reflections, or differences in shading. Assuming that these inherent disparities between</p><p>The financial support of the Academy of Finland and the Infotech Oulu is acknowledged real and fake faces can be observed in single visual spectrum images, the proposed methods in the literature analyze the facial appearance properties like texture <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref> and quality <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref> for face spoofing detection from single images of face region.</p><p>The existing face anti-spoofing techniques analyzing motion, facial texture content and image quality have already achieved impressive results particularly when trained and evaluated on the same database (i.e. intra-test protocols). As all the existing benchmark publicly available datasets lack variations in the collected data (e.g. user demographics, application scenarios, illumination conditions and input cameras), the reported anti-spoofing results may unfortunately not reflect the real uncontrolled operating conditions that the methods will be definitely faced in real world applications such as in mobile authentication.</p><p>To gain insight into the generalization performance of face anti-spoofing techniques, de Freitas Pereira et al. <ref type="bibr" target="#b12">[13]</ref> suggested an inter-database evaluation in which the antispoofing models are trained and tuned on one database and then tested on other databases. The experiments have revealed that the performance of the state-of-the-art methods drastically drops as the methods failed to cope with new spoofing conditions that have not been seen during training and development phases. Even the popular convolutional neural networks (CNN) have failed to derive well-generalizing features for face anti-spoofing <ref type="bibr" target="#b13">[14]</ref>.</p><p>It is indeed impossible to cover all possible variations related to spoofing operating conditions in the training data. Instead of augmenting the training data, a possible direction towards more robust software-based solutions is to design novel feature representations that are less sensitive to different environmental and subject-specific factors. In order to improve the generalization of texture based anti-spoofing methods, we have proposed the use of color texture analysis in <ref type="bibr" target="#b14">[15]</ref>, exploiting the fact that the color gamut of printing and display devices is limited. In order to map the out of gamut colors into the color gamut of different devices, color mapping algorithms are applied. Since the human eye is more sensitive to the luminance than the chrominance information, these mapping algorithms give a huge importance to the preservation of the spatially local luminance variations at the cost of the chroma information. These inherent disparities can be captured by analyzing the texture content of the chrominance channels. Our preliminary investigations in <ref type="bibr" target="#b14">[15]</ref> suggested that color texture when extracted separately from the luminance and the chrominance channels are more stable in many (unknown) conditions compared to their RGB and gray-scale counterparts.</p><p>The generalization capability of our color texture analysis method <ref type="bibr" target="#b14">[15]</ref> was dependent on the diversity of the training data. The method was performing very well when trained on the CASIA Face Anti-Spoofing Database <ref type="bibr" target="#b15">[16]</ref> containing different imaging qualities and then tested on the more constrained Replay-Attack Database <ref type="bibr" target="#b16">[17]</ref>. However, the performance of the method was less satisfactory when trained on constrained data (Replay-Attack Database) and then tested on more diverse data (CASIA Face Anti-Spoofing Database). This can be partially explained by the fact that only the basic local binary patterns (LBP) <ref type="bibr" target="#b17">[18]</ref> were considered for exploring the facial appearance. While LBP is indeed a simple and powerful texture descriptor that has shown to be very effective in many applications including face anti-spoofing, we argue that more advanced feature descriptors and encoding methods are needed to further enhance the generalization capability of face antispoofing.</p><p>In this present work, we propose a novel face representation for a well-generalizing anti-spoofing method using Speeded-Up Robust Features (SURF) and Fisher Vector encoding <ref type="bibr" target="#b18">[19]</ref>. The color information is exploited for discriminating real from fake faces by extracting dense SURF descriptions from different color spaces. The SURF features extracted from the different band images are concatenated and encoded using the Fisher Vector method. The face representation is then fed into a Softmax classifier. Our experiments on three challenging benchmark face spoofing databases, namely the CASIA Face Anti-Spoofing Database <ref type="bibr" target="#b15">[16]</ref>, the Replay-Attack Database <ref type="bibr" target="#b16">[17]</ref> and MSU Mobile Face Spoof Database <ref type="bibr" target="#b11">[12]</ref>, showed robust and stable performance across all these datasets. Most importantly, in the inter-database tests, our approach outperforms all the state of the art and yields in promising generalization capabilities, even when only limited training data is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROPOSED COUNTERMEASURE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The Speeded-Up Robust Features (SURF)</head><p>The Speeded-Up Robust Features (SURF) <ref type="bibr" target="#b19">[20]</ref> is a fast and efficient scale and rotation invariant descriptor. It was originally proposed to reduce the computational complexity of the Scale Independent Feature Transform (SIFT) descriptor <ref type="bibr" target="#b20">[21]</ref>. Instead of using the Difference of Gaussian (DoG) filters to approximate the Laplacian of Gaussian, the SURF descriptor uses the Haar box filters. A convolution with these box filters can be computed rapidly by utilizing integral images.</p><p>The SURF descriptor is obtained using the Wavelet responses in the horizontal and vertical directions. The region around each interest point is first divided into 4 × 4 subregions. Then, for each sub-region j, the horizontal and vertical Wavelet responses are used to form a feature vector V j as follows:</p><formula xml:id="formula_0">V j = [ d x , d y , |d x |, |d y |].<label>(1)</label></formula><p>Where d x and d y are the Haar wavelet responses in the horizontal and vertical directions, respectively. The feature vectors extracted from each sub-region are concatenated to from a SURF descriptor with 64 dimensions:</p><formula xml:id="formula_1">SU RF = [V 1 , ..., V 16 ].<label>(2)</label></formula><p>The SURF descriptor was originally proposed for grayscale images. Inspired by our previous finding <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b21">[22]</ref> showing the importance of the color texture in face antispoofing, we propose to extract the SURF features from the color images instead of the gray-scale representation. First, the SURF descriptor is applied on each color band separately. Then, the obtained features are concatenated to form a single feature vector (referred to as CSURF). Finally, Principal Component Analysis (PCA) <ref type="bibr" target="#b22">[23]</ref> is applied to de-correlate the obtained feature vector and reduce the dimensionality of the face description.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Fisher Vector (FV)</head><p>Extracting dense features has shown to be an essential component in many computer vision applications <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>. In <ref type="bibr" target="#b25">[26]</ref>, Fisher Vector (FV) encoding was shown to perform very well in many image recognition benchmarks. FV embeds a set of feature vectors into a high dimensional space more amenable to linear classification. The feature vectors are obtained by fitting a generative parametric model, e.g. Gaussian Mixture Model (GMM), to the features to be encoded. Let X = {x t , t = 1, ..., T } be a D-dimensional local descriptors extracted from a face Image I and let λ = {µ k , σ k , w k , k = 1, ..., M } be the means, the covariance matrices and the weights of the GMM model λ trained with a large set of local descriptors. The derivations of the model λ with respect of the mean and the covariance parameters (Equation 3 and 4) capture the first and the second order differences between the features X and each of the GMM components.</p><formula xml:id="formula_2">φ 1 k = 1 T √ w k T t=1 α t (k)( x t -µ k σ k )<label>(3)</label></formula><formula xml:id="formula_3">φ 2 k = 1 T √ 2w k T t=1 α t (k)[ (x t -µ k ) 2 σ 2 k -1],<label>(4)</label></formula><p>where, α t (k) is the soft assignment weight of the feature x t to the GMM component k:</p><formula xml:id="formula_4">α t (k) = w k u k (x t ) M j=1 w j u j (x t )<label>(5)</label></formula><p>Here, u i denote the probability density function of the Gaussian component i. The concatenation of these two order differences [φ 1  1 , ..., φ 1 M , φ 2 1 , ..., φ 2 M ] represent the Fisher Vector of the image I described by its local descriptors X. The dimensionality of this vector is 2M D. A Fisher vector represents how the distribution of the local descriptors X differ from the distribution of the GMM model trained with all the training images. To further improve the performance, the Fisher vectors are normalized using a square rooting followed by L 2 normalization <ref type="bibr" target="#b26">[27]</ref>. Figure <ref type="figure" target="#fig_0">1</ref> depict the general block diagrm of our face spoofing detection method. To assess the generalization capability of our proposed countermeasure, we used three public face anti-spoofing databases: CASIA Face Anti-Spoofing Database (CASIA FA) <ref type="bibr" target="#b15">[16]</ref>, Replay-Attack Database <ref type="bibr" target="#b16">[17]</ref> and MSU Mobile Face Spoof Database (MSU MFS) <ref type="bibr" target="#b11">[12]</ref>. These three datasets are the most challenging face anti-spoofing benchmark databases that consist of recordings of real client accesses and various spoofing attack attempts captured with different imaging qualities, including mobile phones, webcams and digital system cameras.</p><p>To allows a fair comparison with other methods proposed in the literature, we followed the official overall test protocols of the three databases. For CASIA FA and MSU MFS the model parameters are trained and tuned using a subject-disjoint crossvalidation on the training set and the results are reported in terms of Equal Error Rate (EER) on the test set. The Replay-Attack database provides also a separate development set for tuning the model parameters. Thus, the results are given in terms of EER on the development set and the Half Total Error Rate (HTER) on the test set following the official test protocol.</p><p>In all our experiments, The dense SU RF features were extracted from 64 × 64 face images with a stride of two pixels and block size of 11 pixels. The frame images, were taken from each video every 320 ms. The Fisher Vectors were estimated using a GMM model with diagonal covariance matrices computed using training set of each database. Finally, the normalized Fisher Vector were fed into a Softmax classifier with a cross-entropy loss function <ref type="bibr" target="#b27">[28]</ref>.</p><p>In addition to the intra-database evaluation, we have also conducted a cross-database evaluation. Where, we used the training set of each database to train the countermeasure model and the testing set to estimate the threshold τ which will be used on the other databases to compute the Half Total Error Rate (HTER).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RESULTS AND DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Effect of the color information</head><p>We begin our experiments by first evaluating the importance of the color SURF features (referred to as CSURF) compared to the gray-scale SURF features (referred to as SURF). In these experiments, we extracted the CSURF features from three color spaces: RGB, HSV and YCbCr. For the sake of simplicity, no dimensionality reduction or feature encoding technique was applied at this point. The results in both intradatabase and cross-database scenarios are presented in Table <ref type="table" target="#tab_0">I</ref> and Table <ref type="table" target="#tab_0">II</ref>, respectively. These results clearly indicate the importance of CSURF descriptions compared to the original SURF descriptions extracted from the gray-scale images. Comparing the results obtained using the different color spaces, we observe that using HSV and YCbCr color spaces yields in better performance compared to the RGB color space. This confirms the importance of using separated luminance and chrominance color spaces. As the color (luminance and the chrominance) information in the HSV and YCbCr color spaces are different, we propose to fuse the features extracted from these two color spaces in order to benefit from their potential complementarity. As shown in tables I and II, this fusion improves the performance in both intra-database (except on MSU database where the use of the HSV color space gives the best performance) and inter-database scenarios compared to the performance obtained using each color space separately. In the rest of our experiments, the CSURF features are extracted from the combined HSV-YCbCr color space. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Effect of feature encoding and dimensionality reduction</head><p>Since the CSURF features are very high-dimensional (393,216), we have also investigated the effect of the Fisher Vector encoding and dimensionality reduction on the performance of the CSURF features in both intra-database and interdatabase scenarios. The results are reported in tables III and IV. These results indicate that a significant performance enhancement is obtained in the two scenarios when FV encoding is applied on the CSURF features. However, the use of PCA for dimensionality reduction increases the robustness even further. In the intra-database scenario, using low dimensionality reduction with 100 principal components, the EER for CASIA FASD and MSU MFSD are 2.9%, 1.9%, respectively, and EER and HTER for Replay-Attack Database are 0.1% and 1.4%, respectively. For the cross-database scenario, the best results are obtained using 300 principal components whereas the average HTER over all the databases is 27.4%. Using too low dimensional features seems to decrease the generalization performance. Since we are focusing on the generalization capability, the CSURF features are projected into 300 principal components in the rest of our experiments.  In all the previous experiments, the CSURF features were encoded using a GMM model with 128 components. To study the effect of the number of the GMM components on the performance, we tested also GMM models with 64, 256 and 512 components. The results, presented in table V and VI, indicate that using 256 Gaussian components gives the best performance on both intra-database and inter-database tests.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Comparison with the state of the art</head><p>Tables VII and VIII provide a comparison between the results of our proposed approach and those of the state-of-the-art methods in both intra-database and cross-database evaluation. In intra-database evaluation (Table <ref type="table" target="#tab_0">VII</ref>), our proposed approach achieves the best performance on two databases: CA-SIA FASD and MSU MFSD. On the Replay-Attack Database, our obtained results are very competitive compared to the state-of-the-art methods. Note that the best performing method on the Replay-Attack Database (i.e. Motion mag+LBP <ref type="bibr" target="#b5">[6]</ref>) gives low performance on the CASIA FASD whereas our proposed methods is able to perform equally well across all the three datasets.</p><p>Most importantly, the inter-database evaluation (Table <ref type="table" target="#tab_0">VIII</ref>) demonstrates that our proposed CSURF approach outperforms all the state-of-the-art methods. The CSURF based face description yields in very promising generalization capabilities, even when only limited training data is used. Hence, our new features and encoding methods seems to better describe the inherent disparities in color information across various conditions.  * the results are re-computed using the frame based scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>We proposed a face anti-spoofing scheme based on color SURF (CSURF) features and Fisher Vector encoding. We extracted the SURF features from two different color spaces (HSV and YCbCr). Then, we applied PCA and Fisher Vector encoding on the concatenated features. The proposed approach based on fusing the features extracted from the HSV and YCbCr was able to perform very well on three most challenging face spoofing datasets, outperforming state of the art results. More importantly, our proposed approach yielded in very interesting generalization performance in the interdatabase experiments even when only limited training data was used. As a future work, we plan to investigate other strategies for creating more robust feature spaces for spoofing detection, including person-specific adaptation of anti-spoofing models <ref type="bibr" target="#b28">[29]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. An overview of our proposed face anti-spoofing method</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I PERFORMANCE</head><label>I</label><figDesc>OF SURF VERSUS CSURF IN INTRA-DATABASE TESTS</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Replay-Attack</cell><cell>CASIA</cell><cell>MSU</cell></row><row><cell>Method</cell><cell></cell><cell>EER</cell><cell>HTER</cell><cell>EER</cell><cell>EER</cell></row><row><cell>SURF(Gray)</cell><cell></cell><cell>19.5</cell><cell>21.2</cell><cell>17.8</cell><cell>18.8</cell></row><row><cell>CSURF (RGB)</cell><cell></cell><cell>11.3</cell><cell>13.5</cell><cell>14.1</cell><cell>17.3</cell></row><row><cell>CSURF (HSV)</cell><cell></cell><cell>6.2</cell><cell>11.5</cell><cell>7.1</cell><cell>7.0</cell></row><row><cell>CSURF (YCbCr)</cell><cell></cell><cell>5.2</cell><cell>8.9</cell><cell>7.8</cell><cell>9.2</cell></row><row><cell cols="2">CSURF (HSV+YCbCr)</cell><cell>3.3</cell><cell>8.2</cell><cell>5.7</cell><cell>7.1</cell></row><row><cell></cell><cell></cell><cell cols="2">TABLE II</cell><cell></cell></row><row><cell cols="6">PERFORMANCE OF SURF VERSUS CSURF IN INTER-DATABASE TESTS</cell></row><row><cell>Train on: Test on:</cell><cell cols="4">CASIA Replay MSU CASIA MSU CASIA Replay Replay MSU</cell><cell>Average</cell></row><row><cell>SURF</cell><cell cols="4">52.3 35.1 52.6 43.8 43.1 48.2</cell><cell>45.8</cell></row><row><cell>CSURF(RGB)</cell><cell cols="4">50.7 32.2 49.4 44.1 44.6 47.8</cell><cell>44,8</cell></row><row><cell>CSURF(HSV)</cell><cell cols="4">50.5 26.1 44.5 44.3 38.9 54.6</cell><cell>43.1</cell></row><row><cell>CSURF(YCbCr)</cell><cell cols="4">40.0 26.2 36.9 31.8 31.7 53.8</cell><cell>36.7</cell></row><row><cell cols="5">CSURF(HSV+YCbCr) 37.9 20.5 36.2 33.0 34.8 50.6</cell><cell>35.5</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Understanding OSN-based facial disclosure against face authentication systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th ACM Symposium on Information, Computer and Communications Security, ser. ASIA CCS &apos;14</title>
		<meeting>the 9th ACM Symposium on Information, Computer and Communications Security, ser. ASIA CCS &apos;14</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="413" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Face anti-spoofing: visual approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Anjos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Komulainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Marcel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hadid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of biometric anti-spoofing</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Marcel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Nixon</surname></persName>
		</editor>
		<editor>
			<persName><surname>Li</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="65" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Biometric antispoofing methods: A survey in face recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Galbally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Marcel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fiérrez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1530" to="1552" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Counter-measures to photo attacks in face recognition: a public database and a baseline</title>
		<author>
			<persName><forename type="first">A</forename><surname>Anjos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Marcel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IAPR IEEE International Joint Conference on Biometrics (IJCB)</title>
		<meeting>IAPR IEEE International Joint Conference on Biometrics (IJCB)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Face liveness detection using dynamic texture</title>
		<author>
			<persName><forename type="first">T</forename><surname>De Freitas Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Komulainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anjos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>De Martino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hadid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Marcel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP Journal on Image and Video Processing</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Computationally efficient face spoofing detection with motion magnification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bharadwaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">I</forename><surname>Dhamecha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vatsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Richa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Detection of face spoofing using visual dynamics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tirunagari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Poh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Windridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Iorliam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Suki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T S</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="762" to="777" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Context based face antispoofing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Komulainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hadid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Biometrics: Theory, Applications and Systems (BTAS 2013)</title>
		<meeting>International Conference on Biometrics: Theory, Applications and Systems (BTAS 2013)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Face spoofing from single images using micro-texture analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Määttä</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hadid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Joint Conference on Biometrics (IJCB)</title>
		<meeting>International Joint Conference on Biometrics (IJCB)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Face liveness detection with component dependent descriptor</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IAPR International Conference on Biometrics</title>
		<imprint>
			<date type="published" when="2013-06">June 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Face anti-spoofing based on general image quality assessment</title>
		<author>
			<persName><forename type="first">J</forename><surname>Galbally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Marcel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IAPR/IEEE Int. Conf. on Pattern Recognition, ICPR</title>
		<meeting>IAPR/IEEE Int. Conf. on Pattern Recognition, ICPR</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1173" to="1178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Face spoof detection with image distortion analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="746" to="761" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Can face anti-spoofing countermeasures work in a real world scenario</title>
		<author>
			<persName><forename type="first">T</forename><surname>De Freitas Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anjos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">De</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Marcel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Biometrics (ICB)</title>
		<imprint>
			<date type="published" when="2013-06">June 2013</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learn convolutional neural network for face anti-spoofing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<idno>abs/1408.5601</idno>
		<ptr target="http://arxiv.org/abs/1408.5601" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Face anti-spoofing based on color texture analysis</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Boulkenafet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Komulainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hadid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A face antispoofing database with diverse attacks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th IAPR International Conference on Biometrics</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="26" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the effectiveness of local binary patterns in face anti-spoofing</title>
		<author>
			<persName><forename type="first">I</forename><surname>Chingovska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anjos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Marcel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of the Biometrics Special Interest Group (BIOSIG)</title>
		<imprint>
			<date type="published" when="2012-09">Sept 2012</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multiresolution grayscale and rotation invariant texture classification with local binary patterns</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mäenpaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<date type="published" when="2002-07">Jul 2002</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="971" to="987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improving the fisher kernel for large-scale image classification</title>
		<author>
			<persName><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2010</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="143" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gool</surname></persName>
		</author>
		<idno type="DOI">10.1007/11744023_32</idno>
		<ptr target="http://dx.doi.org/10.1007/1174402332" />
		<title level="m">Computer Vision -ECCV 2006: 9th European Conference on Computer Vision</title>
		<meeting><address><addrLine>Graz, Austria; Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">May 7-13, 2006. 2006</date>
			<biblScope unit="page" from="404" to="417" />
		</imprint>
	</monogr>
	<note>SURF: Speeded Up Robust Features</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Face spoofing detection using colour texture analysis</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Boulkenafet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Komulainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hadid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1818" to="1830" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Principal component analysis</title>
		<author>
			<persName><forename type="first">I</forename><surname>Jolliffe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fisher Vector Faces in the Wild</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">M</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">High-dimensional signature compression for large-scale image classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1665" to="1672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The devil is in the details: an evaluation of recent feature encoding methods</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Ken Chatfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference</title>
		<meeting>the British Machine Vision Conference</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="76" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-15561-1_11</idno>
		<ptr target="http://dx.doi.org/10.1007/978-3-642-15561-111" />
		<title level="m">Computer Vision -ECCV 2010: 11th European Conference on Computer Vision</title>
		<meeting><address><addrLine>Heraklion, Crete, Greece; Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">September 5-11, 2010. 2010</date>
			<biblScope unit="page" from="143" to="156" />
		</imprint>
	</monogr>
	<note>ch. Improving the Fisher Kernel for Large-Scale Image Classification</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Pattern recognition</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">128</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Person-specific face anti-spoofing with subject domain adaptation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
