<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Fast Clustering Algorithm based on pruning unnecessary distance computations in DBSCAN for High-Dimensional Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-06-04">June 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yewang</forename><surname>Chen</surname></persName>
							<email>ywchen@hqu.edu.cn</email>
							<affiliation key="aff2">
								<address>
									<addrLine>1515 St.Catherine Street West</addrLine>
									<postBox>EV.007.632</postBox>
									<postCode>H3G 2W1</postCode>
									<settlement>Montreal</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shenyu</forename><surname>Tang</surname></persName>
							<email>shengyutang@hqu.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Nizar</forename><surname>Bouguila</surname></persName>
							<email>nizar.bouguila@concordia.ca</email>
							<affiliation key="aff2">
								<address>
									<addrLine>1515 St.Catherine Street West</addrLine>
									<postBox>EV.007.632</postBox>
									<postCode>H3G 2W1</postCode>
									<settlement>Montreal</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cheng</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jixiang</forename><surname>Du</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hailin</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><surname>Xiamen</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<address>
									<addrLine>Nizar Bouguila, Jixiang Du</addrLine>
									<settlement>Shenyu Tang, Cheng Wang, HaiLin Li</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">The College of Computer Science and Technology of Huaqiao University a</orgName>
								<orgName type="institution" key="instit2">Concordia Institute for Information Systems</orgName>
								<address>
									<addrLine>Engineering b a Jimei Avenue 668, Fujian province</addrLine>
									<settlement>Xiamen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">College of Computer Science</orgName>
								<orgName type="institution">Technology of Huaqiao University)</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Concordia Institute for Information Systems Engineering</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Fast Clustering Algorithm based on pruning unnecessary distance computations in DBSCAN for High-Dimensional Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-06-04">June 4, 2018</date>
						</imprint>
					</monogr>
					<idno type="MD5">A6AE74362D339577DF19D7B34D679D65</idno>
					<idno type="DOI">10.1016/j.patcog.2018.05.030</idno>
					<note type="submission">Received date: 28 April 2017 Revised date: 1 February 2018 Accepted date: 31 May 2018 Preprint submitted to Journal of L A T E X Templates</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Pattern Recognition DBSCAN</term>
					<term>ρ-Approximate DBSCAN</term>
					<term>NQ-DBSCAN</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Clustering is an important technique to deal with large scale data which are explosively created in internet. Most data are high-dimensional with a lot of noise, which brings great challenges to retrieval, classification and understanding. No current existing approach is "optimal" for large scale data. For example, DB-SCAN requires O(n 2 ) time, Fast-DBSCAN only works well in 2 dimensions, and ρ-Approximate DBSCAN runs in O(n) expected time which needs dimension D to be a relative small constant for the linear running time to hold. However, we prove theoretically and experimentally that ρ-Approximate DBSCAN degenerates to an O(n 2 ) algorithm in very high dimension such that 2 D &gt;&gt; n. In this paper, we propose a novel local neighborhood searching technique, and apply it to improve DBSCAN, named as NQ-DBSCAN, such that a large number of unnecessary distance computations can be effectively reduced. Theoretical analysis and experimental results show that NQ-DBSCAN averagely runs in O(n * log(n)) with the help of indexing technique, and the best case is O(n) if</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>A Fast Clustering Algorithm based on pruning unnecessary distance computations in DBSCAN for High-Dimensional Data</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Nowadays, large collections of data are explosively created in different fields, and most of these data are high dimensional with a lot of noise, e.g Web Texts and Web videos, some of them have more than 10,000 dimensions, which brings great challenges to retrieval, classification and understanding. Many researches are launched in this area to deal with this kind of data <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b5">5,</ref><ref type="bibr" target="#b6">6,</ref><ref type="bibr" target="#b7">7,</ref><ref type="bibr" target="#b8">8,</ref><ref type="bibr" target="#b9">9,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr" target="#b11">11,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b13">13]</ref>.</p><p>Data clustering is one of the most important and popular data analysis techniques to understand data. It refers to the process of grouping objects into meaningful subclasses (clusters) so that members of a cluster are as similar as 10 possible whereas members of different clusters differ as much as possible <ref type="bibr">[14,</ref><ref type="bibr">15,</ref><ref type="bibr" target="#b14">16]</ref>. Numerous clustering algorithms have been used in many areas such as image processing <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b16">18,</ref><ref type="bibr" target="#b17">19]</ref>, geophysics <ref type="bibr" target="#b18">[20,</ref><ref type="bibr" target="#b19">21]</ref>, customer and marketing analysis <ref type="bibr" target="#b20">[22,</ref><ref type="bibr" target="#b21">23]</ref>, crime detection <ref type="bibr" target="#b22">[24]</ref>, medicine <ref type="bibr" target="#b23">[25,</ref><ref type="bibr" target="#b24">26]</ref> and agriculture <ref type="bibr" target="#b25">[27]</ref>. Innovative clustering methods <ref type="bibr" target="#b26">[28,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b28">30]</ref> and parallel implementation frameworks <ref type="bibr" target="#b29">[31,</ref><ref type="bibr" target="#b30">32]</ref> have been proposed.</p><p>Clustering algorithms can be roughly categorized into partition, hierarchical, grid-based and density-based approaches etc. Density-based clustering approach is one of the most popular paradigms, and the most famous algorithm of this kind is DBSCAN <ref type="bibr" target="#b31">[33]</ref> which is designed to discover clusters of arbitrary shape 20 with a fixed scanning radius (eps) and a density threshold M inP ts. DBSCAN has a large amount of extensions, e.g. <ref type="bibr" target="#b32">[34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37]</ref>, and has been widely applied in many applications, such as astronomy <ref type="bibr" target="#b37">[38]</ref>, neuroscience <ref type="bibr" target="#b38">[39]</ref>. However, DBSCAN has some drawbacks as follows.</p><p>(1) It renders almost useless when subject to high-dimensional data due to the so-called "Curse of dimensionality".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p><p>(2) The running time for DBSCAN is heavily dominated by finding neighbors or obtaining density for each data point. Without indexing, the complexity of DBSCAN would always be O(n 2 ) regardless of the parameters and MinPts.</p><p>If a tree-based spatial index is used, the -neighborhood are expected to be 30 small compared to the size of the whole data space, the average complexity is reduced to O(n * log(n)) <ref type="bibr" target="#b31">[33]</ref>. However, for dimension d &gt; 3 the DBSCAN problem require Ω(N 4/3 ) time to solve, unless very significant breakthroughs could made in theoretical computer science <ref type="bibr" target="#b39">[40]</ref>.</p><p>Many researchers have proposed various techniques in attempts to improve the performance of clustering algorithm on high-dimensional data. For example,</p><p>Wang and Deng developed a serial of important work on soft subspace clustering and fuzzy clustering for high dimensional data <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44]</ref>, which overcome the drawbacks of utilizing only one distance function in most of existing clustering algorithms, and adaptively learn the distance functions suitable for data 40 sets during the clustering process.</p><p>Grid-based technique and approximation techniques are also popular, such as Fast-DBSCAN <ref type="bibr" target="#b44">[45]</ref> and others <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b46">47]</ref>. Grid-based techniques, e.g. <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51]</ref>, divide the data space by grids, perform clustering in each cell locally and merge the results thereby saving runtime. Gunawan <ref type="bibr" target="#b44">[45]</ref> proposed a Fast-DBSCAN based on drawing a 2-dimensional grid. The algorithm imposes an arbitrary grid T on the data space R 2 , where each cell of T has side length /2. If a non-empty cell c contains at least M inP ts points, then all those points in the cell must be core points, because the maximum distance within the cell is . This algorithm theoretically runs in O(n * log(n)) time in the worst 50 case. However it is only applied in 2-dimensional data space.</p><p>Inspired by Fast-DBSCAN, Gan and Tao <ref type="bibr" target="#b39">[40]</ref> proposed a novel algorithm named ρ-approximate DBSCAN, which has a computation time that scales only linearly in n. The improvement of this method from Gunawan <ref type="bibr" target="#b44">[45]</ref> lies in its new tree structure, i.e. quadtree-like hierarchical grid, as well as the sacrifice of small accuracy. Because the cell number in the quadtree-like hierarchical grid T will increase explosively with dimension D, therefore ρ-approximate only saves</p><formula xml:id="formula_0">A C C E P T E D M A N U S C R I P T</formula><p>those non-empty cells. However, it needs dimension D to be a relative small constant for the linear running time to hold, and actually it still runs in O(n 2 ) in high dimension, as the following theorem shows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>60</head><p>Theorem 1. ρ-approximate DBSCAN degenerates to an O(n 2 ) algorithm if</p><formula xml:id="formula_1">2 D n.</formula><p>Proof. Let X be the maximum radius for DBSCAN to correctly cluster data set P , and dimension D be large enough such that 2 D n, which implies there are much more cells than n in the grid. Set = X, for each cell there is at most one point contained if D is large enough, because the side length of each cell is Therefore, most existing current clustering algorithms are not suitable for many realtime applications, due to the "curse of dimensionality". The main reason lies in great number of unnecessary distance calculations, which can be greatly reduced by neighbor searching technique, such as Product quantization for nearest neighbor search <ref type="bibr" target="#b51">[52]</ref>, LSH (Locality-Sensitive Hashing) <ref type="bibr" target="#b53">[53]</ref>, FLANN <ref type="bibr" target="#b54">[54]</ref>.</p><p>In this paper, we propose a new clustering approach, named NQ-DBSCAN, (3) NQ-DBSCAN is suitable for clustering data with a lot of noise.</p><p>The rest of this paper is organized as follow: Section 2 introduces the basic concepts; Section 3 presents the details of the proposed clustering algorithm; 100 Section 4 demonstrates the experimental results of the proposed algorithms on various data sets, and Section 5 gives the conclusion and our future works. where is scanning radius and MinPts is the minimal number of neighbor points for a core point. Some concepts and terms to explain the DBSCAN algorithm 110 can be defined as follows <ref type="bibr" target="#b31">[33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The Basic Concepts of DBSCAN and Preliminary Notation</head><p>Definition 1. The -neighborhood of a point p, denoted by N (p), is defined by N (p)={q|q ∈ P, d p,q ≤ }, where P is a set of points and d p,q is a distance 1. ∀ p, q: if p ∈ C and q is dendity-reachable from p with respect to and M inP ts, then q ∈ C (Maximality).</p><formula xml:id="formula_2">A C C E P T E D M A N U S C</formula><p>2. ∀ p, q ∈ C: p is density-connected to q with respect to and M inP ts We propose a new algorithm to improve DBSCAN by filtering a large number of unnecessary density computations, which is based on the following idea.</p><p>Point p and point q should have similar neighbors, provided p and q are close; given a certain , the closer they are, the more similar their neighbors are.</p><p>As Fig. <ref type="figure" target="#fig_2">1</ref> shows, we can see that points p and q in Fig. <ref type="figure" target="#fig_2">1</ref> (a) have more same neighbors than that they have in Fig. <ref type="figure" target="#fig_4">1 (b)</ref>. Formally, we have some theorems which are important for validating the correctness of our clustering algorithm, as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>Algorithm 2 ExpandCluster(p,neighborPts,C, ,MinPts) <ref type="bibr" target="#b44">[45]</ref> Input:</p><p>p: current search point;</p><p>neighborP ts: density-reachable points from p; C: current cluster id;</p><p>: the maximum distance;</p><p>MinPts: the minimum points to form a cluster;</p><p>Output:</p><p>drP ts (density-reachable points from p);</p><p>1: drP ts ← neighborP ts 2: for each point q ∈ drP ts do</p><formula xml:id="formula_3">3: if q is unclassified then 4: N (p)=RangeQuery(p, ) 5: if |N (p)| ≥ M inP ts then 6: drPts=drPts∪ N (p) 7: end if 8: end if 9:</formula><p>if q does not belong to any cluster then  </p><formula xml:id="formula_4">d p,a &lt; d p,b &lt; d p,c &lt; d p,d , then p (1) = a, p (2) = b, p (3) = c, p (4) = d. Theorem 2. (1) If d p,(M inP ts) ≤ , then p is a core point. (2) p is a non-core point if d p,(i) &gt; , where 1 ≤ i ≤ M inP ts. Proof. (1) ∵ d p,(M inP ts) ≤ , which means d p,(1) ≤ d p,(2) ≤ ... ≤ d p,(M inP ts) ≤ , ∴ |N (p)| ≥ M inP ts, thus p is a core point. (2) ∵ 1 ≤ i ≤ M inP ts and d p,(i) &gt; , ∴ &lt; d p,(i) ≤ d p,(M inP ts) , thus |N (p)| &lt; M inP ts, i.e p is a non-core point. 170 Theorem 3. Let p ∈ P , if |N 2 (p)| &lt; M inP ts, then ∀q ∈ N (p) is non-core point. Proof. ∵ N (q) ⊆ N 2 (p) and |N 2 (p)| &lt; M inP ts, ∴ we have |N (q)| &lt; |N 2 (p)| &lt; M inP ts, then ∀q ∈ N (p) is non-core point.</formula><p>This theorem tells us a fact that if |N 2 (p)| &lt; M inP ts, then all points within the -neighborhood of p are non-core points.</p><p>Theorem 4. Let p ∈ P , and</p><formula xml:id="formula_5">d p,(M inP ts) =l, if l &gt; then ∀ o ∈ O, o is a non-core point, where O = {o|d o,p &lt; l -}. Proof. ∵ d p,(M inP ts) = l ∴ | N l (p) |= M inP ts. ∵ d o,p &lt; l -∴ d o,p + &lt; l then N (o) ⊂ N l (p), thus we have |N (o)| &lt; |N l (p)| = M inP ts. ∴ ∀o ∈ O is 180 non-core point.</formula><p>As Fig. <ref type="figure" target="#fig_5">2</ref> shows, l &gt; , the total number of points within the outer black circle is less than M inP ts, and d o,p &lt; l -, according to Theorem 4, all points in N l-(p) are non-core points, as the red points within red circle show. Proof. ∵ d p,m &lt; -d p,q , ∴ d p,q +d p,m &lt; , then according to Triangle Inequality,</p><formula xml:id="formula_6">Theorem 5. Let p, q, m ∈ P . If d p,m &lt; -d p,q , then m ∈ N (q). A C C E P T E D M A N U S C R I P T p o l -ε ε l ε</formula><formula xml:id="formula_7">we have d q,m &lt; d p,q + d p,m , thus d q,m &lt; , therefore m ∈ N (q).</formula><p>In Fig. <ref type="figure" target="#fig_7">3</ref>, ∀ m 1 contained in blue circle, m 1 satisfies d p,m1 &lt;d p,q , according to Theorem 5, m 1 ∈ N (q). Thus blue points are all contained in</p><formula xml:id="formula_8">N (q). 190 Theorem 6. Let p, q, m ∈ P , if d p,m &gt; + d p,q , then m / ∈ N (q) . Proof. ∵ d p,m &gt; + d p,q , ∴ d p,m -d p,q &gt; . Then according to Triangle Inequality, we have d q,m &gt;d p,m -d p,q , thus d q,m &gt; . ∴ point m / ∈ N (q).</formula><p>In Fig. <ref type="figure" target="#fig_7">3</ref>, ∀ m 2 outside the red circle, we have d p,m2 &gt; + d p,q , according to Theorem 6, m 2 / ∈ N (q). Thus the black points are all not included in N (q). Theorem 7. Let p, q ∈ P , and N 2 (p) is already obtained, in order to get N (q), the searching range is p (L) , p (L+1) , ..., p (U -1) , p (U ) , where L, U satisfy</p><formula xml:id="formula_9">d p,p (L-1) &lt; -d p,q &lt; d p,p (L) and d p,p (U ) &lt; + d p,q &lt; d p,p (U +1) .</formula><p>Proof. ∵ d p,p (L-1) &lt;d p,q , then according to Theorem 5, p (1) , p (2) , ..., p (L-1)</p><p>are contained in N (q). ∵ + d p,q &lt; d p,p (U +1) , and then according to Theorem 6,  </p><p>(blue points) are in N (q), and black points are all outside the -neighborhood of q, only red points are uncertain.</p><p>we have p (U +1) , p (U +2) , ..., p (N ) are not contained in N (q). ∴ p (L) , p (L+1) , ..., p (U -1) , p (U )</p><p>is the searching range for obtaining N (q).</p><p>According to Theorem 7, in Fig. <ref type="figure" target="#fig_7">3</ref> the remaining uncertain points (p (L) , ..., p (U ) ) are those red points, which locate in the annular region between blue circle and red circle.</p><p>Comprehensively, according to Theorem 5, 6 and 7, in order to obtain N (q), we only need to search those red points in the annular region. All distance computations from p to blue and black points are reduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The proposed algorithm</head><p>We MinPts: the minimum points to form a cluster;</p><p>Output: cluster id of each point; </p><formula xml:id="formula_11">A C C E P T E D M A N U S C R I P T</formula><p>In Algorithm 3 (NQ-DBSCAN), the main steps are below.</p><p>• Select an unclassified point p from P, then use RangeQuery to retrieve N 2 (p) (line 4), and sort the distances form p to its 2 -neighbors.</p><p>• According to Theorem 2, we can easily judge whether p is core point or not, as shown in line 8.</p><p>• If p is a core point, it will use ImprovedExpandCluster to find all points 220 that are density-reachable from p (drP ts), as shown in line 10. All points in drP ts will be marked as the same cluster id. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>230</head><p>• First initialize drP ts = N (p) by binary searching from distArr and pLoc.</p><p>• Second, select an unclassified point q from pLoc. If d p,q ≤ we use NeighborQuery to effectively get N (q), and if q is a core point N (q) will be added to the set drP ts. Repeat this step until all points in pLoc are handled.</p><p>• MinPts: the minimum points to form a cluster.</p><p>Output: drPts: all density-reachable neighbor points from p.</p><p>1: binary search drP ts = {o|o ∈ pLoc s.t. dp,o ≤ } 2: for each point q saved in pLoc do</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3:</head><p>if q is unclassified then</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>if dp,q ≤ then 5: N (q)=NeighborQuery (p,q,pLoc,distArr, ,MinPts) </p><formula xml:id="formula_12">6: if |N (q)| ≥ M inP</formula><formula xml:id="formula_13">A C C E P T E D M A N U S C R I P T</formula><p>Take Fig. <ref type="figure" target="#fig_7">3</ref> for example again, p is a core point, its 2 -neighbors have already been retrieved by RangeQuery. ∀q ∈ N (p), in order to retrieve N (q), NeighborQuery only checks those red points.</p><p>Algorithm 5 NeighborQuery(p,q,pLoc,distArr, ,MinPts)</p><p>Input:</p><p>p: reference point;</p><p>q: current search point;</p><p>pLoc: the points number of neighbor sequence;</p><p>distArr: the points distance of neighbor sequence;</p><p>: the maximum distance;</p><p>MinPts: the minimum points to form a cluster;</p><p>Output: N (q). Conectivity defined in Definition 7, as well as Lemma 1 and Lemma 2 in <ref type="bibr" target="#b31">[33]</ref> are also satisfied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Complexity analysis</head><p>The key processes in NQ-DBSCAN are RangeQuery and NeighborQuery, and time complexity of NQ-DBSCAN highly depends on them.</p><p>The complexity of RangeQuery can be O(log n) with the help of indexing techniques, such as R*-tree, otherwise is O(n). In this paper, we use quadtree-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T like hierarchical tree grid <ref type="bibr" target="#b39">[40]</ref>, which works well in many cases, but it still performs not good for very high dimensional data that are sparse. The complexity 260 of building this grid is O(n).</p><p>The complexity of NeighborQuery is O(log(nei)) by using binary search method, where nei is the number of p's neighbors.</p><p>Therefore, the whole time complexity of NQ-DBSCAN is</p><formula xml:id="formula_14">O(α * (log(n) + nei * log(nei)) + β * log(nei) -γ)</formula><p>, where α is execution times of RangeQuery, β is execution times of NeighborQuery, and γ is the total number of filtered points that are unnecessary to visit (including some non-core points and noise points), respectively. Obviously, α + β + γ = n, and then α + β &lt;= n.</p><p>In the case of M inP ts is very large such that γ → n, i.e. most points are identified as non-core points directly, the complexity is O(1). However, it is </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we conduct experiments to evaluate the performance of NQ-DBSCAN, and make comparisons with original DBSCAN and ρ-approximate DBSCAN <ref type="bibr" target="#b39">[40]</ref>, on synthetic and realtime data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Algorithms</head><p>Algorithms. Our experiments involve four algorithms as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>280</head><p>• DBSCAN: the original DBSCAN algorithm in <ref type="bibr" target="#b31">[33]</ref>;</p><p>• NQ-DBSCAN: the proposed algorithm without using indexing technique;</p><p>• "NQ-DBSCAN with indexing": the proposed algorithm with quadtree-like hierarchical tree grid indexing;</p><p>• Approx: the ρ-approximate DBSCAN algorithm.  DBSCAN and NQ-DBSCAN were run on a machine equipped with 3.3GHz CPU and 8 GB memory, the operating system was Windows 10 64-bit and programs were coded in MATLAB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>Approx were coded in C++, and was run on Linux (Ubuntu 14.04) operating system with the same hardware configuration. (2) Uniform Hyper-cube</p><p>We also generate a series of hyper-cubical test cases, some test cases have  20% noise, and the others are noise-free. Each test case includes 4 hypercubes, and points of each hypercube uniformly distributed. There are two hypercubes that intersect with each other. Therefore, there are 3 clusters in all test cases in fact. Two 3d visual Hyper-cubical test cases are shown in Fig. <ref type="figure" target="#fig_15">6</ref> and Fig. <ref type="figure" target="#fig_16">7</ref>, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>The details of these data sets are shown as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>310</head><p>• Spheredata 1: without noise, n=50,000, has 10 test cases with d ranging from 5 to 50.</p><p>• Spheredata 2: with noise, n=100,000, d=10.</p><p>• Spheredata 3: with noise, d=5, 10 test cases with n ranging from 20,000 to 200,000.</p><p>• Spheredata 4: with noise, d=20, 10 test cases with n ranging from 20,000 to 200,000.</p><p>• Spheredata 5: with noise, n=50,000, has 10 test cases with d ranging from 5 to 50.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>• Spheredata 6: with noise, n=100,000, has 10 test cases with d ranging 320 from 5 to 50.</p><p>• Cubedata 1: without noise, n=50,000, has 10 test cases with d ranging from 5 to 50.</p><p>• Cubedata 2: with noise, d=5, has 10 test cases with n ranging from 10,000 to 100,000.</p><p>• Cubedata 3: with noise, d=10, has 10 test cases with n ranging from 10,000 to 100,000.</p><p>• The fifth, MNIST<ref type="foot" target="#foot_2">3</ref> is a handwritten digits data set, which includes 70,000</p><formula xml:id="formula_15">A C C E P T E D M A N U S C R I P T</formula><p>images with size of 28 × 28 pixel. We pick up 10,000 images and transform each 28 × 28 image matrix into a feature vector with 28 × 28 = 784 dimensions.</p><p>Therefore, MNIST used in our experiments is a 784-dimensional data set with cardinality 10,000.</p><p>The sixth, PAM (PAMPA2), which comes from UCI, is a 4-dimensional data 350 set with cardinality 3,850,505.</p><p>The last one is MORPH <ref type="bibr" target="#b56">[56]</ref> which is the largest publicly available longitudinal face database<ref type="foot" target="#foot_3">4</ref> , includes 79,897 face photographs with size of 70 × 80 pixel. Also, we pick up 10,000 face photographs of MORPH in our experiments.</p><p>We convert the RGB images to gray images, and then transform each gray image matrix into a feature vector with 70 × 80 = 5, 600 dimensions. Therefore, MORPH used in our experiments is a 5600-dimensional data set with cardinality 10,000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Experiment 1: Two Examples</head><p>We benchmark NQ-DBSCAN on two test cases, the first one is t4.8k <ref type="bibr" target="#b57">[57]</ref>,</p><formula xml:id="formula_16">360</formula><p>which is a 2-dimensional data set with cardinality 8,000, and the other is Aggregation <ref type="bibr" target="#b58">[58]</ref>, which is a 2-dimensional data set with cardinality 788. The distribution of two data sets and the clusters obtained by NQ-DBSCAN are shown in Fig. <ref type="figure" target="#fig_18">8</ref>. It illustrates that NQ-DBSCAN has the same ability as DBSCAN to detect complex shapes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Experiment 2: Influence of Noise and Dimensionality</head><p>The purpose of this part is to check impaction of noise and dimensionality on NQ-DBSCAN and Approx.</p><p>Firstly, we conduct an experiment on Spheredata 1 and Cubedata 1 which are noise-free. As shown in Fig. <ref type="figure" target="#fig_20">9</ref> and Fig. <ref type="figure" target="#fig_21">10</ref>, we can see that in the case of        Cubedata 1, which means noise has great impaction on Approx. While NQ-DBSCAN works still stable and much better than Approx. The reason lies in noise distributes in the entire data space rather than concentrates in several 380 small space, then additional cells are needed to save noise, which badly affects the efficiency of Approx.</p><p>We also can see from these experiments, the efficiency of Approx decrease rapidly with dimension. Because with the increasing of the data dimension, each cell becomes smaller, and the number of cells rise exponentially, which finally leads to Approx degenerate to an O(n 2 ) algorithm. While, the running time of NQ-DBSCAN still increases linearly with dimension, which implies that NQ-DBSCAN is weakly affected by "curse of dimensionality".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Experiment 3: The Effect of and M inP ts</head><p>The purpose of this experiment is to check the effect of on the proposed 390 algorithm. Spheredata 2 was used in this experiment with cardinality 100,000 and the dimension is 10, MinPts was fixed to 50. Fig. <ref type="figure" target="#fig_10">14</ref> shows the performances of the 3 approaches. Clearly, both NQ-DBSCAN and Approx are quite better than DBSCAN.  . From the two figures, we can see that execution times of RangeQuery α → n and n &gt;&gt; nei in the case of is very small, β increases with . In the case of ∈ [2000, 4000], both α and nei are small, NQ-DBSCAN performs better than other cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>400</head><p>Table . 1 shows the detail of some results on a subset of Spheredata 3 with small and M inP ts. We can see that α &gt;&gt; β when = 1, 000, i.e. the execution times of RangeQuery is far larger than that of NeighborQuery, while α is greatly reduced when = 2, 000 and = 3, 000. We also notice that the running time  But its accuracy is not as good as that of = 2, 000 and = 3, 000.        algorithm (One reason that the proposed algorithm runs slower in ReactionNetwork is the code efficiency in Matlab is not as good as C++).</p><formula xml:id="formula_17">A C C E P T E D M A N U S C R I P T</formula><formula xml:id="formula_18">A C C E P T E D M A N U S C R I P T</formula><p>While the comparisons in Fig. <ref type="figure" target="#fig_38">23</ref> and Fig. <ref type="figure" target="#fig_40">24</ref> present that Approx runs in O(n 2 ), which is clearly inferior to "NQ-DBSCAN with indexing" on BlogFeedback (59-dim) and KDD04 (76 dim), respectively.</p><p>Clearly, we can see that the higher the dimension, the more advantages the proposed algorithm to Approx, and the four figures above prove that "NQ-DBSCAN with indexing" runs in O(n * log(n)).          </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8.">The robust of algorithm</head><p>According to Huber <ref type="bibr" target="#b60">[60]</ref>, a robust procedure can be characterized by the following: 1) it should have a reasonably good efficiency (accuracy) at the as-460 sumed model; 2) small deviations from the model assumptions should impair the performance only by a small amount; and 3) larger deviations from the model assumptions should not cause a catastrophe.</p><p>In order to test the accuracy of the proposed algorithm and ρ-approximate DBSCAN, we conduct some experiments based on an assumption that the clustering labels obtained by DBSCAN is the standard correct result, and evaluate the precision of two approaches as following, which is also used in our previous works <ref type="bibr" target="#b61">[61,</ref><ref type="bibr" target="#b62">62]</ref>. As we know, the clustering results got by a clustering algorithm may have different labels from that got by the other algorithm, e.g. cluster 'A1' obtained by one approach may be the same as cluster 'B2' of the other. Therefore, we have to match labels first, then use the matched labels to calculate Precision.</p><p>In our experiments, we use Kuhn-Munkras <ref type="bibr" target="#b63">[63]</ref> to maximum match two cluster   In the case of data sets having a lot of noise, NQ-DBSCAN works much better, because noise has side effects on Approx. The underlying cause is that noise always distributes in the whole data space rather than concentrates in some small regions, which results in many cells are needed to save noise, and then In addition, NQ-DBSCAN is an exact algorithm, which is also an important advantage to the approximate algorithm ρ-Approximate DBSCAN.</p><formula xml:id="formula_19">A C C E P T E D M A N U S C R I P T</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>Today, large collections of data are explosively created in different fields, and most of these data are high dimensional with a lot of noise, which bring great challenging to clustering. DBSCAN is a creative and elegant technique for density-based clustering. However, it is rendered almost useless for high-520 dimensional data, due to the "curse of dimensionality", which limits its applicability in many realtime applications. ρ-approximate DBSCAN <ref type="bibr" target="#b39">[40]</ref> is an efficient approach designed to replace DBSCAN for big data. By using quadtree-like hierarchical grid and small sacrifice in accuracy, ρ-approximate has a computational time that scales only linearly in n. However, it declines to an O(n 2 ) algorithm in high dimension because the grid technique is also useless in high dimension.</p><p>Also, we find the efficiency of ρ-approximate is greatly reduced when dealing with high dimensional data that has much noise, because the grid technique is useless in high dimension and noise needs additional cells to save.</p><p>In this paper, we propose a clustering algorithm, named NQ-DBSCAN which 530 may return the exact result as DBSCAN, to improve DBSCAN, by using neighbor searching technique and indexing technique to filter great number of unnecessary density computations. The underlying idea is: point p and point q should have similar neighbors, provided p and q are close to each other; given a certain , the closer they are, the more similar their neighbors are.</p><p>Our experiments have shown that the proposed method outperforms ρapproximate in high dimension, also it performs better in data sets with a lot of noise. Although, the worse complexity of NQ-DBSCAN is still O(n 2 ), but its average complexity is about O(n * log(n)) with the help of indexing technique, and the best case is O(n) if proper parameters ( and M inP ts) are used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>540</head><p>The indexing technique we used is quadtree-like hierarchical tree grid, but it fails to work in some sparse and very high-dimensional data. Therefore, in future work, we will try to improve quadtree-like hierarchical tree grid, by combining the merits of other techniques, such as product quantization for nearest neighbor search <ref type="bibr" target="#b51">[52]</ref>, LSH (Locality-Sensitive Hashing) <ref type="bibr" target="#b53">[53]</ref>, FLANN <ref type="bibr" target="#b54">[54]</ref> etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>In the case of 2 D n, ρ-approximate DBSCAN answers any approximate range count query in O(1) expected time (see Lemma 5 in [40]). But here, since each non-empty cell contains at most one point, then there are about n 70 nonempty cells are saved. Thus the query time for each cell to find neighbors is O(n), not O(1) any more, and hence ρ-approximate DBSCAN runs in O(n 2 ) expected time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>80( 1 )( 2 )</head><label>12</label><figDesc>by using local neighbor query technique and quadtree-like hierarchical grid to reduce great number of unnecessary distance computations. Theoretical analysis and experimental results show that the proposed algorithm NQ-DBSCAN can averagely run in O(n * log(n)) expected time with the help of indexing technique, and the best case is O(n) if proper parameters are used, which makes it suitable for many realtime data. A C C E P T E D M A N U S C R I P T Because ρ-Approximate DBSCAN is the most important improvement of DBSCAN currently, we only focus on DBSCAN, ρ-Approximate DBSCAN and NQ-DBSCAN in this paper. There are some advantages of NQ-DBSCAN to ρ-Approximate DBSCAN as below. 90 NQ-DBSCAN is an exact algorithm that may return the same result as DBSCAN if the parameters are same. While ρ-Approximate DBSCAN is an approximate algorithm. The best complexity of NQ-DBSCAN can be O(n), and the average complexity of NQ-DBSCAN is proved to be O(nlog(n)) provided the parameters are properly chosen. While ρ-Approximate DBSCAN runs only in O(n 2 ) in high dimension.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>2. 1 .</head><label>1</label><figDesc>Basic Concepts Density-based clustering algorithms have the ability to find out the clusters of different shapes and sizes. DBSCAN, a pioneer density-based clustering algorithms, is one of the most important and popular clustering algorithms in scientific literature 1 . DBSCAN accepts two parameters: (Eps) and MinPts,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: p and q in (a) have more same neighbors than that case in (b), because p and q in (a) are closer.</figDesc><graphic coords="9,168.16,509.60,233.95,97.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: p is a non-core point, according to Theorem 4, all points in N l-(p) are non-core points, as the red points show.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Illustration of Theorem 5, Theorem 6 and Theorem 7. All points in N -dp,q (p)</figDesc><graphic coords="12,183.26,151.66,200.23,193.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>introduce a new clustering algorithm named NQ-DBSCAN based on the 210 theorems mentioned above. Algorithm 3 shows the main procedures of NQ-DBSCAN. Algorithm 4 illustrates the detail of our improved ExpandCluster which retrieves all density-reachable neighbors from a core point, and Algorithm 5 presents the implementation of Theorem 7. A C C E P T E D M A N U S C R I P T Algorithm 3 NQ-DBSCAN (P, ,MinPts) Input: P : a set of unclassified points; : the maximum distance;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Third, select a new unclassified point p ∈ drP ts. If p is a core point then use RangeQuery again to update N 2 (p), pLoc and distArr, and then repeat the second step, until all points in drP ts are visited. Algorithm 5 (NeighborQuery) is the implementation of Theorem 7, it uses binary search algorithm to obtain N (q) in N 2 (p) rather than the whole data 240 set, as shown in Line 2 -Line 5. A C C E P T E D M A N U S C R I P T Algorithm 4 ImprovedExpandCluster (p, pLoc, distArr, , MinPts) Input: p: reference point; pLoc: saves all points in N 2 (p) such that d p,pLoc(i) ≤ d p,pLoc(i+1) ; distArr: the sorted distances from p to N 2 (p); : the maximum distance;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>1 : 4 :</head><label>14</label><figDesc>// determine L and U according to Theorem 5, 6 and 7 2: binary search index L such that distArr(L) &gt; dp,q -3: binary search index U such that distArr(U ) &lt; dp,q + possibleN eighbor = pLoc(L : U )5: N (q)= pLoc(1 : L) {o|o ∈ possibleN eighbor s.t. dq,o &lt; }3.3. Correctness analysisAs shown in Algorithm 4 and 5, based on Theorems 5, 6 and 7 we can see that if p is a core point Algorithm 4 only retrieve all density-reachable points from p, which is equivalent to Algorithm 2.Similarly, based on Theorem 2, 3 and 4, as well as Algorithm 4, NQ-DBSCAN (Algorithm 3) is also guaranteed to be equivalent to DBSCAN (Al-250 gorithm 1). Thus NQ-DBSCAN meets the requirement of M aximality and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>270meaningless.</head><label></label><figDesc>The best complexity is O(n), in the case of both α and nei are small, while β → n. Generally, the average complexity of NQ-DBSCAN is about O(n * log(n)) if and M inP ts are properly chosen. Of course, without indexing technique, the average complexity is also O(n 2 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: An example of test case which has 4 hyper-spherical data without noise.</figDesc><graphic coords="18,128.16,151.24,150.34,112.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: An example of test case which has 4 hyper-spherical data with noise.</figDesc><graphic coords="18,291.75,151.24,150.34,112.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>290 4 . 2 .</head><label>42</label><figDesc>Data setsWe use two kinds of data sets in our experiments, one is synthetic data and the other is realtime data. All data are normalized such that their domain is [0, 10 5 ] for each dimension. Synthetic Data sets. Two types of synthetic data sets are used in our experiments as below. (1) Gaussian Hyper-sphere We generate a series of Gaussian hyper-spherical test cases, some test cases have 20% noise, and the others are noise-free. Each test case includes 4 clusters, and points of each cluster follows Gaussian distribution with quite different mean 300 from the other clusters. Two 3d visual Gaussian Hyper-spherical test cases are shown in Fig. 4 and Fig. 5, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: An example of test case which has 4 hyper-cubical data without noise (3 clusters).</figDesc><graphic coords="19,128.16,163.49,150.46,112.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: An example of 4 hyper-cubical data with noise (3 clusters).</figDesc><graphic coords="19,291.75,151.24,150.59,125.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>370 dimension is less than 50 ,</head><label>50</label><figDesc>Approx and NQ-DBSCAN performs similarly on both test cases, and the running time increase linearly with dimension.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Two clustering examples of NQ-DBSCAN and DBSCAN on Aggregation and t4.8k.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: The performance of two approaches on Spheredata 1 with n=50,000.(MinPts = 100 and =10,000)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: The performance of two approaches on Cubedata 1 with n=50,000.(MinPts = 100 and =2000)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Running time vs. dimension on Spheredata 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Running time vs. dimension on Spheredata 6.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Fig. 15</head><label>15</label><figDesc>Fig. 15 presents the execution times of RangeQuery and NeighborQuery, and Fig. 16 plots the average neighbors found in RangeQuery increasing with</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 13 :Figure 15 :Figure 16 :</head><label>131516</label><figDesc>Figure 13: Running time vs. dimension on Cubedata 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Figure 17 :</head><label>17</label><figDesc>Figure 17: Running time vs. cardinality on Spheredata 3 (5 dim, =2,000 and MinPts=100).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>Figure 18 :</head><label>18</label><figDesc>Figure 18: Running time vs. cardinality n on Cubedata 2 (5 dim, =2000 and MinPts=100).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Figure 19 :</head><label>19</label><figDesc>Figure 19: Running time vs. cardinality n on Cubedata 3 (10 dim, =2000 and MinPts=100).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_33"><head>Figure 20 :</head><label>20</label><figDesc>Figure 20: Running time vs. cardinality on Spheredata 4. (20 dim, =2,000 and MinPts=100)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_35"><head>Figure 21 :</head><label>21</label><figDesc>Figure 21: Running time VS Cardinality on HouseHold (7 dim) with = 1, 000 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_37"><head>Figure 22 :</head><label>22</label><figDesc>Figure 22: Running time VS Cardinality on ReactionNetwork (28 dim) with = 1, 000 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_38"><head>Figure 23 :</head><label>23</label><figDesc>Figure 23: Running time VS Cardinality on BlogFeedback (59 dim) with = 1, 000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_40"><head>Figure 24 :</head><label>24</label><figDesc>Figure 24: Running time VS Cardinality on KDD04 (76 dim) with = 1, 000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_41"><head>Figure 25 :</head><label>25</label><figDesc>Figure 25: The performance of two approaches on MNIST (784 dim).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_43"><head>Figure 26 :</head><label>26</label><figDesc>Figure 26: The performance of two approaches on MORPH (5,600 dim).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_44"><head>Firstly, we</head><label></label><figDesc>use the original DBSCAN to cluster a data set, and return cluster labels L1 = {A 1 , A 2 , ..., A k }. Secondly, run NQ-DBSCAN and ρ-approximate 470 DBSCAN on the same data set, and obtain L2 = {B 1 , B 2 , ..., B m } and L3 = {C 1 , C 2 , ..., C p }, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_45"><head></head><label></label><figDesc>) algorithm. While "NQ-DBSCAN with indexing" averagely runs in O(n) or O(n * log(n)) in many cases. In very large high dimension NQ-DBSCAN still outperforms Approx without indexing technique. The reason lies in the grid techniques used in Approx is useless in high dimension, while the neighbor searching technique used in NQ-DBSCAN is almost not affected by the dimensionality.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_46"><head>510</head><label></label><figDesc>leads to the efficiency of ρ-approximate rapidly decline. Due to the capability of effectively finding non-core points (Theorem 3 and 4), NQ-DBSCAN can run in O(n) expected time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Definition 5. A point p is density-reachable from a point q with respect to 120 and M inP ts if there is a chain of points p 1 ,p 2 ,...,p n , with p 1 = q and p n = p such that p i+1 is directly density-reachable from p i .</figDesc><table><row><cell>function e.g. Euclidian distance, between p and q.</cell></row><row><cell>Definition 2. A point p is a core point if | N (p) |≥ M inP ts.</cell></row><row><cell>Definition 3. A point p is directly density-reachable from a point q with</cell></row><row><cell>respect to and M inP ts if p ∈ N (q) and q is a core point. Definition 4. A point p is a border point if p is directly density-reachable R I P T from a core point q and | N (p) |&lt; MinPts.</cell></row><row><cell>Definition 6. A point p is density-connected to a point q with respect to</cell></row><row><cell>and M inP ts if there is a point o such that both p and q are density-reachable</cell></row><row><cell>from o.</cell></row><row><cell>Definition 7. Let p be a set of points. A cluster C with respect to and</cell></row><row><cell>M inP ts is a non-empty subset of p satisfying the following conditions:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 1 :</head><label>1</label><figDesc>The performances of NQ-DBSCAN on a sub set of Spheredata 3 with different and M inP ts (d=5, n=20,000).</figDesc><table><row><cell></cell><cell></cell><cell>running</cell><cell>range</cell><cell>nei</cell><cell>filtered</cell></row><row><cell></cell><cell>M inP ts</cell><cell>time</cell><cell>query</cell><cell>query</cell><cell>points</cell></row><row><cell></cell><cell></cell><cell>(seconds)</cell><cell>(α)</cell><cell>(β)</cell><cell>(γ)</cell></row><row><cell></cell><cell>10</cell><cell>7.68</cell><cell cols="2">16659 2877</cell><cell>464</cell></row><row><cell>1000</cell><cell>30 50</cell><cell>7.06 6.70</cell><cell>17506 16099</cell><cell>0 0</cell><cell>2494 3901</cell></row><row><cell></cell><cell>100</cell><cell>5.87</cell><cell>14868</cell><cell>0</cell><cell>5132</cell></row><row><cell></cell><cell>10</cell><cell>9.69</cell><cell cols="2">6843 13152</cell><cell>5</cell></row><row><cell>2000</cell><cell>30 50</cell><cell>9.40 9.57</cell><cell cols="2">6810 13173 6811 13162</cell><cell>17 27</cell></row><row><cell></cell><cell>100</cell><cell>9.17</cell><cell cols="2">6815 13145</cell><cell>40</cell></row><row><cell></cell><cell>10</cell><cell>11.57</cell><cell cols="2">4850 15128</cell><cell>22</cell></row><row><cell>3000</cell><cell>30 50</cell><cell>11.15 11.01</cell><cell cols="2">4850 15128 4850 15128</cell><cell>22 22</cell></row><row><cell></cell><cell>100</cell><cell>11.08</cell><cell cols="2">4850 15128</cell><cell>22</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 2 :</head><label>2</label><figDesc>The performances of NQ-DBSCAN on a sub set of Spheredata 3 with large M inP ts</figDesc><table><row><cell>(d=5, n=20,000).</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>running</cell><cell>range</cell><cell>nei</cell><cell>filtered</cell></row><row><cell></cell><cell>M inP ts</cell><cell>time</cell><cell>query</cell><cell>query</cell><cell>points</cell></row><row><cell></cell><cell></cell><cell>(seconds)</cell><cell>(α)</cell><cell>(β)</cell><cell>(γ)</cell></row><row><cell></cell><cell>200</cell><cell>6.88</cell><cell>14299</cell><cell>649</cell><cell>5052</cell></row><row><cell></cell><cell>1000</cell><cell>2.87</cell><cell>6833</cell><cell>0</cell><cell>13167</cell></row><row><cell>2000</cell><cell>3000</cell><cell>2.73</cell><cell>6718</cell><cell>0</cell><cell>13282</cell></row><row><cell></cell><cell>7000</cell><cell>2.79</cell><cell>6718</cell><cell>0</cell><cell>13282</cell></row><row><cell></cell><cell>12000</cell><cell>2.80</cell><cell>6718</cell><cell>0</cell><cell>13282</cell></row><row><cell></cell><cell>200</cell><cell>14.51</cell><cell cols="2">3858 15862</cell><cell>280</cell></row><row><cell></cell><cell>1000</cell><cell>14.06</cell><cell cols="2">3858 15862</cell><cell>280</cell></row><row><cell>5000</cell><cell>3000</cell><cell>9.87</cell><cell>4655</cell><cell>9025</cell><cell>6320</cell></row><row><cell></cell><cell>7000</cell><cell>1.59</cell><cell>3861</cell><cell>0</cell><cell>16139</cell></row><row><cell></cell><cell>12000</cell><cell>1.74</cell><cell>3861</cell><cell>0</cell><cell>16139</cell></row><row><cell></cell><cell>200</cell><cell>19.91</cell><cell cols="2">1433 18531</cell><cell>36</cell></row><row><cell></cell><cell>1000</cell><cell>19.79</cell><cell cols="2">1433 18531</cell><cell>36</cell></row><row><cell>10000</cell><cell>3000</cell><cell>19.95</cell><cell cols="2">1433 18531</cell><cell>36</cell></row><row><cell></cell><cell>7000</cell><cell>0.61</cell><cell>1386</cell><cell>0</cell><cell>18614</cell></row><row><cell></cell><cell>12000</cell><cell>0.60</cell><cell>1386</cell><cell>0</cell><cell>18614</cell></row><row><cell cols="6">of = 1, 000 is smaller than the others, because there are many filtered points.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table . 2</head><label>.</label><figDesc>illustrates more experiments on the same data set. In this experiment, we test the impaction of large M inP ts. From the table we can see that the number of filtered points increase with M inP ts, the more filtered points the fewer the running time, which is consistent with our analysis mentioned in</figDesc><table><row><cell></cell><cell>1800</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">NQ-DBSCAN</cell></row><row><cell></cell><cell>1600</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">NQ-DBSCAN with indexing</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Approx</cell><cell></cell></row><row><cell></cell><cell>1400</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1200</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>time(sec)</cell><cell>800 1000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2 0 200 400 600</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell><cell>n</cell><cell>1.2</cell><cell>1.4</cell><cell>M 1.6 1.8 2 A N U S C R I P T x 10 4</cell></row><row><cell cols="10">410 A C C E P T E D Section 3.4. This experiment also implies that NQ-DBSCAN is highly efficient to find and filter noise, in other words, it is suitable for clustering data with a</cell></row><row><cell cols="8">lot of noise, such as [59].</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 3 :</head><label>3</label><figDesc>The precision of NQ-DBSCAN on three data sets. All accuracies are calculated by comparing to the result of original DBSCAN. The parameters of NQ-DBSCAN and DBSCAN are given in the formation as [ , MinPts].</figDesc><table><row><cell>data set</cell><cell cols="3">BLOG [2000,30] HOUSE [500,30] PAM [500,30]</cell></row><row><cell>Approx</cell><cell>94.54%</cell><cell>99.67%</cell><cell>99.78%</cell></row><row><cell>NQ-DBSCAN</cell><cell>99.97%</cell><cell>99.6%</cell><cell>100%</cell></row><row><cell cols="3">labels, which has been used in our previous works [61, 62].</cell><cell></cell></row><row><cell cols="4">For example, if a data set has 3 clusters labeled as 'A1', 'A2' and 'A3'</cell></row><row><cell cols="4">obtained by DBSCAN, and our method finds 4 clusters with labels 'B1', 'B2',</cell></row></table><note><p><p><p><p><p><p><p>480</p>'B3' and 'B4' on the same data set. Suppose there are 3 matched pairs found by Kuhn-Munkres algorithm: ('A1','B2'), ('A2', 'B1') and ('A3', 'B4'). If p is labeled as 'A1' by DBSCAN and clustered as 'B2' by our approach, respectively, we consider this prediction as correct. If p is labeled as 'A1' by DBSCAN and clustered as 'B1' by our approach it is wrong. Similar to other cases.</p>As presented in Table</p>.</p>3, the precisions truly speak of that our approach nearly achieves the same results as DBSCAN, the petty difference is caused by the visiting order is different from that of original DBSCAN, because DBSCAN is non-determinative. While ρ-approximate DBSCAN is little inferior to NQ-DBSCAN.</p>490</p>In order to evaluate the performance of NQ-DBSCAN on data sets with deviations, we select 10% data points from BLOG, HOU SE and P AM , respectively, and then shift these points randomly in each dimension by adding a random value η, where η = of f set * random(), and of f set is predefined. As Ta-</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 4 :</head><label>4</label><figDesc>The precision of NQ-DBSCAN on three data sets with deviations. All accuracies are calculated by comparing to the result of original DBSCAN. The parameters of NQ-DBSCAN are given in the formation as [ , MinPts].</figDesc><table><row><cell></cell><cell cols="4">offset BLOG [2000,30] HOUSE[500,30] PAM[500,30]</cell></row><row><cell></cell><cell>100</cell><cell>99.92%</cell><cell>99.31%</cell><cell>99.78%</cell></row><row><cell></cell><cell>200</cell><cell>99.66%</cell><cell>99.73%</cell><cell>99.77%</cell></row><row><cell>NQ-DBSCAN</cell><cell>300</cell><cell>90.29%</cell><cell>89.93%</cell><cell>99.74%</cell></row><row><cell></cell><cell>400</cell><cell>90.29%</cell><cell>89.93%</cell><cell>98.76%</cell></row><row><cell></cell><cell>500</cell><cell>90.29%</cell><cell>89.93%</cell><cell>93.63%</cell></row><row><cell></cell><cell>100</cell><cell>94.49%</cell><cell>99.65%</cell><cell>99.78%</cell></row><row><cell></cell><cell>200</cell><cell>94.30%</cell><cell>99.38%</cell><cell>99.77%</cell></row><row><cell>Approx</cell><cell>300</cell><cell>92.77%</cell><cell>89.79%</cell><cell>99.68%</cell></row><row><cell></cell><cell>400</cell><cell>85.92%</cell><cell>89.79%</cell><cell>98.98%</cell></row><row><cell></cell><cell>500</cell><cell>85.92%</cell><cell>89.79%</cell><cell>93.68%</cell></row><row><cell>be an O(n 2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://en.wikipedia.org/wiki/DBSCAN</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://archive.ics.uci.edu/ml</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>http://yann.lecun.com/exdb/mnist/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>http://www.faceaginggroup.com/morph/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgment The National Science Foundation of China (No.61673186,71771094) ; this work was supported by the Open Project Program of the National Laboratory of Pattern Recognition (NLPR) (NO.201700002); the Open Project Program of the State Key Lab of CAD&amp;CG(Grant No.A1722), Zhejiang University; the 550 Natural Science Foundation of Fujian Province (No.2016J01303); Project of science and technology plan of Fujian Province of China (No.2017H01010065); the Graduate Students Research and Innovation Ability Cultivation Plan of Huaqiao University (No.1511414009); the Huaqiao University graduate research project of education reform (16YJG13).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this subsection, we conduct experiments on Spheredata 3, Spheredata 4, Cubedata 2 and Cubedata 3, respectively, to compare the efficiencies of NQ-DBSCAN, "NQ-DBSCAN with indexing" and Approx by changing the cardinalities of these cases.</p><p>Because Approx runs linearly in low-dimension, we can see that Approx outperforms NQ-DBSCAN in Fig. <ref type="figure">17</ref> and Fig. <ref type="figure">18</ref>. However, with dimension 420 increasing, things go different. In Fig. <ref type="figure">19</ref>, we can see that in this 10-dimensional data set, Approx is still better than NQ-DBSCAN and "NQ-DBSCAN with indexing", but their performances are closer than that in 5 dimension. And then, Fig. <ref type="figure">20</ref> shows that the performance of Approx is inferior to both NQ-DBSCAN and "NQ-DBSCAN with indexing" in the 20-dimensional data set (Spheredata 4).</p><p>All experiments above obtain correct results as we expected, i.e. in Fig. <ref type="figure">17</ref> and Fig. <ref type="figure">19</ref>, we obtain 4 hyper-spherical clusters, and in Fig. <ref type="figure">18</ref> and Fig. <ref type="figure">20</ref>, we get 3 clusters which include 4 hyper-cubes.</p><p>We also can see that "NQ-DBSCAN with indexing" seems to be an O(n) 430 algorithm, because proper and M inP ts are used such that α and nei are both small and β → n, which is consistent with the theoretical analysis mentioned above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">Experiment 5: Experiments on Realtime Applications</head><p>In order to test the performance of NQ-DBSCAN and "NQ-DBSCAN with indexing" in realtime applications, we benchmark it on six test cases with different dimensions, i.e. Household (7 dim), ReactionNetwork (28 dim) , BlogFeedback (59 dim), KDD04 (76 dim), MNIST (784 dim) and MORPH (5,600 dim), and compare them with ρ-Approximate DBSCAN. In the following experiments, MinPts are all fixed to 100. 440 Fig. <ref type="figure">21</ref> and Fig. <ref type="figure">22</ref> show that Approx runs linearly in Household <ref type="bibr">(7 dim)</ref> and ReactionNetwork (28 dim), and its performance is better than the proposed</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>[14] M. Ester, H.-P. Kriegel, J. Sander, Algorithms and applications for spatial data mining, Geographic Data Mining and Knowledge Discovery 5 <ref type="bibr" target="#b6">(6)</ref>.  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Optimized graph learning using partial tags and multiple features for image and video annotation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4999" to="5011" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Deep and fast: Deep learning hashing with semi-supervised graph construction, Image and Vision Computing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A distancecomputation-free search scheme for binary code databases</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="484" to="495" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scalable feature matching by dual cascaded scalar quantization for image retrieval</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="159" to="171" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><surname>A C C E P T E D M A N U S C R I P T</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Affective visualization and retrieval for music video</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="510" to="522" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exploring transfer learning approaches for head pose classification from multi-view surveillance images</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Rajagopal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Vieriu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lanz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="146" to="167" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A multi-task learning framework for head pose estimation under target motion</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lanz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1070" to="1083" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Accelerating high dimensional clustering with lossless data reduction</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">F</forename><surname>Qaqish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Obrien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Hibbard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Clowers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="page">328</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A survey on soft subspace clustering</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">348</biblScope>
			<biblScope unit="page" from="84" to="106" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Arch-int, Determination of the appropriate parameters for k-means clustering using selection of region clusters based on density dbscan (srcd-dbscan)</title>
		<author>
			<persName><forename type="first">O</forename><surname>Limwattanapibool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Expert Systems</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast density clustering strate-590 gies based on the k-means algorithm</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="375" to="386" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A distance-relatedness dynamic model for clustering high dimensional data of arbitrary shapes and densities</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Yousri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Kamel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Ismail</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1193" to="1209" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A graph-theoretical clustering method based on two rounds of minimum spanning trees</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="752" to="766" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kamber</surname></persName>
		</author>
		<title level="m">Data mining: concepts and techniques</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Towards parameter-independent data clustering and image segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="25" to="36" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Satellite image segmentation with shadowed cmeans</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Kundu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="3601" to="3613" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Kernel-induced fuzzy clustering of image pixels with an improved differential evolution algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences An Inter-610 national Journal</title>
		<imprint>
			<biblScope unit="volume">180</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1237" to="1256" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The application of cluster analysis in geophysical data interpretation</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Ogrady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M P</forename><surname>Ohare</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Geosciences</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="271" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fuzzy clustering algorithms for unsupervised change detection in remote sensing images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="699" to="715" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A clustering method to identify representative financial ratios</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">178</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1087" to="1097" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Chameleon based on clustering feature tree and 620 its application in customer segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Operations Research</title>
		<imprint>
			<biblScope unit="volume">168</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="225" to="245" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An intelligent document clustering approach to detect crime patterns</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Bsoul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Salim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Q</forename><surname>Zakaria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Technology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1181" to="1187" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Intuitionistic fuzzy c-means clustering algorithm with neighborhood attraction in segmenting medical image</title>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-P</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-C</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Jen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Computing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="459" to="470" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A new fuzzy clustering algorithm for the segmentation of brain tumor</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">P</forename><surname>Ananthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Balasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kalaiselvi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Computing</title>
		<imprint>
			<biblScope unit="page" from="1" to="630" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Chinchuluun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bhorania</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Pardalos</surname></persName>
		</author>
		<title level="m">Clustering and Classification Algorithms in Food and Agricultural Applications: A Survey</title>
		<imprint>
			<publisher>Springer US</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Black hole: A new heuristic optimization approach for data clustering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hatamlou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">222</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="175" to="184" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Trajectory clustering: a partition-andgroup framework</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Y</forename><surname>Whang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGMOD International Conference on Management of Data</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="593" to="604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Agglomerative mean-shift clustering</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">T</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE 640 Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="209" to="219" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Parallel spectral clustering in distributed systems</title>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="568" to="586" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A parallel clustering technique for the vehicle routing problem with split deliveries and pickups</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Operational Research Society</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1532" to="1546" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A density-based algorithm for discovering clusters in large spatial databases with noise</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Kdd</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="226" to="231" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An improved sampling-based dbscan for large spatial databases</title>
		<author>
			<persName><forename type="first">B</forename><surname>Borah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Sensing and Information Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="page" from="92" to="96" />
		</imprint>
	</monogr>
	<note>Proceedings of International Conference on</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName><surname>A C C E P T E D M A N U S C R I P T</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Density-based clustering with constraints</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Spiliopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Menasalvas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>-Dbscan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Rough Sets, Fuzzy Sets, Data Mining, and Granular-Soft Computing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="216" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Mr-dbscan: an efficient parallel density-based clustering algorithm using mapreduce</title>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel and Distributed Systems (ICPADS), 2011 IEEE 17th International 660 Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="473" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A fast dbscan clustering algorithm by accelerating neighbor searching using groups method</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R M</forename><surname>Reddy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="39" to="48" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">γ-ray dbscan: a clustering algorithm applied to fermi-lat γ-ray data-i. detection performances with real and simulated data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tramacere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vecchio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Astronomy &amp; Astrophysics</title>
		<imprint>
			<biblScope unit="volume">549</biblScope>
			<biblScope unit="page">138</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A similarity model and segmentation algorithm for white matter fiber tracts</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goebl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Plant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 12th International Conference on Data Mining</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="1014" to="1019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Dbscan revisited: Mis-claim, un-fixability, and approximation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2015 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="519" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Distance metric learning for soft subspace clustering in composite kernel space</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F.-L</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="113" to="134" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Cluster prototypes and fuzzy memberships jointly leveraged cross-domain maximum entropy clustering</title>
		<author>
			<persName><forename type="first">P</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Muzic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on cybernetics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="181" to="193" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Transfer prototype-based fuzzy clustering</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F.-L</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ishibuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1210" to="1232" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Enhanced soft subspace clustering integrating within-cluster and between-cluster information</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F.-L</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="767" to="781" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">A faster algorithm for dbscan</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gunawan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
		<respStmt>
			<orgName>Technische University Eindhoven</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Masters thesis</note>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Rough-dbscan: A fast hybrid density based clustering method for large data sets</title>
		<author>
			<persName><forename type="first">P</forename><surname>Viswanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="1477" to="1488" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">St-dbscan: An algorithm for clustering spatial-temporal data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Birant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data &amp; Knowledge Engineering</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="208" to="221" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Using grid for accelerating density-based clustering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mahran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mahar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer and Information Technology</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="35" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Multi-density dbscan cluster based on grid</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xiaoyun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yufang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gmdbscan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on E-Business Engineering</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="780" to="783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Grid density-700 based spatial clustering of applications with noise</title>
		<author>
			<persName><forename type="first">O</forename><surname>Uncu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Gruver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Kotak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sabaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gridbscan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Systems, Man and Cybernetics</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="2976" to="2981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Multi-density dbscan based on grid and contribution</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gcmddbscan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Dependable, Autonomic and Secure Computing</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="502" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Product quantization for nearest neighbor search</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jegou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="117" to="128" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<author>
			<persName><surname>A C C E P T E D M A N U S C R I P T</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Andoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Indyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="710" to="117C" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Scalable nearest neighbor algorithms for high dimensional data</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G L</forename><surname>Marius Muja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2227" to="2240" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Feedback prediction for blogs, in: Data analysis, machine learning and knowledge discovery</title>
		<author>
			<persName><forename type="first">K</forename><surname>Buza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="145" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Morph: a longitudinal image database of normal adult age-progression</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ricanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tesafaye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Automatic Face and Gesture Recognition</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="341" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Chameleon: Hierarchical clustering 720 using dynamic modeling</title>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E.-H</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="68" to="75" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Clustering aggregation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gionis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mannila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tsaparas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data (TKDD)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Skinny-dip: Clustering in a sea of noise</title>
		<author>
			<persName><forename type="first">S</forename><surname>Maurus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Plant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD, ACM</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1055" to="1064" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Robust statistics</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Encyclopedia of Statistical Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1248" to="1251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Decentralized clustering by finding loose and distributed density cores</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="page" from="510" to="526" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Dheat: A density heatbased algorithm for clustering with effective radius</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics: Systems</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="649" to="660" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">The hungarian method for the assignment problem</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Naval research logistics quarterly</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="83" to="97" />
			<date type="published" when="1955">1955</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
