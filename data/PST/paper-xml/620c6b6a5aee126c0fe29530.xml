<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Personalized Prompt Learning for Explainable Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-02-15">15 Feb 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Hong Kong Baptist University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Hong Kong Baptist University</orgName>
								<address>
									<addrLine>34 Renfrew Road</addrLine>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
							<email>zhang@rutgers.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<addrLine>110 Frelinghuysen Road</addrLine>
									<postCode>08854-8019</postCode>
									<settlement>New Brunswick, yongfeng</settlement>
									<region>New Jersey</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Li</forename><forename type="middle">I</forename><surname>Chen</surname></persName>
							<email>lichen@comp.hkbu.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">Hong Kong Baptist University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Hong Kong Baptist University</orgName>
								<address>
									<addrLine>34 Renfrew Road</addrLine>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Personalized Prompt Learning for Explainable Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-02-15">15 Feb 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/xxxxxxx.xxxxxxx</idno>
					<idno type="arXiv">arXiv:2202.07371v1[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS Concepts:</term>
					<term>Information systems ? Recommender systems</term>
					<term>? Computing methodologies ? Natural language generation Recommender Systems</term>
					<term>Explainable Recommendation</term>
					<term>Natural Language Generation</term>
					<term>Transformer</term>
					<term>Pre-trained Language Model</term>
					<term>Prompt Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Providing user-understandable explanations to justify recommendations could help users better understand the recommended items, increase the system's ease of use, and gain users' trust. A typical approach to realize it is natural language generation. However, previous works mostly adopt recurrent neural networks to meet the ends, leaving the potentially more effective pre-trained Transformer models under-explored. In fact, user and item IDs, as important identifiers in recommender systems, are inherently in different semantic space as words that pre-trained models were already trained on. Thus, how to effectively fuse IDs into such models becomes a critical issue. Inspired by recent advancement in prompt learning, we come up with two solutions: find alternative words to represent IDs (called discrete prompt learning), and directly input ID vectors to a pre-trained model (termed continuous prompt learning). In the latter case, ID vectors are randomly initialized but the model is trained in advance on large corpora, so they are actually in different learning stages. To bridge the gap, we further propose two training strategies: sequential tuning and recommendation as regularization. Extensive experiments show that our continuous prompt learning approach equipped with the training strategies consistently outperforms strong baselines on three datasets of explainable recommendation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Traditional recommender systems help users overcome the information overload problem by providing personalized recommendations (e.g., movies or songs) that cater to their interests. Meanwhile, explanations that justify why these recommendations are made are becoming more and more important, as they can help users make better and faster decisions, increase the system's ease of use, and gain their trust in the system <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b57">58]</ref>. There is a variety of explanation style, such as pre-defined templates <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b59">60]</ref>, highlighted image regions <ref type="bibr" target="#b9">[10]</ref> and automatically generated sentences <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b28">29]</ref>. The last type has gained increasing attention recently, mainly due to the availability of textual data on online commercial platforms, such as Amazon and Yelp, which encourage users to express their opinions by writing reviews (see Fig. <ref type="figure" target="#fig_0">1</ref>), as well as the advancement of natural language generation techniques, such as Recurrent Neural Networks (RNN), Transformer <ref type="bibr" target="#b52">[53]</ref> and pre-trained language models <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b41">42]</ref>.</p><p>In particular, recent years have witnessed the stronger and stronger language modeling capability of large pre-trained models. Taking Generative Pre-Training (GPT) series <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43]</ref> as an example, the first generation GPT <ref type="bibr" target="#b41">[42]</ref> after fine-tuning achieves the state-of-the-art in 9 natural language understanding tasks out of 12. Further, GPT-2 <ref type="bibr" target="#b42">[43]</ref> without fine-tuning is able generate news articles that resemble authentic ones. More surprisingly, GPT-3 <ref type="bibr" target="#b3">[4]</ref> could even do simple arithmetic (e.g., 2 digit multiplication) that the model was not trained or fine-tuned for. In the meantime, the size of these models and the volume of training data are becoming prohibitively large. Regarding model size, GPT has 117 million parameters, while GPT-2 and GPT-3 are increased dramatically to 1.5 billion and 175 billion, respectively. With respect to data, GPT takes as input 7000 books (approximately 7GB if a book has the size of 1MB), while GPT-2 and GPT-3 are fed respectively 40GB and 570GB of textual data.</p><p>As a consequence, it is nearly impossible to do customized modifications on the structure of these models. Moreover, it would also be challenging to incorporate into them user and item IDs, which are indispensable in recommender systems but are in very different semantic space as words that these models were trained on. No wonder most previous works <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b56">57]</ref> adopt RNN, such as Long Short-Term Memory (LSTM) <ref type="bibr" target="#b21">[22]</ref> and Gated Recurrent Unit (GRU) <ref type="bibr" target="#b13">[14]</ref>, or small unpretrained Transformer <ref type="bibr" target="#b28">[29]</ref> for explanation generation. This, however, makes the more effective pre-trained models less explored.</p><p>Fortunately, recent progress made in prompt learning <ref type="bibr" target="#b34">[35]</ref> points out a promising way. Instead of modifying the structure of pre-trained models, researchers seek to adapt a given task to the models, so that they can directly model text probability. For instance, a prompt for sentiment classification could be constructed with the format of "I love this book. This book is", where the underlined text is a specific sample and the remaining words are a hand-crafted template. This type of conditioning textual string is referred to as discrete prompt. After feeding it to a pre-trained model, a word prediction can be made at the end of the string, such as "good" or "bad", indicating a positive or negative sentiment.</p><p>Likewise, we could also design discrete prompts for recommendation explanation generation. As IDs are inherently different from words, one naive and straightforward way is to convert IDs into words, such as movie titles and item features. We opt for the latter, and utilize features related to both the target user and the target item, since they represent the user's explicit preferences as well as the item's fine-grained attributes. Moreover, these features could guide the model to talk about certain topics when generating explanations, such as "room" and "location" for hotel recommendations.</p><p>However, the conversion process from IDs into features may lose certain information, e.g., the identification role. Specifically, it is not very likely to convert back an ID with some features. For example, from the fact that Jerry loves cheese we would not be able to certify that someone who enjoys eating cheese must be Jerry. Moreover, prompts do not have to strictly be textual strings. They could be vectors, either randomly initially or resulted from another model. This type of prompt is formally termed continuous/soft prompt. In a similar way, we can also input ID vectors to a pre-trained model for explanation generation.</p><p>A follow-up problem is that the pre-trained model is already trained, but the ID vectors are randomly initialized, so they are actually in different learning stages. Recent study <ref type="bibr" target="#b1">[2]</ref> finds out that such randomly initialized vectors could not be well optimized via stochastic gradient descent, and thus may lead to sub-optimal results. To cope with the problem, we propose two training strategies. The first strategy is called sequential tuning, where we separate the training into two stages: fine-tune continuous prompts (i.e., ID vectors) with the model frozen, and then update the parameters of both. The first stage would enable the continuous prompts to reach the same learning stage as the model, so that in the second stage they could be trained together. Our second strategy named recommendation as regularization is inspired by recent findings <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b46">47]</ref> in explainable recommendation that the explanation performance could be improved by the recommendation task. Indeed, the rating scores represent how much a user appreciates an item, which makes them an informative signal to the learning of explanation generation. Hence, we also leverage rating prediction task to augment the explanation task, and test two typical recommendation models, including Matrix Factorization (MF) <ref type="bibr" target="#b38">[39]</ref> and Multi-Layer Perceptron (MLP).</p><p>We name our method PEPLER<ref type="foot" target="#foot_1">1</ref> , which stands for "PErsonalized Prompt Learning for Explainable Recommendation", where personalization is reflected by the IDs, either implicitly in the discrete prompts or explicitly in the continuous prompts. Without bells and whistles, our method consistently achieves the best performance against strong baselines (built on top of LSTM <ref type="bibr" target="#b21">[22]</ref>, GRU <ref type="bibr" target="#b13">[14]</ref>, Transformer <ref type="bibr" target="#b52">[53]</ref> or BERT <ref type="bibr" target="#b14">[15]</ref>) in terms of both text quality and explainability on three datasets.</p><p>In summary, our key contributions are:</p><p>? We propose PEPLER that generates natural language explanations for recommendations by treating user and item IDs as prompts. To the best of our knowledge, we are the first to introduce prompt learning to the community of recommender systems. ? We propose two training strategies to bridge the gap between continuous prompts and the pre-trained model, in order to enhance the explanation generation performance. In a broader sense, this may inspire researchers on how to better tune pre-trained language models. ? We evaluate the generated explanations on not only text quality metrics (such as BLEU and ROUGE), but also metrics that particularly focus on explainability from the angle of item features. Extensive experiments show that our method consistently outperforms state-of-theart baselines. ? Our work may shed light on a broader scope of natural language generation fields that also need personalization, e.g., personalized conversational systems. In addition, it may point out a way for pre-trained models to deal with multi-modal data, e.g., image and text in captioning systems.</p><p>In what follows, we first summarize related literature in section 2, and then present our explanation generation method PEPLER in section 3. Experimental setup and results analysis are respectively given in section 4 and 5. We make a final conclusion and discuss future works in section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Explainable Recommendation</head><p>Explainable recommendation <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b57">58]</ref> has been studied from two major perspectives: humancomputer interaction and machine learning. The former investigates how people perceive different styles of explanation <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b18">19]</ref>, while the latter provides explanations by designing new explainable recommendation algorithms, to which our work is more related. There exist various types of explanation style, such as pre-defined templates <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b59">60]</ref>, item features <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b53">54]</ref>, ranked text <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b26">27]</ref>, image visualizations <ref type="bibr" target="#b9">[10]</ref>, knowledge graph paths <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b55">56]</ref>, and reasoning rules <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b62">63]</ref>, but in this work we focus on generating natural language explanations. Previous works <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b56">57]</ref> mostly rely on RNN, e.g., LSTM <ref type="bibr" target="#b21">[22]</ref> and GRU <ref type="bibr" target="#b13">[14]</ref>, or unpretrained Transformer <ref type="bibr" target="#b28">[29]</ref>, leaving the potentially more effective pre-trained models under-explored, which motivates this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Transformer and Pre-trained Models</head><p>Transformer <ref type="bibr" target="#b52">[53]</ref> was first brought to the domain of machine translation with the architecture of encoder-decoder. Later works <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b35">36]</ref> show that it remains effective, even when the encoder or the decoder is removed, reducing nearly half of model parameters. Under the paradigm of pretraining plus fine-tuning, Transformer's effectiveness has been confirmed on a wide range of natural language understanding tasks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b41">42]</ref>, such as commonsense reasoning and question answering. More recently, it has been shown that pre-trained Transformer is able to perform novel tasks on which it was not targeted during training, e.g., arithmetic, after increasing both the magnitude of model size and the volume of training corpus <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b42">43]</ref>. However, re-training such models may not be friendly to researchers who do not possess large amounts of computing resources. Therefore, there emerges a new research direction: prompt learning <ref type="bibr" target="#b34">[35]</ref>, where researchers adapt their tasks to pre-trained models, without the need of modifying or re-training them. Prompt learning has been successfully applied to many applications, such as domain adaptation <ref type="bibr" target="#b2">[3]</ref>, text summarization <ref type="bibr" target="#b31">[32]</ref> and image captioning <ref type="bibr" target="#b51">[52]</ref>, but it has been less investigated how prompt learning would benefit recommender systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Personalized Natural Language Generation</head><p>Personalization of natural language generation plays a vital role in a large spectrum of tasks, such as explainable recommendation <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b28">29]</ref>, review summarization <ref type="bibr" target="#b22">[23]</ref>, and dialog systems <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b60">61]</ref>. In these tasks, user and item IDs are important identifiers for personalization. Previous approaches typically adopt MLP to encode the IDs into a context vector, from which RNN can decode a word sequence. This strategy can be found in many applications, such as review generation <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b50">51]</ref>, tip generation <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref> and explanation generation <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b25">26]</ref>. However, it does not fit pre-trained models that were already trained on a massive amount of raw text. Probably because a proper solution to deal with heterogeneous data (i.e., IDs and words) is yet to be invented, previous works with Transformer or pre-trained models for personalized natural language generation replace IDs with text segments, such as persona attributes <ref type="bibr" target="#b60">[61]</ref>, movie titles <ref type="bibr" target="#b61">[62]</ref> and item features <ref type="bibr" target="#b39">[40]</ref>, which is somewhat similar to our discrete prompt learning. But besides this, we further investigate how to incorporate into pre-trained models continuous prompts (i.e., ID vectors), in order to retain as much information as possible. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head><p>The goal of our explanation task is to generate a natural language sentence ??,? for a given user-item pair (?, ?) to justify why ? is recommended to ?. The item ? could be predicted for the user ? by a recommendation model, e.g., matrix factorization <ref type="bibr" target="#b38">[39]</ref>, or resulted from his/her true behavior. At both training and testing stages, only user ? and item ? are used as input for producing the explanation. Hence, our proposed explanation generation approaches are compatible with any recommendation model, in which user and item IDs are indispensable.</p><p>In this section, we present the details of our methodology. First, we briefly go through Transformer, pre-trained language models, and prompt learning. Then, we introduce our proposed two methods for explanation generation, including discrete prompt learning and continuous prompt learning. After that, we illustrate how an explanation is generated during the inference stage. At last, we present two strategies for continuous prompt learning: sequential tuning, and recommendation as regularization. Key notations and concepts used throughout this paper are depicted in Table <ref type="table" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Transformer, Pre-trained Language Models and Prompt Learning</head><p>To better demonstrate our work of PErsonalized Prompt Learning for Explainable Recommendation (PEPLER), we briefly go through Transformer and pre-trained language models that this work is built upon. Transformer <ref type="bibr" target="#b52">[53]</ref>   and ? denotes the dimension of token representations/embeddings. Each layer is composed of two sub-layers: multi-head self-attention (MHSA) and position-wise feed-forward network (FFN). The latter is a two-layer FFN with the ReLU activation function. It performs linear transformations on the former's output O ? ? R |? |?? , and converts it into S ? ,</p><formula xml:id="formula_0">S ? = ReLU(O ? W ?,1 + b ?,1 )W ?,2 + b ?,2<label>(1)</label></formula><p>where</p><formula xml:id="formula_1">W ?,1 ? R ??? ? ? , b ?,1 ? R ? ? ? , W ?,2 ? R ? ? ? ?? , b ?,2 ? R ? are weight parameters.</formula><p>The MHSA sub-layer aggregates ? attention heads, each of which is computed identically with the scaled dot-product attention (e.g., the ?-th head in the ?-th layer A ?,? ? R |? |? ? ? ). Formally, the computation of this sub-layer is defined as follows:</p><formula xml:id="formula_2">O ? = [A ?,1 , ..., A ?,? ]W ? ? A ?,? = softmax( Q ?,? K ? ?,? ? ? + M)V ?,? Q ?,? = S ?-1 W ? ?,? , K ?,? = S ?-1 W ? ?,? , V ?,? = S ?-1 W ? ?,? M = 0, Allow to attend -?, Prevent from attending (2) where [?, ?] represents the concatenation of matrices/vectors, softmax(?) denotes the softmax function, W ? ? ? R ??? and W ? ?,? , W ? ?,? , W ? ?,? ? R ?? ? ? are projection matrices to be learned, S ?-1 ? R |? |?? is the (? -1)-th layer's output, and M ? R |? |? |? | is the attention masking matrix.</formula><p>Each element in M controls whether a token in the sequence can attend to another. For example, in bidirectional language models such as BERT <ref type="bibr" target="#b14">[15]</ref>, M is a zero matrix that allows all tokens in the sequence to attend to each other. Owing to the bidirectionality nature, this type of model is more suitable for natural language understanding tasks. In the case of natural language generation, future tokens would be exposed to bidirectional language models, making them incapable of predicting these tokens. As a comparison, left-to-right unidirectional language models, e.g., GPT <ref type="bibr" target="#b41">[42]</ref>, are particularly designed for natural language generation. Specifically, in these models, the lower triangular part of M is set to 0 and the remaining part -?, so as to allow each token to attend to Table <ref type="table">2</ref>. Prompt learning for typical natural language processing tasks <ref type="bibr" target="#b34">[35]</ref>. In our explanation generation task, the template words "Explain the recommendation:" are removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task</head><p>Input With the two types of masking mechanism, there are also two corresponding pre-training objectives: cloze task, which is formally termed Masked Language Model (MLM) <ref type="bibr" target="#b14">[15]</ref>, for bidirectional language models, and auto-regressive generation for unidirectional language models. Because our explanation generation task is closely related to the latter, we describe it in more details. Specifically, given the output vectors S ? = [s ?,1 , ..., s ?, |? | ] resulting from the last layer of Transformer, we pass them through a linear layer to obtain the probability distribution over all tokens in the dataset. With the token probability distribution, we then make the next-token prediction based on preceding tokens, which can be achieved by minimizing the following negative log-likelihood:</p><formula xml:id="formula_3">L = ?? ? -log ? (? ? |? ? -? , ..., ? ? -1 ; ? ?? )<label>(3)</label></formula><p>where ? ? is the next token to be predicted, ? denotes the size of the sliding context window, and ? ?? represents all parameters in Transformer.</p><p>The pre-trained language models refer to those Transformers that have a great number of parameters (e.g., 1 billion) and were trained on a large volume of textual data (e.g., 100GB). As a consequence, unlike small unpretrained Transformer <ref type="bibr" target="#b28">[29]</ref>, it is less likely to do customized modifications on them. In the meantime, re-training a large Transformer model would be unaffordable for most researchers who do not possess much computing resources. Fortunately, there is a promising solution called prompt learning <ref type="bibr" target="#b34">[35]</ref>, where different natural language processing tasks are adapted to a pre-trained language model so as to enable direct modeling of text. In this way, the knowledge exhibited in the model could also be made good use of.</p><p>Taking sentiment classification as an example, conventionally an input "I love this book" could be predicted by a model as 1, indicating a positive sentiment. In prompt learning, a template such as "X The book is Y" is constructed firstly. Then, the input placeholder X is filled in with a sample, e.g., "I love this book. The book is Y", which is termed prompt. With this, the model can be instructed to Pre-trained Transformer (e.g., GPT-2) Pre-trained Transformer (e.g., GPT-2) Linear Layer</p><formula xml:id="formula_4">? ? 2 ? ? 3 &lt; ? ???&gt; &lt;???&gt; ? ? 2 ? ? 1 ? ?,1 ? ?,2</formula><p>? ?,5 ? ?,6 ? ?,3 ? ?,4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Explanation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Explanation Generation</head><formula xml:id="formula_5">? 2 ? 1 Discrete Prompt ? ?,7 ? 3 ? ? 3 ? ? 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Features in training data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Look-up</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>? ?</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User Item</head><p>Return Features for (?, ?) Fig. <ref type="figure">3</ref>. Our proposed method PEPLER-D that utilizes item features as discrete prompt for explanation generation.</p><p>make a prediction at the output placeholder Y, e.g., "great" or "boring". At last, the prediction is mapped onto a sentiment, i.e., 1 or 0. Clearly, there are two major steps that cost human efforts. The first one is to manually design templates for different application scenarios, and to find the one that best fits a target application. The second is the answer mapping stage, where a number of answer words need to be prepared in advance.</p><p>As a comparison, it does not have to be so sophisticated for natural language generation tasks, for which the predictions to be made are text per se. For example, the template for text summarization could simply be "X TL;DR: Y" <ref type="foot" target="#foot_3">3</ref> , and that for machine translation "French: X English: Y". In a similar way, we could also define the template for explanation generation as "X Explain the recommendation: Y". Although intuitively the template words may look useful, it was found that they could not always guide pre-trained language models to perform the specified task (e.g., "summarize the table") <ref type="bibr" target="#b31">[32]</ref>. Moreover, our key focus is to automatically generate explanations for recommendations rather than manually constructing templates. Therefore, we omit these template words, which results in "X Y" and "X1 X2 Y". A comparison of prompt learning between the aforementioned tasks is given in Table <ref type="table">2</ref>. In the following, we describe our proposed two methods for explainable recommendation: discrete prompt learning and continuous prompt learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Discrete Prompt Learning</head><p>Pre-trained language models, such as BERT <ref type="bibr" target="#b14">[15]</ref> and GPT-2 <ref type="bibr" target="#b42">[43]</ref>, were trained on a large amount of word tokens, which are inherently in a different semantic space as ID tokens, but IDs (e.g., user ID) are indispensable in recommender systems. To resolve this issue, a straightforward way is to find some word tokens to represent the IDs, such as movie titles and item features (e.g., "room" for hotel recommendation). We explore the latter, and denote the proposed approach as PEPLER-D, where "D" stands for "discrete prompt learning". A graphical illustration of PEPLER-D is shown in Fig. <ref type="figure">3</ref>.</p><p>Given a user ? (or an item ?), we can obtain all the associated item features ? ? (or ? ? ) appeared in training set. For each user-item pair (?, ?), we categorize these features into two groups: the intersection of ? ? and ? ? (i.e., ? ? ? ? ? ), and the remaining features (? ? ? ? ? )/(? ? ? ? ? ). Obviously, the former group is more informative as it contains features related to both user ? and item ?. Then, the discrete prompt for this user-item pair is defined as:</p><formula xml:id="formula_6">? ?,? = [(? ? ? ? ? ), (? ? ? ? ? )/(? ? ? ? ? )]<label>(4)</label></formula><p>To prevent from too many features, we may chop off some less informative ones at the right-hand side.</p><p>During the training stage, the input sequence to the pre-trained model can be represented as</p><formula xml:id="formula_7">? = [? 1 , ? ? ? , ? |??,? | , ? 1 , ? ? ? , ? |??,? | ], where ? 1 , ? ? ? , ? |??,? | are the discrete prompt consisting of features, ? 1 , ? ? ? , ? |??,? |</formula><p>are the explanation's word sequence, and ? ?,? and ? ?,? respectively denote the number of features and explanation words. Because all the tokens in sequence ? are of the same type, i.e., words, we can perform embedding look-up once for them all, which gives the sequence's token representation</p><formula xml:id="formula_8">[f 1 , ? ? ? , f |??,? | , e 1 , ? ? ? , e |??,? | ].</formula><p>The input representation of the sequence to the model is the addition of the token representation, and the positional representation</p><formula xml:id="formula_9">[p 1 , ? ? ? , p |? | ]</formula><p>that encodes the position of each token in the sequence. We denote the input representation as</p><formula xml:id="formula_10">S 0 = [s 0,1 , ? ? ? , s 0, |? | ],</formula><p>where |? | is the length of the sequence.</p><p>After passing S 0 through pre-trained Transformer, we obtain the sequence's final representation</p><formula xml:id="formula_11">S ? = [s ?,1 , ? ? ? , s ?, |? | ].</formula><p>Then, we apply a linear layer to each token's final representation to map it onto a |V |-sized vector. As an example, s ?,? becomes c ? after passing through this layer:</p><formula xml:id="formula_12">c ? = softmax(W ? s ?,? + b ? )<label>(5)</label></formula><p>where</p><formula xml:id="formula_13">W ? ? R | V |?? and b ? ? R | V |</formula><p>are weight parameters, and softmax(?) is the softmax function.</p><p>The vector c ? represents the probability distribution over the vocabulary V. For model learning, we adopt negative log-likelihood (NLL) as the loss function, and compute the mean of user-item pairs in the training set:</p><formula xml:id="formula_14">L ? = 1 |T | ?? (?,?) ? T 1 ? ?,? |??,? | ?? ? =1 -log ? ? ? |??,? |+?<label>(6)</label></formula><p>where the probability ? ? ? ? is offset by ? ?,? positions because the explanation is placed at the end of the sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Continuous Prompt Learning</head><p>We have shown that it is feasible to use item features as discrete prompt to a pre-trained model for explanation generation. However, the conversion from IDs to words (i.e., features) may lose some important information of IDs. Taking the identification role of IDs as an example, it is nearly impossible to convert the features back into IDs. Meanwhile, prompts do not necessarily have to be words or even readable. They can be vector representations, either produced by other models or randomly initialized. This type of human-incomprehensible prompts are formally termed continuous/soft prompt. Thus, ID vectors could also be directly used as continuous prompts to generate recommendation explanations. Next, we show how to encode the two types of ID ? and ? into vector representations.</p><p>Conceptually, the input sequence can be represented as</p><formula xml:id="formula_15">? = [?, ?, ? 1 , ? ? ? , ? |??,? | ],</formula><p>as shown in Fig. <ref type="figure">4</ref>. Intuitively, one may regard the IDs as special word tokens, and add them to the pre-trained model's vocabulary V. However, there could be millions or even billions of users and items in recommender systems (e.g., in e-commerce). When generating explanations, predicting a word out of the huge amount of IDs would be time-consuming. Therefore, we do not add the IDs to V, but instead treat them as two additional types of tokens. Specifically, we prepare two sets of token embeddings:</p><formula xml:id="formula_16">U ? R | U |?? and I ? R | I |??</formula><p>, where |U| and |I| respectively represent the number of users and items in a dataset. Then, a user ?'s vector representation can be retrieved via:</p><formula xml:id="formula_17">u = U ? g(?)<label>(7)</label></formula><p>where g(?) ? {0, 1} | U | denotes a one-hot vector, whose non-zero element corresponds to the position that user ?'s vector locates in U. In a similar way, we can obtain i from I for item ?. Notice that, the embeddings U and I are randomly initialized, but will be updated by back-propagation during the training process. Then, the sequence's token representation can be denoted as </p><formula xml:id="formula_18">L ? = 1 |T | ?? (?,?) ? T 1 ? ?,? |??,? | ?? ? =1 -log ? ? ? 2+? (<label>8</label></formula><formula xml:id="formula_19">)</formula><p>where ? ? ? ? is offset by 2 positions (i.e., user ID and item ID), which is slightly different multiple positions of features in Eq. (6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Explanation Generation</head><p>During the inference stage, our goal is to instruct the model to generate a word sequence ? * , which has the maximum log-likelihood, as explanation.</p><formula xml:id="formula_20">? * = arg max ? ? ? |? | ?? ? log ? ? ? |?????? |+?<label>(9)</label></formula><p>Table <ref type="table">3</ref>. Different strategies for tuning pre-trained language models <ref type="bibr" target="#b34">[35]</ref>. "Para. " stands for parameters. "N/A" means that there is no prompt, while "None" indicates that the prompts do not have additional parameters. There are various methods to find the sequence ? * , such as greedy decoding and beam search. Since it is not our key focus to develop searching algorithms, we adopt the simple greedy decoding, which treats the word with the largest probability as the prediction at each step. More precisely, along with the prompt ? and ? (or ? ?,? ), we first feed the model a special begin-of-sequence token &lt;bos&gt;. From the resulting word probability distribution c &lt;???&gt; , we can select a word as prediction. Then, we concatenate this predicted word at the end of the sequence to form a new input sequence for generating another word. We do this repeatedly until the model produces a special end-ofsequence token &lt;eos&gt;, or the generated explanation reaches a pre-defined length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strategy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Sequential Tuning Strategy</head><p>In the case of discrete prompt learning, the prompts are features, which are of the same type as words that pre-trained language models were trained on. As a result, no additional model parameters are introduced, so we can simply optimize the following objective function:</p><formula xml:id="formula_21">J = min ? ?? L ?<label>(10)</label></formula><p>where ? ?? denotes all the trainable parameters in the pre-trained language model. However, in the case of continuous prompt learning, we introduced additional prompt parameters, i.e., two sets of embeddings for users and items. Therefore, the model parameters ? to be updated include pre-trained language model parameters ? ?? and prompt parameters ? ? . Obviously, the two types of parameters are in different learning stages, since the former are already trained from a large amount of textual data, while the latter are randomly initialized. For example, it is easy to distinguish one word from another with the embeddings from ? ?? , e.g., "hotel" and "room", but it may not be that distinguishable for two users with random embeddings from ? ? , such as "Tom" and "Jerry". Also, previous study <ref type="bibr" target="#b1">[2]</ref> shows that randomly initialized parameters could only be updated in a small neighborhood with stochastic gradient descent (SGD). Hence, how to effectively bridge the two types of parameters becomes a critical issue.</p><p>To tackle this problem, we propose a sequential tuning strategy. Specifically, we first freeze the language model parameters ? ?? , and optimize the prompt parameters ? ? with Eq. ( <ref type="formula" target="#formula_18">8</ref>). Once ? ? can no longer be updated, we fine-tune all the model parameters (i.e., ? ?? and ? ? ) with Eq. ( <ref type="formula" target="#formula_18">8</ref>) again. This two-step procedure can be demonstrated with the following formula:</p><formula xml:id="formula_22">J = min ? ? L ? followed by --------? J = min ?={? ?? ,? ? } L ?<label>(11)</label></formula><p>Pre-trained Transformer (e.g., GPT-2)</p><p>Pre-trained Transformer (e.g., GPT-2) </p><formula xml:id="formula_23">Linear Layer ? ? 2 ? ? 3 &lt; ? ???&gt; &lt;???&gt; ? ? 2 ? ? 1 ? ?,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recommendation as Regularization</head><p>User Item Fig. <ref type="figure">5</ref>. Our proposed method PEPLER that regards the rating prediction task as a type of regularization for better learning of the explanation generation task.</p><p>In fact, our sequential tuning strategy is a combination of two typical tuning strategies <ref type="bibr" target="#b34">[35]</ref>: Fixed-LM Prompt Tuning and Prompt+LM Fine-tuning (see Table <ref type="table">3</ref>). In section 5.2, we conduct an effect comparison to prove that this strategy is indeed more useful than either of them. We omit the other three strategies, i.e., Promptless Fine-tuning, Tuning-free Prompting and Fixed-prompt LM Tuning. The first is usually used in pre-training plus fine-tuning paradigm, and the second is particularly suitable for zero-shot learning scenario, so they are not applicable to our methods. The last one is adopted in our PEPLER-D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Recommendation as Regularization</head><p>To bridge the aforementioned gap between pre-trained language models and continuous prompts, we come up with another approach: regularizing the learning of explanation generation via an additional rating prediction task (see Fig. <ref type="figure">5</ref>). The intuition behind this idea is that each rating score ? ?,? was assigned by a user ? to an item ?, so it to some extent captures the relation between this user-item pair. Hence, the ratings could be used to better learn the continuous prompts. Moreover, recent studies find out that the two task of recommendation and an additional task (such as feature ranking <ref type="bibr" target="#b10">[11]</ref>, explanation ranking <ref type="bibr" target="#b27">[28]</ref> and review generation <ref type="bibr" target="#b46">[47]</ref>) could help the learning of each other. Inspired by this, we propose to leverage recommendation task to help the learning of explanation generation. Since there is a great number of off-the-shelf recommendation models and our key focus is on explanation generation, we adopt and test two typical recommendation models: Matrix Factorization (MF) <ref type="bibr" target="#b38">[39]</ref> and Multi-Layer Perceptron (MLP) <ref type="bibr" target="#b30">[31]</ref>.</p><p>Specifically, for MF the rating score r?,? is resulted from the dot product of the target user and item's representations u and i:</p><formula xml:id="formula_24">r?,? = u ? i<label>(12)</label></formula><p>Because the two types of representations are already available, this operation does not introduce additional model parameters. In the case of MLP with ? hidden layers, the rating score is computed </p><formula xml:id="formula_25">? ? ? ? ? ? ? ? ? ? ? a 0 = ? (W 0 [u, i] + b 0 ) a 1 = ? (W 1 a 0 + b 1 ) . . . . . . and r?,? = w ? a ? + ? a ? = ? (W ? a ? -1 + b ? ) (13)</formula><p>where</p><formula xml:id="formula_26">W 0 ? R ? ? ?2? , b 0 ? R ? ? , W * ? R ? ? ?? ? , b * ? R ? ? , w ? R ? ? , b ? ? R</formula><p>are additional parameters for the recommendation task, and ? (?) denotes the sigmoid function. For both MF and MLP, mean square error is adopted as the loss function:</p><formula xml:id="formula_27">L ? = 1 |T | ?? (?,?) ? T (? ?,? -r?,? ) 2<label>(14)</label></formula><p>where ? ?,? is the ground-truth rating that user ? assigned to item ?.</p><p>Then, the two tasks can be integrated into a multi-task learning framework with the following objective function:</p><formula xml:id="formula_28">J = min ?={? ?? ,? ? ,? ??? } (L ? + ?L ? )<label>(15)</label></formula><p>where the model parameters ? consist of pre-trained language model parameters ? ?? , continuous prompt parameters ? ? (i.e., user and item representations) and recommendation model parameters ? ??? (? for MF). Since the recommendation task is used as a regularization term, we can adjust the regularization coefficient ? to control the learning of the explanation generation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL SETUP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>For experimentation, we adopt three publicly available explainable recommendation datasets, and their data splits <ref type="bibr" target="#b25">[26]</ref>. During the splitting process, each dataset is randomly divided into training, validation and testing sets with ratio 8:1:1 for 5 times, and the training set holds at least one record for each user and each item. The three datasets are respectively from TripAdvisor<ref type="foot" target="#foot_4">4</ref> (hotel), Amazon<ref type="foot" target="#foot_5">5</ref> (movies &amp; TV) and Yelp<ref type="foot" target="#foot_6">6</ref> (restaurant). Each record in the datasets is comprised of a user ID, an item ID, a rating in the scale of 1 to 5, an explanation and a feature. The explanations are sentences extracted from user reviews. Each explanation contains at least one item feature, e.g., "bedroom", which ensures the explanation quality. Statistics of the datasets are shown in Table <ref type="table" target="#tab_6">4</ref>. We can see that Yelp is much larger than the other two in terms of size, making it closer to the real-world situation where there are millions of users and items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Metrics</head><p>To evaluate explanation performance, we measure the generated explanations from two main perspectives: text quality and explainability. For the former, we adopt BLEU <ref type="bibr" target="#b40">[41]</ref> in machine translation and ROUGE <ref type="bibr" target="#b33">[34]</ref> in text summarization, and report BLEU-1 and BLEU-4, and Precision, Recall and F1 of ROUGE-1 and ROUGE-2. Notice that, BLEU is a precision-oriented metric, while ROUGE is a recall-oriented metric. Though being widely used, BLUE and ROUGE are not flawless. For example, it is difficult for them to detect the problem of identical sentences, i.e., many explanations for different user-item pairs are exactly the same for some methods, as shown in our experiments. Treating these identical sentences as explanations is less appropriate, because they are less likely to well explain the special property of different recommendations. To quantitatively measure this, we adopt USR that computes the Unique Sentence Ratio of generated explanations <ref type="bibr" target="#b25">[26]</ref>:</p><formula xml:id="formula_29">? ?? = |E | ? (<label>16</label></formula><formula xml:id="formula_30">)</formula><p>where E represents the set of unique sentences generated by a model, and ? is the total number of testing samples. Note that, E only holds one of the exactly matched explanations.</p><p>Moreover, text quality is not equal to explainbility. In the case of explainable recommendation, users may value more an explanation that justifies a recommendation's advantage on certain item features <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">26]</ref>. To this end, we adopt the other three metrics proposed in <ref type="bibr" target="#b25">[26]</ref>: Feature Matching Ratio (FMR), Feature Coverage Ratio (FCR) and Feature Diversity (DIV).</p><p>FMR measures whether a generated explanation contains the feature in the ground-truth text. Formally, it is defined as follows:</p><formula xml:id="formula_31">? ?? = 1 ? ?? ?,? ? (? ?,? ? ??,? )<label>(17)</label></formula><p>where ??,? is the generated explanation for the user-item pair, ? ?,? is the feature in the ground-truth, and ? (?) = 1 when ? is true, or ? (?) = 0 otherwise. FCR is computed as the number of distinct features contained in all the generated explanations, divided by the total number of features in the whole dataset:</p><formula xml:id="formula_32">??? = ? ? |F | (<label>18</label></formula><formula xml:id="formula_33">)</formula><p>where F is the collection of unique features in ground-truth explanations, and ? ? denotes the amount of distinct features appeared in the generated explanations. DIV measures the diversity of features between all generated explanations. The intuition is that explanations are expected to discuss different features in accordance with the given user-item pairs. Hence, it computes the intersection of features between any two generated explanations:</p><formula xml:id="formula_34">??? = 2 ? ? (? -1) ?? ?,? ? ,?,? ? F?,? ? F? ? ,? ?<label>(19)</label></formula><p>where F?,? and F? ? ,? ? represent two feature sets respectively contained in two generated explanations, and |?| denotes the number of features in the resulting set.</p><p>For DIV, the lower, the better, while it is opposite for the rest of metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Compared Methods</head><p>We introduce four state-of-the-art baselines, which are based on representative language models, including BERT <ref type="bibr" target="#b14">[15]</ref>, Transformer <ref type="bibr" target="#b52">[53]</ref>, GRU <ref type="bibr" target="#b13">[14]</ref> and LSTM <ref type="bibr" target="#b21">[22]</ref>, respectively. We divide them into two groups, depending on whether IDs are directly used or not. We first compare our PEPLER-D with the following method, because both of them do not directly make use of IDs but instead map IDs onto item features.</p><p>? Aspect Conditional Masked Language Model (ACMLM) <ref type="bibr" target="#b39">[40]</ref> is a fine-tuned BERT <ref type="bibr" target="#b14">[15]</ref>, where an attention layer is introduced to encode the features for both the user and the item. By predicting masked tokens, this model can produce diverse sentences. Then, we make comparison with the following three methods for our PEPLER, since they all leverage only user and item IDs to generate explanations.</p><p>? Neural Rating and Tips generation (NRT) <ref type="bibr" target="#b30">[31]</ref> can predict a rating and generate a tip simultaneously based on user and item IDs. The generation component is a GRU <ref type="bibr" target="#b13">[14]</ref>. We take the explanations in the datasets as tips. Moreover, we find that the model's problem of generating identical sentences (as reported in <ref type="bibr" target="#b25">[26]</ref>) is caused by the L2 regularization in its original design. For fair comparison, we remove it. ? Attribute-to-Sequence (Att2Seq) <ref type="bibr" target="#b15">[16]</ref> is a review generation approach with a two-layer LSTM <ref type="bibr" target="#b21">[22]</ref>. We take the explanations as reviews. This model has an attention module, but we find that it makes the generated content unreadable. To be fair, we remove it as well. ? PErsonalized Transformer for Explainable Recommendation (PETER) <ref type="bibr" target="#b28">[29]</ref> is a small unpretrained Transformer <ref type="bibr" target="#b52">[53]</ref> particularly designed for explanation generation. To bridge the gap between IDs and words, an additional task named "context prediction" is introduced. This model can also make recommendations. We omit the comparison with our previous work NETE <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref>, since it is outperformed by PETER. Moreover, we conduct a user survey <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref> and show that the explanations generated by NETE are perceived useful by most participants. Hence, as long as the explanations produced by our approaches in this work are of better quality on the automatic metrics than PETER's, they could as well be very useful to real users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Implementation Details</head><p>We train each model on the training set, tune the hyper-parameters on the validation set, and report the performance on the testing set. The results are averaged on the 5 data splits. We adopt the code of ACMLM, and implement the other baselines (i.e., NRT, Att2Seq and PETER) by ourselves. For our models PEPLER and PEPLER-D, we implement them in Python<ref type="foot" target="#foot_7">7</ref> with PyTorch<ref type="foot" target="#foot_8">8</ref> , and load pre-trained GPT-2 <ref type="bibr" target="#b42">[43]</ref> from huggingface<ref type="foot" target="#foot_9">9</ref> as their backbone. GPT-2 uses Byte Pair Encoding (BPE) <ref type="bibr" target="#b43">[44]</ref> for vocabulary construction. This technique could effectively mitigate Out-Of-Vocabulary (OOV) problem by encoding rare words into multiple sub-word units. For example, the word "restaurant" is encoded into three sub-words "rest", "aur" and "ant", while the word "room" is still "room". In total, there are 50,257 BPE tokens in GPT-2. For fair comparison, we apply BPE to all the models, and set the length of explanations to 20 BPE tokens. For our model PEPLER-D, the number of input features is also set to 20 BPE tokens. We reuse the other default settings of the baselines.</p><p>The size of embeddings/representations ? in GPT-2 is 768. We optimize our models PEPLER and PEPLER-D with AdamW <ref type="bibr" target="#b37">[38]</ref>, and set batch size to 128. The learning rate is set to 0.001 for PEPLER, and 0.0001 for PEPLER-D. At each epoch, we save the model if it achieves the lowest loss on the validation set, but when the loss does not decrease for 5 times, we stop training and load the saved model for prediction. In the case of recommendation as regularization in PEPLER, the number of hidden layers ? in MLP is set to 2, and the dimension of hidden layers ? ? 400. We search the regularization coefficient ? from [10 -3 , 10 -2 , ..., 10 3 ]. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS AND ANALYSIS</head><p>In this section, we first quantitatively compare the performance of different explanation methods with automatic metrics. Then, we further study the effect of our proposed two training strategies. At last, we qualitatively examine two explanation samples as generated by all the methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Quantitative Analysis on Explanations</head><p>The performance comparison between different explanation generation methods is shown in Table <ref type="table" target="#tab_8">5</ref>. These methods are divided into two groups. We first examine those that map IDs onto item features, i.e., ACMLM and PEPLER-D. Our PEPLER-D consistently and significantly outperforms ACMLM on the three datasets in terms of text quality measured by BLEU and ROUGE. This demonstrates its effectiveness in generating high-quality sentences that are semantically close to the ground-truth text. Also, we notice that the performance gap between our PEPLER-D and ACMLM (a fine-tuned BERT) is extremely large, because the latter's generation is achieved by predicting masked tokens, which is quite different from conventional auto-regressive generation. This may explain why ACMLM produces diverse sentences (high USR) and features (low DIV), which, however, is less meaningful when text quality cannot be guaranteed. Next, we analyze the results of models that directly leverage user and item IDs for explanation generation, i.e., NRT, Att2Seq, PETER and PEPLER. As we can see, the text quality of these methods are largely improved compared with those that convert IDs into item features, because the conversion process may lose certain information of IDs, e.g., identification. Among the four ID-based methods, NRT and Att2Seq generally achieve the same performance on all metrics, but neither of them are as comparable as PETER and PEPLER. Because NRT and Att2Seq are based on recurrent neural networks (i.e., GRU or LSTM), they may suffer from the notorious long-term dependency problem, and thus their sequence modeling capability could be impaired. As a comparison, PETER and PEPLER do not have such an issue, since in Transformer future tokens at any time step are given access to all the past tokens. Moreover, given the fact that PETER is a small unpretrained Transformer, it does not outperform PEPLER that is pre-trained on large textual corpora and hence possesses rich linguistic knowledge. In the meantime, it proves the rationale of our continuous prompt learning approach and the sequential tuning strategy that could effectively make use of such knowledge for generating better explanations.</p><p>We also observe some special cases on the TripAdvisor dataset, where Att2Seq obtains the largest ROUGE scores. The reasons are as follows. First, we fix its generation issue (see the discussion in Section 4.3), which makes it a competitive baseline. Second, the dataset is quite small and thus the training samples are limited, so our large model may underfit. This is not a problem in real-world applications where there are abundant training samples (e.g., in e-commerce), since our model already achieves the best performance regarding all metrics on the largest dataset Yelp, which has approximately 1.3 million samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Effect of Sequential Tuning</head><p>To validate the superiority of our proposed Sequential Tuning strategy, we compare it with its two composite training strategies: Fixed-LM Prompt Tuning and Prompt+LM Fine-tuning <ref type="bibr" target="#b34">[35]</ref>. The results of Sequential Tuning (utilized in PEPLER) on the three datasets are presented in Table <ref type="table" target="#tab_8">5</ref>. Given the consistent performance across different datasets and metrics, in Fig. <ref type="figure" target="#fig_3">6</ref> we only show BLEU-4 with varied learning rates on the TripAdvisor dataset.</p><p>As it can be seen, the highest BLEU-4 score is achieved by our Sequential Tuning strategy (purple), when the learning rate is set to 10 -3 . This manifests its advantage in bridging the gap between the randomly initialized continuous prompts and the pre-trained language model. In particular, the pattern of our Sequential Tuning and that of Prompt+LM Fine-tuning (green) is quite similar, because they tune all the model parameters, including both prompts and the pre-trained model.</p><p>Obviously, the curve of our Sequential Tuning is on the top of that of Prompt+LM Fine-tuning. The difference is that the former's prompts are already trained, which could help to reduce the gap between prompts and the pre-trained model. This supports the rationale of our two-staged Sequential Tuning strategy. Moreover, when the learning rate is large (i.e., 10 -2 ), the performance of both strategies goes down dramatically, nearly reaching 0, because large learning rates lead to significant changes of parameters in the pre-trained model. Hence, smaller learning rates are more appreciated to fine-tuning. In contrast, the performance of Fixed-LM Prompt Tuning (brown) is relatively stable, regardless of the changing learning rates. However, it does not outperform the other two strategies, because the model is frozen and only prompts can be tuned, and therefore could not be well adjusted to the target explanation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Effect of Recommendation as Regularization</head><p>In this work, we propose two training strategies to bridge continuous prompts and the pre-trained model, including sequential tuning and recommendation as regularization. We analyze the latter in more details, because the former is already presented in the previous subsection.</p><p>To begin with, we make a comparison for the two types of strategy in Table <ref type="table" target="#tab_9">6</ref>. The default PEPLER employs sequential tuning, while the other two methods utilize recommendation as regularization with respectively MF (denoted as PEPLER+MF) and MLP (represented by PEPLER+MLP). Compared with PEPLER, PEPLER+MF not only improves the text quality but also explainability. In the meantime, PEPLER+MLP maintains comparable text quality to PEPLER, but cannot keep up the explainability, e.g., the decreasing in FCR and USR. This could be explained by the difference between MF and MLP in terms of additional parameters for recommendation. For MF, the prediction is made simply by the dot product between user and item embeddings, in which case no additional parameters are involved. In contrast, MLP must go through a stack of hidden layers that consist of many parameters, which might help to predict ratings but adversely affect the learning of the explanation task. Since the recommendation task requires extra rating data for training, which may not be always available in other natural language generation tasks (e.g., dialogue systems), we set sequential tuning as the default training strategy for PEPLER. This strategy needs more training epochs, because it has two stages. Depending on the specific application, one may consider PEPLER+MF.  Furthermore, in Fig. <ref type="figure" target="#fig_4">7</ref> we investigate how PEPLER+MF and PEPLER+MLP react to varying ?, the regularization coefficient on the recommendation task. For better comparison, PETER is included since it is the previous state-of-the-art, and can also perform rating prediction. The accuracy of this task is measured by root mean square error (RMSE), and a lower score indicates a better performance. By comparing the two sub-figures, we can clearly see that there is a trade-off between explanation performance (evaluated by BLEU-4) and recommendation performance (measured by RMSE) for both PEPLER+MF and PEPLER+MLP. For example, generally when ? is no greater than 1, the explanation performance could always reach an optimal point (e.g., when ? = 10 -2 for PEPLER+MF), but the recommendation performance could be greatly deteriorated. It actually supports our design of this training strategy that leverages the recommendation task to help the learning of explanation generation. We notice that there is a huge gap between PEPLER+MF and PEPLER+MLP in terms of recommendation accuracy. Owing to the linearity of MF, its representation ability could be largely limited <ref type="bibr" target="#b20">[21]</ref>, and thus could not accurately estimate the ratings. But because of the simple dot product operation, the relation between users and items encoded in ratings could in turn be easily propagated to the explanation task for better learning. Since the purpose of PEPLER+MF is not to make recommendations, when deploying it for real-world applications, one can prepare an extra effective recommendation model, e.g., neural matrix factorization <ref type="bibr" target="#b20">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Qualitative Case Study on Explanations</head><p>In Table <ref type="table" target="#tab_10">7</ref>, we present two examples generated by all the methods for hotel recommendations on the TripAdvisor dataset. In the first case, the ground-truth explanation gives a positive comment about the hotel's swimming "pool". Only two methods, i.e., ACMLM and our PEPLER, successfully capture Ground-truth the swimming pool is fantastic ACMLM swimming pool swimming pools pool strip beach area NRT the hotel is located in a great location Att2Seq the hotel is located in the heart of the city and the main shopping area is also within walking distance PETER the hotel is located in the heart of the city and the harbour PEPLER-D the room was very nice and the bed was very comfortable PEPLER the pool is amazing and the pool is very relaxing Ground-truth this is one of the finest hotels in all of Europe ACMLM swimming pool area pool ja ##cu ##zzi pool city area gym building pool area spa gym pool area NRT the hotel is located in a great location Att2Seq the hotel is located in the heart of the city and the main shopping area is also within walking distance PETER the hotel is in a great location PEPLER-D the hotel is a short walk from the old town PEPLER the hotel is located in the heart of the city and is very well maintained this key feature. However, ACMLM's explanation is not even readable, because it is just a bunch of unordered random words. These meaningless explanations are not very likely to be useful to real users. As a comparison, the explanations generated by the other approaches are all readable and fluent. This actually echoes their performances on BLEU and ROUGE, which emphasize more text quality and readability. But BLEU and ROUGE are not perfect, because it fails to detect the problem of identical explanations (see the same sentences generated by NRT or Att2Seq for two different cases). This is why we also adopt some explainability metrics <ref type="bibr" target="#b25">[26]</ref> that particularly care about item features and sentence diversity. Moreover, Att2Seq tends to generate long explanations, which may explain why it obtains good performance regarding ROUGE on the TripAdvisor dataset (see Table <ref type="table" target="#tab_8">5</ref>), because ROUGE is a recall-oriented metric and favors long sentences. The explanations generated by the other three approaches, i.e., PETER, PEPLER-D and PEPLER, are quite good, because they all adopt the Transformer model, which has strong language modeling capability. Despite of that, the explanations from our PEPLER are semantically closer to the ground-truth. Taking the second case as an example, the ground-truth explanation evaluates the overall quality of the hotel ("one of the finest hotels"), but PETER and PEPLER-D respectively talks about location ("great location") and distance ("short walk"), while our PEPLER comments about not only the hotel's location ("located in the heart of city") but also its quality ("well maintained"). We attribute this to the effectiveness of our proposed continuous prompt learning and the sequential tuning strategy. Moreover, we see that the expression of PEPLER's explanations is quite rich, which could be brought by the linguistic knowledge contained in the pre-trained model, as it is already trained on large text corpora.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this work, we propose two prompt learning approaches to exploit the rich knowledge contained in pre-trained language models for recommendation explanation generation. To bridge the gap between continuous prompts and pre-trained models, we come up with two effective learning strategies. Extensive experiments demonstrate the effectiveness of our approaches in generating high-quality explanations as measured by text quality and explainability metrics.</p><p>As future works, we are immensely interested in whether the generated explanations possess bias or stereotype against certain social groups and how to mitigate them, as reported in recent studies <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b44">45]</ref> that pre-trained models exhibit societal bias towards different groups of people. Besides explanation generation for recommender systems, we also plan to adopt our approaches to other applications of personalized natural language generation, such as personalized question answering systems and personalized conversational agents. Moreover, it would also be interesting to incorporate item images into pre-trained models to generate visual explanations for recommendations, since "a picture is worth a thousand words". Another meaningful extension is to adapt pre-trained models to cross-lingual explanation generation, since international platforms, e.g., Amazon, may serve users who speak different languages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. A review example from Yelp. The user and the restaurant are omitted for privacy protection.</figDesc><graphic url="image-1.png" coords="2,119.44,84.68,247.13,118.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. A comparison between left-to-right unidirectional attention masking (left) and bidirectional attention masking (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>[u, i, e 1 , ? ? ? , e |??,? | ]. The follow-up steps are identical to discrete prompt learning in Section 3.2: performing addition for token representation and positional representation to obtain S 0 = [s 0,1 , ? ? ? , s 0, |? | ], passing S 0 through pre-trained Transformer for producing S ? = [s ?,1 , ? ? ? , s ?, |? | ], applying a linear layer with softmax function to each token's final representation s ?,? for next-word prediction, and employing NLL loss function on the word probability distribution c ? :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. A comparison of three tuning strategies for prompt learning in terms of BLEU-4 with varying learning rates on the TripAdvisor dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. The effect of regularization coefficient ? on the recommendation task with MF or MLP for PEPLER on the TripAdvisor dataset. For better comparison, the results of PETER are shown.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Key notations and concepts.</figDesc><table><row><cell>Symbol</cell><cell>Description</cell></row><row><cell>T</cell><cell>training set</cell></row><row><cell>U</cell><cell>set of users</cell></row><row><cell>I</cell><cell>set of items</cell></row><row><cell>V</cell><cell>set of words</cell></row><row><cell>F</cell><cell>set of features</cell></row><row><cell>E</cell><cell>set of explanations</cell></row><row><cell>U</cell><cell>embeddings of users</cell></row><row><cell>I</cell><cell>embeddings of items</cell></row><row><cell>u</cell><cell>embedding of user ?</cell></row><row><cell>i</cell><cell>embedding of item ?</cell></row><row><cell>c</cell><cell>probability distribution over the vocabulary</cell></row><row><cell>W</cell><cell>weight matrix</cell></row><row><cell>w, b</cell><cell>weight vector</cell></row><row><cell>?</cell><cell>weight scalar</cell></row><row><cell>M</cell><cell>attention masking matrix</cell></row><row><cell>?</cell><cell>model parameters</cell></row><row><cell>?</cell><cell>word sequence of an explanation</cell></row><row><cell>?, ? ? ? , ? ?</cell><cell>dimension of representation</cell></row><row><cell>?</cell><cell>number of attention heads</cell></row><row><cell>?</cell><cell>number of Transformer layers</cell></row><row><cell>?</cell><cell>number of MLP hidden layers</cell></row><row><cell>ReLU(?)</cell><cell>ReLU activation function</cell></row><row><cell>? (?)</cell><cell>sigmoid activation function</cell></row><row><cell cols="2">softmax(?) softmax function</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>consists of ? identical layers. The ?-th layer encodes the previous layer's output S ?-1 into S ? ? R |? |?? , where ? ? [1, ?], |? | is the length of the input token sequence,</figDesc><table><row><cell></cell><cell></cell><cell>Prevent from attending</cell><cell>Allow to attend</cell></row><row><cell></cell><cell></cell><cell>Source</cell><cell>Source</cell></row><row><cell></cell><cell>? 1</cell><cell>? 2 ? 3 ? 4 ? 5 ? 6 ? 7</cell><cell>? 1 ? 2 ? 3 ? 4 ? 5 ? 6 ? 7</cell></row><row><cell></cell><cell>? 1</cell><cell></cell><cell>? 1</cell></row><row><cell></cell><cell>? 2</cell><cell></cell><cell>? 2</cell></row><row><cell>Target</cell><cell>? 3 ? 4</cell><cell>Target</cell><cell>? 3 ? 4</cell></row><row><cell></cell><cell>? 5</cell><cell></cell><cell>? 5</cell></row><row><cell></cell><cell>? 6</cell><cell></cell><cell>? 6</cell></row><row><cell></cell><cell>? 7</cell><cell></cell><cell>? 7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Our proposed method PEPLER that treats user and item IDs as continuous prompt for explanation generation.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="3">Explanation Generation</cell></row><row><cell></cell><cell></cell><cell></cell><cell>? ? 1</cell><cell cols="2">? ? 2</cell><cell>? ? 3 &lt; ? ???&gt;</cell></row><row><cell>Million or even billion-scale</cell><cell></cell><cell></cell><cell cols="2">Linear Layer</cell></row><row><cell>users and items</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">? ?,1 ? ?,2</cell><cell cols="2">? ?,3 ? ?,4</cell><cell>? ?,5 ? ?,6</cell></row><row><cell>Item</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">Pre-trained Transformer (e.g., GPT-2)</cell></row><row><cell>User</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">Pre-trained Transformer (e.g., GPT-2)</cell></row><row><cell></cell><cell>?</cell><cell>?</cell><cell>&lt;???&gt;</cell><cell>? ? 1</cell><cell>? ? 2 ? 3 ?</cell></row><row><cell>Embedding Look-up</cell><cell cols="3">Continuous Prompt</cell><cell cols="2">Explanation</cell></row><row><cell>Fig. 4.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>the set of all generated word sequences, and |?????? | denotes the prompt's length, i.e., 2 for [?, ?] and ? ?,? for ? ?,? .</figDesc><table><row><cell></cell><cell cols="3">LM Para. Prompt Para. Typical Example</cell></row><row><cell>Promptless Fine-tuning</cell><cell>Tuned</cell><cell>N/A</cell><cell>BERT [15]</cell></row><row><cell>Tuning-free Prompting</cell><cell>Frozen</cell><cell>None</cell><cell>GPT-3 [4]</cell></row><row><cell>Fixed-LM Prompt Tuning</cell><cell>Frozen</cell><cell>Tuned</cell><cell>Prefix-Tuning [32]</cell></row><row><cell>Fixed-prompt LM Tuning</cell><cell>Tuned</cell><cell>None</cell><cell>Our PEPLER-D</cell></row><row><cell>Prompt+LM Fine-tuning</cell><cell>Tuned</cell><cell>Tuned</cell><cell>P-Tuning [37]</cell></row><row><cell>Sequential Tuning: Fixed-LM Prompt Tuning ? Prompt+LM Fine-tuning</cell><cell>Tuned</cell><cell>Tuned Twice</cell><cell>Our PEPLER</cell></row><row><cell>where ? is</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 .</head><label>4</label><figDesc>Statistics of the three datasets.</figDesc><table><row><cell></cell><cell cols="2">TripAdvisor Amazon</cell><cell>Yelp</cell></row><row><cell>#users</cell><cell>9,765</cell><cell>7,506</cell><cell>27,147</cell></row><row><cell>#items</cell><cell>6,280</cell><cell>7,360</cell><cell>20,266</cell></row><row><cell>#records</cell><cell>320,023</cell><cell cols="2">441,783 1,293,247</cell></row><row><cell>#features</cell><cell>5,069</cell><cell>5,399</cell><cell>7,340</cell></row><row><cell>#records / user</cell><cell>32.77</cell><cell>58.86</cell><cell>47.64</cell></row><row><cell>#records / item</cell><cell>50.96</cell><cell>60.02</cell><cell>63.81</cell></row><row><cell>#words / explanation</cell><cell>13.01</cell><cell>14.14</cell><cell>12.32</cell></row><row><cell>as follows:</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 .</head><label>5</label><figDesc>Performance comparison of explanation generation methods in terms of Explainability and Text Quality on three datasets. The methods are divided into two groups according to whether IDs are directly used or not. B1 and B4 stand for BLEU-1 and BLEU-4. R1-P, R1-R, R1-F, R2-P, R2-R and R2-F denote Precision, Recall and F1 of ROUGE-1 and ROUGE-2. BLEU and ROUGE are percentage values (% symbol omitted for table clarity), while the others are absolute values. The best performing values are boldfaced, and ** and * indicate the statistical significance over the second best baseline respectively for</figDesc><table><row><cell>and ? &lt; 0.05 via Student's t-test.</cell><cell>Explainability Text Quality</cell><cell>FMR? FCR? DIV? USR? B1? B4? R1-P? R1-R? R1-F? R2-P? R2-R? R2-F?</cell><cell>Yelp</cell><cell>ACMLM 0.05 0.31 0.95 0.95 7.01 0.24 7.89 7.54 6.82 0.44 0.48 0.39</cell><cell>PEPLER-D 0.05 0.24 1.53 0.13 9.17** 0.40** 15.67** 10.47** 11.73** 1.09** 0.78** 0.83**</cell><cell>NRT 0.06 0.12 1.67 0.20 10.92 0.60 16.73 11.91 12.89 1.63 1.21 1.26</cell><cell>Att2Seq 0.05 0.05 2.25 0.05 10.25 0.54 17.13 11.44 12.72 1.49 1.13 1.16</cell><cell>PETER 0.08 0.15 1.62 0.15 10.74 0.63 16.18 11.90 12.63 1.60 1.32 1.28</cell><cell>PEPLER 0.08** 0.30** 1.52 0.35** 11.23 0.73** 17.51 12.55* 13.53** 1.86* 1.42 1.46**</cell><cell>Amazon</cell><cell>ACMLM 0.10 0.31 2.07 0.96 9.52 0.22 11.65 10.39 9.69 0.71 0.81 0.64</cell><cell>PEPLER-D 0.08 0.19 1.85* 0.15 10.94** 0.49** 16.31** 11.80** 12.80** 1.43** 1.13** 1.16**</cell><cell>NRT 0.10 0.04 2.71 0.09 12.06 0.69 17.17 13.15 13.83 1.94 1.68 1.64</cell><cell>Att2Seq 0.09 0.04 2.64 0.05 12.07 0.73 18.35 12.86 14.14 2.01 1.56 1.61</cell><cell>PETER 0.09 0.09 2.16 0.20 11.75 0.89 16.51 13.10 13.55 1.96 1.76 1.68</cell><cell>PEPLER 0.11 0.27** 2.06 0.38** 13.19* 1.05** 18.51 14.16 14.87 2.36* 1.88 1.91**</cell><cell>TripAdvisor</cell><cell>ACMLM 0.07 0.41 0.78 0.94 3.45 0.02 4.86 3.82 3.72 0.18 0.20 0.16</cell><cell>PEPLER-D 0.05 0.22 2.69 0.08 14.61** 0.87** 18.07** 14.83** 15.32** 1.76** 1.66** 1.58**</cell><cell>NRT 0.05 0.02 6.07 0.00 13.76 0.80 19.01 14.57 15.58 2.10 1.59 1.68</cell><cell>Att2Seq 0.06 0.05 4.74 0.02 15.20 0.96 18.74 16.42 16.38 2.42 2.32 2.19</cell><cell>PETER 0.07 0.09 3.62 0.05 15.13 1.00 18.30 16.15 16.00 2.24 2.23 2.06</cell><cell>PEPLER 0.07* 0.21** 2.71** 0.24** 15.49 1.09 19.48 15.67 16.24 2.48 2.21 2.16</cell></row><row><cell>0.01</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>? &lt;</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 .</head><label>6</label><figDesc>Comparison of our proposed two strategies for continuous prompt learning on the TripAdvisor dataset. PEPLER employs the default sequential tuning, while the other two methods use recommendation as regularization with MF and MLP respectively. "Rec Para. " stands for additional parameters for recommendation. Arrows ? and ? respectively denote the performance increase and decrease compared with PEPLER.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Explainability</cell><cell></cell><cell cols="4">Text Quality</cell><cell></cell><cell>Training</cell></row><row><cell></cell><cell></cell><cell cols="9">FMR FCR DIV USR BLEU-1 BLEU-4 Epoch Rating Rec Para.</cell></row><row><cell>PEPLER</cell><cell></cell><cell cols="5">0.07 0.21 2.71 0.24 15.49</cell><cell cols="2">1.09</cell><cell>17</cell><cell>No</cell><cell>No</cell></row><row><cell cols="2">PEPLER+MF</cell><cell cols="5">0.08? 0.26? 3.00? 0.29? 16.67?</cell><cell cols="2">1.27?</cell><cell>10</cell><cell>Yes</cell><cell>No</cell></row><row><cell cols="7">PEPLER+MLP 0.07 0.09? 3.36? 0.07? 16.05?</cell><cell cols="2">1.09</cell><cell>8</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell></cell><cell>1.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.6</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.4</cell><cell></cell><cell></cell><cell></cell></row><row><cell>BLEU-4</cell><cell>0.7 0.8 1.0 0.9</cell><cell cols="2">PEPLER+MF PETER PEPLER+MLP</cell><cell></cell><cell>RMSE</cell><cell>1.2 0.8 1.0</cell><cell></cell><cell></cell><cell>PEPLER+MF PEPLER+MLP PETER</cell></row><row><cell></cell><cell>10 3</cell><cell>10 2</cell><cell>0.1 Regularization Coefficient 1 10</cell><cell>10 2</cell><cell>10 3</cell><cell>10 3</cell><cell>10 2</cell><cell cols="2">0.1 Regularization Coefficient 1 10</cell><cell>10 2</cell><cell>10 3</cell></row><row><cell></cell><cell></cell><cell cols="2">(a) BLEU-4 with varying ?</cell><cell></cell><cell></cell><cell></cell><cell cols="4">(b) RMSE with varying ?</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 .</head><label>7</label><figDesc>Explanations on two different cases as generated by different methods on the TripAdvisor dataset. The boldfaced words in the ground-truth are the key features. Matched features in the generated explanations are also boldfaced.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>J. ACM, Vol. 37, No. 4, Article 111. Publication date: February 2022.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>Codes are available at https://github.com/lileipisces/PEPLER</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>It is an excerpt from a dialogue in a famous French novella The Little Prince. The complete dialogue is "Il y a une fleur. Je crois qu'elle m'a apprivois?", meaning "There is a flower. I think that she has tamed me".</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>"TL;DR" stands for "Too Long; Did/Do not Read".</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>https://www.tripadvisor.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5"><p>http://jmcauley.ucsd.edu/data/amazon</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6"><p>https://www.yelp.com/dataset/challenge</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_7"><p>https://www.python.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_8"><p>https://pytorch.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_9"><p>https://huggingface.co/gpt2</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning heterogeneous knowledge base embeddings for explainable recommendation</title>
		<author>
			<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vahid</forename><surname>Azizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithms</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">137</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A convergence theory for deep learning via over-parameterization</title>
		<author>
			<persName><forename type="first">Zeyuan</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Song</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="242" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">PADA: A Prompt-based Autoregressive Approach for Adaptation to Unseen Domains</title>
		<author>
			<persName><forename type="first">Eyal</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadav</forename><surname>Oved</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tom B Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural attentional rating regression with review-level explanations</title>
		<author>
			<persName><forename type="first">Chong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 World Wide Web Conference</title>
		<meeting>the 2018 World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1583" to="1592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generate natural language explanations for recommendation</title>
		<author>
			<persName><forename type="first">Hanxiong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoyun</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR&apos;19 Workshop on ExplainAble Recommendation and Search</title>
		<meeting>SIGIR&apos;19 Workshop on ExplainAble Recommendation and Search</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural Collaborative Reasoning</title>
		<author>
			<persName><forename type="first">Hanxiong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoyun</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunqi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference</title>
		<meeting>The Web Conference</meeting>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Explaining recommendations based on feature sentiments in product reviews</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Intelligent User Interfaces</title>
		<meeting>the 22nd International Conference on Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="17" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">User evaluations on sentiment-based recommendation explanations</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongning</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Interactive Intelligent Systems (TiiS)</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Personalized fashion recommendation with visual explanations based on multimodal attention network: Towards visually explainable recommendation</title>
		<author>
			<persName><forename type="first">Hanxiong</forename><surname>Xu Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongteng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyuan</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="765" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning to rank features for recommendation over multiple categories</title>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Xu Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 39th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="305" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dynamic explainable recommendation based on neural attentive models</title>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Xu Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="53" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Co-Attentive Multi-Task Learning for Explainable Recommendation</title>
		<author>
			<persName><forename type="first">Zhongxia</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiting</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoqing</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yining</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2137" to="2143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</title>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Van Merri?nboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning to generate product reviews from attributes</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaohan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="623" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Unified language model pre-training for natural language understanding and generation</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hsiao-Wuen</forename><surname>Hon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="13063" to="13075" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fairness-Aware Explainable Recommendation over Knowledge Graphs</title>
		<author>
			<persName><forename type="first">Zuohui</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yikun</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruoyuan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaoying</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingqiang</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijie</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chirag</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">How should I explain? A comparison of different explanation types for recommender systems</title>
		<author>
			<persName><forename type="first">Fatih</forename><surname>Gedikli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dietmar</forename><surname>Jannach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mouzhi</forename><surname>Ge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="367" to="382" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Trirank: Review-aware explainable recommendation by modeling aspects</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1661" to="1670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural collaborative filtering</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Towards personalized review summarization via user-aware sequence network</title>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoran</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6690" to="6697" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">CAESAR: context-aware explanation based on supervised attention for service recommendations</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruihai</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Information Systems</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="147" to="170" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Towards Controllable Explanation Generation for Recommender Systems via Neural Template</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of the Web Conference</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="198" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Generate neural template explanations for recommendation</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 29th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="755" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">EXTRA: Explanation Ranking Datasets for Explainable Recommendation</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 44th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2463" to="2469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">On the Relationship between Explanation and Recommendation: Learning to Rank Explanations for Improved Performance</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.00627</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Personalized Transformer for Explainable Recommendation</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4947" to="4957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Persona-Aware Tips Generation</title>
		<author>
			<persName><forename type="first">Piji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1006" to="1016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Neural rating regression with abstractive tips generation for recommendation</title>
		<author>
			<persName><forename type="first">Piji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="345" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Prefix-tuning: Optimizing continuous prompts for generation</title>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4582" to="4597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Towards understanding and mitigating social biases in language models</title>
		<author>
			<persName><forename type="first">Paul Pu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chiyu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis-Philippe</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6565" to="6576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text summarization branches out</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing</title>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhe</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinlan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroaki</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.13586</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Generating wikipedia by summarizing long sequences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Etienne</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Pot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Goodrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Sepassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><surname>Shazeer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Sixth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.10385</idno>
		<title level="m">GPT Understands, Too</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Probabilistic matrix factorization</title>
		<author>
			<persName><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russ</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1257" to="1264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Justifying recommendations using distantly-labeled reviews and fine-grained aspects</title>
		<author>
			<persName><forename type="first">Jianmo</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiacheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="188" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Improving language understanding by generative pre-training</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Tim Salimans, and Ilya Sutskever</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Neural Machine Translation of Rare Words with Subword Units</title>
		<author>
			<persName><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Irch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The woman worked as a babysitter: On biases in language generation</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Premkumar</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP-IJCNLP</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3407" to="3412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Neural Logic Reasoning</title>
		<author>
			<persName><forename type="first">Shaoyun</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanxiong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 29th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1365" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Dual Learning for Explainable Recommendation: Towards Unifying User Preference Prediction and Review Generation</title>
		<author>
			<persName><forename type="first">Peijie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanjie</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richang</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference</title>
		<meeting>The Web Conference</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="837" to="847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">An Unsupervised Aspect-Aware Recommendation Model with Explanation Text Generation</title>
		<author>
			<persName><forename type="first">Peijie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Counterfactual explainable recommendation</title>
		<author>
			<persName><forename type="first">Juntao</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingqiang</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunqi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 30th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1784" to="1793" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Explaining Recommendations: Design and Evaluation</title>
		<author>
			<persName><forename type="first">Nava</forename><surname>Tintarev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judith</forename><surname>Masthoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recommender Systems Handbook</title>
		<editor>
			<persName><forename type="first">Bracha</forename><surname>Shapira</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="353" to="382" />
		</imprint>
	</monogr>
	<note>2 ed.</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Multimodal review generation for recommender systems</title>
		<author>
			<persName><forename type="first">Quoc-Tuan</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hady</forename><surname>Lauw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1864" to="1874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Multimodal few-shot learning with frozen language models</title>
		<author>
			<persName><forename type="first">Maria</forename><surname>Tsimpoukelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serkan</forename><surname>Cabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Tem: Tree-enhanced embedding model for explainable recommendation</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 World Wide Web Conference</title>
		<meeting>the 2018 World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1543" to="1552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Reinforcement knowledge graph reasoning for explainable recommendation</title>
		<author>
			<persName><forename type="first">Yikun</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zuohui</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerard</forename><surname>De Melo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="285" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">CAFE: Coarse-to-fine neural symbolic reasoning for explainable recommendation</title>
		<author>
			<persName><forename type="first">Yikun</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zuohui</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Handong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingqiang</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaoying</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijie</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerard</forename><surname>Zhou Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shan</forename><surname>De Melo</surname></persName>
		</author>
		<author>
			<persName><surname>Muthukrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 29th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1645" to="1654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Explanation as a Defense of Recommendation</title>
		<author>
			<persName><forename type="first">Aobo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongbo</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongning</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Fourteenth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1029" to="1037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Explainable Recommendation: A Survey and New Perspectives</title>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends? in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="101" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Towards conversational search and recommendation: System ask, user respond</title>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Explicit factor models for explainable recommendation based on phrase-level sentiment analysis</title>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guokun</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th international ACM SIGIR conference on Research &amp; development in information retrieval</title>
		<meeting>the 37th international ACM SIGIR conference on Research &amp; development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="83" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A Pre-Training Based Personalized Dialogue Generation Model with Persona-Sparse Data</title>
		<author>
			<persName><forename type="first">Yinhe</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rongsheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoxi</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9693" to="9700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Improving Conversational Recommender Systems via Knowledge Graph based Semantic Fusion</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuqing</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanhang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingsong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1006" to="1014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Faithfully Explainable Recommendation via Neural Logic Reasoning</title>
		<author>
			<persName><forename type="first">Yaxin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yikun</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zuohui</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerard</forename><surname>De Melo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
