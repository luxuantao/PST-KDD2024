<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unbiased Offline Recommender Evaluation for Missing-Not-At-Random Implicit Feedback</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Longqi</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yin</forename><surname>Cui</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuan</forename><surname>Xuan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chenyang</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Serge</forename><surname>Belongie</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Deborah</forename><surname>Estrin</surname></persName>
							<email>destrin@cornell.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Cornell Tech</orgName>
								<orgName type="institution" key="instit2">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Cornell Tech</orgName>
								<orgName type="institution" key="instit2">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Cornell Tech</orgName>
								<orgName type="institution" key="instit2">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Cornell Tech</orgName>
								<orgName type="institution" key="instit2">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">Cornell Tech</orgName>
								<orgName type="institution" key="instit2">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution" key="instit1">Cornell Tech</orgName>
								<orgName type="institution" key="instit2">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="department">RecSys &apos;18)</orgName>
								<address>
									<addrLine>October 2-7, 9 pages</addrLine>
									<postCode>2018</postCode>
									<settlement>Vancouver, New York</settlement>
									<region>BC, NY</region>
									<country>Canada. ACM, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department">RecSys &apos;18</orgName>
								<address>
									<addrLine>October 2-7</addrLine>
									<postCode>2018</postCode>
									<settlement>Vancouver</settlement>
									<region>BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Unbiased Offline Recommender Evaluation for Missing-Not-At-Random Implicit Feedback</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9F39DD23F025289618F95869AE352EC6</idno>
					<idno type="DOI">10.1145/3240323.3240355</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Recommendation</term>
					<term>Evaluation</term>
					<term>Bias</term>
					<term>Implicit feedback</term>
					<term>Propensity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Implicit-feedback Recommenders (ImplicitRec) leverage positive only user-item interactions, such as clicks, to learn personalized user preferences. Recommenders are often evaluated and compared offline using datasets collected from online platforms. These platforms are subject to popularity bias (i.e., popular items are more likely to be presented and interacted with), and therefore logged ground truth data are Missing-Not-At-Random (MNAR). As a result, the widely used Average-Over-All (AOA) evaluator is biased toward accurately recommending trendy items. In this paper, we (a) investigate evaluation bias of AOA and (b) develop an unbiased and practical offline evaluator for implicit MNAR datasets using the Inverse-Propensity-Scoring (IPS) technique. Through extensive experiments using four real-world datasets and four widely used algorithms, we show that (a) popularity bias is widely manifested in item presentation and interaction; (b) evaluation bias due to MNAR data pervasively exists in most cases where AOA is used to evaluate ImplicitRec; and (c) the unbiased estimator significantly reduces the AOA evaluation bias by more than 30% in the Yahoo! music dataset in terms of the Mean Absolute Error (MAE).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>inefficient, and irreproducible. Unlike other machine learning applications, unbiased evaluation of recommendation performance offline is notoriously challenging because of the biased user feedback collected from online platforms that selectively recommend items. Prior work on Explicit-rating Recommenders (ExplicitRec) <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b29">30]</ref> revealed that users give subjective ratings to items, which results in Missing-Not-At-Random (MNAR) ground truth data. It has been widely recognized in the literature <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref> that MNAR rating data can lead to biased conclusions. Therefore, many mechanisms are proposed to debias offline recommender evaluation of rating data <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref>.</p><p>However, existing approaches are not directly applicable to implicit user-item interactions (e.g., click, watch, and listen) <ref type="bibr" target="#b5">[6]</ref>, which are much more prevalent and have been widely used by many stateof-the-art recommendation solutions <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b28">29]</ref>. Different from explicit ratings (e.g., those based on a Likert scale), implicit feedback signals are one-sided and positive only. In other words, an ideal recommender would never observe user interactions with irrelevant <ref type="foot" target="#foot_0">1</ref> items, whereas in ExplicitRec, complete observations assume that each user has a latent preference score for every item. As a result, for Implicit-feedback Recommenders (ImplicitRec), it is unclear whether a missing item in a user's history is not favored by the user or has simply not yet been observed.</p><p>Existing work simplifies the evaluation of ImplicitRec by assuming that positive signals are Missing-At-Random (MAR) <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b10">11]</ref>, that is, each favored item is equal-likely to be clicked or viewed by an user. This assumption does not hold in real-world settings because online recommenders manifest popularity bias <ref type="bibr" target="#b1">[2]</ref> (popular items are much more likely to be recommended and presented to users). Such a bias leads to the phenomenon that relevant and trendy items are more likely to be interacted with by users. Eventually, the Average-Over-All (AOA) evaluator implicitly places greater weights on the accuracy of serving popular items than on serving long-tail ones. This may overlook key limitations of recommendation algorithms, such as under-serving cold start groups <ref type="bibr" target="#b24">[25]</ref>, being dominated <ref type="bibr" target="#b1">[2]</ref>, and exacerbating unhealthful user behavior <ref type="bibr" target="#b23">[24]</ref> In this paper, we develop an unbiased offline recommendation evaluator for MNAR implicit feedback. Our framework is based on the Inverse-Propensity-Scoring (IPS) technique used in causal inference <ref type="bibr" target="#b6">[7]</ref>, which was recently applied to evaluate ExplicitRec <ref type="bibr" target="#b15">[16]</ref>. Specifically, we (a) qualitatively and theoretically demonstrate that the existing evaluation protocol for ImplicitRec is biased; (b) derive unbiased performance estimators for major evaluation metrics, including AUC, DCG, DCG@K, and Recall@K; and (c) conduct extensive experiments using four real-world datasets (citeulike <ref type="bibr" target="#b25">[26]</ref>, Tradesy <ref type="bibr" target="#b3">[4]</ref>, Amazon book <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b27">28]</ref>, and Yahoo! music <ref type="bibr" target="#b0">[1]</ref>) and four widely used algorithms (BPR <ref type="bibr" target="#b14">[15]</ref>, PMF <ref type="bibr" target="#b13">[14]</ref>, U-CML <ref type="bibr" target="#b4">[5]</ref>, and A-CML <ref type="bibr" target="#b4">[5]</ref>). Our experimental results highlight three key contributions and implications of this work:</p><p>• The analysis of datasets and trained models (Section 4.2) reveals that popularity bias is widely manifested in item presentation (i.e., popular items are more likely to be presented than longtail ones) and interaction (i.e., users tend to interact more with popular items). This implies that more attention is needed in considering the potentially negative social and economic impacts of the bias <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b23">24]</ref>. • The comparisons of the classical AOA evaluator to the unbiased evaluator proposed herein (Sections 4.3 and 4.4) demonstrate that AOA is biased in evaluating most ImplicitRec. The bias may lead to inaccurate judgments of algorithmic improvements and sub-optimal decisions when it comes to model selection. • The unbiased evaluator significantly reduces AOA evaluation error by more than 30% in the Yahoo! music dataset in terms of the mean absolute error (MAE) (Section 5).</p><p>Our code is available at https://github.com/ylongqi/unbiasedoffline-recommender-evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Our work is inspired by three lines of research: (a) debiasing the evaluation of ExplicitRec; (b) ImplicitRec algorithms and evaluations; and (c) counterfactual evaluation. In this section, we discuss how our work builds upon existing ideas and contributes new knowledge to the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Debiasing the evaluation of ExplicitRec</head><p>Previous research has shown that for explicit-feedback recommenders, users' ratings are MNAR <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref>. This is because people tend to subjectively choose the items they rate, and the selection reflects biases of personal preferences <ref type="bibr" target="#b15">[16]</ref> and opinions <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b19">20]</ref>. To handle MNAR data and conduct unbiased evaluation, previous work assumed that users have latent ratings for every item, and then use popularity <ref type="bibr" target="#b18">[19]</ref> or other predictive models <ref type="bibr" target="#b15">[16]</ref> to estimate the probability that any given rating is observed. However, such a paradigm is not applicable to implicit feedback because of two fundamental differences: Implicit feedback (a) is available only for the subset of items preferred by users, and (b) is often recorded passively and thus is unlikely to be intentionally controlled.</p><p>Our work addresses the unique missing patterns of implicit feedback by extending the IPS framework <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">ImplicitRec and evaluation</head><p>Recently, there has been a trend toward development of recommenders using implicit feedback signals <ref type="bibr" target="#b5">[6]</ref>, such as click <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b25">26]</ref>, watch <ref type="bibr" target="#b2">[3]</ref>, and view <ref type="bibr" target="#b28">[29]</ref>. These signals are much richer than ratings. Classical offline evaluation approaches <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b28">29]</ref> randomly hold out one interacted item per user as a testing set and then report the average performance. Such a paradigm has been shown to be unbiased under MAR feedback <ref type="bibr" target="#b10">[11]</ref>. However, MAR signals rarely exist in the real world, because it is very unlikely that a content platform would present items completely at random. In fact, item presentation is usually mediated by recommendation engines, which are subject to popularity bias <ref type="bibr" target="#b1">[2]</ref>.</p><p>Our work points out that under MNAR user feedback, the existing evaluation paradigm is biased. In light of this, we develop a practical and effective technique to address the bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Counterfactual evaluation</head><p>Our unbiased evaluator is based on the techniques developed for counterfactual evaluation <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b22">23]</ref>, which aim to evaluate ranking policies offline based on the logs collected from online interactive systems. It has been successfully applied to interactive search <ref type="bibr" target="#b7">[8]</ref> and recommendation <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b22">23]</ref>. Our debiasing framework is built on the Self-Normalized Inverse-Propensity-Scoring (SNIPS) estimator proposed by Swaminathan et al. <ref type="bibr" target="#b21">[22]</ref>.</p><p>However, classical counterfactual reasoning operates on interactive logs, for example, (user 1 , article 1 , reward 1 ), ..., (user n , article n , reward n ), which are different from the implicit feedback-based matrix completion task that we consider. To the best of our knowledge, there has been little research on applying counterfactual estimators to debias ImplicitRec evaluations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">UNBIASED RECOMMENDER EVALUATION FOR IMPLICIT FEEDBACK</head><p>Recommenders built on implicit feedback receive only users' onesided (positive) preference signals, such as clicks and watches. Under complete observations, user u has a set of preferred items S u among the entire set of items, I (i.e., S u ⊆ I). An ideal recommendation evaluator calculates the following reward R( Ẑ ) for the predicted item ranking Ẑ .</p><formula xml:id="formula_0">R( Ẑ ) = 1 |U| u ∈U 1 |S u | i ∈S u c( Ẑu,i ),<label>(1)</label></formula><p>where Ẑu,i is the predicted ranking of item i (among all the items in I) for user u, and the function c denotes any top-N scoring metric, such as Area Under Curve (AUC), Discounted Cumulative Gain (DCG), DCG@K, or Recall@K. These functions are defined as follows:</p><formula xml:id="formula_1">AUC: c( Ẑu,i ) = 1 - Ẑu,i |I|<label>(2)</label></formula><formula xml:id="formula_2">DCG: c( Ẑu,i ) = 1 log 2 ( Ẑu,i + 1)<label>(3)</label></formula><formula xml:id="formula_3">DCG@K: c( Ẑu,i ) = 1{ Ẑu,i ≤ K } log 2 ( Ẑu,i + 1)<label>(4)</label></formula><p>Recall@K: c( Ẑu,i ) = 1{ Ẑu,i ≤ K } (5) Eqn. 1 measures idealistic recommendation performance, which assumes that users would go through all items in the system and interact with every one that appeals to them. From a practical standpoint, it is impossible to browse and judge millions or billions of items. As a result, recommenders have access to only a partial view of S u , denoted by S * u . For each positive signal (u, i), i ∈ S u , we use O u,i to indicate whether (u, i) is observed (O u,i = 1 if (u, i) is observed, and O u,i = 0 otherwise). In addition, inspired by <ref type="bibr" target="#b15">[16]</ref>, we  , Z 2 and Z 3 , for the same user. Among the shaded items that were preferred by the user, the ones with a solid border were observed by recommenders. The performance was measured by DCG, and the results are presented in Table <ref type="table">1</ref>.</p><p>Table <ref type="table">1</ref>: The true and estimated DCG values for three recommenders in Fig. <ref type="figure" target="#fig_1">1</ref>. R( Ẑ ) denotes the ground truth, and RAOA ( Ẑ ) denotes the AOA estimations. The AOA estimator outputs larger values when popular items are ranked higher.</p><formula xml:id="formula_4">Estimator Z 1 Z 2 Z 3 R( Ẑ )</formula><p>0.463 0.463 0.494 RAOA ( Ẑ ) 0.585 0.340 0.390 assume the observations of every signal to be Bernoulli distributed, that is, O u,i ∼ B(1, P u,i ), where with probability P u,i = P(O u,i = 1), (u, i) is observed by a recommender.</p><p>In reality, the partial view S * u is mostly biased and the implicit feedback is MNAR. In Section 3.1, we show that the AOA evaluator, which is widely used in the existing literature, is biased, and in Section 3.2 we propose an unbiased evaluator based on the inversepropensity-scoring (IPS) technique <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Average-over-all (AOA) evaluator</head><p>In prior literature, R( Ẑ ) was estimated by taking the average over all observed user feedback S * u :</p><formula xml:id="formula_5">RAOA ( Ẑ ) = 1 |U| u ∈U 1 |S * u | i ∈S * u c( Ẑu,i ) = 1 |U| u ∈U 1 i ∈S u O u,i i ∈S u c( Ẑu,i ) • O u,i<label>(6)</label></formula><p>To intuitively illustrate the bias of the AOA evaluator, we considered a hypothetical platform that served 12 items, as shown in Fig. <ref type="figure" target="#fig_1">1</ref>. We divided the items into two groups based on the number of interactions they received: popular items (a 1 , ..., a 5 ) and long-tail items (b 1 , ..., b 7 ). For a specific user, three different recommenders generated distinct ranked lists, Z 1 , Z 2 , and Z 3 , based on the predicted user preferences. Each item on the platform was either relevant (shaded) or irrelevant (blank) to the user. Among all the relevant items, only feedback for a partial set was observed (solid border). To encode the popularity bias manifested in ImplicitRec (i.e., user interactions with popular items are more likely to be observed), we assumed that among the relevant items, 75% of the popular items and 25% of the long-tail items were interacted with. In addition, three ranked lists were strategically designed: The Z 1 and Z 2 ranked lists had the same true performance on the ranking of relevant items but differed on the serving of the popular and long-tail groups. The Z 3 ranked list achieved the best true performance.</p><p>We calculated the DCG scores (eqn. 3) for three recommenders using the AOA evaluator (eqn. 6) and compared the scores to the true performances (eqn. 1). According to the results presented in Table <ref type="table">1</ref>, Z 1 was evaluated as much more accurate than Z 2 and Z 3 , despite the fact that, in reality, Z 2 had the same performance as Z 1 , and Z 3 performed much better. This demonstrates that the AOA evaluator is significantly biased toward the accuracy of serving trendy items; that is, the estimated RAOA ( Ẑ ) is larger if popular items are ranked higher. The conclusions made based on such empirical evidence result in incorrect and even opposite judgments of the relative utilities of recommenders.</p><p>Basically, the expected outcome of the AOA evaluator does not conform to the true performance, that is,</p><formula xml:id="formula_6">E O RAOA ( Ẑ ) R( Ẑ ).</formula><p>We prove this inequivalence by a counterexample. Suppose that for any user u, among all relevant items (S u ), only one item k u ∈ S u has an observation probability close to 1, so that</p><formula xml:id="formula_7">P(O u,k u ) = 1 -ϵ; whereas for the other items, P(O u,i ) = ϵ, i ∈ S u \{k u }. In this case, E O RAOA ( Ẑ ) ≈ ϵ 1 1 |U | u ∈U c( Ẑu,k u ) R( Ẑ ).</formula><p>Next, we present our proposed unbiased performance evaluator as an alternative to the existing AOA evaluator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Unbiased evaluator</head><p>To conduct unbiased evaluation of biased observations, we leverage the IPS framework <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b21">22]</ref> that weights each observation with the inverse of its propensity, where the term propensity refers to the tendency or the likelihood of an event happening. The intuition is to down-weight the commonly observed interactions, while upweighting the rare ones. In the context of this paper, the probability P u,i is treated as the pointwise propensity score. Therefore, the IPS unbiased evaluator is defined as follows:</p><formula xml:id="formula_8">RIPS ( Ẑ |P) = 1 |U| u ∈U 1 |S u | i ∈S * u c( Ẑu,i ) P u,i = 1 |U| u ∈U 1 |S u | i ∈S u c( Ẑu,i ) P u,i • O u,i<label>(7)</label></formula><p>We prove that given any propensity assignment P, RIPS ( Ẑ |P) is an unbiased estimator.</p><formula xml:id="formula_9">E O RIPS ( Ẑ |P) = 1 |U| u ∈U 1 |S u | i ∈S u c( Ẑu,i ) P u,i • E O O u,i = 1 |U| u ∈U 1 |S u | i ∈S u c( Ẑu,i ) = R( Ẑ )<label>(8)</label></formula><p>Furthermore, to estimate |S u | and control the variability of the IPS evaluator, we leverage the control variates <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b21">22]</ref> to derive a Self-Normalized Inverse-Propensity-Scoring (SNIPS) evaluator. According to the theory of Monte Carlo approximation <ref type="bibr" target="#b21">[22]</ref>, the estimation Ŵ of the expectation E X [W (X )] has a lower variance if a multiplicative control variate V (X ) with known expectation E</p><formula xml:id="formula_10">X [V (X )] = v 0 is introduced, that is, if Ŵ is calculated as: Ŵ = n j =1 W (X j ) n j =1 V (X j ) v.</formula><p>While Ŵ is not a completely unbiased estimator, it strongly converges to the true expectation for large n <ref type="bibr" target="#b21">[22]</ref>.</p><p>In the context of the IPS evaluator, because</p><formula xml:id="formula_11">E O i ∈S * u 1 P u, i = E O i ∈S u 1 P u, i • O u,i = |S u |,</formula><p>we can write the SNIPS evaluation as follows:</p><formula xml:id="formula_12">RSNIPS ( Ẑ |P) = 1 |U| u ∈U 1 |S u | E O i ∈S * u 1 P u, i i ∈S * u 1 P u, i i ∈S * u c( Ẑu,i ) P u,i = 1 |U| u ∈U 1 i ∈S * u 1 P u, i i ∈S * u c( Ẑu,i ) P u,i<label>(9)</label></formula><p>A key challenge in computing RSNIPS ( Ẑ |P) is to predict the propensity scores P u,i . Next, we demonstrate our method, which estimates the propensity scores based solely on raw observations, without requiring any auxiliary user or item information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Estimating propensity scores</head><p>We assume that the propensity score P u,i is user independent, that is, P u,i = P(O u,i = 1) = P(O * ,i = 1) = P * ,i . This simplified assumption is made to address the lack of auxiliary user information in many user-item interaction records. 2 We derive P * ,i by constructing a two-step generative process of user-item interactions: (1) Select, where a recommender system selects a set of items to present to a user; and (2) Interact, where the user browses the recommended items and interacts with the ones she likes. Therefore, P * ,i can be calculated as follows:</p><formula xml:id="formula_13">P * ,i = P select * ,i • P interact|select * ,i ,<label>(10)</label></formula><p>where P select * ,i is the probability that item i is recommended and</p><formula xml:id="formula_14">P interact |select * ,i</formula><p>is the conditional probability that the user interacts with item i given that it is recommended.</p><p>Since implicit feedback is passively recorded and is less likely to be subjectively manipulated, we assume that</p><formula xml:id="formula_15">P interact|select * ,i = P interact * ,i</formula><p>, that is, the user interacts with all the items she likes in the recommended set, and the user's preferences are not affected by recommendations. 3 Also, because P interact * ,i is user independent, it is proportional to only the item's true popularity n i (the number of occurrences in the complete observation):</p><formula xml:id="formula_16">Pinteract * ,i ∝ n i (<label>11</label></formula><formula xml:id="formula_17">)</formula><p>Because items that are frequently interacted with are more likely to be recommended in ImplicitRec <ref type="bibr" target="#b1">[2]</ref>, the probability P select * ,i is modeled using n * i (the number of times item i is interacted with) 2 This assumption may be relaxed in cases where auxiliary user information is available. We discuss this issue in Section 6. 3 In reality, user-item interactions may be affected by the order of presentation of the items, and users' preferences may be shaped by recommendations in the long term. Modeling these effects may further improve the evaluator's performance (as discussed in Section 6).</p><p>as a covariate. Specifically, we follow a common template that accurately captures the popularity bias <ref type="bibr" target="#b18">[19]</ref>, which assumes that P select * ,i conforms to a power-law distribution parameterized by γ :</p><formula xml:id="formula_18">Pselect * ,i ∝ (n * i ) γ (12)</formula><p>Therefore, according to the constructed generation process, P * ,i depends on only two variates, n * i and n i :</p><formula xml:id="formula_19">P * ,i ∝ (n * i ) γ • n i ,<label>(13)</label></formula><p>where</p><formula xml:id="formula_20">n i = u ∈U 1 [i ∈ S u ] and n * i = u ∈U,i ∈S * u O * ,i</formula><p>. However, empirically, n i is not directly observable. To address this problem, we observe that n * i is sampled from a binomial distribution <ref type="foot" target="#foot_1">4</ref> parameterized by n i , that is, n * i ∼ B(n i , P * ,i ). Therefore, a relationship between n i and n * i can be built by bridging the generative model (eqn. 13) with the following unbiased estimator:</p><formula xml:id="formula_21">P * ,i = n * i n i ∝ (n * i ) γ • n i (14) Therefore, n i ∝ (n * i ) 1-γ 2 .</formula><p>We use this as a replacement for the unobserved n i in eqn. 13, which results in an unbiased P * ,i estimator that is determined by only the empirical counts of items:</p><formula xml:id="formula_22">P * ,i ∝ n * i γ +1 2<label>(15)</label></formula><p>Different values of the power-law exponent γ affect the propensity distributions over items with different observed popularity levels. A larger γ leads to lower propensity scores for long-tail items and higher scores for popular ones. In deployed systems, the exponent can be empirically predicted (as shown in Section 4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS WITH BIASED FEEDBACK AND THE UNBIASED EVALUATOR</head><p>To more thoroughly understand the nature of MNAR implicit feedback and the proposed unbiased evaluator, we studied three largescale real-world datasets and four recommendation algorithms. Our experiments are comprised of three parts: (a) investigating how popularity bias is manifested in real-world platforms, (b) exploring properties of the power-law exponent, and (c) understanding debiasing effects of the unbiased evaluator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental setup</head><p>To describe the stup of the experiments, we review the datasets and algorithms, describe the recommendation model implementations with OpenRec <ref type="bibr" target="#b27">[28]</ref>, and present the details of model training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Datasets.</head><p>We used three datasets of varied size and sparsity ( # interactions # users×# items ). For each dataset, we randomly and independently hold out 15% of user-item interactions for validation and 15% for testing, and we used the remaining 70% of records for training. During testing, we excluded cold-start users and items that have no record in the training set.</p><p>• citeulike <ref type="bibr" target="#b25">[26]</ref>. citeulike is a reference management service, where scholars curate article collections based on their preferences and professional needs. We used the dataset collected by Wang et al. <ref type="bibr" target="#b25">[26]</ref> and treated "saving an article" as a positive implicit feedback signal. The dataset contains 204,986 interactions between 5,551 users and 16,980 items (sparsity: 2e-3).</p><p>• Tradesy <ref type="bibr" target="#b3">[4]</ref>. Tradesy is a large second-hand retail market for clothing and fashion. We used the dataset released by He et al. <ref type="bibr" target="#b3">[4]</ref>, and treated "want an item" and "bought an item" as positive signals. The final dataset includes 19,243 users, 165,906 wanted or bought items, and 394,421 interactions (sparsity: 1e-4). • Amazon book <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b27">28]</ref>. The Amazon book dataset was derived from the original Amazon review dataset <ref type="bibr" target="#b12">[13]</ref> by Yang et al. <ref type="bibr" target="#b27">[28]</ref>.</p><p>The dataset records users' purchasing history under the Amazon book category. The dataset covers 99,473 users, 450,166 books, and 996,938 transactions (sparsity: 2e-5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Algorithms.</head><p>We considered recommendation models with different training procedures (pairwise and pointwise) and architectures (matrix-factorization based and metric-learning based).</p><p>• Bayesian Personalized Ranking (BPR) <ref type="bibr" target="#b14">[15]</ref>. BPR is based on the general framework of matrix factorization that learns vector representations for users and items. Specifically, user u's preference toward item i is modeled as xu,i = v T u v i + β i , where v * denote representations, and β i denotes the item-specific bias. Built upon the scoring function xu,i , BPR trains the model parameters on (u, i, j) triplets (i and j represent interacted item and non-interacted item respectively) using a pairwise ranking based optimization framework that minimizes the following loss. min</p><formula xml:id="formula_23">Θ (u,i, j)∈D -ln ( xu,i -xu, j ) + λ Θ Θ (<label>16</label></formula><formula xml:id="formula_24">)</formula><p>where D is the set of triplets that are randomly sampled from the training dataset and Θ is the set of model parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Collaborative Metric Learning with Uniform Weights (U-</head><p>CML) <ref type="bibr" target="#b4">[5]</ref>. U-CML is trained on the same (u, i, j) triplets as BPR, but instead of modeling user-item scores using dot products, U-CML leverages the Euclidean distance metric to regularize the embedding space, that is, xu,i</p><formula xml:id="formula_25">= β i -v u -v i 2</formula><p>, where all representations are bounded within a unit sphere. Another difference between U-CML and BPR is that U-CML minimizes the pairwise hinge loss: min</p><formula xml:id="formula_26">Θ (u,i, j)∈D m + xu,i -xu, j + + λ Θ Θ 2<label>(17)</label></formula><p>• CML with Approximate-Rank Weights (A-CML). U-CML model randomly samples the triplets from the training set, making most of them become trivial samples as the training proceeds. Therefore, as suggested by Hsieh et al. <ref type="bibr" target="#b4">[5]</ref>, we leveraged the approximate-rank weighting technique <ref type="bibr" target="#b26">[27]</ref> to adjust the weight of each training instance: min</p><formula xml:id="formula_27">Θ (u,i, j)∈D w u, j m + xu,i -xu, j + + λ Θ Θ 2 , (<label>18</label></formula><formula xml:id="formula_28">)</formula><p>where w u, j = log(rank(u, j) + 1) and rank(u, j) is the rank of item j in user u's recommendation list. The rank can be estimated by sequential <ref type="bibr" target="#b26">[27]</ref> or parallel <ref type="bibr" target="#b4">[5]</ref> sampling. To speed up the training, we sampled 10 negative items in parallel for each observed useritem interaction, as suggested by Hsieh et al. <ref type="bibr" target="#b4">[5]</ref>. • Probabilistic Matrix Factorization (PMF) <ref type="bibr" target="#b13">[14]</ref>. PMF is a pointwise trained recommendation model, that is, it is built upon pairs (u, i). The model is optimized to minimize the following regularized square error:</p><formula xml:id="formula_29">min Θ u,i c u,i (r u,i -xu,i ) 2 + λ Θ Θ 2 ,<label>(19)</label></formula><p>where r u,i = 1 if user u interacted with item i, and r u,i = 0 otherwise. Because of the sparsity of the interactions, c u,i is set to a higher value for r u,i = 1 than for r u,i = 0. In our experiments, c u,i was set to 1 and 0.25, respectively, for those two cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Implementations and training.</head><p>We implemented the algorithms based on the OpenRec framework <ref type="bibr" target="#b27">[28]</ref>. The dimensionality of user and item representations was set to 50 for citeulike and to 100 for the other datasets. Each model was trained using the Adam optimizer <ref type="bibr" target="#b8">[9]</ref> with a batch size of 8K. Because of differences in the sizes of the datasets, the models were trained for 50K, 120K, and 200K iterations <ref type="foot" target="#foot_2">5</ref> under citeulike, tradesy, and Amazon book, respectively. We conducted model selection <ref type="bibr" target="#b15">[16]</ref> for each algorithm-metric pair by training recommenders with different regularization parameters, that is, λ Θ ∈ {0.1, 0.01, 0.001, 1e -4, 1e -5}. The optimal training iteration and λ Θ value are determined by the evaluation on the validation set. The recommendation performances are finally reported on the held-out testing sets. Because of the large item space, it is computationally infeasible to compute rankings over all items. Therefore, for each user, we randomly and independently sample 200 items with which users have not interacted before and compute rankings over the sampled sets. This is a common approach adopted by recent literature <ref type="bibr" target="#b27">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Investigating popularity bias</head><p>We initially conducted an experiment to understand to what extent popularity bias is manifested in real-world recommendation systems. Specifically, we investigated two kinds of bias related to popularity: (a) interaction bias (i.e., that users tend to interact more often with popular items), and (b) presentation bias (i.e., that recommenders unfairly present more popular items than long-tail ones).</p><p>However, in existing datasets, interaction bias is barely separable from presentation bias <ref type="bibr" target="#b16">[17]</ref>, since a user can interact with an item only if it is presented. Therefore, we resorted to the joint effects of the two kinds of bias, which are manifested in the distribution of n * i , that is, the number of times users interact with each item. Intuitively, an unbiased platform should expect users to interact broadly. As a result, user attentions are likely to be evenly distributed. On the contrary, if a platform is highly biased, then user interactions tend to be more concentrated, which leads to dominance by a small set of items. We show the n * i distribution for all i ∈ I in Fig. <ref type="figure" target="#fig_2">2</ref>. Given that the horizontal axis is log scaled, the n * i distribution is significantly skewed: Most of the items received very few user interactions. For example, on Amazon book, more than 99.9% of items received fewer than 100 interactions. In addition, the degree of bias varies across datasets: The Amazon book dataset is the most popularity biased, while the tradesy dataset is the least popularity biased.</p><p>For the presentation bias, we measured the average number of times that an item with the observed popularity n * ∈ [1, max(n * i )] was recommended, denoted by f (n * ). An unbiased system should  expect a relatively flat f (n * ) with a small slope, whereas a biased recommender may produce linearly or exponentially growing f (n * ).</p><p>We treated the top 50 recommendations that the trained recommenders made for every user as recommended items, and f (n * ) was computed as follows:</p><formula xml:id="formula_30">f (n * ) = i ∈I 1(n * i = n * ) • N i i ∈I 1(n * i = n * ) ,<label>(20)</label></formula><p>where N i is the frequency of item i in all users' top 50 recommendations. For each user, the recommendation list was computed over the complete item set I, excluding items that the user had already interacted with in the training set. In Fig. <ref type="figure" target="#fig_3">3</ref>, we show the empirically estimated f (n * ). All three f (n * ) curves appear to be mostly monotonic, with small variations, which suggests that an item with small n * i is much less likely to be presented, compared to the ones with larger n * i . Also, different algorithms tend to manifest diverse patterns. For example, in Amazon book, BPR and A-CML are more likely to present long-tail items than PMF and U-CML.</p><p>To sum up the findings, we demonstrated that both forms of popularity bias pervasively exist on platforms that use the mainstream recommendation algorithms. Although the amount of bias varies across platforms and algorithms, it appears to be highly significant. In addition, the estimation of presentation bias provides a mechanism for gaining an empirical understanding of the properties of the power-law exponent (eqn. 15), which is discussed next. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Exploring the power-law exponent</head><p>To understand the properties of γ , we estimated its value by running simulations on offline datasets. The shape of the probability distribution Pselect * ,i , parameterized by γ , was most likely to be affected by two factors: the recommendation algorithm (which controls what to select) and the content platform (which determines what is available). Therefore, we predict a γ for each algorithm-platform pair. Due to the fact that Pselect * ,i is only determined by an item's observed popularity n * i , the probability satisfies: Pselect * ,i</p><formula xml:id="formula_31">∝ (n * i ) γ ∝ f (n * = n * i ).</formula><p>Estimating the value of γ is equivalent to minimizing the following square error:</p><formula xml:id="formula_32">min γ (x,y)∈T log f (y) f (x) -γ • log y x 2<label>(21)</label></formula><p>where T denotes all possible combinations of (x, y) where x, y ∈ [1, max(n * i )] and x y. Because this is a quadratic optimization problem, γ can be analytically solved as:</p><formula xml:id="formula_33">γ = (x,y)∈T log f (y) f (x ) • log y x (x,y)∈T log y x 2<label>(22)</label></formula><p>We fit γ using the calculated f (u * ) from Section 4.2. To make the estimation numerically more stable and robust to outliers, we exclude the top 0.5% of items that have the highest n * . The final estimated γ values are presented in Table <ref type="table" target="#tab_0">2</ref>. We find that the power-law curve accurately fits f (n * ) with small average square error (within the range (0.001, 0.02)). Also, among all algorithms, A-CML stands out (bolded in Table <ref type="table" target="#tab_0">2</ref>) as having the lowest estimated γ value in all datasets, which suggests that it manifests the least presentation bias. However, overall, the estimated γ value is relatively stable given a dataset (the value range is 0.34, 0.82, and 0.41 for the citeulike, Tradesy, and Amazon book datasets, respectively).</p><p>These experimental results suggest that in practice, if the past recommendation algorithm is known, using the power-law function can accurately fit and reconstruct Pselect * ,i . Even if the accurate recommender is unknown, it is still plausible to roughly predict the γ value by experimenting classical algorithms in the given dataset. In the next experiment, we leverage the estimated γ value to understand debiasing effects of the unbiased evaluator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Understanding the unbiased evaluator</head><p>compare the outputs from the AOA and the unbiased evaluator under the same algorithm-platform settings. Specifically, for each dataset, we experiment on the minimum, average and maximum γ values from Table <ref type="table" target="#tab_0">2</ref>. We evaluate models against four metrics: AUC, DCG, DCG@5 and Recall@5, as defined from eqn. 2 to eqn. 5. The experimental results are presented in Fig. <ref type="figure" target="#fig_4">4</ref>. Our main findings are discussed below.</p><p>• The unbiased evaluator reports lower performance, regardless of the algorithm, dataset or evaluation metric. As shown in Fig. <ref type="figure" target="#fig_4">4</ref>, after applying the unbiased evaluation, the estimated recommendation performance significantly drops. This is because recommenders usually perform worse on long tail items than popular ones, and the unbiased evaluator corrects and reduces the biased weights that AOA places on popular items. This finding reveals that the traditional evaluation method may over-estimate the performance of recommendation algorithms. • The unbiased evaluator may amplify, diminish, or flip the relative differences reported by AOA. In many cases, the unbiased estimator does not change the absolute performance difference between algorithms but amplifies the relative difference, e.g., BPR outperforms PMF by 22% and 26% in terms of the Recall reported by AOA and γ (min), respectively. Also, the unbiased evaluator may diminish (e.g., U-CML vs. BPR under Amazon book-DCG) or flip (e.g., PMF vs. U-CML under Tradesy-DCG) the relative differences. These observations highlight a caveat that traditional evaluation may lead to inaccurate or mis-judgments of algorithms' relative utilities. • The outputs of the unbiased estimator are stable for different γ values from the estimated range. In all conditions, the outputs of the unbiased evaluator are stable for differnt γ values (min, avg., or max). In other words, as long as the γ value is from the estimated range, the unbiased evaluator is expected to produce robust evaluation results.</p><p>In summary, these results demonstrate that the unbiased evaluator is robust and has the potential to more objectively evaluate and compare different recommenders. Next, we empirically measure its debiasing performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATING DEBIASING PERFORMANCE</head><p>We leverage the Yahoo! music ratings dataset <ref type="bibr" target="#b0">[1]</ref> to quantify debiasing performance of the unbiased evaluator. The dataset contains users' ratings towards a uniform-randomly selected sets of music, which can be used to measure recommenders' true performances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental setup</head><p>The original dataset includes a training set and a testing set. The training set contains 300K ratings given by 15.4K users against 1K songs through natural interactions, and the testing set is collected by asking a subset of 5.4K users to rate 10 randomly selected songs. To tailor this dataset for experimenting implicit feedback, we treat items rated greater than or equal to 4 as relevant, and others as irrelevant, as suggested by prior literature <ref type="bibr" target="#b4">[5]</ref>. We filter the testing set by retaining users who have at least a relevant and an irrelevant song in the testing set and two relevant songs in the training set (2,296 users satisfy these requirements). We additionally held out a biased testing set (biased-testing) from the training set by randomly sampling 300 songs for each user.</p><p>We train models discussed in Section 4.1 using the same protocol but with fixed hyperparameters (λ Θ = 0.001, training iterations: 10K, latent factors: 50). For each model, different evaluators are used to evaluate its performance against the biased-testing set in terms of AUC and Recall. <ref type="foot" target="#foot_3">6</ref> The models' true performances were calculated by AOA over the unbiased testing set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>Table <ref type="table" target="#tab_1">3</ref> shows the mean absolute error (MAE) between different evaluators' outputs on the biased-testing set and the recommenders' true performances. For both AUC and Recall, the unbiased evaluator (UB) reduced more than 30% of the errors in AOA, and UB's debiasing performance was insensitive to the hyperparameter selections. Within the range of [1.5, 3.0], UB consistently produced significantly lower errors than AOA. However, these results also demonstrate that UB is still imperfect, and that there is ample room for future improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND DISCUSSION</head><p>We studied the problem of evaluating ImplicitRec using offline datasets and showed that the widely adopted AOA evaluation is biased toward popularity. Built upon the IPS technique from causal inference, we developed a theoretically grounded unbiased evaluator and empirically demonstrated its ability to significantly reduce recommender evaluation biases. However, the developed unbiased evaluator is limited in its two simplified assumptions, which points out promising future research directions:  • User-independent propensity. In the absence of detailed metainformation about users, we assumed that the propensity was user independent and that the probability of an item being presented was determined by its observed popularity. In reality, the propensity may be affected by user-specific traits and preferences. Future research could investigate more sophisticated propensity estimation methods, such as building predictive models to take auxiliary user features into consideration. • Selection-independent interaction. We assumed that the probability that a user interacts with an item is independent of the probability that the item is recommended. This does not capture the potential impact of recommendations and item presentation order on users' preferences. Future research could conduct controlled user testing to model these nuanced effects.</p><p>In addition, our work has implications for the development of recommendation algorithms that are robust to popularity bias. This work shows that a recommender's accuracy on popular items usually overestimates that recommender's true performance. Algorithms that intend to be robust to popularity bias should explore ways to improve long-tail recommendations, not only through popularity under-weighting, but also via other techniques such as stratified sampling, data augmentation, and low-shot learning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure1:A hypothetical example to illustrate the evaluation bias that results from use of the AOA evaluator. Three recommenders generated distinct lists of recommendations, Z 1 , Z 2 and Z 3 , for the same user. Among the shaded items that were preferred by the user, the ones with a solid border were observed by recommenders. The performance was measured by DCG, and the results are presented in Table1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The distribution of n * i (the observed number of interactions with item i) in the three datasets. The items are presented in descending order of n * i . The horizontal axis is log scaled for better visualization. In all datasets, the n * i distribution is skewed and the user interactions are significantly biased.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Empirically estimated f (n * ) on the three datasets and the four recommendation algorithms. f (n * ) denotes the average number of times that an item with observed popularity n * was recommended. Both axes are log scaled. Therefore, exponential growth is linear in the figure. All settings manifest significant presentation bias.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Comparison of the traditional and unbiased evaluators in measuring the performance of four recommendation algorithms. The evaluations were conducted over three datasets using four metrics. Each sub-figure represents a specific datasetmetric pair. For the unbiased evaluator, three estimated γ values from Section 4.3 were used in the experiments. The unbiased evaluator significantly reduces the biased weights that the AOA method places on the popular items and produces robust and consistent results for any γ from the estimated range.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 : Estimated γ value for every dataset-algorithm pair. The algorithm that achieves the lowest γ in each dataset is bolded. The γ estimation is more sensitive to the choice of datasets than algorithms.</head><label>2</label><figDesc></figDesc><table><row><cell>Dataset</cell><cell cols="5">BPR U-CML A-CML PMF Average</cell></row><row><cell>citeulike</cell><cell>1.67</cell><cell>1.64</cell><cell>1.55</cell><cell>1.89</cell><cell>1.69</cell></row><row><cell>Tradesy</cell><cell>2.96</cell><cell>2.40</cell><cell>2.25</cell><cell>3.07</cell><cell>2.67</cell></row><row><cell cols="2">Amazon book 1.85</cell><cell>2.11</cell><cell>1.70</cell><cell>1.80</cell><cell>1.87</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 : Mean absolute error (MAE) between evaluators' out- puts on the biased-testing set and recommenders' true per- formances. Performance was measured against AUC and Re- call. For the unbiased evaluator (UB), four γ values were used in the experiments (γ</head><label>3</label><figDesc>= 1.5, 2.0, 2.5, 3.0).</figDesc><table><row><cell></cell><cell cols="4">(a) Mean absolute error (MAE) on AUC</cell><cell></cell></row><row><cell cols="6">Model AOA UB(1.5) UB(2.0) UB(2.5) UB(3.0)</cell></row><row><cell cols="2">U-CML 0.151</cell><cell>0.102</cell><cell>0.099</cell><cell>0.096</cell><cell>0.094</cell></row><row><cell cols="2">A-CML 0.152</cell><cell>0.103</cell><cell>0.099</cell><cell>0.097</cell><cell>0.094</cell></row><row><cell>BPR</cell><cell>0.147</cell><cell>0.109</cell><cell>0.106</cell><cell>0.104</cell><cell>0.103</cell></row><row><cell>PMF</cell><cell>0.148</cell><cell>0.103</cell><cell>0.100</cell><cell>0.097</cell><cell>0.095</cell></row><row><cell></cell><cell cols="4">(b) Mean absolute error (MAE) on Recall</cell><cell></cell></row><row><cell cols="6">Model AOA UB(1.5) UB(2.0) UB(2.5) UB(3.0)</cell></row><row><cell cols="2">U-CML 0.401</cell><cell>0.270</cell><cell>0.260</cell><cell>0.253</cell><cell>0.248</cell></row><row><cell cols="2">A-CML 0.399</cell><cell>0.274</cell><cell>0.264</cell><cell>0.258</cell><cell>0.253</cell></row><row><cell>BPR</cell><cell>0.380</cell><cell>0.275</cell><cell>0.268</cell><cell>0.262</cell><cell>0.258</cell></row><row><cell>PMF</cell><cell>0.386</cell><cell>0.267</cell><cell>0.259</cell><cell>0.252</cell><cell>0.248</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>An item is relevant to a user if the user is interested in interacting with it (e.g., clicking or viewing it). Otherwise, the item is regarded as irrelevant.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>O * , i satisfies the Bernoulli distribution.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>An iteration is defined as a feed forward and a backward propagation using a batch (size=8K) of randomly sampled training data.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3"><p>Recall@30 (biased-testing set) and Recall@1 (testing set) were compared since the biased-testing set is 10 times as large as the testing set.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank the anonymous reviewers for their insightful comments and suggestions. This research was funded by the National Science Foundation (#1700832) and Oath (the Connected Experiences Laboratory at Cornell Tech). The work was further supported by the small data lab at Cornell Tech, which receives funding from NSF, NIH, RWJF, UnitedHealth Group, Google, and Adobe.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Yahoo! Webscope dataset ydata-ymusic-rating-study-v1</title>
		<ptr target="http://research.yahoo.com/Academic_Relations" />
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Controlling Popularity Bias in Learning-to-Rank Recommendation</title>
		<author>
			<persName><forename type="first">Himan</forename><surname>Abdollahpouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bamshad</forename><surname>Mobasher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM Conference on Recommender Systems</title>
		<meeting>the Eleventh ACM Conference on Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="42" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The YouTube video recommendation system</title>
		<author>
			<persName><forename type="first">James</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Liebald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junning</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Palash</forename><surname>Nandy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Van Vleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ullas</forename><surname>Gargi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sujoy</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blake</forename><surname>Livingston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth ACM conference on Recommender systems</title>
		<meeting>the fourth ACM conference on Recommender systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="293" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">VBPR: Visual Bayesian Personalized Ranking from Implicit Feedback</title>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="144" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Collaborative metric learning</title>
		<author>
			<persName><forename type="first">Cheng-Kang</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Longqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deborah</forename><surname>Estrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="193" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Collaborative filtering for implicit feedback datasets</title>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Mining, 2008. ICDM&apos;08</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tutorial on Counterfactual Evaluation and Learning for Search, Recommendation and Ad Placement</title>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Swaminathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Research and Development in Information Retrieval (SIGIR)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1199" to="1201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unbiased learning-to-rank with biased feedback</title>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Schnabel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Tenth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="781" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unbiased offline evaluation of contextual-bandit-based news article recommendation algorithms</title>
		<author>
			<persName><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth ACM international conference on Web search and data mining</title>
		<meeting>the fourth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="297" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Top-n recommendation with missing implicit feedback</title>
		<author>
			<persName><forename type="first">Daryl</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gert</forename><surname>Lanckriet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th ACM Conference on Recommender Systems</title>
		<meeting>the 9th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="309" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Collaborative prediction and ranking with non-random missing data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marlin</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the third ACM conference on Recommender systems</title>
		<meeting>the third ACM conference on Recommender systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="5" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Inferring networks of substitutable and complementary products</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Probabilistic matrix factorization</title>
		<author>
			<persName><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1257" to="1264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">BPR: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence</title>
		<meeting>the twenty-fifth conference on uncertainty in artificial intelligence</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Recommendations as Treatments: Debiasing Learning and Evaluation</title>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashudeep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navin</forename><surname>Chandak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1670" to="1679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Human-recommender systems: From benchmark data to benchmark cognitive models</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Shafto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olfa</forename><surname>Nasraoui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM Conference on Recommender Systems</title>
		<meeting>the 10th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="127" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Training and testing of recommender systems on data missing not at random</title>
		<author>
			<persName><forename type="first">Harald</forename><surname>Steck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 16th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="713" to="722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Item popularity and recommendation accuracy</title>
		<author>
			<persName><forename type="first">Harald</forename><surname>Steck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth ACM conference on Recommender systems</title>
		<meeting>the fifth ACM conference on Recommender systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="125" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Evaluation of recommendations: rating-prediction and ranking</title>
		<author>
			<persName><forename type="first">Harald</forename><surname>Steck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM conference on Recommender systems</title>
		<meeting>the 7th ACM conference on Recommender systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="213" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Counterfactual risk minimization: Learning from logged bandit feedback</title>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="814" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The self-normalized estimator for counterfactual learning</title>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3231" to="3239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Off-policy evaluation for slate recommendation</title>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshay</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alekh</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miro</forename><surname>Dudik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damien</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Imed</forename><surname>Zitouni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3635" to="3645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Investigating the healthiness of internet-sourced recipes: implications for meal planning and recommender systems</title>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Trattner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Elsweiler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th international conference on world wide web. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 26th international conference on world wide web. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="489" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep content-based music recommendation</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Schrauwen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2643" to="2651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Collaborative deep learning for recommender systems</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dit-Yan</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1235" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Wsabie: Scaling up to large vocabulary image annotation</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In IJCAI</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2764" to="2770" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">OpenRec: A Modular Framework for Extensible and Adaptable Recommendation Algorithms</title>
		<author>
			<persName><forename type="first">Longqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Bagdasaryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Gruenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng-Kang</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deborah</forename><surname>Estrin</surname></persName>
		</author>
		<idno type="DOI">10.1145/3159652.3159681</idno>
		<ptr target="https://doi.org/10.1145/3159652.3159681" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining (WSDM &apos;18)</title>
		<meeting>the Eleventh ACM International Conference on Web Search and Data Mining (WSDM &apos;18)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="664" to="672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Personalizing Software and Web Services by Integrating Unstructured Application Usage Traces</title>
		<author>
			<persName><forename type="first">Longqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deborah</forename><surname>Estrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 26th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="485" to="493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Modeling the Assimilation-Contrast Effects in Online Product Rating Systems: Debiasing and Recommendations</title>
		<author>
			<persName><forename type="first">Xiaoying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhou</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Lui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM Conference on Recommender Systems</title>
		<meeting>the Eleventh ACM Conference on Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="98" to="106" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
