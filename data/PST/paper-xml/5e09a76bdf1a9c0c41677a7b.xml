<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">POLAR++: Active One-shot Personalized Article Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuhui</forename><surname>Ding</surname></persName>
						</author>
						<title level="a" type="main">POLAR++: Active One-shot Personalized Article Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Recommender systems</term>
					<term>active learning</term>
					<term>one-shot learning</term>
					<term>cold-start</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We study the problem of personalized article recommendation, in particular when the user's preference data is missing or limited, which is knowns as the user cold-start issue in recommender systems. We propose POLAR++, an active recommendation framework that utilizes Bayesian neural networks to capture the uncertainty of user preference, actively selects articles to query the user for feedback, and adaptively learns user preference with one-shot learning. For the article recommendation, we design an attention-based CNN to quantify the similarity between user preference and recommended articles, which significantly improves the performance with only a few articles rated by the users. We evaluate the proposed POLAR++ on datasets of different scale and sources. Experimental results demonstrate the effectiveness of the proposed model. We have successfully deployed POLAR++ into AMiner as the recommendation engine for article recommendation, which further confirms the effectiveness of the proposed model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>R ECOMMENDER systems play a key role in today's web applications. For example, in academic search sites such as Google Scholar and AMiner <ref type="bibr" target="#b0">[1]</ref>, article recommendation is essential for users to find the right articles as the number of articles has been increasing dramatically in the past years. The recently released Open Academic Graph (OAG) 1 consists of 208,915,369 papers, 52,678 venues, and 253,144,301 authors <ref type="bibr" target="#b1">[2]</ref>. Many digital library providers article recommendations to help users find recent or related articles. These recommendations are often based on keyword similarity between the current article and candidate articles.</p><p>An article may cover several different topics. For example, this current paper covers recommender systems, active learning, one-shot learning, and cold-start. Users with different backgrounds and interests may be interested in different topics. Recommendation results without personalization may ignore user preference and diversity, thus cannot satisfy users.</p><p>Precisely capturing users' preferences is always challenging. Still taking the academic search as an example, a large portion of the users have the cold-start problem on various topics, partially because their profiles are incomplete or missing and partially because we cannot collect sufficient data for them on the different topics. Methods based on implicit user feedback are typically preferred <ref type="bibr" target="#b2">[3]</ref>. However, the amount of user feedback might be limited. For new users, only real-time implicit feedback is possible. Therefore, it is difficult to directly apply the traditional recommenda-</p><p>• Zhengxiao Du is with the Department of Computer Science and Technology, Tsinghua University. E-mail: duzx16@mails.tsinghua.edu.cn • Jie Tang is with the Department of Computer Science and Technology, Tsinghua University. E-mail: jietang@tsinghua.edu.cn. Jie Tang is the corresponding author.  <ref type="bibr" target="#b3">[4]</ref> or Collaborative Filtering <ref type="bibr" target="#b4">[5]</ref> in this scenario. Inspired by the recent success of one-shot deep learning <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, we propose to learn a one-shot deep matching metric for personalized article recommendation by actively querying the user for feedback. For new users, we may not know their preferences. How can we efficiently and effectively acquire users' preferences through a few user interactions? Motivating Example Fig. <ref type="figure" target="#fig_0">1</ref> gives an example from AMiner.org to illustrate how to actively learn the preferences of a new user and recommending related articles. The left of the figure gives the initial state of our problem. A new user comes to the website and visits an article. Since we do not know the user's preferences, we cannot provide a personalized recommendation. The Active Interaction part shows our solution to this problem: we ask the user to give feedback to a few articles. Different colors represent articles in different fields. Once the user gives the feedback, with the help of one-shot learning, the model learns the user's preferences and accordingly recommends articles the user might be interested in, as shown in the right figure.</p><p>The problem now is the selection of the queried articles would greatly influence the final recommendation performance, as only with high-quality user feedback, one-shot learning can learn the user's preferences effectively. The articles with feedback are only a small part of articles the user might be interested in. As a result, the learned model might be overfitting to the user's interest with the limited feedback, covering only a small part of the user's interest. To this end, we propose to combine an active learning strategy with one-shot learning. However, it is still an open question on how to design a strategy to actively learn the user's preferences and intentions with minimal user efforts.</p><p>Another challenge with personalized article recommendation is that new articles come every day, without enough time to collect user opinions. Therefore, content-based recommendation methods are preferred <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>. Articles often contain highly representative texts, like the abstract of a paper. Text similarity, which plays a crucial role in recommender systems and information retrieval, poses another challenge. The bag-of-words model, on which most traditional methods are based, ignores the information about word order and co-occurrence. Therefore these methods cannot capture the matching signals in phrases or higher levels. Recently, due to the development of word embeddings and neural networks, many neural similarity models that can directly deal with word sequences are proposed <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, but they often treat all the words in an article indiscriminately. Therefore, they cannot distinguish essential parts of an article from stereotyped expressions such as the paper describes and we find that.</p><p>Contribution To address these challenges, we propose POLAR++ (PersOnaLized Article Recommendation frame-work++) 2 , to actively learn to provide personalized article recommendations. Our main contributions can be summarized as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>To tackle the active one-shot article recommendation problem, we propose a recommendation framework based on Bayesian neural networks to capture the uncertainty of user preference and actively learn a new user's preference via user interactions. The Bayesian active learning method can be applied to any deep models for ranking or recommendation with a pairwise approach.</p><p>• Combining the proposed model with densityweighted Expected Loss Optimization <ref type="bibr" target="#b16">[17]</ref>, we introduce active learning into POLAR <ref type="bibr" target="#b15">[16]</ref>, an attentionbased CNN combined with one-shot learning for personalized article recommendation to utilize extremely sparse implicit user feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>We conduct experiments on datasets of different sources and scales. Empirical results show that our framework can perform stably and significantly better than comparative methods.</p><p>2. A prior version was published in <ref type="bibr" target="#b15">[16]</ref> Organization The rest of the paper is organized as follows: Section 2 reviews related work. Section 3 and 4 are devoted to our POLAR++ framework. The experimental setting is presented in Section 5 and the experimental results are analyzed in Section 6. Section 7 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Related literature of this work can be categorized into three groups: article recommendation, one-shot learning, and active learning. In this section, we briefly review literature in the three aspects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Article Recommendation</head><p>Article recommendation plays an important role in academic search sites and digital libraries and has attracted a lot of research interest. Giles et al. introduced the first research-article recommender as part of the CiteSeer project <ref type="bibr" target="#b17">[18]</ref>. Content-based filtering <ref type="bibr" target="#b3">[4]</ref> is one of the most widely used and researched recommendation method and has been successfully applied in article recommendation <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>. Most approaches use plain words as features, although some use n-grams <ref type="bibr" target="#b19">[20]</ref>, topics <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b20">[21]</ref>, and citations <ref type="bibr" target="#b17">[18]</ref>. Collaborative filtering <ref type="bibr" target="#b4">[5]</ref> makes recommendation predictions by utilizing the explicit or implicit ratings of the current user and similar users <ref type="bibr" target="#b21">[22]</ref>. However, in article recommendation, collaborative filtering often suffers from the cold-start problem <ref type="bibr" target="#b9">[10]</ref>. Some works also use graph-based methods to explore the inherent connections in academia <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>.</p><p>Our work is also related to information retrieval <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref> and semantic matching <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>. Traditional methods for measuring the similarity between two pieces of texts, such as BM25 <ref type="bibr" target="#b25">[26]</ref> and TF-IDF <ref type="bibr" target="#b24">[25]</ref>, are based on the bag-ofwords model and do not perform well in identifying the matching of phrases and sentences. Models based on neural networks can be categorized into two groups. The first group, called representation-based models, get the distributed semantic representation of an article with neural networks and then take as the similarity score the similarity (often cosine similarity) between distributed representations of two articles <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b26">[27]</ref>. However, these models cannot identify the specific matching signals. The second group of models, called interaction-based models, use neural networks to learn the patterns in the word-level interaction of two articles, usually based on word embeddings <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b27">[28]</ref>. These models lack the explicit expressions of word weights but rather depend on the characteristics of word embeddings. Representation-based models and interaction-based models have been combined in Duet <ref type="bibr" target="#b13">[14]</ref> to improve the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">One-shot Learning</head><p>One-shot learning is essential for classification in cases where only a few examples are available. The Bayesian method in <ref type="bibr" target="#b28">[29]</ref> models the knowledge learned in other classes as a prior probability function w.r.t. the model parameters and generates a posterior density to recognize new instances given an exemplar of a novel class. Recent oneshot learning methods based on deep learning fall into two categories. Metric-based approaches try to learn a similarity metric to help predict the label of instance. In <ref type="bibr" target="#b5">[6]</ref>, a Siamese network is learned with several convolutional layers used before the fully-connected layers and the top-level energy function. Matching Nets <ref type="bibr" target="#b7">[8]</ref> take as input not only the new sample but also a small support set that contains labeled examples. An LSTM with read-attention over the support set implements the embedding function. Meta-learning-based approaches aim to learn how to update the parameters or directly predict the parameters given a few training instances, including Memory-Augmented Network <ref type="bibr" target="#b6">[7]</ref> and LSTM-based meta-learner <ref type="bibr" target="#b29">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Active Learning</head><p>Active learning is a subfield of machine learning in which a learning algorithm can choose the data from which it learns. It is closely related to Optimal Experiment Design <ref type="bibr" target="#b30">[31]</ref> in the statistic literature. There are three different scenarios: membership query synthesis <ref type="bibr" target="#b31">[32]</ref>, stream-based sampling <ref type="bibr" target="#b32">[33]</ref>, and pool-based sampling <ref type="bibr" target="#b33">[34]</ref>. One of the most common frameworks for active learning is Uncertainty Sampling <ref type="bibr" target="#b33">[34]</ref>, where the active learner selects the instance for which the prediction uncertainty is highest. The uncertainty measure includes Entropy <ref type="bibr" target="#b34">[35]</ref> for classification and Variance <ref type="bibr" target="#b35">[36]</ref> for regression. The drawback of uncertainty sampling is that it often samples the outliers or the instances with greater noise. Query-by-Committee <ref type="bibr" target="#b36">[37]</ref> is more theoreticallymotivated, which maintains a committee of models and minimizes the version space by querying in controversial regions of the input space, which are instances the committee disagree about most. Based on the decision theory, Expected Error Reduction <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref> aims to maximize the expected reduction of the generalization error, but is also the most computationally expensive framework.</p><p>Bayesian-based active learning has received much attention recently. A Bayesian information-theoretic active learning approach is presented in <ref type="bibr" target="#b39">[40]</ref>. Unlabeled instances whose prediction the parameters under the posterior disagree about are selected. Expected Loss Optimization <ref type="bibr" target="#b16">[17]</ref> selects the instance that maximizes the expected loss based on Bayesian decision theory. In <ref type="bibr" target="#b40">[41]</ref> a Bayesian active learning algorithm for deep learning in image data is proposed based on the idea in <ref type="bibr" target="#b41">[42]</ref>.</p><p>Most works that apply active learning to recommender systems are based on collaborative filtering <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b44">[45]</ref>. The active learning method is also called the Ask-To-Rate technique <ref type="bibr" target="#b45">[46]</ref>. A comprehensive survey can be found in <ref type="bibr" target="#b46">[47]</ref>. The Popularity strategy and the Coverage strategy are two representative heuristic methods, but they are not personalized. More advanced methods are based on uncertainty reduction <ref type="bibr" target="#b47">[48]</ref> or error reduction <ref type="bibr" target="#b48">[49]</ref>, <ref type="bibr" target="#b49">[50]</ref>. For example, in <ref type="bibr" target="#b43">[44]</ref> a decision tree is built to model the Ask-To-Rate process for cold-start users. However, these methods are based on collaborative filtering methods with a fixed item set, while our method utilizes the text information to provide recommendations of the latest articles. Recently, an attribute-driven active learning method for item cold-start problem is proposed in <ref type="bibr" target="#b50">[51]</ref>. They propose four heuristic criteria to select diverse and representative users for ratings. However, none of the four criteria considers the uncertainty of preference predictions, which is necessary for the efficiency in the user cold-start problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Definition</head><p>To begin with, we first define the one-shot personalized article recommendation problem as follows.</p><p>Definition 1 (One-shot Personalized Article Recommendation Problem <ref type="bibr" target="#b15">[16]</ref>). The input of the problem is a query article d q , the set of candidate articles D = {d i } N i=1 , and a support set S = {( di , ŷi )} T i=1 related to user u, where di is a support article and ŷi represents the user feedback for di . The output is a totally ordered set R(d q , S) ⊂ D with |R| = k, which is the top-k recommendation for u with respect to d q .</p><p>Note that either the query article d q or the support set S could be empty (but not both of them). In the former case, it is the purely personalized article recommendation. In the latter case, it is the non-personalized related article recommendation. At this point we assume that the support set for a user u is fixed. For a new user, the support set is empty, which means that it is impossible to provide personalized recommendations for the user.</p><p>Moving from this, we define the new problem in the pool-based sampling setting <ref type="bibr" target="#b33">[34]</ref> of active learning : Definition 2 (Active One-shot Article Recommendation Problem). The input of the problem is a query article d q , an unlabeled set U, and an interview budget b (number of feedback acquisition from the user). An active strategy π selects an article from U and gets its feedback from the user at each step until b article-feedback pairs are collected and form the actively-built support set Q. The output is the recommendation result R(d q , Q).</p><p>We define the active learning problem in the adaptive setting (which is also called Personalized Active Learning in <ref type="bibr" target="#b46">[47]</ref>). When the model selects the i-th article, it has access to the previous (i − 1) articles and ratings, so that the strategy can dynamically adapt to different users and improve the efficiency of the interview process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Bayesian Neural Networks</head><p>A Bayesian neural network is a neural network with a prior distribution on its parameters. Given the weight matrix W i and the bias vector b i for the i-th layer, we often place a Gaussian distribution over the weight matrix:</p><formula xml:id="formula_0">p(W i ) ∼ N (0, σ 2 i I)<label>(1)</label></formula><p>For simplicity, we assume a point estimate for the bias vector b i .</p><p>Let ω = {W i } L i=1 denote the set of model parameters and f ω (x) the network output with respect to input x and parameter ω. Given a training set D train , the parameter posterior is p(ω|D train ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Variational Inference by Dropout</head><p>In practice, evaluation of the true posterior p(ω|D train ) cannot be done analytically and an approximation is needed. We define an approximating variational distribution q(ω), which is easy to evaluate. The approximation should be as close to the posterior as possible, with minimal Kullback-Leibler(KL) divergence to the true posterior. Minimizing the KL divergence is equivalent to maximizing the log evidence lower bound:</p><formula xml:id="formula_1">L V I = q(ω) log p(D train |f ω (x))dω − KL(q(ω)||p(ω))</formula><p>(2) which is the basic equation of Variational Inference <ref type="bibr" target="#b51">[52]</ref>.</p><p>Following <ref type="bibr" target="#b41">[42]</ref>, we use the distribution of the network parameter with dropout <ref type="bibr" target="#b52">[53]</ref> as q(ω). Consider a neural network with only one layer, which gives output as y = σ(Mx + b). If we use dropout with zeroing probability p on the input vector x, , it's equivalent to</p><formula xml:id="formula_2">ỹ = σ(Mx + b) = σ(M( x) + b) = σ(M(diag( ) • x) + b) = σ((M • diag( ))x + b) = σ(Wx + b) i ∼ Bernoulli(1 − p) for i = 1, 2, • • • , K</formula><p>Therefore dropout on x turns the weight matrix of the network into a random variable W = M • diag( ) and M is the parameter of its distribution. We can apply dropout in every layer of a network. The corresponding distribution, which we call dropout distribution, can function as the approximating distribution q(ω).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">APPROACH</head><p>Given a query document d q and a support set S, for each article d i in D, we predict the corresponding score y i = s(d i |d q , S). k articles in D with the largest recommendation scores are selected as the top-k recommendation.</p><p>To solve the Active One-shot Article Recommendation Problem, we model the uncertainty of recommendation scores explicitly in our proposed model. Therefore, unlike our previous work, the prediction of the recommendation score is a distribution, not a single point, of R. We learn a Bayesian NN f that takes the triple x i = (d q , S, d i ) as input, and gives output f ω (x i ). We define a likelihood function over the network's output and get the distribution p(y i |f ω (x)).</p><p>It's noted that the model parameters ω are random variables with prior and posterior distribution described in Section 3.2. With the posterior of parameters, we can get the predicted distribution given a new data point x by integrating:</p><formula xml:id="formula_3">p(y|x, D train ) = p(y|f ω (x))p(ω|D train )dω<label>(3)</label></formula><p>which is also referred to as marginalizing the likelihood over ω.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">One-shot Personalized Recommendation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">One-shot Personalization</head><p>The recommendation problem for a specific user u can be considered as identifying whether u will accept an article or not and converted into binary classification. For each pair ( d, ŷ) ∈ S, ŷ is binary(1 for relevant and 0 for irrelevant). S can be seen as the training set for this classification problem, where d is a training instance and ŷ is the corresponding label. It is probable to make an analogy between oneshot learning and our problem because S is of minimal size or even empty. Inspired by <ref type="bibr" target="#b7">[8]</ref>, our model computes f ω (d q , S, d i ) as:</p><formula xml:id="formula_4">f ω (d q , S, d i ) =    c ω (d q , d i ) S = ∅ c ω (d q , d i ) + 1 |S| ( d,ŷ)∈S c ω ( d, d i )ŷ S = ∅<label>(4</label></formula><p>) where c ω (•, •) is our attention-based CNN for text similarity with parameters ω, which will be discussed in the following part. The first part of s is the matching score with the query article. The second part, the personalized score, is the normalized linear combination of the feedback in S with text similarity as coefficients, and equals zero when S is empty. The whole framework is illustrated in Figure <ref type="figure" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Attention-based CNN for Text Similarity</head><formula xml:id="formula_5">Each article d i is a sequence of l i terms [t i1 , t i2 , • • • , t ili ] (</formula><p>We use term instead of word to show that the article has gone through preprocessing including tokenization and removal of stopwords). The matching matrix of article d m and d n , M (m,n) ∈ R lm×ln , is defined as follows:</p><formula xml:id="formula_6">M (m,n) i,j = w T mi • w nj w mi • w nj<label>(5)</label></formula><p>where w mi and w nj are the word embeddings of term t mi and t nj . Since the cosine similarity of word embeddings can capture the semantic similarity <ref type="bibr" target="#b53">[54]</ref>,</p><formula xml:id="formula_7">M (m,n) i,j</formula><p>represents the similarity between t mi and t nj .</p><p>Since all terms are treated equally in the matching matrix without any weighting, the matching matrix cannot reflect the term importance, thus cannot distinguish the matching  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Object Parts Selection</head><p>In fine-grained classification <ref type="bibr" target="#b54">[55]</ref>, image patches which contain parts of certain objects are selected through a supervised process to extract discriminative features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attention Matrix</head><p>In <ref type="bibr" target="#b55">[56]</ref>, an attention matrix is employed to give different attention weights to units in a feature map.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Configurable Convolution</head><p>For visual question answering task <ref type="bibr" target="#b56">[57]</ref>, configurable convolutional kernels are generated by transforming the question embeddings from the semantic space into the visual space, which implements the question-guided attention.</p><p>signals of essential terms from those of structural, unimportant terms.</p><p>To add the attention mechanism, we go over several applications of the attention mechanism in CNN in Table <ref type="table" target="#tab_1">1</ref>. We think the attention matrix, which can represent the importance of units in the feature map, quite suitable for our problem. The attention matrix, A (m,n) ∈ R lm×ln is defined as follows:</p><formula xml:id="formula_8">A (m,n) i,j = r mi • r nj<label>(6)</label></formula><p>where r mi and r nj are the weights of term t mi and t nj .</p><p>The matching matrix M (m,n) and the attention matrix A (m,n) are combined by element-wise multiplication:</p><formula xml:id="formula_9">Z (m,n) = M (m,n) ⊗ A (m,n)<label>(7)</label></formula><p>Z (m,n) is the input of a CNN that consists of several convolutional layers and max-pooling layers. Similar to CNNs in image recognition <ref type="bibr" target="#b57">[58]</ref>, the filters in low-level convolutional layers can capture different matching signals between phrases, while the filters in high-level convolutional layers can capture the matching signals between sentences and paragraphs. The max-pooling layers can downsample the signals and reduce the spatial size of feature maps.</p><p>The output of the last max-pooling layer is then turned into a vector and passed through an MLP with several hidden layers. In this paper, we use only one hidden layer. For the final output, a single unit is connected to all the units of the last hidden layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Local Weight and Global Weight</head><p>Traditional methods for text similarity often combine two types of term weights: the local weight, which depends on the specific document where the term occurs, and the global weight, which relies on the property of the whole corpus. Take the TF-IDF <ref type="bibr" target="#b24">[25]</ref> method as an example. The TF (term frequency, how many times the term occurs in the given document) is the local weight, and the IDF (inverse document frequency, the inverse of how many documents the term occurs in) is the global weight.</p><p>We also combine the two weights in our model. The final weight of a term is the product of its local and global weights: where µ ij and υ ij are respectively the local and global weights of the term t ij .</p><formula xml:id="formula_10">r ij = µ ij • υ ij<label>(8)</label></formula><p>Local Weight: The local weight measures the relevance of a term to the subject of the document. For example, in the following text <ref type="bibr" target="#b58">[59]</ref>:</p><p>Example 1. We propose a low-complexity audio-visual person authentication framework based on multiple features and multiple nearest-neighbor classifiers. The proposed MCCN method delivers a significant separation between the scores of client and impostors as observed on trials run on a unique database.</p><p>nearest-neighbor, classifier and features are obviously more important than complexity and database, and should have higher local weights, because they are more related to the topic of the text: audio-visual authentication.</p><p>Traditionally, the local weight is a math function of the frequency that the term occurs in a document, such as the term frequency (TF) in TF-IDF <ref type="bibr" target="#b24">[25]</ref> or BM25 <ref type="bibr" target="#b25">[26]</ref> ranking function:</p><formula xml:id="formula_11">BM25(d, q) = n i=1 IDF(q i ) f (q i , d)(k 1 + 1) f (q i , d) + k 1 (1 − b + b |d| l )<label>(9)</label></formula><p>where q i is the i-th term of the query, f (q i , d) is the term frequency of q i in d and l is the average length of documents. k 1 and b are free parameters.</p><p>The basic idea of these methods is that the more important for a document a term is, the more frequently it occurs in the document. This is not always true. In Example 1, the important terms such as authentication and classifier occur only once, while the terms that occur more than once are stopwords like of and on. Therefore, a better mechanism for local weights is needed.</p><p>Inspired by <ref type="bibr" target="#b59">[60]</ref>, we propose a local weight network based on distributed word representations. The basic idea is that, because of the linearity of word embeddings, the subject of a document can be expressed as the mean of vectors of its terms. The difference between the mean vector and term vector can be seen as the semantic difference between the document and the term.</p><p>The input vector x ij for the local weight µ ij is the difference between the word vector w ij and the mean vector of d i :</p><p>x</p><formula xml:id="formula_12">ij = w ij − w i<label>(10)</label></formula><p>where</p><formula xml:id="formula_13">w i = 1 n i ni k=1 w ik (<label>11</label></formula><formula xml:id="formula_14">)</formula><p>Figure <ref type="figure" target="#fig_2">3</ref> gives an illustration of the feature vector.</p><p>We employ a feed-forward network to learn the patterns in the feature vector x ij and produce the local weight. The network is a multilayer perceptron(MLP) with multiple hidden layers and gives outputs within an interval.</p><formula xml:id="formula_15">µ ij = σ(W (L) • u (L) ij + b (L) ) + α (<label>12</label></formula><formula xml:id="formula_16">)</formula><p>where L is the number of hidden layers in the feed-forward network, u</p><formula xml:id="formula_17">(L)</formula><p>ij is the output of the last hidden layer, and σ is the Sigmoid function. α is a nonnegative hyperparameter to set a lower bound and avoid giving a term a local weight close to 0. The ratio of the maximum value to the minimum value of local weights is 1 + 1 α . It indicates that the smaller α is, the wider the range of local weights is.</p><p>Global Weight: The global weight measures how distinctive and specific a term is. It is independent of the specific document but depends on the whole corpus. For example, in a set of papers on computer science, computer and software are less specific than medicine and neural and should be given lower global weights. However, in a medical document corpus, it may just be the reverse.</p><p>The most widespread form of global weights is the inverse document frequency (IDF). The idea is that the specificity of a term can be quantified as an inverse function of its document frequency. There are a whole family of inverse functions, and the most common one is:</p><formula xml:id="formula_18">IDF(t) = log( N n t ) (<label>13</label></formula><formula xml:id="formula_19">)</formula><p>where t is the aim term, n t is the document frequency of t and N is the total number of documents in the corpus. Since the IDF measure has long been used and the use of other measures such as PageRank did not lead to better results, here we also employ IDF as the measure of global weights. But to narrow the range of global weights and control the effect, instead of the raw IDF values, we use:</p><formula xml:id="formula_20">υ ij = [IDF(t ij )] β<label>(14)</label></formula><p>where β is a hyperparameter within the interval (0,1). The smaller β is, the narrower the range of global weights is.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Bayesian Active Learning in Recommendation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Pairwise Loss for Bayesian Learning</head><p>We formulate the training set in the setting of Pairwise Approach of Learning to Rank <ref type="bibr" target="#b60">[61]</ref>. It means that D train = {(d q and support set S (i) . We transform it into the constraint on the recommendation score as y</p><formula xml:id="formula_21">(i) q , S (i) ), d (i) + , d<label>(i)</label></formula><formula xml:id="formula_22">(i) + − y (i)</formula><p>− ≥ 1 and the log likelihood in the first term of (2) becomes:</p><formula xml:id="formula_23">log p(D train |f ω (x)) = N i=1 log p(y (i) + − y (i) − ≥ 1)|f ω (x (i) + ), f ω (x (i) − ) Let f + and f − denote f ω (x + ) and f ω (x − ) p(y + − y − ≥ 1|f + , f − ) = ∞ f− ∞ y−+1 p(y + |f + )p(y − |f − )dy + dy −</formula><p>The distribution of the score given model output, p(y|f ω (x)), partly decides the form of our objective function. We didn't use a Normal distribution like most cases, because the square difference of the Normal distribution can show an unstable behavior in the initial points of the Neural Network weight optimization. Instead, we define the distribution p(y|f ω (x)) as an Exponential Distribution:</p><formula xml:id="formula_24">p(y|f ω (x)) = τ exp(−τ (y − f ω (x))) y ≥ f ω (x) 0 y &lt; f ω (x) (<label>15</label></formula><formula xml:id="formula_25">)</formula><p>where τ is the model precision.</p><p>With this distribution, we have:</p><formula xml:id="formula_26">p(y + − y − ≥ 1|f + , f − ) = ∞ f− ∞ y−+1 τ 2 exp(−τ (y + − f + + y − − f − ))dy + dy − When f + − f − ≤ 1, it is equal to ∞ f− τ exp(−τ (2y − − f + − f − + 1))dy − = 1 2 exp(−τ (f − − f + + 1)) When f + − f − &gt; 1, it is equal to f+−1 f− ∞ f+ τ 2 exp(−τ (y + − f + + y − − f − ))dy + dy − + ∞ f+−1 ∞ y−+1 τ 2 exp(−τ (y + − f + + y − − f − ))dy + dy − =1 − exp(−τ (f + − f − − 1)) + 1 2 exp(−τ (f + − f − − 1)) =1 − 1 2 exp(−τ (f + − f − − 1))</formula><p>Therefore we have</p><formula xml:id="formula_27">log(D train |f ω (x)) = N i=1 E ω [(d (i) q , S (i) ), d<label>(i)</label></formula><p>+ , d</p><formula xml:id="formula_28">(i) − ]</formula><p>where</p><formula xml:id="formula_29">E ω [(d q , S), d + , d − ] = τ (1 − f + + f − ) f + − f − ≤ 1 log(1 − 1 2 exp(−τ (f + − f − − 1))) f + − f − &gt; 1<label>(16)</label></formula><p>When f + − f − ≤ 1, this function is the same as the hinge loss function except for the coefficient τ . However, when f + − f − &gt; 1, the loss will not directly drop to zero, but gradually decrease to zero as f + − f − increases. Therefore, it can be considered as the smoothed version of hinge loss.</p><p>As for the second term in (2), it's proved in <ref type="bibr" target="#b41">[42]</ref> that it can be approximated by L2 regularization term</p><formula xml:id="formula_30">Wi∈ω λ i ||W i || 2 ,</formula><p>as long as the weight decay λ i satisfies:</p><formula xml:id="formula_31">λ i = 1 − p i 2σ 2 i (<label>17</label></formula><formula xml:id="formula_32">)</formula><p>where p(W i ) ∼ N (0, σ 2 i I). Above all, maximizing (2) can be approximated as minimizing the following loss function</p><formula xml:id="formula_33">L = −q(ω) N i=1 E ω (D (i) train )dω + Wi∈ω λ i ||W i || 2 (18)</formula><p>The final problem is, to minimize the above loss function, we have to integrate over the parameter space. The integration can be approximated by Monte-Carlo Sampling from q(ω). For a neural network with dropout, Monte-Carlo Sampling is equivalent to forward pass with dropout. Therefore, minimizing the objective in ( <ref type="formula">2</ref>) is equivalent to optimizing the following loss function in neural networks:</p><formula xml:id="formula_34">L = − N i=1 E ω (D (i) train ) + Wi∈ω λ i ||W i || 2<label>(19)</label></formula><p>After training, forward pass with dropout through the network is equivalent to sampling from the optimal distribution q * (ω). This leads to a Monte-Carlo integration to compute the predicted distribution:</p><formula xml:id="formula_35">p(y|x, D train ) = p(y|f ω (x))p(ω|D train )dω ≈ p(y|f ω (x))q * (ω)dω ≈ 1 T T t=1 p(y|f ωt (x))</formula><p>where ωt ∼ q * (ω), which is the model parameter sampled from optimal dropout distribution. The optimization is done through standard backpropagation <ref type="bibr" target="#b61">[62]</ref> and stochastic gradient descent method with mini-batches. For regularization, we use dropout in the output of every hidden layer and early stopping strategy <ref type="bibr" target="#b62">[63]</ref> to avoid over-fitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Expected Loss Optimization</head><p>The active learning metric we choose is Expected Loss Optimization <ref type="bibr" target="#b16">[17]</ref>. The basic idea is to choose the instance that maximizes the expected loss of the current best action. For the ranking problem, the action for an instance refers to deciding its ranking in the list. Therefore the expected loss for article d i given d q and S is</p><formula xml:id="formula_36">EL(d i |d q , S) = Y i min π yi</formula><p>l(π, Y)P (Y|(d q , S), D train )dy i dY i (20)   where l(•, •) is the loss function, Y is the vector of the recommendation scores of all the documents and Y i is Y after removing y i .</p><p>For ranking problem, we define the loss function as the difference between the DCG for current ranking and the ranking with the largest DCG:</p><formula xml:id="formula_37">l(π, Y) = max π DCG(π , Y) − DCG(π, Y)<label>(21)</label></formula><p>where DCG(π, Y) = i yi log 2 (1+π(i)) . Combining <ref type="bibr" target="#b19">(20)</ref> and ( <ref type="formula" target="#formula_37">21</ref>), we have:</p><formula xml:id="formula_38">EL(d i |d q , S) = Y i [ yi max π DCG(π, Y)P (Y|(d q , S), D train )dy i − max π yi DCG(π, Y)P (Y|(d q , S), D train )dy i ]dY i<label>(22)</label></formula><p>An important property of expected loss for ranking is that it considers not only the uncertainty of the article's predicted score, but also its current ranking among unlabeled Algorithm 1 Active Personalized Article Recommendation Algorithm Input: A new user u, the query document d q , an unlabeled set U, the query budget b. Output: The support set S for u S ← ∅ for i=1to N do {N=size of unlabeled set} a i ← N j=1 c(d i , d j ) end for for n=1to b do for i = 1 to T do {T=number of MC sampling} for j = 1 to N do Take forward pass through the network with dropout and get the output y i j = f (d q , S, d i ) end for end for for j = 1 to N do EL(j) ← 0</p><formula xml:id="formula_39">g j ← N k=1 y k j N for i = 1 to T do d i j ← BDCG({y i k } N k=1 )) for k = 1 to N ,k = j do g k ← y i k end for EL(j) ← EL(j) + d i j − BDCG({g k } N k=1 ) end for end for i ← argmax (dj ,u(dj ) / ∈S) a j • EL(j) S ← S ∪ {(d i , u(d i ))} end for</formula><p>articles. With the same predicted uncertainty, the article with a higher ranking has a higher expected loss. In this way, ELO surpasses traditional uncertainty sampling, which only considers the prediction uncertainty.</p><p>However, ELO can still be troubled by outliers, the instances that are located in the sparse area of the input space. We further propose to combine the density with ELO:</p><formula xml:id="formula_40">argmax di EL(d i |d q , S) × 1 |U| dj ∈U c(d i , d j )<label>(23)</label></formula><p>where c(d i , d j ) is the similarity between d i and d j predicted by our CNN model. The latter part in <ref type="bibr" target="#b22">(23)</ref> is the average similarity between d i and articles in U. <ref type="bibr" target="#b22">(23)</ref> aims to find the instance that is representative of most unlabeled articles while maximizing the expected loss at the same time. The completed algorithm for active learning is described in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DATASET AND EXPERIMENT SETTING</head><p>To evaluate the proposed model, we conduct experiments on article recommendation problem in non-personalized setting, personalized setting, and active setting, based on datasets of different sources and scales, in comparison with baselines in both article recommendation and active learning. In this section, we will introduce the dataset and experiment setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dataset</head><p>We evaluate the performance of the proposed model on article recommendation two small, manually labeled datasets and a large-scale dataset based on user clicks.</p><p>The first dataset is based on papers from AMiner <ref type="bibr" target="#b0">[1]</ref> and consists of 188 query papers with ten candidate papers for each query. The second dataset is based on documents of patents coming from the Patent Full-Text Databases of the United States Patent and Trademark Office 3 and consists of 67 queries with 20 candidates for each query. In each dataset, we gather relevance judgments from college students or experts on patent analysis as the ground truth. The relevance is expressed as binary: relevant or irrelevant. Abstracts of the papers or the patent documents are used as texts and texts longer than 96 terms are truncated.</p><p>The third dataset is Related-Article Recommendation Dataset (RARD) <ref type="bibr" target="#b63">[64]</ref> from Sowiport, a digital library of social science articles that displays related articles to its users. The dataset contains 63923 distinct queries with user click log. Each query article has an average of 9.1 articles displayed. A recommender-as-a-service provider Mr. DLib generates the displayed documents, so they are of high relevance to the query. We choose 800 queries that have the most clicks for test and other queries are used for training. Since the abstracts of some articles are missing, the titles and the abstracts of articles are combined as texts. Texts longer than 64 terms are truncated.</p><p>To conduct experiments on Active One-shot Article Recommendation Problem, we use the Citation Network Dataset in AMiner <ref type="bibr" target="#b0">[1]</ref>. The citation data is extracted from DBLP, ACM, MAG (Microsoft Academic Graph), and other sources. The version we used contains 3,272,991 papers and 8,466,859 citations. The citations of a paper are randomly divided into two equal parts. The first part is used as the support set(or unlabeled set in Active Learning setting) and the second part is used as the positive recommendations for training and evaluation. To ensure the quality, we randomly select the negative recommendations from the neighborhood of the paper in the citation network. Abstracts of papers are used as texts and texts longer than 96 terms are truncated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Baselines for Article Recommendation</head><p>The following are several traditional methods.</p><p>• TF-IDF <ref type="bibr" target="#b24">[25]</ref>: The similarity score between a query and a document is computed by summing the weights of the query's terms which also occur in the document. The weight of a term is the product of its TF and IDF weights. Results of relevance ranking(%). NG stands for NDCG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AMiner</head><p>Patent RARD Method NG@3 NG@5 NG@10 NG@3 NG@5 NG@10 NG@1 NG@3 NG@5 The following are several neural matching models.</p><p>• MV-LSTM <ref type="bibr" target="#b12">[13]</ref>:The interactions between different positional sentence representations generated by a Bi-LSTM form a similarity matrix to generate the matching score.</p><p>•</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MatchPyramid [12]:</head><p>A CNN is built on the standard matching matrix to get the matching score.</p><p>• DRMM <ref type="bibr" target="#b27">[28]</ref>:The matching between the terms in the query and the document is expressed as a histogram, where only the counts of the matching score in different intervals are reserved. The histogram is sent to an MLP to get the matching score. For the fairness of comparison, all models don't involve user feedback, which will be discussed in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Baselines for Active Learning</head><p>• Random: The active documents are selected randomly from the unlabeled set. Any method that can't beat this baseline doesn't make sense.</p><p>• Entropy: The entropy is a standard uncertainty measure for classification gained from information theory. We define the recommendation problem as binary classification to predict the recommendation score is 0 or 1 and p i = p(y i = 1), then</p><formula xml:id="formula_41">H[y i ] = −[p i log p i + (1 − p i ) log (1 − p i )]</formula><p>• Relevance: For this method we always choose the document that has the largest recommendation score, which means it's the most relevant to the user's known preference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Expected Error Reduction [38]:</head><p>The active selection strategy is to maximize the expected reduction of the loss function after retraining the model on the new training set. We use the cross entropy as the loss function.</p><p>• BALD <ref type="bibr" target="#b39">[40]</ref>: The active selection strategy is to maximize the expected reduction of parameter entropy after retraining the model on the new training set. By removing the part unrelated to x and rearrange the order of integral, the objective can become entropies in y space:</p><formula xml:id="formula_42">argmax x H(y|x, D train )−E ω∼p(ω|Dtrain) [H[y|f ω (x)]]</formula><p>The following are several variations of our proposed model:</p><p>• POLAR++Variance: The variance is a common uncertainty measure for regression. We use</p><formula xml:id="formula_43">E[•] to de- note E ω∼p(ω|Dtrain),y∼p(y|f ω (x)) [•] Var(y|x, D train ) =E[(y − E[y|ω]) 2 ] + E[(E[y|ω] − E[y]) 2 ]</formula><p>The first term is a constant ( 1 τ ) 2 dependent on the model precision. The second term can be approximated by the variance of predicted y in Monte-Carlo Sampling.</p><p>• POLAR++ELO The active selection strategy is to maximize the Expected Loss for Ranking without density according to <ref type="bibr" target="#b21">(22)</ref>.</p><p>• POLAR++DWELO DWELO (Density-Weighted Expected Loss Optimization) is the complete active leraning algorithm which combines ELO and density, as described in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Parameter Setting</head><p>The word embeddings in all the models above are 256 dimensions trained on Wikipedia via the skip-gram model, using hierarchical softmax and negative sampling <ref type="bibr" target="#b53">[54]</ref>.</p><p>In the Local Weight Network there are two hidden layers, with 64 and 32 hidden units respectively. The CNN has three convolutional layers and three max-pooling layers. The first and second convolutional layers both have 32 filters and the third convolutional layer has 16 filters. All convolutional filters are set to 3 × 3 and all max-pooling kernels are set to 2 × 2. The number of hidden units in the full-connected layer is set to 256. For the hyperparameters α and β, we set α = 1 and β = 1  4 , which is discussed in Section 6.</p><p>We set T in Algorithm 1, the number of MC sampling, as 32, to balance the precision and time complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULT AND ANALYSIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Non-Persoalized Setting</head><p>In the non-personalized setting, only the query article is given while the support set is kept empty. Table <ref type="table">2</ref> shows the ranking accuracy of different methods in terms of NDCG.</p><p>From the evaluation results, we can observe that our proposed model POLAR can perform better than all the baselines. POLAR can outperform the best baselines 6.9%-13.2%  on NDCG@3 and 3.3%-20.3% on NDCG@5. The average improvements of NDCG on each dataset are respectively 3.8%, 8.1% and 6.4%.</p><p>Among the traditional ranking models, TF-IDF is the most competitive one, even outperforming the best neural baselines by 5.5% in some cases. But we can also find that TF-IDF performs not very well on the patent dataset. The reason might be that documents of patents are often written by non-academic researchers and terms on the same topic might vary from person to person. Only taking the exact matching signals into account, TF-IDF might be unsuitable for such a situation, while the methods based on word embeddings can perform better.</p><p>As for the neural ranking models, we can see that interaction-based models, including DRMM and Match-Pyramid, perform slightly better than representation-based models. Although the Duet combines the interaction-based model and the representation-based model, it doesn't perform better than individual interaction-based models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Personalized Setting</head><p>We utilize the datasets in the previous part to simulate the personalization problem. We select those queries that have more than one positive-labeled candidate. For every query, we randomly divide the labeled documents two parts. The first part is used as the support set, and the second part is used as the candidate set to recommend. Then we compare the proposed one-shot framework (called POLAR- The support set is quite sparse compared with the size of candidates. For example, in the RARD dataset, the average size of support set for each query is only 1.5. In the AMiner dataset, the size of the support set is only 1 for 45% queries and 2 for 47%. In the patent dataset, the sizes of 75% support sets are no greater than 3.</p><p>The result is shown in table <ref type="table" target="#tab_3">3</ref>. We can see that the performance can be improved with a small amount of feedback data. On average, POLAR-OS can outperform POLAR-ALL by 7.0% on NDCG@1 and 5.7% on NDCG@3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Active Learning Setting</head><p>In this section, we show that the proposed active learning method can effectively select informative articles to improve recommendation performance in the active learning setting. For each recommendation episode, the support set is empty at the beginning. At each step, we select an unlabeled article according to the evaluated method and add the article and corresponding label to the support set. Following the traditional evaluation method for active learning, we show the NDCG of different strategies as the function of rated articles. Fig. <ref type="figure" target="#fig_6">4</ref> shows the NDCG comparison results on the Citation Dataset.</p><p>We can see that POLAR++DWELO can outperform all the baselines w.r.t. NDCG@n metrics. As n increases, the margin between our method and baselines continuously increases. This is also reasonable because when n is small, even the worst strategy can find a few articles that the user must be interested in. A wise strategy aims to find the complete preferences of the user.</p><p>All the baselines can achieve better performance than the Random strategy, which proves their utility in active learning. Among all the non-random baselines, the Relevance strategy performs worst, because the Relevance strategy always chooses the article that is most relevant to the user's known preferences, but often less informative.</p><p>The Expected Error Reduction method can perform best at first but soon fails. As the number of rated articles increases, its performance even falls behind Relevance strategy. This is because it chooses the article which can reinforce the existing belief over the unlabeled articles. Therefore it can be restricted to the user's partial interest.</p><p>For uncertainty based method, BALD performs slightly better than Entropy. This is quite surprising because BALD is derived from minimizing the entropy of parameter posterior, which does not make sense in our one-shot learning setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">More Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.1">Comparison of Different Variations of POLAR++</head><p>For simplicity, we only show the result of the complete algorithm, POLAR++DWELO, along with those of baselines, in Fig. <ref type="figure" target="#fig_6">4</ref>. The NDCG comparison results among different variations of our proposed method are shown in Fig. <ref type="figure" target="#fig_7">5</ref>.</p><p>Both without the help of density information, POLAR++ELO can significantly outperform PO-LAR++Variance. This confirms our idea in Section 4.2.2: Expected Loss Optimization is a better active learning strategy for the ranking problem than Uncertainty Sampling, because it considers not only the prediction uncertainty but also the relative ranking in the list. The density-weighted version of ELO, POLAR++DWELO, This proves that with the help of density information, the algorithm can choose the informative articles, rather than outliers, the articles that are not representative in document space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.2">How the Attention Matrix Can Help</head><p>To illustrate the improvements different parts of the attention matrix bring, we compare three versions of the proposed model with different attention matrices. To compute the attention matrix, POLAR-LOC uses only the local weights and POLAR-GLO uses only the global weights. POLAR-ALL uses both local weights and global weights.</p><p>The performance in terms of NDCG@3 is shown in Figure <ref type="figure" target="#fig_8">6</ref>.3. In most cases, POLAR-LOC, the model with the local weight network performs better than POLAR-GLO. The reason might be that the local weight network is trainable, with greater ability to learn the importance of terms. IDF is only a statistical way to get approximate global weights. The complete model, POLAR-ALL, which combines the two weights, performs significantly better than either of them. This confirms that the local and global weights are complementary to each other. However, we also see that in RARD, the performances of POLAR-LOC and POLAR-All are quite close, which is against the result on other datasets. We guess the reason might be that RARD dataset is in German and contains less unlabeled texts. This can lead to the inaccurate global weights based on IDF values and as a result, global weight matrix cannot help much in POLAR-ALL.</p><p>To have a better understanding of how local and global weights work, we show the pixel images of four matrices in Figure <ref type="figure" target="#fig_9">7</ref>. From the images we can find that the local weights of most terms are low while the global weights of most terms are high. The statistical analysis of the local and global weights in Table <ref type="table" target="#tab_4">4</ref> also supports this idea. Therefore, we can conclude that the global weights function by deemphasizing unimportant terms in the corpus with low weights, while the local weights function by highlighting key terms in specific articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.3">Sensitivity Analysis of Hyperparameters</head><p>Since there are two hyperparameters α and β to control the effect of the local and global weights in our proposed model, we further study the effect of different choices of α and β. The result is shown in figure <ref type="figure" target="#fig_10">8</ref> In general, the variance in β has greater effect than that in α. In our model the global weights are predefined values which couldn't be changed once β is chosen, while the local weights are calculated by the local weight network, which can automatically adapt to different choices of α. Therefore it is important to choose the value of β. When β is close to 1, the global weights are equal to IDF values, which vary so greatly that the model will ignore the effect of cosine similarity. When β is close to 0, the global weights are almost uniform and have little effect.But the model with the value of α equal to 0 cannot perform well either, because the local weight network can have too strong effect and be troubled by over-fitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION AND FUTURE WORK</head><p>In this paper, we study the problem of actively learning users' preference in article recommendation. We define the Active One-shot Article Recommendation Problem, which is extended from our previous definition of One-shot Personalized Article Recommendation. We propose a novel framework POLAR++ in which an active learning algorithm based Bayesian NN is applied to deal with the user coldstart issue. An attention-based CNN model for text similarity is combined with the framework of one-shot learning to deal with sparse user feedback. Experimental results show that the proposed model significantly outperforms both the traditional and the state-of-art neural baselines. The model has been used in AMiner to provide recommendations of similar papers.</p><p>The limit of our model is that it combines the information of different support articles at a high level. Our future work might consider combining the information of different support articles at lower levels, such as iterating over the support set with an LSTM or CNN. Moreover, we would like to combine our model with Reinforcement Learning to train a deeper and more powerful model in the online environment. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Left: a motivation example for Active One-shot Article Recommendation Problem and our solution. Right: the one-shot personalized recommendation with the user's feedback and the ranking performance comparison of POLAR++ and several active learning baselines.</figDesc><graphic url="image-1.png" coords="2,48.00,43.69,516.00,190.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The architecture of the overall framework. The articles are transformed into sequences of word embeddings through the embedding layer. The attention matrix and matching matrix are computed and sent to the CNN. The matching scores are combined with the support set gained from active interaction with the user to get the final scores.</figDesc><graphic url="image-2.png" coords="5,48.00,43.70,516.00,269.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. A two-dimensional example of the feature vectors for local weights.</figDesc><graphic url="image-3.png" coords="6,48.00,43.69,252.01,94.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>•Doc2Vec [ 65 ]:</head><label>65</label><figDesc>We get the distributed representation of each article via Paragraph Vector model. The similarity score between two articles is produced by the cosine similarity of their representations.• WMD<ref type="bibr" target="#b65">[66]</ref>:The Word Mover's Distance (WMD) is the minimum distance required to transport words from one document to another based on the word embeddings. 3. http://patft.uspto.gov/ TABLE 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>•Duet [ 14 ]</head><label>14</label><figDesc>:An interaction-based model and a representation-based model are combined to get the matching score of two articles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. NDCG@5,10 and 20 as the functions of queried articles for different active learning methods.</figDesc><graphic url="image-5.png" coords="10,48.00,224.09,515.93,133.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. NDCG@5, 10 and 20 as the functions of queried articles for different variations of POLAR++.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. The performance of different attention matrices.</figDesc><graphic url="image-6.png" coords="11,48.00,43.70,516.00,117.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. The visualization result of four matrices used in the matching of a pair of texts. The brighter the pixel is, the larger value it has. The text pair is as follows(the words in brackets are removed stopwords): T1:novel robust stability criteria (for) stochastic hopfield neural networks (with) time delays; T2:new delay dependent stability criteria (for) neural networks (with) time varying delay.</figDesc><graphic url="image-7.png" coords="12,85.37,43.69,438.56,109.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Performance comparison for POLAR-LOC with different α and POLAR-GLO with different β on the AMiner dataset.</figDesc><graphic url="image-8.png" coords="13,98.27,43.70,412.77,139.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 1 Attention</head><label>1</label><figDesc></figDesc><table /><note>mechanisms in CNNMethodDescription</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 3</head><label>3</label><figDesc>Performance for the model with one shot learning and without. NG stands for NDCG.</figDesc><table><row><cell></cell><cell cols="2">AMiner</cell><cell cols="2">Patent</cell><cell cols="2">RARD</cell></row><row><cell>Method</cell><cell cols="6">NG@1 NG@3 NG@1 NG@3 NG@1 NG@3</cell></row><row><cell>POLAR-ALL</cell><cell>76.1</cell><cell>79.2</cell><cell>52.3</cell><cell>66.2</cell><cell>36.5</cell><cell>36.5</cell></row><row><cell>POLAR-OS</cell><cell>79.1</cell><cell>81.9</cell><cell>57.1</cell><cell>69.7</cell><cell>39.4</cell><cell>39.2</cell></row><row><cell cols="7">OS) with the best model that ignores support sets in the</cell></row><row><cell cols="4">previous part (called POLAR-ALL).</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 4</head><label>4</label><figDesc>The statistical analysis of the local and global weights.</figDesc><table><row><cell>Weight</cell><cell>Max</cell><cell>Min</cell><cell>Mean</cell><cell>Std</cell></row><row><cell>Local</cell><cell>2.00</cell><cell>1.00</cell><cell>1.20</cell><cell>0.15</cell></row><row><cell>Global</cell><cell>1.96</cell><cell>1.08</cell><cell>1.86</cell><cell>0.08</cell></row><row><cell cols="5">can further perform slightly better than POLAR++ELO.</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The work is supported by the National Key R&amp;D Program of China (2018YFB1402600), NSFC for Distinguished Young Scholar (61825602), and Tsinghua University Initiative Scientific Research Program (20181080300).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Arnetminer: Extraction and mining of academic social networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="990" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Oag: Toward linking large-scale heterogeneous entity graphs</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;19</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2585" to="2595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Bandit learning with implicit feedback</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="7287" to="7297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Content-based recommendation systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Pazzani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Billsus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Adaptive Web, Methods and Strategies of Web Personalization</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="325" to="341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Empirical analysis of predictive algorithms for collaborative filtering</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Breese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kadie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
				<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName><forename type="first">G</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Deep Learning Workshop</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Meta-learning with memory-augmented neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1842" to="1850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Collaborative topic modeling for recommending scientific articles</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Research-paper recommender systems: a literature survey</title>
		<author>
			<persName><forename type="first">J</forename><surname>Beel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gipp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Langer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Breitinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. on Digital Libraries</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="305" to="338" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning deep structured semantic models for web search using clickthrough data</title>
		<author>
			<persName><forename type="first">P.-S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2333" to="2338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Text matching as image recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2793" to="2799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A deep architecture for semantic matching with multiple positional sentence representations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2835" to="2841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning to match using local and distributed representations of text for web search</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>WWW</publisher>
			<biblScope unit="page" from="1291" to="1299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">End-to-end neural ad-hoc ranking with kernel pooling</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Power</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Polar: Attention-based cnn for oneshot personalized article recommendation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML/PKDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="675" to="690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Active learning for ranking through expected loss optimization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Inagaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1180" to="1191" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Citeseer: An autonomous web agent for automatic retrieval and identification of interesting publications</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Autonomous Agents</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="116" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Context-aware citation recommendation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>WWW</publisher>
			<biblScope unit="page" from="421" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A keyphrase-based paper recommender system</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ferrara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pudota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tasso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Digital Libraries and Archives -7th Italian Research Conference, IRCDL 2011</title>
				<meeting><address><addrLine>Pisa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">January 20-21, 2011. 2011</date>
			<biblScope unit="page" from="14" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Recommending academic papers via users&apos; reading purposes</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="241" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Collaborative filtering by personality diagnosis: A hybrid memory and model-based approach</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Pennock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
				<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="473" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Research paper recommender systems: A random-walk based approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Web Intelligence</title>
				<imprint>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="page" from="778" to="781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Relational retrieval using a combination of path-constrained random walks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="53" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Extended boolean information retrieval</title>
		<author>
			<persName><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1022" to="1036" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Okapi at TREC-3</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC</title>
				<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="109" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep sentence embedding using long short-term memory networks: Analysis and application to information retrieval</title>
		<author>
			<persName><forename type="first">H</forename><surname>Palangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Audio, Speech and Lang. Proc</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="694" to="707" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A deep relevance matching model for ad-hoc retrieval</title>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">One-shot learning of object categories</title>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="594" to="611" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Theory of Optimal Experiments</title>
		<author>
			<persName><forename type="first">V</forename><surname>Federov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972">1972</date>
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Queries and concept learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Angluin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="319" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Training connectionist networks with queries and selective sampling</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Atlas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Ladner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="566" to="573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A sequential algorithm for training text classifiers</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Gale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A mathematical theory of communication</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell system technical journal</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Active learning with statistical models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="705" to="712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Selective sampling using the query by committee algorithm</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="133" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Toward optimal active learning through sampling estimation of error reduction</title>
		<author>
			<persName><forename type="first">N</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="441" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Optimistic active-learning using mutual information</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Greiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="823" to="829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Bayesian active learning for classification and preference learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Huszar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lengyel</surname></persName>
		</author>
		<idno>abs/1112.5745</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deep bayesian active learning with image data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1183" to="1192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dropout as a bayesian approximation: Representing model uncertainty in deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1050" to="1059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A bayesian approach toward active learning for collaborative filtering</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
				<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Adaptive bootstrapping of recommender systems using decision trees</title>
		<author>
			<persName><forename type="first">N</forename><surname>Golbandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lempel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="595" to="604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Personalized active learning for collaborative filtering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Harpale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2008</title>
				<meeting>the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2008<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">July 20-24, 2008, 2008</date>
			<biblScope unit="page" from="91" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Cold-start problem in collaborative recommender systems: Efficient methods based on ask-to-rate technique</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nadimi-Shahraki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bahadorpour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CIT</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="105" to="113" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A survey of active learning in collaborative filtering recommender systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rubens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science Review</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="29" to="50" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Influence-based collaborative active learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Rubens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 ACM Conference on Recommender Systems, RecSys 2007</title>
				<meeting>the 2007 ACM Conference on Recommender Systems, RecSys 2007<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">October 19-20, 2007, 2007</date>
			<biblScope unit="page" from="145" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Output divergence criterion for active learning in collaborative settings</title>
		<author>
			<persName><forename type="first">N</forename><surname>Rubens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tomioka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information and Media Technologies</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="119" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Collaborative filtering via gaussian probabilistic latent semantic analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="259" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Addressing the item cold-start problem by attribute-driven active learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<idno>abs/1805.09023</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Variational inference: A review for statisticians</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kucukelbir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mcauliffe</surname></persName>
		</author>
		<idno>abs/1601.00670</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">The application of two-level attention models in deep convolutional neural network for fine-grained image classification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="842" to="850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">ABCNN: attentionbased convolutional neural network for modeling sentence pairs</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sch Ütze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="259" to="272" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">ABC-CNN: an attention based convolutional neural network for visual question answering</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
		<idno>abs/1511.05960</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="818" to="833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Audio visual person authentication by multiple nearest neighbor classifiers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICB</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1114" to="1123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Learning to reweight terms with distributed representations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="575" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Learning to rank using gradient descent</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Renshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lazier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Deeds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Hullender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="issue">6088</biblScope>
			<biblScope unit="page" from="533" to="536" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Overfitting in neural nets: Backpropagation, conjugate gradient, and early stopping</title>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="381" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Rard: The relatedarticle recommendation dataset</title>
		<author>
			<persName><forename type="first">J</forename><surname>Beel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Carevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schaible</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neusch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">From word embeddings to document distances</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I</forename><surname>Kolkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="957" to="966" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
