<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A combinatorial strongly subexponential strategy improvement algorithm for mean payoff games ଁ</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2006-06-27">27 June 2006</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Henrik</forename><surname>Björklund</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Technology Department</orgName>
								<orgName type="institution">Uppsala University</orgName>
								<address>
									<postBox>Box 337</postBox>
									<postCode>751 05</postCode>
									<settlement>Uppsala</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Sergei</forename><surname>Vorobyov</surname></persName>
							<email>sergei.vorobyov@it.uu.se</email>
							<affiliation key="aff0">
								<orgName type="department">Information Technology Department</orgName>
								<orgName type="institution">Uppsala University</orgName>
								<address>
									<postBox>Box 337</postBox>
									<postCode>751 05</postCode>
									<settlement>Uppsala</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A combinatorial strongly subexponential strategy improvement algorithm for mean payoff games ଁ</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2006-06-27">27 June 2006</date>
						</imprint>
					</monogr>
					<idno type="MD5">7C2CF5C41E1E152E874CF5883F998E38</idno>
					<idno type="DOI">10.1016/j.dam.2006.04.029</idno>
					<note type="submission">Received 30 September 2004; received in revised form 21 June 2005; accepted 20 April 2006 Dedicated to the memory of Leonid Khachiyan, 1952-2005</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Mean payoff game</term>
					<term>Cyclic game</term>
					<term>Parity game</term>
					<term>Ergodic partition</term>
					<term>Combinatorial linear programming</term>
					<term>Longest shortest parth</term>
					<term>Iterative improvement</term>
					<term>Randomized subexponential algorithm</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We suggest the first strongly subexponential and purely combinatorial algorithm for solving the mean payoff games problem. It is based on iteratively improving the longest shortest distances to a sink in a possibly cyclic directed graph.</p><p>We identify a new "controlled" version of the shortest paths problem. By selecting exactly one outgoing edge in each of the controlled vertices we want to make the shortest distances from all vertices to the unique sink as long as possible. The decision version of the problem (whether the shortest distance from a given vertex can be made bigger than a given bound?) belongs to the complexity class NP ∩ CONP. Mean payoff games are easily reducible to this problem. We suggest an algorithm for computing longest shortest paths. Player MAX selects a strategy (one edge from each controlled vertex) and player MIN responds by evaluating shortest paths to the sink in the remaining graph. Then MAX locally changes choices in controlled vertices looking at attractive switches that seem to increase shortest paths lengths (under the current evaluation). We show that this is a monotonic strategy improvement, and every locally optimal strategy is globally optimal. This allows us to construct a randomized algorithm of complexity min(poly•W, 2 O( √ n log n) ), which is simultaneously pseudopolynomial (W is the maximal absolute edge weight) and subexponential in the number of vertices n. All previous algorithms for mean payoff games were either exponential or pseudopolynomial (which is purely exponential for exponentially large edge weights).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Infinite games on finite graphs play a fundamental role in model checking, automata theory, logic, and complexity theory. We consider the problem of solving mean payoff games (MPGs) <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b36">37]</ref>, also known as cyclic games <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b29">30]</ref>. In these games, two players take turns moving a pebble along edges of a directed edge-weighted graph. Player MAX wants to maximize and player MIN to minimize (in the limit) the average edge weight of the infinite path thus formed. MPGs are determined, and every vertex has a value, which each player can secure by a uniform positional strategy. Deciding whether the value is above (below) a certain threshold belongs to the complexity class NP ∩ CONP. The well-known parity games, also in NP ∩ CONP, polynomial time equivalent to model checking for the -calculus <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b16">17]</ref>, are polynomial time reducible to MPGs. Other well-known games with NP ∩ CONP decision problems, to which MPGs reduce, are simple stochastic <ref type="bibr" target="#b11">[12]</ref> and discounted payoff <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b36">37]</ref> games. At present, despite substantial efforts, there are no known polynomial time algorithms for any of the games mentioned.</p><p>All previous algorithms for MPGs are either pseudopolynomial or exponential. These include a potential transformation method by Gurvich et al. <ref type="bibr" target="#b19">[20]</ref> (see also Pisaruk <ref type="bibr" target="#b29">[30]</ref>), and a dynamic programming algorithm solving k-step games for big enough k by Zwick and Paterson <ref type="bibr" target="#b36">[37]</ref>. Both algorithms are pseudopolynomial of complexity O(poly(n) • W ), where n is the number of vertices and W is the maximal absolute edge weight. The algorithm <ref type="bibr" target="#b36">[37]</ref> always makes (poly(n) • W ) steps, and for the algorithm <ref type="bibr" target="#b19">[20]</ref> there are known game instances on which it shows the worst case (poly(n) • W ) behavior, where W may be exponential in n. Reduction to simple stochastic games <ref type="bibr" target="#b36">[37]</ref> and application of the algorithm from <ref type="bibr" target="#b24">[25]</ref> gives subexponential complexity (in the number of vertices n) only if the game graph has bounded outdegree (see the remark below). The subexponential algorithms we suggested for simple stochastic games of arbitrary outdegree in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b10">11]</ref> make at most 2 O( √ n log n) iterations. However, in a reduction from MPGs <ref type="bibr" target="#b36">[37]</ref>, large weights result in long rational coefficients. This prevents each iteration, which requires solving a linear program, to run in strongly polynomial time, independent of the weights. Solving resulting linear programs by a combinatorial subexponential algorithm <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref> squares the overall complexity. This drawback is overcome with the new techniques presented here, which avoid the detour over simple stochastic games and linear programming subroutines altogether.</p><p>We suggest the first strongly subexponential strategy improvement algorithm for MPGs, which starts with some strategy of the maximizing player<ref type="foot" target="#foot_0">1</ref> MAX and iteratively "improves" it with respect to a simple strategy evaluation function, based on computing shortest paths in the residual graph. Iterative strategy improvement algorithms are known for the related simple stochastic <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b12">13]</ref>, discounted payoff <ref type="bibr" target="#b30">[31]</ref>, and parity games <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b2">3]</ref>. Until the present paper, a direct combinatorial iterative strategy improvement for MPGs appeared to be elusive. Reductions to discounted payoff games and simple stochastic games (with known iterative strategy improvement) lead to numerically unstable computations with long rationals and solving linear programs. The algorithms suggested in this paper are free of these drawbacks. Our method is discrete, requires only addition and comparison of integers in the same order of magnitude as occurring in the input. In the combinatorial model of computation, the subexponential running time bound is independent of the edge weights (strongly subexponential).</p><p>We present a simple and discrete randomized subexponential strategy improvement scheme for MPGs, and show that for any integer p, the set of vertices from which MAX can secure a value &gt; p can be found in time</p><formula xml:id="formula_0">min(O(n 2 • |E| • W ), 2 O( √ n log n) ),</formula><p>where n is the number of vertices and W is the largest absolute edge weight. The first bound matches those from <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b29">30]</ref>, while the second part is an improvement when, roughly, n log n &lt; log 2 W .</p><p>The new strategy evaluation for MPGs may be used in several other iterative improvement algorithms, which are also applicable to parity and simple stochastic games <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b12">13]</ref>. These include random single switch, all profitable switches, and random multiple switches; see, e.g., <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8]</ref>. They are simplex-type algorithms, very efficient in practice, but without currently known subexponential upper bounds, and no nontrivial lower bounds.</p><p>By a known simple reduction from parity games <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b16">17]</ref> to MPGs, our algorithm can be immediately applied for solving parity games. In contrast to the previous strategy improvement algorithms <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b2">3]</ref>, our new algorithm is conceptually much simpler, more efficient, and easier to implement.</p><p>Remark (On Ludwig's <ref type="bibr" target="#b24">[25]</ref> algorithm). The algorithm <ref type="bibr" target="#b24">[25]</ref> is subexponential 2 O( √ n) only for binary simple stochastic games, in which every vertex has outdegree at most two (more precisely, for games with outdegree bounded by a constant). Although a simple stochastic game, with arbitrary vertex outdegrees, reduces to a binary one, this may lead to a quadratic O(n 2 ) blow-up in the number of vertices, and the algorithm <ref type="bibr" target="#b24">[25]</ref> becomes exponential: 2 O( √ n 2 ) = 2 O(n) in the number of vertices. One may weakly argue that the algorithm <ref type="bibr" target="#b24">[25]</ref> is anyway subexponential in the length of input, since the length of input for arbitrary outdegree games is O(n 2 ), for representing edges. However, a straightforward brute-force algorithm systematically exploring all up to 2 n log n positional strategies and selects the best one is also subexponential in the length of input in this case! So the algorithm <ref type="bibr" target="#b24">[25]</ref> does not show drastic advantages over the brute-force one for arbitrary outdegree games. The first (really) subexponential 2 O( √ n log n) algorithms (in the number of vertices n, which should be recognized as a the adequate measure of complexity) for simple stochastic games of arbitrary outdegree are based on different (compared to <ref type="bibr" target="#b24">[25]</ref>) randomization schemes and were first suggested in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b10">11]</ref>. Note how the real subexponential bound 2 O( √ n log n) compares favorably to "subexponential" 2 O(n) .</p><p>Outline: Section 2 defines MPGs and introduces the associated computational problems. Section 3 describes the longest shortest paths (LSP) problem and its relation to MPGs. In addition, it gives an intuitive explanation of our algorithm and the particular randomization scheme that achieves subexponential complexity. Section 4 describes the algorithm in detail and Section 5 proves the two main theorems guaranteeing correctness. In Section 6 we explain how to improve the cost per iteration, while detailed complexity analysis is given in Section 7. Possible variants of the algorithm are discussed in Section 8. Section 9 shows that the decision version of the LSP problem is in NP ∩ CONP. In Section 10 we give an example graph family for which the wrong choice of iterative improvement policy leads to an exponential number of iterations. Finally, in Section 11 we apply our algorithm to solving parity games.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Mean payoff games</head><p>A mean payoff game (MPG for short) <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b36">37]</ref> is played by two adversaries, players MAX and MIN, on a finite, directed, edge-weighted, leafless 2 </p><formula xml:id="formula_1">graph G = (V , E, w), where V = V MAX ∪ V MIN , V MAX ∩ V MIN = ∅, E ⊆ V × V ,</formula><p>and w : E → Z is the weight function. Starting from some designated initial vertex, the players move a pebble along edges of the graph. Whenever, the pebble comes to a vertex v ∈ V MAX , player MAX makes a move by selecting some edge (v, u) and the pebble goes to vertex u. Similarly, MIN selects a move when the pebble is in a vertex from V MIN . The duration of the game is infinite and the resulting infinite sequence of edges e 1 e 2 e 3 . . . is called a play. Player MAX wants to maximize the payoff</p><formula xml:id="formula_2">max = lim inf k→∞ 1 k • k i=1 w(e i ),</formula><p>whereas player MIN wants to minimize the payoff</p><formula xml:id="formula_3">min = lim sup k→∞ 1 k • k i=1</formula><p>w(e i ).</p><p>A positional strategy for MAX is a function :</p><formula xml:id="formula_4">V MAX → V such that (v, (v)) ∈ E for all v ∈ V MAX .</formula><p>Positional strategies for MIN are defined symmetrically. Using a positional strategy , the player always deterministically selects the same successor (v) in each vertex v where he makes a move, independently of the history of the play. It turns out that in every MPG each vertex v has a value (v) such that whenever a play starts in v, MAX has an optimal positional strategy that secures him a payoff max (v) against any strategy of MIN, and, vice versa, MIN has an optimal positional strategy that secures him a payoff min (v). 3 Moreover, both players have uniform such strategies: the same optimal positional strategy may be used independently of the initial vertex of the game. Revealing this strategy before a play starts is not a disadvantage and does not lead to a suboptimal payoff. Accordingly, throughout the paper we restrict our attention to positional strategies only. Given a positional strategy for MAX, define G = (V , E ), by deleting all MAX edges not used in , i.e., E = E\{(v, u)|v ∈ V MAX and (v) = u}. Note that if both players use positional strategies, then any play will follow a (possibly empty) simple path to a simple cycle, where it will stay forever. The value of this play is the average edge weight on this cycle. See <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b6">7]</ref> for details.</p><p>2 i.e., every vertex has at least one outgoing edge. 3 Thus, if both use optimal strategies, max = min = (v). Deviating from an optimal strategy may only lead to a suboptimal payoff for the player.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Algorithmic problems for MPGs</head><p>We will address several computational problems for MPGs.</p><p>The decision problem: Given an MPG, a distinguished start vertex, and a threshold value p, can MAX secure a payoff &gt; p?</p><p>p-mean partition: Given p, partition the vertices of an MPG G into subsets G p and G &gt;p such that MAX can secure a payoff &gt; p starting from every vertex in G &gt;p , and MIN can secure a payoff p starting from every vertex in G p .</p><p>Ergodic partition: Compute the value of each vertex of the game. This gives a partition of the vertices into subsets with the same value. Such a partition is called ergodic <ref type="bibr" target="#b19">[20]</ref>.</p><p>Clearly, the p-mean partitioning subsumes the decision problem. Whenever one player fixes a positional strategy, an optimal counterstrategy of the opponent can be computed in polynomial time, by using Karp's minimum mean weight cycle algorithm; see <ref type="bibr">[14, p. 617]</ref>. Therefore, the decision problem is in NP ∩ CONP, and there is a straightforward exponential (in the number of vertices of one player) time algorithm exploring all MAX strategies. Known pseudopolynomial time algorithms were surveyed in the introduction.</p><p>Our basic algorithm solves the 0-mean partition problem, which subsumes the p-mean partition. Indeed, subtracting p from the weight of every edge makes the mean value of all cycles (in particular, of optimal cycles) smaller by p, and the problem reduces to 0-mean partitioning. The complexity remains the same for integer thresholds p, and changes slightly for rational ones; see Section 7. Until Section 7.2 we assume such thresholds to be integral. In Section 7.2 we extend the basic algorithm to solve the ergodic partition problem. Another problem to which our algorithm may be extended is finding optimal strategies in MPGs.</p><p>Some of our proofs rely on an equivalent finite version of MPGs <ref type="bibr" target="#b15">[16]</ref>, where a play stops as soon as some vertex is revisited and the mean value on the resulting cycle determines the payoff. Thus, for a play e 1 e 2 • • • e r e r+1 • • • e s , where e r • • • e s is a simple cycle, the value is s i=r w(e i )/(sr + 1). Ehrenfeucht and Mycielski <ref type="bibr" target="#b15">[16]</ref> proved the following equivalence (see also <ref type="bibr" target="#b6">[7]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 2.1. The value of every vertex in the finite duration version of MPGs equals its value in the infinite duration version.</head><p>The next corollary will be used implicitly throughout the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 2.2. A positional strategy of MAX gives a value &gt; p in a vertex, iff all cycles reachable from it in G have average value &gt; p.</head><p>Since the partition threshold 0 has a special role in our exposition, we call the G &gt;0 partition the winning set of MAX.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">A high-level description of the algorithm</head><p>We start by informally describing the essential ingredients of our algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">The longest shortest paths problem</head><p>The algorithm for computing 0-mean partitions in MPGs is based on a new "controlled" version of the well-known single source <ref type="foot" target="#foot_1">4</ref> shortest paths problem on directed graphs. Suppose a given digraph has some distinguished set of controlled vertices, and we can select exactly one edge leaving every controlled vertex, deleting all other edges from these vertices. Such a selection is called a positional strategy. We want to find a positional strategy that maximizes the shortest paths from all vertices to the distinguished sink (also avoiding negative cycles that make the sink unreachable and the distances -∞).</p><p>For a strategy denote by G the graph obtained from G by deleting all outgoing edges from controlled vertices, except those used in .</p><p>Formally, the problem is specified as follows. THE LONGEST SHORTEST PATHS PROBLEM (LSP). Given: (1) a directed edge-weighted graph G with a unique sink t, (2) a distinguished set U ⊆ V [G] of controlled vertices, with t / ∈ U . Find: a positional strategy selecting exactly one outgoing edge from each vertex in U such that in the graph G the length of the shortest path from every vertex to sink t is as large as possible (over all positional strategies).</p><p>Distances. As usual, the length of a finite simple path to the sink in G equals the sum of edge weights on the path. In a cyclic G the distances to the sink are defined as (1) +∞ for every vertex on a positive weight cycle;</p><p>(2) -∞ for every vertex on a negative weight cycle;</p><p>(3) 0 for every vertex on a 0-weight cycle.</p><p>The last clause is motivated by our application to the 0-mean partition problem for MPGs, in which 0-weight loops do not contribute to the G &gt;0 partition. For the real LSP it would be more logical to postulate that every vertex on a 0-weight cycle has distance +∞ to the sink, as we do in Section 9.</p><p>We make sure that all strategies generated by iterative improvement in every run of our algorithm are admissible, i.e., the graph G has no nonpositive weight cycles. Thus, computing shortest paths in G always yields finite or +∞ distances, and the last two clauses in the distance definition above never need to apply.</p><p>For our purpose of finding 0-mean partitions in MPGs, it suffices to consider a version of the LSP problem with the following additional input data.</p><p>Additionally given: an admissible strategy 0 , which guarantees that in the graph G 0 there are no cycles with nonpositive weights.</p><p>With this additionally supplied strategy 0 we know that the longest shortest distance from every vertex to the sink t is at least finite, &gt; -∞. It is not excluded that 0 or the optimal strategy will make some distances equal +∞ (this is the goal of MAX, which he will try to figure out by iterative improvement starting with 0 ). We prove that our algorithm never generates an inadmissible strategy. Treating 0-weight cycles by maintaining the admissibility invariant for the algorithm (rather than just assuming wlog that 0-weight cycles are absent, as we do in Section 9) adds certain complications, but pays off with a better complexity, as explained below.</p><p>The simplifying additional input strategy is easy to provide in the reduction from MPGs by adding 0-weight edges from all MAX vertices to the sink.Actually, it is more difficult to obtain a subexponential iterative improvement algorithm without this "additionally given" strategy. Indeed, it is conceivable that there are no admissible strategies at all, and every strategy allows for reaching a negative cycle from every vertex (although we do not know that a priori). Then there is no apparent way to figure this out, except the full exponential enumeration and verification of the strategy space. This is because the neighborhood structure on this space is completely "flat" and moving between neighboring strategies provides no improvement.</p><p>Note that for DAGs, the LSP problem can be easily solved in polynomial time by dynamic programming. Start by topologically sorting the vertices and proceed backward from the sink (distance 0), using the known longest shortest distances for the preceding vertices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Relating the 0-mean partition and LSP problems</head><p>The relation between finding 0-mean partitions and computing longest shortest paths is now easy to describe. To find a 0-mean partition in an MPG G, just add a retreat vertex t (belongs to MIN and will later become the sink) to the game graph with a self-cycle edge of weight 0, then add a 0-weight retreat edge from every MAX vertex to t. From now on, we assume that G has undergone this transformation. Clearly, we have the following property. Proposition 3.1. Adding the retreat does not change the 0-mean partition of the game, except that the new retreat vertex belongs to the G 0 part. This is because we do not add anything allowing MAX to create new positive cycles, or MIN to create new nonpositive cycles (except in retreat t). MAX will prefer playing to t only if all other positional strategies lead to negative cycles.</p><p>The key point is now as follows. Break the self-cycle in t and consider the LSP problem for the resulting graph, with t being the unique sink. The set V MAX becomes the set of controlled vertices, and the initial strategy (the "additionally given" clause in the LSP definition above) selects retreat t in every controlled vertex, guaranteeing that no vertex has distance -∞. <ref type="foot" target="#foot_2">5</ref> We have the following equivalence.</p><p>Theorem 3.2. The partition G &gt;0 consists exactly of those vertices for which the longest shortest path distance to t is +∞.</p><p>Proof. The same MAX positional strategy simultaneously achieves positive weight cycles both in the MPG and the corresponding LSP instance. Recall that by convention 0-weight cycles yield 0 distances to the sink.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Blocking nonpositive cycles</head><p>As early as in 1991 Leonid Khachiyan <ref type="bibr" target="#b22">[23]</ref> considered the following variant of the LSP problem, stated here using our terminology.</p><p>BLOCKING NONPOSITIVE CYCLES.</p><p>Given: a directed edge-weighted leafless graph and a vertex subset, in which the controller must choose exactly one outgoing edge per vertex and delete all other outgoing edges.</p><p>Find: a subset B of vertices from which the controller can make unreachable any nonpositive weight cycles.</p><p>In the decision version the question is whether a given vertex belongs to B. As an immediate consequence of the preceding definitions we have the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 3.3.</head><p>(1) The problems 0-mean partition in MPGs and blocking nonpositive cycles are polynomial time equivalent.</p><p>(2) The decision version of blocking nonpositive cycles is in NP ∩ CONP.</p><p>(3) Blocking nonpositive cycles is polynomial time reducible to the LSP problem.</p><p>Note that in the LSP problem, except being interested in the +∞ distances to the sink (which corresponds to positive cycles in blocking nonpositive cycles), we are additionally interested in computing finite distances. Our algorithm iteratively improves these finite distances, until, hopefully, improving them to +∞. Our goal with the LSP problem was exactly inventing the optimization (rather than decision) problem appropriate for iterative improvement.</p><p>To our knowledge, there are no other mentions of the LSP problem and its relation to MPGs in the literature. <ref type="foot" target="#foot_3">6</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">The algorithm</head><p>Our 0-mean partition algorithm computes LSP in the graph resulting from an MPG (after adding the retreat vertex and edges, as explained above), by making iterative strategy improvements. Once a strategy is fixed, all shortest paths are easily computable, by using the Bellman-Ford algorithm. Since there are negative weight edges, the Dijkstra algorithm cannot be used. An improvement to the straightforward application of the Bellman-Ford algorithm is described in Section 6.</p><p>The main step of our iterative strategy improvement algorithm is the so-called attractive switch. Comparing a current choice made by the strategy with alternative choices, a possible improvement can be decided locally as follows. If changing the choice in a controlled vertex to another successor seems to give a longer distance (seems attractive), we make this change. Such a change is called a switch.</p><p>Switching is similar (but is the opposite) to the usual edge relaxation in the shortest paths algorithms. Suppose the current distance (using the current strategy ) from a vertex v to the sink is d (v), but for an edge (v, u) not used by we have d (v) &lt; w(v, u) + d (u) (attractiveness). Then we switch the current edge (v, (v)) to (v, u), get new strategy , and recompute the shortest distances.</p><p>We prove two crucial properties (Theorems 5.1 and 5.2, respectively):</p><p>(1) every such switch really increases the shortest distances (i.e., attractiveness is improving or profitable); this guarantees monotonic (acyclic) improvement, no backtracking is necessary; (2) once none of the alternative possible choices is attractive, all possible positive weight cycles MAX can enforce are found (i.e., a stable strategy is optimal).<ref type="foot" target="#foot_4">7</ref> </p><p>Although our subexponential algorithm proceeds by making just one attractive switch at a time, the evaluation of the shortest paths for a fixed positional strategy gives a useful quality measure on strategies that can be used in other iterative improvement schemes. Other algorithms, making many switches simultaneously are also possible and fit into our framework. We discuss some such algorithms in Section 8.</p><p>Another interpretation of our algorithm is game-theoretic. MAX makes choices in the controlled vertices, and the choices in all other vertices belong to MIN. For every strategy of MAX, MIN responds with an optimal counterstrategy, computing the shortest paths from every vertex to the sink. After that, the algorithm improves MAX's strategy by making an attractive switch, etc. This game always terminates in finitely many iterations with a stable strategy that cannot be improved. Randomization helps in obtaining a subexponential upper bound on the number of iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Randomization scheme</head><p>The order in which attractive switches are made is crucial for the subexponential complexity bound. Section 10 gives an example of a poor switching policy with an exponentially long chain of attractive switches. The space of all positional strategies of MAX in an MPG/LSP instance can be identified with the Cartesian product of sets of edges leaving the controlled vertices. Fixing any edge in this set and letting others vary determines a facet in this space. A facet corresponds to a subgame in which one of the choices of player MAX is fixed in one vertex, and choices in all other vertices are unconstrained. Edges of MAX are in one-to-one correspondence with game facets. In particular, deleting a MAX edge (without creating a sink) determines a subgame in which MAX has fewer choices, and corresponds to eliminating one facet. This allows us to define the algorithm recursively: a solution to a complicated game is determined using a solution to a simpler game with one facet/edge less. Operating in terms of facets is very convenient and makes the connections to combinatorial optimization transparent and explicit.</p><p>The algorithm for computing the LSP in an MPG/LSP instance G is as follows:</p><p>(1) Start from some strategy that guarantees for shortest distances &gt; -∞ in all vertices. <ref type="foot" target="#foot_5">8</ref>(2) If is the only possible MAX strategy in G, return it as optimal.</p><p>(3) Otherwise, randomly and uniformly select some facet F of G not containing . Temporarily throw this facet away, and recursively find a best strategy * on the remainder, G\F . This corresponds to deleting a MAX edge not used by and finding a best strategy in the resulting subgame. (4) If * is optimal in G, return it as a result. Optimality is easily checked by computing shortest distances in G * from all vertices of the graph to the sink, <ref type="foot" target="#foot_6">9</ref> and testing whether there is an attractive switch from * to the edge defining F. (5) Otherwise, make an attractive switch to F, set G = F , denote the resulting strategy by , and repeat from step 2. This algorithm incorporates the fairly well-known randomization scheme for combinatorial linear programming due to Matoušek et al. <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref>, although we use it here for a nonconvex optimization. Applied to the LSP and MPG 0-mean partition problems, it gives a subexponential 2 O( √ n log n) expected running time bound, where n is the number of MAX vertices. The essential properties needed for the analysis of <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref> to work are as follows:</p><p>• For every strategy and (sub)game G in any run of the algorithm the set of facets F i of G not containing define a partial ordering of subgames G\F i by the value of their best strategies (this value is a vector of shortest distances to the sink under a strategy; see Section 4.1). • The algorithm always finds a globally optimal strategy in a subgame G\F i (F i selected randomly) and makes only monotonic profitable switches (Theorems 5.2 and 5.1, respectively). Thus, after finding an optimal strategy in a subgame G\F i , the algorithm will never revisit any strategies in subgames G\F j , where G\F j is lower than G\F i or incomparable with it in the partial ordering above.</p><p>It follows that the so-called hidden dimension decreases randomly, and the subexponential analysis of <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref> applies. Another possibility consists in using the slightly more complicated randomization scheme of Kalai <ref type="bibr" target="#b21">[22]</ref>, as we did in <ref type="bibr" target="#b2">[3]</ref> for parity games, which leads to the same subexponential bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Retreats, admissible strategies, and strategy measure</head><p>As explained above, we modify an MPG by allowing MAX to "surrender" in every vertex. Add the retreat vertex t of MIN with a self-cycle of weight 0 and a retreat edge of weight 0 from every MAX vertex to t. Clearly, MAX secures a value &gt; 0 from a vertex in the original MPG iff the same strategy does it in the modified game. Assume from now on that the retreat has been added to G. Intuitively, the "add retreats" transformation is useful because MAX can start by a strategy that chooses the retreat edge in every vertex, thus "losing only 0". We call strategies "losing at most 0" admissible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 4.1 (Admissibility).</head><p>A strategy of MAX in G is admissible if all cycles in G are positive, except the cycle over the retreat vertex t.</p><p>Our algorithm, starting from the initial "additionally given" admissible strategy, iterates through only admissible strategies of MAX (an important invariant). This guarantees that the only losing (for MAX, nonpositive) cycle in G is the self-cycle over t. Once MAX has at least one admissible strategy providing for shortest distances &gt; -∞, he will never want to use any inadmissible strategies, which allow for distances -∞ for some vertices (negative cycles). Hence optimal strategies can be searched for among admissible strategies only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Measuring the quality of strategies</head><p>We now define a measure that evaluates the "quality" of an admissible strategy. It can be computed in strongly polynomial time, as shown in Section 6.</p><p>Given an admissible strategy , the best MIN can hope to do is to reach the 0-mean self-cycle over t. Any other reachable cycle will be positive, by the definition of an admissible strategy. The shortest path from every vertex v to t is well-defined, because there are no nonpositive cycles in G (except over t). Therefore, we define the value of a strategy in a vertex as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 4.2 (Vertex value wrt a strategy).</head><p>For an admissible strategy of MAX, the value val (v) of vertex v is defined as the shortest path distance from v to t in G , or +∞ if t is not reachable.</p><p>It follows that for admissible strategies finite values may only result from shortest paths leading to the sink (retreat) t. Note that for each admissible MAX strategy there is an optimal positional counterstrategy of MIN that guarantees the shortest paths are taken in each vertex, namely the strategy defined by the shortest path forest; see, e.g., <ref type="bibr" target="#b13">[14]</ref>.</p><p>The relative quality of two admissible strategies is defined componentwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 4.3 (Ordering strategies).</head><p>Let and be two MAX admissible strategies. Say that is better than , formally denoted &gt; , if val (v) val (v) for all vertices v ∈ V , with strict inequality for at least one vertex. Say that , if &gt; or they have equal values in all vertices.</p><p>The notation below will be useful for describing switches.</p><p>Notation 4.4. If is a strategy of MAX, x ∈ V MAX , and (x, y) ∈ E, then the switch in x to y changes to the new strategy [x → y], defined as</p><formula xml:id="formula_5">[x → y](v) def = y, if v = x, (v), otherwise.</formula><p>The following definition makes a distinction between switches that improve the strategy value, and switches that merely look like they do. Later, Corollary 5.5 shows that the two notions are in fact equivalent. Definition 4.5 (Attractiveness, stability, and profitability). Given an admissible strategy , a switch</p><formula xml:id="formula_6">[v → u] is 1. attractive, if val (v) &lt; w(v, u) + val (u); 2. profitable, if [v → u] is admissible and [v → u] &gt; .</formula><p>A strategy without attractive switches is called stable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Note that</head><p>• attractiveness is defined using the values with respect to the current strategy only (which is very easy to check), whereas • profitability requires to recompute the shortest distances after making a switch and checking admissibility and distance improvements.</p><p>Our algorithm proceeds by making attractive switches only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Requirements for the measure</head><p>The algorithm's correctness and efficiency rely on the following properties:</p><p>(1) If is an admissible strategy, and there is no better admissible strategy, then is winning from all vertices in MAX's winning set G &gt;0 . This is evident from the definitions, since optimal strategies are among admissible ones; see the explanation after Definition 4.1. (2) Every attractive switch is profitable and preserves admissibility (Theorem 5.1).</p><p>(3) If an admissible strategy has no attractive switches, then there is no better admissible strategy (Theorem 5.2). In other words, every stable strategy is optimal.</p><p>Property (2) guarantees monotonicity, termination, and a pseudopolynomial upper bound. Subexponential analysis relies both on (2) and (3). Both properties allow the iterative improvement be guided by attractiveness, easily checkable as soon as the measure has been computed. Testing profitability would otherwise require recomputing the measure for every possible potential switch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Correctness of the measure</head><p>In this section we state and prove the two major theorems, guaranteeing that every step of the algorithm (consisting in making an attractive switch) is improving and that the final strategy is the best, respectively. Afterward, we give two corollaries clarifying the relation between attractiveness and profitability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Attractiveness implies profitability</head><p>Our first theorem states that any attractive switch is profitable. This means that we never have to actually evaluate other strategies before selecting the next iterate. Instead we can let the improvement scheme be guided by attractiveness. Monotonicity, guaranteed by Theorem 5.1, implies that every sequence of attractive switches will eventually terminate.</p><p>The number of iterations will be at most pseudopolynomial, because distances increase in integral steps and every vertex has a natural integral distance limit equal the number of vertices times the absolute weight of the heaviest edge. Either we terminate before reaching this limit, or the distance becomes +∞. Recall that an admissible strategy does not permit any negative or 0-weight cycles.</p><p>Theorem 5.1 (Attractive is profitable). If is an admissible strategy then any strategy obtained by an attractive switch from is admissible and better, i.e., &gt; .</p><p>Proof. Let be admissible, (v i ) = v j be the current successor of v i , and consider an attractive switch for v i in resulting in a new strategy ≡ [v i → v j ], selecting another successor v j of v i . Recall that the (v i , t)-shortest path problem is expressible by the following linear program: maximize v i subject to t = 0 for sink t, v i w(i, j ) + v j for each edge (v i , v j ) of weight w(i, j ).</p><formula xml:id="formula_7">Suppose d = (d (v 1 ), . . . , d (v n ))</formula><p>is the vector of shortest distances from all vertices to the sink in G . This vector is a feasible solution to the LP above (some components of d may be +∞, meaning that MAX enforces positive cycles, hence infinite distances to the sink; since is admissible, there are no nonpositive cycles in G ). Let v i w(i, j ) + v j be the constraint corresponding to the edge (v i , v j ) currently selected by , and v i w(i, j ) + v j be the constraint corresponding to an alternative edge (v i , v j ) selected by . In order to speak about attractiveness, d (v i ) needs to be finite. Note that the constraint v i w(i, j ) + v j corresponding to the current choice is satisfied by d as equality; otherwise, d (v i ) is not the shortest path distance. By attractiveness, d (v i ) &lt; w(i, j ) + d (v j ). Thus, replacing (switching) the old constraint v i w(i, j ) + v i with the new v i w(i, j ) + v j results in a new LP, which keeps the old solution d as feasible (thus we get ), but also allows for increasing the value of v i , maybe up to +∞ (thus we get profitability). This holds because the new constraint is not tight for v i after substituting d . Therefore, increasing v i may only increase the right-hand sides of other constraints. Note that this argument is based on the special monotone form of the linear constraints for the shortest path problem.</p><p>We also have to show that an attractive switch preserves strategy admissibility. By assumption, is admissible, therefore, G has no nonpositive cycles. Let us prove that G possesses the same property. Suppose, toward a contradiction, that G has a nonpositive cycle C. This cycle should necessarily contain the vertex v i in which the switch was made and the new edge (v i , v j ) used by ; otherwise, this cycle exists already in G . Consider the path from v j to v i defined by the cycle C. Since also exists in G (a switch in single vertex v i was made), d (v j ) w( ) + d (v i ), where w( ) is the sum of edge weights in , because d is the vector of shortest distances. By attractiveness, d (v i ) &lt; w(i, j ) + d (v j ) (strict!). But the last two inequalities imply 0 &lt; w( ) + w(i, j ) = w(C). Therefore, C is a positive cycle, a contradiction.</p><p>By a similar argument, making simultaneously several (rather than just one at a time) attractive switches is profitable, but we do not need it here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Stability implies optimality</head><p>Our second theorem shows that an admissible MAX strategy with no attractive switches is at least as good as any other admissible strategy, i.e., is winning from every vertex in G &gt;0 . This means that if we are only looking for the vertices from which MAX can enforce positive weight cycles (when solving MPGs) we can stop as soon as we find an admissible stable strategy. Although there may be also inadmissible strategies that allow MAX to enforce 0-weight cycles, such cycles are of no interest for MAX, because they do not add vertices to G &gt;0 . Section 9 deals with the case where 0-weight cycles are considered good for MAX.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 5.2 (Stable is optimal). If is an admissible strategy with no attractive switches, then</head><p>for every other admissible strategy .</p><p>Proof. Suppose, is a stable strategy, and let d be the vector of shortest distances in G to the sink (one component per vertex). Suppose, toward a contradiction, that there is a better than admissible strategy , providing a longer distance d (v 0 ) &gt; d (v 0 ), in G , for some vertex v 0 . Note that d (v 0 ) should be finite (for a distance improvement to exist) and the shortest path in G from v 0 leads to the sink. <ref type="bibr">It</ref>  In G , MAX has all strategies available, while MIN has just one. Nevertheless, we will show that in G no admissible MAX strategy can improve over d (v 0 ). Suppose the contrary, and make the following potential transformation <ref type="bibr" target="#b19">[20]</ref> of G , by changing the weight of each edge according to the rule:</p><p>The following property is not necessary for correctness, but clarifies the relation between attractiveness and profitability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 5.4. If an admissible strategy is obtained from another admissible strategy by one or more nonattractive switches, then .</head><p>Proof. Consider the game (V , E , w ), where</p><formula xml:id="formula_8">E = E\{(u, v) : u ∈ V MAX ∧ (u) = v ∧ (u)</formula><p>= v} and w is w restricted to E . In this game is stable and both , are admissible strategies. Hence, by Theorem 5.2, .</p><p>Finally, by using Theorem 5.1, we obtain the following equivalence.</p><p>Corollary 5.5. A single switch (between two admissible strategies) is attractive if and only if it is profitable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Efficient computation of the strategy measure</head><p>For an admissible strategy the shortest paths in G (strategy measure) can be computed by using the Bellman-Ford algorithm for single-sink shortest paths in graphs with possibly negative edge weights; see, e.g., <ref type="bibr" target="#b13">[14]</ref>. This We first compute the set of vertices that have different values under the old and the new strategies and , respectively, and then recompute the values only in these vertices, using the Bellman-Ford algorithm. If the algorithm improves the value of n i vertices in iteration i, we only need to apply the Bellman-Ford algorithm to a subgraph with O(n i ) vertices and at most |E| edges; hence it runs in time O(n i • |E|). Since the maximum possible number of integral distance improvements in n vertices is n 2 • W , the sum of all n i 's does not exceed n 2 • W , so the total running time becomes at most O(n 2 • |E| • W ), saving a factor of n. It remains to compute, in each iteration, which vertices need to change their values. Algorithm 1 does this, taking as arguments a game G, the shortest distances d : V → N ∪ {∞} computed with respect to the old strategy , the new strategy , and the set of switched vertices U ⊆ V , where differs from .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1. Mark all vertices v for which val (v) = val (v).</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MARK-CHANGING-VERTICES</head><formula xml:id="formula_9">(G, U ⊆ V , d : V → N ∪ {∞}) (1) mark all vertices in U (2) while U = ∅ (3) remove some vertex v from U (4) foreach unmarked predecessor u of v in G (5) if w(u, x) + d[x] &gt; d[u] for all unmarked (6) successors x of u in G (7) mark u (8)</formula><p>U ← U ∪ {u} Theorem 6.1. If an attractive switch changes an admissible strategy to , then for every vertex v ∈ V , the following claims are equivalent.</p><p>(1) Algorithm 1 marks v.</p><p>(2) Every shortest path from v to t in G passes through some switch vertex.</p><p>(3) val (v) = val (v).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof. (1) ⇒ (2)</head><p>. By induction on the set of marked vertices, which expands as the algorithm proceeds. The base case holds since the vertices marked before the while loop are the switch vertices; these clearly satisfy <ref type="bibr" target="#b1">(2)</ref>. For the induction step, assume the claim holds for every marked vertex and that vertex u is about to be marked on line 7. Let x be any successor of u included in some shortest path from u to t in G . Since w(u, x)</p><formula xml:id="formula_10">+ d[x] = d[u],</formula><p>and by the condition on line 5, x must be already marked. Hence, by the induction hypothesis, every shortest path through x passes through U. This completes the induction step.</p><p>(2) ⇒ (1). For an arbitrary vertex v, consider all its shortest paths in G . Denote by v the maximal number of edges passed by such a path before a vertex in U is reached (so v is the unweighted length of an initial segment). The proof is by induction on v. The base case is clear: v = 0 iff v ∈ U , and all vertices in U are marked. Assume that the claim holds for all vertices u with u &lt; k and consider an arbitrary vertex v with v = k. By the inductive hypothesis, all successors of v that occur on a shortest path are marked. Hence, when the algorithm removes the last of them from U, the condition on line 5 is triggered and v is marked.</p><p>(3) ⇒ (2). If some shortest path from v to t in G does not pass through a switch vertex, then the same path is available also in G , hence val (v) = val (v).</p><p>(2) ⇒ (3). Assume ( <ref type="formula">2</ref>) and consider an arbitrary shortest path from v to t in G . If it contains any switch vertices, let u be the first of them. The same path from v to u, followed by the path in G from u to t, gives a shorter path in G , since the length of shortest paths strictly increase in switch vertices. If the path does not contain any switch vertices, then by <ref type="bibr" target="#b1">(2)</ref> it is longer than every shortest path in G .</p><p>We thus showed that Algorithm 1 does what it is supposed to. To finish the argument, we show that it runs in time O(|E|), so it is dominated by the time used by the Bellman-Ford algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 6.2. Algorithm 1 can be implemented to run in time O(|E|).</head><p>Proof. Every vertex can be added to U and analyzed in the body of the while loop at most once. The condition on line 5 can be tested in constant time if we keep, for each vertex u, the number of unmarked successors x of u with w(u, x)+d[x]=d <ref type="bibr">[u]</ref>. Thus, the time taken by the foreach loop is linear in the number of predecessors of v (equivalently, in the number of edges entering v), and the claim follows.</p><p>To improve the efficiency even further, instead of relying on Bellman-Ford's O(n|E|) algorithm (applies to arbitrary edge weights), we can use a faster Fredman-Tarjan's O(|E|+n log(n)) implementation of Dijkstra's algorithm (requires nonnegative weights) based on Fibonacci heaps. Nonnegative edge weights can be ensured by the following trick involving, once again, potential transformations. Recall that a potential for an edge-weighted DAG is a function p on its vertices such that p(u) p(v) + w(u, v) for every graph edge (u, v). Knowing a potential, we can transform edge weights by w (u, v) := w(u, v)p(u) + p(v) 0 (by the potential property above), thus rendering all edge weights nonnegative. Since a potential transformation changes the lengths of all paths from u to v by p(v)p(u) (telescoping), the shortest paths are preserved under such transformations, and we can safely rely on Dijkstra's algorithm. The only question is how to get a potential. Luckily, it turns out that we implicitly maintain potentials through repeated computations of the shortest paths.</p><p>Indeed, let P be an instance of the linear program from the proof of Theorem 5.1 and d be its optimal solution. Recall from the proof that making an attractive switch keeps the vector of shortest distances d, previously optimal for P , as feasible for the new LP P resulting from an attractive switch. But feasibility of d for P means precisely that d represents the required potential for P . Thus, shortest distances from one computation of the shortest paths are potentials for the next iteration.</p><p>Therefore, the above O(n 2 • |E| • W ) bound with the Bellman-Ford's algorithm can be further improved to O(n • (|E| + n log n) • W ) with Dijkstra-Fredman-Tarjan's algorithm. This allows for improving pseudopolynomial bounds in Theorems 7.1 and 7.2, as well as in Section 11.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Complexity of the algorithm</head><p>Section 2 lists several computational problems for MPGs. We first show that our basic 0-mean partition algorithm with small modifications also solves the p-mean partition and the splitting into three sets problems with the same asymptotic running time bound. In Section 7.2 we show how to solve the ergodic partition problem, which introduces a small extra polynomial factor in the complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Complexity of partitioning with integer thresholds</head><p>The basic algorithm in Section 3 solves the 0-mean partition problem for MPGs. The p-mean partition problem with an integer threshold p can be solved by subtracting p from all edge weights and solving the 0-mean partition problem. As a consequence, we also solve the decision problem for integer thresholds p. Zwick and Paterson <ref type="bibr" target="#b36">[37]</ref> consider a slightly more general problem of splitting into three sets around an integer threshold p, with vertices of value &lt; p, =p, and &gt; p, respectively. We can solve this by two passes of the p-mean partition algorithm. First, partition the vertices into two sets with values p and &gt; p, respectively. Second, invert the game by interchanging V MIN and V MAX and negating all edge weights, and solve the (-p)-mean partition problem. These two partitions correspond to the &lt; p and p partitions of the original game, and combining the two solutions we get the desired three-partition for only twice the effort.</p><p>We now analyze the running time of our algorithms, asymptotically the same for all versions of the problem mentioned in the previous paragraph. The complexity of a strategy improvement algorithm consists of two parts: the cost of computing the measure times the number of iterations necessary. Section 6 demonstrates that this combined cost is at most O(n 2 • |E| • W ). This is the same complexity as for the algorithm by Zwick and Paterson for the splitting into three sets problem <ref type="bibr" target="#b36">[37,</ref><ref type="bibr">Theorem 2.4</ref>]. If W is very big, the number of iterations can of course also be bounded by v∈V MAX outdeg(v), the total number of strategies for MAX. Using the randomization scheme of Matoušek, Sharir, and Welzl from Section 3.5 we obtain the simultaneous bound 2 O( √ n log n) , independent of W. Combining both bounds, we get the following theorem.</p><p>Theorem 7.1. The decision, p-mean partition, and splitting into three sets problems for MPGs can be solved in time</p><formula xml:id="formula_11">min(O(n 2 • |E| • W ), 2 O( √ n log n) ).</formula><p>(</p><p>The min in (1) means that both bounds apply simultaneously, for the same algorithm. One follows by monotonicity and boundedness of distance improvements, the other by randomized analysis. As W increases, the second bound becomes asymptotically better. Note that there are no nontrivial lower bounds for MPGs, and in our experiments with random games both bounds in (1) do not seem tight. After all, over years many people conjectured/claimed MPGs polynomial time solvable.</p><p>Note that a more precise estimation replaces n by |V MAX | in the subexponential bound, because we only consider strategies of MAX and only vertices in V MAX matter. Also, n • W can be replaced by an upper bound on the length of the longest shortest path. For instance, one such bound is the sum, over all vertices, of the maximal positive outgoing edge weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Computing the ergodic partition</head><p>We now explain how computing the values of all vertices of an MPG (ergodic partitioning) reduces to computing a series of p-mean partitions. We first describe the ergodic partition algorithm, which uses an algorithm for the p-mean partition problem with rational thresholds as a subroutine. We then analyze our algorithm for the case of rational thresholds, and finally bound the total running time, including all calls to the p-mean partition algorithm.</p><p>Denote by w -and w + the smallest and largest edge weights, respectively, and W = w +w -. Then the average weight of any cycle (i.e., the value of any vertex in the MPG) is a rational number with denominator n in the interval [w -, w + ]. We can find the value for each vertex by bisecting the interval, until each vertex value is contained in an interval of length 1/n 2 . There is at most one possible value inside each such interval (because the difference between two unequal mean cycle values is at least 1/n(n -1)), and it can be found easily <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b36">37]</ref>. We start by solving the p-mean partition problems dichotomizing the interval [w -, w + ] with integral thresholds p while it is possible (making slightly uneven partitions if necessary). After that, for bisecting the subintervals of length 1 we have to deal with rational thresholds p/q for q n 2 . We therefore have to solve the p-mean partition problem for rational nonintegral thresholds p. As can be readily verified, our p-mean partition algorithm directly applies to this case, with a slightly modified complexity analysis.</p><p>The combinatorial subexponential bound does not depend on thresholds being integers or rationals, but we need to analyze the depth of the measure, because it is important for the pseudopolynomial bound. Recall that p/q-mean partitioning reduces to 0-mean partitioning by subtracting p/q from edge weights. After subtracting p/q from each (integral) edge weight w, the weight of every path of length k to the sink has the form k i=1 w ikp/q. The sum k i=1 w i can take at most n • W different values, and k can take at most n values, so each vertex can improve its value at most n 2 • W times, compared with n • W in the integral case. 11 Thus, solving the 0-mean problem for rational thresholds takes at most n times longer.</p><p>During the dichotomy process, we consider subproblems (partitions) with different number of vertices and different thresholds in the range [w -, w + ]. The largest absolute edge weight remains bounded by W, and the total number of vertices in all the subproblems remains n. To find a correct value we need to bisect at most O(log(W • n 2 )) = O(log W + log n) times. The complexity of one p-mean partitioning T (n) is superlinear in n, so T (i) + T (j) T (i + j) (i.e., partitioning resulting in one vertex set empty is the worst case). Hence the total computation time does not exceed O((log W + log n) • T (n)). We summarize this in the following theorem.</p><p>Theorem 7.2. The ergodic partition problem for MPGs can be solved in time</p><formula xml:id="formula_13">min(O(n 3 • |E| • W • (log n + log W )), (log W ) • 2 O( √ n log n) ).</formula><p>Zwick-Paterson's algorithm for this problem has the worst case bound O(n 3 • |E| • W ) [37, Theorem 2.3], which is slightly better for small W, but worse for large W. Note that the algorithm <ref type="bibr" target="#b36">[37]</ref> always makes (n 3 • |E| • W ) iterations, on every game instance. We are not aware of any MPG instances on which our algorithm makes that many steps. The algorithm described in this section is not strongly subexponential. A strongly subexponential algorithm for the MPG ergodic partition problem is described in <ref type="bibr" target="#b37">[38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Variants of the algorithm</head><p>An extension of Theorem 5.1 shows that any combination of attractive switches improves the strategy value, and thus any policy for selecting switches in each iteration will eventually lead to an optimal strategy. In particular, all policies that have been suggested for parity and simple stochastic games apply. These include the all profitable, random single, and random multiple switch algorithms; see, e.g., <ref type="bibr" target="#b5">[6]</ref>. In our experiments with large random and nonrandom game instances these algorithms witness extremely fast convergence. In this section we suggest two alternative ways of combining policies.</p><p>Initial random multiple switching: Start with the MAX strategy retreating to the sink from each vertex. Prior to running the randomized subexponential algorithm from Section 3.5, make a polynomially long sequence of random (multiple) attractive switches, selecting them at each step uniformly at random. Use the last strategy obtained, if not yet optimal, as an initial one in the randomized subexponential algorithm of Section 3.5. There is a hypothesis due to Williamson Hoke <ref type="bibr" target="#b34">[35]</ref> that every completely unimodal function (possessing a unique local maximum on every Boolean subcube) can be optimized by the random single switch algorithm in polynomially many steps. The LSP problem exhibits a structure similar to CU-functions (so the subexponential stage may never become necessary). Investigating these problems may shed light on possibilities of polynomial time optimization for both.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">The LSP problem is in NP ∩ CONP</head><p>The decision version of the LSP problem, restricted to determine whether the longest shortest path from a distinguished vertex s to the sink is bigger than a given bound D, is another example of a problem in NP ∩ CONP.</p><p>In the definition of the LSP problem in Section 3.1 we postulated that a 0-weight cycle (which actually makes the sink unreachable) defines a 0 distance from every vertex on the cycle to the sink. This "unnatural" definition was motivated by simplicity and by the LSP application for computing 0-mean partitions in MPGs. This was convenient because 0-weight cycles are not interesting for MAX for reaching a positive mean value. Moreover, 0-weight cycles are impossible in admissible strategies, and only such strategies are needed (visited) by our algorithms to compute 0-mean partitions in MPGs.</p><p>However, in the LSP problem it is more natural to postulate that whenever MAX can enforce a 0-weight cycle, the distance to the (unreachable) sink becomes +∞. We show here that a minor modification allows us to reuse Theorems 5.1 (attractiveness implies profitability) and 5.2 (stability implies optimality), as well as subexponential algorithms from Sections 3.4, 3.5, to compute LSP, and to prove the NP ∩ CONP-membership.</p><p>The necessary modifications are achieved by making the following simplifying assumption about the instances of the LSP problem.</p><p>Assumption. A graph in an LSP problem instance does not contain 0-weight cycles.</p><p>This assumption may be done without any loss of generality. Indeed, if the graph G has n vertices, we can multiply all edge weights by n + 1 and add 1. As a result, all 0-weight cycles, if any, will disappear (become positive), and the lengths l, l of all paths/simple cycles in G and the modified graph G will only differ within the factor of (n + 1), i.e., l(n + 1) &lt; l l(n + 1) + n. Consequently, all negative/positive cycles in the original graph will preserve their signs. Proof. First note that we can add retreat edges to any LSP problem instance similarly as to MPGs: from any controlled vertex, make an extra edge of weight -2 • n • W -1 to the sink. Thus, we guarantee that there is an admissible strategy, namely the one always using the retreat edge. In a solution to the transformed LSP problem, a vertex has value &lt;-n•W , iff it can only reach the sink through a retreat edge, iff it has value -∞ in the original problem.</p><p>Both for YES-and NO-instances, the short witness is an optimal (stable) positional strategy in controlled vertices of the transformed problem. By computing the shortest paths to the sink in G , i.e., computing the strategy measure, it can be verified in polynomial time that no switch is attractive and thus that the strategy is optimal by Theorem 5.2. This can be used as a witness for YES-instances by testing if the value is &gt; D, and for NO-instances by testing whether the value is D.</p><p>The absence of 0-weight cycles assumption is essential in the proof above. The example in Fig. <ref type="figure" target="#fig_2">1</ref> demonstrates a 0-weight cycle, and a stable strategy, which does not provide the optimal (in the LSP sense) solution.</p><p>For MPGs we were satisfied with the definition of optimality that only stipulates that MAX can secure positive weight cycles whenever possible. Thus, in Fig. <ref type="figure" target="#fig_2">1</ref> the strategy "go to t" in the leftmost vertex is MPG-optimal, but not LSP-optimal. In contrast, the LSP-optimality makes 0-weight cycles attractive (shortest distance to the sink equals +∞). This was essentially used in the proof of Proposition 9.1 and can always be achieved by making the initial transformation to satisfy the Assumption.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">LSP: exponential sequences of attractive switches</head><p>One might conjecture that any sequence of attractive switches converges fast on any LSP problem instance, and consequently MPGs are easily solvable by iterative improvement. It is not so easy to come up with "hard" LSP examples. In this section we present a set of instances of the LSP problem and an improvement policy, selecting an attractive switch in every step, leading to exponentially long sequences of strategy improvements. This shows that the LSP problem is nontrivial, and the choice of the next attractive switch is crucial for the efficiency.</p><p>Consider the (2n + 2)-vertex graph shown in Fig. <ref type="figure" target="#fig_3">2</ref>, where round vertices belong to MAX, square ones to MIN, and the leftmost vertex is the sink. The optimal strategy of MAX is marked by the dashed edges. Adding N is unnecessary here (N may be set to 0 for simplicity), but will be needed later.</p><p>If the iterative improvement algorithm starts from the initial MAX strategy 0 shown by solid lines in binary vertices and always makes the rightmost attractive single switch, it visits all 2 n possible strategies of MAX, as can be readily verified using enough paper and patience.</p><p>The LSP instances above can be generated from MPGs as follows. In Fig. <ref type="figure" target="#fig_3">2</ref>, add a self-cycle of weight 0 in the leftmost vertex. Add the retreat vertex and edges as explained in Section 3.2. If the algorithm starts by switching from the "retreat everywhere" strategy to the initial strategy 0 above, and then always chooses the rightmost attractive single switch, it follows exactly the same exponentially long chain of improving strategies, as in the LSP case. Adding a large N is now essential to keep all the paths nonnegative; otherwise, the initial "switch from the retreat" would be nonattractive.</p><p>Actually, the LSP-instances in Fig. <ref type="figure" target="#fig_3">2</ref> are "trivial", because the graphs are acyclic and longest shortest distances are easily computable by dynamic programming in polynomial time (in the left-to-right order), as mentioned in the end of Section 3.1. These LSP-instances are also easily solvable by the "random single switches" policy, selecting an attractive switch uniformly at random. The reason is as follows. The second from the left dashed edge remains always attractive, and once the algorithm switches to this edge, it will never switch back. Such an edge defines a so-called absorbing facet. Obviously, the random single switch algorithm is expected to switch to the absorbing facet in polynomially many, namely O(n), steps. The problem that remains has one dimension less, and the preceding dashed edge determines an absorbing facet. The algorithm converges in O(n 2 ) expected iterations. Currently we are unaware of any LSP instances that require superpolynomially many steps of the single random, multiple random, or all profitable (attractive) switches algorithms.</p><p>The example of this section is inspired by the one due to Lebedev mentioned in <ref type="bibr" target="#b19">[20]</ref>, and kindly provided by Gurvich. Unlike the GKK-algorithm <ref type="bibr" target="#b19">[20]</ref>, which is deterministic and bound to perform the exponential number of iterations, corresponding exactly to the exponential sequence determined by the rightmost attractive switches above, our randomized algorithms quickly solve the examples from this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">Application to parity games</head><p>The algorithm described in this paper immediately applies to parity games, after an obvious translation. Parity games are similar to MPGs, but instead of weighted edges they have vertices colored in nonnegative integer colors. Player EVEN (MAX) wants to ensure that in every infinite play the largest color appearing infinitely often is even, and player ODD (MIN) tries to make it odd. Parity games are determined in positional strategies <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>Transform a parity game into a MPG by leaving the graph and the vertex partition between players unchanged, and by assigning every vertex <ref type="foot" target="#foot_8">12</ref> of color c the weight (-n) c , where n is the total number of vertices in the game. Apply the algorithm described in the preceding sections to find a 0-mean partition. Obviously, the vertices in the partition with value &gt; 0 are winning for EVEN and all other are winning for ODD in the parity game.</p><p>Actually, the new MPG algorithm, together with a more economic translation and more careful analysis, gives a considerable improvement for parity games over our previous algorithm from <ref type="bibr" target="#b2">[3]</ref>, which has complexity</p><formula xml:id="formula_14">min(O(n 4 • |E| • k • (n/k + 1) k ), 2 O( √ n log n) ),</formula><p>where n is the number of vertices, |E| is the number of edges, and k is the number of colors. Thus, in the worst case the first component in the upper bound may be as high as O(|E|•n 5 •2 n ), when the number of colors equals the number of vertices. The MPG algorithm improves the first component in the upper bound to O(n 2 •|E|•(n/k + 1) k ), thus gaining a factor of n 2 •k. To prove this bound, we assign weights to vertices more sparingly than in the straightforward reduction mentioned above. It is readily verified that we may equally well give a vertex of color c the weight (-1) c • c-1 i=0 (n i + 1), where n i is the number of vertices of color i. In the worst case (when all n i are roughly equal), this gives W = O((n/k + 1) k ).</p><p>There are two reasons for this improvement. First, each vertex can improve its value at most n • (n/k + 1) k times, compared with n 2 •(n/k +1) k in <ref type="bibr" target="#b2">[3]</ref> (this is because the measure for every vertex in <ref type="bibr" target="#b2">[3]</ref> is a triple, rather a single number, containing additionally the largest cycle color and the path length, now both unneeded; however, the shortest distance may be as big as the sum of all positive vertices). Second, we now apply the simpler and more efficient counterstrategy algorithm from Section 6, which saves an extra factor nk.</p><p>Moreover, translating a parity game into an MPG allows us to assign weights even more sparingly, and this additionally improves over (n/k + 1) k . Indeed, if we want to assign a minimum possible weight to a vertex of color i, we may select this weight (with an appropriate sign) equal to the total absolute weight of all vertices of preceding colors of opposite parity, plus one. This results in a sequence w 0 = 1, w 1 = -(n 0 • w 0 + 1), w i+2 = -(n i+1 • w i+1 + n i-1 • w i-1 + • • • + 1) = -n i+1 • w i+1 + w i . In the case of k = n (one vertex per color) it results in the Fibonacci sequence with alternating signs: w 0 = 1, w 1 = -2, w i+2 = -w i+1 + w i , which is, in absolute value, asymptotically O(1.618. . . n ), better than 2 n .</p><p>Finally, the new MPG-based algorithm for parity games is easier to explain, justify, and implement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="12.">Conclusions</head><p>We defined the longest shortest paths (LSP) problem and showed how it can be used as a basis for a discrete (combinatorial) strategy evaluation for MPGs. Similar evaluations were already known for parity <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b2">3]</ref>, discounted payoff <ref type="bibr" target="#b30">[31]</ref>, and simple stochastic games <ref type="bibr" target="#b24">[25]</ref>, although not discrete for the last two classes of games. Our result implies that any combinatorial strategy improvement policy may be applied to solve MPGs, thus avoiding the difficulties of high precision rational arithmetic involved in reductions to discounted payoff and simple stochastic games, and solving associated linear programs by either a nonstrongly polynomial, or a strongly subexponential subroutine. For comparison, our algorithm uses a strongly polynomial subroutine for shortest paths in edge-weighted directed graphs.</p><p>Combining the new strategy evaluation with the algorithm for combinatorial linear programming suggested by Matoušek, Sharir, and Welzl, allowed us to develop the first combinatorial subexponential 2 O( √ n log n) (and simultaneously pseudopolynomial) algorithm for solving MPGs.</p><p>The remaining major open problem is whether any strategy improvement scheme for the games discussed (or any other) has polynomial time complexity.</p><p>Since this paper was finished, there were several important developments. Khachiyan with colleagues <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b23">24]</ref> succeeded to prove that a version of the LSP problem restricted to nonnegative edge weights is polynomial time solvable. The case of arbitrary weights, needed for the reduction from MPGs, resists. The idea of "controlled" optimization problem, first implemented in the LSP, received a further development, in the form of a more general controlled linear programming problem <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b8">9]</ref>. A new efficient approach to solving mean payoff and simple stochastic games based on the linear complementarity problem has been introduced and investigated in <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b32">33]</ref>. An algorithm based on representing an MPG as a linear program, solving it, and "tightening" a solution to a solution of the game was proposed in <ref type="bibr" target="#b31">[32]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>algorithm runs in O(n • |E|) time, where n = |V |. Every vertex can have its shortest path length improved at most O(n • W ) times (W is the largest absolute edge weight; distances are increased in integral steps). Since there are n vertices, the number of switches cannot exceed O(n 2 • W ). Together with the O(n • |E|) bound per iteration this gives total time O(n 3 • |E| • W ). Here we show how to reuse the shortest distances computed in previous iteration to improve this upper bound by a linear factor to O(n 2 • |E| • W ). Since there are no known nontrivial lower bounds on the number of improvement steps, it is practically important to reduce the cost of each iteration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Proposition 9 . 1 .</head><label>91</label><figDesc>The decision version of the LSP problem (subject to the assumption above) is in NP ∩ CONP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Switching to the dotted edge is not attractive, but improves the values in all vertices to +∞.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. LSP instances allowing for exponentially long chains of improving switches.</figDesc><graphic coords="17,75.84,67.53,395.82,116.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>is convenient to let +∞ + ∞ + w, for every relation ∈ { , =, } and finite w. +∞ be the partition of G into the sets of vertices with finite and infinite shortest distances in d . Thus,v 0 is in G f . Note that in G (fullgame graph, not just G ) MAX has no edges from G f to G +∞ . Otherwise, has an attractive switch to this edge (from a finite to infinite value), contradicting the stability assumption. Although MIN may have edges from G f to G +∞ , they are not parts of the shortest paths under , and we may delete them. Let us also throw away the part G +∞ , and in G f for each MIN vertex leave just one outgoing edge u (such edges exist!). On the contrary, we return back all edges of MAX to the partition G</figDesc><table><row><cell cols="4">Since the components of d are shortest distances, the relation d (u) d (v) + w holds for every edge u</cell><cell>w → v in G ,</cell></row><row><cell cols="2">with at least one</cell><cell>per vertex u satisfied as equality. Therefore, d (u) = d (v) + w for every edge u</cell><cell>w → v of MAX in</cell></row><row><cell cols="4">G (tightness), because in G MAX has exactly one edge per vertex. Moreover, d (u) d (v ) + w for every other</cell></row><row><cell>edge u</cell><cell cols="2">w → v of MAX not in , by stability of (there are no attractive switches).</cell></row><row><cell cols="2">Let G f and G</cell><cell></cell></row></table><note><p><p>w</p>→ v, for which d (u) = d (v) + w f . As explained above, they are not leaving G f . Denote the resulting graph G .</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The games are symmetric, and the algorithm can also be applied to optimize for the minimizing player. This is an advantage when the minimizing player has fewer choices.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>Actually, we use the symmetric and equivalent "single-sink" shortest paths problem as more adequate for our purposes. A sink is a vertex with no outgoing edges.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>Actually, there may exist negative cycles consisting only of vertices from V MIN . Such cycles are easy to identify and eliminate in a preprocessing step, using the Bellman-Ford algorithm. In the sequel we assume that this is already done.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3"><p>The authors would appreciate any references.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4"><p>The case when 0-weight cycles are interpreted as good (winning) for MAX is considered in Section 9.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5"><p>We may assume that G contains no 0-weight cycles. This is important for the LSP problem and can be done without loss of generality; see the proof of Theorem 5.2 and Section</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6"><p>This is not needed if we apply the algorithm for finding 0-mean partitions in MPGs, but we have to start with an admissible strategy.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_7"><p>Proceeding in stages: Another version of the algorithm starts as described in the previous subsection, and afterward always maintains a partition of the vertices (from which the longest shortest distance is not yet +∞) into two sets: R of vertices where MAX is still using the conservative strategy of retreating immediately to the sink, and N of all other vertices. In all vertices in N ∩ V MAX , MAX already switched away from retreating. Since the value of a vertex can only increase, MAX will never change back playing to retreats in those vertices (so retreat edges from vertices in N may be safely removed without influencing the 0-mean partition). We fix the choices in R and proceed as in Section 3.5, to find the best strategy in controlled vertices in N. If the resulting strategy is globally optimal (contains no attractive switches in R), we stop. Otherwise we make some or all attractive switches in vertices in R. Each stage of this version of the algorithm is subexponential, and there are only linearly many such stages, because a vertex leaving R never returns back.<ref type="bibr" target="#b10">11</ref> Note that a straightforward approach, multiplying all rational edge weights with denominator q n 2 by q, thus reducing to the integral case, would lead to a worse bound n 3 • W .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_8"><p>Formally, we have to assign this weight to every edge leaving a vertex, but it makes no difference.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are grateful to Leonid Khachiyan, Vladimir Gurvich, and Endre Boros for inspiring discussions and illuminating ideas. We thank DIMACS for providing a creative working environment.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ଁ Supported by Swedish Research Council grants "Infinite Games: Algorithms and Complexity", "Interior-Point Methods for Infinite Games", "Infinite Games for Program Verification: Combinatorial Optimization Approach", and by an Institutional grant from the Swedish Foundation for International Cooperation in Research and Higher Education.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>w (u, v) = w(u, v)d (u) + d (v).</head><p>After this transformation:</p><p>(1) all edges in become 0-weight (by tightness);</p><p>(2) all other MAX edges become nonpositive (by stability, as explained above);</p><p>(3) all edges of MIN become 0-weight; (4) weights of all cycles remain unchanged (by telescoping);</p><p>(5) weights of finite paths v 0 , . . . , v l change by a constant -d (v 0 ) + d (v l ) (also by telescoping), hence the relation (&lt; , =, &gt;) between costs of two paths to the sink remains unchanged.</p><p>Let MAX use an allegedly better than admissible strategy from v 0 in G undergone the potential transformation above. Since MIN has just one available strategy, defines a unique play, in which every edge traversed is nonpositive by the explanation above. This play may be either finite, or infinite (actually both possibilities will lead to contradictions).</p><p>Suppose this play is finite, terminating in the sink. Let and be the paths from v 0 to the sink t in G determined by and , respectively, and functions c, c give paths costs before and after the potential transformation. We have If the play is infinite (i.e., does not terminate in the sink), then the cycle C formed by with the unique MIN strategy has all edges of nonpositive weight, i.e., C is a nonpositive weight cycle. 10 But C exists already in G , and is admissible by assumption (i.e., has no nonpositive cycles), a contradiction.</p><p>As a consequence, we obtain the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 5.3. In any MPG G every admissible stable strategy is winning for player MAX from all vertices in G &gt;0</head><p>. 10 Note that if G has no 0-weight cycles at all, then the cycle C is negative; thus is no better than , a contradiction. We can achieve the absence of 0-weight cycles by multiplying the weight of each edge by n + 1 and subtracting 1. Thus, all 0-weight cycles become negative and all other cycles keep their signs. Although this is a possible and useful approach (see Section 9), it multiplies the maximal edge weight W by n, slightly deteriorating the pseudopolynomial upper bound. Instead, to finish the proof we rely on strategy admissibility, which is maintained invariant during attractive switching; cf., Theorem 5.1.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Controlled linear programming: boundedness and duality</title>
		<author>
			<persName><forename type="first">H</forename><surname>Björklund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Svensson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vorobyov</surname></persName>
		</author>
		<idno>DIMACS-2004-56</idno>
		<ptr target="http://dimacs.rutgers.edu/TechnicalReports/" />
	</analytic>
	<monogr>
		<title level="j">NJ</title>
		<imprint>
			<date type="published" when="2004-12">December 2004</date>
		</imprint>
		<respStmt>
			<orgName>DIMACS: Center for Discrete Mathematics and Theoretical Computer Science, Rutgers University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The controlled linear programming problem</title>
		<author>
			<persName><forename type="first">H</forename><surname>Björklund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Svensson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vorobyov</surname></persName>
		</author>
		<idno>DIMACS- 2004-41</idno>
		<ptr target="http://dimacs.rutgers.edu/TechnicalReports/" />
	</analytic>
	<monogr>
		<title level="j">NJ</title>
		<imprint>
			<date type="published" when="2004-09">September 2004</date>
		</imprint>
		<respStmt>
			<orgName>DIMACS: Center for Discrete Mathematics and Theoretical Computer Science, Rutgers University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A discrete subexponential algorithm for parity games</title>
		<author>
			<persName><forename type="first">H</forename><surname>Björklund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sandberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vorobyov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">20th International Symposium on Theoretical Aspects of Computer Science, STACS&apos;2003</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Alt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Habib</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2607</biblScope>
			<biblScope unit="page" from="663" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">On combinatorial structure and algorithms for parity games</title>
		<author>
			<persName><forename type="first">H</forename><surname>Björklund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sandberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vorobyov</surname></persName>
		</author>
		<idno>2003-002</idno>
		<ptr target="http://www.it.uu.se/research/reports/" />
		<imprint>
			<date type="published" when="2003-01">January 2003</date>
		</imprint>
		<respStmt>
			<orgName>Department of Information Technology, Uppsala University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Randomized subexponential algorithms for parity games</title>
		<author>
			<persName><forename type="first">H</forename><surname>Björklund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sandberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vorobyov</surname></persName>
		</author>
		<idno>2003-019</idno>
		<ptr target="http://www.it.uu.se/research/reports/" />
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Department of Information Technology, Uppsala University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Complexity of model checking by iterative improvement: the pseudo-Boolean framework</title>
		<author>
			<persName><forename type="first">H</forename><surname>Björklund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sandberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vorobyov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Andrei Ershov Fifth International Conference</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Broy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Zamulin</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2890</biblScope>
			<biblScope unit="page" from="381" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Memoryless determinacy of parity and mean payoff games: a simple proof</title>
		<author>
			<persName><forename type="first">H</forename><surname>Björklund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sandberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vorobyov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoret. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">310</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="365" to="378" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Randomized subexponential algorithms for infinite games</title>
		<author>
			<persName><forename type="first">H</forename><surname>Björklund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sandberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vorobyov</surname></persName>
		</author>
		<idno>DIMACS- 2004-09</idno>
		<ptr target="http://dimacs.rutgers.edu/TechnicalReports/" />
	</analytic>
	<monogr>
		<title level="j">NJ</title>
		<imprint>
			<date type="published" when="2004-04">April 2004</date>
		</imprint>
		<respStmt>
			<orgName>DIMACS: Center for Discrete Mathematics and Theoretical Computer Science, Rutgers University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Controlled linear programming for infinite games</title>
		<author>
			<persName><forename type="first">H</forename><surname>Björklund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Svensson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vorobyov</surname></persName>
		</author>
		<idno>DIMACS- 2005-13</idno>
		<ptr target="http://dimacs.rutgers.edu/TechnicalReports/" />
	</analytic>
	<monogr>
		<title level="j">NJ</title>
		<imprint>
			<date type="published" when="2005-04">April 2005</date>
		</imprint>
		<respStmt>
			<orgName>DIMACS: Center for Discrete Mathematics and Theoretical Computer Science, Rutgers University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Linear complementarity algorithms for mean payoff games</title>
		<author>
			<persName><forename type="first">H</forename><surname>Björklund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Svensson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vorobyov</surname></persName>
		</author>
		<idno>DIMACS- 2005-05</idno>
		<ptr target="http://dimacs.rutgers.edu/TechnicalReports/" />
	</analytic>
	<monogr>
		<title level="j">NJ</title>
		<imprint>
			<date type="published" when="2005-02">February 2005</date>
		</imprint>
		<respStmt>
			<orgName>DIMACS: Center for Discrete Mathematics and Theoretical Computer Science, Rutgers University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Combinatorial structure and randomized subexponential algorithms for infinite games</title>
		<author>
			<persName><forename type="first">H</forename><surname>Björklund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vorobyov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoret. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">349</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="347" to="360" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The complexity of stochastic games</title>
		<author>
			<persName><forename type="first">A</forename><surname>Condon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. and Comput</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="203" to="224" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On algorithms for simple stochastic games</title>
		<author>
			<persName><forename type="first">A</forename><surname>Condon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">DIMACS Ser. Discrete Math. Theoret. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="51" to="71" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Cormen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Rivest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stein</surname></persName>
		</author>
		<title level="m">Introduction to Algorithms</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press and McGraw-Hill Book Company</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note>second ed.</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><surname>Ehrenfeucht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mycielski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Positional games over a graph</title>
		<imprint>
			<date type="published" when="1973">1973</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">334</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Positional strategies for mean payoff games</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ehrenfeucht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mycielski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Game Theory</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="109" to="113" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Model checking and the Mu-calculus</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Emerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">DIMACS Series in Discrete Mathematics</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Immerman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ph</forename><forename type="middle">G</forename><surname>Kolaitis</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="185" to="214" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Tree automata, -calculus and determinacy</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Emerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Jutla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual IEEE Symposium on Foundations of Computer Science</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="368" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On model-checking for fragments of -calculus</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Emerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jutla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Sistla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Aided Verification, Proceedings of the Fifth International Conference</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Courcoubetis</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">697</biblScope>
			<biblScope unit="page" from="385" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cyclic games and an algorithm to find minimax cycle means in directed graphs</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Gurvich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Karzanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Khachiyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">USSR Comput. Math. Math. Phys</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="85" to="91" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On nonterminating stochastic games</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Karp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="359" to="370" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A subexponential randomized simplex algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kalai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th ACM STOC</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="475" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Private communication, DIMACS</title>
		<author>
			<persName><forename type="first">L</forename><surname>Khachiyan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004-04">April 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Extending Dijkstra&apos;s algorithm to maximize the shortest path by node-wise limited arc interdiction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Khachiyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gurvich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<idno>RRR 31-2005</idno>
		<imprint>
			<date type="published" when="2005-10">October 2005</date>
			<publisher>RUTCOR, Rutgers Center of Operations Research</publisher>
		</imprint>
	</monogr>
	<note type="report_type">RUTCOR Research Report</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A subexponential randomized algorithm for the simple stochastic game problem</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ludwig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. and Comput</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="151" to="155" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A subexponential bound for linear programming</title>
		<author>
			<persName><forename type="first">J</forename><surname>Matoušek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sharir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welzl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth ACM Symposium on Computational Geometry</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A subexponential bound for linear programming</title>
		<author>
			<persName><forename type="first">J</forename><surname>Matoušek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sharir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welzl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="498" to="516" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Extensions of two person zero sum games</title>
		<author>
			<persName><forename type="first">H</forename><surname>Moulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Anal. Appl</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="490" to="508" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Prolongements des jeux à deux joueurs de somme nulle</title>
		<author>
			<persName><forename type="first">H</forename><surname>Moulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bull. Soc. Math. France</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Mean cost cyclical games</title>
		<author>
			<persName><forename type="first">N</forename><surname>Pisaruk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="817" to="828" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Theory of hybrid systems and discrete events systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Puri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>EECS University of Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">See also: Linear programming polytope and algorithm for mean payoff games</title>
		<author>
			<persName><forename type="first">O</forename><surname>Svensson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vorobyov</surname></persName>
		</author>
		<ptr target="http://rutcor.rutgers.edu/∼rrr" />
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd Intern. Conference on Algorithmic Aspects in Information and Management (AAIM&apos;06)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>2nd Intern. Conference on Algorithmic Aspects in Information and Management (AAIM&apos;06)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005-10">October 2005. 2006</date>
			<biblScope unit="volume">4041</biblScope>
			<biblScope unit="page" from="64" to="78" />
		</imprint>
	</monogr>
	<note>RUTCOR Research Report RRR 34-2005, RUTCOR, Rutgers Center of Operations Research</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A subexponential algorithm for a subclass of P-matrix generalized linear complementarity problems</title>
		<author>
			<persName><forename type="first">O</forename><surname>Svensson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vorobyov</surname></persName>
		</author>
		<idno>DIMACS-2005-20</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th Intern. Andrei Ershov Memorial Conference &quot;Perspectives of System Informatics&quot; (PSI&apos;06)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>6th Intern. Andrei Ershov Memorial Conference &quot;Perspectives of System Informatics&quot; (PSI&apos;06)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005-06">June 2005. 2006</date>
		</imprint>
		<respStmt>
			<orgName>DIMACS: Center for Discrete Mathematics and Theoretical Computer Science, Rutgers University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>See also: Linear complementarity and P-matrices for stochastic Games. to appear</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A discrete strategy improvement algorithm for solving parity games</title>
		<author>
			<persName><forename type="first">J</forename><surname>Vöge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jurdziński</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CAV&apos;00: Computer-Aided Verification</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Emerson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Sistla</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">1855</biblScope>
			<biblScope unit="page" from="202" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Completely unimodal numberings of a simple polytope</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Williamson</forename><surname>Hoke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Appl. Math</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="69" to="81" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Extending Dijkstra&apos;s algorithm to shortest paths with blocks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gurvich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Khachiyan</surname></persName>
		</author>
		<idno>DIMACS- 2005-04</idno>
		<ptr target="http://dimacs.rutgers.edu/TechnicalReports/" />
	</analytic>
	<monogr>
		<title level="j">NJ</title>
		<imprint>
			<date type="published" when="2005-02">February 2005</date>
		</imprint>
		<respStmt>
			<orgName>DIMACS: Center for Discrete Mathematics and Theoretical Computer Science, Rutgers University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The complexity of mean payoff games on graphs</title>
		<author>
			<persName><forename type="first">U</forename><surname>Zwick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Paterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoret. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">158</biblScope>
			<biblScope unit="page" from="343" to="359" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Fast algorithms for monotonic discounted linear programs with two variables per inequality</title>
		<author>
			<persName><forename type="first">D</forename><surname>Andersson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vorobyov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006-05">May 2006</date>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Isaac Newton Institute for Mathematical Sciences</orgName>
		</respStmt>
	</monogr>
	<note>preprint NI06019-LAA</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
