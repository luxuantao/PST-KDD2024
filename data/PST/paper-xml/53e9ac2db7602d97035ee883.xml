<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Machine Vision and Applications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Tomas</forename><surname>Brandtberg</surname></persName>
							<email>tomas.brandtberg@cb.slu.se</email>
							<affiliation key="aff0">
								<orgName type="department">Centre for Image Analysis</orgName>
								<orgName type="institution">Swedish University of Agricultural Sciences</orgName>
								<address>
									<addrLine>Lägerhyddvägen 17</addrLine>
									<postCode>SE-752 37</postCode>
									<settlement>Uppsala</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Centre for Image Analysis</orgName>
								<orgName type="institution">Swedish University of Agricultural Sciences</orgName>
								<address>
									<addrLine>Lägerhyddvägen 17</addrLine>
									<postCode>SE-752 37</postCode>
									<settlement>Uppsala</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fredrik</forename><surname>Walter</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centre for Image Analysis</orgName>
								<orgName type="institution">Swedish University of Agricultural Sciences</orgName>
								<address>
									<addrLine>Lägerhyddvägen 17</addrLine>
									<postCode>SE-752 37</postCode>
									<settlement>Uppsala</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Machine Vision and Applications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">56282F7696C7891D1EC4C2BB162E6B13</idno>
					<note type="submission">Received: 24 June 1997 / Accepted: 28 April 1998</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Computer vision -Scale space -Aerial image -Forestry -Remote sensing</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents an automatic multiple-scale algorithm for delineation of individual tree crowns in high spatial resolution infrared colour aerial images. The tree crown contours were identified as zero-crossings, with convex grey-level curvature, which were computed on the intensity image for each image scale. A modified centre of curvature was estimated for every edge segment pixel. For each segment, these centre points formed a swarm which was modelled as a primal sketch using an ellipse extended with the mean circle of curvature. The model described the region of the derived tree crown based on the edge segment at the current scale. The sketch was rescaled with a significance value and accumulated for a scale interval. In the accumulated sketch, a tree crown segment was grown, starting at local peaks, under the condition that it was inside the area of healthy vegetation in the aerial image and did not trespass into a neighbouring crown segment. The method was evaluated by comparison with manual delineation and with ground truth on 43 randomly selected sample plots. It was concluded that the performance of the method is almost equivalent to visual interpretation. On the average, seven out of ten tree crowns were the same. Furthermore, ground truth indicated a large number of hidden trees. The proposed technique could be used as a basic tool in forest surveys.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Vision is the process of discovering from images what is present in the world, and where it is <ref type="bibr" target="#b19">[20]</ref>. But in an aerial image of a forest a single tree crown may only be discernible as an individual object over a certain interval of scale. At the finer scales, all branches are visible and it may not be a simple task to group them correctly together to a single tree crown. On the other hand, at coarser levels of scales, a tree crown may have merged together with its neighbours.</p><p>At these scales, one would talk about an image of a forest rather than an image of trees. Consequently, a multiple-scale algorithm is appropriate for the process of delineating individual tree crowns. Scale-space theory in computer vision offers a formal mathematical treatment of analysing images at multiple scales [e.g. <ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref>.</p><p>In the forestry community, digital remote sensing analysis has often been used for image enhancement followed by on-screen interpretation, but future automated methods will increasingly use many kinds of image information, e.g. boundaries, shape and context <ref type="bibr" target="#b14">[15]</ref>. Advance information should be used in the analysis if it is available. For instance, an expected tree crown size interval might simplify the decision process. The crown size is closely related to the appropriate image scale. The interval can often be derived from a forest stand description or a forest map if a rough description of the relationship between the tree crown size and the stem diameter exists. The geographical site in which the image is captured is also a clue in this context.</p><p>The finer levels of aerial image scale have mainly been used for visual interpretation [e.g. <ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b23">24]</ref> for estimating timber volumes and tree species composition. The technique to estimate the size of individual tree crowns by a computerized system is still a future course of action during forest surveys. Some methods for recognition of individual tree crowns have been proposed, e.g. a crown-following approach based on the spectral valleys between tree crowns <ref type="bibr" target="#b6">[7]</ref> and a vision expert system based on the radial brightness distribution of tree crowns <ref type="bibr" target="#b21">[22]</ref>. A three-dimensional crown model for generating a set of image templates can be used for image matching <ref type="bibr" target="#b22">[23]</ref>. The number of trees per hectare may be estimated by counting the number of greylevel maxima above a certain level of a smoothed image, after the Gaussian kernel bandwidth has been estimated <ref type="bibr" target="#b4">[5]</ref>.</p><p>This paper proposes an algorithm which makes use of edge contours, with convex grey-level curves, at multiple scales for estimating each tree crown area. The organization of the article is as follows. First, there is an analysis overview in Sect. 2. Each step of the algorithm is fully described in Sect. <ref type="bibr" target="#b2">3</ref>. Sections 4-6 present an evaluation of the method on a large image data set with ground truth. For reasons of comparison, the latter section includes a delineation work made by an experienced visual interpreter. We also give a brief section about other similar analysis systems. Finally, there is a conclusion and a discussion section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System overview</head><p>Figure <ref type="figure" target="#fig_0">1</ref> gives a system overview of the multiple scale analysis of the aerial images. The procedure of segmenting significant tree crowns was primarily based on scale-space theory. It is a framework for low-level or early image processing.</p><p>Image smoothing was performed on the intensity (brightness) image <ref type="bibr" target="#b5">[6,</ref><ref type="bibr">Chap. 4</ref>] derived from the colour infrared (CIR) aerial image. Intensity edges were detected as zerocrossings <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b26">27]</ref> which have subpixel accuracy. Only edges with convex grey-level curves were further processed.</p><p>At each image scale and for each edge pixel, a centre of curvature was computed. All such points belonging to the same edge segment formed a path (evolute) or swarm. An ellipse was estimated based on these points and extended with the mean circle of curvature. The values of the sketch were high in the interior part and decreased towards the periphery. The model was used as a modified primal sketch <ref type="bibr" target="#b19">[20]</ref>. A significance value based on the total edge curvature and the shape of the ellipse rescaled the values of the sketch. The sketches were accumulated for a scale interval.</p><p>Local peaks were detected among the accumulated sketches and if they were above a certain significance threshold, they were selected as seed points for the tree crowns. A tree crown segment was grown from each seed point as long as it did not contradict its neighbouring segments or was outside the global segment identifying the delimiter between the objects and the background.</p><p>The algorithm was evaluated on 43 sample plots randomly selected from 86 plots on 24 different images. The aerial images were captured in central Sweden on productive Fig. <ref type="figure">2</ref>. A subimage of the original intensity aerial image. The square is 30 m wide and the pixel size corresponds to 10 cm on the ground (300 × 300 pixels). Birch is the predominantly tree species in this subimage forest land. On each sample plot, ground truth was available, together with a tree crown delineation made by an experienced visual aerial image interpreter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Algorithm</head><p>The different steps of the algorithm are described in detail in this section, together with exemplifying pictures and sketches of the image processing. A subimage of one of the aerial images is used as a running example (Fig. <ref type="figure">2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Image smoothing</head><p>The purpose of smoothing is to round off the contour of each individual tree crown and merge different contour parts that are close to each other. Furthermore, the smoothing identifies those edge contours that obviously belong to the same circular tree crown. As crowns are of different sizes and shapes, smoothing must be at different scales.</p><p>Image isotropic smoothing was based on a family of discrete kernels. The image representation L at scale level t was given by Lindeberg <ref type="bibr" target="#b16">[17]</ref>: <ref type="bibr" target="#b0">(1)</ref> where T (n; t) = e -t I n (t) and I n is the modified Bessel function of integer order n. The modified Bessel functions are not always available as standard routines. Use must then be made of an algorithm to generate the required filter coefficients T (n; t) for a scale value t, and an algorithm of that kind was specified in Lindeberg <ref type="bibr" target="#b15">[16]</ref>. The smoothing was light, t = 9.0 up to approximately t = 36.0, for merging tree crown parts that were already close to each other. Figure <ref type="figure" target="#fig_1">3</ref> shows a smoothed image at scale level t = 36.0. </p><formula xml:id="formula_0">L(x, y; t)= ∞ m=-∞ T (m; t) ∞ n=-∞ T (n; t) • f (x -m, y -n) ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Effective scale</head><p>To be able to appropriately compare and sum up the primal sketches at different levels of scale, the notation of effective scale <ref type="bibr" target="#b17">[18]</ref> was adopted. This is based on the assumption that the probability that a certain local extremum disappears after a small amount of smoothing (effective scale unit) should remain constant over scale. The local extremum was a tree crown edge in this analysis.</p><p>If the expected density, p(t), of extreme points at a certain level of scale is known, the effective scale τ as a function of the ordinary scale parameter t, can be written as</p><formula xml:id="formula_1">τ = A + B × log p(t) .</formula><p>(</p><formula xml:id="formula_2">)<label>2</label></formula><p>The density p(t) of convex edges was investigated for a representative aerial image. A function was estimated by regression analysis by letting the logarithm of the scale and the density values be the independent and dependent variables, respectively. The constant A in Eq. 2 can be set to zero and the constant B in Eq. 2 is just a rescaling of the effective scale parameter. With A equal to zero and B equal to one, the effective scale parameter τ was given by τ = -1.6003 -0.2348 × log t .</p><p>(</p><formula xml:id="formula_3">)<label>3</label></formula><p>The effective scale τ was incremented with equal step length using the relationship in Eq. 3 and the t values calculated in this way were used in the image smoothing process. Note that the straight-line approximation is valid only in an interior scale interval, when there is no inference with the inner scale (pixel size) and outer scale (image size).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Edge detection using a differential geometric definition</head><p>Edges in a digital image may be defined in many different ways. For the continuous case, it is natural to define edges as Tree Crown u v Fig. <ref type="figure">4</ref>. A new orthonormal coordinate system is introduced relative to the outer tree crown contour those points where the gradient magnitude assumes a maximum in the gradient direction <ref type="bibr" target="#b18">[19]</ref>. This method is called non-maximum suppression [e.g. 4].</p><p>Edges, which represent tree crown contours in our aerial images, are defined by a differential geometric approach <ref type="bibr" target="#b18">[19]</ref>. Therefore, a new orthonormal coordinate system (u,v), at any image point, is introduced (see Fig. <ref type="figure">4</ref>), where the vaxis is parallel to the gradient direction of the brightness L in the actual point, and the u-axis perpendicular to it. Thus, the u-axis is approximately parallel to the tangent of the level curve. The local directional derivative operators in this new coordinate system are related to the Cartesian coordinates as</p><formula xml:id="formula_4">∂ ū = sin β∂ x -cos β∂ y , ∂ v = cos β∂ x + sin β∂ y . (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>At an arbitrary image point the gradient magnitude is equal to</p><formula xml:id="formula_6">∂ v L, denoted L v .</formula><p>It is assumed that the second-and thirdorder directional derivatives of L in the v -direction are not simultaneously zero. The condition for an image point to be a gradient maximum, i.e. an edge point, in the gradient direction is given by</p><formula xml:id="formula_7">L v v = 0 , L v v v &lt; 0 . (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>A change of the coordinate system, from the curvilinear system to the Cartesian system, using the relationship in Eq. 4 above, gives</p><formula xml:id="formula_9">L v v = L 2 x Lxx + L 2 y Lyy + 2LxLyLxy (L 2 x + L 2 y ) = 0 , (<label>6</label></formula><formula xml:id="formula_10">)</formula><formula xml:id="formula_11">L v v v = L 3 x Lxxx + 3L 2 x LyLxxy + 3LxL 2 y Lxyy + L 3 y Lyyy (L 2 x + L 2 y ) 3 2 &lt; 0<label>(7)</label></formula><p>Using these equations, it is a simple task to find edge points. Note that the edge points (zero-crossings) are a subpixel entity. Very light thresholding (T = 0.5) on the gradient magnitude was performed.</p><p>To simplify the subsequent treatment of the edge segments, there was no application of any interpolation scheme. All 8-connected neighbouring pixels on the negative and positive side, respectively, of the zero-crossing formed an edge segment. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Grey-level curvature estimation on the edges</head><p>A useful entity often used for corner detection, after some modifications, is the curvature κ of level curves in the smoothed image L <ref type="bibr" target="#b18">[19]</ref>:</p><formula xml:id="formula_12">κ = L ū ū L v = L 2 x L yy + L 2 y L xx -2L x L y L xy (L 2 x + L 2 y ) 3/2 . (<label>8</label></formula><formula xml:id="formula_13">)</formula><p>The curvature was calculated on the zero-crossings and a threshold ensured that only edge pixels with convex (κ &lt; 0) grey-level curves were processed further. Pixels with a very high curvature value (κ &lt; -0.20) were also removed. Note that the curvature value is the curvature of the grey-level curve at the current edge pixel and not the curvature of the edge. Furthermore, the zero-crossings do not always follow the grey levels. Additionally, a convex section was removed if its sector angle, relative to its mean centre of curvature, corresponded to less than π/4. Edge segments were also removed if they consisted of less than ten pixels. Figure <ref type="figure" target="#fig_2">5</ref> shows the selected edges with convex grey-level curvature values at scale level t = 36.0 for the example subimage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Parameters derived from the curvature</head><p>The parameter average curvature can be derived from the curvature values for each edge segment with convex greylevel curves. In the continuous case, it is defined as <ref type="bibr" target="#b9">[10]</ref> </p><formula xml:id="formula_14">k = 1 L L s=0 k(s) ds , (<label>9</label></formula><formula xml:id="formula_15">)</formula><p>where L is the length of a simple connected curve, k(s) is the curvature at point s, and s is the running arc length </p><formula xml:id="formula_16">K = 1 N N i=1 k i , (<label>10</label></formula><formula xml:id="formula_17">)</formula><p>where N is the total number of edge pixels in the current segment and k i is the curvature at edge pixel number i . The distance between edge pixels is thus always counted as one and the edge was formed by the pixels on the positive and negative side of the zero-crossings, respectively. The average curvature gives an estimate of the mean radius of curvature <ref type="bibr" target="#b20">[21]</ref>:</p><formula xml:id="formula_18">ρ = 1 κ . (<label>11</label></formula><formula xml:id="formula_19">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Transformation processes in scale space</head><p>An edge contour normally goes through at least one of the following four transformation processes when blurring is gradually increased: 1) 'Rounding off', 2) 'Expansion', 3) 'Transformation into circles', and 4) 'Merger' <ref type="bibr" target="#b1">[2]</ref>. The centres of curvature belonging to the edge pixels will be transformed analogously. If the expected tree crown size interval and the digital nature of the images are taken into account, there are mainly five cases (see Fig. <ref type="figure" target="#fig_3">6</ref>): 1) 'Move position', 2) 'Merge' or 3) 'Split' relative to neighbouring centres of curvature, 4) 'Show up' or 5) 'Disappear'. The expected tree crown size interval will influence points 4 and 5.</p><p>The smoothing process starts at scale level t = 9.0. It was motivated by the fact that a merger between two closed contours takes place when the t-value is about equal to the distance between them <ref type="bibr" target="#b1">[2]</ref>. In the finer levels of scale (less than t = 9.0, approximately), the fine structures predominantly represent internal tree crown branches and edges. The scale-space technique in this algorithm focuses on the tree crown contours, which mainly undergoes rounding-off transformations at higher levels of scale. Therefore, no loss of essential information was expected to take place due to the heuristically chosen and applied scale interval. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">The centre of curvature primal sketch</head><p>A primal sketch <ref type="bibr" target="#b19">[20]</ref> may describe significant image intensity changes. It may also be used analogously for describing significant curvature changes of contours <ref type="bibr" target="#b0">[1]</ref>, based on primitives like corner and smooth join. A similar modification of the original term primal sketch is introduced here. An appropriate name of the modification is the centre of curvature primal sketch.</p><p>At each edge pixel P in a segment, a curvature value was calculated using Eq. 8. The circle of curvature at point P is a circle tangent to the curve at point P whose centre, (ξ, η) (Fig. <ref type="figure" target="#fig_4">7</ref>), lies on the concave side of the curve and whose curvature is the same as that of the curve at point P <ref type="bibr" target="#b20">[21]</ref>. The circle is also called the osculating circle because it has a higher degree of contact with the edge than any other circle. The path of all centres of curvature of a smooth curve is called the evolute. For a circle, the evolute is mapped into the same point (origin). For an ellipse contour, the evolute is a path in the xy-plane having a specific position.</p><p>In our algorithm, the radius of the mean circle of curvature ρ and the gradient direction at each edge pixel were used to find a modified evolute. Only reasonable radii were considered further (ρ &gt; 0.5 m and ρ &lt; 5.0 m). The points of the evolute from an edge contour segment were modelled with an ellipse by using a sample covariance matrix S, with the coordinate pair of the centre of curvature as a two-dimensional variable. Principal component analysis <ref type="bibr" target="#b10">[11]</ref> was used to find the major and minor axis of the ellipse. The (j,k)th matrix element of the sample covariance matrix S was the estimated covariance between the ith and jth elements, and the variance of the ith element when i=j :</p><formula xml:id="formula_20">s jk = 1 N -1 N i=1 (x ij -xj )(x ik -xk ) , (<label>12</label></formula><formula xml:id="formula_21">)</formula><p>where j, k = 1,2 and the coordinates for the centre of gravity of the N (N &gt; 1) evolute points were given by</p><formula xml:id="formula_22">xj = 1 N N i=1 x ij . (<label>13</label></formula><formula xml:id="formula_23">)</formula><p>The orientation of the first principal component (major axis) was given by φ = arctan The area of the ellipse models a scatter plot of all the evolute points. The two-dimensional Gaussian function with standard deviation σ can be separated into the product of two one-dimensional functions <ref type="bibr" target="#b24">[25]</ref> and applied here:</p><formula xml:id="formula_24">g(x) = 1 √ 2πσ × exp - x 2 2σ 2 . (<label>15</label></formula><formula xml:id="formula_25">)</formula><p>The square root of the calculated eigenvalues of Eq. 12 σ 1 and σ 2 , extended with the value of the mean radius of curvature ρ, formed the major and minor axis (2a and 2b if a &gt; b) of the model. The product of two one-dimensional and perpendicular models formed the basis of the twodimensional primal sketch. Centred at the current mean centre of curvature the model was given by</p><formula xml:id="formula_26">h(x, y) = ρ 2 (ab) × exp -constant × x 2 a 2 + y 2 b 2 , (<label>16</label></formula><formula xml:id="formula_27">)</formula><p>where constant = 2.0 for good segmentation results. At the centre of gravity of the ellipse the values of the exponential term were close to one and it decreased towards the edge of the ellipse region. If σ 1 and σ 2 were low, the scaling factor before the exponential term was almost one. The derived sketch indicated where one could expect to find the visible tree crown computed from the visible tree crown edge. The primal sketch was rescaled by a significance value. It was computed from the quotient of the sector angle relative to the mean centre of curvature and a whole circle (Fig. <ref type="figure" target="#fig_4">7</ref>). For example, an angle of a half-circle rescaled the values of the model by a half. Finally, the calculated model was added to a primal sketch accumulator. Figure <ref type="figure">8</ref> shows the primal sketches of the subimage at scale level t = 36.0 and Fig. <ref type="figure" target="#fig_6">9</ref> the accumulated (scale levels from t = 9.0 to approximately t = 36.0) sketches.</p><p>The accumulator was smoothed by a Gaussian kernel with a small t-value (in this work t = 5.0.) for merging close peaks. This procedure corresponded to merging several </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8">Tree crown segments</head><p>The goal of the image analysis is delineated individual tree crowns. This can be achieved by first using a global threshold in the image. The threshold should in some optimal way identify the delimiter between vegetation (all healthy tree crowns) and non-vegetation or the dark background. The latter group includes (dark) stones and soil on the ground, dead vegetation and other non-living objects. The thresholding is feasible because of the higher spectral reflectance of the healthy vegetation in the near-infrared band of the aerial image <ref type="bibr" target="#b8">[9]</ref>, which will affect the local intensity of the aerial image.</p><p>Simple image statistics can be used for estimating a global threshold value <ref type="bibr" target="#b12">[13]</ref>, based on the pixel brightness weighted with the gradient magnitude in an ideal twobrightness-level image:</p><formula xml:id="formula_28">T = N i=1 N j=1 |h ij | N i=1 N j=1 |e ij | = B + D 2 , (<label>17</label></formula><formula xml:id="formula_29">)</formula><p>where h is the product of the grey level and the gradient magnitude, e is the gradient magnitude and the objects and background pixels have ideal grey-level values B and D, respectively. N represents the image size in number of pixels. Under the assumption that B and D do not vary over the image, this equation is the appropriate threshold value for segmenting objects from the background. Unfortunately, the brightness of the tree crown objects in an aerial image is not ideal, especially if there is lowelevation sun. Generally, there is a sunny side and a dark side of the tree crown. Therefore, a more suitable, but similar, method was developed. According to Eq. 5, the tree crown contour was the point where L vv = 0. Furthermore, L vv can be expected to be negative inside the tree crown and positive outside at scale level t = 9.0. L vv is always negative inside and close to the steep edges, and the gradient magnitude is always high there. Thus, these points were expected to be counted with higher weights. A grey-level histogram was formed for the whole image where L vv &lt; 0 by incrementing the appropriate grey level with the e-values. This distribution was further processed and had an approximately normal distribution around the mean, with an estimated standard error (Fig. <ref type="figure" target="#fig_7">10</ref>). An interval of confidence was formed (90 %) and the lower limit was used as a threshold for a global segment in the image.</p><p>In the image of the accumulated primal sketches, each tree crown was visible as a local maximal point with a neighbourhood with decreasing values. Each detected peak represented a seed point for a tree crown segment if the significance value was high. The global segment was 4neighbourhood eroded <ref type="bibr" target="#b9">[10]</ref> three times before the subsequent process. Starting at the seed point, the region was grown inside the global segment as long as the values were decreasing and did not contradict with neighbouring segments. The identified and labelled tree crown segments were grown into the previously eroded regions in the end (Fig. <ref type="figure" target="#fig_0">11</ref>).</p><p>The computation time for the running example image was less than 30 s on a Digital Personal Workstation 433au (433-MHz Alpha processor, 2 MB cache, 128 MB memory).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Aerial image data set and image analysis software</head><p>The delineation technique was evaluated on an aerial image data set. The set consisted of 50 colour infrared images captured as a sample in central Sweden (62 • 27 N, 16 • 55 E), on 10 August 1995, between 13:00 and 14:30 p.m. The height was 600 m above the ground and the image scale was approximately 1:2000 (focal length: 302.97 mm). The forest stands were 40 years or older but were mainly mature with an average age of approximately 80 years. They were mainly naturally regenerated at the beginning of the 20th century. The stands were both mixed and pure forest stands and consisted predominantly of Scots pine (Pinus silvestris L.), Norway spruce (Picea abies (L.) Karst.), birch (Betula pubescens Ehrh.) and some aspen (Populus tremula L.). The central squares (7.5 × 7.5 cm and 5000 × 5000 pixels) of the original aerial images (23 × 23 cm, Kodak Aerochrome Infrared Film 2443) were scanned. This was justified by the near-orthogonal projection of the whole image, i.e. all the tree crowns were observed almost straight from above. The images were resampled by bilinear interpolation <ref type="bibr" target="#b5">[6]</ref> to a pixel size corresponding to 10 cm on the ground. The final size of the images corresponded to a square of 120 m.</p><p>The algorithm was implemented in the Khoros Software Package, version 2.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Ground truth and visual interpretation</head><p>Ground truth was measured on 86 sample plots (radius 10 m) for 24 images during the summer of 1996. The plots were randomly positioned with a square spacing (50 m) relative the centre of the aerial image. The latter position was identified using a Global Positioning System (GPS) and manual recognition of the trees on the ground and in the image.</p><p>A set of 43 randomly selected plots out of 86 was used in the evaluation of the delineation algorithm. The composition of the tree species on these 43 sample plots was: Scots pine 23 % of the total stem volume, Norway spruce 62 % and birch 14 %. Aspen was less than 1 %.</p><p>For comparison with the accuracy achieved by a human interpreter, which is still the prevalent method, an experienced aerial image interpreter made a manual delineation of the corresponding image subset. The interpretation was performed on a slightly larger subimage (radius 12 m) than the sample plot (radius 10 m) for better visibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental validation on image and field data</head><p>The algorithm was evaluated on the 43 randomly selected sample plots. A summary of the different segment configurations for each tree species compared with the segment configurations made by the manual interpreter is presented in Table <ref type="table">1</ref>. Numerous small tree crowns were identified by the human interpreter but our computerized algorithm ignored them due to the specified threshold values. Some distinct tree crowns were not identified during the visual interpretation, but were found by our system. A lot of sun patches were erroneously found by the computer, but the interpreter could usually discriminate them from the tree crowns.</p><p>Table <ref type="table">1</ref>. Delineation results of the 43 randomly selected sample plots (radius 12 m) compared with manual interpretation. The tree crown segment configurations made by our computerized system relative to the manual image interpreter (The configuration 3:1 means that three segments were found by our system, but it was interpreted manually as a single object) Tree species 3:1 2:1 1:0 1:1 0: Table <ref type="table">2</ref> shows a summary of the performance compared with ground truth. Light sun patches (23 were counted) on the ground were not included. Note that Table <ref type="table">1</ref> and Table <ref type="table">2</ref> are approximate values, derived from an assessment of the configuration of each image segment (see e.g. Fig. <ref type="figure" target="#fig_0">11</ref>).</p><p>The relation between the number of tree crowns identified on the sample plots by the algorithm and the number of Table <ref type="table">2</ref>. Delineation results of the 43 randomly selected sample plots (radius 10 m) compared with the ground truth. The tree crown segment configurations made by our computerized system relative to the ground truth on the sample plots. Identified sun patches on the ground (class 1:0) are not included Tree species 3:1 2:1 1:1 0:  trees (diameter at breast height greater than 10.0 cm) measured on the ground is presented in Table <ref type="table">3</ref>.</p><p>The linear relationship between the stem diameter at breast height and the corresponding (parallel) diameter of the tree crown, excluding solitary branches, was validated for the 43 sample plots (Fig. <ref type="figure" target="#fig_0">12</ref>). The diameters (stem and crown) were always calculated as area-weighted mean diameters. For N number of trees on a sample plot, the mean diameter D was given by</p><formula xml:id="formula_30">D = N i=1 d 3 i N i=1 d 2 i . (<label>18</label></formula><formula xml:id="formula_31">)</formula><p>The mean value was calculated using all trees on each sample plot, irrespective of the tree species. The forest in our images was dominated by Norway spruce, which consequently influenced the regression function the most.</p><p>Based on the linear relationship between stem and crown diameters it is of interest to show the relationship between the mean diameter of the tree crown segments in the images and the corresponding mean crown diameters measured on the ground for all 43 sample plots (Fig. <ref type="figure" target="#fig_9">13</ref>). In this case, they are generally uncorrelated. Most of the trees are approximately of the same size, which is shown as a narrow interval on the horizontal axis in Fig. <ref type="figure" target="#fig_9">13</ref>. On an average of the whole analysed data set the crown diameter visible in the image was 54 % of the corresponding physical tree crown diameter on the ground. Table <ref type="table">3</ref>. The total number of plots (43) distributed on different tree count groups. Each group defines a class (width 10 %) which is the number of segments identified by the algorithm relative to the number of trees (diameter at breast height greater than 10.0 cm) counted on the ground Consequently, the mean tree crown diameter measured in the images, and the mean stem diameter measured on the ground were also uncorrelated (Fig. <ref type="figure" target="#fig_10">14</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Comparison with other works</head><p>It is of interest to compare our presented tree crown delineation algorithm with the two other approaches in the cited articles by Gougeon <ref type="bibr" target="#b6">[7]</ref> and Pollock <ref type="bibr" target="#b22">[23]</ref>. When making such a comparison one should bear in mind the different conditions under which the analyses were performed. The different conditions depended on varying spatial and spectral resolution, altitudes and camera parameters. The forest type and tree species are probably the most important factor.</p><p>Gougeon <ref type="bibr" target="#b6">[7]</ref> used one band of one image from the airborne Multi-detector Electro-optical Imaging Sensor (MEIS II), with a pixel size of 31 cm. It was acquired on 22 November 1982, from an altitude of 440 m (1440ft. in the text) over a research plantation in Ontario, Canada. The algorithm consisted of a valley-following process combined with a rulebased program for further delineation. Gougeon found that the automatic delineation counts differed by 7.7 % from the ground counts. Photo counts, performed by an experienced photo interpreter using stereo pairs of normal colour aerial images at a scale of 1:2000, differed by 18.1 % from the ground counts. In general, 81 % of the tree crowns are the same as those obtained by the visual interpretation of the imagery.</p><p>Pollock <ref type="bibr" target="#b22">[23]</ref> also used MEIS II images, but they were acquired in two flightlines over another part of the research forest in Ontario, on 16 August 1988. The six wave-length bands in which the images were sensed were all between 0.43 µm and 1.07 µm. Not all of them were used due to poor quality. The nominal along-scanline pixel ground dimension was 0.364 m for both flightlines. The nominal along-flightline pixel ground sizes were 0.414 m and 0.398 m, respectively. The automatic tree crown recognition procedure was based on a model of the image formation process at the scale of an individual tree. Pollock tested the procedure with scenes of mixed uneven-aged forests, in which the trees represent a wide variety of species, sizes and growing conditions. He found that the errors in the automatic recognition results were mostly omission errors. The errors in the automatic and manual image-based crown diameter estimates were comparable. Furthermore, both these sets of estimates tended to be low relative to the ground measurements, probably because of the intersection of tree crowns and the failure to resolve branches at the outer contour. The numbers of commission errors in the manual and the liberally assessed automatic recognition results were 10 % and 11 % of the 340 sample trees. On the other hand, the liberally assessed automatic recognition omission error was 38 %. The corresponding manual recognition omission error was 14 %. The overall agreement of the automatic image-based crown diameter classification with the field-measurement-based crown diameter classification was 0.434 (full resolution) and 0.707 (half-resolution), respectively.</p><p>The algorithm presented in this paper identified, on the average, seven out of ten manually interpreted tree crowns, if the very small trees are omitted. The omission error consisted of very small tree crowns or dark crowns that were below the estimated global threshold. On an average of the whole data set, 54 % of the physical tree crown diameter was visible in the image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>Our algorithm was able to capture circular and elongated tree crowns if the solution did not contradict with other neighbouring tree crown segments. The delineation results were almost equivalent to the time-consuming and expensive manual delineation work and are very good if one accepts that the classes 1:2 and 2:1 in Table <ref type="table">1</ref> might cancel each other. The ground truth indicated a considerable number of hidden trees, or trees standing very close to each other, that were not visible in the aerial images. Compared with the ground truth, the segmentation process was often not able to discriminate trees standing very close to each other or small trees standing close to large trees. On an average, only minor parts of the tree crowns were visible in the images, due to partly overlapping tree crowns, light conditions, and shapes of tree crowns.</p><p>One drawback with the low dynamic range of the infrared photographic film was that the shady side of a large tree crown (e.g. spruce) was completely dark. Using the edge segmentation method presented here, this limitation was partly circumvented. The combination of the edge detection for estimating tree crown shapes and extension and the global threshold value for identifying the brightness delimiter between the background and the objects was proven to be very applicable. The estimate of the global threshold value was reasonable for all analysed images.</p><p>Light sun patches on the ground were identified as tree crowns in many cases. These segments must be classified in a subsequent analysis, e.g. by using colour or possibly a shape measure.</p><p>The algorithm presented is suited for identifying individual tree crown regions, useful for, e.g. species classifications. It was shown that the segment area is an uncertain variable for direct estimating of, e.g. stem diameters, without taking all neighbouring segments into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Discussion</head><p>The underlying tree crown model in the scale-space search for tree crowns was, in principle, a circular model. But ellipse-shaped crowns could be found in some cases, if that was the best solution. The general tree crown model was based on the fact that an undamaged tree has a major stem and the branches grow radially out from the stem. A natural forest contains numerous broken and leaning trees, which makes the analysis very difficult and there were many cases when false identification of the tree crowns occurred.</p><p>Generally, a sample image often contains trees of almost the same size due to the low spatial variation within the forest stands. The delineation process should pay more attention to large trees because they contain most of the stem volumes and are more valuable. The illumination and visibility should be similar for the same class of forest stand and the segmentation algorithm can be expected to perform equally, on the average, on images of the same class of forest. Furthermore, if the forest is dominated by trees of the same size class, it might be possible to replace the heuristically chosen smoothing interval with an interval derived from features of the objects in the image.</p><p>The accumulated sketch can also be used as input to another higher level algorithm, such as snakes <ref type="bibr" target="#b11">[12]</ref>, which needs a closed initial contour. But it might be too detailed for our purposes and difficult to use because of missing tree crown contours inside dense parts. The algorithm combined with the simple global threshold estimation fulfilled most of our segmentation requirements and solved the multiplescale property of the tree crown contours in two dimensions. Further improvements and calibrations of the overall performance of the algorithm are possible.</p><p>An important feature of the mature forest is that there is often a visible dark spacing between tree crowns in the aerial image. It might be very narrow, just a few decimetres, and it might be the result of trees waving in the wind. This feature was often useful for the edge detection process.</p><p>The global threshold could be further improved by dividing the image into different gradient orientation regions, each one resulting into a unique threshold. This approach might improve the effect of the sun illumination and treat the sunny parts and the shadow parts of the trees as two different subimages. One might also use the gradient values raised to some power to emphasize the grey values at the brightness edges. To remove the fact that the curvature of the grey level curve is not identical to the curvature of the edge, it might be possible to introduce an alternative edge definition based on a single (global) threshold value and treat the border pixels of the segment as an edge.</p><p>Further developments may use information derived from this segmentation algorithm. Such data are the estimated tree stem position and estimated tree crown shape and overlap. Further research will use the crown segments as regions of interest (ROI) for internal structure analysis [e.g. 3]. Together, they may be used for species classification and, if the analysis includes spatial relationships between segments, it might be possible to estimate stem diameter. Tree height data should also be included, from e.g. an airborne laser scanner, for estimating stem volumes.</p><p>The research work concerning digital image analysis of aerial images presented here anticipates that the photographic film will be replaced by a digital camera in the future. This is expected to be much more cost effective and to have very good sensitivity and a high dynamic range.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tomas</head><p>Brandtberg was born in Norrköping, Sweden, in 1963. He received the M.Sc. degree in forestry from the Swedish University of Agricultural Sciences, Umeå, Sweden, in 1992. He is currently a graduate student at the Centre for Image Analysis, Swedish University of Agricultural Sciences, Uppsala, Sweden, under Prof. Gunilla Borgefors. His primary research interests in image analysis are automatic extraction of forest parameters from high spatial resolution aerial images and integration of laser height data.</p><p>Fredrik Walter was born in Sundsvall, Sweden, in 1967. He received the M.Sc. degree in forestry from the Swedish University of Agricultural Sciences, Umeå, Sweden, in 1994. He is currently a graduate student at the Centre for Image Analysis, Swedish University of Agricultural Sciences, Uppsala, Sweden, under Prof. Gunilla Borgefors. His primary research interest in image analysis is extraction of forest parameters from CARABAS radar images.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Block diagram of the system. Thick arrows indicate procedures performed at multiple scales</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Isotropic smoothed aerial image at scale level t=36.0. (Compare with the original image in Fig. 2)</figDesc><graphic coords="3,43.65,30.93,226.77,226.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig.5. Edges (zero-crossings) or tree crown contours with convex greylevel curves at scale level t = 36.0 marked with the corresponding curvature. These edges were used in the subsequent analysis. A dark edge pixel corresponds to a low curvature value</figDesc><graphic coords="4,43.65,30.93,226.77,226.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>6 .</head><label>6</label><figDesc>Planar scale-space transformation processes of centres of curvature. Filled arrowheads are edge motion in scale space and empty arrowheads are related motion of centre of curvature. Circles of curvature at an edge point P are marked from start point to end point. Due to the digital nature of the image and the fact that the edge points (zero-crossings) are subpixel entities, this equation was reformulated as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. A centre of curvature ellipse model derived from an edge segment (left). The centre of gravity of the model and the features used for computing a significance value of the configuration (right)</figDesc><graphic coords="5,305.89,30.93,226.77,226.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>s 22 -Fig. 8 .</head><label>228</label><figDesc>Fig. 8. Centre of curvature primal sketches computed on the subimage at scale level t=36.0 and rescaled with the significance value. The maximal value in this image should be less than one</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Accumulated rescaled primal sketches from scale level t=9.0 to approximately scale level t=36.0. The maximal value in this image is greater than one with high probability</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Approximately normal distributed grey-level histogram of the gradient weights for a large test image at scale level t = 9.0. (Derived threshold T=67)</figDesc><graphic coords="6,43.65,30.93,226.77,226.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 11 .Fig. 12 .</head><label>1112</label><figDesc>Fig. 11. Delineated tree crowns with white borders after the segmentation process. The computations were performed on a slightly larger subimage to avoid image edge influence</figDesc><graphic coords="7,43.65,30.93,226.77,226.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Plot of the area weighted mean crown diameter (m) measured in the image vs the area-weighted mean crown diameter (m) measured on the ground for the 43 sample plots</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>GroupFig. 14 .</head><label>14</label><figDesc>Fig. 14. Plot of the area weighted mean crown diameter (m) measured in the image vs the basal area-weighted mean stem diameter (cm) measured on the ground for the 43 sample plots</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. We wish to thank Magnus Larsson, SCA Forest and Timber, Sundsvall, Sweden for economic aid and equipment for the field inventory in the summer of 1996. We also wish to thank Leif Sund, at Danielsbergs Värdshus, Matfors and DHR, Nederede, near Stöde, for their help with accommodation during this period. We also acknowledge Jüri Talts at the National Land Survey of Sweden in Gävle, for the visual aerial image interpretation, and Professor Gunilla Borgefors, Centre for Image Analysis, for discussions of the manuscript. This work was financially supported by the Swedish Council for Forestry and Agricultural Research (SJFR) under contract no. 20 .0040/95.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Curvature Primal Sketch</title>
		<author>
			<persName><forename type="first">H</forename><surname>Asada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="14" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Edge Focusing</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bergholm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="726" to="741" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards structure-based classification of tree crowns in high spatial resolution aerial images</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brandtberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scand J Forest Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="89" to="96" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Computational Approach to Edge Detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="679" to="698" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Stem number estimation by kernel smoothing of aerial photos</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dralle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rudemo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Can J Forest Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1228" to="1236" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Digital image processing</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Woods</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Addison Wesley</publisher>
			<pubPlace>Reading, Mass</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A crown-following approach to the automatic delineation of individual tree crowns in high spatial resolution aerial images</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Gougeon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Can J Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="274" to="284" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Predicting Tree Groundline Diameter from Crown Measurements Made on 35-mm Aerial Photography</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Hagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Photogramm Eng Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="687" to="690" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Harris</surname></persName>
		</author>
		<title level="m">Satellite remote sensing. Routledge &amp; Kegan Paul</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Image Based Measurement Systems</title>
		<author>
			<persName><surname>Hejden F Van Der</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>Chichester</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Principal Component Analysis</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">T</forename><surname>Jolliffe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Snakes: Active Contour Models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Comput Vision</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="321" to="331" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Threshold selection based on a simple image statistic</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Illingworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Föglein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Vision, Graphics Image Process</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="125" to="147" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The structure of images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Koenderink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol Cybern</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="363" to="370" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Advances in remote sensing technologies for forest surveys and management</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Leckie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Can J Forest Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="464" to="483" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On the construction of a scale-space for discrete images</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lindeberg</surname></persName>
		</author>
		<idno>Internal Rep. TRITA-NA-P8808</idno>
	</analytic>
	<monogr>
		<title level="j">Dept. Numerical Analysis Computer Science, Royal Institure of Technology</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<pubPlace>Stockholm, Sweden</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scale-Space for Discrete Signals</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lindeberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="234" to="254" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Effective Scale: A Natural Unit for Measuring Scale-Space Lifetime</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lindeberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1068" to="1074" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Scale-Space Theory in Computer Vision</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lindeberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Dordrecht</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Vision</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<publisher>Freeman</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Scale-Based Description and Recognition of Planar Curves and Two-Dimensional Shapes</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mokhtarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mackworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="34" to="43" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Final Results of the Vision Expert System VES: Finding Trees in Aerial Photographs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pinz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wissensbasierte Mustererkennung (Knowledge-Based Pattern Recognition), OCG-Schriftenreihe 49</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Pinz</surname></persName>
		</editor>
		<meeting><address><addrLine>Vienna</addrLine></address></meeting>
		<imprint>
			<publisher>Oldenbourg Verlag</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="90" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">The automatic recognition of individual trees in aerial images of forests based on a synthetic tree crown image model</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Pollock</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<pubPlace>Vancouver, Canada</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of British Columbia</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Canadian large-scale aerial photographic systems (LSP)</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Spencer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Photogramm Eng Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="475" to="482" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Edge contours using multiple scales</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Vision Graphics Image Process</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="256" to="274" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Scale-space filtering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th Int. Joint Conf. Artificial Intelligence</title>
		<meeting>8th Int. Joint Conf. Artificial Intelligence<address><addrLine>Karlsruhe, West Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1983-08">1983. August 1983</date>
			<biblScope unit="page" from="1019" to="1022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Scaling theorems for zero-crossings</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="25" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
