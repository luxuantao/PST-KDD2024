<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-strategy ensemble grey wolf optimizer and its application to feature selection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-12-10">10 December 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Qiang</forename><surname>Tu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronics and Information Technology</orgName>
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<settlement>Guangzhou, Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xuechen</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronics and Information Technology</orgName>
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<settlement>Guangzhou, Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xingcheng</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronics and Information Technology</orgName>
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<settlement>Guangzhou, Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Information Science</orgName>
								<orgName type="institution">Xinhua College of Sun Yat-sen University</orgName>
								<address>
									<settlement>Guangzhou, Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-strategy ensemble grey wolf optimizer and its application to feature selection</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-12-10">10 December 2018</date>
						</imprint>
					</monogr>
					<idno type="MD5">4C50E254AEA73985AEFF7C838F024526</idno>
					<idno type="DOI">10.1016/j.asoc.2018.11.047</idno>
					<note type="submission">Received 26 July 2018 Received in revised form 9 November 2018 Accepted 29 November 2018</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Intelligent simulation Function optimization Grey wolf optimizer Multi-strategy ensemble Feature selection</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>h i g h l i g h t s</head><p>• A multi-strategy ensemble GWO is proposed to boost the precision and efficiency of the original GWO.</p><p>• A parameter self-adjusting strategy is utilized to balance the exploitation and exploration of the proposed MEGWO.</p><p>• Wilcoxons signed-rank test and performance profile are used to investigate the significance of the MEGWO.</p><p>• Feature selection is employed to evaluate the effectiveness of MEGWO on real-world applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent decades, nature-inspired intelligent simulation optimization algorithms (ISOAs) by mimicking the laws of natural evolution, physical rules or biological behaviours have thrived. Optimization problems brought up in complex systems are usually characterized by non-linearity, non-differentiability, multimodality, discontinuity, inseparability and inequality constraints. Traditional mathematical programming methods are no longer efficient in resolving such problems <ref type="bibr" target="#b0">[1]</ref>. In contrast, ISOAs with good self-learning ability and efficient search mechanism become competitive alternatives.</p><p>In 1980s and 1990s, with the rapid development of modern computing and data storage technology, some classical and powerful ISOAs have been proposed and extensively investigated, including Simulated Annealing algorithm (SA) <ref type="bibr" target="#b1">[2]</ref>, Genetic Algorithm (GA) <ref type="bibr" target="#b2">[3]</ref>, Back Propagation Neural Network (BPNN) <ref type="bibr" target="#b3">[4]</ref>, Differential Evolution (DE) <ref type="bibr" target="#b4">[5]</ref>, Particle Swarm Optimization (PSO) <ref type="bibr" target="#b5">[6]</ref>, etc. Since the 21st century, the inspirations from nature have continued to spawn the rapid development of ISOAs. During recent years, not only traditional ISOAs have been further studied, but also a variety of novel heuristic algorithms appear successively, such as: Firefly Algorithm (FA) <ref type="bibr" target="#b6">[7]</ref>, Harmony Search (HS) <ref type="bibr" target="#b7">[8]</ref>, Bat Algorithm (BA) <ref type="bibr" target="#b8">[9]</ref>, Cuckoo Search (CS) <ref type="bibr" target="#b9">[10]</ref>, Bacteria Foraging Algorithm (BFA) <ref type="bibr" target="#b10">[11]</ref>, Shuffled Frog Leaping Algorithm (SFLA) <ref type="bibr" target="#b11">[12]</ref>, Artificial Bee Colony algorithm (ABC) <ref type="bibr" target="#b12">[13]</ref>, Biogeography-Based Optimization (BBO) <ref type="bibr" target="#b13">[14]</ref>, Grey Wolf Optimizer (GWO) <ref type="bibr" target="#b14">[15]</ref>, Whale Optimization Algorithm (WOA) <ref type="bibr" target="#b15">[16]</ref>, etc. These algorithms have shown great potential to deal with real-world optimization problems especially in the field of feature selection (FS).</p><p>Feature selection (FS) is an important preprocessing step that has a significant impact on the performances of data mining and machine learning techniques <ref type="bibr" target="#b16">[17]</ref>. Searching for the optimal feature subset amongst an unabridged dataset is a challenging problem, especially for large-scale datasets. In recent years, many ISOAs are employed to tackle the FS problems. In <ref type="bibr" target="#b17">[18]</ref> an efficient Grasshopper Optimization Algorithm (GOA) with evolutionary population dynamics and selection operators has been employed to deal with FS. In <ref type="bibr" target="#b18">[19]</ref> an intelligent detection system based on hybridizing GA and random weight network has been proposed to automatically identify the relevant features of the spam emails. In <ref type="bibr" target="#b19">[20]</ref> I. <ref type="bibr">Aljarah et al.</ref> proposed an asynchronous binary Salp Swarm Algorithm (SSA) with three different updating strategies to tackle the FS problems. In <ref type="bibr" target="#b20">[21]</ref> M. Mafarja et al. integrated eight time-varying transfer functions into the Dragonfly Algorithm (DA) to convert the step vector from continuous to a binary space for FS problems.</p><p>Grey wolf optimizer is a novel ISOAs by simulating the social hierarchy and hunting behaviour of grey wolves in nature <ref type="bibr" target="#b14">[15]</ref>. As GWO has the advantages of simple principle, fewer tuning parameters, fast convergence and strong local search ability, the research on it has made remarkable progress and achieved fruitful rewards. The main applications of GWO include global optimization, machine learning, power engineering, environmental applications, wireless sensor network, medical bioinformatics and image processing <ref type="bibr" target="#b21">[22]</ref>. In <ref type="bibr" target="#b22">[23]</ref> Emary et al. proposed two novel binary versions of GWO for feature selection by using different updating mechanisms. In <ref type="bibr" target="#b23">[24]</ref> GWO was utilized to determine the best combination of control variables to solve optimal reactive power dispatch (ORPD) problem. In <ref type="bibr" target="#b24">[25]</ref> a multi-level hybrid clustering routing protocol algorithm based on GWO was proposed for wireless sensor networks. In <ref type="bibr" target="#b25">[26]</ref> Song et al. proposed a novel surface wave dispersion curve inversion scheme where GWO was used for parameter estimation in surface waves. In <ref type="bibr" target="#b26">[27]</ref> two different approaches for multi-objective binary GWO algorithm were utilized for improving cervix lesion classification in medical bioinformatics. In <ref type="bibr" target="#b27">[28]</ref> a novel approach of multilevel thresholding based on GWO was proposed to solve the image segmentation problem.</p><p>These applications show that GWO can be widely used to solve a variety of real-world optimization problems. However, similarly to other ISOAs, GWO has its inevitable drawbacks and limitations. The main drawback of GWO is the insufficiency of global search capability as all three alpha, beta, and delta wolves tend to converge to the solution with the same search strategy. The main limitation is that the single search strategy makes GWO not effectively handle various optimization problems with different characteristics <ref type="bibr" target="#b21">[22]</ref>. Hence, some modifications have been done to improve the performance of GWO. The modifications can be categorized into four aspects: update mechanisms, new operators, population and social hierarchy, and hybridization. From the aspect of update mechanisms, researchers target on the balance between exploration and exploitation of GWO. To achieve this balance, dynamically tuning the parameters of GWO and adopting different update strategies for search agents are two main means <ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref>. The scheme of adding new operators focuses on improving the performance of GWO by embedding a new operator like crossover operator or a local search algorithm <ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref>. Some researchers investigate the effect of hierarchical structure and do some modifications on it since the hierarchy is a basic and unique feature of GWO <ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref>. As for hybridization, the most common strategy is to integrate GWO with two or more algorithms to have complementary advantages <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref>.</p><p>Considering the combination of update mechanisms and new operators, a multi-strategy ensemble GWO (MEGWO) is proposed to boost the efficiency and precision of the original GWO in this paper. The proposed MEGWO incorporates three different search strategies including enhanced global-best lead strategy, adaptable cooperative hunting strategy, and disperse foraging strategy. The enhanced global-best lead strategy can fully explore the excellent experience of leader wolf to enhance the local search ability of GWO. By the adaptable cooperative hunting strategy, the global search capability of the original GWO is enhanced as a result of embedding the one-dimensional update operation. Then, disperse foraging strategy is utilized to further enhance the exploration by relocating a part of search agents to a promising area of the search space. Moreover, the adaptive parameter tuning strategy is used for balancing the exploitation and exploration of the algorithm during the iterative process. The performance of the proposed algorithm is examined on 18 benchmark functions and CEC2014 test set. Nonparametric Wilcoxon test and performance profile are also used to investigate the significance of the results. Furthermore, feature selection is employed to evaluate the effectiveness of MEGWO on real-world applications.</p><p>The rest of the paper is organized as follows. In Section 2, we describe the mechanism and mathematical model of GWO. In Section 3, the motivations and details of MEGWO are illustrated.</p><p>Then the experiments on a wide set of test functions and the application on feature selection of MEGWO are conducted and discussed in Section 4. Finally, conclusions and future direction are given in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">An overview of grey wolf optimizer</head><p>GWO is a population-based stochastic algorithm that mimics the leadership hierarchy and hunting strategy of grey wolves in nature <ref type="bibr" target="#b39">[40]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Leadership hierarchy</head><p>Grey wolves in nature have a strict social dominant hierarchy as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. According to the order of social status from high to low, the grey wolf is categorized into four levels: alpha (α), beta (β), delta (δ) and omega (ω). Different levels of grey wolves play different roles and bear corresponding responsibilities. The higher the level the wolf belongs to, the better understanding of the location of the prey it has. This mechanism is essential for effective hunting of grey wolves. In order to mathematically model the social hierarchy of wolves when designing GWO, the first three fittest search agents in every iteration are regarded as α, β, and δ. The rest of search agents are treated as ω. During optimization, ω are guided by α, β, and δ towards promising areas of the search space to find the optimal solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Hunting strategy</head><p>According to <ref type="bibr" target="#b40">[41]</ref>, the hunting behaviour of grey wolves mainly consists of three phases: tracking and approaching prey, encircling and harassing prey, and attacking prey. The mathematical model of encircling behaviour is formulated as follows:</p><formula xml:id="formula_0">D t = ⏐ ⏐ C t • X t p -X t ⏐ ⏐ (1) X t+1 = X t p -A t • D t (2)</formula><p>where X t P and X t indicate the position vectors of the prey and the wolf at tth iteration, respectively. X t+1 stands for the position vector of the wolf at (t + 1) th iteration. A and C are coefficient vectors.</p><formula xml:id="formula_1">A = 2ϕ • r 1 -ϕ, C = 2 • r 2 .</formula><p>ϕ is linearly decreased from 2 to 0 over the course of iterations and ϕ = 2 -2 • (t/L). L indicates the maximum number of iterations. r 1 and r 2 are random vectors whose elements are all within [0, 1]. It is noted that the parameters A and C allow wolves to be relocated to any place in the search space around the prey <ref type="bibr" target="#b39">[40]</ref>.</p><p>In the GWO algorithm, it is assumed that α, β, and δ have better knowledge about the potential location of the prey (optimum). Therefore, the first three fitness search agents obtained so far are considered as α, β, and δ, respectively. Then other search agents are assumed as ω and obliged to update their location in the light of α, β, and δ. The mathematical model of hunting behaviour is formulated as follows:</p><formula xml:id="formula_2">D t α = ⏐ ⏐ C t 1 • X t α -X t ⏐ ⏐ (3) D t β = ⏐ ⏐ C t 2 • X t β -X t ⏐ ⏐<label>(4)</label></formula><formula xml:id="formula_3">D t δ = ⏐ ⏐ C t 3 • X t δ -X t ⏐ ⏐ (5) X t 1 = X t α -A t 1 • D t α (6) X t 2 = X t β -A t 2 • D t β (7) X t 3 = X t δ -A t 3 • D t δ (8) X t+1 = ( X t 1 + X t 2 + X t 3 ) /3<label>(9)</label></formula><p>where X t α , X t β , and X t δ stand for the positions of α, β, and δ at tth iteration, respectively. D t α , D t β , and D t δ denote the approximate distances between the current solution and α, β, and δ, respectively.</p><p>After estimating the approximate distances, the final location of the solution can be calculated by Eq. ( <ref type="formula" target="#formula_3">9</ref>). The pseudo code of original GWO algorithm is presented in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Multi-strategy ensemble GWO</head><p>In GWO, α, β, and δ lead ω towards promising areas to search the optimal solution. This phenomenon can cause premature aggregating in the current optimal position and make GWO fall into the local optimum. Moreover, the complicated optimization problems have various characteristics such as: high dimensionality, nonlinearity, multi-modality, and non-separable <ref type="bibr" target="#b41">[42]</ref>. It is difficult for single search strategy of GWO to solve a variety of complex optimization problems. </p><formula xml:id="formula_4">for i = 1 to N do 9:</formula><p>Update the position of search agent X t i by Eq.( <ref type="formula" target="#formula_3">9</ref>)</p><p>10:</p><p>end for 11:</p><p>Update ϕ, A, C</p><p>Evaluate the fitness value of all search agents 13:</p><p>Update X t α , X t β , X t δ 14: t = t + 1 15: end while</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Enhanced global-best lead strategy</head><p>Inspired by the concept of global-best strategy proposed in global-best harmony search (GHS) <ref type="bibr" target="#b42">[43]</ref>, an enhanced global-best lead strategy is proposed in this paper. In GHS, the best harmony in the harmony memory is regarded as the global-best candidate solution. GHS modifies the pitch-adjustment step of by randomly selecting one element from the best harmony vector such that the new harmony can mimic the best harmony. The results in <ref type="bibr" target="#b42">[43]</ref> indicated that such modifications enhanced the local search ability of HS and allowed it to work efficiently on both continuous and discrete problems. However, this pitch-adjustment approach that the new harmony is selected directly from the best harmony has a bias towards exploitation <ref type="bibr" target="#b43">[44]</ref>.</p><p>The enhanced global-best lead strategy in this paper regards the alpha wolf as the global-best wolf in the pack. The new strategy adopts the same way as GHS to explore the rich experience of the alpha wolf. In addition, it adds a modified differential mutation operation to keep the search from having a bias towards exploitation.</p><formula xml:id="formula_6">X t+1 i,d = { X t α,j rand , rand 1 &lt; GR X t α,d + 2 • ϕ • r 3 • (X t m,d -X t n,d ), otherwise<label>(10)</label></formula><p>where t indicates the number of current iterations. i, m, and n ∈ {1, 2, . . . , N}, i ̸ = m ̸ = n and d ∈ {1, 2, . . . , D}. Herein, N is the population size and D is the number of the dimensions of the solution. j rand is a randomly chosen integer within the range <ref type="bibr">[1, D]</ref>. ϕ gradually decreases from 2 to 0 over the course of iterations. X α stands for the position of α. GR represents the global-best guidance rate which is a user-specified constant between 0 and 1. Both rand 1 and r 3 are random numbers between 0 and 1.</p><p>It can be seen from Eq. ( <ref type="formula" target="#formula_6">10</ref>) that there are two update operators in the enhanced global-best lead strategy. They are elite decision operator based on the self-cognition of α and elite guidance operator by integrating social cognition into the experience of α. When rand 1 &lt; GR, each wolf updates the dth element of its position vector by randomly selecting an element from the position vector of α. This operator can enhance the local search ability and speed up the convergence rate of the algorithm, yet it may reduce the diversity of population and cause the algorithm to trap into local optimum. As a supplement, when rand 1 ≥ GR, the differential mutation operation which uses X α as the basis vector is adopted to maintain the individual diversity and expand the scope of the search <ref type="bibr" target="#b44">[45]</ref> </p><formula xml:id="formula_7">, m ̸ = n ̸ = i 8: Update X t i,d by X t+1 i,d =X t α,d + 2 • ϕ • r 3 • (X t m,d -X t n,d ) 9:</formula><p>end if 10:</p><p>end for 11: end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Adaptable cooperative hunting strategy</head><p>Like most evolution algorithms, GWO adopts the total-dimensional update operation which changes all elements of the solution vector in each iteration. This mechanism has an excellent performance for optimization of non-separable function. However, it may not be able to achieve a high quality solution for multimodal and separable functions due to the interferences among different dimensions of the solution <ref type="bibr" target="#b45">[46]</ref>. ABC <ref type="bibr" target="#b12">[13]</ref> is a novel swarm intelligent optimization algorithm, which is inspired by the behaviour of bees finding honey. One-dimensional update operation is an interesting feature of ABC. This operation only changes one element of candidate solution vector in each iteration and utilizes the greedy selection strategy to ensure the new better solution obtained to be reserved for the next iteration <ref type="bibr" target="#b45">[46]</ref>. According to the study of <ref type="bibr" target="#b46">[47]</ref>, the one-dimensional updating operation can provide a higher population diversity than the total-dimensional one and thus makes ABC have a strong global search ability especially for multimodal and separable functions.</p><p>In the original GWO, ω wolves encircle and attack prey by teamwork under the leadership of α, β and δ to complete hunting. We regard this update mode as cooperative hunting strategy. Inspired by the one-dimensional update operation of ABC, we integrate the one-dimensional update operation into the framework of original GWO to form an adaptable cooperative hunting strategy. In adaptable cooperative hunting phase, one-dimensional update operation and total-dimensional update operation are alternatively adopted when search agents update their position vectors. Specifically, each search agent will choose one-dimensional update operation with probability SR and total-dimensional one with probability (1 -SR). SR is formulated as follows:</p><formula xml:id="formula_8">SR = SR max -(SR max -SR min ) • t/L (11)</formula><p>where SR max and SR min are the upper and lower bounds of SR, respectively.</p><p>In this way, the proposed cooperative hunting strategy improves the adaptability of the algorithm on various functions. That is why we name the strategy as adaptable cooperative hunting strategy. The pseudo code of cooperative hunting strategy is presented in Algorithm 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3 Adaptable cooperative hunting algorithm</head><p>Input: The search agent population X t , parameter ϕ, A, C and SR Output: Updated search agents population X t+1 ,</p><formula xml:id="formula_9">1: for i = 1 to N do 2: if rand 2 ≤ SR then 3:</formula><p>Generate a random integer j rand and j rand ∈ {1, 2, . . . , D} </p><formula xml:id="formula_10">for d = j do 9:</formula><p>Update the position of search agent X t i,d by Eq.( <ref type="formula" target="#formula_3">9</ref>)</p><p>10:</p><p>end for 11: end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Disperse foraging strategy</head><p>Food shortage events may occur in the area where a pack of grey wolves live. This event forces a part of wolves to be dispersed into a new area to forage for surviving. The dispersal behaviour make it more possible that grey wolves migrate to a region with abundant food and improve the viability of wolves in harsh environments. To mathematically model the disperse behaviour, disperse foraging strategy is proposed. In disperse foraging phase, a part of search agents can be repositioned to a promising area of the search space according to the dispersion rate (DR) and update their location as follows <ref type="bibr" target="#b47">[48]</ref>:</p><formula xml:id="formula_11">X t+1 i,d =X t i,d + ρ • ∆ t i,d • B t i,d<label>(12)</label></formula><formula xml:id="formula_12">∆ t i,d = (X t m,d -X t n,d )<label>(13)</label></formula><p>where ρ is the scale factor that controls the migration distance of search agents during the foraging phase and ρ ∼ N(0.5, 0.1 2 ). The same setting of ρ can be found in <ref type="bibr" target="#b48">[49]</ref>. ∆ t i,d represents a random migration distance of the search agent. B t i,d is a logical value which is used to determine whether the search agent is dispersed and can be formulated as follows:</p><formula xml:id="formula_13">B t i,d = { 1, rand 3 &gt; DR 0, otherwise<label>(14)</label></formula><p>where DR is defined as a linearly decreasing parameter over the iterative course which formulates as follows:</p><formula xml:id="formula_14">DR = DR max -(DR max -DR min ) • t/L (<label>15</label></formula><formula xml:id="formula_15">)</formula><p>It can be seen from Eqs. ( <ref type="formula" target="#formula_5">12</ref>) and ( <ref type="formula" target="#formula_14">15</ref>), the scale factor ρ assists search agents to show a more random behaviour throughout optimization process. Meanwhile, the self-adaptive adjustment of DR is utilized to control the scale of search agents which are dispersed to a new area. In the early stage of iterations, a small scale of grey wolves is repositioned in disperse foraging phase with a large DR value. It contributes to provide a fast convergence speed. Then, when the value of DR becomes smaller as the number of iterations increases, search agents are more likely to participate in disperse foraging operation and increase the chance that the algorithm avoids local optimum. The pseudo code of disperse foraging strategy is presented in Algorithm 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 4 Disperse foraging algorithm</head><p>Input: The search agent population X t , parameter DR Output: Updated search agents population X t+1 1: Generate a logic matrix B t by Eq.( <ref type="formula" target="#formula_13">14</ref>)</p><p>2: Generate the dispersed distance matrix ∆ t by Eq.( <ref type="formula" target="#formula_12">13</ref>)</p><p>3: Update the position of search agent X t by Eq.( <ref type="formula" target="#formula_5">12</ref>)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Main procedure of MEGWO</head><p>The main process of MEGWO is illustrated as Fig. <ref type="figure" target="#fig_2">2</ref>. It can be seen from Fig. <ref type="figure" target="#fig_2">2</ref> that the enhanced global-best lead strategy makes search agents fully exploit the search space around the current best solution. The strategy has good local search ability and can help to find a more precise solution. As for adaptable cooperative hunting strategy, one-dimensional update operation is embedded in the framework of the original GWO. It not only retains the advantages of fast convergence speed and strong local search ability of GWO, but also makes full use of the characteristics of onedimensional update operation to improve the diversity of populations and hence enhance the global search ability. Besides the above two strategies, as a supplementary means, disperse foraging strategy is vital to balance the exploitation and exploration of the algorithm during the iterative course. It can not only guarantee the convergence speed of the algorithm in the early stage of iteration, but also enlarge the search range of the population and prevent the algorithm from falling into local stagnation in the later stage of iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental results and discussion</head><p>In order to investigate the performance of MEGWO, a great deal of experiments were implemented in this section. 18 classical benchmark functions were used to analyse the impact of the relevant parameters and the effectiveness of the improvement strategies in MEGWO. Furthermore, 30 benchmark functions from CEC2014 <ref type="bibr" target="#b49">[50]</ref> were employed to compare MEGWO with other three modified GWO algorithms and seven state-of-the-art ISOAs algorithms. The analysis of computational complexity of the proposed algorithm was conducted as well. Finally, feature selection was applied to validate the performance of MEGWO on real-world problems. All experiments were performed on a PC with Intel(R) Core i7-7700k 4.20 GHz CPU, 8 GB RAM in the Windows10 OS and coded in Matlab R2014b.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental results on benchmark set1 4.1.1. Benchmark test functions and parameter settings</head><p>In this subsection, 18 benchmark test problems with different characteristics were applied to analyse the performance of MEGWO <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b51">52]</ref>. The selected test functions are summarized in Table <ref type="table" target="#tab_3">1</ref>, where C indicates the characteristics of the test functions, which include unimodal (U), multimodal (M), separable (S), and non-separable (N). Range denotes the search range of test functions. F min means the global optimal value. The 18 test functions can be classified into three groups: unimodal functions (f 1 -f 6 ), multimodal functions (f 7 -f 12 ), shifted functions (f 13 -f 18 ). Our objective is to obtain the minimum for each function.</p><p>For each problem, the population size (N) was 20 and the maximum number of iterations (L) was 2500 for 30-dimensional function and 3500 for 50-dimensional case. The other specific parameters of MEGWO algorithm were set as follows: GR = 0.8, SR max = 1, SR min = 0.6, DR max = 0.4 and DR min = 0 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">The impact of parameter GR</head><p>The parameter GR determines how many search agents will adopt elite decision operator based on the self-cognition of α wolf.</p><p>It is crucial for balance the between exploration and exploitation in the enhanced global-best lead phase. To find appropriate GR value, we performed a large amount of experiments. We varied the value of GR from 0 to 1 with interval length 0. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3.">The effectiveness of the improvement strategies on MEGWO</head><p>As mentioned previously, MEGWO algorithm consists of three main improvement strategies: enhanced global-best lead strategy, adaptable cooperative hunting strategy, and disperse foraging strategy. The objective of this subsection is to validate the effectiveness of these three strategies. To this end, a comparison between MEGWO and its variants were conducted for 18 test functions with 50-dimensions. Herein, its variants are denoted as MEGWO1, MEGWO2 and MEGWO3, respectively. The algorithm adopting the adaptable cooperative hunting strategy and disperse foraging strategy while the enhanced global-best lead strategy is not used is referred to MEGWO1. The algorithm employing enhanced global-best lead strategy, disperse foraging strategy and the adaptable cooperative strategy without one-dimensional update operation is denoted as MEGWO2. The algorithm adopting enhanced global-best lead strategy and adaptable cooperative hunting strategy while disperse foraging strategy is ignored is denoted as MEGWO3. For each test function, 30 independent runs were implemented and L was set to 3500. The Mean and Std results of GWO, MEGWO1, MEGWO2, MEGWO3 and MEGWO are shown in Table <ref type="table" target="#tab_5">3</ref>. Wilcoxon's signed-rank test at a 5% significant level was employed for evaluated test systems. '' + ", '' -", and '' ≈ " denote that the performance of the proposed MEGWO is superior to, inferior to, or similar to that of corresponding algorithm, respectively <ref type="bibr" target="#b52">[53]</ref>. The best results are highlighted in bold.</p><p>Observed from Table <ref type="table" target="#tab_5">3</ref>, MEGWO surpasses GWO on 15 test functions and is similar to GWO on 3 test functions. The results show that the performance of GWO has a significant improvement utilizing the combination of three improvement strategy. With respect to MEGWO1, MEGWO shows better performance on 11 test functions. However, it achieves similar performance on 5 test functions f 6 , f 9 , f 13 , f 15 , and f 16 while it obtains worse results for f 17 and f 18 . This is due to the fact that the enhanced global-best lead strategy was not used in MEGWO1 which makes the algorithm focus on deep exploration and achieve promising results for multi-modal functions. Compared to MEGWO2, MEGWO obtains better results on 5 functions while it got similar results on 10 functions and worse results on 3 functions f 2 , f 3 , and f 7 . It seems that MEGWO without one-dimensional update operation emphasizes on exploitation and is good at solving unimodal functions problems. With respect to MEGWO3, MEGWO obtains better results on 14 functions and similar results on 4 functions. The performance of MEGWO3 is obviously inferior to MEGWO. Hence, it can be concluded that the disperse foraging strategy plays an important role in improving the efficiency and accuracy of GWO. The convergence characteristics of 5 algorithms on 50-dimensional test function f 1 , f 4 , f 11 , and f 14 are shown in Fig. <ref type="figure">3</ref>. From Fig. <ref type="figure">3</ref>, we can observe that MEGWO converges closest to the global optimum for all the functions and with a fastest rate of convergence except for f 1 . Similar behaviours can also be observed on most of the rest test functions. Due to the space limit, we omit other resulting figures.</p><p>From Table <ref type="table" target="#tab_5">3</ref> and Fig. <ref type="figure">3</ref>, it concludes that each update strategy is indispensable and the integration of them is the key to improve the performance of the algorithm efficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experiment results and analysis on benchmark set 2 4.2.1. Benchmark functions of CEC2014</head><p>In this section, IEEE CEC2014 benchmark functions were utilized <ref type="bibr" target="#b49">[50]</ref>. This benchmark set consists of 30 unconstrained optimization problems with different characteristics such as unimodality, multimodality, hybrid and composite modality. More details about the definition of these functions can be found in <ref type="bibr" target="#b49">[50]</ref>. According to the guidelines provided by <ref type="bibr" target="#b49">[50]</ref>, the range of the search space for each variable is [-100, 100]. The termination criteria is defined as be the maximum number of function evaluations (NFE), which is 10 4 × dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Comparison of MEGWO with other modified GWO algorithms</head><p>To validate the superiority of MEGWO, the proposed algorithm were compared with the original GWO <ref type="bibr" target="#b14">[15]</ref> and three existing modified GWO algorithms including EPDGWO <ref type="bibr" target="#b31">[32]</ref>, LGWO <ref type="bibr" target="#b34">[35]</ref> and RWGWO <ref type="bibr" target="#b36">[37]</ref>. The initial parameters of these algorithms were set to the ones adopted in their original references and are reported in Table <ref type="table" target="#tab_6">4</ref>. NFE was set to 3 × 10 5 for all the algorithms for a fair comparison. For each test function with 30 dimensions, 51 independent runs were implemented. The statistical tests in experiment 4.2 are similar to those of experiment 4.1 while Mean and Std were used as criterions. The comparison results are presented in Table <ref type="table" target="#tab_7">5</ref> and the best results are marked in bold. Please note that the results of LGWO and RWGWO are directly taken from their original literatures.</p><p>As shown in Table <ref type="table" target="#tab_7">5</ref>, MEGWO beats the original GWO for all of the test functions except for f 24 and f 26 . Compared with EPDGWO, MEGWO achieves better results for all of the functions except for f 24 . With respect to LGWO, MEGWO achieves better results on 17 functions. Meanwhile it gets worse results on 11 functions of the rest ones and similar results on the other 2 functions. Compared with RWGWO, MEGWO could obtain better results on 25 functions and similar results on 1 function. For f 6 , f 24 , f 29 , and f 30 , MEGWO is beaten by RWGWO. As Table <ref type="table" target="#tab_7">5</ref> states, MEGWO shows a significant Sphere</p><formula xml:id="formula_16">f 1 (x) = n ∑ i=1 x 2 i US [-100,100] 0 Schwefel2.22 f 2 (x) = n ∑ i=1 |x i | + n ∏ i=1 |x i | UN [-10,10] 0 Quartic f 3 (x) = n ∑ i=1 ix 4 i + rand(0, 1) US [-1.28,1.28] 0 Rosenbrock f 4 (x) = n-1 ∑ i=1 [ (x i -1) 2 + 100 ( x i+1 -x 2 i ) 2 ]</formula><p>UN [-10,10] 0 Schwefel2.26</p><formula xml:id="formula_17">f 5 (x) = 418.98288727243369 * n - n ∑ i=1 x i sin (√ |x i | ) UN [-500</formula><p>,500] 0</p><p>Step</p><formula xml:id="formula_18">f 6 (x) = n ∑ i=1 (⌊x i + 0.5⌋) 2 US [-100,100] 0 Ackley f 7 (x) = -20 exp(-1 5 √ 1 n n ∑ i=1 x 2 i ) -exp[ 1 n n ∑ i=1 cos(2π x i )] +20 + e MN [-32,32] 0 Rastrigin f 8 (x) = n ∑ i=1 [x 2 i -10 cos(2π x i ) + 10]</formula><p>MS [-5.12,5.12] 0 Griewank -450</p><formula xml:id="formula_19">f 9 (x) = n ∑ i=1 x 2 i 4000 - n ∏ i=1 cos( x i √ i ) + 1 MN [-600,600] 0 Levy f 10 (x) = n-1 ∑ i=1 (x i -1) 2 [1 + sin 2 (3π x i+1 )] + sin 2 (3π x 1 ) + |x n -1| [1 + sin 2 (3π x n )] MN [-10,10] 0 Penalized1 f 11 (x) = π n {10sin 2 (π y i ) + n-1 ∑ i-1 (y i -1) 2 [1 + 10sin 2 (π y i+1 )]+ (y n -1) 2 } + n ∑ i=1 u(x i , 10, 100, 4), y i = 1 + 1 4 (x i + 1), u(x i , a, k, m) = ⎧ ⎨ ⎩ k(x i -a) m , x i &gt; a 0 , -a ≤ x ≤ a k(-x i -a) m , x i &lt; -a MN [-50,50] 0 Penalized2 f 12 (x) = 1 10 { sin 2 (3π x 1 ) + n-1 ∑ i=1 (x i -1) 2 [ 1 + sin 2 (3πx i+1 ) ] +(x n -1) 2 [ 1 + sin 2 (2π x n ) ]} + n ∑ i=1 u (x i , 5, 100<label>, 4)</label></formula><p>Shifted Griewank</p><formula xml:id="formula_20">f 15 (z) = 1 + n ∑ i=1 z 2 i 4000 - n ∏ i=1 cos( z i √ i ) -180, z = x -o MN [-600,600]</formula><p>-180</p><p>Shifted Ackley</p><formula xml:id="formula_21">f 16 (z) = -20 exp[-1 5 √ 1 n n ∑ i=1 z 2 i ] -exp[ 1 n n ∑ i=1 cos(2π z i )] +20 + e -140, z = x -o MN [-32,32]</formula><p>-140</p><p>Shifted Rastrigin</p><formula xml:id="formula_22">f 17 (z) = n ∑ i=1 (z 2 i -10 cos(2π z i ) + 10) -330, z = x -o MS [-5,12<label>,5.12]</label></formula><p>-330</p><p>Shifted Rosenbrock</p><formula xml:id="formula_23">f 18 (z) = n-1 ∑ i=1 [ (z i -1) 2 + 100 ( z i+1 -z 2 i ) 2 ] + 390, z = x -o + 1 UN [-100,100] 390</formula><p>improvement over GWO, EPDGWO and RWGWO while LGWO also provides a very competitive result compared to MEGWO. To make our superiority more distinguished, we introduce performance profiles <ref type="bibr" target="#b61">[62]</ref> as a tool for evaluation of all relevant algorithms on the CEC2014 test sets.</p><p>Performance profiles can clearly reflect the performance of one algorithm in the algorithms set G which consists of n g algorithms on a functions set F which consists of n f test functions. The mean fitness value is chosen as the performance metric. µ f ,g is defined as the mean fitness value after performing algorithm g on function f .</p><p>If we compare the performance on function f by algorithm g with the best performance by the algorithms in set G on this function, the performance ratio r f ,g is calculated as follows:</p><formula xml:id="formula_24">r f ,g = µ f ,g min{µ f ,g : g ∈ G} (16)</formula><p>To obtain an overall assessment of the performance of algorithm g on all functions, we define</p><formula xml:id="formula_25">ρ g (τ ) = 1 n f size{f ∈ F : r f ,g ≤ τ } (17)</formula><p>which is the probability for algorithm g ∈ G that a performance ratio r f ,g is within a factor τ ∈ R of the best possible ratio <ref type="bibr" target="#b61">[62]</ref>. Fig. <ref type="figure" target="#fig_5">4</ref> presents the performance ratios of the mean fitness value for the five algorithms on the CEC2014 test set. The results are displayed by a log scale2. From Fig. <ref type="figure" target="#fig_5">4</ref>, it is clear that MEGWO has the highest probability to be the optimal algorithm and the probability that MEGWO is the winner on a given test function is about 0.57 when τ = 0. When τ = 1 both LGWO and MEGWO are the winner on approximately 76% of the problems. Though the MEGWO obtains similar performance to LGWO when τ is in the interval <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18]</ref>, the performance curve of MEGWO lies above all the other curves and MEGWO can achieve optimality for about 97% problems when τ ≥ 18. From all above comparisons, it concludes  The parameter settings of algorithms. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm</head><formula xml:id="formula_26">N = 10, MaxDT = 100, ω i = 1.05, ω f = 0.5, C 1 = C 2 = 1.49 WOASA 2017 [61] N = 10, MaxDT = 100, l ∼ U(-1, 1), p ∼ U(0, 1), T = 20</formula><p>that MEGWO performs significantly better than that other GWO variants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3.">Comparison of MEGWO with other state-of-the-art algorithms</head><p>To further show the superiority of MEGWO, the performance of MEGWO was compared with seven state-of-the-art optimizers, such as ACS <ref type="bibr" target="#b55">[56]</ref>, MEABC <ref type="bibr" target="#b54">[55]</ref>, SinDE <ref type="bibr" target="#b56">[57]</ref>, BHS <ref type="bibr" target="#b57">[58]</ref>, DE/BBO <ref type="bibr" target="#b53">[54]</ref>, WOA <ref type="bibr" target="#b15">[16]</ref> and CLPSO-LOT <ref type="bibr" target="#b58">[59]</ref> for CEC2014 problems by the mean of fitness value and standard deviation of the solutions of objective functions. The parameter settings of all algorithms in this subsection can be found in Table <ref type="table" target="#tab_6">4</ref>. 51 independent runs were carried out for all test functions with 30 dimensions. Table <ref type="table" target="#tab_8">6</ref> presents the experimental results obtained by MEGWO and other seven algorithms. The best results are marked in bold. Please note that the results of BHS and DE/BBO are directly taken from <ref type="bibr" target="#b51">[52]</ref>. To intuitively verify the significant difference between MEGWO and other seven state-of-the-art algorithms, the paired Wilcoxon signed-rank tests were performed with a level of significance α = 0.05 in this subsection <ref type="bibr" target="#b52">[53]</ref>. The results of Wilcoxon signedrank tests of MEGWO and other seven comparison algorithms on 30-dimensional functions from CEC2014 test set are listed in Table <ref type="table">7</ref>, where R + indicates the sum of ranks for the problems in which MEGWO outperforms those algorithms for comparison and R -denotes the sum of ranks on the opposite. p-value represents something about how significant differences the result is: the smaller the p-value, the stronger the evidence. n represents the total number of test functions while w, t, and l indicate the number of MEGWO superior, inferior, or similar to the corresponding algorithm, respectively <ref type="bibr" target="#b62">[63]</ref>. As Table <ref type="table">7</ref> states, the number of functions on which MEGWO performs better than ACS, MEABC, SinDE, BHS, DE/BBO, WOA and CLPSO-LOT are 28, 26, 26, 28, 24, 29, and 21, respectively. MEGWO shows a significant improvement over ACS, BHS, and WOA with a level of significance α = 0.001, over MEABC, SinDE, DE/BBO and CLPSO-LOT with α = 0.01. It concludes that the proposed algorithm MEGWO provides very competitive results compared to other seven state-of-the-art algorithms.</p><p>It is well-known that the ability to well-balance exploration and exploitation is essential for algorithms targeting on optimization problems with different characteristics. Firstly, compared with  Given all the reasons above, the mutual cooperation among several update strategies can effectively improve the performance of GWO for various complex function optimization problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Computation complexity and time complexity analysis 4.3.1. Computation complexity analysis</head><p>Any optimization algorithms need to have low computational complexity, so that it can solve real-life optimization problems with less computational volume. In order to analyse the computational complexity of GWO and MEGWO, the step wise computational complexity in terms of worst case of computation time is calculated as follows:</p><p>In the population initialization stage, both GWO and MEGWO have computational complexity O(N).</p><p>As for the main iterative loop, in GWO, the position vector of each search agent is updated so the computational complexity is O(N • D) for this step. After updating the position of the population, the fitness values of all search agents are evaluated in O(N) time. Because both the update process and evaluation operation are terminated within the maximum number of iterations saying T , the computational complexity is multiplied by T . After summarizing all the complexities as discussed above, the total computation complexity in GWO is obtained as O(T • N • D).</p><p>In the main iterative progress of MEGWO, the enhanced globalbest lead operation randomly select one element from the solution vector for each search agent in O(1) time and update all search agents in O(N • D) time. In adaptable cooperative hunting step, the one-dimensional update operation only changes one element for each solution vector so the computational complexity is O(N) while the total-dimensional update operation has computational complexity O(N • D). Because the above two update operations conduct in an alternate-running mode, the computational complexity is still O(N •D) in terms of worst case. In the last step of the algorithm, part of search agents will be dispersed to a promising area of the search space with O(N) computational complexity. As a result, the total computation complexity in MEGWO is O(T • N • D).</p><p>Hence, from the perspective of the worst complexity, both algorithms have the same value O(T • N • D).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Time complexity analysis</head><p>According to the guidelines of IEEE CEC2014 <ref type="bibr" target="#b49">[50]</ref>, we supplemented the time complexity analysis of GWO and MEGWO. The parameters T 0 , T 1 , and T 2 are defined the same as in IEEE  T2 is the average value of five T 2 values.</p><p>The time complexities of GWO and MEGWO for 10, 30, and 50-dimensional functions are shown in Table <ref type="table" target="#tab_9">8</ref>. The computing time T2 of GWO is almost 2.3312 times of the one of MEGWO for 10-dimensional case. T2 of GWO is approximately 70.23% more than the one of MEGWO for 30-dimensional case and 52.14% more than T2 of MEGWO for 50-dimensional case. To better analyse the results, Fig. <ref type="figure" target="#fig_6">5</ref> is plotted. The figure shows that the computing complexity of GWO is obviously higher than that of MEGWO. The reason is that enhanced global-best lead strategy and adaptable cooperative hunting strategy in proposed MEGWO run alternately. This mechanism does not increase the time complexity of MEGWO in essence. On the other hand, MEGWO adopts parallel operations to evaluate the fitness value of the population while GWO utilizes serial operations. Therefore, MEGWO is superior to GWO in terms of time complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Application to feature selection</head><p>In order to validate the performance of MEGWO on real-world problems, the proposed MEGWO was applied on feature selection (FS) which is considered as a multi-objectives optimization problem. The target of FS is to find the optimal feature subsets. FS can eliminate irrelevant or redundant features, so as to reduce the number of features, improve model accuracy and reduce running time <ref type="bibr" target="#b60">[61]</ref>. The GWO was originally designed to solve problems with continuous variables. Due to the property of FS that solutions are restricted to the binary {0, 1}, the MEGWO should be developed into a binary version. Herein, Value ''1'' represents the corresponding feature is selected; otherwise the Value is set to''0''. In this paper, firstly we allow each search agent update their positions in the continuous search spaces [0, 1] to a d-dimensional candidate solution v t i , and then each element of the solution v t i is converted to the binary {0, 1} based on a hard decision operator as below. The tradeoff of FS is between minimizing the number of selected features and maximizing classification accuracy. As a result, the objective optimization function can be expressed as <ref type="bibr" target="#b63">[64]</ref>:</p><formula xml:id="formula_27">{ x t i,d = 1, v t i,d &gt; 0.5 x t i,d = 0, otherwise<label>(18)</label></formula><formula xml:id="formula_28">fitness = w 1 • r R + w 2 • (|R|/|N|) (19)</formula><p>where r R represents the classification error rate of a given classifier, |R| indicates the size of the selected features subset and |N| represents the number of the features in the dataset. w 1 and w 2 are two weighting coefficients corresponding to classification quality and subset size respectively. w 1 ∈ [0, 1] and w 2 = (1-w 1 ) are adopted in <ref type="bibr" target="#b63">[64]</ref>. In our experiments, w 1 was set to 0.99 and w 2 was set to 0.01 which are commonly used in the literature <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b19">20]</ref>.</p><p>Twelve datasets listed in Table <ref type="table" target="#tab_10">9</ref> from the UCI machine learning repository <ref type="bibr" target="#b64">[65]</ref> are performed in the experiments. These datasets have various numbers of samples, features and classifications. Each dataset was divided in a cross-validation manner <ref type="bibr" target="#b65">[66]</ref>. In K -fold cross-validation, K -1 folds are used for training, validation and the remaining folds are used for testing. The size of dataset for training, validation, and testing was equal to each other. A wrapper approach-based on the K -Nearest Neighbour (KNN) classifier (where K = 5) was used for FS <ref type="bibr" target="#b66">[67]</ref>. SRPSO <ref type="bibr" target="#b59">[60]</ref>, SinDE <ref type="bibr" target="#b56">[57]</ref>,</p><p>and WOASA <ref type="bibr" target="#b60">[61]</ref> were selected as the comparison algorithms to investigate the performance of MEGWO. For all experiments in this section, the population size for SRPSO, SinDE, and WOASA were all chosen as 10. The population size for MEGWO was set to 5. The maximum number of iterations for four algorithms was set to 100 and all algorithms ran 5 times.</p><p>Table <ref type="table" target="#tab_11">10</ref> outlines the two main objectives, classification accuracy and average selection size for FS. Observed from Table <ref type="table" target="#tab_11">10</ref>, it is evident that MEGWO is much better than SRPSO on all datasets. With respect to SinDE, MEGWO outperforms it on almost all datasets except for Waveform dataset. For waveform dataset, SinDE provides 78.98% classification accuracy by using 15 features while MEGWO renders 78.82% accuracy with 16 features. Compared with WOASA, MEGWO obtains better results on 10 datasets in terms of classification accuracy except Sonar and Waveform datasets. Meanwhile, MEGWO provides better or similar results on 11 datasets in terms of the number of selected features except for Sonar dataset.</p><p>Table <ref type="table" target="#tab_12">11</ref> shows the mean fitness values and the average computational time (/s) obtained from the four optimization algorithms. As can be seen in Table <ref type="table" target="#tab_12">11</ref>, MEGWO outperforms SRPSO, SinDE, and WOASA in terms of the mean fitness values on almost all the datasets except for Sonar and Waveform datasets. For Sonar dataset and Waveform dataset, WOASA obtained the best mean fitness values in comparison to other algorithms. With respect to the average computational time, MEGWO has the minimum computational time compared with other approaches except for Waveform dataset. For Waveform dataset, SRPSO has the minimum computational time in 64.83 s.</p><p>According to Tables <ref type="table" target="#tab_11">10</ref> and<ref type="table" target="#tab_12">11</ref>, the performance ranking of the four algorithms is shown as: SRPSO &lt; SinDE &lt; WOASA &lt; MEGWO. For Sonar and Waveform datasets which have large numbers of features or samples, WOASA can provide better results than MEGWO in terms of mean fitness values, classification accuracy and number of selected features. The reason is that the combination of WOA and Simulated Annealing (SA) allows the algorithm to explore extensively in the feature space and intensify the local search. Though the excessive execution of the embedded SA algorithm makes WOASA perform well for high dimensional optimization problems, this method consumes too many computational resources and increases time cost. In contrast, the performance results of MEGWO prove its capability to achieve a better balance between the accuracy and time complexity. The main reason is that, the one-dimensional update operation in MEGWO only changes one element of candidate solution vector in each iteration and employs the greedy selection strategy to ensure the new better solution obtained to be reserved for the next iteration. The operation can prevent the destruction of excellent solution to some extent and improve the population diversity. This characteristic allows MEGWO to work efficiently on multimodal and separable functions especially for feature selection problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and future direction</head><p>In this study, an efficient GWO-based optimizer with several different update strategies, named as MEGWO, was proposed for various complex function optimization. In MEGWO, search agents update their positions based on the cooperation among three search strategies, which improves the global and local search ability of the proposed algorithm. MEGWO not only retains the advantage of fast convergence speed and strong local search ability of GWO, but also makes full use of the characteristics of each search strategy to balance the global and local search ability. The performance of the proposed algorithm was examined on 18 test functions and IEEE CEC2014 test set. Furthermore, feature selection was employed to investigate the effectiveness of MEGWO on real world applications. The obtained results show that the modification on original GWO accelerates convergence speed, enhances searching efficiency and improves the computational precision as well. It is also proved that the proposed MEGWO is an efficient and reliable algorithm for real world optimization problems.</p><p>Although the method presented in this paper effectively enhances the performance of GWO for optimization of various complex functions, it introduces more additional parameters. The users who wish to adopt MEGWO need to train the parameters to obtain the optimal setting in advance. Therefore, parameter-free GWO or parameter self-adaptive GWO to various real-world problems will be a vital research direction in our future work. Also, to the best of our knowledge, there is little work which consider about the weighting factors of alpha, beta and delta in Eq. ( <ref type="formula" target="#formula_3">9</ref>). These factors reflect the contribution of each leader in the final solution and hence worth investigating in the future. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The leadership hierarchy of wolves and their characteristics.</figDesc><graphic coords="3,94.51,55.32,396.60,107.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The main process of MEGWO.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>2 i</head><label>2</label><figDesc>-450, z = xi |} -450, z = xo UN [-100,100]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>N = 20 ,N = 40 ,N = 40 ,N = 40 ,N = 40 ,N = 40 ,N = 40 ,N = 40 ,N = 40 ,N = 40 ,N = 40 , 30 In Section 4. 4 MEGWON = 5 ,N = 10 ,</head><label>2040404040404040404040304510</label><figDesc>MaxDT = 7500, ϕ 0 = 2, SR max = 1, SR min = 0.6,RW max = 0.4, RW min = 0, GR = 0MaxDT = 7500, a 0 = MaxDT = 7500, a 0 = MaxDT = 7500, a 0 = 2, β ∼ U(0, 2), p ∼ U(0, MaxDT = 7500, a 0 = 2 DE/BBO 2011 [54] N = 100, MaxDT = 3000, CR = 0MaxDT = 7500, C = 1MaxDT = 7500, α = 1, β = 10, γ = 1.5, pa = 0MaxDT = 7500, freq = 0MaxDT = 7500, l ∼ U(-1, 1), p ∼ U(0, MaxDT = 7500, BW max = 0.1, BW min = 0.0001, PAR max = 0.99, PAR min = 0.35, HMCR = 0MaxDT = 7500, w max = 0.9, w min = 0.4, C 1 = C 2 = 1.49445, m = 7, a = 0.2, g = MaxDT = 100, ϕ 0 = 2, SR max = 1, SR min = 0.6,RW max = 0.4, RW min = 0, GR = 0MaxDT = 100, freq = 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Performance profile of 5 algorithms on CEC2014 benchmark functions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Time complexity of GWO and MEGWO for dimensions 10, 30 and 50.</figDesc><graphic coords="12,366.66,155.37,140.87,116.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>. The pseudo code of enhanced global-best lead strategy is presented in Algorithm 2.</figDesc><table><row><cell cols="2">Algorithm 2 Enhanced global-best lead algorithm</cell><cell></cell></row><row><cell cols="2">Input: The search agent population X t , X t α , parameter ϕ and GR Output: Updated search agents population X t+1 ,</cell><cell></cell></row><row><cell cols="2">1: for i = 1 to N do</cell><cell></cell></row><row><cell>2:</cell><cell>for d = 1 to D do</cell><cell></cell></row><row><cell>3:</cell><cell>if rand 1 &lt; GR then</cell><cell></cell></row><row><cell>4:</cell><cell>Generate a random integer j rand and j rand</cell><cell>∈</cell></row><row><cell>5: 6:</cell><cell>{1, 2, . . . , D} Update X t i,d by X t+1 i,d = X t α,j rand else</cell><cell></cell></row><row><cell>7:</cell><cell>Selected two other search agents X t m and X t n</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>2, and kept the other parameters fixed for all of the test functions with 30 dimensions. Each algorithm independently ran 30 times on each test function while the mean of fitness value (Mean) and the standard deviation of fitness value (Std) are documented in Table2. The best results are marked in bold.It can be seen from Table2that the value GR = 0.8 provides a best solution compared with other choices of GR values for most of test functions. For functions f 1 , f 2 , and f 3 , when GR is set to 1, the algorithm provides the best solution which even converges to the theoretical optimal one for functions f 1 and f 2 . For function f 4 , the value of GR = 0.8 obtains the best solution. For function f 5 , the value GR = 0.4, 0.6, 0.8, and 1 provide the same results in terms of the Mean and Std. For function f 6 , all of GR values can help the algorithm to converge to the optimal solution. Since the unimodal functions f 1 to f 6 have only one global optimum, these results show that the exploitation ability of MEGWO can be improved by a large GR value. Functions f 7 to f 12 are multimodal test functions and appropriate to validate the exploration ability of different algorithms. Based</figDesc><table /><note><p><p><p>on Table</p>2</p>, GR = 0.8 provides best results compared with other GR values for functions f 7 to f 12 , which concludes that MEGWO with GR = 0.8 obtains best global convergence performance. For shifted functions f 13 to f 16 , GR = 0.8 also provides very competitive solutions compared to other GR values in terms of Mean and Std. Therefore, considering the balance between exploration and exploitation in the enhanced global-best lead phase, we conclude that setting GR as 0.8 is an appropriate choice.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1</head><label>1</label><figDesc>Test functions used in the experiments.</figDesc><table><row><cell>Name</cell><cell>Function</cell><cell>C</cell><cell>Range</cell><cell>Fmin</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc>Experimental results of MEGWO using different GR values for 18 test functions (D = 30).</figDesc><table><row><cell>Fun</cell><cell></cell><cell>GR = 0</cell><cell>GR = 0.2</cell><cell>GR = 0.4</cell><cell>GR = 0.6</cell><cell>GR = 0.8</cell><cell>GR = 1</cell></row><row><cell>f 1</cell><cell>Mean Std</cell><cell>2.08E-59 1.51E-59</cell><cell>1.42E-132 2.45E-132</cell><cell>1.18E-174 0.00E+00</cell><cell>1.13E-215 0.00E+00</cell><cell>4.30E-296 0.00E+00</cell><cell>0.00E+00 0.00E+00</cell></row><row><cell>f 2</cell><cell>Mean Std</cell><cell>2.65E-36 3.28E-36</cell><cell>8.91E-82 1.39E-81</cell><cell>6.01E-106 5.54E-106</cell><cell>3.84E-135 6.23E-135</cell><cell>2.14E-193 0.00E+00</cell><cell>0.00E+00 0.00E+00</cell></row><row><cell>f 3</cell><cell>Mean Std</cell><cell>4.95E-03 3.98E-03</cell><cell>2.51E-03 8.59E-04</cell><cell>1.84E-03 1.13E-03</cell><cell>8.17E-04 4.80E-04</cell><cell>6.20E-04 1.58E-04</cell><cell>4.52E-04 1.12E-04</cell></row><row><cell>f 4</cell><cell>Mean Std</cell><cell>1.57E+01 1.34E+00</cell><cell>1.63E+01 4.94E-01</cell><cell>1.62E+01 5.67E-01</cell><cell>1.56E+01 6.38E-01</cell><cell>1.01E+01 2.80E-01</cell><cell>1.02E+01 8.81E-00</cell></row><row><cell>f 5</cell><cell>Mean Std</cell><cell>1.97E+02 1.37E+02</cell><cell>-6.06E-12 1.05E-12</cell><cell>-1.82E-12 0.00E+00</cell><cell>-1.82E-12 0.00E+00</cell><cell>-1.82E-12 0.00E+00</cell><cell>-1.82E-12 0.00E+00</cell></row><row><cell>f 6</cell><cell>Mean Std</cell><cell>0.00E+00 0.00E+00</cell><cell>0.00E+00 0.00E+00</cell><cell>0.00E+00 0.00E+00</cell><cell>0.00E+00 0.00E+00</cell><cell>0.00E+00 0.00E+00</cell><cell>0.00E+00 0.00E+00</cell></row><row><cell>f 7</cell><cell>Mean Std</cell><cell>1.10E-14 4.10E-15</cell><cell>5.03E-15 2.05E-15</cell><cell>2.73E-15 0.00E+00</cell><cell>2.73E-15 2.05E-15</cell><cell>2.66E-15 0.00E+00</cell><cell>1.45E-14 1.03E-14</cell></row><row><cell>f 8</cell><cell>Mean Std</cell><cell>6.63E-01 5.74E-01</cell><cell>0.00E+00 0.00E+00</cell><cell>0.00E+00 0.00E+00</cell><cell>0.00E+00 0.00E+00</cell><cell>0.00E+00 0.00E+00</cell><cell>0.00E+00 0.00E+00</cell></row><row><cell>f 9</cell><cell>Mean Std</cell><cell>0.00E+00 0.00E+00</cell><cell>0.00E+00 0.00E+00</cell><cell>0.00E+00 0.00E+00</cell><cell>0.00E+00 0.00E+00</cell><cell>0.00E+00 0.00E+00</cell><cell>0.00E+00 0.00E+00</cell></row><row><cell>f 10</cell><cell>Mean Std</cell><cell>5.73E-17 5.54E-17</cell><cell>3.77E-30 3.38E-30</cell><cell>1.50E-32 0.00E+00</cell><cell>1.50E-32 0.00E+00</cell><cell>1.50E-32 0.00E+00</cell><cell>2.01E-15 3.47E-15</cell></row><row><cell>f 11</cell><cell>Mean Std</cell><cell>6.36E-19 4.28E-19</cell><cell>1.70E-32 1.29E-33</cell><cell>1.57E-32 0.00E+00</cell><cell>1.57E-32 0.00E+00</cell><cell>1.57E-32 0.00E+00</cell><cell>1.41E-20 2.44E-20</cell></row><row><cell>f 12</cell><cell>Mean Std</cell><cell>2.85E-17 3.07E-17</cell><cell>7.97E-29 1.37E-28</cell><cell>1.35E-32 0.00E+00</cell><cell>1.35E-32 0.00E+00</cell><cell>1.35E-32 0.00E+00</cell><cell>1.46E-12 2.52E-12</cell></row><row><cell>f 13</cell><cell>Mean Std</cell><cell>-4.50E+02 1.33E-08</cell><cell>-4.50E+02 1.64E-09</cell><cell>-4.50E+02 2.02E-08</cell><cell>-4.50E+02 2.68E-08</cell><cell>-4.50E+02 1.13E-09</cell><cell>-4.50E+02 6.61E-09</cell></row><row><cell>f 14</cell><cell>Mean Std</cell><cell>-4.49E+02 5.54E-02</cell><cell>-4.49E+02 3.29E-01</cell><cell>-4.49E+02 4.65E-01</cell><cell>-4.49E+02 2.93E-01</cell><cell>-4.50E+02 2.89E-02</cell><cell>-4.49E+02 1.92E-01</cell></row><row><cell>f 15</cell><cell>Mean Std</cell><cell>-1.80E+02 4.27E-03</cell><cell>-1.80E+02 1.66E-05</cell><cell>-1.80E+02 1.12E-05</cell><cell>-1.80E+02 9.54E-05</cell><cell>-1.80E+02 2.19E-06</cell><cell>-1.80E+02 2.62E-05</cell></row><row><cell>f 16</cell><cell>Mean Std</cell><cell>-1.39E+02 1.01E-04</cell><cell>-1.40E+02 7.25E-06</cell><cell>-1.40E+02 1.44E-05</cell><cell>-1.40E+02 4.44E-05</cell><cell>-1.40E+02 4.36E-06</cell><cell>-1.40E+02 5.56E-06</cell></row><row><cell>f 17</cell><cell>Mean Std</cell><cell>-3.29E+02 5.74E-01</cell><cell>-3.29E+02 1.15E+00</cell><cell>-3.30E+02 2.47E-02</cell><cell>-3.30E+02 2.54E-01</cell><cell>-3.30E+02 5.76E-03</cell><cell>-3.29E+02 1.15E+00</cell></row><row><cell>f 18</cell><cell>Mean Std</cell><cell>4.65E+02 3.85E+01</cell><cell>4.68E+02 3.38E+01</cell><cell>4.65E+02 3.32E+01</cell><cell>4.74E+02 3.67E+01</cell><cell>4.49E+02 2.14E+01</cell><cell>4.80E+02 4.94E+01</cell></row></table><note><p>Fig. 3. Convergence curves on 50-dimensional test functions f 1 , f 4 , f 11 , and f 14 of 5 algorithms.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc>Experimental results of GWO, MEGWO1, MEGWO2, MEGWO3, MEGWO on 18 functions (D = 50).</figDesc><table><row><cell>Fun</cell><cell>Index</cell><cell>GWO</cell><cell></cell><cell>MEGWO1</cell><cell></cell><cell>MEGWO2</cell><cell></cell><cell>MEGWO3</cell><cell></cell><cell>MEGWO</cell></row><row><cell>f 1</cell><cell>Mean Std</cell><cell>2.62E-141 2.70E-141</cell><cell>+</cell><cell>6.50E-50 1.04E-49</cell><cell>+</cell><cell>2.22E-322 0.00E+00</cell><cell>+</cell><cell>6.26E-227 0.00E+00</cell><cell>+</cell><cell>0.00E+00 0.00E+00</cell></row><row><cell>f 2</cell><cell>Mean Std</cell><cell>1.21E-82 9.16E-83</cell><cell>+</cell><cell>3.43E-30 6.02E-30</cell><cell>+</cell><cell>9.83E-280 0.00E+00</cell><cell>-</cell><cell>1.62E-195 0.00E+00</cell><cell>+</cell><cell>9.72E-245 0.00E+00</cell></row><row><cell>f 3</cell><cell>Mean Std</cell><cell>6.11E-04 3.96E-04</cell><cell>+</cell><cell>4.60E-03 1.20E-03</cell><cell>+</cell><cell>4.18E-04 2.36E-04</cell><cell>-</cell><cell>1.30E-03 7.84E-04</cell><cell>+</cell><cell>5.13E-04 2.93E-04</cell></row><row><cell>f 4</cell><cell>Mean Std</cell><cell>4.71E+01 9.68E+01</cell><cell>+</cell><cell>3.56E+01 4.08E+01</cell><cell>+</cell><cell>2.80E+01 1.93E+01</cell><cell>+</cell><cell>2.27E+01 2.39E+01</cell><cell>+</cell><cell>1.11E+01 1.79E+01</cell></row><row><cell>f 5</cell><cell>Mean Std</cell><cell>1.19E+04 6.98E+02</cell><cell>+</cell><cell>3.55E+01 5.72E+01</cell><cell>+</cell><cell>1.46E-11 0.00E+00</cell><cell>≈</cell><cell>2.30E-10 6.11E-10</cell><cell>+</cell><cell>1.46E-11 0.00E+00</cell></row><row><cell>f 6</cell><cell>Mean Std</cell><cell>0.00E+00 0.00E+00</cell><cell>≈</cell><cell>0.00E+00 0.00E+00</cell><cell>≈</cell><cell>0.00E+00 0.00E+00</cell><cell>≈</cell><cell>0.00E+00 0.00E+00</cell><cell>≈</cell><cell>0.00E+00 0.00E+00</cell></row><row><cell>f 7</cell><cell>Mean Std</cell><cell>1.12E-14 3.00E-15</cell><cell>+</cell><cell>2.90E-14 5.35E-15</cell><cell>+</cell><cell>3.02E-15 1.12E-15</cell><cell>-</cell><cell>9.77E-15 5.80E-15</cell><cell>+</cell><cell>4.09E-15 1.83E-15</cell></row><row><cell>f 8</cell><cell>Mean Std</cell><cell>0.00E+00 0.00E+00</cell><cell>≈</cell><cell>3.55E-16 1.12E-15</cell><cell>+</cell><cell>0.00E+00 0.00E+00</cell><cell>≈</cell><cell>0.00E+00 0.00E+00</cell><cell>≈</cell><cell>0.00E+00 0.00E+00</cell></row><row><cell>f 9</cell><cell>Mean Std</cell><cell>0.00E+00 0.00E+00</cell><cell>≈</cell><cell>0.00E+00 0.00E+00</cell><cell>≈</cell><cell>0.00E+00 0.00E+00</cell><cell>≈</cell><cell>0.00E+00 0.00E+00</cell><cell>≈</cell><cell>0.00E+00 0.00E+00</cell></row><row><cell>f 10</cell><cell>Mean Std</cell><cell>5.36E+00 9.97E-01</cell><cell>+</cell><cell>3.61E-11 2.71E-11</cell><cell>+</cell><cell>1.50E-32 0.00E+00</cell><cell>≈</cell><cell>3.63E-01 8.03E-01</cell><cell>+</cell><cell>1.50E-32 0.00E+00</cell></row><row><cell>f 11</cell><cell>Mean Std</cell><cell>1.79E-01 5.80E-02</cell><cell>+</cell><cell>6.07E-13 3.46E-13</cell><cell>+</cell><cell>1.57E-32 2.89E-48</cell><cell>≈</cell><cell>5.25E-15 1.34E-14</cell><cell>+</cell><cell>1.57E-32 2.89E-48</cell></row><row><cell>f 12</cell><cell>Mean Std</cell><cell>1.90E+00 4.55E-01</cell><cell>+</cell><cell>1.18E-11 9.77E-12</cell><cell>+</cell><cell>1.35E-32 2.89E-48</cell><cell>≈</cell><cell>7.06E-20 2.23E-19</cell><cell>+</cell><cell>1.35E-32 2.89E-48</cell></row><row><cell>f 13</cell><cell>Mean Std</cell><cell>1.15E+04 5.48E+03</cell><cell>+</cell><cell>-4.50E+02 5.29E-08</cell><cell>≈</cell><cell>-4.50E+02 4.01E-07</cell><cell>≈</cell><cell>-4.49E+02 2.85E-01</cell><cell>+</cell><cell>-4.50E+02 1.75E-09</cell></row><row><cell>f 14</cell><cell>Mean Std</cell><cell>-4.03E+02 5.04E+00</cell><cell>+</cell><cell>-4.45E+02 1.49E+00</cell><cell>+</cell><cell>-4.42E+02 3.13E+00</cell><cell>+</cell><cell>-4.40E+02 1.33E+00</cell><cell>+</cell><cell>-4.46E+02 1.01E+00</cell></row><row><cell>f 15</cell><cell>Mean Std</cell><cell>-6.39E+01 5.07E+01</cell><cell>+</cell><cell>-1.80E+02 3.18E-05</cell><cell>≈</cell><cell>-1.80E+02 1.90E-03</cell><cell>≈</cell><cell>-1.79E+02 7.10E-02</cell><cell>+</cell><cell>-1.80E+02 2.88E-06</cell></row><row><cell>f 16</cell><cell>Mean Std</cell><cell>-1.26E+02 2.11E+00</cell><cell>+</cell><cell>-1.40E+02 8.62E-05</cell><cell>≈</cell><cell>-1.40E+02 5.18E-01</cell><cell>≈</cell><cell>-1.40E+02 6.64E-02</cell><cell>≈</cell><cell>-1.40E+02 1.99E-06</cell></row><row><cell>f 17</cell><cell>Mean Std</cell><cell>-7.44E+01 2.99E+01</cell><cell>+</cell><cell>-3.30E+02 4.81E-01</cell><cell>-</cell><cell>-2.30E+02 1.47E+01</cell><cell>+</cell><cell>-3.28E+02 8.42E-01</cell><cell>+</cell><cell>-3.29E+02 8.48E-01</cell></row><row><cell>f 18</cell><cell>Mean Std</cell><cell>1.10E+09 8.26E+08</cell><cell>+</cell><cell>5.07E+02 3.71E+01</cell><cell>-</cell><cell>5.64E+02 9.16E+01</cell><cell>+</cell><cell>1.18E+03 1.20E+02</cell><cell>+</cell><cell>5.26E+02 4.19E+01</cell></row><row><cell cols="2">+/-/≈</cell><cell>15/0/3</cell><cell></cell><cell>11/2/5</cell><cell></cell><cell>5/3/10</cell><cell></cell><cell>14/0/4</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc>Experimental results of GWO, EPDGWO, LGWO, RWGWO, and MEGWO for CEC2014 (D = 30).</figDesc><table><row><cell>Fun</cell><cell>Index</cell><cell>GWO</cell><cell></cell><cell>EPDGWO</cell><cell></cell><cell>LGWO</cell><cell></cell><cell>RWGWO</cell><cell></cell><cell>MEGWO</cell></row><row><cell>f 1</cell><cell>Mean Std</cell><cell>3.32E+07 2.02E+07</cell><cell>+</cell><cell>7.91E+07 2.05E+07</cell><cell>+</cell><cell>5.24E+00 3.85E+00</cell><cell>-</cell><cell>8.02E+06 3.31E+06</cell><cell>+</cell><cell>1.50E+06 3.13E+05</cell></row><row><cell>f 2</cell><cell>Mean Std</cell><cell>1.01E+09 1.15E+09</cell><cell>+</cell><cell>4.54E+09 7.03E+08</cell><cell>+</cell><cell>0.00E+00 0.00E+00</cell><cell>≈</cell><cell>2.23E+05 5.51E+05</cell><cell>+</cell><cell>0.00E+00 0.00E+00</cell></row><row><cell>f 3</cell><cell>Mean Std</cell><cell>2.85E+04 6.80E+03</cell><cell>+</cell><cell>1.74E+04 3.77E+03</cell><cell>+</cell><cell>1.41E+ 01 2.24E-02</cell><cell>+</cell><cell>3.16E+02 4.34E+02</cell><cell>+</cell><cell>0.00E+00 0.00E+00</cell></row><row><cell>f 4</cell><cell>Mean Std</cell><cell>1.94E+02 5.82E+01</cell><cell>+</cell><cell>3.53E+02 4.78E+01</cell><cell>+</cell><cell>3.46E+01 1.54E+01</cell><cell>+</cell><cell>3.41E+01 1.80E+01</cell><cell>+</cell><cell>1.46E+01 1.06E+01</cell></row><row><cell>f 5</cell><cell>Mean Std</cell><cell>2.10E+01 4.83E+ 02</cell><cell>+</cell><cell>2.09E+01 4.62E+ 02</cell><cell>+</cell><cell>2.06E+01 3.11E+ 02</cell><cell>+</cell><cell>2.05E+01 7.46E+ 02</cell><cell>+</cell><cell>2.02E+01 2.20E+ 02</cell></row><row><cell>f 6</cell><cell>Mean Std</cell><cell>1.16E+01 2.64E+00</cell><cell>+</cell><cell>2.42E+01 1.81E+00</cell><cell>+</cell><cell>9.72E+00 3.41E+00</cell><cell>-</cell><cell>9.84E+00 3.49E+00</cell><cell>-</cell><cell>1.12E+01 4.30E+00</cell></row><row><cell>f 7</cell><cell>Mean Std</cell><cell>7.67E+00 4.64E+00</cell><cell>+</cell><cell>4.19E+01 7.57E+00</cell><cell>+</cell><cell>0.00E+00 0.00E+00</cell><cell>-</cell><cell>2.53E-01 1.43E-01</cell><cell>+</cell><cell>4.88E-05 8.06E-05</cell></row><row><cell>f 8</cell><cell>Mean Std</cell><cell>6.50E+01 1.45E+01</cell><cell>+</cell><cell>1.64E+02 1.79E+01</cell><cell>+</cell><cell>2.90E+01 2.64E+01</cell><cell>+</cell><cell>4.38E+01 8.48E+00</cell><cell>+</cell><cell>0.00E+00 0.00E+00</cell></row><row><cell>f 9</cell><cell>Mean Std</cell><cell>8.54E+01 3.30E+01</cell><cell>+</cell><cell>2.18E+02 1.70E+01</cell><cell>+</cell><cell>8.14E+01 3.16E-01</cell><cell>+</cell><cell>6.33E+01 1.30E+01</cell><cell>+</cell><cell>5.90E+01 8.59E-02</cell></row><row><cell>f 10</cell><cell>Mean Std</cell><cell>1.80E+03 4.93E+02</cell><cell>+</cell><cell>5.65E+03 6.35E+02</cell><cell>+</cell><cell>2.00E+03 4.52E+02</cell><cell>+</cell><cell>9.61E+02 2.72E+02</cell><cell>+</cell><cell>3.25E+00 1.16E+00</cell></row><row><cell>f 11</cell><cell>Mean Std</cell><cell>2.90E+03 7.24E+02</cell><cell>+</cell><cell>6.88E+03 3.58E+02</cell><cell>+</cell><cell>2.00E+03 6.41E+00</cell><cell>+</cell><cell>2.68E+03 3.68E+02</cell><cell>+</cell><cell>1.70E+03 2.94E+00</cell></row><row><cell>f 12</cell><cell>Mean Std</cell><cell>2.12E+00 9.58E-01</cell><cell>+</cell><cell>2.53E+00 2.86E-01</cell><cell>+</cell><cell>9.28E-02 2.98E-01</cell><cell>-</cell><cell>5.45E-01 1.66E-01</cell><cell>+</cell><cell>2.36E-01 4.50E-01</cell></row><row><cell>f 13</cell><cell>Mean Std</cell><cell>3.74E-01 8.88E-02</cell><cell>+</cell><cell>9.10E-01 1.38E-01</cell><cell>+</cell><cell>3.89E-01 2.44E-02</cell><cell>+</cell><cell>2.80E-01 6.30E-02</cell><cell>+</cell><cell>2.39E-01 1.68E-02</cell></row><row><cell>f 14</cell><cell>Mean Std</cell><cell>7.49E-01 1.40E+00</cell><cell>+</cell><cell>1.14E+01 2.94E+00</cell><cell>+</cell><cell>4.29E-01 3.72E-02</cell><cell>+</cell><cell>4.23E-01 2.15E-01</cell><cell>+</cell><cell>2.32E-01 2.14E-02</cell></row><row><cell>f 15</cell><cell>Mean Std</cell><cell>2.06E+01 2.20E+01</cell><cell>+</cell><cell>8.43E+01 5.29E+01</cell><cell>+</cell><cell>7.52E+00 4.09E+00</cell><cell>+</cell><cell>8.81E+00 1.51E+00</cell><cell>+</cell><cell>5.76E+00 6.04E-01</cell></row><row><cell>f 16</cell><cell>Mean Std</cell><cell>1.09E+01 5.80E-01</cell><cell>+</cell><cell>1.26E+01 3.15E-01</cell><cell>+</cell><cell>1.06E+01 2.14E-02</cell><cell>+</cell><cell>1.03E+01 6.11E-01</cell><cell>+</cell><cell>9.15E+00 2.01E-02</cell></row><row><cell>f 17</cell><cell>Mean Std</cell><cell>6.28E+05 6.11E+05</cell><cell>+</cell><cell>2.40E+06 1.13E+06</cell><cell>+</cell><cell>1.64E+03 6.99E+02</cell><cell>-</cell><cell>5.71E+05 4.10E+05</cell><cell>+</cell><cell>2.57E+04 1.29E+04</cell></row><row><cell>f 18</cell><cell>Mean Std</cell><cell>5.27E+06 1.34E+07</cell><cell>+</cell><cell>4.64E+07 2.22E+07</cell><cell>+</cell><cell>1.14E+03 2.90E+01</cell><cell>+</cell><cell>6.52E+03 4.62E+03</cell><cell>+</cell><cell>4.49E+01 1.10E+01</cell></row><row><cell>f 19</cell><cell>Mean Std</cell><cell>2.56E+01 1.77E+01</cell><cell>+</cell><cell>3.54E+01 5.31E+00</cell><cell>+</cell><cell>9.84E+00 1.99E-02</cell><cell>+</cell><cell>1.14E+01 2.03E+00</cell><cell>+</cell><cell>5.82E+00 1.33E-02</cell></row><row><cell>f 20</cell><cell>Mean Std</cell><cell>1.31E+04 5.26E+03</cell><cell>+</cell><cell>4.00E+03 1.92E+03</cell><cell>+</cell><cell>8.17E+01 4.71E+01</cell><cell>+</cell><cell>6.27E+02 1.12E+03</cell><cell>+</cell><cell>3.27E+01 9.40E+00</cell></row><row><cell>f 21</cell><cell>Mean Std</cell><cell>4.97E+05 1.05E+06</cell><cell>+</cell><cell>7.31E+05 3.74E+05</cell><cell>+</cell><cell>1.54E+03 2.07E+03</cell><cell>+</cell><cell>2.58E+05 1.76E+05</cell><cell>+</cell><cell>8.28E+02 2.76E+02</cell></row><row><cell>f 22</cell><cell>Mean Std</cell><cell>2.50E+02 1.16E+02</cell><cell>+</cell><cell>5.59E+02 1.36E+02</cell><cell>+</cell><cell>2.42E+02 2.37E+01</cell><cell>+</cell><cell>2.08E+02 1.29E+02</cell><cell>+</cell><cell>1.83E+02 1.53E+01</cell></row><row><cell>f 23</cell><cell>Mean Std</cell><cell>3.28E+02 4.16E+00</cell><cell>+</cell><cell>3.35E+02 4.73E+00</cell><cell>+</cell><cell>2.00E+02 2.86E-01</cell><cell>-</cell><cell>3.15E+02 2.77E-01</cell><cell>+</cell><cell>3.15E+02 3.96E-01</cell></row><row><cell>f 24</cell><cell>Mean Std</cell><cell>2.00E+02 7.27E-04</cell><cell>-</cell><cell>2.00E+02 1.45E-03</cell><cell>-</cell><cell>2.00E+02 2.18E-05</cell><cell>-</cell><cell>2.00E+02 3.04E-03</cell><cell>-</cell><cell>2.17E+02 6.46E-01</cell></row><row><cell>f 25</cell><cell>Mean Std</cell><cell>2.11E+02 2.04E+00</cell><cell>+</cell><cell>2.12E+02 4.77E+00</cell><cell>+</cell><cell>2.00E+02 3.98E-03</cell><cell>-</cell><cell>2.04E+02 1.18E+00</cell><cell>+</cell><cell>2.01E+02 7.96E-01</cell></row><row><cell>f 26</cell><cell>Mean Std</cell><cell>1.00E+02 9.62E-02</cell><cell>≈</cell><cell>1.01E+02 1.28E-01</cell><cell>+</cell><cell>1.00E+02 4.00E-02</cell><cell>≈</cell><cell>1.00E+02 7.36E-02</cell><cell>≈</cell><cell>1.00E+02 2.61E-02</cell></row><row><cell>f 27</cell><cell>Mean Std</cell><cell>4.33E+02 1.82E+01</cell><cell>+</cell><cell>8.73E+02 1.66E+02</cell><cell>+</cell><cell>3.99E+02 1.00E+00</cell><cell>-</cell><cell>4.09E+02 6.09E+00</cell><cell>+</cell><cell>4.06E+02 1.85E+00</cell></row><row><cell>f 28</cell><cell>Mean Std</cell><cell>9.14E+02 6.63E+01</cell><cell>+</cell><cell>1.21E+03 1.43E+02</cell><cell>+</cell><cell>2.04E+02 1.86E-02</cell><cell>-</cell><cell>4.34E+02 8.45E+00</cell><cell>+</cell><cell>8.88E+02 3.32E+01</cell></row><row><cell>f 29</cell><cell>Mean Std</cell><cell>2.90E+05 1.57E+06</cell><cell>+</cell><cell>1.35E+06 2.53E+06</cell><cell>+</cell><cell>2.47E+02 2.19E+01</cell><cell>-</cell><cell>2.14E+02 2.37E+00</cell><cell>-</cell><cell>9.37E+02 4.67E+00</cell></row><row><cell>f 30</cell><cell>Mean Std</cell><cell>2.98E+04 1.57E+04</cell><cell>+</cell><cell>4.21E+04 1.38E+04</cell><cell>+</cell><cell>3.02E+04 5.19E+02</cell><cell>+</cell><cell>6.69E+02 2.14E+02</cell><cell>-</cell><cell>1.36E+03 2.48E+02</cell></row><row><cell>+/-/≈</cell><cell></cell><cell>28/1/1</cell><cell></cell><cell>29/1/0</cell><cell></cell><cell>17 /11 /2</cell><cell></cell><cell>25 /4 /1</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6</head><label>6</label><figDesc>Experimental results of MEGWO and other seven state-of-the-art algorithms for CEC2014 (D = 30).</figDesc><table><row><cell>Fun</cell><cell>Index</cell><cell>ACS</cell><cell>MEABC</cell><cell>SinDE</cell><cell></cell><cell>BHS</cell><cell>DE/BBO</cell><cell>WOA</cell><cell>CLPSO-LOT</cell><cell>MEGWO</cell></row><row><cell>f 1</cell><cell>Mean Std</cell><cell>2.24E+06 6.14E+05</cell><cell>9.09E+06 3.38E+06</cell><cell cols="2">6.27E+06 3.78E+06</cell><cell>9.33E+06 6.93E+06</cell><cell>9.80E+06 2.66E+06</cell><cell>1.44E+07 6.73E+06</cell><cell>3.12E+05 7.07E+04</cell><cell>1.50E+06 3.13E+05</cell></row><row><cell>f 2</cell><cell>Mean Std</cell><cell>1.00E+10 0.00E+00</cell><cell>1.93E+02 3.75E+02</cell><cell cols="2">4.98E+01 2.55E+02</cell><cell>1.09E+04 8.76E+03</cell><cell>3.69E+01 1.11E+02</cell><cell>1.33E+05 4.26E+04</cell><cell>1.68E+02 2.61E+02</cell><cell>0.00E+00 0.00E+00</cell></row><row><cell>f 3</cell><cell>Mean Std</cell><cell>2.19E-04 1.20E-04</cell><cell>9.73E+02 7.45E+02</cell><cell cols="2">5.27E+00 2.48E+01</cell><cell>1.26E+04 1.05E+04</cell><cell>5.86E-01 1.08E+00</cell><cell>1.71E+04 1.42E+04</cell><cell>5.14E+01 7.24E+01</cell><cell>0.00E+00 0.00E+00</cell></row><row><cell>f 4</cell><cell>Mean Std</cell><cell>3.98E+01 3.41E+01</cell><cell>1.92E+01 2.56E+01</cell><cell cols="2">4.82E+00 1.02E+01</cell><cell>1.16E+02 3.28E+01</cell><cell>6.21E+01 1.91E+01</cell><cell>1.58E+02 4.04E+01</cell><cell>6.07E+01 3.08E+01</cell><cell>1.46E+01 1.06E+01</cell></row><row><cell>f 5</cell><cell>Mean Std</cell><cell>2.02E+01 8.17E-02</cell><cell>2.02E+01 2.52E-02</cell><cell cols="2">2.09E+01 5.56E-02</cell><cell>2.06E+01 3.04E-01</cell><cell>2.04E+01 3.82E-02</cell><cell>2.03E+01 1.92E-01</cell><cell>2.03E+01 1.49E-01</cell><cell>2.02E+01 2.20E-02</cell></row><row><cell>f 6</cell><cell>Mean Std</cell><cell>2.48E+01 2.21E+00</cell><cell>1.39E+01 1.47E+00</cell><cell cols="2">8.81E-02 2.63E-01</cell><cell>1.48E+01 2.31E+00</cell><cell>6.32E+00 6.03E+00</cell><cell>3.39E+01 3.64E+00</cell><cell>8.00E+00 1.09E+00</cell><cell>1.12E+01 1.30E+00</cell></row><row><cell>f 7</cell><cell>Mean Std</cell><cell>8.75E-06 2.23E-05</cell><cell>3.90E-06 1.25E-05</cell><cell cols="2">1.16E-03 2.97E-03</cell><cell>2.48E-02 4.37E-02</cell><cell>5.13E-14 5.71E-14</cell><cell>4.51E-01 1.10E-01</cell><cell>1.55E-16 7.93E-17</cell><cell>4.88E-05 8.06E-05</cell></row><row><cell>f 8</cell><cell>Mean Std</cell><cell>5.61E+01 1.01E+01</cell><cell>0.00E+00 0.00E+00</cell><cell cols="2">2.22E+01 1.96E+01</cell><cell>4.26E-10 4.03E-11</cell><cell>4.46E-14 5.61E-14</cell><cell>1.78E+02 2.67E+01</cell><cell>5.71E+01 1.22E+01</cell><cell>0.00E+00 0.00E+00</cell></row><row><cell>f 9</cell><cell>Mean Std</cell><cell>1.08E+02 1.82E+01</cell><cell>5.20E+01 8.32E-02</cell><cell cols="2">1.54E+02 1.40E+01</cell><cell>6.14E+01 1.36E+01</cell><cell>6.23E+01 6.77E+00</cell><cell>2.35E+02 5.17E+01</cell><cell>6.75E+01 1.47E+01</cell><cell>5.90E+01 8.59E-02</cell></row><row><cell>f 10</cell><cell>Mean Std</cell><cell>2.47E+03 4.48E+02</cell><cell>6.00E-01 7.77E-01</cell><cell cols="2">4.88E+02 4.57E+02</cell><cell>1.01E-01 4.24E-02</cell><cell>1.27E+01 3.11E+00</cell><cell>3.77E+03 8.32E+02</cell><cell>4.69E+02 1.95E+02</cell><cell>3.25E+00 1.16E+00</cell></row><row><cell>f 11</cell><cell>Mean Std</cell><cell>3.59E+03 3.64E+02</cell><cell>1.78E+03 2.39E+02</cell><cell cols="2">6.26E+03 3.16E+02</cell><cell>1.91E+03 4.15E+02</cell><cell>3.07E+03 3.01E+00</cell><cell>4.63E+03 9.85E+02</cell><cell>2.16E+02 2.23E+00</cell><cell>1.70E+03 2.94E+00</cell></row><row><cell>f 12</cell><cell>Mean Std</cell><cell>1.00E+00 1.25E-01</cell><cell>1.59E-01 2.53E-02</cell><cell cols="2">1.95E+00 2.61E-01</cell><cell>1.22E-01 1.98E-02</cell><cell>5.98E-01 7.57E-02</cell><cell>1.54E+00 4.70E-01</cell><cell>1.51E-01 4.08E-02</cell><cell>2.36E-01 4.50E-01</cell></row><row><cell>f 13</cell><cell>Mean Std</cell><cell>3.26E-01 4.53E-02</cell><cell>2.66E-01 3.88E-02</cell><cell cols="2">2.85E-01 3.86E-02</cell><cell>3.95E-01 8.61E-02</cell><cell>3.18E-01 3.36E-02</cell><cell>5.21E-01 9.74E-02</cell><cell>3.24E-01 6.41E-02</cell><cell>2.39E-01 1.68E-02</cell></row><row><cell>f 14</cell><cell>Mean Std</cell><cell>2.46E-01 3.06E-02</cell><cell>2.32E-01 2.69E-02</cell><cell cols="2">2.50E-01 4.06E-02</cell><cell>2.88E-01 5.45E-02</cell><cell>2.59E-01 2.21E-02</cell><cell>2.61E-01 6.14E-02</cell><cell>2.17E-01 2.08E-02</cell><cell>2.32E-01 2.14E-02</cell></row><row><cell>f 15</cell><cell>Mean Std</cell><cell>1.33E+01 1.95E+00</cell><cell>6.48E+00 8.37E-01</cell><cell cols="2">1.49E+01 7.86E-01</cell><cell>2.45E+01 1.33E+01</cell><cell>7.50E+00 8.46E-01</cell><cell>6.45E+01 2.28E+01</cell><cell>4.26E+00 1.36E-01</cell><cell>5.76E+00 6.04E-01</cell></row><row><cell>f 16</cell><cell>Mean Std</cell><cell>1.25E+01 2.68E-01</cell><cell>9.84E+00 4.32E-01</cell><cell cols="2">1.20E+01 2.56E-01</cell><cell>9.15E+00 8.2E-01</cell><cell>1.02E+01 3.21E-01</cell><cell>1.23E+01 5.53E-01</cell><cell>1.10E+01 7.82E-01</cell><cell>9.15E+00 2.01E-01</cell></row><row><cell>f 17</cell><cell>Mean Std</cell><cell>4.10E+03 5.98E+02</cell><cell>3.11E+06 1.38E+06</cell><cell cols="2">1.59E+05 1.28E+05</cell><cell>1.44E+06 1.05E+06</cell><cell>7.26E+05 3.18E+05</cell><cell>2.06E+06 1.60E+06</cell><cell>3.01E+04 2.06E+04</cell><cell>2.57E+04 1.29E+04</cell></row><row><cell>f 18</cell><cell>Mean Std</cell><cell>1.56E+02 2.12E+01</cell><cell>1.63E+03 1.72E+03</cell><cell cols="2">4.85E+02 8.04E+02</cell><cell>1.81E+03 2.08E+03</cell><cell>1.30E+03 1.31E+03</cell><cell>4.58E+03 5.42E+03</cell><cell>2.90E+03 2.47E+03</cell><cell>4.49E+01 1.10E+01</cell></row><row><cell>f 19</cell><cell>Mean Std</cell><cell>7.92E+00 6.51E-01</cell><cell>6.78E+00 7.45E-01</cell><cell cols="2">6.28E+00 8.21E+00</cell><cell>1.60E+01 2.63E+01</cell><cell>4.73E+00 3.84E-01</cell><cell>4.34E+01 3.56E+01</cell><cell>7.94E+00 1.03E+00</cell><cell>5.82E+00 8.33E-01</cell></row><row><cell>f 20</cell><cell>Mean Std</cell><cell>6.27E+01 9.87E+00</cell><cell>9.04E+03 5.77E+03</cell><cell cols="2">1.30E+02 1.18E+02</cell><cell>1.29E+04 8.13E+03</cell><cell>9.82E+02 3.95E+02</cell><cell>8.14E+03 5.98E+03</cell><cell>2.38E+02 4.84E+01</cell><cell>3.27E+01 9.40E+00</cell></row><row><cell>f 21</cell><cell>Mean Std</cell><cell>1.36E+03 3.04E+02</cell><cell>3.02E+05 1.20E+05</cell><cell cols="2">1.12E+04 1.17E+04</cell><cell>2.94E+05 2.26E+05</cell><cell>1.20E+05 6.11E+04</cell><cell>1.06E+06 6.84E+05</cell><cell>5.54E+04 3.37E+04</cell><cell>8.28E+02 2.76E+02</cell></row><row><cell>f 22</cell><cell>Mean Std</cell><cell>2.70E+02 9.04E+01</cell><cell>3.06E+02 9.29E+01</cell><cell cols="2">1.29E+02 7.05E+01</cell><cell>5.36E+02 1.83E+02</cell><cell>8.84E+02 2.89E+01</cell><cell>7.68E+02 2.87E+02</cell><cell>2.35E+02 9.61E+01</cell><cell>1.83E+02 9.53E+01</cell></row><row><cell>f 23</cell><cell>Mean Std</cell><cell>3.15E+02 8.38E-13</cell><cell>3.15E+02 2.47E-01</cell><cell cols="2">3.15E+02 6.21E-03</cell><cell>3.16E+02 5.32E-01</cell><cell>3.15E+02 4.02E-13</cell><cell>3.25E+02 6.46E+00</cell><cell>3.15E+02 8.77E-01</cell><cell>3.15E+02 3.96E-13</cell></row><row><cell>f 24</cell><cell>Mean Std</cell><cell>2.25E+02 4.91E+00</cell><cell>2.27E+02 3.43E+00</cell><cell cols="2">2.25E+02 3.01E+00</cell><cell>2.32E+02 5.30E+00</cell><cell>2.23E+02 9.81E-01</cell><cell>2.06E+02 3.79E-01</cell><cell>2.00E+02 1.12E-03</cell><cell>2.17E+02 6.46E-01</cell></row><row><cell>f 25</cell><cell>Mean Std</cell><cell>2.07E+02 1.20E+00</cell><cell>2.08E+02 1.29E+00</cell><cell cols="2">2.07E+02 1.65E+00</cell><cell>2.14E+02 4.91E+00</cell><cell>2.07E+02 9.52E-01</cell><cell>2.23E+02 1.60E+01</cell><cell>2.07E+02 1.59E+00</cell><cell>2.01E+02 7.96E-01</cell></row><row><cell>f 26</cell><cell>Mean Std</cell><cell>1.00E+02 5.24E-02</cell><cell>1.00E+02 7.35E-02</cell><cell cols="2">1.04E+02 1.97E+01</cell><cell>1.73E+02 4.50E+01</cell><cell>1.00E+02 3.69E-02</cell><cell>1.00E+02 1.26E-01</cell><cell>1.00E+02 5.13E-02</cell><cell>1.00E+02 2.61E-02</cell></row><row><cell>f 27</cell><cell>Mean Std</cell><cell>4.07E+02 2.08E+00</cell><cell>4.11E+02 4.42E+00</cell><cell cols="2">3.07E+02 1.15E+00</cell><cell>7.30E+02 1.24E+02</cell><cell>9.10E+02 3.03E+01</cell><cell>1.16E+03 2.75E+02</cell><cell>4.86E+02 1.73E+02</cell><cell>4.06E+02 1.85E+00</cell></row><row><cell>f 28</cell><cell>Mean Std</cell><cell>9.93E+02 6.20E+01</cell><cell>9.66E+02 6.11E+01</cell><cell cols="2">8.93E+02 4.39E+01</cell><cell>1.18E+03 2.75E+02</cell><cell>7.78E+02 1.93E+01</cell><cell>2.13E+03 6.60E+02</cell><cell>1.36E+03 1.59E+02</cell><cell>8.88E+02 3.32E+01</cell></row><row><cell>f 29</cell><cell>Mean Std</cell><cell>1.61E+03 3.60E+02</cell><cell>1.09E+03 1.11E+02</cell><cell cols="2">1.64E+03 4.76E+02</cell><cell>1.28E+03 3.65E+02</cell><cell>1.82E+03 2.74E+02</cell><cell>5.00E+06 4.43E+06</cell><cell>9.02E+03 1.16E+04</cell><cell>9.37E+02 4.67E+00</cell></row><row><cell>f 30</cell><cell>Mean Std</cell><cell>2.10E+03 4.85E+02</cell><cell>2.97E+03 6.66E+02</cell><cell cols="2">1.43E+03 5.44E+02</cell><cell>4.30E+03 2.43E+03</cell><cell>1.59E+03 4.72E+02</cell><cell>5.81E+04 2.90E+04</cell><cell>1.72E+03 5.46E+02</cell><cell>1.36E+03 2.48E+02</cell></row><row><cell>Table 7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">the original global best strategy in GHS, the enhanced global-</cell></row><row><cell cols="3">Wilcoxon signed-rank test results. p-value</cell><cell>R +</cell><cell>R -</cell><cell>n/w/t/l</cell><cell cols="5">best lead strategy embeds an elite guidance operator which in-</cell></row><row><cell cols="2">MEGWO VS ACS</cell><cell>0.0005</cell><cell>436</cell><cell>29</cell><cell>30/28/2/0</cell><cell cols="5">tegrates social cognition into the experience of the alpha wolf.</cell></row><row><cell cols="2">MEGWO VS MEABC</cell><cell>0.0012</cell><cell>431</cell><cell>34</cell><cell>30/26/3/1</cell><cell cols="5">This modification supports the detailed local search around the</cell></row><row><cell cols="2">MEGWO VS SinDE MEGWO VS BHS</cell><cell>0.0015 0.0001</cell><cell>393 451</cell><cell>72 14</cell><cell>30/26/4/0 30/28/2/0</cell><cell cols="5">current optimal solution and provide fast convergence to optimum</cell></row><row><cell cols="2">MEGWO VS DE/BBO</cell><cell>0.003</cell><cell>376</cell><cell>89</cell><cell>30/24/6/0</cell><cell cols="5">or near optimum solutions. Secondly, the one-dimensional update</cell></row><row><cell cols="2">MEGWO VS WOA MEGWO VS CLPSO-LOT</cell><cell>0.0001 0.001</cell><cell>456 374</cell><cell>9 91</cell><cell>30/29/1/0 30/21/7/2</cell><cell cols="5">operation adopted in the adaptable cooperative hunting strategy</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">can avoid the destruction of excellent solution to some extent and</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">improve the population diversity. The alternative operation of one-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">dimensional and total-dimensional update strategy can not only</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8</head><label>8</label><figDesc>Time complexity for GWO and MEGWO (/s).</figDesc><table><row><cell>D = 10</cell><cell>D = 30</cell><cell>D = 50</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9</head><label>9</label><figDesc>List of datasets used in the experiment.</figDesc><table><row><cell>No</cell><cell>Dataset</cell><cell>No. of Samples</cell><cell>No. of Features</cell><cell>No. of Classes</cell></row><row><cell>1</cell><cell>Australian</cell><cell>690</cell><cell>14</cell><cell>2</cell></row><row><cell>2</cell><cell>Breast</cell><cell>277</cell><cell>9</cell><cell>2</cell></row><row><cell>3</cell><cell>Hearts</cell><cell>270</cell><cell>12</cell><cell>2</cell></row><row><cell>4</cell><cell>Ionosphere</cell><cell>351</cell><cell>34</cell><cell>2</cell></row><row><cell>5</cell><cell>Kr_vs_kp</cell><cell>3196</cell><cell>36</cell><cell>2</cell></row><row><cell>6</cell><cell>Sonar</cell><cell>208</cell><cell>60</cell><cell>2</cell></row><row><cell>7</cell><cell>Segmentation</cell><cell>210</cell><cell>19</cell><cell>7</cell></row><row><cell>8</cell><cell>Vowel</cell><cell>528</cell><cell>10</cell><cell>2</cell></row><row><cell>9</cell><cell>Wine</cell><cell>178</cell><cell>13</cell><cell>3</cell></row><row><cell>10</cell><cell>Waveform</cell><cell>5000</cell><cell>21</cell><cell>3</cell></row><row><cell>11</cell><cell>Wdbc</cell><cell>569</cell><cell>30</cell><cell>2</cell></row><row><cell>12</cell><cell>Zoo</cell><cell>101</cell><cell>16</cell><cell>7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 10</head><label>10</label><figDesc>Classification accuracy and average number of selected features for SRPSO, SinDE, WOASA, and MEGWO.</figDesc><table><row><cell>Dataset</cell><cell>Accuracy</cell><cell></cell><cell></cell><cell></cell><cell cols="4">Average number of selected features</cell></row><row><cell></cell><cell>SRPSO</cell><cell>SinDE</cell><cell>WOASA</cell><cell>MEGWO</cell><cell>SRPSO</cell><cell>SinDE</cell><cell>WOASA</cell><cell>MEGWO</cell></row><row><cell>Australian</cell><cell>80.93%</cell><cell>85.39%</cell><cell>86.67%</cell><cell>87.54%</cell><cell>4.6</cell><cell>4.8</cell><cell>4.2</cell><cell>3.2</cell></row><row><cell>Breast</cell><cell>73.81%</cell><cell>78.99%</cell><cell>79.71%</cell><cell>79.86%</cell><cell>4.4</cell><cell>4.2</cell><cell>4.4</cell><cell>4.0</cell></row><row><cell>Hearts</cell><cell>76.00%</cell><cell>81.78%</cell><cell>85.19%</cell><cell>85.33%</cell><cell>4.8</cell><cell>4.6</cell><cell>4.2</cell><cell>4.0</cell></row><row><cell>Ionosphere</cell><cell>90.45%</cell><cell>94.55%</cell><cell>95.45%</cell><cell>95.91%</cell><cell>16.4</cell><cell>10.8</cell><cell>10.6</cell><cell>10.6</cell></row><row><cell>Kr_vs_kp</cell><cell>78.20%</cell><cell>80.23%</cell><cell>82.17%</cell><cell>82.53%</cell><cell>18.6</cell><cell>16.4</cell><cell>15.2</cell><cell>15.2</cell></row><row><cell>Sonar</cell><cell>86.15%</cell><cell>93.08%</cell><cell>95.67%</cell><cell>94.81%</cell><cell>28.2</cell><cell>26.4</cell><cell>23.4</cell><cell>25.6</cell></row><row><cell>Segmentation</cell><cell>88.76%</cell><cell>91.81%</cell><cell>91.43%</cell><cell>94.67%</cell><cell>9.8</cell><cell>7.0</cell><cell>8.0</cell><cell>5.2</cell></row><row><cell>Vowel</cell><cell>92.27%</cell><cell>96.52%</cell><cell>97.73%</cell><cell>98.48%</cell><cell>7.8</cell><cell>7.6</cell><cell>7.4</cell><cell>7.0</cell></row><row><cell>Wine</cell><cell>92.36%</cell><cell>95.53%</cell><cell>97.51%</cell><cell>98.43%</cell><cell>6.6</cell><cell>4.6</cell><cell>4.2</cell><cell>4.0</cell></row><row><cell>Waveform</cell><cell>75.54%</cell><cell>78.98%</cell><cell>79.52%</cell><cell>78.82%</cell><cell>18.2</cell><cell>15</cell><cell>16.0</cell><cell>16.0</cell></row><row><cell>Wdbc</cell><cell>92.21%</cell><cell>92.77%</cell><cell>94.04%</cell><cell>94.53%</cell><cell>5.2</cell><cell>5.4</cell><cell>5.2</cell><cell>5.0</cell></row><row><cell>Zoo</cell><cell>96.86%</cell><cell>98.04%</cell><cell>98.04%</cell><cell>99.22%</cell><cell>9.4</cell><cell>6.5</cell><cell>5.6</cell><cell>5.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 11</head><label>11</label><figDesc>Mean fitness value and average computational time (/s) for SRPSO, SinDE, WOASA, and MEGWO.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Mean Fitness</cell><cell></cell><cell></cell><cell cols="3">Average Computational time (/s)</cell><cell></cell></row><row><cell></cell><cell>SRPSO</cell><cell>SinDE</cell><cell>WOASA</cell><cell>MEGWO</cell><cell>SRPSO</cell><cell>SinDE</cell><cell>WOASA</cell><cell>MEGWO</cell></row><row><cell>Australian</cell><cell>0.192</cell><cell>0.148</cell><cell>0.135</cell><cell>0.126</cell><cell>3.74</cell><cell>3.48</cell><cell>18.09</cell><cell>3.46</cell></row><row><cell>Breast</cell><cell>0.264</cell><cell>0.211</cell><cell>0.206</cell><cell>0.204</cell><cell>2.83</cell><cell>2.93</cell><cell>11.72</cell><cell>2.62</cell></row><row><cell>Hearts</cell><cell>0.242</cell><cell>0.184</cell><cell>0.157</cell><cell>0.149</cell><cell>2.84</cell><cell>2.84</cell><cell>16.35</cell><cell>2.77</cell></row><row><cell>Ionosphere</cell><cell>0.099</cell><cell>0.057</cell><cell>0.048</cell><cell>0.044</cell><cell>3.16</cell><cell>3.12</cell><cell>14.36</cell><cell>2.89</cell></row><row><cell>Kr_vs_kp</cell><cell>0.221</cell><cell>0.199</cell><cell>0.181</cell><cell>0.177</cell><cell>53.12</cell><cell>45.22</cell><cell>230.21</cell><cell>38.67</cell></row><row><cell>Sonar</cell><cell>0.142</cell><cell>0.072</cell><cell>0.047</cell><cell>0.056</cell><cell>4.38</cell><cell>3.85</cell><cell>11.84</cell><cell>2.73</cell></row><row><cell>Segmentation</cell><cell>0.117</cell><cell>0.0849</cell><cell>0.089</cell><cell>0.0557</cell><cell>3.42</cell><cell>3.49</cell><cell>26.76</cell><cell>3.37</cell></row><row><cell>Vowel</cell><cell>0.083</cell><cell>0.041</cell><cell>0.032</cell><cell>0.022</cell><cell>4.87</cell><cell>5.46</cell><cell>25.28</cell><cell>3.51</cell></row><row><cell>Wine</cell><cell>0.081</cell><cell>0.048</cell><cell>0.028</cell><cell>0.019</cell><cell>3.77</cell><cell>4.15</cell><cell>29.74</cell><cell>3.71</cell></row><row><cell>Waveform</cell><cell>0.248</cell><cell>0.215</cell><cell>0.212</cell><cell>0.217</cell><cell>64.83</cell><cell>79.94</cell><cell>368.76</cell><cell>84.82</cell></row><row><cell>Wdbc</cell><cell>0.082</cell><cell>0.073</cell><cell>0.061</cell><cell>0.056</cell><cell>5.58</cell><cell>4.56</cell><cell>25.16</cell><cell>4.52</cell></row><row><cell>Zoo</cell><cell>0.037</cell><cell>0.023</cell><cell>0.023</cell><cell>0.011</cell><cell>2.83</cell><cell>2.95</cell><cell>16.17</cell><cell>2.71</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research was supported in part by the National Natural Science Foundation of China under Grant No. 61301181, No. 61572534, and No. 61873290, in part by the Project-sponsored by SRF, China for ROCS, SEM, under Grant [2014]1685, and in part by the Special Project for Promoting Economic Development in Guangdong Province, China under Grant GDME-2018D004.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict of interest</head><p>The authors declare that they have no conflict of interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethical approval</head><p>This article does not contain any studies with human participants performed by any of the authors.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">High performance computing for cyber physical social systems by using evolutionary multi-objective optimization algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1109/TETC.2017.2703784</idno>
		<ptr target="http://dx.doi.org/10.1109/TETC.2017.2703784" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Emerg. Top. Comput. PP</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Optimization by simulated annealing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gelatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vecchi</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.220.4598.671</idno>
		<ptr target="http://dx.doi.org/10.1126/science.220.4598.671" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="issue">4598</biblScope>
			<biblScope unit="page" from="671" to="680" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A fast and elitist multiobjective genetic algorithm: NSGA-ii</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Meyarivan</surname></persName>
		</author>
		<idno type="DOI">10.1109/4235.996017</idno>
		<ptr target="http://dx.doi.org/10.1109/4235.996017" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="182" to="197" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Classification of multispectral remote sensing data using a back-propagation neural network</title>
		<author>
			<persName><forename type="first">P</forename><surname>Heermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Khazenie</surname></persName>
		</author>
		<idno type="DOI">10.1109/36.124218</idno>
		<ptr target="http://dx.doi.org/10.1109/36.124218" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="88" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Differential Evolution -A simple and efficient heuristic for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
		<idno type="DOI">10.1023/A:1008202821328</idno>
		<ptr target="http://dx.doi.org/10.1023/A:1008202821328" />
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-0-387-30164-8_630</idno>
		<ptr target="http://dx.doi.org/10.1007/978-0-387-30164-8_630" />
	</analytic>
	<monogr>
		<title level="m">Proc. of 1995 IEEE Int</title>
		<meeting>of 1995 IEEE Int<address><addrLine>Perth, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-08">Nov. 27-Dec. (8) 2011</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Firefly algorithm, stochastic test functions and design optimisation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1504/IJBIC.2010.032124</idno>
		<ptr target="http://dx.doi.org/10.1504/IJBIC.2010.032124" />
	</analytic>
	<monogr>
		<title level="j">Int. J. Bio-Inspired Comput</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="78" to="84" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A new heuristic optimization algorithm: Harmony search</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Loganathan</surname></persName>
		</author>
		<idno type="DOI">10.1177/003754970107600201</idno>
		<ptr target="http://dx.doi.org/10.1177/003754970107600201" />
	</analytic>
	<monogr>
		<title level="j">Simulation</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="60" to="68" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Bat algorithm: A novel approach for global engineering optimization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gandomi</surname></persName>
		</author>
		<idno type="DOI">10.1108/02644401211235834</idno>
		<ptr target="http://dx.doi.org/10.1108/02644401211235834" />
	</analytic>
	<monogr>
		<title level="j">Eng. Comput</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="464" to="483" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Cuckoo search algorithm: A metaheuristic approach to solve structural optimization problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alavi</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00366-011-0241-y</idno>
		<ptr target="http://dx.doi.org/10.1007/s00366-011-0241-y" />
	</analytic>
	<monogr>
		<title level="j">Eng. Comput</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="35" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A hybrid least square-fuzzy bacterial foraging strategy for harmonic estimation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mishra</surname></persName>
		</author>
		<idno type="DOI">10.1109/TEVC.2004.840144</idno>
		<ptr target="http://dx.doi.org/10.1109/TEVC.2004.840144" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="73" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Optimization of water distribution network design using the shuffled frog leaping algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eusuff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lansey</surname></persName>
		</author>
		<idno type="DOI">10.1061/(ASCE)0733-9496(2003)129:3(210)</idno>
		<ptr target="http://dx.doi.org/10.1061/(ASCE)0733-9496" />
	</analytic>
	<monogr>
		<title level="j">J. Water Resour. Plan. Manag</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A comparative study of Artificial Bee Colony algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Akay</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.amc.2009.03.090</idno>
		<ptr target="http://dx.doi.org/10.1016/j.amc.2009.03.090" />
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">214</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="108" to="132" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Biogeography-based optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Simon</surname></persName>
		</author>
		<idno type="DOI">10.1109/TEVC.2008.919004</idno>
		<ptr target="http://dx.doi.org/10.1109/TEVC.2008.919004" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="702" to="713" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Grey wolf optimizer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewis</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.advengsoft.2013.12.007</idno>
		<ptr target="http://dx.doi.org/10.1016/j.advengsoft.2013.12.007" />
	</analytic>
	<monogr>
		<title level="j">Adv. Eng. Softw</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="46" to="61" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The whale optimization algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewis</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.advengsoft.2016.01.008</idno>
		<ptr target="http://dx.doi.org/10.1016/j.advengsoft.2016.01.008" />
	</analytic>
	<monogr>
		<title level="j">Adv. Eng. Softw</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="51" to="67" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An efficient binary salp swarm algorithm with crossover scheme for feature selection problems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Al-Zoubi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.knosys.2018.05.009</idno>
		<ptr target="http://dx.doi.org/10.1016/j.knosys.2018.05.009" />
	</analytic>
	<monogr>
		<title level="j">Knowl.-Based Syst</title>
		<imprint>
			<biblScope unit="volume">154</biblScope>
			<biblScope unit="page" from="43" to="67" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Evolutionary population dynamics and grasshopper optimization approaches for feature selection problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hammouri</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.knosys.2017.12.037</idno>
		<ptr target="http://dx.doi.org/10.1016/j.knosys.2017.12.037" />
	</analytic>
	<monogr>
		<title level="j">Knowl.-Based Syst</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="page" from="25" to="45" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An intelligent system for spam detection and identification of the most relevant features based on evolutionary random weight networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ala'm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.inffus.2018.08.002</idno>
		<ptr target="http://dx.doi.org/10.1016/j.inffus.2018.08.002" />
	</analytic>
	<monogr>
		<title level="j">Inf. Fusion</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="67" to="83" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Asynchronous accelerating multi-leader salp chains for feature selection</title>
		<author>
			<persName><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.asoc.2018.07.040</idno>
		<ptr target="http://dx.doi.org/10.1016/j.asoc.2018.07.040" />
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="964" to="979" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Binary dragonfly optimization for feature selection using time-varying transfer functions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.knosys.2018.08.003</idno>
		<ptr target="http://dx.doi.org/10.1016/j.knosys.2018.08.003" />
	</analytic>
	<monogr>
		<title level="j">Knowl.-Based Syst</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Grey wolf optimizer: A review of recent variants and applications</title>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Al-Betar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00521-017-3272-5</idno>
		<ptr target="http://dx.doi.org/10.1007/s00521-017-3272-5" />
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="413" to="435" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Binary grey wolf optimization approaches for feature selection</title>
		<author>
			<persName><forename type="first">E</forename><surname>Emary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zawbaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hassanien</surname></persName>
		</author>
		<idno type="DOI">10.1016/jneucom.2015.06.083</idno>
		<ptr target="http://dx.doi.org/10.1016/jneucom.2015.06.083" />
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="page" from="371" to="381" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Using the gray wolf optimizer for solving optimal reactive power dispatch problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sulaiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Mustaffa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Aliman</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.asoc.2015.03.041</idno>
		<ptr target="http://dx.doi.org/10.1016/j.asoc.2015.03.041" />
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="286" to="292" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Grey wolf optimization-based energyefficient routing protocol for heterogeneous wireless sensor networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Al-Aboody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Al-Raweshidy</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISCBI.2016.7743266</idno>
		<ptr target="http://dx.doi.org/10.1109/ISCBI.2016.7743266" />
	</analytic>
	<monogr>
		<title level="m">Computational and Business Intelligence (ISCBI), 2016 4th International Symposium on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="101" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Grey wolf optimizer for parameter estimation in surface waves</title>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.soildyn.2015.04.004</idno>
		<ptr target="http://dx.doi.org/10.1016/j.soildyn.2015.04.004" />
	</analytic>
	<monogr>
		<title level="j">Soil Dyn. Earthq. Eng</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="147" to="157" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multi-objective grey wolf optimizer for improved cervix lesion classification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sahoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chandra</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.asoc.2016.12.022</idno>
		<ptr target="http://dx.doi.org/10.1016/j.asoc.2016.12.022" />
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="64" to="80" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multilevel thresholding using grey wolf optimizer for image segmentation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Khairuzzaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhury</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2017.04.029</idno>
		<ptr target="http://dx.doi.org/10.1016/j.eswa.2017.04.029" />
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="64" to="76" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Weighted distance grey wolf optimizer for global optimization problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mohideen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ali</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCIC.2015.7435714</idno>
		<ptr target="http://dx.doi.org/10.1109/ICCIC.2015.7435714" />
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Computational Intelligence &amp; Computing Research (ICCIC)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A fuzzy hierarchical operator in the grey wolf optimizer algorithm</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Soria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Melin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Valdez</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.asoc.2017.03.048</idno>
		<ptr target="http://dx.doi.org/10.1016/j.asoc.2017.03.048" />
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="315" to="328" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Natural selection methods for grey wolf optimizer</title>
		<author>
			<persName><forename type="first">M</forename><surname>Al-Betar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Awadallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2018.07.022</idno>
		<ptr target="http://dx.doi.org/10.1016/j.eswa.2018.07.022" />
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="481" to="498" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Evolutionary population dynamics and grey wolf optimizer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Saremi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00521-014-1806-7</idno>
		<ptr target="http://dx.doi.org/10.1007/s00521-014-1806-7" />
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1257" to="1263" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Blackout risk prevention in a smart grid based flexible optimal strategy using grey wolf-pattern search algorithms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mahdad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Srairi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.enconman.2015.04.005</idno>
		<ptr target="http://dx.doi.org/10.1016/j.enconman.2015.04.005" />
	</analytic>
	<monogr>
		<title level="j">Energy Convers. Manage</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="411" to="429" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Precise equivalent model of small hydro generator cluster and its parameter identification using improved Grey Wolf optimizer</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1049/iet-gtd.2015.1141</idno>
		<ptr target="http://dx.doi.org/10.1049/iet-gtd.2015.1141" />
	</analytic>
	<monogr>
		<title level="j">IET Gener. Transm. Distrib</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2108" to="2117" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">An efficient modified grey wolf optimizer with lévy flight for optimization tasks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pahlavani</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.asoc.2017.06.044</idno>
		<ptr target="http://dx.doi.org/10.1016/j.asoc.2017.06.044" />
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="115" to="134" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Grouped grey wolf optimizer for maximum power point tracking of doubly-fed induction generator based wind turbine</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.enconman.2016.10.062</idno>
		<ptr target="http://dx.doi.org/10.1016/j.enconman.2016.10.062" />
	</analytic>
	<monogr>
		<title level="j">Energy Convers. Manag</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="427" to="443" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deep</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.swevo.2018.01.001</idno>
		<ptr target="http://dx.doi.org/10.1016/j.swevo.2018.01.001" />
	</analytic>
	<monogr>
		<title level="m">A novel random walk grey wolf optimizer</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A novel hybrid PSO-GWO approach for unit commitment problem</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kamboj</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00521-015-1962-4</idno>
		<ptr target="http://dx.doi.org/10.1007/s00521-015-1962-4" />
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1643" to="1655" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Hybridizing grey wolf optimization with differential evolution for global optimization and test scheduling for 3D stacked SoC</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1109/JSEE.2015.00037</idno>
		<ptr target="http://dx.doi.org/10.1109/JSEE.2015.00037" />
	</analytic>
	<monogr>
		<title level="j">J. Syst. Eng. Electron</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="317" to="328" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">How effective is the grey wolf optimizer in training multi-layer perceptrons</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10489-014-0645-7</idno>
		<ptr target="http://dx.doi.org/10.1007/s10489-014-0645-7" />
	</analytic>
	<monogr>
		<title level="j">Appl. Intell</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="150" to="161" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Wolf-pack (canis lupus) hunting strategies emerge from simple rules in computational simulations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Muro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Escobedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Spector</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Coppinger</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.beproc.2011.09.006</idno>
		<ptr target="http://dx.doi.org/10.1016/j.beproc.2011.09.006" />
	</analytic>
	<monogr>
		<title level="j">Behav. Process</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="192" to="197" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Problem definitions and evaluation criteria for the cec 2005 special session on real-parameter optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KanGAL report</title>
		<imprint>
			<biblScope unit="page">2005</biblScope>
			<date type="published" when="2005">2005005. 2005</date>
		</imprint>
		<respStmt>
			<orgName>Nanyang Technological University Singapore</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Global-best harmony search</title>
		<author>
			<persName><forename type="first">M</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mahdavi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.amc.2007.09.004</idno>
		<ptr target="http://dx.doi.org/10.1016/j.amc.2007.09.004" />
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">198</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="643" to="656" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">An improved global-best harmony search algorithm for faster optimization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2014.03.016</idno>
		<ptr target="http://dx.doi.org/10.1016/j.eswa.2014.03.016" />
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="5788" to="5803" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A global best artificial bee colony algorithm for global optimization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cam.2012.01.013</idno>
		<ptr target="http://dx.doi.org/10.1016/j.cam.2012.01.013" />
	</analytic>
	<monogr>
		<title level="j">J. Comput. Appl. Math</title>
		<imprint>
			<biblScope unit="volume">236</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2741" to="2753" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Artificial bee colony algorithm with variable search strategy for continuous optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kiran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hakli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gunduz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Uguz</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ins.2014.12.043</idno>
		<ptr target="http://dx.doi.org/10.1016/j.ins.2014.12.043" />
	</analytic>
	<monogr>
		<title level="j">Inform. Sci</title>
		<imprint>
			<biblScope unit="volume">300</biblScope>
			<biblScope unit="page" from="140" to="157" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">An improved artificial bee colony and its application</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.knosys.2016.05.052</idno>
		<ptr target="http://dx.doi.org/10.1016/j.knosys.2016.05.052" />
	</analytic>
	<monogr>
		<title level="j">Knowl.-Based Syst</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="14" to="31" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A novel artificial bee colony algorithm based on modified search equation and orthogonal learning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSMCB.2012.2222373</idno>
		<ptr target="http://dx.doi.org/10.1109/TSMCB.2012.2222373" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1011" to="1024" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Modified cuckoo search algorithm with self adaptive parameter method</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yin</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ins.2014.11.042</idno>
		<ptr target="http://dx.doi.org/10.1016/j.ins.2014.11.042" />
	</analytic>
	<monogr>
		<title level="j">Inform. Sci</title>
		<imprint>
			<biblScope unit="volume">298</biblScope>
			<biblScope unit="page" from="80" to="97" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Problem definitions and evaluation criteria for the cec 2014 special session and competition on single objective real-parameter numerical optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suganthan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<pubPlace>Zhengzhou China; Singapore</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computational Intelligence Laboratory, Zhengzhou University ; Nanyang Technological University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Symbiotic organisms search: A new metaheuristic optimization algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Prayogo</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.compstruc.2014.03.007</idno>
		<ptr target="http://dx.doi.org/10.1016/j.compstruc.2014.03.007" />
	</analytic>
	<monogr>
		<title level="j">Comput. Struct</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="98" to="112" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A novel hybrid algorithm based on biogeography-based optimization and grey wolf optimizer</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.asoc.2018.02.049</idno>
		<ptr target="http://dx.doi.org/10.1016/j.asoc.2018.02.049" />
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="197" to="214" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A practical tutorial on the use of nonparametric statistical tests as a methodology for comparing evolutionary and swarm intelligence algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Derrac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.swevo.2011.02.002</idno>
		<ptr target="http://dx.doi.org/10.1016/j.swevo.2011.02.002" />
	</analytic>
	<monogr>
		<title level="j">Swarm Evolut. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="18" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">DE/BBO: A hybrid differential evolution with biogeography-based optimization for global numerical optimization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ling</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00500-010-0591-1</idno>
		<ptr target="http://dx.doi.org/10.1007/s00500-010-0591-1" />
	</analytic>
	<monogr>
		<title level="j">Soft Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="645" to="665" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Multi-strategy ensemble artificial bee colony algorithm</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rahnamayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ins.2014.04.013</idno>
		<ptr target="http://dx.doi.org/10.1016/j.ins.2014.04.013" />
	</analytic>
	<monogr>
		<title level="j">Inform. Sci</title>
		<imprint>
			<biblScope unit="volume">279</biblScope>
			<biblScope unit="page" from="587" to="603" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wunnava</surname></persName>
		</author>
		<idno type="DOI">10.1109/ReTIS.2015.7232842</idno>
		<ptr target="http://dx.doi.org/10.1109/ReTIS.2015.7232842" />
		<title level="m">A new adaptive cuckoo search algorithm in: 2015 IEEE 2nd International Conference on Recent Trends in Information Systems (ReTIS)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A sinusoidal differential evolution algorithm for numerical optimisation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Draa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bouzoubia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Boukhalfa</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.asoc.2014.11.003</idno>
		<ptr target="http://dx.doi.org/10.1016/j.asoc.2014.11.003" />
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="99" to="126" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Biogeographic harmony search for emergency air transportation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00500-014-1556-6</idno>
		<ptr target="http://dx.doi.org/10.1007/s" />
	</analytic>
	<monogr>
		<title level="j">Soft Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="500" to="514" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Enhancing comprehensive learning particle swarm optimization with local optima topology</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ins.2018.08.049</idno>
		<ptr target="http://dx.doi.org/10.1016/j.ins.2018.08.049" />
	</analytic>
	<monogr>
		<title level="j">Inform. Sci</title>
		<imprint>
			<biblScope unit="volume">471</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Self regulating particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tanweer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sundararajan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ins.2014.09.053</idno>
		<ptr target="http://dx.doi.org/10.1016/j.ins.2014.09.053" />
	</analytic>
	<monogr>
		<title level="j">Inform. Sci</title>
		<imprint>
			<biblScope unit="volume">294</biblScope>
			<biblScope unit="page" from="182" to="202" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Hybrid whale optimization algorithm with simulated annealing for feature selection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2017.04.053</idno>
		<ptr target="http://dx.doi.org/10.1016/j.neucom.2017.04.053" />
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">260</biblScope>
			<biblScope unit="page" from="302" to="312" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Benchmarking optimization software with performance profiles</title>
		<author>
			<persName><forename type="first">E</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Moré</surname></persName>
		</author>
		<idno type="DOI">10.1007/s101070100263</idno>
		<ptr target="http://dx.doi.org/10.1007/s101070100263" />
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="201" to="213" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">A comparison of the power of wilcoxon&apos;s rank-sum statistic to that of student&apos;s t statistic under various nonnormal distributions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Blair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Higgins</surname></persName>
		</author>
		<idno type="DOI">10.3102/10769986005004309</idno>
		<ptr target="http://dx.doi.org/10.3102/10769986005004309" />
	</analytic>
	<monogr>
		<title level="j">J. Educ. Stat</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="309" to="335" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Binary ant lion approaches for feature selection</title>
		<author>
			<persName><forename type="first">E</forename><surname>Emary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zawbaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hassanien</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2016.03.101</idno>
		<ptr target="http://dx.doi.org/10.1016/j.neucom.2016.03.101" />
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">213</biblScope>
			<biblScope unit="page" from="54" to="65" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">UCI repository of machine learning databases</title>
		<author>
			<persName><forename type="first">C</forename><surname>Blake</surname></persName>
		</author>
		<ptr target="http://archive.ics.uci.edu/ml/index.php" />
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>University of California, Department of Information and Computer Science</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">A survey of cross-validation procedures for model selection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arlot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Celisse</surname></persName>
		</author>
		<idno type="DOI">10.1214/09-SS054</idno>
		<ptr target="http://dx.doi.org/10.1214/09-SS054" />
	</analytic>
	<monogr>
		<title level="j">Stat. Surv</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="40" to="79" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A new belief-based k-nearest neighbor classification method</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dezert</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.patcog.2012.10.001</idno>
		<ptr target="http://dx.doi.org/10.1016/j.patcog.2012.10.001" />
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="834" to="844" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
