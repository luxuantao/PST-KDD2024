<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Grammatical Evolution Hyper-Heuristic for Combinatorial Optimization Problems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nasser</forename><forename type="middle">R</forename><surname>Sabar</surname></persName>
							<email>nasser.sabar@nottingham.edu.my</email>
						</author>
						<author>
							<persName><forename type="first">Masri</forename><surname>Ayob</surname></persName>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Rong</forename><surname>Qu</surname></persName>
							<email>rong.qu@nottingham.ac.uk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Nottingham Malaysia Campus</orgName>
								<address>
									<addrLine>Jalan Broga, Se-menyih 43500</addrLine>
									<settlement>Selangor</settlement>
									<country key="MY">Malaysia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">Data Mining and Optimization Research Group (DMO)</orgName>
								<orgName type="institution">University Kebangsaan Malaysia</orgName>
								<address>
									<addrLine>UKM</addrLine>
									<postCode>43600</postCode>
									<settlement>Bangi, Selangor</settlement>
									<country key="MY">Malaysia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University of Nottingham Malaysia Campus</orgName>
								<address>
									<addrLine>Jalan Broga</addrLine>
									<postCode>43500</postCode>
									<settlement>Semenyih, Selangor</settlement>
									<country key="MY">Malaysia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">The University of Nottingham</orgName>
								<address>
									<postCode>NG8 1BB</postCode>
									<settlement>Nottingham</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="laboratory">ASAP Research Group</orgName>
								<orgName type="institution">The University of Nottingham</orgName>
								<address>
									<postCode>NG8 1BB</postCode>
									<settlement>Nottingham</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Grammatical Evolution Hyper-Heuristic for Combinatorial Optimization Problems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">24B2721AACA84B36150F38D40ECCB413</idno>
					<idno type="DOI">10.1109/TEVC.2013.2281527</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Grammatical evolution</term>
					<term>hyper-heuristics</term>
					<term>timetabling</term>
					<term>vehicle routing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Designing generic problem solvers that perform well across a diverse set of problems is a challenging task. In this work, we propose a hyper-heuristic framework to automatically generate an effective and generic solution method by utilizing grammatical evolution. In the proposed framework, grammatical evolution is used as an online solver builder, which takes several heuristic components (e.g., different acceptance criteria and different neighborhood structures) as inputs and evolves templates of perturbation heuristics. The evolved templates are improvement heuristics, which represent a complete search method to solve the problem at hand. To test the generality and the performance of the proposed method, we consider two wellknown combinatorial optimization problems: exam timetabling (Carter and ITC 2007 instances) and the capacitated vehicle routing problem (Christofides and Golden instances). We demonstrate that the proposed method is competitive, if not superior, when compared to state-of-the-art hyper-heuristics, as well as bespoke methods for these different problem domains. In order to further improve the performance of the proposed framework we utilize an adaptive memory mechanism, which contains a collection of both high quality and diverse solutions and is updated during the problem solving process. Experimental results show that the grammatical evolution hyper-heuristic, with an adaptive memory, performs better than the grammatical evolution hyper-heuristic without a memory. The improved framework also outperforms some bespoke methodologies, which have reported best known results for some instances in both problem domains.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>available for a given problem <ref type="bibr" target="#b0">[1]</ref>. These problems are encountered in many real world applications such as scheduling, production planning, routing, economic systems and management <ref type="bibr" target="#b0">[1]</ref>. Many real world optimization problems are complex and very difficult to solve. This is due to the large, and often heavily constrained, search spaces, which make their modeling (let alone solving) a very complex task <ref type="bibr" target="#b1">[2]</ref>. Usually, heuristic methods are used to solve these problems, as exact methods often fail to obtain an optimal solution in a reasonable amount of time. The main aim of heuristic methods, which provide no guarantee of returning an optimal solution (or even near optimal solution), is to find a reasonably good solution within a realistic amount of time <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>. Meta-heuristic algorithms provide some high level control strategy in order to provide effective navigation of the search space. A vast number of meta-heuristic algorithms, and their hybridizations, have been presented to solve optimization problems. Examples of meta-heuristic algorithms include scatter search, tabu search, genetic algorithms, genetic programming, memetic algorithms, variable neighborhood search, guided local search, GRASP, ant colony optimization, simulated annealing, iterated local search, multistart methods and parallel strategies <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>.</p><p>Given a problem, an interesting question that comes to mind is:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Which algorithm is the most suitable for the problem at hand and what are the optimal structures and parameter values?</head><p>The most straightforward answer to the above question might be to employ trial-and-error to find the most suitable meta-heuristic from the large variety of those available, and then employ trial-and-error to determine the appropriate structures and parameter values. While these answers seem reasonable, in terms of the computational time involved, it is impractical in many real world applications. Many bespoke meta-heuristic algorithms that have been proposed over the years are manually designed and tuned, focusing on producing good results for specific problem instances. The manually designed algorithms (customized by the user and not changed during problem solving) that have been developed over the years are problem specific, i.e., they are able to obtain high quality results for just a few problem instances, but usually fail on other instances even of the same problem and cannot be directly applied to other optimization problems. Of course, the no free lunch theorem <ref type="bibr" target="#b4">[5]</ref> states that a general search method does not exist, but it does not mean that we cannot investigate more general search algorithms to explore the limits of such an algorithm <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b7">[8]</ref>.</p><p>Numerous attempts have been made to develop automated search methodologies that are able to produce good results across several problem domains and/or instances. Hyperheuristics <ref type="bibr" target="#b5">[6]</ref>, meta-learning <ref type="bibr" target="#b8">[9]</ref>, parameter tuning <ref type="bibr" target="#b9">[10]</ref>, reactive search <ref type="bibr" target="#b10">[11]</ref>, adaptive memetic algorithms <ref type="bibr" target="#b11">[12]</ref> and multimethod <ref type="bibr" target="#b12">[13]</ref>, are just some examples. The performance of any search method critically depends on its structures and parameter values <ref type="bibr" target="#b5">[6]</ref>. Furthermore, different search methodologies, coupled with different structures and parameter settings, may be needed to cope with problem instances or different problem domains <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>. A search may even benefit from adapting as it attempts to solve a given instance. Therefore, the performance of any search method may be enhanced by automatically adjusting their structures or parameter values during the problem solving process. Thus, the ultimate goal of automated heuristic design is to develop search methodologies that are able to adjust their structures or parameter values during the problem solving process, and work well not only across different instances of the same problem, but also across a diverse set of problem domains <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>.</p><p>Motivated by these aspects, particularly the hyper-heuristic framework <ref type="bibr" target="#b5">[6]</ref>, in this work, we propose a grammatical evolution hyper-heuristic framework (GE-HH) to generate local search templates during the problem instance solving process, as depicted in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>The evolved templates represent a complete local search method, which contains the acceptance criteria of the local search algorithm (to determine a way of escaping from local optima), the local search structures (neighborhoods), and their combination. The GE-HH operates on the search space of heuristic components, instead of the solution space. In addition, GE-HH also maintains a set of diverse solutions, utilizing an adaptive memory mechanism, which updates the solution quality and diversity as the search progresses. We choose grammatical evolution to search the space of heuristic components due to its ability to represent heuristic components and it being able to avoid the problem of code bloat that is often encountered in traditional genetic programming. Our objectives are:</p><p>1) To design an automatic algorithm that works well across different instances of the same problem and also across two different problem domains; 2) To merge the strengths of different search algorithms in one framework; 3) To test the generality and consistency of the proposed method on two different problem domains. The performance and generality of the GE-HH is assessed using two well-known NP-hard combinatorial optimization problems: examination timetabling (Carter <ref type="bibr" target="#b13">[14]</ref> and ITC 2007 <ref type="bibr" target="#b14">[15]</ref> instances) and the capacitated vehicle routing problem (Christofides <ref type="bibr" target="#b15">[16]</ref> and Golden <ref type="bibr" target="#b16">[17]</ref> instances). Although both domains have been extensively studied by the research community, the reasons for choosing them are twofold. Firstly, they represent real world applications and, we believe, that the state-of-the-art results can still be improved. Currently, a variety of algorithms have achieved very good results for some instances. However, most methodologies fail on generality and consistency. Secondly, these two domains have been widely studied in the scientific literature and we would like to evaluate our algorithm across two different domains that other researchers have studied. Although our intention is not to present an algorithm that can beat the state of the art, but rather can work well across different domains, our results demonstrate that GE-HH is able to update the best known results for some instances.</p><p>The remainder of the work is organized as follows. The generic hyper-heuristic framework and its classification are presented in Section II. The grammatical evolution algorithm is presented in Section III, followed by our proposed GE-HH framework in Section IV. The experimental results and result comparisons are presented in Section V and VI, respectively. Finally, discussions and concluding remarks are presented in Sections VII and VIII respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. Hyper-Heuristics</head><p>Meta-heuristics are generic search methods that can be applied to solve combinatorial optimization problems. However, to find high quality solutions, meta-heuristics often need to be designed and tuned (as do many classes of algorithms, including those in this work) and they are also often limited to one problem domain or even just a single problem instance. The objective for a solution methodology that is independent of the problem domain serves as one of the main motivations for designing hyper-heuristic approaches <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b17">[18]</ref>.</p><p>Recently, significant research attention has been focused on hyper-heuristics. Burke et al. <ref type="bibr" target="#b5">[6]</ref> defined hyper-heuristics as:</p><p>An automated methodology for selecting or generating heuristics to solve hard computational search problems. One possible hyper-heuristic framework is composed of two levels, known as high and low level heuristics (see Fig. <ref type="figure" target="#fig_1">2</ref>).</p><p>The high level heuristic is problem independent. It has no knowledge of the domain, only the number of heuristics that are available and (non-domain) statistical information that is The low level heuristics correspond to a pool of candidates of problem dependent human-designed heuristics or components of existing heuristics, which operate directly on the solution space for a given problem instance. Based on their past performance, heuristics compete with each other through learning, selection or generation mechanisms at a particular point, to construct or improve a solution for a given problem instance.</p><p>The fact that the high level strategy is problem independent means that it can be applied to different problem domains with little development effort. Indeed, one of the goals of hyper-heuristics is to raise the level of generality of search methodologies and to build systems that are more generic than other methods <ref type="bibr" target="#b5">[6]</ref>.</p><p>Burke et al. <ref type="bibr" target="#b5">[6]</ref> classified hyper-heuristics into two dimensions, based on the nature of the heuristic search space and the source of feedback during learning (see Fig. <ref type="figure" target="#fig_2">3</ref>). The nature of the heuristic search space can either be heuristics to choose heuristics or heuristics to generate heuristics. Heuristics can be called from a given pool of heuristics. For example, Burke et al. <ref type="bibr" target="#b18">[19]</ref> used tabu search with reinforcement learning as a heuristic selection mechanism to solve nurse rostering and timetabling problems. Heuristics can also be generated by combining existing heuristic components. For example, Burke et al. <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref> employed genetic programming to evolve new low level heuristics to solve the bin packing problem.</p><p>The nature of the heuristic search space can be further classified depending on the type of low level heuristics as In on-line hyper-heuristics, the learning takes place during the problem solving. Examples of online approaches include those based on genetic algorithms <ref type="bibr" target="#b21">[22]</ref>, tabu search <ref type="bibr" target="#b18">[19]</ref>, and local based search <ref type="bibr" target="#b22">[23]</ref>. In off-line hyper-heuristics, learning occurs during the training phase before solving other problem instances, examples include those based on genetic programming <ref type="bibr" target="#b19">[20]</ref> and learning classifier systems <ref type="bibr" target="#b23">[24]</ref>. Recently, grammatical evolution (GE), which is a variant of genetic programming that uses a grammar to evolve a variable-length program in an arbitrary language <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref> was utilized in <ref type="bibr" target="#b20">[21]</ref> as an off-line heuristic builder to solve the bin packing problem. Our work differs from <ref type="bibr" target="#b20">[21]</ref>, where we use GE as an online solver builder, and is a much more general methodology that is able to address two problem domains, and produce best known results. In addition, the GE in <ref type="bibr" target="#b20">[21]</ref> has been specifically designed and tested on the bin packing problem only (i.e., the grammar has been specifically designed for the bin packing problem only).</p><p>Our proposed GE-HH framework can be classified as an on-line generational hyper-heuristic. In this respect, it is the same as a genetic programming hyper-heuristic that generates heuristics. Genetic programming hyper-heuristics have been utilized to solve many combinatorial optimization problems including SAT <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, scheduling <ref type="bibr" target="#b26">[27]</ref> and bin packing <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b27">[28]</ref>. A recent and comprehensive review on hyperheuristics is available in <ref type="bibr" target="#b28">[29]</ref>.</p><p>Most of the proposed genetic programming based hyperheuristic approaches, however, are constructive heuristics. Their general limitation is that they are tailored to solve specific problems (e.g., SAT, bin packing, and TSP) using a restricted constructive heuristic component. This limitation restricts their applicability to cope with different problem domains without any redevelopment (e.g., redefine the terminals and functions). In addition, previous genetic programming based hyper-heuristics were only applied to one single domain, which raises the question as to what extent they will generalize to other domains.</p><p>Motivated by the above, this work proposes an improvement based hyper-heuristic using grammatical evolution. The proposed framework takes several heuristic components (e.g., acceptance criteria and neighborhood structures) as input and automatically generates a local search template by selecting the appropriate combination of these heuristic components. The differences between our approach and the previous genetic programming based hyper-heuristics in the literature are:</p><p>1) The proposed framework generates a perturbation local search template rather than constructive heuristics. 2) The proposed framework is not tailored to a particular problem domain, for example, it can be applied to several domains (the user only needs to change the neighborhood structures when applying it to another problem domain).</p><p>3) The proposed framework utilizes an adaptive memory mechanism to maintain solution diversity.</p><p>III. Grammatical Evolution Grammatical evolution (GE) <ref type="bibr" target="#b29">[30]</ref> is a variant of genetic programming (GP) <ref type="bibr" target="#b30">[31]</ref>. It is a grammar based GP that can evolve a variable-length program in an arbitrary language. Unlike GP, GE uses a linear genome representation rather than a tree. The clear distinction between the genotype and phenotype in GE allows the evolutionary process (e.g., crossover) to be performed on the search space (variable length linear genotypic) without needing to tailor the diversity-generating operator to the nature of the phenotype <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>. The mapping process of genotype and phenotype to generate a program is governed by a grammar, which contains domain knowledge <ref type="bibr" target="#b29">[30]</ref>. The grammar is represented by Backus Naur form (BNF). The program is generated by using a binary string (genome) to determine which production rule in the BNF definition will be used. The GE general framework is composed of three procedures: 1) grammar; 2) search engine; and 3) a mapper procedure (see Fig. <ref type="figure" target="#fig_3">4</ref>). A. BNF Grammar GE utilizes BNF to generate the output program <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>. A suitable BNF grammar must be defined when solving a problem and the definitions vary from one problem to another. The BNF grammar can be represented by a tuple &lt; T , N, S, P &gt; where T is the terminal set, N is the set of non terminals, S is the start symbol (a member of N), and P is a set of production rules. If more than one production rule is used within a particular N, the choice is delimited with the '|' symbol. Below is an example of BNF grammar (adopted from <ref type="bibr" target="#b29">[30]</ref>): T = {Sin, Cos, Tan, Log, + , -, /, *, (,)} // set of terminal N = {expr, op, pre -op} // set of non-terminal S = &lt;expr &gt; // starting symbol and P can be represented as // production rules</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Search Engine</head><p>GE uses a standard genetic algorithm as its search engine <ref type="bibr" target="#b29">[30]</ref>. A candidate solution (genotype or chromosome) is represented by a one-dimensional variable length string array. The gene in each chromosome is called a codon. Each codon is an 8-bit binary number (see Fig. <ref type="figure" target="#fig_4">5</ref>).</p><p>The codon values are used in the mapper procedure to determine which rule to be selected for the non-terminal symbol when it is converted <ref type="bibr" target="#b29">[30]</ref> (see Section III-C). The GA starts with a population of chromosomes, which are randomly generated. The fitness of each chromosome is calculated by executing its corresponding program. The fitness function varies from one domain to another. GA operators (selection, crossover, mutation and replacement) are then applied. At each generation, the evolved solutions (children) from the crossover and mutation operators are evaluated by converting them into its corresponding program via the mapper function. If the fitness of the new solution is better than the worst solution in the population, it will replace it. The process is repeated until a stopping condition is satisfied (e.g., number of generations). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Mapper Procedure</head><p>The mapper function converts the genotype into a phenotype (i.e., a program). The function takes two inputs: the binary string (genotype) and the BNF grammar <ref type="bibr" target="#b29">[30]</ref>. The conversion from genotype to phenotype is carried out using the following rule:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rule = (codon integer value) MOD (number of rules for the current non-terminal)</head><p>The mapper function begins by mapping the starting symbol into terminals. It converts each codon to its corresponding integer value. Assume we have the above BNF grammar (see Section III-A) and genotype (see Fig. <ref type="figure" target="#fig_4">5</ref>). First of all, convert all codon values to integers (with reference to Fig. <ref type="figure" target="#fig_3">4</ref>, this will be 220, 203, 17, 3, 109, 215, 104, 30). Then, starting from the starting symbol, apply the mapping rule to convert the leftmost non-terminal into a terminal until all nonterminals have been converted into terminals. The genotypeto-phenotype mapping process of the above BNF grammar and the solution (genotype) is illustrated in Table <ref type="table" target="#tab_0">I</ref>.</p><p>The mapper begins (see Table <ref type="table" target="#tab_0">I</ref>) with the starting symbol &lt;expr&gt;, and then reads the first codon (220). The starting symbol &lt;expr&gt; has four production rules to select from (see Section III-A). Following the mapping rules, the codon value and the number of production rules are used with the modular function to decide which rule to select, i.e., 220 MOD 4 = 0, which means we select the first production rule (&lt;expr&gt; &lt;op&gt; &lt;expr&gt;). Since this production rule is not a complete expression (it has at least one non-terminal), rules will be applied again. The process will continue from the leftmost non-terminal in the current production rule. Continuing with &lt;expr&gt; &lt;op&gt; &lt;expr&gt;, take the next codon value (203), the next production rule will be (203 MOD 4 = 3) &lt;var&gt; &lt;op&gt; &lt;expr&gt;. Since &lt;var&gt; has only one choice, &lt;var&gt; will be replaced by X and the production rules will be X&lt;op&gt; &lt;expr&gt;. Continuing with the same mapper rules until all non-terminals are converted to terminals, the complete expression will be X-X.</p><p>During the conversion process, not all codons may be used, or after using all codon values not all non-terminals have been replaced by terminals. In the case where non-terminals have been replaced with terminals but not all codon values have been used, the mapper process will simply ignore the rest. If all codon values have been used but the expression is still invalid, a wrapper procedure is invoked. The wrapper procedure reads the codon value from the left to right for a predefined number of iterations. If the wrapper procedure is finished but the complete expression is still not available, the genotype is given the lowest fitness value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. Grammatical Evolution Hyper-Heuristic</head><p>Framework In this Section, we present the grammatical evolution hyperheuristic (GE-HH) framework. Then, we introduce the adaptive memory mechanism, hybridizing it with GE-HH.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Proposed Framework</head><p>It is well established that the efficiency of any problem solver relies on its ability to explore regions of the search space, which is strongly influenced by its structures and parameter values <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b11">[12]</ref>. Therefore, the performance of any search methodology can potentially be enhanced by automatically adjusting its structures and/or parameter values. In this work, we propose a grammatical evolution hyperheuristic (GE-HH) framework that generates a different local search template (problem solver) to suit the given problem instance. The proposed framework takes several basic heuristic components as input and generates a local search template by combining these basic components. The process of combining heuristic components will be carried out automatically. Thus, the benefit of this framework is not only to generate different local search templates by combining basic heuristic components, but also to discover new kinds of heuristics, without relying on human interference.</p><p>As we mentioned earlier (see Section III), there are three essential procedures of grammatical evolution algorithm: 1) a grammar; 2) a search engine; and 3) a mapper function. Our search engine (genetic algorithm), and the mapper function are implemented as in the original algorithm <ref type="bibr" target="#b29">[30]</ref>. The BNF grammar, which is problem dependent, must be defined in order to suit the problem at hand. Generally, the design of the BNF grammar, which decides which production rule will be selected, has a significant impact on the output, i.e., the programs. In our GE-HH framework, the basic heuristic components are represented by BNF. To design a complete BNF grammar one needs to carry out the following steps <ref type="bibr" target="#b29">[30]</ref>:</p><p>1) Determine the terminals, non-terminals and starting symbol. 2) Design the BNF syntax which may have problem specific function(s). In this work, three different heuristic components [acceptance criteria (AC), neighborhood structures (NS) and neighborhood combinations (NC)] are used as basic elements of the BNF grammar. We have selected these three components because they are recognized as crucial components in designing problem solvers <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b17">[18]</ref>. These are explained as follows:</p><p>1. The acceptance criteria (AC) decide whether to accept or reject a solution. A number of acceptance criteria have been proposed in the literature and each one has its own strengths and weaknesses. The strength of one acceptance criterion can compensate for the weakness of another if they can be integrated into one framework. In this work, we have employed several acceptance criteria.</p><p>The acceptance criteria that are used in our GE-HH framework have been widely used in the literature <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b28">[29]</ref>, and are presented below.</p><p>2. The second heuristic component that is used in our GE-HH framework are the neighborhood structures (NS) or move operators. The aim of any neighborhood structure is to explore the neighbor of current solutions or to generate a neighborhood solution. The neighborhood solution is generated by performing a small perturbation or changing some attribute(s) of the current solution. The neighborhood structures are critical in the design of any local search method <ref type="bibr" target="#b35">[36]</ref>. Traditionally, each neighborhood structure has its own characteristics (weaknesses and strengths), thus, several types of neighborhood structures may be needed to cope with changes in the problem landscape as the search progresses. In this work, we have employed several neighborhoods which are problem dependent. The descriptions of the neighborhood structures that have been used in our work, which are different from one domain to another, are presented in problem description sections (see Sections V-B4 and V-C4). 3. The third heuristic component employed in our framework is the neighborhood combinations/operators (NC).</p><p>The aim of the neighborhood combinations/operators is to combine the strength of two or more neighborhood structures into one structure. Such combination has been shown to be very efficient in solving many optimization problems <ref type="bibr" target="#b36">[37]</ref>. The benefit of such an idea was first demonstrated using strategic oscillation in tabu search <ref type="bibr" target="#b37">[38]</ref>. Recently, Lu et al. <ref type="bibr" target="#b36">[37]</ref> conducted a comprehensive analysis to assess the performance of neighborhood combinations within several local search methods (tabu search, iterated local search and steepest decent algorithm) in solving university course timetabling problems. Their aim was to answer why some neighborhood structures can produce better results than others and what characteristics constitute a good neighborhood structure. They concluded that the use of neighborhood combinations can dramatically improve local search performance. Other works which have also studied the benefit of using neighborhood combinations include <ref type="bibr" target="#b38">[39]</ref>- <ref type="bibr" target="#b40">[41]</ref>. In this work, three kinds of neighborhood combinations/operators are used <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b17">[18]</ref>, which are described below.</p><p>After determining the basic elements of the BNF grammar, we now need to specify the starting symbol (S), terminals (T ), non-terminals (N) and the production rules (P) that will represent the heuristic components. These are as follows:</p><p>The above BNF grammar is valid for every local search template (LST) for both problem domains in this work. This is because each local search template (LST) has different rules and characteristics. Finding the best BNF grammar for every local search template (LST) would be problem dependent, if not problem instance dependent. Please note that not all local search templates will improve the solution because the employed acceptance criteria might accept worse solutions with a certain probability. For example, the local search that uses all moves acceptance criterion (AM) will accept any solution that does not violate any hard constraints regardless of its quality.</p><p>The programs in our GE-HH represent local search templates or problem solvers. The local search template starts with an initial solution and then iteratively improves it. The initial solution can be randomly generated or by using heuristic methods (see Sections V-B3 and V-C3). Please note that the initial solution generation method is not a part of the GE-HH. In this work, we use two fitness functions. The first one, penalty cost, is problem dependent, and is used by the inner loop of the generated local search template in deciding whether to accept or reject the perturbed solution (see Sections V-B and V-C for more details about the penalty cost). The second fitness function is problem independent and it measures the quality of the generated program (local search template) after executing it. At every iteration, if the generated programs are syntactically correct (all non-terminals can be converted into terminals), the programs are executed and their fitness is computed from their output. In this work, the fitness function of the generated programs is calculated as a percentage of improvement (PI). Assume f 1 is the fitness of the initial solution and f 2 is the fitness of the solution after executing the generated programs, then PI</p><formula xml:id="formula_0">= | (f 1 -f 2 )/ f 1 | * 100, if f 2 &lt; = f 1 . If f 2 &gt; f 1 discard the generated program.</formula><p>With all the GE-HH elements (grammar, search engine, mapper procedure and fitness function) defined, the proposed GE-HH framework is carried out as depicted in Fig. <ref type="figure">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Hybrid Grammatical Evolution Hyper-Heuristic and Adaptive Memory Mechanism</head><p>Traditionally, previous hyper-heuristic frameworks that have been proposed in the literature operate on a single solution <ref type="bibr" target="#b5">[6]</ref>, Fig. <ref type="figure">6</ref>. Proposed GE-HH framework. <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b28">[29]</ref>. Single solution based perturbative hyper-heuristics start with an initial solution and iteratively move from the current solution to another one by applying an operator such as 2-opt. Although single solution based methods have been widely used to solve several kinds of problems, it is accepted that pure single solution based methods are not well suited to fine tuning for large search spaces and heavily constrained problems <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b44">[45]</ref>. As a result, single solution based methods have been hybridized with other techniques to improve their efficiency <ref type="bibr" target="#b44">[45]</ref>. Generally, it is believed that a good search methodology must have the ability of exploiting and exploring different regions of the solution search space rather than focusing on a particular region. That is, we must address the problem of exploitation versus diversification, which is a key feature in designing efficient search methodologies <ref type="bibr" target="#b43">[44]</ref>.</p><p>In order to enhance the efficiency of the GE-HH framework and to diversify the search process, we hybridize it with an adaptive memory mechanism. This method has been widely used with several meta-heuristic algorithms such as tabu search, ant colonies, genetic algorithms and scatter search <ref type="bibr" target="#b45">[46]</ref>. The main idea is to enhance the diversification by maintaining a population of solutions. For example, the reference set in scatter search <ref type="bibr" target="#b45">[46]</ref> includes a collection of both high quality and diverse solutions.</p><p>In this work, the adaptive memory mechanism (following the approach in <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref>) contains a collection of both high quality and diverse solutions, which are updated as the algorithm progresses. The size of the memory is fixed (equal to the number of acceptance criteria, which is 8). Our adaptive memory works as follows.</p><p>1) Generate a set of diverse solutions. The set of solutions can be generated randomly or by using a heuristic method. In this work, the solutions are generated using a heuristic method (see Sections V-B3 and V-C3). 2) For each solution, associate a frequency matrix, which will be used to measure solution diversity. The frequency matrix saves the frequency of assigning an object (exam or customer) to the same location. For example, in exam timetabling, the frequency matrix stores how many times the exam has been assigned to the same timeslot. While in the capacitated vehicle routing problem, it stores how many times a customer has been assigned to the same route. Fig. <ref type="figure" target="#fig_5">7</ref> shows an example of a solution and its corresponding frequency matrix. The frequency matrix is initialized to zero. We can see five objects (represented by rows) and there are five available locations (represented by columns). The solution on the left of Fig. <ref type="figure" target="#fig_5">7</ref> can be read as follows: object1 is assigned to location 1, object 2 is assigned to location 3, etc. The frequency matrix on the right side of the Fig. <ref type="figure" target="#fig_5">7</ref> can be read as follows: object 1 has been assigned to location 1 twice, to location 2 three times, to location 3 once, to location 4 four times and to location 5 once; and so on for the other objects.</p><p>3) If any solution is improved by the GE-HH framework, we update the frequency matrix. 4) Calculate the quality and the diversity of the improved solution. In this work, the quality represents the penalty cost that calculates the number of soft constraint violations (see Sections V-B and V-C). The diversity is measured using entropy information theory ( <ref type="formula">1</ref>), (2) as follows <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref>:</p><formula xml:id="formula_1">ε i = e j=1 e ij m . log e ij m</formula><p>log e (1)</p><formula xml:id="formula_2">ε = e i=1 ε i e (2)</formula><p>where e ij is the frequency of allocating object i to location j. m is the number of objects. ε i is the entropy for object i.</p><p>ε is the entropy for one solution (0 ≤ ε i &lt; 1). 5) Add the new solution to the adaptive memory by considering the solution quality and diversity. Fig. <ref type="figure" target="#fig_6">8</ref> shows the hybrid GE-HH framework with an adaptive memory mechanism. Algorithm 1 presents the pseudo-code of GE-HH.</p><p>The algorithm starts by generating a set of initial solutions for the adaptive memory mechanism (see Sections V-B3 and V-C3) and defining the BNF grammar (see Section IV-A). It then initializes the genetic algorithm parameters and creates a population of solutions by assigning a random value between 0 and 255 for each chromosome gene (codons) <ref type="bibr" target="#b29">[30]</ref>. For each solution (chromosome) in the population, the corresponding program is generated by invoking the mapping function. In order to ensure that there is no duplication in the generated program (i.e., the program does not have two consecutive operators) the program is checked by the edit function. For example, if the generated program is SA: N1N2++N2+N4, with consecutive ++ operators, the edit function will remove one of the + operators and the program will be SA: N1N2+N2+N4. One solution from the adaptive memory mechanism is then selected, to which the generated programs are applied. The adaptive memory is then updated.</p><p>Subsequently, the genetic algorithm is executed for a predefined number of generations. At every generation, offspring are generated by applying selection, crossover and mutation.</p><p>The generated offspring (programs) are then executed. If the offspring is better than the worst chromosome, it is added to the population and the adaptive memory mechanism is updated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. Experimental Results</head><p>In this section, we evaluate and compare the proposed GE-HH with the state of the art of hyper-heuristics, and other search methodologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. GE-HH Parameters Setting</head><p>In order to find appropriate parameter values for GE-HH, we utilize the relevance estimation and value calibration method (REVAC) <ref type="bibr" target="#b48">[49]</ref>. REVAC is a steady state genetic algorithm that uses entropy theory to determine the parameter values for algorithms. Our aim is not to find the optimal parameter values for each domain, but to find generic values that can be used for both domains. To use the same parameter settings across instances of both domains, we tuned GE-HH for each domain separately and then used the average of them in value obtained by REVAC for all tested instances. In order to have a reasonable trade-off between solution quality and the computational time needed to reach good quality solutions, the execution time for each instance is fixed to 20 seconds. The number of iterations performed by REVAC is fixed at 100 iterations (see <ref type="bibr" target="#b48">[49]</ref> for more details). For each domain, the average values over all tested instances for each parameter are recorded. Then, the average values over all parameters are set as the generic values for GE-HH. The parameter settings of GE-HH that have been used for both domains are listed in Table <ref type="table" target="#tab_1">II</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Problem Domain I: Exam Timetabling Problems</head><p>Exam timetabling is a well-known NP-hard combinatorial optimization problem <ref type="bibr" target="#b49">[50]</ref> and is faced by all academic institutions. The exam timetabling problem can be defined as the process of allocating a set of exams into a limited number of timeslots and rooms so as not to violate any hard constraints and to minimize soft constraint violations as much as possible <ref type="bibr" target="#b50">[51]</ref>. In this work, we carried out experiments on the most widely used uncapacitated Carter benchmarks (Toronto b type I in <ref type="bibr" target="#b50">[51]</ref>) and also on the recently introduced exam timetable dataset from the 2007 international timetabling competition (ITC 2007) <ref type="bibr" target="#b14">[15]</ref>.</p><p>1) Test Set I: Carter Uncapacitated Datasets: The Carter datasets have been widely used in the scientific literature <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b50">[51]</ref>. They are un-capacitated exam timetabling problems where room capacities are ignored. The constraints are shown in Table <ref type="table" target="#tab_1">III</ref>.</p><p>The quality of a timetable is measured and based on how well the soft constraints have been satisfied. The proximity cost is used to calculate the penalty cost (3) <ref type="bibr" target="#b13">[14]</ref>   Table <ref type="table" target="#tab_2">IV</ref> gives the characteristics of the uncapacitated exam timetabling benchmark problem (Toronto b type I in <ref type="bibr" target="#b50">[51]</ref>) which comprises 13 real world derived instances.</p><formula xml:id="formula_3">Soft carter = m-1 k=1 m l=k+1 (w i ×s kl )/S, i ∈ {0, 1, 2, 3, 4} (3)</formula><p>2) Test Set II: ITC 2007 Datasets: The second dataset was introduced in the second International Timetabling Competition (ITC 2007), aimed at facilitating a better understanding of real world timetabling problems and to reduce the gap between research and practice <ref type="bibr" target="#b14">[15]</ref>. It is a capacitated problem and has several hard and soft constraints (Tables V and VI, respectively).</p><p>The objective function from <ref type="bibr" target="#b14">[15]</ref> is used (see ( <ref type="formula">4</ref>)). The ITC 2007 problem has eight instances. Table <ref type="table" target="#tab_5">VII</ref> shows the main characteristics of these instances</p><formula xml:id="formula_4">Soft ITC2007 = s∈S (w 2R S 2R S + w 2D S 2D S + w PS S PS S ) + w NMD S 2NMD + w FL S FL + w p S P + w R S R .</formula><p>(4) 3) Problem Domain I: Initial Solutions: As mentioned in Section IV-A, GE-HH starts by initializing the adaptive memory mechanism, which contains a population of solutions. In this work, we employ hybrid graph coloring heuristics <ref type="bibr" target="#b51">[52]</ref> to generate an initial population of feasible solutions for both the Carter and the ITC 2007 instances. The three graph coloring heuristics we utilize are:</p><p>1) Least saturation degree first (SD): exams are ordered dynamically, in an ascending order, by the number of remaining timeslots;    The solution construction method starts with an empty timetable and applies the hybridized heuristics to select and assign the unscheduled exams one by one until all exams have been scheduled. To select an exam, the hybridized heuristic (SD + LD + LE) first sorts the unscheduled exams in a nondecreasing order of the number of available timeslots (SD). Those with equal SD evaluations are then arranged in a nonincreasing order of the number of conflicts they have with other exams (LD) and those with equal LD evaluations are then arranged in a non-increasing order of the number of student enrolments (LE). The first exam in the final order is assigned to the timetable. We assign exams to a random timeslot when it has no conflict with those that have already been scheduled (in the case of ITC 2007, an exam is assigned to best fit a room), ensuring that all hard constraints are satisfied. If some exams cannot be assigned to any available timeslot, we stop the process and start again. Although there is no guarantee that a feasible solution can be generated, for all the instances used in this work, we were always able to obtain a feasible solution.</p><p>4) Problem Domain I: Neighborhood Structures: The neighborhood structures that we employed in the GE-HH framework for both Carter and ITC 2007, which are commonly used in the literature <ref type="bibr" target="#b41">[42]</ref>, are as follows:</p><formula xml:id="formula_5">Nbe1:</formula><p>Select one exam at random and move it to any feasible timeslot-room. Nbe2:</p><p>Select two exams at random and swap their timeslots (if feasible). Nbe3:</p><p>Select two timeslots at random and swap all their exams. Nbe4:</p><p>Select three exams at random and exchanges their timeslots at random (if feasible). Nbe5:</p><p>Move the exam causing the highest soft constraint violation to any feasible timeslot. Nbe6:</p><p>Select two exams at random and move them to another random feasible timeslots. Nbe7:</p><p>Select one exam at random, select a timeslot at random (distinct from the one that was assigned to the selected exam) and then apply the Kempe chain neighborhood operator. Nbe8:</p><p>Select one exam at random, select a room at random (distinct from the one that was assigned to the selected exam) and then move the exam to the room (if feasible). Nbe9:</p><p>Select two exams at random and swap their rooms (if feasible).</p><p>Note that neighborhoods Nbe8 and Nbe9 are applied to ITC 2007 datasets only because they consider rooms. The neighborhood solution is accepted if it does not violate any hard constraints. Thus, the search space of GE-HH is limited to feasible solutions only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Problem Domain II: Capacitated Vehicle Routing Problems</head><p>The capacitated vehicle routing problem (CVRP) is a wellknown challenging combinatorial optimization problem <ref type="bibr" target="#b52">[53]</ref>. The CVRP can be defined as the process of designing a least cost set of routes to serve a set of customers <ref type="bibr" target="#b52">[53]</ref>. In this work, we test GE-HH on two sets of benchmark capacitated vehicle routing problem datasets. These are the 14 instances introduced by Christofides <ref type="bibr" target="#b15">[16]</ref> and 20 large scale instances introduced by Golden <ref type="bibr" target="#b16">[17]</ref>. The CVRP can be represented as an undirected graph G (V , E), where V = {v 0 , v 1 . . . v n } is a set of vertices which represents a set of fixed locations (customers) and E = {(v i , v j ): v i , v j ∈V , i &lt; j} represents the arc between locations (customers). E is associated with nonnegative costs or travel time defined by matrix C = (c ij ), where c ij represents the travel distance between customers v i and v j . Vertex v 0 represents the depot which is associated with m vehicles of capacity Q 1 . . . Q m to start their routes R 1 . . . R m . The remaining vertices v 1 . . . v n represent the set of customers and each customer requests q 1 . . . q n goods and serving time δ i . The aim is to find a set of tours that do not violate any hard constraints and minimize the distance. The hard constraints that must be respected are:</p><p>1) Each vehicle starts and ends at the depot.</p><p>2) The total demand of each route does not exceed the vehicle capacity. 3) Each customer is visited exactly once by exactly one vehicle. 4) The duration of each route does not exceed a global upper bound. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE IX</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Golden Instances</head><p>The cost of each route is calculated using <ref type="bibr" target="#b4">(5)</ref> [53]</p><formula xml:id="formula_6">C(R i ) = n-1 j=0 c j,j+1 + n j=0 δ i<label>(5)</label></formula><p>and the cost for one solution is calculated using ( <ref type="formula" target="#formula_7">6</ref>)</p><formula xml:id="formula_7">f = m i=1 C(R i ).<label>(6)</label></formula><p>The two sets of benchmark problems that we have considered in this work have similar constraints and objective function. However, the complexity, instance sizes, and customer distributions are different from one set to another.</p><p>1) Test Set I: Christofides Datasets: The first set comprises of 14 instances and was introduced by Christofides <ref type="bibr" target="#b15">[16]</ref>. The main characteristics of the problem are summarized in Table <ref type="table" target="#tab_5">VIII</ref>. The instance size varies from 51 to 200 customers, including the depot. Each instance has a capacity constraint. Instances 6-10, 13, and 14 also have a maximum route length restriction and non-zero service times. The problem instances can be divided into two types: in instances 1-10, the customers Results of GE-HH Compared to GE-HH* are randomly located, while in instances 11-14, the customers are in clusters.</p><p>2) Test Set II: Golden Datasets: The second CVRP dataset involves 20 large scale instances presented by Golden <ref type="bibr" target="#b16">[17]</ref> (see Table <ref type="table" target="#tab_7">IX</ref>). The instances have between 200 and 483 customers, including the depot. Instances 1-8 have route length restrictions.</p><p>3) Problem Domain II: Initial Solutions: For both the Christofides and the Golden instances, the initial population of feasible solutions is constructed utilizing the savings algorithm <ref type="bibr" target="#b53">[54]</ref>.</p><p>4) Problem Domain II: Neighborhoods Structures: The neighborhood structures that we employ in GE-HH for both the Christofides and the Golden instances are the most common ones used to solve the capacitated vehicle routing problems in the literature. They are as follows:</p><formula xml:id="formula_8">Nbv1:</formula><p>Select one customer at random and move it to any feasible route. Nbv2:</p><p>Select two customers at random and swap their routes. Nbv3:</p><p>Select one route at random and reverse a part of a tour between two selected customers. Nbv4:</p><p>Select three customers at random and exchanges their routes at random. Nbv5:</p><p>Select one route at random and perform the 2-opt procedure. Nbv6:</p><p>Perform the 2-opt procedure on all routes. Nbv7:</p><p>Select two distinct routes at random and swap a portion of the first route with the first portion and second route. Nbv8:</p><p>Select two distinct routes at random and from each route select one customer. Swap the adjacent customer of the selected one for both routes. Nbv9:</p><p>Select two distinct routes at random and swap the first portion with the last portion. Nbv10</p><p>Select one customer at random and move it to another position in the same route.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE XI</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acronyms of Compared Methods</head><p>The neighborhood solution is accepted if it does not break any hard constraints. Thus, the search space of GE-HH is limited to feasible solutions only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. Computational Results and Comparison</head><p>To assess the benefit of incorporating an adaptive memory mechanism in GE-HH, for each domain, we have carried out two sets of experiments. The first one compares the performance of the grammatical evolution hyper-heuristic with an adaptive memory (GE-HH) and the grammatical evolution hyper-heuristic without an adaptive memory (GE-HH*) using the same parameter values and computational resources. The second test compares and analyses the performance of GE-HH against the state of the art of hyper-heuristics and bespoke methods. For both experimental tests, we report the best, average, standard deviation, and average time over 51 independent runs with different random seeds. By executing 51 runs, instead of 50, we can easily calculate the median value without the need for interpolation. The aim of executing the proposed hyper-heuristic framework 51 runs is to get more information and to have a good indication regarding the algorithm consistency and generality, as it is highly recommended in the literature to have more than 30 runs in statistical analysis on algorithm performance <ref type="bibr" target="#b2">[3]</ref>. The results represent the cost </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results of GE-HH Compared to Hyper-Heuristic Approaches</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE XIII</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results of GE-HH Compared to Bespoke Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE XIV</head><p>Results of GE-HH Compared to GE-HH* and GE-HH** of soft constraint violations. In addition, we also report, for each instance, the percentage deviation from the best known value found in the literature, calculated as follows ( <ref type="formula">7</ref>):</p><formula xml:id="formula_9">(%) = best GE-HH -best * best * % (7)</formula><p>where best GE-HH is the best result obtained over 51 independent runs by GE-HH and best* represents the best known value found in the literature.</p><p>We evaluate the performance of GE-HH by considering the following three criteria:</p><p>1) Generality: We define generality as the ability of GE-HH to work well, not only across different instances of the same problem, but also across two different problem domains. 2) Consistency: This is the ability of GE-HH to produce stable results when executed several times for every instance. Typically, consistency is one of the most important criteria in evaluating any algorithm. This is because many search algorithms have a stochastic component, which leads to different solutions over multiple runs even if the initial solution is the same. We measure the consistency of GE-HH based on the average and the standard deviation, over 51 independent runs. 3) Efficiency: This is the ability of GE-HH to produce good results that are close or better than the best known value in the literature. We measure the efficiency of GE-HH by reporting, for each instance, the best and the percentage deviation, see (%) in <ref type="bibr" target="#b6">(7)</ref>, from the best known results in the literature. For all tested instances, except the ITC 2007 problem instances, we compare the GE-HH results with the state of the art in terms of solution quality rather than computational time. This is because the different computer resources researchers use make the comparison difficult, if not impossible <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b54">[55]</ref>. Therefore, we set the number of generations as the termination criterion. As for the ITC 2007 datasets, the organizer provided benchmark software to determine the allowed execution time <ref type="bibr" target="#b14">[15]</ref>. We have used this software to determine the execution time using our computer resources (i.e., 10 minutes). We have given extra time to GE-HH, due to the use of the adaptive memory (i.e., 10.83 minutes). As a result, the execution time of our method is within the range of those published in the literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problems Domain I: Computational Results on Exam Timetabling Problems</head><p>1) Test Set I: Carter Uncapacitated Datasets: Table X lists, for each instance, the best, average, standard deviation, and average time obtained by GE-HH and GE-HH*.</p><p>From Table <ref type="table" target="#tab_7">X</ref>, one can clearly see that GE-HH outperforms GE-HH* across all instances. Furthermore, both the best and average results obtained by GE-HH are better than GE-HH* on all instances. We can also see that in GE-HH, on 12 of the 13 instances, the standard deviation is lower than GE-HH*. However, the computational time is different where GE-HH* is lower than GE-HH. This is mainly due to the use of population of solutions and diversity updating mechanism in the GE-HH framework. The results reveal that the use of the adaptive memory mechanism has an effect on the ability of the GE-HH in producing good quality and consistent results over all instances.</p><p>We compare the performance of GE-HH against hyperheuristics and other bespoke methods (Table <ref type="table" target="#tab_7">XI</ref>).</p><p>Table <ref type="table" target="#tab_8">XII</ref> shows the comparison of the best and average results of GE-HH and other hyper-heuristic methods. We also report, for each instance, the percentage deviation [ (%)] from the best result obtained by other hyper-heuristics and instance ranking. As can be seen from Table <ref type="table" target="#tab_8">XII</ref>, GE-HH finds better solutions for 7 out of 13 instances compared to other hyper-heuristic methods and obtained the second best results for the other 5 instances (except Rye-s-93 which obtained third best results).</p><p>Table <ref type="table" target="#tab_8">XIII</ref> presents, for all instances, the best, average, percentage deviation [ (%)], and instance ranking by GE-HH along with a comparison with respect to the best known results (shown in bold) in the literature obtained by bespoke methods. It can be seen that, even though GE-HH does not obtain the best solutions for all instances, over all, it obtains competitive results especially when considering the percentage deviation [ (%)] from the best known value found in the literature. If we consider an individual comparison, GE-HH is able to obtain better solutions on instances <ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7</ref> Results in Tables XII and XIII demonstrate that, across all instances, GE-HH outperforms other hyper-heuristic methodologies and obtained competitive results compared to other bespoke methods. Except instance Ute-s-92 (ranked 6), the instance ranking varies between 2 to 4. Also, the percentage deviation indicates that GE-HH results are very close to the best known results. This demonstrates that GE-HH is able to generalize well over a set of problem instances rather than only producing good results for one or more of the problem instances.</p><p>2) Test Set II: ITC 2007 Datasets: The first set of experiments compares the results of GE-HH (with memory and extra computational time), GE-HH* (without memory and without    We now compare the performance of GE-HH with the best available results in the literature which are divided into two groups (see   <ref type="table" target="#tab_12">XVIII</ref>, where for 4 out of 14 instances, GE-HH achieved better results than GE-HH* (tie on 7 instances). The average results obtained by GE-HH on all instances are better than GE-HH* and the standard deviation is relatively small (varies between 0.00 and 0.93). Even though GE-HH did not outperform GE-HH* across all instances, the standard deviation reveals that GE-HH generalized well over all instances. Overall, the result implies that hybridizing the adaptive memory mechanism with GE-HH has made a significant improvement.</p><p>In Table <ref type="table" target="#tab_14">XIX</ref>, we compare the experimental results of GE-HH with the best available results in the literature. To the best of our knowledge, only two hyper-heuristics have been tested on Christofides instances (first and second methods in Table <ref type="table" target="#tab_14">XIX</ref>) and both report the percentage deviation only. Due to the large number of bespoke methods that are available in the literature, we have only considered those that have produced the best known results and some of the more recently published methods. The considered methods are classified into single based and population based solution methods (see Table <ref type="table" target="#tab_14">XIX</ref>). Table <ref type="table" target="#tab_15">XX</ref> shows the comparison of GE-HH against hyper-heuristic methods in term of percentage deviation from the best known results. We can see that, for 9 instances, GE-HH matches the best known results in the literature and for 4 instances, GE-HH produced a better quality (ranked first) when compared to other hyper-heuristics. The computational results of GE-HH compared to other bespoke methods are presented in Table <ref type="table" target="#tab_16">XXI</ref>, where for 9 out of 12 instances GE-HH has obtained the best known results. For the remaining instances, the quality of the solutions, with regard to percentage deviation, is between 1.9% and 0.11% and instance ranking varies between 2 and 4. According to this result, GE-HH is competitive with the presented bespoke methods. Considering the generality, it is obvious that GE-HH is able to produce good results across all instances and the percentage deviation is relatively small.</p><p>2) Test Set II: Golden Datasets: The computational results of GE-HH and GE-HH* are tabulated in Table <ref type="table" target="#tab_17">XXII</ref>. The presented results clearly show that GE-HH outperformed GE-HH* across all instances. Furthermore, the average and standard deviation of GE-HH is much better than GE-HH*, again indicating that the adaptive memory mechanism has a big impact on the performance and generality.</p><p>In order to assess the performance of GE-HH, the results of GE-HH are compared with the best available results in the literature. Again, due to the uncountable number of methods that have been tested on Golden instances, only those that produced the best known results and few recent methods are considered as shown in Table XXIII. To the best of our knowledge, only  <ref type="table" target="#tab_18">XXIV</ref>, one can find that, GE-HH reached the best known results for 4 out of 20 instances. For the other instances, the quality of solution (percentage deviation) is between 0.17% and 0.68% and instance ranking varies between 2 and 5. Compared to the hyper-heuristic method (first method in Table XXIV), GE-HH is able to obtain better solutions on 14 instances. When comparing with bespoke methods, for 4 instances, GE-HH reached the best known results. GE-HH produces competitive results for the remaining 16 instances compared to other bespoke methods and very close to the best known value (percentage deviation). It should be noted that bespoke methods are specifically designed to produce the best results for one or more instances, while, one can see that GE-HH is able to obtain a much higher level of generality across all instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. Discussion</head><p>As shown throughout this work, in both problem domains (exam timetabling and capacitated vehicle routing problems), GE-HH obtained competitive results, if not better (on some instances), when compared against existing best methods in the literature. GE-HH is able to update the best known results for some instances (on both domains). In both domains, our GE-HH outperformed previously proposed hyper-heuristic methods. We note that, for both domains, the standard deviation is relatively small. Also, the percentage deviation demonstrates that, in both domains, GE-HH results are very close to the best known. This positive result reveals that our GE-HH is efficient, consistent, and generalizes well over both domains. In our opinion, this is due to the following. 1) The capability of GE-HH in dealing with different problem instances by evolving different local search templates during the problem solving process. By evolving different local search templates, GE-HH can easily adapt to any changes that might occur during problem solving. 2) Since some problem instances are very difficult to solve and have many local optima, GE-HH struggles in obtaining good quality solutions without getting stuck in local optima. Therefore, by incorporating the adaptive memory mechanism, GE-HH is more effective in diversifying the search of solutions by exploring different regions. Overall,   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results of GE-HH Compared to Bespoke Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE XXIII</head><p>Acronyms of Compared Methods the benefit of the proposed method is its ability to find the best solver from the supplied pool of solvers (local search acceptance criteria) as well as the best configuration for the selected solver. This alleviates the question of which solver one should use and what is the best configuration for it. Furthermore, it does not rely on complicated search approaches to find out how to generate a local search template. Rather, it provides a general mechanism regardless of the nature and complexity of the problems. It is simple to implement, and can be easily applied to other domains without significant effort (i.e., users only need to change the set of neighborhood structures).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. Conclusion</head><p>In this work, we have proposed a new improvement based hyper-heuristic framework for combinatorial optimization problems. The proposed framework employs a grammatical evolution algorithm (GE-HH) to search the space of basic heuristic components. These are: 1) a set of acceptance criteria; 2) neighborhood structures; and 3) neighborhood combinations. They are represented by a grammar definition.</p><p>The proposed framework takes these heuristic components as input and evolves several templates of perturbation heuristics during problem solving. The performance of the GE-HH is enhanced by hybridizing it with an adaptive memory mechanism, which contains a set of high-quality and diverse solutions. To demonstrate the generality, consistency, and efficiency of the proposed framework, we have tested the proposed framework on two different and challenging problem domains, exam timetabling and capacitated vehicle routing benchmark problems, using the same parameter settings. The results demonstrate that GE-HH produces highly competitive solutions, if not better, and generalizes well across both problem domains. The main contributions of this work are 1) The development of a GE-HH framework that automatically generates templates of perturbation heuristics, demonstrating that strengths of different search algorithms can be merged into one hyper-heuristic framework.</p><p>2) The integration of an adaptive memory mechanism, which contains a collection of high quality and diverse solutions, within a hyper-heuristic framework, and which also obtained consistent results, generalized across different problem domains and produced high quality solutions, which are either competitive or better than (on some cases) other bespoke methods.</p><p>3) The development of a hyper-heuristic framework, which can be easily applied to different problem domains without much effort (i.e., the user only needs to change the neighborhood structures). Experimental results have demonstrated the effectiveness and the generality of this method on very well established benchmarks. In our future work, we intend to investigate the effectiveness of integrating GE-HH in the HyFlex framework (a benchmark framework for cross-domain heuristic search) that has been recently introduced <ref type="bibr" target="#b87">[88]</ref>, <ref type="bibr" target="#b88">[89]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. GE-HH framework.</figDesc><graphic coords="2,55.22,54.16,237.60,185.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Generic hyper-heuristic framework.</figDesc><graphic coords="3,57.50,54.00,237.60,202.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Classifications of hyper-heuristic approaches, according to two dimensions. (a) Nature of the heuristic search space. (b) Source of feedback during learning [6].</figDesc><graphic coords="3,320.52,53.40,237.60,116.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Grammatical evolution.</figDesc><graphic coords="4,55.22,53.88,237.60,160.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Example of genotype.</figDesc><graphic coords="4,318.23,54.16,237.60,50.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Solution and it is corresponding frequency matrix.</figDesc><graphic coords="8,318.23,530.95,237.60,85.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Hybrid grammatical hyper-heuristic framework and adaptive memory mechanism.</figDesc><graphic coords="9,57.50,53.56,237.60,134.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Carter's Un-Capacitated Benchmark Exam Timetabling Dataset where 1) w i = 2 |4-i| is the cost of scheduling two conflicting exams e l and e k (which have common enrolled students) with i timeslots apart, if i = |t l -t k | &lt; 5, i.e., w 0 = 16, w 1 = 8, w 2 = 4, w 3 = 2 and w 4 = 1; t l and t k as the timeslot of exam e l and e k , respectively; 2) s kl is the number of students taking both exams e k and e l , if i = |t l -t k | &lt; 5; 3) m is the number of exams in the problem; 4) S is the number of students in the problems.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>2 )</head><label>2</label><figDesc>Largest degree first (LD): exams are ordered, in a decreasing order, by the number of conflicts they have with all other exams; 3) Largest enrolment first (LE): exams are ordered by the number of students enrolled, in decreasing order.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>, and 2 compared to Mc 7 , Mc 8 , Mc 9 , Mc 10 , Mc 11 , and Mc 12 , respectively. Furthermore, only Mc 10 reported results for Purs-93 and Rye-s-93 instances, and Mc 7 and Mc 11 reported results for the Rye-s-93 instance (we suspect, due to the complexity and inconsistencies in these instances).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>extra computational time) and GE-HH** (with memory and without extra computational time). The best, average, standard deviation of the results and the average time are reported in Table XIV. It can be seen that, across all instances, GE-HH outperforms GE-HH* and GE-HH** (in most cases), not only on solution quality, but also on the average and the standard deviation. Comparing the results of GE-HH* with GE-HH**, the results demonstrate that GE-HH** outperforms GE-HH* on 5 out of 8 instances. The average and standard deviation of GE-HH** are better than GE-HH* for all tested instances. The results demonstrate the importance of incorporating the adaptive memory mechanism within GE-HH as well as implying that GE-HH is more general and consistent.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>hyper-heuristic and bespoke methods). In addition, we also included the results of GE-HH** in the comparison to assess its ability in producing good quality solutions compared to ITC 2007 winners as well as post ITC 2007 methods. It is clear from Tables XVI and XVII that GE-HH is the overall best. The presented results demonstrate that GE-HH not only generalizes well over a set of problem instances, but also produces much higher quality solutions. One can also see that GE-HH** outperformed the ITC 2007 winners on 7 instances and post ITC 2007 methods on 4 out of 8 tested instances (see TablesXVI and XVII).B. Problems Domain II: Computational Results on Capacitated Vehicle Routing Problems1) Test Set I: Christofides Datasets: The experimental results of GE-HH and GE-HH* are reported in Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="6,48.69,54.20,236.64,567.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="7,50.97,54.32,237.60,411.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="7,320.52,54.24,237.60,271.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="13,122.01,87.02,372.00,178.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="14,66.72,89.53,477.60,225.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="14,66.72,367.43,477.60,216.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="14,66.72,631.11,477.60,104.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="18,131.72,81.99,348.00,181.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="18,66.72,301.52,477.60,178.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="18,143.72,524.64,324.00,211.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="19,69.01,83.16,477.60,190.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I</head><label>I</label><figDesc>Example of the Mapping Process</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II GE</head><label>II</label><figDesc></figDesc><table><row><cell>-HH Parameters</cell></row><row><cell>TABLE III</cell></row><row><cell>Carter Hard and Soft Constraints</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE IV</head><label>IV</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE V</head><label>V</label><figDesc>ITC 2007 Hard Constraints</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE VII ITC</head><label>VII</label><figDesc></figDesc><table /><note><p>2007 Benchmark Exam Timetabling Datasets</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VIII Christofides Instances</head><label>VIIIInstances</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE X</head><label>X</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE XII</head><label>XII</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE XV</head><label>XV</label><figDesc>Acronyms of Compared Methods</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE XVI</head><label>XVI</label><figDesc>Results of GE-HH and GE-HH** on the ITC 2007 Exam Timetabling Datasets Compared to ITC 2007 Winners</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>TABLE XVII</head><label>XVII</label><figDesc>Results of GE-HH on the ITC 2007 Exam timetabling Datasets Compared to Post-ITC 2007 Approaches</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE XVIII Results</head><label>XVIII</label><figDesc></figDesc><table /><note><p>of GE-HH Compared to GE-HH*</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table XV )</head><label>XV</label><figDesc>: ITC 2007 winners (see Table XVI) and Post-ITC 2007 (see Table XVII</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>TABLE XIX</head><label>XIX</label><figDesc>Acronyms of Compared Methodsone hyper-heuristic (first method in TableXXIII) has been tested on Golden instances. TableXXIVgives the comparison results. From Table</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>TABLE XX</head><label>XX</label><figDesc>Results of GE-HH Compared to Hyper-Heuristic Methods</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>TABLE XXI</head><label>XXI</label><figDesc>Results of GE-HH Compared to Bespoke Methods</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>TABLE XXII</head><label>XXII</label><figDesc>Results of GE-HH Compared TO GE-HH*</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>TABLE XXIV</head><label>XXIV</label><figDesc></figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the UKM Action Research Grant Scheme (UKM-PTS-011-2009), and in part by the Fundamental Research Grant Scheme (UKM-TT-02-FRGS 0121-2009) N. R. Sabar is with Data Mining and Optimization Research Group (DMO), University Kebangsaan Malaysia, UKM Bangi 43600, Selangor, Malaysia, and also with the</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>She is currently an Associate Professor in the School of Computer Science, University of Nottingham. Her research interests include meta-heuristics, constraint programming, mathematical programming, case based reasoning and knowledge discovery techniques on scheduling, especially educational timetabling, healthcare personnel scheduling and network routing problems, and a range of combination optimization problems including portfolio optimization.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Stochastic local search: Foundations and applications</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stützle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Mateo, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Why is optimization difficult?,&quot; in Nature-Inspired Algorithms for Optimisation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zapf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nebro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="1" to="50" />
			<pubPlace>Berlin, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Talbi</surname></persName>
		</author>
		<title level="m">Metaheuristics from Design to Implementation</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Handbook of Metaheuristics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gendreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Potvin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Springer Verlag</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">No free lunch theorems for optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Wolpert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Macready</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="82" />
			<date type="published" when="1997-04">Apr. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A classification of hyper-heuristic approaches</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hyde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ochoa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Woodward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Metaheuristics</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Gendreau</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Potvin</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="page" from="449" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">What is autonomous search?</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hamadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Monfroy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Saubion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hybrid Optimization</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="357" to="391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">There is a free lunch for hyper-heuristics, genetic programming and computer scientists</title>
		<author>
			<persName><forename type="first">R</forename><surname>Poli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Graff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic Programming</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="195" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cross-disciplinary perspectives on meta-learning for algorithm selection</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Smith-Miles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Parameter control in evolutionary algorithms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Eiben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hinterding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="124" to="141" />
			<date type="published" when="1999-07">Jul. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Reactive search optimization: Learning while optimizing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Battiti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brunato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Metaheuristics</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="543" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Meta-Lamarckian learning in memetic algorithms</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Keane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="110" />
			<date type="published" when="2004-04">Apr. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Self-adaptive multimethod search for global optimization in real-parameter spaces</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Vrugt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hyman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="243" to="259" />
			<date type="published" when="2009-04">Apr. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Examination timetabling: Algorithmic strategies and applications</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Laporte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Oper. Res. Soc</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="373" to="383" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Setting the research agenda in automated timetabling: The second international timetabling competition</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mccollum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schaerf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Paechter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mcmullan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Parkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Gaspero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Burke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INFORMS J. Comput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="120" to="130" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The vehicle routing problem</title>
		<author>
			<persName><forename type="first">N</forename><surname>Christofides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mingozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Toth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Combinator. Optimiz</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">315338</biblScope>
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Very large-scale vehicle routing: New test problems, algorithms, and results</title>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Golden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wasil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1165" to="1179" />
			<date type="published" when="2005-05">May 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hyperheuristics: Recent developments</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chakhlevitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cowling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adaptive and Multilevel Metaheuristics</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="3" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A tabu-search hyperheuristic for timetabling and rostering</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Soubeiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Heurist</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="451" to="470" />
			<date type="published" when="2003-12">Dec. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A genetic programming hyper-heuristic approach for evolving 2-D strip packing heuristics</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hyde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Woodward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="942" to="958" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Grammatical evolution of local search heuristics</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Hyde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kendall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="406" to="417" />
			<date type="published" when="2012-06">Jun. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">DVRP: A hard dynamic combinatorial optimisation problem tackled by an evolutionary hyper-heuristic</title>
		<author>
			<persName><forename type="first">P</forename><surname>Garrido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Riff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Heurist</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="40" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hybridizations within a graph-based hyperheuristic framework for university timetabling problems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Burke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Oper. Res. Soc</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="1273" to="1285" />
			<date type="published" when="2009-09">Sep. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hyperheuristics: Learning to combine simple heuristics in bin-packing problems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schulenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Mar Ín-Blázquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GECCO</title>
		<meeting>GECCO</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="942" to="948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automated discovery of local search heuristics for satisfiability testing</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Fukunaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="61" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Generating SAT local-search heuristics using a GP hyper-heuristic framework</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bader-El-Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Poli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th Int. Conf. Artif. Evol</title>
		<meeting>8th Int. Conf. Artif. Evol</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="37" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Evolving dispatching rules using genetic programming for solving multiobjective flexible job-shop problems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Ind. Eng</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="453" to="473" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A histogram-matching approach to the evolution of bin-packing strategies</title>
		<author>
			<persName><forename type="first">R</forename><surname>Poli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Woodward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Burke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CEC</title>
		<meeting>IEEE CEC</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="3500" to="3507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Hyper-heuristics: A survey of the state of the art</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hyde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ochoa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ozcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Qu</surname></persName>
		</author>
		<idno type="DOI">10.1057/jors.2013.71</idno>
	</analytic>
	<monogr>
		<title level="j">J. Oper. Res. Soc., in press</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Grammatical evolution</title>
		<author>
			<persName><forename type="first">M</forename><surname>O'neill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ryan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="349" to="358" />
			<date type="published" when="2001-08">Aug. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Grammar-based genetic programming: A survey</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Mckay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">X</forename><surname>Hoai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Whigham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>O'neill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetic Program. Evolvable Mach</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="365" to="396" />
			<date type="published" when="2010-09">Sep. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Development and application of hyperheuristics to personnel scheduling</title>
		<author>
			<persName><forename type="first">E</forename><surname>Soubeiga</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Nottingham, U.K.</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Optimisation and Planning Research Group, School of Computer Science, Univ. Nottingham</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A cooperative hyper-heuristic search framework</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ouelhadj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Petrovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Heurist</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="835" to="857" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A Monte Carlo hyper-heuristic to optimise component placement sequencing for multihead placement machine</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ayob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kendall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Intell. Technol</title>
		<meeting>Int. Conf. Intell. Technol</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="132" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Iterated local search vs. hyper-heuristics: Towards general-purpose search algorithms</title>
		<author>
			<persName><forename type="first">E</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Curtois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hyde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ochoa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Petrovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vazquez-Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gendreau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CEC</title>
		<meeting>IEEE CEC</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Variable neighbourhood search: Methods and applications</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mladenović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Moreno Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="319" to="360" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Neighborhood analysis: A case study on curriculum-based course timetabling</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lü</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Heurist</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="97" to="118" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Tabu search and adaptive memory programming-Advances, applications and challenges</title>
		<author>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interfaces in Computer Science and Operations Research</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A theoretician&apos;s guide to the experimental analysis of algorithms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Math. Soc</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="page" from="215" to="250" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Neighborhood portfolio approach for local search applied to timetabling problems</title>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Gaspero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schaerf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Model. Algorithms</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="89" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Progressive tree neighborhood applied to the maximum parsimony problem</title>
		<author>
			<persName><forename type="first">A</forename><surname>Goëffon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Richer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Hao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Comput. Biol. Bioinform</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="136" to="145" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Hybrid variable neighbourhood approaches to university exam timetabling</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Eckersley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mccollum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Petrovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">206</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="46" to="53" />
			<date type="published" when="2010-10">Oct. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Design and statistical analysis of a hybrid local search algorithm for course timetabling</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bellio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Di</forename><surname>Gaspero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schaerf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Schedul</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="61" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Hybrid metaheuristics</title>
		<author>
			<persName><forename type="first">C</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Puchinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Raidl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hybrid Optimization</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="305" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A taxonomy of hybrid metaheuristics</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Talbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Heurist</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="541" to="564" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Adaptive memory programming: A unified view of metaheuristics</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Taillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gendreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Potvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2001-11">Nov. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Cosearch: A parallel cooperative metaheuristic</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Talbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bachelet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Model. Algorithms</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="22" />
			<date type="published" when="2006-04">Apr. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Genetic hybrids for the quadratic assignment problem</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fleurent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ferland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">DIMACS Series in Discrete Mathematics and Theoretical Computer Science</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Amer. Math. Soc</publisher>
			<pubPlace>Providence, RI, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Efficient relevance estimation and value calibration of evolutionary algorithm parameters</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nannen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Eiben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CEC</title>
		<meeting>IEEE CEC</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="103" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A survey of automated timetabling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schaerf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Rev</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="87" to="127" />
			<date type="published" when="1999-04">Apr. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A survey of search methodologies and automated system development for examination timetabling</title>
		<author>
			<persName><forename type="first">R</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mccollum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T G</forename><surname>Merlot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Schedul</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="89" />
			<date type="published" when="2009-02">Feb. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Solving a practical examination timetabling problem: A case study</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ayob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Abdullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hamdan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCSA</title>
		<meeting>ICCSA</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="611" to="624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">The Vehicle Routing Problem</title>
		<author>
			<persName><forename type="first">P</forename><surname>Toth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vigo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>SIAM</publisher>
			<biblScope unit="volume">9</biblScope>
			<pubPlace>Philadelphia, PA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Scheduling of vehicles from a central depot to a number of delivery points</title>
		<author>
			<persName><forename type="first">G</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="568" to="581" />
			<date type="published" when="1964-08">Jul.-Aug. 1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Comparison of metaheuristics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Silberholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Golden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Metaheuristics</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="625" to="640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Fuzzy multiple heuristic orderings for examination timetabling</title>
		<author>
			<persName><forename type="first">H</forename><surname>Asmuni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Garibaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mccollum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Practice and Theory of Automated Timetabling V</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="334" to="353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A graph-based hyper-heuristic for educational timetabling problems</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mccollum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Meisels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Petrovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="177" to="192" />
			<date type="published" when="2007-01">Jan. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A study of heuristic combinations for hyper-heuristic systems for the uncapacitated examination timetabling problem</title>
		<author>
			<persName><forename type="first">N</forename><surname>Pillay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Banzhaf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">197</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="482" to="491" />
			<date type="published" when="2009-09">Sep. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Adaptive automated construction of hybrid heuristics for exam timetabling and graph colouring problems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mccollum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">198</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="392" to="404" />
			<date type="published" when="2009-10">Oct. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A hybrid algorithm for the examination timetabling problem</title>
		<author>
			<persName><forename type="first">L</forename><surname>Merlot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Boland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stuckey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Practice and Theory of Automated Timetabling IV</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="207" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Enhancing timetable solutions with local search methods</title>
		<author>
			<persName><forename type="first">E</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Newall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Practice and Theory of AutomatedTimetabling IV</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="195" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A Multi-start large neighbourhood search approach with local search methods for examination timetabling</title>
		<author>
			<persName><forename type="first">S</forename><surname>Abdullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Burke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Automated Planning Scheduling (ICAPS)</title>
		<meeting>Int. Conf. Automated Planning Scheduling (ICAPS)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="334" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Novel local-searchbased approaches to university examination timetabling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Caramia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dell'olmo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Italiano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INFORMS J. Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">86</biblScope>
			<date type="published" when="2008">2008</date>
			<pubPlace>Winter</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A novel similarity measure for heuristic selection in examination timetabling</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Petrovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Practice and Theory of Automated Timetabling V</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="247" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Solving exam timetabling problems with the flex-deluge algorithm</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bykov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th Int. Conf. Practice Theory Autom. Timetabling</title>
		<meeting>6th Int. Conf. Practice Theory Autom. Timetabling</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="370" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">ITC2007 solver description: A hybrid approach</title>
		<author>
			<persName><forename type="first">T</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="page" from="429" to="446" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A multi-staged algorithmic process for the solution of the examination timetabling problem</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gogos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Alefragis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Housos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. PATAT</title>
		<meeting>PATAT</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="19" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">ITC2007 Track 2, an approach using general CSP solver</title>
		<author>
			<persName><forename type="first">M</forename><surname>Atsuta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nonobe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ibaraki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. PATAT</title>
		<meeting>PATAT</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="19" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Itc2007-Examination track</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">De</forename><surname>Smet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. PATAT</title>
		<meeting>PATAT</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="19" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Developmental approach to the examination timetabling problem</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pillay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. PATAT</title>
		<meeting>PATAT</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="19" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Adaptive selection of heuristics for improving constructed exam timetables</title>
		<author>
			<persName><forename type="first">E</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Soghier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. PATAT , 2010, pp</title>
		<meeting>PATAT , 2010, pp</meeting>
		<imprint>
			<biblScope unit="page" from="136" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Evolving hyper-heuristics for a highly constrained examination</title>
		<author>
			<persName><forename type="first">N</forename><surname>Pillay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. PATAT</title>
		<meeting>PATAT</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="336" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">An improved multi-staged algorithmic process for the solution of the examination timetabling problem</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gogos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Alefragis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Housos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">An extended great deluge approach to the examination timetabling problem</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mccollum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mcmullan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Parkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Abdullah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th Multidisciplin. Int. Conf. Schedul.: Theory Appl</title>
		<meeting>4th Multidisciplin. Int. Conf. Schedul.: Theory Appl</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="424" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Stable solving of CVRPs using hyperheuristics</title>
		<author>
			<persName><forename type="first">P</forename><surname>Garrido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Castro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GECCO</title>
		<meeting>GECCO</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="255" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Coalition-based metaheuristic: A self-adaptive metaheuristic using reinforcement learning and mimetism</title>
		<author>
			<persName><forename type="first">D</forename><surname>Meignan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Koukam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Créput</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Heurist</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Parallel iterative search methods for vehicle routing problems</title>
		<author>
			<persName><forename type="first">É</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Taillard</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Networks</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="661" to="673" />
			<date type="published" when="1993-12">Dec. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">A tabu search heuristic for the vehicle routing problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gendreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Laporte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Manage. Sci</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1276" to="1290" />
			<date type="published" when="1994-10">Oct. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Probabilistic diversification and intensification in local search for vehicle routing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Rochat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">É</forename><forename type="middle">D</forename><surname>Taillard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Heurist</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="147" to="167" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">The granular tabu search and its application to the vehicle-routing problem</title>
		<author>
			<persName><forename type="first">P</forename><surname>Toth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INFORMS J. Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">333</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">A self-adaptive local search algorithm for the classical vehicle routing problem</title>
		<author>
			<persName><forename type="first">C</forename><surname>Alabas-Uslu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dengiz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="8990" to="8998" />
			<date type="published" when="2011-07">Jul. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">A hybrid genetic-Particle Swarm Optimization Algorithm for the vehicle routing problem</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Marinakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marinaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1446" to="1455" />
			<date type="published" when="2010-03">Mar. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">A new Hybrid Electromagnetism-like Algorithm for capacitated vehicle routing problems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Yurtkuran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Emel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="3427" to="3433" />
			<date type="published" when="2010-04">Apr. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">A general heuristic for vehicle routing problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pisinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ropke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2403" to="2435" />
			<date type="published" when="2007-08">Aug. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Active-guided evolution strategies for large-scale capacitated vehicle routing problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Braysy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2964" to="2975" />
			<date type="published" when="2007-10">Oct. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Edge assembly crossover for the capacitated vehicle routing problem</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nagata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Computation in Combinatorial Optimization</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="142" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Bumble bees mating optimization algorithm for the vehicle routing problem</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Marinakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marinaki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="347" to="369" />
			<pubPlace>Berlin, Germany</pubPlace>
		</imprint>
	</monogr>
	<note>Handbook of Swarm Intelligence</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">HyFlex: A benchmark framework for cross-domain heuristic search evolutionary computation in combinatorial optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ochoa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hyde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Curtois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vazquez-Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gendreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mccollum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Parkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Petrovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Burke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Computation in Combinatorial Optimization</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="136" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">The cross-domain heuristic search challenge-An international research Competition &quot; in Learning and Intelligent Optimization</title>
		<author>
			<persName><forename type="first">E</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gendreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hyde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mccollum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ochoa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Parkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Petrovic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="631" to="634" />
			<pubPlace>Berlin, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Sabar received the B.Sc. degree in computer science from the University of Al-Anbar</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nasser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2005, and the M.Phil. and Ph.D. degrees in computer science from the National University of Malaysia</title>
		<meeting><address><addrLine>Al-Anbar, Iraq; Selangor, Malaysia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010 and 2013</date>
		</imprint>
	</monogr>
	<note>respectively</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
