<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Minimizing the makespan in a two-machine cross-docking flow shop problem q</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2007-11-07">7 November 2007</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Feng</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Industrial Engineering and Management</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Chung-Yee</forename><surname>Lee</surname></persName>
							<email>cylee@ust.hk</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Industrial Engineering and Logistics Management</orgName>
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
								<address>
									<addrLine>Clearwater Bay</addrLine>
									<settlement>Kowloon, Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Minimizing the makespan in a two-machine cross-docking flow shop problem q</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2007-11-07">7 November 2007</date>
						</imprint>
					</monogr>
					<idno type="MD5">C8707EE40FE957C977DCE7A0DD41F08A</idno>
					<idno type="DOI">10.1016/j.ejor.2007.10.051</idno>
					<note type="submission">Received 30 June 2005; accepted 26 October 2007</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Machine scheduling</term>
					<term>Logistics</term>
					<term>Cross-docking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper studies a two-machine cross-docking flow shop scheduling problem in which a job at the second machine can be processed only after the processing of some jobs at the first machine has been completed. The objective is to minimize the makespan. We first show that the problem is strongly NP-hard. Some polynomially solvable special cases are provided. We then develop a polynomial approximation algorithm with an error-bound analysis. A branch-and-bound algorithm is also constructed. Computational results show that the branch-and-bound algorithm can optimally solve problems with up to 60 jobs within a reasonable amount of time.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In the past decade, the cross-docking problem has led to relatively new logistics techniques in the retail, grocery, and other distribution industries. The idea is to transfer shipments directly from inbound to outbound trailers without storage in between. In a traditional warehousing system, goods are received from vendors and stored in devices like pallet racks or shelving. When a customer requests an item, workers take the item from the shelves and send it to the destination. However, if the customer request is assigned when the goods are arriving from the vendor, the workers only need to move the shipment from the inbound trailer to an outbound trailer for the appropriate destination with the result being less inventory or none. A system meeting this aim is called cross docking. Clearly, cross docking will consolidate shipments from disparate sources and help distributors/suppliers to realize economies of scale in outbound transportation. Walmart is well known as a pioneer in implementing cross-docking operations. Today, almost all third-party logistics companies in Hong Kong are implementing cross-docking systems.</p><p>There are many papers related to cross docking <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref>. Yet very few of them have addressed the problem from a scheduling point-of-view. Consider a cross-dock setting in a third party logistics company in which we assume that there are n inbound carriers. Each of them carries a specific type of product that may be needed by several destinations. We first need to download and unpack the product in each inbound carrier. There are m outbound trailers each carries several products with the same destination. We assume that due to space constraint, there is only one outbound trailer working at any time and it will work only if all products need to be loaded on to that trailer are ready. Clearly, an outbound trailer cannot leave the dock until it has collected all products that need to be loaded on to that trailer. In this situation, the scheduling of inbound products download-and-unpack operations will affect the efficiency of the cross-docking system as well as that of the total supply chain system. Our purpose is to sequence the download-and-unpack operations for the inbound carriers as well as the collecting operations for outbound trailers to minimize the makespan. We formulate this problem as a two-machine flow shop problem, where an operation on the first machine is to download and unpack the inbound products (we call it a job), while collecting those products with the same destination into an outbound trailer is considered as an operation (also we call it a job) on the second machine. Note that an operation on the second machine can not start unless the corresponding product has been downloaded and unpacked on the first machine. Our purpose is to sequence the inbound carriers as well as to sequence outbound trailers to minimize the makespan. This scheduling problem is similar to the classical two-machine flow shop problem. Clearly, if each destination needs only one product, the problem can be reduced to the classical two-machine flow shop problem.</p><p>This paper is organized as follows. In Section 2, we mathematically define the problem and provide some optimality properties. In Section 3, we prove that our problem is strongly NP-hard. Section 4 introduces some special cases that are polynomially solvable. In Section 5, a heuristic is presented for the general problem. Then, in Section 6, we describe a branch and bound algorithm. Computational tests and results are given in Section 7. Section 8 includes concluding remarks and further research direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Notation and optimality properties</head><p>In the classical two-machine flow shop problem, we are given two machines, M 1 and M 2 , and a set of n jobs, J ¼ fJ 1 ; J 2 ; . . . ; J n g. Each J i ; i ¼ 1; . . . ; n, must be processed first on M 1 and then on M 2 , and requires processing times of uðiÞ and vðiÞ, respectively. The problem of minimizing the makespan is denoted as F 2kC max and is known to be polynomially solvable by Johnson's algorithm <ref type="bibr" target="#b7">[8]</ref>. We are now ready to state our problem. We call our problem the Two-Machine Cross-Docking Flow Shop Problem. Following the standard classification scheme <ref type="bibr" target="#b8">[9]</ref>, our problem is denoted as F 2jCDjC max .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F 2jCDjC max</head><p>Problem: There are two machines, M 1 and M 2 , and two sets of jobs, J 1 ¼ fJ 11 ; J 21 ; . . . ; J n1 g and J 2 ¼ fJ 12 ; J 22 ; . . . ; J m2 g, where each J i1 ; i ¼ 1; . . . ; n; must be processed on M 1 , and requires a processing time of p i1 , and each J j2 ; j ¼ 1; . . . ; m, must be processed on M 2 and requires a processing time of p j2 . For each J j2 in J 2 , there is a corresponding subset of J 1 , call it S j , such that J j2 can be processed on M 2 only after all jobs in S j have been completed on M 1 . Our purpose is to sequence jobs in J 1 on M 1 and jobs in J 2 on M 2 such that the makespan, i.e., the finishing time of all jobs on the second machine, is minimized.</p><p>Note that if m = n and S j ¼ fJ j1 g for all j, then our problem will lead to the classical model F 2kC max . Also, we assume that all jobs in J 1 will be used by the jobs in J 2 , i.e., [ m j¼1 S j ¼ J 1 . Otherwise, we can process jobs in [ m j¼1 S j first, then J 1 n [ m j¼1 S j on M 1 . We have the following optimality properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Property 1</head><p>(i) There exists an optimal schedule such that if the completion time of jobs in set S j is earlier than that of S k on M 1 ; 1 6 j; k 6 m, then J j2 is processed before J k2 on M 2 . (ii) There exists an optimal schedule such that if jobs in J 2 are processed on M 2 in the sequence J 12 , J 22 ; . . . ; J m2 (after re-indexed), then jobs are processed on M 1 in the following order:</p><formula xml:id="formula_0">S 1 ; S 2 n S 1 ; S 3 n ðS 1 [ S 2 Þ; . . . ; S m n [ mÀ1 j¼1 S j .</formula><p>Proof (i) If not, i.e., J j2 is processed after J k2 on M 2 , we can move J j2 to start at the starting time of J k2 and move all jobs originally between J k2 and J j2 (including J k2 ) to the right by p j2 . The new solution is still feasible without increasing the makespan. (ii) If jobs in S 1 are not processed first, we just move them to the first jS 1 j positions and move other affected jobs to the right accordingly. After the move, the schedule is still feasible without increasing the makespan. We can then move jobs in S 2 n S 1 to be processed immediately after S 1 and move other affected jobs to the right accordingly. After the move, the schedule is still feasible without increasing the makespan. Repeat the process eventually we reach our goal. h Property 2. If S j S k ; 1 6 j; k 6 m, then there exists an optimal schedule such that J j2 is processed before J k2 on M 2 .</p><p>Proof. If not, we can move J j2 to start at the starting time of J k2 and move all jobs originally between J k2 and J j2 (including J k2 ) to the right by p j2 . The new solution is still feasible without increasing the makespan. h Corollary 1. If S j ¼ J 1 for some j; 1 6 j 6 m, then there exists an optimal solution such that J j2 is processed at the last position on M 2 .</p><p>Property 3. For a given j; 1 6 j 6 m, if S j \ S k ¼ ; for all k, with k 6 ¼ j and 1 6 k 6 m, then there exists an optimal solution such that jobs in S j are processed consecutively on M 1 .</p><p>Proof. If not, we just move all jobs in S j to the right to make them be processed consecutively and finish at the same time as before. Those jobs affected and not in S j will be moved to the left accordingly. The new solution is still feasible without increasing the makespan. h Property 4. For a given i, 1 6 i 6 n, if J i1 2 S j for all j; 1 6 j 6 m, then there exists an optimal solution such that J i1 is processed at the first position on M 1 .</p><p>Proof. If not, just move J i1 to be processed at the first position on M 1 and those jobs affected will then be moved to the right accordingly. The new solution is still feasible without increasing the makespan. h</p><p>Corollary 2. For a given set S J 1 , if S S j for all j; 1 6 j 6 m, then there exists an optimal solution such that jobs in S are processed consecutively and are processed first before other jobs on M 1 .</p><p>Remark 1. We denote the instance of our problem as ðJ 1 ; P 1 ; J 2 ; P 2 ; SÞ, where P 1 ¼ ðp 11 ; p 21 ; . . . ; p n1 Þ; P 2 ¼ ðp 12 ; p 22 ; . . . ; p m2 Þ; S ¼ fS 1 ; S 2 ; . . . ; S m g. Our problem is reversible. Namely, given an instance, ðJ 1 ; P 1 ; J 2 ; P 2 ; SÞ of F 2jCDjC max , if we let S 0 i ¼ fJ j2 jJ i1 2 S j ; j ¼ 1; 2; . . . ; mg; i ¼ 1; . . . ; n; S 0 ¼ fS 0 1 ; S 0 2 ; . . . ; S 0 n g, then the instance of ðJ 2 ; P 2 ; J 1 ; P 1 ; S 0 Þ has the same optimal makespan value as that of ðJ 1 ; P 1 ; J 2 ; P 2 ; SÞ and their optimal solutions can be transformed to each other in polynomial time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Problem complexity</head><p>We will show that our problem F 2jCDjC max is strongly NP-hard by transforming a well known strongly NP-hard problem, F 2jprecjC max <ref type="bibr" target="#b11">[12]</ref>, to our problem in polynomial time. F 2jprecjC max can be stated as follows.</p><p>There is a set of jobs, J ¼ fJ 1 ; J 2 ; . . . ; J n g, and two machines, M 1 and M 2 . For j ¼ 1; . . . ; n, job J j is processed on M 1 and then processed on M 2 with the processing times, p j1 and p j2 , respectively. Furthermore, there is a precedence relation (partial order) of jobs, R, in which, if ðJ i ; J j Þ 2 R then job J j cannot start on any machine until job J i is completed on that machine and is denoted as J i ! J j . This relationship is usually represented by a reduction digraph <ref type="bibr" target="#b4">[5]</ref>. The objective is to minimize the makespan, i.e., the finishing time of all jobs on M 2 .</p><p>It has been shown in <ref type="bibr" target="#b11">[12]</ref> that F 2jprecjC max is strongly NP-hard if the reduction graph is an arbitrary acyclic digraph (see also <ref type="bibr" target="#b4">[5]</ref>). Furthermore, a two-machine flow shop problem with series-parallel precedence relations can be solved polynomially <ref type="bibr" target="#b12">[13]</ref>. An O(nlogn) algorithm for this type of precedence relation can be found in <ref type="bibr" target="#b10">[11]</ref> and <ref type="bibr" target="#b16">[17]</ref>. To the best of our knowledge, few papers have focused on the heuristics and there is no algorithm with a constant performance ratio for the F 2jprecjC max problem. In the remainder of this section, when we mention the problem F 2jprecjC max , we assume that the reduction graph is an arbitrary acyclic digraph. Hence, F 2jprecjC max is strongly NP-hard. Before we analyze the complexity of our problem, we first provide the following observation.</p><p>Given a schedule r for F 2jprecjC max or F 2jCDjC max , we denote r ¼ ðr 1 ; r 2 Þ, where r 1 ; r 2 are sequences of jobs on M 1 and M 2 , respectively. Let B i ðr 1 Þ and C i ðr 1 Þ denote the starting and completion time of J i (in F 2jprecjC max Þ or J i1 (in F 2jCDjC max ) on M 1 , respectively. Similarly, let B j ðr 2 Þ and C j ðr 2 Þ denote the starting and completion time of J j or J j2 on M 2 , respectively.</p><p>It can be seen that a schedule r ¼ ðr 1 ; r 2 Þ is feasible for F 2jprecjC max if it satisfies the following three conditions: Condition A: For any j, J j finishes on M 1 before it starts to be processed on M 2 , i.e., C j ðr 1 Þ 6 B j ðr 2 Þ. Condition B: For any two jobs, J i and J j , with J i ! J j ; J i is processed before</p><formula xml:id="formula_1">J j on M 1 , i.e., C i ðr 1 Þ 6 B j ðr 1 Þ.</formula><p>Condition C: For any two jobs, J i and J j , with J i ! J j ; J i is processed before</p><formula xml:id="formula_2">J j on M 2 , i.e., C i ðr 2 Þ 6 B j ðr 2 Þ.</formula><p>If r satisfies Conditions A, B, and C, then we say that r is A-feasible, B-feasible, and C-feasible to F 2jprecjC max , respectively. Hence, if r is A-feasible, B-feasible and C-feasible simultaneously, it is feasible for F 2jprecjC max .</p><p>Theorem 1. F 2jCDjC max is strongly NP-hard.</p><p>Proof. We show that F 2jCDjC max is strongly NP-hard by transforming F 2jprecjC max to our problem in polynomial time. Given an instance of F 2jprecjC max with J ¼ fJ 1 ; J 2 ; . . . ; J n g; P 1 ¼ ðp 11 ; p 21 ; . . . ; p n1 Þ; P 2 ¼ ðp 12 ; p 22 ; . . . ; p n2 Þ, a precedence relation R, and a positive integer M, the question we ask is ''can we find a feasible schedule for F 2jprecjC max with makespan no greater than M?" We now construct an instance for our problem F 2jCDjC max as follows.</p><p>Generate n jobs for M 1 and n jobs for M 2 , with processing times p j1 , and p j2 for j ¼ 1; . . . ; n, respectively. Namely, J 1 ¼ J 2 ¼ J . Recall that in F 2jprecjC max , a precedence relation is represented by an induced graph. For J j 2 J , if J j has no precedent job, then let S j ¼ fJ j1 g. On the other hand, if J j has at least one precedent job, then we let S j be the set of jobs that include job J j1 plus all jobs corresponding to the precedent nodes of J j1 in its induced graph. Because each J j 2 J has at most n À 1 precedent jobs, and each node in the induced acyclic graph has at most n À 1 precedent nodes, we can construct all S j in a polynomial time. Hence, it is a polynomial transformation. Clearly, it is also a pseudo-polynomial transformation <ref type="bibr">[4, p. 101</ref>]. Let the threshold value be M.</p><p>The question we ask is ''can we find a feasible schedule for F 2jCDjC max with a makespan no greater than M?" ? If there exists a feasible schedule of F 2jprecjC max with a makespan no greater than M, then by (i) the construction of the problem instance, (ii) the definition of cross-docking, and (iii) the assumption that the reduction graph is an acyclic digraph, we know that the same schedule is also feasible for F 2jCDjC max with the same makespan (no greater than M).</p><p>If there exists a feasible schedule of F 2jCDjC max with a makespan no greater than M, let the schedule be denoted as r ¼ ðr 1 ; r 2 Þ, where r 1 and r 2 are the sequences of J 1 on M 1 and J 2 on M 2 , respectively. Note that even though r ¼ ðr 1 ; r 2 Þ is feasible to F 2jCDjC max , it may be infeasible to F 2jprecjC max .</p><p>By the construction of the instance of F 2jCDjC max and the definition of cross-docking, it is clear that r is A-feasible to F 2jprecjC max . Suppose that r is already A-feasible but not B-feasible to F 2jprecjC max , i.e., there exist J i and J j with J i ! J j but C i ðr 1 Þ &gt; B j ðr 1 Þ (see Fig. <ref type="figure">1</ref>). Note that by definition of cross-docking, both B i ðr 2 Þ and B j ðr 2 Þ cannot be less than C i ðr 1 Þ.</p><p>In such a case, we move J j to the right immediately after J i to finish at C i ðr 1 Þ on M 1 . We push the sub-sequence originally between J j and J i (including J i Þ on M 1 accordingly to the left (see Fig. <ref type="figure">2</ref>). We call this operation Shifting Operation between J j and J i on M 1 . After the shifting, we denote the new schedule as r 0 ¼ ðr 0 1 ; r 2 Þ. Observation 1. If J j ! J e for some e then J i ! J j implies that J i1 will be included in S e by the construction of the instance. Hence, in such a case, B e ðr 2 Þ P C i ðr 1 Þ. Thus after the shifting operation between J j and J i on M 1 , the new schedule r 0 ¼ ðr 0 1 ; r 2 Þ is still A-feasible to F 2jprecjC max without increasing the makespan.</p><p>Note also that after the above shifting operation J i and J j will satisfy C i ðr 0 1 Þ 6 B j ðr 0 1 Þ. However, it may happen that if J j ! J e and J j is processed before J e on M 1 (see Fig. <ref type="figure">1</ref>) in r, yet J j will process behind J e in r 0 (after our shifting operation) and therefore will violate Condition B. Fortunately, as shown in the following, the above shifting operation could be performed in certain order so that r could eventually be transferred into a B-feasible schedule of F 2jprecjC max within polynomial time.</p><p>Assume r 1 ¼ ðJ i 1 ; J i 2 ; . . . ; J in Þ, we perform the following precedence violation check between the (currently) last position job J in and other jobs, fJ i 1 ; J i 2 ; . . . ; J i nÀ1 g on M 1 . Start from J i nÀ1 and then J i nÀ2 ; . . ., and perform Shifting Operation between J i k and J in on M 1 ; 1 6 k 6 n À 1, should J i k and J in violate the Condition B (i.e. J in ! J i k , yet C in ðr 1 Þ &gt; B i k ðr 1 Þ). After finish the checking and possible shifting operations between J in and each job in fJ i 1 ; J i 2 ; . . . ; J i nÀ1 g, we will end up with a subset of jobs, S, followed by J in , then followed by fJ i 1 ; J i 2 ; . . . ; J i nÀ1 g n S, where S is a subset of fJ i 1 ; J i 2 ; . . . ; J i nÀ1 g. Note that similar to the argument in Observation 1, the new schedule is still A-feasible.</p><p>If fJ i 1 ; J i 2 ; . . . ; J i nÀ1 g n S ¼ ;, then we fix J i n as the last position job permanently and continue. Otherwise, fJ i 1 ; J i 2 ; . . . ; J i nÀ1 g n S 6 ¼ ;. In such a case, J in ! J j for all J j 2 fJ i 1 ; J i 2 ; . . . ; J i nÀ1 g n S. Let the last job in the sequence of fJ i 1 ; J i 2 ; . . . ; J i nÀ1 g n S be J k . Clearly, J in ! J k . Start from the second to the last job (i.e. next to J k ) and continue to the left, we perform the Shifting Operation between that job and J k , should they violate the Condition B. Once again, after finish all such checking and possible shifting operations, we will either find no job to be sequenced after J k (and hence we fix J k as the last position job permanently), or find one job that is not J k (and can not be J in either) in the last position. In the later case, we will continue the Condition B checking and possible shifting operations between the currently last position job and all other jobs. Note that after at most n À 1 rounds of such checking and possible shifting operations, we will fix a job as the last position job permanently. Furthermore, similar to Observation 1, the new schedule is still A-feasible without increasing the makespan. Continue the procedures, after at most n À 2 rounds of Condition B checking and possible shifting operations, we will fix the second to last position job permanently. Repeat the procedures, eventually we will fix all jobs in polynomial time, and find a new schedule which is B-feasible without increasing the makespan.</p><p>Suppose that r is already A-feasible and B-feasible yet not C-feasible for F 2jprecjC max , i.e., there exist two jobs, J i and J j , with J i ! J j , but C i ðr 2 Þ &gt; B j ðr 2 Þ. We can do shifting operation, similar to that above, for M 2 in the opposite direction. Namely, if J i ! J j yet J i is processed after J j on M 2 , we move J i to the left immediately before J j to start at the original B j ðr 2 Þ on M 2 . We push the sub-sequence originally between J j and J i (including J j ) accordingly to the right. We call this operation Shifting Operation between J j and J i on M 2 . Similar to Observation 1, it can be seen that after the shifting operation, the new schedule is still A-feasible and B-feasible to F 2jprecjC max without increasing the makespan.</p><p>Let r 2 ¼ ðJ j 1 ; J j 2 ; . . . ; J j n Þ initially. Note that for convenience we still use the same sequence notation although it may be different from r 1 . We perform the following precedence violation check between the (currently) first position job J j 1 and other jobs, fJ j 2 ; J j 3 ; . . . ; J j n g. Start from J j 2 and then J j 3 ; . . ., and perform shifting operation between J j 1 and J j k on M 2 ; 2 6 k 6 n, should J j 1 and J j k violate the Condition C ði:e:; J j k ! J j 1 ; yetC j k ðr 2 Þ &gt; B j 1 ðr 2 ÞÞ. Continue the procedure similar to that above, after at most n À 1 rounds of checking and possible shifting operation, we will fix a job as the first position job permanently. Continue the procedures, after at most n À 2 rounds of checking and possible shifting operation we will fix the second position job permanently. Repeat the procedures, eventually we will fix all jobs, and find a feasible schedule that satisfies all precedence constraints. Moreover, the final schedule also remains A-feasible and B-feasible and the makespan is not larger. As a consequence, we get a feasible schedule of F 2jprecjC max with makespan no larger than M. h Please note that while F 2jprecjC max is strongly NP-hard, F 2jprec; p ik ¼ 1jC max is polynomially solvable <ref type="bibr" target="#b2">[3]</ref>. It is interesting to see by the following corollary that F 2jCD; p ik ¼ 1jC max is still strongly NP-hard.</p><p>Corollary 3. F 2jCD; p ik ¼ 1jC max ., i.e., p i1 ¼ p j2 ¼ 1 for all i and j, is still strongly NP-hard.</p><p>Proof. We show that F 2jCD; p ik ¼ 1jC max is strongly NP-hard by transforming F 2jCDjC max in pseudo-polynomial time to our problem. Given an instance of F 2jCDjC max above, (in Section 2) and a positive integer M, the question we ask is ''can we find a feasible schedule F 2jCDjC max with a makespan no larger than M?"</p><p>Now we construct an instance of F 2jCD; p ik ¼ 1jC max as follows.</p><p>Corresponding to each job J i1 in F 2jCDjC max ; i ¼ 1; . . . ; n, we construct a set of jp i1 j jobs, . Hence, the size of the instance as well as the maximum value is bounded pseudo-polynomially.</p><formula xml:id="formula_3">K 0 i1 ¼ K l1 : l ¼ P iÀ1 k¼1 p k1 þ</formula><p>? If there exists a feasible schedule of F 2jCDjC max with a makespan no greater than M, the schedule should be feasible to F 2jCD; p ik ¼ 1jC max with the same makespan (no greater than M).</p><p>If there exists a feasible schedule of F 2jCD; p ik ¼ 1jC max with a makespan no greater than M, denoted as r 0 ¼ ðr 0 1 ; r 0 2 Þ. For notational convenience, we call those jobs in F 2jCD; p ik ¼ 1jC max corresponding to the same job in F 2jCDjC max as the same group jobs. For example, for each i, jobs belong to K 0 i1 are in the same group. Assume that in r 0 ¼ ðr 0 1 ; r 0 2 Þ the jobs in the same group are not processed consecutively. In such a case, we can group jobs in the following way: For machine M 1 , starting from the last position job in the sequence, we move all jobs that belong to the same group of the last position job to the right to make all jobs in that group to be processed consecutively. While we are moving those jobs to the right on M 1 we did move some jobs in between to the left accordingly, and it can be seen that the makespan will not increase. We then continue move the next group of jobs, . . . , until all jobs in the same group are processed consecutively in M 1 . We did similar grouping procedure for jobs in M 2 except that we start from the first job and we group jobs by moving them to the left. Note that the grouping processes above on M 1 and M 2 could not violate the constraint of S i that is required by the J i2 in F 2jCDjC max for any i. This is due to the construction of the instance in which any single job in M 2 , say belong to the same group of J i2 , can not start until all jobs corresponding S i has finished process in M 1 . Note also that these moves could not increase the value of the makespan. Thus, we can obtain a feasible schedule of F 2jCDjC max , with a makespan no greater than M. h Since the problem is strongly NP-hard, it is unlikely to find a polynomial algorithm that can solve the problem optimally. Thus, in the following three sections, we provide (i) some polynomially solvable special cases, (ii) a heuristic algorithm to solve the general problem with an error bound analysis, and (iii) a branch-and-bound algorithm to solve the general problem optimally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Polynomially solvable special cases</head><p>Special case 1: The F 2jCDjC max problem with S j \ S k ¼ ; for all j, k with 1 6 j, k 6 m and j 6 ¼ k.</p><p>Lemma 1. The problem of Special case 1 can be solved optimally by Algorithm 1 below. Algorithm 1. Apply Johnson's algorithm with processing times (u(j), v(j)), where uðjÞ ¼ P i:J i1 2Sj p i1 and vðjÞ ¼ p j2 ; j ¼ 1; . . . ; m. The sequence of jobs on M 2 is decided by Johnson's algorithm. The sequence of jobs on M 1 is ordered according to Property 1 (ii) where jobs within each S j ; j ¼ 1; . . . ; m, can be sequenced in any order.</p><p>Proof. By Property 3, there exists an optimal solution such that for all j, 1 6 j 6 m, jobs in each S j should be processed consecutively. We thus can combine those jobs in S j into a combined one with processing time (u(j), v(j)) where uðjÞ ¼ P i:J i1 2Sj p i1 and vðjÞ ¼ p j2 . Hence the remaining proof is the same as that for the classical F 2kC max problem. h Special case 2: F 2jCDjC max with m = 2.</p><p>Lemma 2. The problem of Special Case 2 can be solved optimally by Algorithm 2 below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2</head><p>Step 1: Process jobs in S 12 ¼ S 1 \ S 2 first on M 1 .</p><p>Step 2: Apply Algorithm 1 to the sub-problem with S 0 1 ¼ S 1 n S 12 , and S 0 2 ¼ S 2 n S 12 . Let the first job on M 1 starts at</p><formula xml:id="formula_4">P i:J i 2S 12 p i1 .</formula><p>Proof. By Corollary 2, there exists an optimal solution such that jobs of S 12 are processed first on M 1 . Hence, the argument for the remaining part is similar to that of Lemma 1. h</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Heuristic algorithm with an error-bound analysis</head><p>Since F 2jCDjC max is strongly NP-hard, we now provide a heuristic with error bound analysis. Note that the classical problem, F 2kC max can be solved optimally in polynomial time by Johnson's Algorithm. Given an instance of F 2jCDjC max , an auxiliary instance of F 2kC max can be first constructed and based on its optimal solution, a good heuristic solution for the original problem is expected to get. The corresponding algorithm is presented as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Algorithm F2R</head><p>Step 1: For an instance of F 2jCDjC max , we construct an instance of F 2kC max with n jobs, and with processing times (u(i), v(i)), where uðiÞ ¼ p i1 ; vðiÞ ¼ P j:J i1 2Sj p j2 =q j i ¼ 1 . . . ; n, and q j ¼ jS j j is the number of jobs contained in S j .</p><p>Step 2: Apply Johnson's algorithm to the auxiliary problem F 2kC max and obtain its optimal (permutation) solution, ðr Ã ; r Ã Þ. Generate a schedule r F2R ¼ ðr Ã ; r 2 Þ, where r 2 is generated by processing J j2 on M 2 as early as possible after all jobs in S j have been completed by the schedule of r Ã on M 1 . Denote the corresponding makespan as C F 2R .</p><p>Theorem 2. C F 2R 6 ð2 À 1=q 2 max ÞC Ã , where C Ã denotes the optimal makespan and q 2 max ¼ maxfq j : j ¼ 1; 2; . . . ; mg.</p><p>Proof. Let C F be the optimal makespan to the auxiliary problem F 2kC max (instance constructed in Step 1). Note that for any feasible solution to F 2jCDjC max , we can always construct a feasible solution for the corresponding auxiliary F 2kC max with job sequence (same for both machines) exactly the same as that in M 1 of F 2jCDjC max , yet with smaller or equal makespan. Hence, C F 6 C Ã . It can be seen that when we construct the solution for F 2jCDjC max from the optimal solution of the auxiliary problem F 2kC max , we push at most P m j¼1 p j2 ðq j À 1Þ=q j to the right on machine M 2 . Hence</p><formula xml:id="formula_5">C F 2R 6 C F þ X m j¼1 p j2 ðq j À 1Þ=q j 6 C Ã þ X m j¼1 p j2 ðq j À 1Þ=q j :</formula><p>Since P m j¼1 p j2 6 C Ã and q j 6 q 2 max for each j ¼ 1; . . . ; m. Hence, we have</p><formula xml:id="formula_6">C F 2R 6 C Ã þ X m j¼1 p j2 ðq j À 1Þ=q j ¼ C Ã þ X m j¼1 ðp j2 À p j2 =q j Þ ¼ C Ã þ X m j¼1 p j2 À X m j¼1 p j2 =q j 6 C Ã þ X m j¼1 p j2 À X m j¼1 p j2 =q 2 max ¼ C Ã þ X m j¼1 p j2 ð1 À 1=q 2 max Þ 6 C Ã þ C Ã ð1 À 1=q 2 max Þ ¼ C Ã ð2 À 1=q 2 max Þ Ã Remark 3</formula><p>(i) Note that the reverse problem also has its corresponding maximum value of q 1 max . If q 1 max &lt; q 2 max , then algorithm F2R will perform better on the reverse problem than on the primary problem in terms of the worst-case error bound. Thus, we can run the above algorithm for the primary problem and its reverse problem and select the best solution. The result will improve the error bound to 2 À 1= minfq 1 max ; q 2 max g. (ii) The result C F 6 C Ã shown in the first paragraph of the proof will be used later to provide lower bound in the branch and bound algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">The branch-and-bound algorithm</head><p>A branch-and-bound algorithm for a minimization problem has the following general characteristics:</p><p>A branching rule that defines the partitions of the set of feasible solutions into subsets.</p><p>A lower bounding rule that provides a lower bound on the value of each solution in a subset generated by the branching rule.</p><p>A search strategy that selects a node from which to branch.</p><p>Additional features, such as dominance rules and upper bounding procedures, may also be presented and, if fully exploited, could lead to substantial improvements in the algorithmic performance. A diagram representing this process is called a search tree. In this tree, each node represents a sub-problem with a given fixed partial sequence of jobs. The number of edges in the path from the root node to P i is called the depth or level of the node. In our case, the schedule r 0 associated with the node P 0 is the empty schedule.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">The branching rule</head><p>We adopt the following branching rule. Nodes at level k of the search tree correspond to a set of jobs in J 1 that has been scheduled at the beginning positions on M 1 , which makes k jobs of J 2 available on M 2 . More specifically, there are m! ðmÀkÞ! nodes in level k. Our branching idea is based on job order on M 2 , i.e., we assume that at a node of level k, there are k jobs with a sequence order already fixed on M 2 , say J j l1 2 ; J j l2 2 ; . . . ; J j lk 2 . In order to make these jobs to be processed in M 2 in that sequence, by Property 1, we assume the corresponding jobs on M 1 are S j l1 [ S j l2 [ . . . [ S j lk in the order of r l ¼ ðS j l1 ; S j l2 n S j l1 ; . . . ; S j lk n S kÀ1 i¼1 S j li Þ. It should be pointed out that we sequence jobs in S j l1 first and we sequence them in arbitrary order within S j l 1 . We then sequence jobs in S j l2 n S j l1 ; . . . etc.</p><p>At the current node P l (assumed at level k), define U l and AðU l Þ as the sets of unscheduled jobs on M 1 and M 2 , respectively, i.e., U l ¼ J 1 n S k s¼1 S j ls ; AðU l Þ ¼ J 2 n fJ j l1 2 ; J j l2 2 ; . . . ; J j lk 2 g. We can branch the node P l by attaching one job in AðU l Þ to be processed at the next position of k + 1 on M 2 and also the corresponding set of jobs to r l be processed on M 1 . Without loss of generality, we assume AðU l Þ ¼ fJ j lðkþ1Þ 2 ; J j lðkþ2Þ 2 ; . . . ; J j lm 2 g. According to above branching rule, a total of m-k successive nodes can be generated from the current node P l (see Fig. <ref type="figure">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">The lower bounds</head><p>A lower bound is useful for reducing the size of the search tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A machine-based lower bound</head><p>The following bound based on machines is obvious:</p><formula xml:id="formula_7">MB ¼ max X n i¼1 p i1 þ min j¼1;...;m fp j2 g; min j¼1;...;m X i:J i1 2Sj p i1 ( ) þ X m j¼1 p j2</formula><p>( )</p><formula xml:id="formula_8">:</formula><p>A job-based lower bound At branching node P l , let C max ðr l Þ denote the completion time of all jobs in J 2 n AðU l Þ. It is known that if r l is fixed, then C max ðr l Þ can be obtained within polynomial time. Also, we have the following lower bound of the optimal makespan value:</p><formula xml:id="formula_9">JB ¼ C max ðr l Þ þ X j:J j2 2AðU l Þ p j2 :</formula><p>Fig. <ref type="figure">3</ref>. Branching tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A non-crossed relaxation lower bound</head><p>At branching node P l , we have a fixed sequence of jobs in the schedule r l for M 1 and for corresponding jobs processed on M 2 . We can apply an idea similar to that of Algorithm F2R for the remaining set of jobs, to find a lower bound of makespan for that subset of jobs, and then concatenate with the already scheduled jobs to come out a lower bound for the problem.</p><p>For J i1 2 U l , let uðiÞ ¼ p i1 and vðiÞ ¼ P j:J i1 2Sj p j2 jS j nr l j , where, S j n r l denotes the set of S j excluding those jobs that have been scheduled in the schedule r l . Then, we construct an instance of F 2kC max for the sub-problem with processing times ðuðiÞ; vðiÞÞ. We solve this classical flow shop problem with Johnson's algorithm and obtain its optimal solution with makespan V Ã ðU l Þ. For this sub-problem, we push jobs on M 2 to the right so that jobs are processed consecutively without idle time and finish at V Ã ðU l Þ. These operations will not affect its optimality property (Fig. <ref type="figure">4</ref>).</p><p>At branching node P l , let P ðU l Þ denote the total processing times of jobs in U l on M 1 . Note that by Remark 3 (ii), V Ã ðU l Þ obtained above is a lower bound for the sub-problem of jobs U l on M 1 and AðU l Þ on M 2 . The lower bound at branching node P l , can then be given as follows:</p><formula xml:id="formula_10">LB F ¼ X n i¼1 p i1 þ V Ã ðU l Þ À P ðU l Þ:</formula><p>Given that we already have schedule r l , and V Ã ðU l Þ is a lower bound of makespan for the remaining set of jobs, it is clear that LB F is a lower bound for the whole problem at branching node P l . Note that if there is overlapping on M 2 when concatenating r l with the remaining set of jobs (there will be no idle time on M 2 in Fig. <ref type="figure">4</ref>), then LB F may not be a good lower bound. Nevertheless, in such a case a simple lower bound will be C max ðr l Þ þ P j:J j2 2AðU l Þ p j2 and that has been discussed and defined as JB above.</p><p>It is noted that the lower bound of JB and LB F depend on the current node P l (can be applied only at node P l ), while the lower bound of MB has nothing to do with any branching node. From the above three lower bounds, we have LBðrÞ ¼ maxfMB; JB; LB F g:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">The search strategy</head><p>Our search strategy selects the subproblem with the best bound; e.g., the lowest lower bound in the case of a minimization problem. This approach is motivated by the observation that the subproblem with the best lower bound has to be evaluated anyway and that it is more likely to contain the optimal solution than any other node. As shown in <ref type="bibr" target="#b6">[7]</ref>, this strategy has the characteristic that, if other parts of the branch-and-bound algorithm are not changed, the number of partial problems decomposed before termination is minimized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">The dominance rules</head><p>In any branch, we already fixed some schedule. Hence, the corresponding subproblem is similar to the original problem yet M 1 is available from t 1 ¼ P i:J i1 2J 1 nU l p i1 and M 2 is available from t 2 , where t 2 is equal to the completion time of jobs in fJ j2 : J j2 2 J 2 n AðU l Þg in the current schedule. Note that it has been shown in <ref type="bibr" target="#b9">[10]</ref> that for the classical problem F 2kC max if M 1 and M 2 are available at t 1 and t 2 , respectively (instead of time zero), Johnson's algorithm can still be applied to get an optimal solution. Interestingly, in our problem, F 2jCDjC max , while we reach at branching node P l , we can treat our problem as a new problem with machine starting time at t 1 and t 2 , respectively, and most of the optimality properties developed in Section 2 can be applied here in a similar way if we let S j ¼ S j \ U l for all j with J j2 2 AðU l Þ. For notational convenience, Fig. <ref type="figure">4</ref>. A non-cross relaxation lower bound.</p><p>we let S U l j ¼ S j \ U l in the remainder of this Section. Also, while we mention ''at branching node P l " we assume that we are at level k, and we are with sequenced jobs r l and un-sequenced jobs, U l , on M 1 , and un-sequenced jobs, AðU l Þ), on M 2 . Property 5. At branching node P l , for a given j and k with J j2 2 AðU l Þ and J k2 2 AðU l Þ, if S U l j S U l k , then there exists an optimal schedule for ðU l ; AðU l ÞÞ such that J j2 is processed before J k2 on M 2 , and hence in the next level of branch (level k + 1), we do not need to consider J k2 as the first next job in M 2 .</p><p>Proof. Similar to that of Property 2. h Property 6. If S U l j \ S U j k ¼ / for any two jobs J j2 2 AðU l Þ and J k2 2 AðU l Þ; j 6 ¼ k, then apply Johnson's algorithm with processing times (u(j), v(j)), where uðjÞ ¼ P i:J i1 2S U l j p i1 and vðjÞ ¼ p j2 , to those j with J j2 2 AðU l Þ to decide the sequence of the remaining part and stop the branch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark 5</head><p>(i) Since our branching idea is based on job sequence on M 2 , we do not specifically apply Corollary 2 here. Nevertheless, if there is a set S U l , and if ðS U l j n SÞ \ ðS U l k n SÞ ¼ / for all j 6 ¼ k, then even though we do not specifically pay attention to set S in the current branching, Property 6 will be applied to the problem in the next level. (ii) It should be noted that an upper bound can also be useful for reducing computation in the branch-and-bound (B&amp;B) algorithm. For example, we can choose the algorithm F2R for this aim.</p><p>Since this B&amp;B scheme is more complicated than that for the traditional scheduling problem, we provide a simple example in the Appendix for reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Computational results</head><p>In addition to the number of jobs in J 1 and J 2 , the crosses of the jobs in J 2 , i.e., S j \ S k are important factors that affect the efficiency of the branch-and-bound algorithm. While S j is generated by randomly selecting J i1 as its item, these crosses will be affected partly by the correlation between m and n. Our computational experience tells us that the closer m and n are, the more difficult the corresponding instances appear to be. Consequently, we test our branch-and-bound algorithm on problems constructed as follows. In each group of instances, n is fixed and the number m is randomly chosen from the range of ½na; nb, where a = 0.8, b = 1.2. The processing times of jobs in J 1 and J 2 are generated by the uniform distribution <ref type="bibr" target="#b9">[10,</ref><ref type="bibr">100]</ref>. J i1 is selected randomly to be an item of S j by the distribution between 0 and 1. See Table <ref type="table" target="#tab_1">1</ref> for the computational results. For each case, 100 different problems are solved. The solution is aborted if more than abort time is required. The algorithms are coded in C++ and run on a Pentium 4 2.53 GHz computer with 504 Mb RAM.</p><p>Within two minutes, our algorithm can be used to solve all problems optimally up to 40 jobs. For n = 50 with m 2 ½40; 60, all problems can be solved within 5 minutes. Also, approximately 65% of the problems with n = 60 ðm 2 ½48; 72Þ were solved within 5 minutes. We report some basic results in Table <ref type="table" target="#tab_1">1</ref> by the minimal run times (Min. CPU(s)), the maximal run times (Max. CPU (s)), the average run times (Av. CPU(s)), the average number of nodes (Av. nodes), the programming abort time (Abort time (minutes)) and the number of unsolved problems (Unsolved prob.). The percentage of truncated nodes with regard to the total number of nodes reflects the lower bound sharpness. Since our branching is actually based on the jobs on machine M 2 , the total number of nodes could be calculated by the factorial of the number m of jobs on machine M 2 , i.e., m!. Table <ref type="table" target="#tab_1">1</ref> shows us that the average number of nodes (Av. nodes) is far smaller than m!.</p><p>It is not difficult to know that any first come fist serve algorithm, including the one shown below, will result with performance ratio not greater than 2. a The zero indicates that the corresponding problems can be solved within one second. b The zero indicates that no problem is aborted within the abort time.</p><p>of U 0 ¼ J 1 n ; ¼ J 1 , the instance has five jobs with the processing times u(i) and v(i) on M 1 and M 2 respectively uð1Þ ¼ 2; uð2Þ ¼ 1; uð3Þ ¼ 2; uð4Þ ¼ 3; uð5Þ ¼ 1;</p><p>vð1Þ ¼ p 22 =jS 2 j þ p 32 =jS 3 j ¼ 1=4 þ 2=4 ¼ 0:75;</p><formula xml:id="formula_11">vð2Þ ¼ p 12 =jS 1 j þ p 22 =jS 2 j ¼ 3=2 þ 1=4 ¼ 1:75;</formula><p>vð3Þ ¼ p 32 =jS 3 j ¼ 2=4 ¼ 0:5; vð4Þ ¼ p 22 =jS 2 j þ p 32 =jS 3 j ¼ 1=4 þ 2=4 ¼ 0:75; vð5Þ ¼ p 12 =jS 1 j þ p 22 =jS 2 j þ p 32 =jS 3 j ¼ 2:25:</p><p>After solving the above instance of F 2kC max by Johnson's algorithm, we get the optimal solution (2, 5, 4, 3, 1) with the value of V Ã ðU 0 Þ ¼ 9:75. We have LB F ¼ P ðJ 1 Þ þ V Ã ðU 0 Þ À P ðU 0 Þ ¼ 9:75: Finally, we get a lower bound related to r 0 : LBðr 0 Þ ¼ maxfMB; JB; LB F g ¼ maxf10; 6; 9:75g ¼ 10:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Upper bound</head><p>Because the sequence of (2, 5, 4, 3, 1) is feasible for the original problem, this gives an upper bound, i.e., UB = 12.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Level 1:</head><p>Because there are still three jobs that have not been available to be processed on M 2 , we ''branch" node P 0 on the unavailable jobs in J 2 and create the following two additional nodes:</p><p>Node P 1 : ðJ 12 Þr 0 þ ð2; 5Þ. Node P 2 : ðJ 32 Þr 0 þ ð1; 3; 4; 5Þ.</p><p>Note that by Theorem 3 we do not need to consider the node corresponding to J 22 at this level as S U 0 1 S U 0 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Node P 1</head><p>Lower bound At the node, r 1 ¼ ð2; 5Þ and U 1 ¼ J 1 n fJ 21 ; J 51 g ¼ fJ 11 ; J 31 ; J 41 g. Clearly, we have</p><formula xml:id="formula_12">JB ¼ C max ðr 1 Þ þ X j:J j2 2AðU 1 Þ p j2 ¼ 5 þ 3 ¼ 8:</formula><p>Similar to that for node P 0 , we construct the following instance of F 2kC max to determine the non-crossed relaxation lower bound. Because of U 1 ¼ fJ 11 ; J 31 ; J 41 g, the instance has three jobs with the processing times u(i) and v(i) on M 1 and M 2 respectively uð1Þ ¼ 2; uð3Þ ¼ 2; uð4Þ ¼ 3; vð1Þ ¼ p 22 =jS 2 n r 1 j þ p 32 =jS 3 n r 1 j ¼ 1=2 þ 2=3 ¼ 7=6; vð3Þ ¼ p 32 =jS 3 n r 1 j ¼ 2=3; vð4Þ ¼ p 22 =jS 2 n r 1 j þ p 32 =jS 3 n r 1 j ¼ 7=6: By Johnson's algorithm, we get the optimal solution with a value of V Ã ðU 1 Þ ¼ 23=3. We have</p><formula xml:id="formula_13">LB F ¼ P ðJ 1 Þ þ V Ã ðU 1 Þ À P ðU 1 Þ ¼ 29=3:</formula><p>Therefore, we have LBðr 1 Þ ¼ maxfMB; JB; LB F g ¼ 10.</p><p>Because LBðr 3 Þ ¼ 11 &lt; UB ¼ 12, a new node will be created from node P 3 . Since U 3 ¼ fJ 31 g, only one node could be considered by appending J 31 to r 3 and we have node P 4 , which is fathomed. It is easy to see that the value of node is 11. There is no unsolved node and we get the optimal solution of r Ã ¼ ð2; 5; 1; 4; 3Þ with the objective of 11 (see Fig. <ref type="figure">5</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .Fig. 2 .</head><label>12</label><figDesc>Fig. 1. Non-B-feasible schedule.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell cols="2">Computational times</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>n</cell><cell>m</cell><cell>Min. CPU(s)</cell><cell>Max. CPU(s)</cell><cell>Av. CPU(s)</cell><cell>Av. nodes</cell><cell>Abort time (minutes)</cell><cell>Unsolved Prob.</cell></row><row><cell>5</cell><cell>[4, 6]</cell><cell>0 a</cell><cell>0</cell><cell>0</cell><cell>6</cell><cell>2</cell><cell>0 b</cell></row><row><cell>10</cell><cell>[8, 12]</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>73</cell><cell>2</cell><cell>0</cell></row><row><cell>20</cell><cell>[16, 24]</cell><cell>0</cell><cell>1</cell><cell>0.05</cell><cell>1000</cell><cell>2</cell><cell>0</cell></row><row><cell>30</cell><cell>[24, 36]</cell><cell>0</cell><cell>3</cell><cell>0.81</cell><cell>5895</cell><cell>2</cell><cell>0</cell></row><row><cell>40</cell><cell>[32, 48]</cell><cell>0</cell><cell>30</cell><cell>6.94</cell><cell>26,843</cell><cell>2</cell><cell>0</cell></row><row><cell>50</cell><cell>[40, 60]</cell><cell>8</cell><cell>182</cell><cell>51.2</cell><cell>120,000</cell><cell>5</cell><cell>0</cell></row><row><cell>60</cell><cell>[48, 72]</cell><cell>35</cell><cell>288</cell><cell>164.031</cell><cell>154,340</cell><cell>5</cell><cell>35</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>F. Chen, C.-Y. Lee / European Journal of Operational Research 193 (2009) 59-72</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors are grateful to three referees for their constructive comments. This research is supported in part by NSFC/ RGC Joint Research Scheme 2006-2007 (N_HKUST612/06).</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>q This research is supported in part by NSFC/RGC Joint Research Scheme 2006-2007 (N-HKUST612/06).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm RS</head><p>Randomly schedule jobs in J 1 on M 1 . When all corresponding preceding jobs finished on M 1 , start to process jobs in J 2 on M 2 as early as possible.</p><p>Theorem 2 tells us that the worst performance ratio of algorithm F2R may not be much better than the trivial bound 2 when q max is sufficiently large. In addition to the contribution of introducing the parameter of q max into the algorithm F2R, and with better error bound performance when q max is not large, we conduct some computational experiments to show that the average performance of algorithm F2R is much better than that of algorithm RS.</p><p>We compare the computational performance of algorithm F2R and algorithm RS based on the criterion of Average Relative Error (ARE), i.e., ARE</p><p>, where CðH Þ is the makespan generated by heuristic algorithm H and C Ã is the optimal makespan. We consider the following cases for our tests. For each case, we test 100 instances. See Table <ref type="table">2</ref>.</p><p>Table <ref type="table">2</ref> shows that the average relative error of F2R is much better than that of RS. Note that the algorithm F2R was employed to generate the initial upper bound in the branch and bound algorithm, Table <ref type="table">2</ref> also shows that our initial upper bound is effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion</head><p>In the paper, we study a two-machine scheduling model for the cross-docking problem occurring in logistics. We first show that the problem is strongly NP-hard. Some polynomially solvable special cases are provided. We then develop a polynomial approximation algorithm with an error-bound analysis. A branch-and-bound algorithm is also constructed. Computational results show that the branch-and-bound algorithm can optimally solve problems with up to 60 jobs within a reasonable amount of time. Future research direction includes developing good heuristics with better error bound and considering the model with other objective functions. Appendix A. An example of the B&amp;B scheme for cross-docking scheduling Given two job sets, J 1 ¼ fJ 11 ; J 21 ; J 31 ; J 41 ; J 51 g; J 2 ¼ fJ 12 ; J 22 ; J 32 g, S 1 ¼ fJ 21 ; J 51 g; S 2 ¼ fJ 11 ; J 21 ; J 41 ; J 51 g; S 3 ¼ fJ 11 ; J 31 ; J 41 ; J 51 g,</p><p>First, we establish the machine-based lower bound as follows:</p><p>Level 0:</p><p>The root node is associated with empty schedule of r 0 . At the node of P 0 , we get the lower bound as well as the upper bound related to the optimal candidate. Node 0</p><p>Lower bound Since r 0 ¼ ðÞ, we have</p><p>In order to determine the non-crossed relaxation lower bound, we first construct an instance of F 2kC max . Because </p><p>Because of U 2 ¼ fJ 21 g, we construct a trivial instance of F 2kC max with the single job of J 21 and the processing times u(2) and v(2) on M 1 and M 2 respectively uð2Þ ¼ 1;</p><p>For the trivial case, we know that V Ã ðU 2 Þ ¼ 5. We have LB</p><p>From the above calculations, we determine the following diagram:</p><p>Level 2: Because of LBðr 2 Þ ¼ 14 &gt; UB ¼ 12, node P 2 is fathomed. We only need to branch node P 1 . Since U 1 ¼ fJ 11 ; J 31 ; J 41 g, we have S 2 \ U 1 ¼ fJ 11 ; J 41 g; S 3 \ U 1 ¼ fJ 11 ; J 31 ; J 41 g. Also, due to S U 1 2 S U 1 3 , only one successor of node P 1 needs to be created by appending jobs J 22 to the next job on M 2 and appending S 2 n r 1 ¼ fJ 11 ; J 41 g to the next jobs set to be processed on M 1 .</p><p>Node P 3 (LB Calculation) r 3 ¼ ð2; 5; 1; 4Þ and U 3 ¼ J 1 n fJ 21 ; J 51 ; J 11 ; J 41 g ¼ fJ 31 g. First, we have</p><p>Because U 3 has only one job, it is also a trivial case and we get the non-crossed relaxation lower bound LB</p><p>Therefore, we have LBðr 3 Þ ¼ maxfMB; JB; LB F g ¼ 11 and the following diagram. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The best shape for a crossdock</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Bartholdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Gue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Science</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="235" to="244" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reducing labor costs in an international crossdocking terminal</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Bartholdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Gue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="823" to="832" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deterministic scheduling with pipelined processors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bruno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>So</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="308" to="316" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Computer and Intractability: A Guide to the Theory of NP-Completeness</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Garey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>W.H. Freeman and Company</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Flow shop scheduling problems under machine-dependent precedence constraints</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Gladky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Shafransky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Strusevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Combinatorial Optimization</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="13" to="28" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The effects of trailer scheduling on the layout of freight terminals</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Gue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Science</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="419" to="428" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Enumerative approaches to combinatorial optimization: Part I</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ibaraki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Operations Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="1" to="340" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Optimal two and three-stage production schedules with setup times included</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Naval Research Logistic Quarterly</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="61" to="68" />
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sequencing and scheduling algorithms and complexity</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Lawler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Lenstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H G</forename><surname>Rinnooy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Shmoys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Logistics of Production and Inventory</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Graves</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">H G</forename><surname>Rinnooy Kan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Zipkin</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="445" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Machine scheduling with an availability constraint</title>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Global Optimization, Special Issue on Optimization on Scheduling Application</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="363" to="384" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The two-machine maximum flow time problem with series-parallel precedence constraints: An algorithm and extensions</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Monma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="792" to="798" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sequencing to minimize the maximum job cost</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Monma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="942" to="951" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sequencing with series-parallel precedence constraints</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Monma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Sidney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Operations Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="215" to="224" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Making the move to cross docking</title>
		<author>
			<persName><forename type="first">M</forename><surname>Napolitano</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Warehousing Education and Research Council</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Peck</surname></persName>
		</author>
		<title level="m">Operational Analysis of Freight Terminals Handling Less Than Container Load Shipments</title>
		<imprint>
			<date type="published" when="1983">1983</date>
		</imprint>
		<respStmt>
			<orgName>University of Illinois at Urbana-Champaign</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A systems approach to docks and cross docking</title>
		<author>
			<persName><forename type="first">G</forename><surname>Schwind</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Material Handling Engineering</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="59" to="62" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The two-machine flow time problem with series-parallel precedence constraints</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Sidney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="782" to="791" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Designing and Managing the Supply Chain: Concepts, Strategies, and Case Studies</title>
		<author>
			<persName><forename type="first">D</forename><surname>Simchi-Levi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kaminsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Simchi-Levi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<pubPlace>McGraw-Hill, Irwin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Optimal solution to a dock door assignment problem</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Tsui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer and Industrial Engineering</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="283" to="286" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A microcomputer based decision support tools for assigning dock doors in freight yards</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Tsui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and Industrial Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="309" to="312" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m">Fig. 5. Final schedule</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
