<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Library of Constructive Skeletons for Sequential Style of Parallel Programming (Invited Paper)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kiminori</forename><surname>Matsuzaki</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematical Informatics</orgName>
								<orgName type="institution">The University of Tokyo</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kento</forename><surname>Emoto</surname></persName>
							<email>emoto@ipl.t.u-tokyo.ac.jp</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematical Informatics</orgName>
								<orgName type="institution">The University of Tokyo</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hideya</forename><surname>Iwasaki</surname></persName>
							<email>iwasaki@cs.uec.ac.jp</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Electro-Communications</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhenjiang</forename><surname>Hu</surname></persName>
							<email>hu@mist.t.u-tokyo.ac.jp</email>
							<affiliation key="aff3">
								<orgName type="department">Department of Mathematical Informatics</orgName>
								<orgName type="institution">The University of Tokyo</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Library of Constructive Skeletons for Sequential Style of Parallel Programming (Invited Paper)</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">37905CD376103160174BDD3EC3BD60A1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>With the increasing popularity of parallel programming environments such as PC clusters, more and more sequential programmers, with little knowledge about parallel architectures and parallel programming, are hoping to write parallel programs. Numerous attempts have been made to develop high-level parallel programming libraries that use abstraction to hide low-level concerns and reduce difficulties in parallel programming. Among them, libraries of parallel skeletons have emerged as a promising way towards this direction. Unfortunately, these libraries are not well accepted by sequential programmers, because of incomplete elimination of lower-level details, ad-hoc selection of library functions, unsatisfactory performance, or lack of convincing application examples. This paper addresses principle of designing skeleton libraries of parallel programming and reports implementation details and practical applications of a skeleton library SkeTo. The SkeTo library is unique in its feature that it has a solid theoretical foundation based on the theory of Constructive Algorithmics, and is practical to be used to describe various parallel computations in a sequential manner.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Parallel programming offers the potential for substantial performance improvements, but exploration of this potential has been regarded as sort of privilege of expert programmers. This situation is changing dramatically with the availability of low-cost hardware and fast computer net-works which makes it easy to build up parallel computer systems such as PC clusters. More and more sequential programmers, with little knowledge about parallel architecture and parallel programming, are hoping to write parallel programs. For non-experienced parallel programmers who are used to sequential programming, the rapid development of a correct parallel application is as important as its execution time; they would like to build parallel applications with a minimum of effort. This eagerly calls for a new parallel programming paradigm such that a sequential programmer can easily and quickly develop parallel programs running reasonably fast on some nearby parallel machines.</p><p>There have been numerous attempts to develop highlevel parallel programming tools that use abstraction to hide low-level concerns and reduce complexity so that users can quickly build correct parallel programs. These tools may appear as a new high-level parallel programming language <ref type="bibr" target="#b3">[4]</ref> or a complicated parallel programming library such as MPI and PVM, and therefore they usually require non-experienced parallel programmers to spend much time for learning them due to the gap between the styles of sequential and parallel programming. It would be ideal if one could write parallel programs as if he or she wrote sequential ones, except some specific functions that have both sequential and parallel interpretations. The parallel interpretation could be automatically adopted, when programs run on parallel machines.</p><p>Skeletal parallel programming 1 (or structured parallel programming) <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b49">50]</ref> has emerged as a promising way towards this direction. In skeletal parallel pro-gramming, programmers are encouraged to build a parallel program from ready-made components (i.e., skeletons or patterns) for which efficient parallel implementations are known to exist, making the parallelization process simpler. There are many definitions of skeletons, but the point is that useful patterns of parallel computation and interaction are packaged up as constructs, such as a framework <ref type="bibr" target="#b49">[50]</ref>, a second order structure <ref type="bibr" target="#b48">[49]</ref>, or a template <ref type="bibr" target="#b11">[12]</ref>. Skeletal parallel programs are easy to understand even for non-experienced parallel programmers, because they look very much like sequential programs with just a single execution stream.</p><p>Unfortunately, few widely-used applications are actually developed with parallel skeletons. There are mainly four reasons for this. First, like design patterns in software engineering, parallel skeletons have been introduced in a rather ad-hoc manner mostly based on application domains. There is no clear discipline on skeleton design for adding new skeletons or combining different sets of skeletons developed for different purposes. Second, because parallel programming relies on a fixed set of parallel primitive skeletons for specifying parallelism, programmers often find it hard to choose proper ones and then to integrate them well to develop efficient parallel programs. In many cases, the reason programmers feel reluctant to use skeletons is simply because they are not sure whether the provided skeletons are powerful enough to solve their problems and they give up too early. Third, since parallelism should be specified with the skeletons, big overheads could be introduced due to, for example, unnecessary intermediate data structures passed between skeletons. Finally, since most skeleton systems are defined upon some new languages or require extension of existing languages with new syntax, and they do not completely hide all lower-level details of parallel programming from programmers, sequential programmers (non-experienced parallel programmers) often feel uncomfortable to use them.</p><p>To solve these problems, we borrowed the theory of Constructive Algorithmics to define and structure skeletons and developed a new skeleton library named SkeTo. <ref type="foot" target="#foot_0">2</ref> The theory of Constructive Algorithmics <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b42">43]</ref>, also known as Bird-Meertens Formalisms (BMF for short), was initially proposed for systematical construction of efficient sequential programs by means of program calculation. In Constructive Algorithmics, programs are structured so that calculation rules and theories are constructively established for deriving efficient programs from initial specifications. The key observation is that each control structure (of BMF) should be derivable from the data structure it manipulates. The fact that skeletons are basically control structures encourages us to apply the theory of Constructive Algorithmics to define and structure skeletons according to the data structures.</p><p>This paper addresses principle of designing skeleton libraries of parallel programming, and reports implementation details and practical applications of the skeleton library SkeTo that supports complete sequential style of parallel programming. The library is unique in that it has a solid theoretical foundation based on the theory of Constructive Algorithmics, and is practical to be used to describe various parallel computations in a sequential manner. Our main contributions are two folds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• In principle:</head><p>We propose a unified approach to defining and structuring skeletons on various parallel data structures. Though many works have been devoted to applying Constructive Algorithmics to formal development of parallel programs on regular data structures like lists <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b48">49]</ref>, as far as we are aware, we give the first constructive definition for irregular data structures like trees. This enables us to define and structure skeletons on irregular data structures as we do on regular data structures.</p><p>• In practice: We have successfully implemented a practical skeleton library SkeTo, with which many interesting and practical applications have been developed (Section 6). Our skeleton library system has the following features.</p><p>-Our system gives the first efficient parallel implementation of constructive skeletons for manipulating trees and matrices on distributed memory architectures. The rest of this paper is organized as follows. We start by briefly explaining related work in Section 2. Then, we show how to apply the theory of Constructive Algorithmics to design parallel skeletons for manipulating parallel data structures, regular or irregular, in Section 3. We illustrate our SkeTo library with a simple example in Section 4, and explain in detail the implementation issues in Section 5. We list applications and give experimental results in Section 6, and conclude the paper and highlight future works in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Skeletal parallel programming was first proposed by Cole <ref type="bibr" target="#b16">[17]</ref>, and many researchers have been devoted themselves to it <ref type="bibr" target="#b45">[46]</ref>.</p><p>Darlington <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref> is one of the pioneers in this research area. In his framework, each application program has twolayers structure: higher skeleton level and lower base language level. In the higher level, users write a program with skeletons, abstracting its parallel behavior using the SCL (structured coordination language) whose syntax has some kind of functional notation. In the lower level, users describe sequential aspect of the program in the base language. Darlington selected Fortran as the base language in his implementation. The idea that skeletal parallel part and sequential part are separated in a parallel program is also adopted in the P3L <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b20">21]</ref> system. In a P3L program, skeletal part is written in a functional notation with clear specification of its input and output, while the base part is described in the C language. From these descriptions, the P3L compiler generates a C code that calls MPI library functions.</p><p>From users' point of view, both Darlington's system and P3L have higher level layer which has to be written in the specific language in functional-like notation. Thus users, especially outside the computer science field, may feel difficulties in using these systems in the development of parallel programs, because they have to acquire the ability of programming in the new language.</p><p>Some systems have only a single layer but syntactically extend the base language for the description of skeletonrelated part of the program. An instance of such systems is Skil <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>, which is an imperative, C-based language with some enhancements of functional features. The enhancements include introduction of type variables for polymorphism, special data structure for distributed objects, and higher-order functions. Although Skil is an epoch-making system in the research of skeletal parallel programming, it is now somewhat obsolete because most of the enhanced features can be easily achieved by the C++ language. HPC++ <ref type="bibr" target="#b37">[38]</ref> is another system that introduces extensions (compiler directives) into the base language. HPC++ is a C++ library, developed from the viewpoint of parallelization of the standard template library. Although it is not explicitly addressed that the library implements parallel skeletons, the library includes parallel algorithms that correspond to such data parallel skeletons as map, reduce and scan.</p><p>In contrast to the above systems with enhanced syntax into the base language, our SkeTo library introduces no special extension to the base C++ language. Thanks to this design principle, users who can develop a standard C++ program can use the SkeTo library without being annoyed with the acquisition of new syntax or new language. Among recent skeleton libraries that have no syntactic enhancements, Muesli and eSkel are well known. Muesli, developed by Kuchen <ref type="bibr" target="#b38">[39]</ref>, is a C++ library that works using MPI. It supports data parallel skeletons for distributed array and matrix, and control parallel skeletons. eSkel <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b18">19]</ref> is a library of C functions, also on top of MPI. The latest version of eSkel supports control parallel skeletons, putting emphasis on addressing the issues of nesting of skeletons and interaction between parallel activities. Compared with these libraries, SkeTo stands on the data parallel programming model with a solid foundation based on Constructive Algorithmics, and we can offer data parallel skeletons on wide variety of distributed data structures; SkeTo supports tree besides array and matrix in a constructive way. In addition, SkeTo has a new skeleton accumulate <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b34">35]</ref> that abstracts a general and nice combination of data parallel skeletons.</p><p>Our work was inspired by the development of Muesli. We are developing the SkeTo library as the practical product of our researches on Constructive Algorithmics. One of its important results is systematic program optimization by fusion transformation. This transformation merges two successive function calls into a single one and eliminates the overhead of both function calls and generation of intermediate data structures passed between the functions. SkeTo is equipped with automatic fusion transformation based on the idea of shortcut deforestation <ref type="bibr" target="#b27">[28]</ref> with some modifications that makes it adapt to parallel data structures <ref type="bibr" target="#b32">[33]</ref>. By the shortcut deforestation, we can reduce the number of transformation rules and make the implementation of SkeTo simple. This is in sharp contrast to other transformation approaches <ref type="bibr" target="#b30">[31]</ref> with large number of transformation rules. This simple optimization mechanism by fusion transformation is SkeTo's distinguishing feature that has not been implemented in other systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Constructive Skeletons</head><p>In this section, we explain the principle in the design of our skeleton library, which is based on the theory of Constructive Algorithmics. We show what kind of basic skeletons should be defined, and how to add and structure new skeletons. Since our skeletons are designed based on Constructive Algorithmics, they are considered to be constructive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Constructive Algorithmics</head><p>Constructive Algorithmics <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b42">43]</ref> is a theory proposed for systematic development of algebraic rules/laws based on which efficient programs are derived from specification via program calculation (manipulation).</p><p>It has been proved to be very useful for development of efficient sequential programs <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>The key point of Constructive Algorithmics is that each computation structure used in a function (program) should be derivable from the data structure on which the computation is defined. We will not detail the theory; rather we explain the facts that actually motivated us to use it in the design of our parallel skeletons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Algebraic Data Structures</head><p>In Constructive Algorithmics, data structures are defined constructively (algebraically). For instance, integer lists can be defined by<ref type="foot" target="#foot_1">3</ref> </p><formula xml:id="formula_0">IntList = Nil | Cons Int IntList</formula><p>saying that a list may be empty denoted by Nil, or a list denoted by Cons a x, which is built up from an integer element a and a (shorter) list x by the constructor Cons. So Cons 1 (Cons 2 (Cons 3 Nil)) constructs a list with three elements 1, 2 and 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Homomorphic Computation Structures</head><p>Each algebraic data structure is equipped with a basic computation pattern called homomorphism. For instance, a homomorphism, say h, on the integer lists is the following computation pattern:</p><formula xml:id="formula_1">h (Nil) = e h (Cons a x) = a ⊕ h (x)</formula><p>where e is a constant and ⊕ is an infixed binary operation. Choosing different pairs of e and ⊕, h(x) denotes different computation, which will be represented by hom IntList (e, ⊕, x). When it is clear from the context, we may omit the subscript. For instance, computation for summing up elements of a list x is described as hom(0, +, x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Properties of Homomorphisms</head><p>Homomorphism plays a central role in program development <ref type="bibr" target="#b9">[10]</ref>. We briefly review those features that are much related to the design of our skeleton library, which has not been well recognized so far in the community of skeletal parallel programming.</p><p>• Homomorphism, though being simple, is powerful in theory to describe any computation on the data structure it is defined upon, appearing either as a single homomorphism or a compositional use of homomorphisms. We believe that the descriptive power of compositional use is worth emphasizing in skeletal parallel programming.</p><p>• Homomorphism enjoys many nice algebraic rules that are useful to eliminate overheads caused by unnecessary data passed between skeletons, or to construct new rules to optimize programs that are defined with homomorphisms. So if we consider homomorphisms as skeletons, skeletal programs can be efficient enough.</p><p>• Homomorphism can serve as the basis for building practical computation such as the dynamic programming <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b47">48]</ref>, incremental computation <ref type="bibr" target="#b35">[36]</ref>, and the inverse computation <ref type="bibr" target="#b44">[45]</ref>. So with homomorphism, we are able to add other useful algorithmic computation patterns as skeletons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Design Issues</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Challenges in Design of Parallel Skeletons</head><p>The features of homomorphism indicate that homomorphism can serve as the basis of our skeleton design. A big challenge is how to formalize parallel data structures in an algebraic way such that homomorphisms manipulating these data in parallel can be derived. It has been shown that useful data structures like lists, nested lists, and trees can be described algebraically but sequentially. Recall the above definition of IntList. Though it is constructive, it is not in parallel in the sense that there is an order on the construction. As a matter of fact, it remains open how to constructively define parallel data structures, in particular for the irregular data structures like ill-balanced trees and for the nested data structures like dense or sparse matrices.</p><p>In the following, we will first explain in detail the basic idea in the design of data parallel skeletons through the case study on parallel lists. Then, we briefly explain the design of the data parallel skeletons on parallel matrices and parallel trees with a focus on showing how we can constructively define these two parallel data structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Skeletons on Parallel Lists</head><p>Following Constructive Algorithmics, we start with the following definition of a constructive and parallel view of lists (i.e., parallel lists or distributed lists).</p><formula xml:id="formula_2">DList α = Empty | Singleton α | DList α ++ DList α</formula><p>A list (of type DList α) is either the empty list, a singleton list containing a single element (of type α), or the concatenation of two lists (of type DList α) by + + . Concatenation + + is associative, and Empty is its unit.</p><formula xml:id="formula_3">(x ++ y) ++ z = x ++ (y ++ z)</formula><p>Parallelism in this constructive list lies in the associativity of + + , giving many ways of constructing a list, i.e., no specific (sequential) order is imposed on the list construction. For simplicity, we write [ ] for Empty, [a] for Singleton a, and the term [1] ++ <ref type="bibr" target="#b1">[2]</ref> ++ <ref type="bibr" target="#b2">[3]</ref> denotes a list with three elements, often abbreviated to <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Homomorphism on Parallel Lists</head><p>List homomorphisms (or homomorphisms when it is clear from context) <ref type="bibr" target="#b6">[7]</ref> are those functions on parallel lists that promote through list concatenation. More precisely, a function h satisfying the following three equations is called a list homomorphism:</p><formula xml:id="formula_4">h([ ]) = ι ⊕ h([a]) = f (a) h(x ++ y) = h(x) ⊕ h(y)</formula><p>where f and ⊕ are given functions, and ⊕ is associative with the identity unit ι ⊕ . We shall write hom L (f, ⊕, x) for h(x). For example, the function sum(x), summing up all elements in a list x, can be defined as a homomorphism hom L (id, +, x).</p><p>List homomorphism captures a natural recursive computation pattern and can serve as the most essential parallel skeleton on parallel lists, which has been recognized in <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b48">49]</ref>. Intuitively, the above h means that the value of h on the larger list depends in a particular way (using binary operation ⊕) on the values of h applied to the two pieces of the list. The computations of h(x) and h(y) are independent of each other and can thus be carried out in parallel. This simple equation can be viewed as expressing the well-known divide-and-conquer paradigm of parallel programming.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Basic Skeletons</head><p>While list homomorphism is a good parallel skeleton in general, specialized list homomorphisms can be implemented more efficiently. The most important three such skeletons are map, reduce and scan (Figure <ref type="figure">1</ref>).</p><p>Map is the operation that applies a function to every element in a list. Informally, we have</p><formula xml:id="formula_5">map L (f, [x 1 , x 2 , . . . , x n ]) = [f (x 1 ), f (x 2 ), . . . , f (x n )].</formula><p>Reduce is the operation that collapses a list into a single value by repeated application of some associative binary operator. Informally, for an associative binary operator ⊕, we have</p><formula xml:id="formula_6">reduce L (⊕, [x 1 , x 2 , . . . , x n ]) = x 1 ⊕ x 2 ⊕ • • • ⊕ x n .</formula><p>Scan is the operation that accumulates all intermediate results in the computation of reduce. Informally, for an associative binary operator ⊕, we have</p><formula xml:id="formula_7">scan L (⊕, [x 1 , x 2 , . . . , x n ]) = [x 1 , x 1 ⊕ x 2 , . . . , x 1 ⊕ x 2 ⊕ • • • ⊕ x n ].</formula><p>Map, reduce and scan have nice massively parallel implementations on many parallel architectures <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b48">49]</ref>. If f and ⊕ use O(1) computation time, then map L (f, x) can be implemented using O(1) parallel time, and both reduce L (⊕, x) and scan L (⊕, x) can be implemented using O(log n).</p><p>It is worth noting not only that the three skeletons are specialized version of homomorphisms, but also that a homomorphism is a composition of them:</p><formula xml:id="formula_8">hom L (f, ⊕, x) = reduce L (⊕, map L (f, x)).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adding New Skeletons</head><p>Quite often, we need to introduce new parallel skeletons for some specific application domains, but extension of skeletons has been treated in an ad-hoc way.</p><p>In our framework, new skeletons are defined around homomorphisms, that is, new parallel computation patterns are defined with the basic skeletons or the skeletons that are defined upon the basic ones. Theoretically, this is always possible if one does not care about efficiency. Any function f on lists can be expressed as a composition of a projection function with a homomorphism, often called almost homomorphism <ref type="bibr" target="#b17">[18]</ref>:</p><formula xml:id="formula_9">f (x) ≡ fst(hom L (g, ⊕, x))</formula><p>where fst is a projection function returning the first element of a pair, and the function g and the associative operator ⊕ are defined by</p><formula xml:id="formula_10">g(x) = (f ([x]), [x]) (r 1 , x 1 ) ⊕ (r 2 , x 2 ) = (f (x 1 ++ x 2 ), x 1 ++ x 2 ).</formula><p>In practice, we care about efficiency when introducing new domain-specific skeletons. Let us see how we define new skeletons. Suppose we want to introduce a new skeleton poly(⊕, ⊗, x) for capturing the pattern of general polynomial computation: computing on list x = [x 1 , x 2 , . . . , x n ] with two associative operators ⊕ and ⊗ and producing the result of</p><formula xml:id="formula_11">x 1 ⊕ (x 1 ⊗ x 2 ) ⊕ • • • ⊕ (x 1 ⊗ x 2 ⊗ • • • ⊗ x n ).</formula><p>We may define this new skeleton by</p><formula xml:id="formula_12">poly(⊕, ⊗, x) = reduce L (⊕, scan L (⊗, x))</formula><p>and this new skeleton inherits nice properties of homomorphism. As a simple use of this this skeleton, if we choose ⊗ as + and ⊕ as the function bigger to return the bigger of two numbers, then poly(bigger, +, x) will compute the maximum of all the prefix sums of a list x.</p><p>As a matter of fact, a new skeleton can be defined in various ways even with homomorphisms. For the above poly skeleton, we can do better by defining it by</p><formula xml:id="formula_13">poly(⊕, ⊗, x) = fst(hom L (dup, ⊙, x))</formula><p>where dup(a) = (a, a)</p><formula xml:id="formula_14">(a 1 , b 1 ) ⊙ (a 2 , b 2 ) = (a 1 ⊕ (b 1 ⊗ a 2 ), b 1 ⊗ b 2 )</formula><p>provided that ⊗ is distributive over ⊕. This new definition is more efficient since it is a one-pass algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Skeletons on Regularly Nested Data Structures</head><p>Following the same thought of parallel lists, we are defining skeletons to manipulate matrices (a list of lists of the same length), a kind of regularly nested data structures. As explained in Section 3.2.1, we focus ourselves on the key step of giving a constructive and parallel view (representation) of matrices.</p><p>The traditional representations of matrices by nested lists (row-majored or column-majored representations) <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b48">49]</ref> impose much restriction on the access order of elements. Wise et al. <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b50">51]</ref> represented a two-dimensional array by a quadtree, which does not fully expose freedom in the construction of matrices.</p><p>We borrow the idea in <ref type="bibr" target="#b10">[11]</ref> where a more flexible construction of matrices is given for derivation of sequential programs. We define a matrix to be built up by three constructors |•| (singleton), -• (above) and -• (beside) <ref type="bibr" target="#b24">[25]</ref>.</p><formula xml:id="formula_15">DMatrix α = |α| | (DMatrix α) -• (DMatrix α) | (DMatrix α) - • (DMatrix α)</formula><p>Here, |a| constructs a matrix with a single element a. Given two matrices x and y of the same width, x -• y constructs a new matrix where x is located above y. Similarly, given matrices x and y of the same height, x -• y constructs a matrix where x is located on the left of y.</p><p>The parallelism in this definition of matrices is revealed by the following properties of -• and -• .</p><p>1. Constructors -• and -• are associative.</p><p>2. Constructors -• and -• satisfy the following abide (a coined term from above and beside) property.</p><formula xml:id="formula_16">(x - • u) -• (y - • v) = (x -• y) - • (u -• v)</formula><p>Thanks to these properties, a matrix can be represented in many ways. For example, the following 3 × 3 matrix   1 2 3 4 5 6 7 8 9   can be represented by many ways, two of which are given below.</p><formula xml:id="formula_17">(|1| - • |2| - • |3|) -• (|4| - • |5| - • |6|) -• (|7| - • |8| - • |9|) (|1| -• |4| -• |7|) - • (|2| -• |5| -• |8|) - • (|3| -• |6| -• |9|)</formula><p>This is in sharp contrast to the quadtree representation of matrices <ref type="bibr" target="#b26">[27]</ref>, which does not allow such freedom. With this parallel matrices, we can directly define matrix homomorphisms and basic skeletons of map M , reduce M and scan M on parallel matrices. Figure <ref type="figure" target="#fig_0">2</ref> gives informal definitions of three important skeletons on matrices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Skeletons on Irregular Data Structures</head><p>Trees are important and widely used in representing hierarchical structures such as XML, but trees are typically irregular; a tree may be ill-balanced and some tree nodes may have too many children. It is a big challenge to give a constructive definition of parallel trees, which, as far as we are aware, is an open problem.</p><p>For simplicity, we consider binary trees:</p><formula xml:id="formula_18">Tree α = Leaf α | Fork α (Tree α) (Tree α)</formula><p>reading that a tree is either a tree with just a leaf node, or a tree with a root node and left and right trees. This algebraic representation of trees, as often seen very often in literature, cannot describe "good" parallelism in ill-balanced trees. To resolve this problem, we propose the following novel definition for parallel trees:</p><formula xml:id="formula_19">DTree α = Leaf α | ForkL (DTree α) (DTree α) (DTree α) | ForkR (DTree α) (DTree α) (DTree α)</formula><p>DTree can be regarded as a generalization of Tree where internal nodes are trees instead of node elements. Parallelism of this DTree is expressed by the requirement that ForkL and ForkR satisfy the following tree-shift property.</p><formula xml:id="formula_20">ForkL nt (ForkL nt ′ lt ′ rt ′ ) rt = ForkL (ForkL nt nt ′ rt) lt ′ rt ′ ForkL nt (ForkR nt ′ lt ′ rt ′ ) rt = ForkR (ForkL nt nt ′ rt) lt ′ rt ′ ForkR nt lt (ForkL nt ′ lt ′ rt ′ ) = ForkL (ForkR nt lt nt ′ ) lt ′ rt ′ ForkR nt (ForkR nt ′ lt ′ rt ′ ) rt = ForkR (ForkR nt lt nt ′ ) lt ′ rt ′ map L (f, [x1, x2, . . . , xn]) = [f (x1), f (x2), . . . , f (xn)] reduceL(⊕, [x1, x2, . . . , xn]) = x1 ⊕ x2 ⊕ • • • ⊕ xn scanL(⊕, [x1, x2, . . . , xn]) = [x1, x1 ⊕ x2, x1 ⊕ x2 ⊕ • • • ⊕ xn]</formula><p>Figure <ref type="figure">1</ref>. Three basic skeletons on parallel lists (⊕ is associative.)   This property can be considered as a tree-version associatively, compared to the associativity of + + in the definition of parallel lists. With this property, any tree, balanced or imbalanced, can be expressed as a balanced tree, as seen in the example of Figure <ref type="figure" target="#fig_2">4</ref>.</p><formula xml:id="formula_21">map M (f, 0 B B B @ x11 x12 • • • x1n x21 x22 • • • x2n . . . . . . . . . . . . xm1 xm2 • • • xmn 1 C C C A ) = 0 B B B @ f (x11) f (x12) • • • f (x1n) f (x21) f (x22) • • • f (x2n) . . . . . . . . . . . . f (xm1) f (xm2) • • • f (xmn) 1 C C C A reduceM (⊕, ⊗, 0 B B B @ x11 x12 • • • x1n x21 x22 • • • x2n . . . . . . . . . . . . xm1 xm2 • • • xmn 1 C C C A ) = (x11 ⊗ x12 ⊗ • • • ⊗ x1n)⊕ (x21 ⊗ x22 ⊗ • • • ⊗ x2n)⊕ . . . (xm1 ⊗ xm2 ⊗ • • • ⊗ xmn) scanM (⊕, ⊗, 0 B B B @ x11 x12 • • • x1n x21 x22 • • • x2n . . . . . . . . . . . . xm1 xm2 • • • xmn 1 C C C A ) = 0 B B B @ y11 y12 • • • y1n y21 y22 • • • y2n . . . . . . . . . . . . ym1 ym2 • • • ymn 1 C C C A where yij = (x11 ⊗ x12 ⊗ • • • ⊗ x1j)⊕ (x21 ⊗ x22 ⊗ • • • ⊗ x2j)⊕ . . . (xi1 ⊗ xi2 ⊗ • • • ⊗ xij)</formula><formula xml:id="formula_22">map T (f, x1 /\ x2 x3 /\ x4 x5 ) = f (x1) /\ f (x2) f (x3) /\ f (x4) f (x5) reduceT (⊕, ⊗, f, x1 /\ x2 x3 /\ x4 x5 ) = f (x1) ⊕ ((f (x2) ⊕ (f (x4) ⊗ f (x5))) ⊗ f (x3)) uAccT (⊕, ⊗, k, x1 /\ x2 x3 /\ x4 x5 ) = y1 /\ y2 y3 /\ y4 y5 where 8 &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; : y1 = f (x1) ⊕ ((f (x2) ⊕ (f (x4) ⊗ f (x5))) ⊗ f (x3)) y2 = f (x2) ⊕ (f (x4) ⊗ f (x5)) y3 = f (x3) y4 = f (x4) y5 = f (x5) dAccT (⊙, g l , gr, c, x1 /\ x2 x3 /\ x4 x5 ) = z1 /\ z2 z3 /\ z4 z5 where 8 &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; : z1 = c z2 = c ⊙ g l (x1) z3 = c ⊙ gr(x1) z4 = c ⊙ g l (x1) ⊙ g l (x2) z5 = c ⊙ g l (x1) ⊙ gr(x2)</formula><p>For lack of space, we just give informal definitions of the four important skeletons on parallel trees in Figure <ref type="figure" target="#fig_1">3</ref>. All of these skeletons can be efficiently implemented by the tree contraction algorithm [44], as will be seen later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">The SkeTo Library</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">An Overview</head><p>Figure <ref type="figure" target="#fig_3">5</ref> depicts the framework of the SkeTo library <ref type="foot" target="#foot_2">4</ref>with which programmers are allowed to write skeletal parallel programs in C++ in a sequential style. The SkeTo library itself is implemented in standard C++ and MPI, and the optimization mechanism is in OpenC++ [16], a meta-language for C++.</p><p>The SkeTo library provides parallel skeletons for data structures of lists, matrices, and trees. For each data structure, the library consists of two classes (in C++); one provides the definition of parallel data structure, and the other provides the parallel skeletons. The parallel data structures are implemented based on the theory discussed in Section 3, and the implementation conceals the detail of data distribution from the user. The user thus can use the parallel data structures as he or she uses the sequential ones. For each parallel data structure, homomorphism and basic skeletons such as map, reduce, and scan are provided. These skeletons are implemented carefully using the MPI library, and thus skeletal programs with these skeletons run efficiently. The domain-specific skeletons such as poly are not provided but can be added afterwards easily with our basic skeletons as shown in Section 5.2.</p><p>The skeleton library also provides several wrapper functions of MPI to make the skeletal programs look just like sequential ones. We can see some of them in the sample program in the following section (Figure <ref type="figure" target="#fig_5">6</ref>). The parallel programs composed with the skeletons may suffer from poor performance. To resolve this problem, the SkeTo library provides meta optimization mechanism based on the fusion transformation techniques. This mechanism is implemented in OpenC++ and automatically optimizes the skeletal programs. See <ref type="bibr" target="#b40">[41]</ref> for the details of this optimization mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">A Programming Example</head><p>To give a flavor of how to write parallel programs in a sequential style using the SkeTo library, let us consider the computation of the variance of a list [x 1 , x 2 , . . . , x n ].</p><formula xml:id="formula_23">var = n i=1 (x i -ave) 2 /n ave = n i=1 x i /n</formula><p>We can specify the algorithm in the following clear parallel program with our skeletons:</p><formula xml:id="formula_24">variance(x) = var where n = length(x) ave = reduce L (+, x) / n var = reduce L (+, map L (sqr, map L (sub(ave), x))) / n</formula><p>where sqr is a function to square a number, and sub(ave) is a function to subtract ave from a number. The executable C++ code on the SkeTo library for this problem is given in Figure <ref type="figure" target="#fig_5">6</ref>. skeleton::cout &lt;&lt; "average:" &lt;&lt; ave &lt;&lt; "\n" &lt;&lt; "variance:" &lt;&lt; var &lt;&lt; "\n"; MPI functions such as MPI_Init and MPI_Finalize are concealed under the implementation of this function. There are several other wrapper functions of the MPI, for example, the class skeleton::cout (line 19) enables us to output only from the master processor, which often has rank 0, with the same usage as the std::cout. These wrapper functions are helpful for programmers who are not familiar with the MPI.</p><p>The sample program first generates an instance of parallel list structure, data_list (line 11), by specifying a generator function and the size of list. Note that no details about data distribution are revealed on the program, since the constructor automatically distributes the elements in a proper way.</p><p>The sample program then computes the average and the variance with the reduce and the map skeletons (lines <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr">[16]</ref><ref type="bibr" target="#b16">[17]</ref>. The functional arguments passed to the skeletons are function objects, and thus the functions are inline-expanded by the C++ compiler and the overhead of function calls are removed. The map_ow (lines 15, 16) is a specialized version of the map skeleton which overwrites the output on the input list. These specialized skeletons enable users to write more efficient skeletal parallel programs.</p><p>Thanks to the efficient implementation of the skeletons, the skeletal programs show good scalability. Furthermore, by using meta optimization mechanism we can obtain more efficient programs, in which intermediate structures passed between the skeletons are removed. In the sample program, the meta optimizer automatically fuses the successive calls of map_ow and reduce into one. The optimized program As seen so far, users can compose parallel programs easily in a sequential manner, and the obtained programs are reasonably efficient.</p><p>1 template&lt;typename A, typename OP, typename OT&gt; 2 struct poly_odot : public skeleton::binary_function&lt;std::pair&lt;A,A&gt;, std::pair&lt;A,A&gt;,  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Implementation Issues</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Functional Arguments of the Skeletons</head><p>The skeletons take function objects for their functional arguments, and this is beneficial in the point of efficiency and extensibility of the skeletons.</p><p>In the classic C programs we implement skeletons using pointers to the functions. This implementation is much worse than the hand-coded programs because of sorrowful overhead of calling functions. The function objects, on the other hand, can be inline-expanded by the C++ compiler, and thus the skeletal programs implemented with function objects are much more efficient, and in many case they are as efficient as the hand-coded one.</p><p>Furthermore, the function objects are manipulatable like functional programming in conjunction with the template mechanism of C++. For example, we can implement composition of functions and partial-binding of arguments with these mechanisms. This advantage is essential in importing the theoretical results based on Constructive Algorithmics to extend the skeletons (the following section) and to implement the meta optimization mechanism <ref type="bibr" target="#b40">[41]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Extensibility of the Skeletons</head><p>Homomorphism and basic skeletons are provided as ready-made skeletons in the SkeTo library. Other skeletons can be easily implemented with these skeletons. Here, we briefly show how we can extend the SkeTo library for domain-specific purposes, with the example of the poly skeleton.</p><p>A new skeleton can be implemented in the following two steps; first we define the function objects passed to the ready-made skeletons, and then we define the new skeleton by calling the ready-made skeletons with the newly defined function objects. Figure <ref type="figure">8</ref> gives a sample code of implementing poly. In lines 1-11, we define a new function object for ⊙ with function objects for ⊕ and ⊗. The function object for dup can also be defined in the same way. In lines 13-21, we implement the new skeleton by calling basic skeletons map and reduce.</p><p>Defining the new skeletons with basic skeletons is much easier than defining them from scratch. Furthermore, the inline-expansion of function objects and the fusion transformation by the optimization mechanism provide reasonably efficient implementations of the newly defined skeletons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Implementation Issues on Matrices</head><p>The parallel representation of matrices in Section 3 enables us to split any matrix and distribute it in arbitrary sizes and shapes. This is in sharp contrast to traditional representations such as nested lists or quad-trees that restrict the shape of a distributed submatrix to be a list (vector) or a square matrix of the power of two. This freedom of distribution enables the library to use an arbitrary number of processors, and supports the library to be potentially scalable even in heterogeneous environments.</p><p>On this freedom, the library automatically distributes a matrix among processors so that the division of the matrix becomes as square as possible. This block distribution is suitable for the memory hierarchy that recent computers have. Some algorithms require particular distribution manners, such as row-major, column-major or square blocking, for their efficient execution. For example, an efficient algorithm of matrix multiplication needs the shape of the distribution to be square. In those cases, users can control the distribution of matrices by specifying a distribution policy to the library so that the algorithm can be executed efficiently. We provide policies for row-major, column-major, strictly square blocking and roughly square blocking. The skeletons also allow manual distribution for expert users.</p><p>We implemented three specialized homomorphisms in Section 3 and some other useful functions as skeletons. The implementation of the basic matrix skeletons is a straightforward extension of that of list skeletons: the execution of the skeleton consists of local computation on each processor and global tree-style communication among the processors, where the difference is that the computation proceeds in two directions in an arbitrary order.</p><p>The skeletons take two operators satisfying the abide property, while other existing libraries only take one associative and commutative operator. In fact, an associative and commutative operator satisfies the abide property with itself, and thus our matrix skeletons capture wider range of parallel programs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Implementation Issues on Trees</head><p>The parallel structure of binary trees introduced in Section 3 provides the basis of efficient parallel programs manipulating trees. For a given binary tree, we can construct its parallel structure in more than one way, and thus finding a well-distributable parallel structure with reasonably small cost is important. By borrowing the idea of m-bridges <ref type="bibr" target="#b46">[47]</ref>, which are segments in a tree satisfying certain properties on their size, we implemented a two-pass algorithm for constructing parallel structures of trees. This algorithm guarantees the size of the divided trees to be certain factor of evenly-divided size, and the scalability of the parallel programs for binary trees of arbitrary shapes.</p><p>The parallel skeletons for binary trees are implemented based on the tree contraction algorithms. The tree contraction algorithms, first proposed on shared memory architectures <ref type="bibr" target="#b0">[1,</ref><ref type="bibr">44]</ref>, and then extended on hypercube networks <ref type="bibr" target="#b41">[42]</ref>, are distinguished parallel algorithms for computing on trees. We reformalized the algorithms in order to apply them on our parallel tree structures.</p><p>We implemented seven parallel skeletons including the four basic skeletons shown in Section 3 carefully using the MPI. As the list skeletons' case, domain-specific skeletons are implementable by composing these skeletons. For example, consider the following more specific reduction skeleton defined on (sequential) tree with an associative and commutative operator ⊕.</p><formula xml:id="formula_25">reduce ′ T (⊕, Fork n l r) = n ⊕ reduce ′ T (⊕, l) ⊕ reduce ′ T (⊕, r)</formula><p>We can implement it with the ready-made basic skeleton reduce T in the same way as the implementation of the poly skeleton. The simplicity of extending our skeleton library is more worth noting for tree skeletons since writing parallel tree algorithms from scratch is not straightforward. We now briefly remark on the parallel skeletons for general trees. There have been only a few studies on the parallel programming on general trees and they were rather ad hoc. We have formalized the parallel tree skeletons for general trees based on binary tree skeletons <ref type="bibr" target="#b39">[40]</ref>. Under this formalization we have implemented general tree skeletons as wrapper functions of the binary tree skeletons with the same techniques as in adding new skeletons. As far as we are aware, these binary and general tree skeleton library is the first that supports general-purpose tree manipulations in parallel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Applications and Experiments</head><p>SkeTo allows users to write parallel programs for various problems. We have so far written a set of skeletal parallel programs listed below<ref type="foot" target="#foot_3">5</ref> , and measured their speedups. TA-BLE 1 shows the execution times of the programs without the initial data distribution and final data gathering. The first three programs are written with list skeletons, the following four with matrix skeletons, and the last three with tree skeletons.</p><p>The parallel computer environment for the experiments is a PC cluster of sixteen uniform PCs connected with Gigabit Ethernet. Each PC has a CPU of Pentium4 3.0GHz (Hyper Threading ON) and 1GB memory, with Linux 2.6.8 for the OS, gcc 2.95 for the compiler, and mpich 1.2.6 for the MPI.</p><p>• Variance: The program that computes the variance, listed in Figure <ref type="figure" target="#fig_5">6</ref> in Section 4. The number of elements of the input is 10000000. The measurement is of repetition of 100 times.</p><p>• Bracket Matching: The program that solves the bracket matching problem of 4 kinds of brackets <ref type="bibr" target="#b34">[35]</ref>.</p><p>The length of the input string is 10000000. The measurement is of repetition of 100 times.</p><p>• Heat Equation: The program that solves the onedimensional heat equation. The number of elements of the input is 100000. The measurement is of ten unit time.</p><p>• Matrix Multiplication: The program that executes matrix multiplication which is fundamental matrix manipulation. The size of the input matrices is 1000 × 1000. • Maximum Subarray Sum: The program that calculates the maximum of all the subarray (submatrix) sums. The size of the input matrices is 400 × 400.</p><p>• F-Norm: The program that calculates the Frobenius norm of matrices (the square root of the sum of squares of the elements). The size of the input matrices is 4000 × 4000.</p><p>• QR Factorization: The program that calculates QR factorization of a given matrix. It uses Frens and Wise's algorithm <ref type="bibr" target="#b26">[27]</ref>, which is originally developed for quadtrees, and thus this program restricts the number of processors involved in the calculation to be a square number.</p><p>• Height of Tree: The program that computes the height of given binary tree. The number of nodes of the input tree is 2000001.</p><p>• XPath Query: The program that executes XPath query in parallel. The number of nodes of the input tree is 2000001, and the executed query is of five axes.</p><p>• Party Planning: The program that solves a dynamic programming problem on general trees called party planning problem <ref type="bibr" target="#b19">[20]</ref>, which is to find a set of nodes that maximize the sum under certain condition. The number of nodes of the input tree is 1000000.</p><p>The experimental results show good speedups in general. In particular, the results of Variance, Bracket Matching, and F-Norm show almost linear scalability. The results of Heat Equation and Matrix Multiplication show super-linear speedups. This can happen in memory-intensive applications where a large memory space is needed with respect to the cache size. These results prove the efficiency of the programs written with the SkeTo library.</p><p>The programs with tree skeletons are a bit less scalable than those with list or matrix skeletons. This is because even parallel trees cannot be as uniformly distributed as parallel lists or matrices. These results suggest us further work on dividing trees more suitable way.</p><p>Unfortunately the results of Maximum Subarray Sum and QR Factorization show poor speedups. The former is due to the current implementation of the SkeTo which only allows the parallel execution of the outer skeleton when nested calls of skeletons are used. Future version of the SkeTo will allow fully parallelization of nested calls of skeletons. The latter is due to the program that is written to parallelize a part of the recursive execution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>This paper applies the theory of Constructive Algorithms to the design and implementation of the SkeTo library supporting parallel programming in a sequential way. Compared with the existing skeleton libraries <ref type="bibr" target="#b38">[39]</ref>, the SkeTo library attains several new features, which make the system practically useful.</p><p>• It has high description power. Skeletons and their combination are powerful to describe various parallel computations. This is not only theoretically correct, but also convinced by many practical applications being developed.</p><p>• The skeletons can be extended in a compatible way. A new skeleton can be introduced systematically, either as a special case of homomorphism or as a generalization being a combination of homomorphisms, and it inherits the nice properties that homomorphisms have. Therefore, all the skeletons, old or new, coexist in a compatible way.</p><p>• Efficiency can be achieved through systematic optimization. Since all skeletons are basically homomorphisms, many useful calculation rules such as fusion and tupling are easily to be transported here for optimization of skeletal programs.</p><p>• The skeleton library supports a sequential style of parallel programming. It completely hides lower-level details about parallel programming, so that programmers can stand on the algorithmic level and write parallel programs sequentially without problems such as deadlock.</p><p>We are now working to make the SkeTo library more practical to be used widely for parallel programming in sequential style. One of the current issues is to implement the optimization rules for matrix and tree skeletons. In addition, we are interested in how to formalize the control parallel skeletons in theory of Constructive Alogrithmics, which is a challenge but worth consideration.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Three basic skeletons on parallel matrices (⊕ and ⊗ are associative and satisfy the abide property.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Four basic skeletons on parallel trees (⊙, ⊕ and ⊗ are associative, and ⊗ is distributive over ⊕.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Balancing an imbalanced tree.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. The framework of the SkeTo Library.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>1 / 2 3 4 double val; 5 Sub</head><label>1245</label><figDesc>* definitions of header files and other function objects * / struct Sub : public skeleton::unary_function&lt;double, double&gt; { (double val_) : val(val_){ } 6 double operator()(double x) const { return x -val; } 7 }; 8 9 int SketoMain(int argc, char ** argv) 10 { 11 dist_list&lt;double&gt; * as = new dist_list&lt;double&gt;(gen, SIZE); 12 13 double ave = list_skeletons::reduce(add, add_unit, as) / SIZE; 14 15 list_skeletons::map_ow(Sub(ave), as); 16 list_skeletons::map_ow(sqr, as); 17 double var = list_skeletons::reduce(add, add_unit, as) / SIZE;18 19</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. A sample program that computes the variance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>7 .</head><label>7</label><figDesc>The computation time before/after the optimization. runs 1.3 times faster (Figure7) than the original skeletal program. The optimized program is almost the same as the carefully hand-coded program with MPI library functions, and so is the performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>oplus_, OT otimes_) : oplus(oplus_), otimes(otimes_) {} 7 std::pair&lt;A,A&gt; operator()(const std::pair&lt;A,A&gt;&amp; lhs, const std::pair&lt;A,A&gt;&amp; rhs) const { 8 return std::pair&lt;A,A&gt;(oplus(lhs.first,otimes(lhs.second,rhs.first)), 9 otimes(lhs.second, rhs.second));</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>12 13</head><label>12</label><figDesc>Figure 8. A sample code for imlementing the poly skeleton.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 . Speedups for parallel programs with the skeletons</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">P = 1</cell><cell cols="2">P = 2</cell><cell cols="2">P = 4</cell><cell cols="2">P = 8</cell><cell cols="2">P = 16</cell></row><row><cell>Problem</cell><cell>time</cell><cell>ratio</cell><cell>time</cell><cell>ratio</cell><cell>time</cell><cell>ratio</cell><cell>time</cell><cell>ratio</cell><cell>time</cell><cell>ratio</cell></row><row><cell>Variance</cell><cell>38.8</cell><cell>1</cell><cell>19.5</cell><cell cols="2">1.95 10.1</cell><cell>3.85</cell><cell>5.07</cell><cell>7.64</cell><cell>2.48</cell><cell>15.6</cell></row><row><cell>Bracket Matching</cell><cell>115.1</cell><cell>1</cell><cell>57.7</cell><cell cols="2">1.99 29.3</cell><cell cols="2">3.92 14.7</cell><cell>7.80</cell><cell>7.4</cell><cell>15.47</cell></row><row><cell>Heat Equation</cell><cell>86.7</cell><cell>1</cell><cell>43.0</cell><cell cols="2">2.02 20.4</cell><cell>4.25</cell><cell cols="2">7.38 11.8</cell><cell>5.36</cell><cell>16.2</cell></row><row><cell>Matrix Multiplication</cell><cell>14.1</cell><cell>1</cell><cell>5.21</cell><cell cols="2">2.71 2.52</cell><cell cols="2">5.60 1.05</cell><cell cols="2">13.40 0.530</cell><cell>26.62</cell></row><row><cell>Maximum Subarray Sum</cell><cell>6.21</cell><cell>1</cell><cell>3.51</cell><cell cols="2">1.77 2.30</cell><cell cols="2">2.70 1.72</cell><cell cols="2">3.61 1.50</cell><cell>4.15</cell></row><row><cell>F-Norm</cell><cell>0.21</cell><cell>1</cell><cell>0.104</cell><cell cols="2">1.97 0.053</cell><cell cols="2">3.88 0.026</cell><cell cols="2">7.72 0.013</cell><cell>15.01</cell></row><row><cell>QR Factorization</cell><cell>297.1</cell><cell>1</cell><cell>-</cell><cell></cell><cell>-96.60</cell><cell cols="4">3.09 64.76  *  4.64  *  70.47</cell><cell>4.22</cell></row><row><cell>Height of Tree</cell><cell>0.547</cell><cell>1</cell><cell>0.214</cell><cell cols="2">2.55 0.128</cell><cell cols="2">4.28 0.104</cell><cell cols="2">5.25 0.080</cell><cell>6.83</cell></row><row><cell>XPath Query</cell><cell>1.92</cell><cell>1</cell><cell>0.762</cell><cell cols="2">2.52 0.694</cell><cell cols="2">2.77 0.476</cell><cell cols="2">4.04 0.360</cell><cell>5.35</cell></row><row><cell>Party Planning</cell><cell>0.143</cell><cell>1</cell><cell>0.143</cell><cell cols="2">1.00 0.094</cell><cell cols="2">1.51 0.069</cell><cell cols="2">2.07 0.040</cell><cell>3.66</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(* P = 9)</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>See http://www.ipl.t.u-tokyo.ac.jp/SkeTo/ for details including information about how to download the SkeTo system.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>Although the skeleton library is in C++, we explain the principle in this section using Bird Meertens Formalism (BMF for short)<ref type="bibr" target="#b6">[7,</ref> 8], a functional notation designed for program development. BMF is very similar to the functional language Haskell<ref type="bibr" target="#b8">[9]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>SkeTo is an abbreviation for "Skeleton Library in Tokyo", and means "supporter" in Japanese.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>The sources of all the parallel programs are available at the SkeTo web page, so we shall omit detailed explanation due to space limit.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A simple parallel tree contraction algorithm</title>
		<author>
			<persName><forename type="first">K</forename><surname>Abrahamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dadoun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Kirkpatrik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Przytycka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Algorithms</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="287" to="302" />
			<date type="published" when="1989-06">June 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">P3L: A structured high level programming language and its structured support</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bacci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Danelutto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Orlando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pelagatti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vanneschi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Concurrency Practice and Experience</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="225" to="255" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An exploration of the Bird-Meertens formalism</title>
		<author>
			<persName><forename type="first">R</forename><surname>Backhouse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOP Summer School on Constructive Algorithmics</title>
		<meeting><address><addrLine>Ameland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989-09">September 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Research Directions in High-Level Parallel Programming Languages</title>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Banâtre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Métayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings</title>
		<imprint>
			<biblScope unit="volume">574</biblScope>
			<date type="published" when="1991">June 17-19, 1991. 1992</date>
			<pubPlace>Mont Saint-Michel, France</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Two fundamental concepts in skeletal parallel programming</title>
		<author>
			<persName><forename type="first">A</forename><surname>Benoit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computational Science</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3515</biblScope>
			<biblScope unit="page" from="764" to="771" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Flexible skeletal programming with eSkel</title>
		<author>
			<persName><forename type="first">A</forename><surname>Benoit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hillston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gilmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th International Euro-Par Conference</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>11th International Euro-Par Conference<address><addrLine>Euro-Par</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="volume">3648</biblScope>
			<biblScope unit="page" from="761" to="770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Logic of Programming and Calculi of Discrete Design</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bird</surname></persName>
		</author>
		<editor>M. Broy</editor>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page" from="5" to="42" />
		</imprint>
	</monogr>
	<note>An introduction to the theory of lists</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Constructive functional programming</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOP Summer School on Constructive Algorithmics, Abeland</title>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Introduction to Functional Programming using Haskell</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bird</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Prentice Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>De Moor</surname></persName>
		</author>
		<title level="m">Algebras of Programming</title>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Lectures on constructive functional programming</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Bird</surname></persName>
		</author>
		<idno>Technical Monograph PRG-69</idno>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
		<respStmt>
			<orgName>Oxford University Computing Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dattel: A data-parallel C++ template library</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gorlatch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Leshchinskiy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Parallel Processing Letters</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="461" to="472" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Scans as primitive operations</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Blelloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Computers</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1526" to="1538" />
			<date type="published" when="1989-11">November 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Skil: An imperative language with algorithmic skeletons</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Botorog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kuchen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th International on High Performance Distributed Computing (HDPC&apos;96)</title>
		<meeting>5th International on High Performance Distributed Computing (HDPC&apos;96)</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="243" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient high-level parallel programming</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Botorog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kuchen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<biblScope unit="volume">196</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="71" to="107" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A metaobject protocol for C++</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chiba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA&apos;95)</title>
		<meeting><address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-10">October 1995</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="285" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Algorithmic skeletons : a structured approach to the management of parallel computation. Research Monographs in Parallel and Distributed Computing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cole</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<pubPlace>Pitman, London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Parallel programming, list homomorphisms and the maximum segment sum problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cole</surname></persName>
		</author>
		<idno>CSR-25-93</idno>
		<imprint>
			<date type="published" when="1993-05">May 1993</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computing Science, The University of Edinburgh</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bringing skeletons out of the closet: a pragmatic manifesto for skeletal parallel programming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Parallel Computing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="389" to="406" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Introduction to Algorithms</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Cormen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Rivest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Skeletons for data parallelism in P3L</title>
		<author>
			<persName><forename type="first">M</forename><surname>Danelutto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pasqualetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pelagatti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd International Euro-Par Conference (Euro-Par&apos;97)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>3rd International Euro-Par Conference (Euro-Par&apos;97)</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">1300</biblScope>
			<biblScope unit="page" from="619" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Parallel programming using skeleton functions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Darlington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H J</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W N</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>While</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Parallel Architectures and Reduction Languages Europe (PARLE&apos;93)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>of the Conference on Parallel Architectures and Reduction Languages Europe (PARLE&apos;93)</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">694</biblScope>
			<biblScope unit="page" from="146" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Parallel skeletons for structured composition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Darlington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>To</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, PPoPP&apos;95</title>
		<meeting>5th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, PPoPP&apos;95<address><addrLine>Santa Barbara, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="19" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Categories, relations and dynamic programming. thesis</title>
		<author>
			<persName><forename type="first">O</forename><surname>De Moor</surname></persName>
		</author>
		<idno>PRG-98</idno>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
		<respStmt>
			<orgName>Programming research group, Oxford Univ</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Monograph</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A compositional framework for developing parallel programs on two dimensional arrays</title>
		<author>
			<persName><forename type="first">K</forename><surname>Emoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kakehi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Takeichi</surname></persName>
		</author>
		<idno>METR2005-09</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Department of Mathematical Informatics, University of Tokyo</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">A gentle introduction to category theory -the calculational approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fokkinga</surname></persName>
		</author>
		<idno>Lecture Notes</idno>
		<imprint>
			<date type="published" when="1992">1992</date>
			<pubPlace>The Netherlands</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Dept. INF, University of Twente</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">QR factorization with mortonordered quadtree matrices for memory re-use and parallelism</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Frens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Wise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2003 ACM Symp. on Principles and Practice of Parallel Programming</title>
		<meeting>2003 ACM Symp. on Principles and Practice of Parallel Programming</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="144" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A short cut to deforestation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Launchbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conference on Functional Programming Languages and Computer Architecture</title>
		<meeting>Conference on Functional Programming Languages and Computer Architecture<address><addrLine>Copenhagen</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993-06">June 1993</date>
			<biblScope unit="page" from="223" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Constructing list homomorphisms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gorlatch</surname></persName>
		</author>
		<idno>MIP-9512</idno>
		<imprint>
			<date type="published" when="1995-08">August 1995</date>
		</imprint>
		<respStmt>
			<orgName>Fakultät für Mathematik und Informatik, Universität Passau</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Systematic efficient parallelization of scan and other list homomorphisms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gorlatch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Euro-Par&apos;96. Parallel Processing</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Bouge</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Fraigniaud</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Mignotte</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Robert</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">1124</biblScope>
			<biblScope unit="page" from="401" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Optimization rules for programming with collective operations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gorlatch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wedler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lengauer</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IPPS/SPDP&apos;99. 13th Int. Parallel Processing Symp. &amp; 10th Symp. on Parallel and Distributed Processing</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Atallah</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="492" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Formal derivation of efficient parallel programs by construction of list homomorphisms</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Iwasaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Takeichi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Programming Languages and Systems</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="444" to="461" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An accumulative parallel skeleton for all</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Iwasaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Takeichi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11st European Symposium on Programming (ESOP 2002), volume 2305 of Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Grenoble, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002-04">April 2002</date>
			<biblScope unit="page" from="83" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Parallelization in calculational forms</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Takeichi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">25th ACM Symposium on Principles of Programming Languages</title>
		<meeting><address><addrLine>San Diego, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-01">January 1998</date>
			<biblScope unit="page" from="316" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A new parallel skeleton for general accumulative computations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Iwasaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Parallel Programming</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="389" to="414" />
			<date type="published" when="2004-10">October 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Incremental data compression -extended abstract</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jeuring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Navy Environmental Systems Workshop</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Fisher</surname></persName>
		</editor>
		<meeting>the Navy Environmental Systems Workshop</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Theories for Algorithm Calculation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jeuring</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
		<respStmt>
			<orgName>Faculty of Science, Utrecht University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D thesis</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">HPC++: Experiments with the parallel standard template library</title>
		<author>
			<persName><forename type="first">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1997 International Conference on Supercomputing (ICS&apos;97)</title>
		<meeting>1997 International Conference on Supercomputing (ICS&apos;97)</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="124" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A skeleton library</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kuchen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th International Euro-Par Conference</title>
		<meeting>8th International Euro-Par Conference<address><addrLine>Euro-Par</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">2002. 2002</date>
			<biblScope unit="volume">2400</biblScope>
			<biblScope unit="page" from="620" to="629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Design and implementation of general tree skeletons</title>
		<author>
			<persName><forename type="first">K</forename><surname>Matsuzaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Takeichi</surname></persName>
		</author>
		<idno>METR2005-30</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Department of Mathematical Engineering and Information Physics, University of Tokyo</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A fusion-embedded skeleton library</title>
		<author>
			<persName><forename type="first">K</forename><surname>Matsuzaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kakehi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Iwasaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Akashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th International Euro-Par Conference</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004-08">EuroPar 2004. August 2004</date>
			<biblScope unit="volume">3149</biblScope>
			<biblScope unit="page" from="644" to="653" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Optimal tree constraction and term matching on the hypercube and related networks</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Mayr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Werchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="445" to="460" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Functional programming with bananas, lenses, envelopes and barbed wire</title>
		<author>
			<persName><forename type="first">E</forename><surname>Meijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fokkinga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Paterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conference on Functional Programming Languages and Computer Architecture</title>
		<meeting>Conference on Functional Programming Languages and Computer Architecture<address><addrLine>Cambridge, Massachuetts</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991-08">August 1991</date>
			<biblScope unit="volume">523</biblScope>
			<biblScope unit="page" from="124" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Parallel tree contraction and its application. In 6th Annual IEEE Syrup. on the Foundations of Comp</title>
		<author>
			<persName><forename type="first">G</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reif</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="page" from="478" to="489" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Theory and applications of inverting functions as folds</title>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Comput. Program</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="87" to="116" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Patterns and Skeletons for Parallel and Distributed Computing</title>
		<editor>F. Rabhi and S. G.</editor>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Springer Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">List ranking and parallel tree contraction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Reid-Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Modugno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Synthesis Parallel Algorithms</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Reif</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann Publishers</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="115" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Make it practical: A generic linear time algorithm for solving maximum weightsum problems</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sasano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Takeichi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ogawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2000 ACM SIGPLAN International Conference on Functional Programming (ICFP 2000)</title>
		<meeting><address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2000-09">September 2000</date>
			<biblScope unit="page" from="137" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Foundations of Parallel Programming</title>
		<author>
			<persName><forename type="first">D</forename><surname>Skillicorn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Using generative design patterns to generate parallel code for a distributed memory environment</title>
		<author>
			<persName><forename type="first">K</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Szafron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schaeffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Anvik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mac-Donald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PPoPP &apos;03: Proceedings of the ninth ACM SIGPLAN symposium on Principles and practice of parallel programming</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="203" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Representing matrices as quadtrees for parallel processors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Wise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing Letters</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="195" to="199" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
