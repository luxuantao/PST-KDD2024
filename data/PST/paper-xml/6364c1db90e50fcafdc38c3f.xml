<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">OverGen: Improving FPGA Usability through Domain-specific Overlay Generation</title>
				<funder>
					<orgName type="full">VMware</orgName>
				</funder>
				<funder ref="#_Wcc92uV #_qwfZPW9">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sihao</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jian</forename><surname>Weng</surname></persName>
							<email>jian.weng@cs.ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dylan</forename><surname>Kupsh</surname></persName>
							<email>dkupsh@cs.ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Atefeh</forename><surname>Sohrabizadeh</surname></persName>
							<email>atefehsz@cs.ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhengrong</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Licheng</forename><surname>Guo</surname></persName>
							<email>lcguo@cs.ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiuyang</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute of Software</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maxim</forename><surname>Zhulin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rishabh</forename><surname>Mani</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lucheng</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute of Software</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jason</forename><surname>Cong</surname></persName>
							<email>cong@cs.ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tony</forename><surname>Nowatzki</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">OverGen: Improving FPGA Usability through Domain-specific Overlay Generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Reconfigurable architectures</term>
					<term>Domain-specific Accelerators</term>
					<term>FPGA</term>
					<term>CGRA</term>
					<term>Design Automation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>FPGAs have been proven to be powerful computational accelerators across many types of workloads. The mainstream programming approach is high level synthesis (HLS), which maps high-level languages (e.g. C + #pragmas) to hardware. Unfortunately, HLS leaves a significant programmability gap in terms of reconfigurability, customization and versatility: Although HLS compilation is fast, the downstream physical design takes hours to days; FPGA reconfiguration time limits the time-multiplexing ability of hardware, and tools do not reason about cross-workload flexibility. Overlay architectures mitigate the above by mapping a programmable design (e.g. CPU, GPU, etc.) on top of FPGAs. However, the abstraction gap between overlay and FPGA leads to low efficiency/utilization.</p><p>Our essential idea is to develop a hardware generation framework targeting a highly-customizable overlay, so that the abstraction gap can be lowered by tuning the design instance to applications of interest. We leverage and extend prior work on customizable spatial architectures, SoC generation, accelerator compilers, and design space explorers to create an end-toend FPGA acceleration system. Our novel techniques address inefficient networks between on-chip memories and processing elements, as well as improving DSE by reducing the amount of recompilation required.</p><p>Our framework, OverGen, is highly competitive with fixedfunction HLS-based designs, even though the generated designs are programmable with fast reconfiguration. We compared to a state-of-the-art DSE-based HLS framework, AutoDSE. Without kernel-tuning for AutoDSE, OverGen gets 1.2? geomean performance, and even with manual kernel-tuning for the baseline, OverGen still gets 0.55? geomean performance -all while providing runtime flexibility across workloads.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>FPGAs have proven to be highly performant and flexible hardware accelerators for important data-processing workloads (e.g. <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref>), and have garnered significant traction in industry (e.g. <ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref>). Unfortunately, FPGAs pose significant challenges for programmer productivity. With RTL programming at the extreme end of complexity/lowproductivity, the pragmatic options are high-level synthesis (HLS) and overlays, described next.</p><p>In HLS, a high-level language code (e.g. C with #pragmas) is lowered to a hardware state machine, and then passed as RTL to a traditional FPGA synthesis flow. Pragmas specify hints about the optimal hardware structure (e.g. unroll factor, initiation interval), and state-of-the-art frameworks ? Sihao Liu and Jian Weng are co-first authors. like AutoDSE <ref type="bibr" target="#b21">[21]</ref> explore these parameters on behalf of the programmer. While highly effective, HLS limits programmer productivity through high compilation/synthesis times. Also, multiplexing between applications by reflashing the FPGA bitstream takes significant time, taking more than a second to reconfigure modern FPGAs <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b22">22]</ref>. Moreover, HLS designs are specific to the input application: if any flexibility across applications is required, it must be programmed-in explicitly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>High-level Synthesis (HLS)</head><note type="other">App</note><p>Alternatively, FPGA overlays map a coarser grain architecture (e.g. CPUs <ref type="bibr" target="#b23">[23]</ref><ref type="bibr" target="#b24">[24]</ref><ref type="bibr" target="#b25">[25]</ref><ref type="bibr" target="#b26">[26]</ref>, GPUs <ref type="bibr" target="#b27">[27]</ref><ref type="bibr" target="#b28">[28]</ref><ref type="bibr" target="#b29">[29]</ref><ref type="bibr" target="#b30">[30]</ref>, CGRAs <ref type="bibr" target="#b31">[31]</ref><ref type="bibr" target="#b32">[32]</ref><ref type="bibr" target="#b33">[33]</ref><ref type="bibr" target="#b34">[34]</ref>) on top of the FPGA's fine grain abstractions. While overlays reduce compilation/synthesis time and are more general, they experience quite high overheads due to the abstraction gap between general purpose architectures and the low-level fine-grain abstractions exposed by FPGAs. Overlays can be customized with domain-specific extensions <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b35">35]</ref>, but this approach is highly time-consuming.</p><p>Vision and Requirements: Our vision is to use an HLSlike approach where the generated hardware is tuned to input applications, but which targets a highly-flexible overlay architecture instead of a fixed-function pipeline. Figure <ref type="figure" target="#fig_0">1</ref> gives the basic idea, where a set of applications are fed to a design-space exploration (DSE) step to determine the ISA and resource provisioning in the overlay, and compiling a new application (and reconfiguring) is extremely fast. Ideally, small application changes would not require FPGA synthesis.</p><p>We envision four requirements for overlay generation to be successful: 1. the overlay design space must include both system parameters and a broad accelerator design space, 2. it must balance generality versus specialization, depending on the degree of diversity in input applications, 3. the memory system itself should be highly specializable to the application, and 4. it has to get competitive performance with traditional HLS within a reasonable DSE time frame.</p><p>Approach: For the first two requirements, we leverage prior work on flexible multicore system generators (e.g. <ref type="bibr" target="#b36">[36,</ref><ref type="bibr" target="#b37">37]</ref>) and spatial architecture synthesis (e.g. <ref type="bibr" target="#b38">[38]</ref><ref type="bibr" target="#b39">[39]</ref><ref type="bibr" target="#b40">[40]</ref><ref type="bibr" target="#b41">[41]</ref><ref type="bibr" target="#b42">[42]</ref><ref type="bibr" target="#b43">[43]</ref><ref type="bibr" target="#b44">[44]</ref><ref type="bibr" target="#b45">[45]</ref><ref type="bibr" target="#b46">[46]</ref>). Multi-core system generators enable simple scaling in terms of cores, cache and network <ref type="bibr" target="#b36">[36]</ref>. Spatial architecture 1 synthesis can provide accelerators for each core that are tuned to one or more applications. Spatial architectures provide a broad design space from fixed custom datapath accelerators to systolic arrays and vector architectures to coarse grain reconfigurable architectures (CGRAs). This flexibility comes from the graph-based representation of spatial architectures (nodes are PEs, switches, memory units, etc.).</p><p>To enable a highly application-specialized memory-system (requirement 3), our primary insight is that data-reuse structures (e.g. DMA engines, scratchpads) must be incorporated into the spatial architecture design space -i.e. enabling a custom topology connecting reuse structures to compute structures. For the DSE to make good decisions, this requires the compiler to analyze and expose data-reuse analysis to the spatial-scheduler intermediate representation. We refer to this technique as spatial-memory exploration.</p><p>Finally, for requirement 4, we notice that significant time is spent on recompiling workloads as the hardware definition changes. We develop novel techniques for modifying the hardware while preserving the validity of previous compilations. We call these schedule-preserving transformations.</p><p>Implementation and Implications: Our implementation is called OverGen, which integrates two open-source frameworks, the DSAGEN <ref type="bibr" target="#b38">[38]</ref> spatial architecture generation framework and the ChipYard <ref type="bibr" target="#b36">[36]</ref> SoC generator, and extends these with support for FPGA resource modeling at the system level, novel hardware design space extensions, and novel algorithms for DSE-time reduction.</p><p>While much of this work is about the integration of previous ideas and existing frameworks (with some novel extensions), the results are profound: Our evaluation suggests that domain-specific spatial overlays, and the OverGen framework specifically, have the potential to challenge HLS as the defacto FPGA design methodology. Our approach preserves a programmer-friendly interface with short compilation and reconfiguration times, and has competitive performance across many domains compared to the stateof-the-art HLS framework AutoDSE <ref type="bibr" target="#b21">[21]</ref>. Across workload suites of DSP, Machsuite, and Vitis Vision, OverGen achieves geomean speedups of 1.21?, 1.13?, 1.25? speedups over baseline AutoDSE without kernel tuning, and it still reaches comparable performance, 0.71?, 0.37?, 0.65? respectively, with manual kernel tuning for AutoDSE. Our approach also enables overlays that support single or multiple workloads by automatically reasoning about the cross-workload flexibility. 1 Spatial architectures are those that expose low-level aspects of hardware in their ISA, like resource assignment and scheduling of the operand network.   and cutting edge DSE-for-HLS <ref type="bibr" target="#b21">[21]</ref>.</p><p>Paper Organization: Section II gives background on our decoupled-spatial accelerator design space. Section III overviews the approach and benefits. Section IV describes the spatial memory optimization. Section V covers the details of overlay design. Sections VI, VII, and VIII cover implementation, methodology and evaluation, and we conclude after discussing related work in Section IX.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND: SPATIAL ARCHITECTURE SYNTHESIS</head><p>Our approach extends prior work on spatial architecture synthesis to create each overlay tile. This section first gives background on the accelerator execution model and then elaborates on design representation, the compilation and DSE techniques -all are enhanced in this work. We finish this section by describing the intellectual and practical limitations of existing spatial architecture synthesis techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Decoupled-Spatial Execution</head><p>Execution Model: The accelerator execution model we use in this work is decoupled-spatial <ref type="bibr" target="#b47">[47]</ref><ref type="bibr" target="#b48">[48]</ref><ref type="bibr" target="#b49">[49]</ref><ref type="bibr" target="#b50">[50]</ref><ref type="bibr" target="#b51">[51]</ref><ref type="bibr" target="#b52">[52]</ref><ref type="bibr" target="#b53">[53]</ref><ref type="bibr" target="#b54">[54]</ref><ref type="bibr" target="#b55">[55]</ref>. In this model, compute and memory accesses are expressed in a dataflow graph (DFG), and streams define coarse grain patterns of memory access, value generation, or communication. Streams and instructions execute when they receive all inputs required for one instance of their computation, as in ordereddataflow <ref type="bibr" target="#b56">[56]</ref>. An example transformation from source to dataflow graph (DFG) is shown in Figure <ref type="figure" target="#fig_2">2</ref>(a) and 2(b); note the loop is unrolled by two iterations. Spatial Hardware and Mapping: Spatial architectures expose underlying hardware details to the ISA, like the capabilities and connectivity of hardware elements. Figure <ref type="figure" target="#fig_2">2(c)</ref> shows an example represented as an architecture description graph (ADG). The ADG is composed of primitives like processing elements (PEs), switches for routing operands, DMA for generating memory addresses and requests, and ports for synchronizing between memory and compute. The compiler is responsible for mapping instructions, streams, and communication onto appropriate hardware units (e.g. PEs, stream engines, and switches); see the example in Figure <ref type="figure" target="#fig_2">2(d)</ref>.</p><p>Spatial Design Space: The modular nature of spatial hardware and its representation as an ADG, as in Figure <ref type="figure" target="#fig_2">2</ref>(c), lead to a wide design space. The parameters of each component form a rich space which enables tradeoffs among performance, flexibility, and hardware cost. The topology is also flexible, enabling designs from app-specific datapaths, to vector architectures, mesh-CGRAs and much in between.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Spatial Compilers and Pragma Hints</head><p>A compiler that bridges high-level programming language to the decoupled-spatial execution is required to improve the programming productivity. OverGen leverages and extends the DSAGEN C+pragma compiler <ref type="bibr" target="#b38">[38,</ref><ref type="bibr" target="#b57">57]</ref>. For context, two pragma extensions hint transformation decisions:</p><p>#pragma dsa config { #pragma dsa decouple for (i = 0; i &lt; n; ++i) for (j = 0; j &lt; n; ++j)</p><formula xml:id="formula_0">c[i] = a[i+j] * b[j]; }</formula><p>Listing 1: An FIR example annotated with pragmas #pragma dsa config This pragma annotates the scope of decoupled-spatial specialization. All the offloaded code regions within the compound body will be concurrent on the spatial configuration. #pragma dsa decouple This pragma indicates all the memory accesses under the annotated loop level are alias-free if they are accessed by different pointers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generic Transformation:</head><p>The instructions within the innermost loop will be sliced into two subsets, computational and memory access <ref type="bibr" target="#b58">[58]</ref>. All the instructions that transitively depend on the load/store instructions are considered address generation, and the remaining ones are computational <ref type="bibr" target="#b57">[57]</ref>. The computational instructions will be represented in a dataflow graph and fed to a spatial scheduler; and the memory instructions will later be fed to the memory analyzer.</p><p>Idiomatic and Modular Transformation: The compiler's role is to transform the program according to the capability of a particular design instance. If a certain transformation demands a specific hardware feature that is unavailable, a fallback transformation will be applied to guarantee the success of compilation <ref type="bibr" target="#b57">[57]</ref>. After the analysis and transformation, all mapped instructions to the decoupledspatial execution will be replaced by the accelerator ISA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Automated Spatial Accelerator Synthesis</head><p>Our work leverages the spatial accelerator synthesis algorithm proposed in prior work <ref type="bibr" target="#b38">[38]</ref>, where the goal is to find the best single-core accelerator for a set of input workloads. The algorithm essentially performs graph-based simulated annealing on the ADG, using entirely random modifications and an evaluation function based on a simple performance and area model. To make DSE fast, the algorithm can avoid recompiling a kernel if the random hardware changes do not affect that kernel ("schedule repair").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations of prior work:</head><p>We address three key limitations of prior spatial-accelerator synthesis works <ref type="bibr" target="#b38">[38]</ref><ref type="bibr" target="#b39">[39]</ref><ref type="bibr" target="#b40">[40]</ref><ref type="bibr" target="#b41">[41]</ref><ref type="bibr" target="#b42">[42]</ref><ref type="bibr" target="#b43">[43]</ref>:</p><p>? Datapath Limited: Prior work performs spatial synthesis on the datapath of a single-core only, avoiding specializing memories within a core (e.g. scratchpads and their topology), and ignoring the shared memory system. ? Reuse Ignored: Prior systems ignore data-reuse as a firstorder design constraint. This information is required to make good decisions about how to provision memory and network bandwidths, and it must be captured and made available by the compiler. ? ASIC Focused: Prior works focus on developing spatial architectures for ASICs. FPGAs have new challenges for optimizing across multiple resources (BRAMs, LUTs, DSPs, etc.), and present a compelling use case. These limitations prevent prior systems from reasoning about critical design tradeoffs like core-count vs vector-width, scratchpad vs cache size, in-core reuse vs shared bandwidth. To address these limitations, OverGen extends the design space beyond a single core while considering FPGA resources (Section V) and adds reuse and memory access structures into the spatial/graph-level DSE (Section IV) -overall creating a full-stack overlay generation framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. OVERGEN OVERVIEW &amp; TRADEOFFS</head><p>Here we discuss how OverGen spans compilation, design space exploration, and resource modeling, and then overview the design space and key tradeoffs. A. Overview Compilation: Figure <ref type="figure" target="#fig_3">3</ref> shows the overview of OverGen. We begin with the compilation flow, which takes the systemlevel ADG (sysADG) as input. The sysADG defines the spatial accelerator and system design spec, and is created during overlay generation (described later). The programming interface of OverGen is multithreaded C with aforementioned pragmas (details in Section VI-E). The LLVM-based compiler will attempt to create the highest-performance dataflow graph for the spatial accelerator using its knowledge of the available hardware features in the sysADG. The compiler then extracts  the mDFG is enhanced with information about array size, suitability for mapping arrays to scratchpads, and data reuse of each stream. The program represented as an mDFG is then mapped onto the ADG by the spatial scheduler, using the reuse information to make informed decisions. The mDFG could fail to map to the hardware; if so, the compiler will "relax" the DFG complexity by using less aggressive transformations (e.g. reduce unrolling degree <ref type="bibr" target="#b57">[57]</ref>).</p><p>Overlay Generation: The input to the overlay generation is a set of workloads which forms the domain of interest. It is too inefficient to redo the compilation with each step of DSE. Therefore, the compiler generates a set of different mDFGs representing program versions that could be useful for different possible accelerators, and it incrementally recompiles these during DSE.</p><p>Compiled mDFGs are used to guide spatial-accelerator synthesis: all mDFGs are scheduled to an ADG, and the ADG is iteratively updated to maximize the objective (mean performance of the best-performing mDFG for each workload). There are four innovations over prior work: 1. the system and spatial accelerator are co-designed; 2. reuse and array information enables reasoning about memory and cache allocation at the spatial level, and 3. DSE balances FPGA resource utilization, and 4. the mDFG resource utilization guides ADG transformations with schedule-preserving transformations, described in Section V-B.</p><p>Finally, the chosen sysADG will then be lowered to synthesizable RTL for the FPGA, in part leveraging hardware generators from DSAGEN <ref type="bibr" target="#b38">[38]</ref> and ChipYard <ref type="bibr" target="#b36">[36]</ref>. DSAGEN's microarchitecture implementation is enhanced to enable pipelining on FPGAs with tight cycle-time constraints.</p><p>Model Setup: Our FPGA resource utilization model is based on per-hardware element models. Elements with a few parameters (e.g. core) can be exhaustively synthesized. For elements with many parameters, we use a machine-learning (ML) based model, trained from synthesizing a representative design space. Leveraging learned models means that this framework can more easily be ported to other FPGAs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Overlay Design Space</head><p>System Design Space: Our target for the overlay is a homogenous multi-tile (i.e. multicore) where each tile contains an instance of the spatial accelerator, associated with a lightweight control core. Because we target highly-acceleratable workloads, the control cores are kept simple (single issue, small private cache), and are only provisioned for managing accelerator execution. The control cores and accelerators share access to a shared L2 cache over a crossbar-based NoC. Overall we explore the number of tiles, NoC bandwidth, L2 banks (for controlling L2 bandwidth), and L2 capacity.</p><p>Accelerator Design Space: The first order parameter of the accelerator is the number of processing elements (PEs), which determines the maximum compute bandwidth. The topology determines the flexibility, which can be characterized by the number and the radix of switches. We support a variety of functional units (FUs), with datatypes from 8 to 64-bit integer, and single/double precision float. PEs can have a wider bitwidth than each FU, in which case OverGen generates PEs supporting subword SIMD.</p><p>Streams for memory access and data manipulation execute on respective "stream engines":</p><p>? DMA: Memory engine for accessing shared L2.</p><p>? Scratchpad: Memory engine for private scratchpad.</p><p>? Recurrence: Communicating loop-carried dependencies.</p><p>? Generate: Generating affine value sequences.</p><p>? Register: Pulling data from accelerator to control core. All stream engines have a parameterizable bandwidth. Memory stream engines have a capacity (scratchpad only) and parameter for whether parallel indirect access is supported (requires reordering hardware). Finally, Ports connect memory and compute units, enabling synchronization. Their width determines the maximum ingest/egest rates. Ports have a few additional parameters for supporting certain stream patterns (e.g. whether they support automatic padding for non-vectorwidth <ref type="bibr" target="#b56">[56]</ref> and whether they support meta-data about whether the stream has computed a dimension of the loop <ref type="bibr" target="#b57">[57]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Key tradeoffs</head><p>OverGen opens a variety of tradeoffs that were previously difficult to explore and would have required manual effort: Big tiles vs. More tiles: Many acceleratable workloads benefit from vectorization, while others are difficult to vectorize due to irregularity or loop dependencies. This leads to a tradeoff where some domains prefer more small accelerators (less pipeline/vector parallelism) or fewer large accelerators (more pipeline/vector parallelism).</p><p>L2 cache size vs. Scratchpad capacity: Some workloads have regular access to private data that can map to scratchpads, while less regular codes often benefit from hardware managed caches. Each domain requires a tailored allocation.</p><p>Balancing Bandwidths: The overall design space has essentially three levels of memory hierarchy, from shared cache to spatially distributed scratchpads, and reuse in the computation units. Allocating bandwidths across these levels requires understanding the compute bandwidth and data reuse possible in the chosen workloads -these decisions are tightly coupled with accelerator size and number of tiles.</p><p>Compute Density vs. Generality: If the goal of the overlay is to support either many workloads or dissimilar workloads, a more general overlay is required. This tradeoff can be made by constructing a flexible datapath at the cost of more resources, thus affecting all of the above tradeoffs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. SPATIAL MEMORY EXPLORATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Motivating Spatial Memory DSE</head><p>Prior spatial architecture synthesis algorithms assume that all memory elements (scratchpads/DMAs) can communicate with all computation elements. While this simplifies the design space and spatial scheduling, it also prevents the DSE from exploring the best way to connect memories and processing elements together. Figure <ref type="figure" target="#fig_5">4</ref>(a) shows an example design where memory stream engines communicate over essentially a crossbar to the spatial compute units. Figure <ref type="figure" target="#fig_5">4(b)</ref> shows the potential of a system that allows spatial memories, where these engines have local communication with a smaller subset of elements. Similarly, extending this design space enables the possibility of deciding between multiple smaller scratchpads or a single unified scratchpad.</p><p>Making these decisions with existing DFG abstractions is difficult, as they lack two key pieces of information: 1. the relationship between access patterns and data structures, and 2. the size and reuse of these data structures. Together, these can enable reasoning about the validity and performance of spatial memory optimizations.  . Array nodes have edges to streams that consume or produce those arrays, and we include reuse properties on streams. An example is in Figure <ref type="figure" target="#fig_6">5</ref> for a simplified version of FIR. Here, the input array a is stored in scratchpad for higher bandwidth requirement and reuse. The size parameter describes the total size allocated in either DRAM or scratchpad. If it is in scratchpad, the additional space of double-buffering is included. Also, streams are annotated with additional information for computing the reuse factor, including data traffic, data footprint, stationary reuse, and recurrent reuse (see the "Reuse Analysis" paragraph).</p><p>There is now sufficient information in the mDFG to decide which scratchpad to use -i.e., if data can be routed between the scratchpad node in the ADG and PE nodes that consume this data, and if there is enough remaining space in the scratchpad. If there is ever a limited capacity, the reuse information can help determine which array node in the mDFG should be mapped to a scratchpad node; for example, if an array has a stream with stationary reuse at the port, the benefit of exploiting reuse at the scratchpad level could be less than another array without stationary reuse. Note that the reuse information in the mDFG will also be used in the DSE for making system-level design decisions (Section V).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Software Support for Spatial Memory</head><p>To implement spatial memories, we extract array and reuse information from the program, and embed this in the mDFG to utilize during spatial scheduling.</p><p>Array Node Extraction: As it was discussed in Section II, all memory operations under the stream pragma are "restricted" (alias free), so we can extract the arrays involved in the dataflow graph by analyzing the pointer expressions. Specifically, we extract all the array pointers that are transitively used by all the decoupled memory operations. Consider the example in Figure <ref type="figure" target="#fig_6">5</ref>(a): a, b, and c are extracted as array nodes. An array node has three attributes: pointer, footprint, data traffic, and memory reuse.</p><p>Reuse Analysis: Being aware of memory behaviors that can be captured by hardware specializations helps both compiler General Reuse refers to when a memory stream repeatedly accesses a set of data within a program region. Scratchpad is often favored to exploit this reuse, provided there is sufficient capacity. Reuse can be identified by finding a discrepancy between data footprint (array or tile size) and traffic (number of uses). Consider the operand a[i * 32+ii+j] from the innermost loop; the compiler recursively analyzes and joins the memory boundaries touched by each loop, and finally computes that 255 elements are in the memory footprint. To compute the data traffic, the compiler notes that every loop variable is involved in this pointer expression, which means a different element is accessed in each iteration. Thus, the data traffic of this operand is computed by multiplying all loop trip counts, i.e. 32 ? 128 ? 32 = 16384. This indicates that each element is reused an average of 16384  255 times. Indirect memory access, e.g. a[b[?]], can also be analyzed similarly. To simplify, we assume: 1. b[?] is linear and can be analyzed by the above techniques; 2. no memory access will overflow, and the indirect memory access is a uniform distribution over array a. Therefore, data traffic is calculated by multiplying loop trip counts, and the data footprint is the size of array a.</p><p>Stationary Reuse refers to an operand repeatedly reused across the innermost loop so that this operand can be stationary in the compute substrate (e.g. the port FIFO). Consider the b[j] operand: Because the innermost loop ii does not involve the pointer expression, this value is reused across loop ii 32 times. Even though b[j] also has general reuse, it does not provide as much value to map to scratchpad, because much of the reuse is captured as stationary reuse (i.e. in the port).</p><p>Recurrent Reuse refers to when a pair of memory streams repeatedly update a set of data. When this set of data can concurrently fit in the data path pipeline and port FIFO, this pair of streams are favored to use the recurrence stream engine to avoid memory traffic. Consider the c[io * 32+ii]: it repeatedly reads and writes a set of memory touched by ii (i.e. 32 concurrent instances) along with j (i.e. 32 recurrences). Therefore, when there is enough on-chip buffer for these 32 concurrent instances, this pair of streams will be mapped to the recurrence stream engine.</p><p>To sum up, reuse behavior captured by scratchpad, port FIFO, and the recurrence stream engine will all be considered as the reuse factor; this factor is used to calculate the bandwidth pressure of each stream in the DSE performance model (Section V-C). mDFG Scheduling: Enhancing any spatial-scheduling algorithm to support mDFGs is straightforward. The principle is to treat array nodes (the ones representing the data structure), as any other node which must be scheduled onto the ADG, but with unique scheduling constraints. Intuitively, an array node can be mapped to a memory stream engine if:</p><p>1) There is sufficient remaining space (for a scratchpad).</p><p>2) There is a legal route from producers to consumers.</p><p>3) The access pattern of all streams for the array node is supported by the stream engine (e.g. indirect access). The stream engines in our implementation allow more than one array each (as they support multiple concurrent streams), provided there is sufficient capacity. The tradeoff is that the bandwidth must be shared between any associated streams. Thus, even if it is legal to map more than one array to a scratchpad, it is sometimes beneficial to avoid sharing by using a different scratchpad or even just placing the array node onto a DMA stream engine; this can help maximize the utilization of available bandwidth.</p><p>Having reuse info on streams can help resolve these choices. For example, array nodes with stationary reuse at ports (e.g., read the same value X times) provide less benefit when mapped to scratchpads than those array nodes without stationary reuse -this is because their bandwidth consumption is already reduced. These factors must be considered during spatial scheduling; thus, we modify the objective of the spatial scheduler to use the projected performance of the mDFG, which factors in reuse and bandwidth bottlenecks. Because this is a critical portion of the system-level DSE, we explain the performance model in the next section (Section V-C).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. UNIFIED SYSTEM &amp; ACCELERATOR DESIGN SPACE EXPLORATION</head><p>The goal of DSE in OverGen is to codesign the system parameters and accelerator features/topology to maximize FPGA performance on the set of input applications. Here we first give an overview, then discuss a novel technique to use prior schedules to guide spatial DSE, and finally discuss the performance and area modeling techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overlay Design Exploration</head><p>Logically, one iteration of the DSE involves proposing a new ADG for the hardware, recompiling all the workloads to it, and evaluating an objective (performance and FPGA resource use) to guide the next step of DSE -repeat until convergence. We use three main strategies to reduce the time for each DSE iteration.</p><p>First, we attempt to avoid recompilation as much as possible. During standard compilation, the compiler will iteratively back-off from aggressive transformations that require more resources than available (e.g. reduce the vector width and recompile). To avoid this during DSE, the compiler pre-generates different mDFGs for each program region which each use different transformations (different unrolling degrees, use a recurrence stream instead of accumulation, etc.). These different mDFGs are maintained during DSE, and ultimately only one of them needs to be used (only one has to schedule correctly to the ADG). While this increases the up-front cost for the first DSE iteration, it eliminates from-scratch recompilation during DSE.</p><p>Next, we also try to avoid the expensive spatial-scheduling stage of compilation by reusing the mDFG-to-ADG schedules from the prior iteration of DSE. A simple approach is to only re-schedule the portions of the DFG mapped to ADG elements that were modified (i.e. schedule repair <ref type="bibr" target="#b38">[38]</ref>). In addition, we can use information about prior schedules to make a more informed decision about how to modify the ADG (see Section V-B).</p><p>Finally, we leverage the disparity between spatial scheduling time (very high) and system-level design-space exploration (quite low). Rather than explore both ADG design (spatial DSE) and system parameters (system DSE) at the same level of the DSE, it is relatively inexpensive to nest system DSE inside of spatial DSE -i.e. run a full exploration of system parameters every time we modify the ADG. This improves the convergence of the overall DSE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DSE Flow Summary:</head><p>The overall DSE flow is in Figure <ref type="figure" target="#fig_7">6</ref>. At the beginning of each DSE iteration, the spatial DSE will propose a new ADG named ADG * . ADG * is constructed using a combination of random and schedule-preserving transformations (Section V-B). Then, mDFGs are rescheduled onto ADG * , leveraging the prior schedules for any unchanged portions of the ADG. If any program region has no successfully scheduled mDFGs, then ADG * is abandoned, The objective function favors estimated performance first (Section V-C), followed by estimated resources-peraccelerator (Section V-D). This secondary objective encourages the spatial DSE to prune unneeded resources in the ADG, even if it does not lead to more cores or higher performance in the current DSE iteration. The final step is to choose whether to continue with this ADG * , which is done stochastically through a simulated annealing approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Schedule Preserving Transformations</head><p>During each DSE iteration where the Spatial DSE randomly modifies the hardware, it is common that some of the compiled DFGs can become invalidated due to hardware deletions or resource reduction. While this can sometimes be rectified by repairing the schedule to use other resources, it often cannot be. In these cases, the DSE algorithm either has to use a lower-performance schedule, less-vectorized DFG. The repair itself also takes a significant amount of time. This is unfortunate, because this can even happen when deleting units that are not necessary: e.g. a switch that is only used to pass through a value without requiring flexible routing.</p><p>Thus, we introduce the concept of schedule-preserving transformations, which use prior DFG schedules to guide hardware modifications that preserve their validity. Schedule preserving transformations are defined as hardware modifications that simplify the ADG while adding back the minimum capability to support the existing schedules. Thus, in essence, schedule-preserving transformations increase hardware utilization, providing further incentives for the removal of hardware units that provide less value. Specifically, we identified three such transformations:</p><p>Node Collapsing, as shown in Figure <ref type="figure" target="#fig_8">7</ref>(a), occurs when a unit which performs routing (e.g. a switch) is deleted. Here, after the routing node is deleted, any routes on existing schedules that went through the node are used to define new direct hardware connections from their source to their destination. Thus, this transformation preserves prior schedules by ensuring a valid path for routes through a deleted unit.</p><p>Edge Delay Preservation, as shown in Figure <ref type="figure" target="#fig_8">7</ref>(b), preserves the pipeline depth of all operands for a PE when an intervening routing node is deleted. A balanced pipeline depth ensures that all operands arrive at the same time to avoid pipeline bubbles; these bubbles can lower the throughput of the spatial accelerator <ref type="bibr" target="#b59">[59]</ref>. Our approach is to increase peroperand FIFO-depths in the PE (called delay-fifos) whenever this imbalance can be observed on an existing schedule.</p><p>Module-Capability Pruning prunes excess module capabilities, and associated hardware, that are not needed by mapped schedules. Without this transformation, the DSE oftentimes does not have enough incentive to remove some costly capabilities, and more frequently removes capabilities that are actually useful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Performance Model with Spatial Memory</head><p>To estimate performance, we implemented a bottleneckbased analysis that captures system-level design parameters, memory bandwidth at different layers, and computational bandwidth. Specifically, the overall performance is calculated as the weighted geometric mean of the estimated IPC for each mDFG. An mDFG's IPC is calculated by multiplying the maximum instruction bandwidth (mDFG Insts) by the number of tiles and by the lowest bottleneck factor of all levels of the memory system:</p><formula xml:id="formula_1">Perf = (mDFG Insts) ? (# of Tiles) ? min L 1 ...L 3 ( R Production R Consumption )<label>(1)</label></formula><p>The mDFG Insts factor captures vectorization degree, allowing the DSE to explore tradeoffs between higher vectorization degrees and number of tiles. Memory operations, namely load and store operations, are included within the estimated IPC to ensure that vectorization of pure datamovement DFGs is incentivized.</p><p>While counting loads and instructions estimates the ideal IPC, memory bandwidth limitations reduce the observed IPC, as memory subsystems cannot always supply enough data to fulfill computational requirements. We compute the most-bottlenecked performance reduction over L 1 , L 2 , and L 3 , corresponding to the Scratchpad, L2 Cache, and DRAM. This bottleneck factor is calculated by dividing the production and consumption rate (as R Production R Consumption in the previous equation). These factors are calculated as follows, taking into account stream reuse factors (see Section IV-B):</p><formula xml:id="formula_2">R Production = BW L N ,L N+1 ? (# of Banks) R Consumption = ? i=1 ( BW(Stream i ) Reuse(Stream i ) ) ? (# of Shared Tiles)<label>(2)</label></formula><p>In the above equations, the production rate is computed by multiplying the bandwidth and bank count at each memory level. The consumption rate, or data needed to satisfy compute bandwidth, is the sum of compute data required by a single tile, multiplied by the number of tiles at that memory hierarchy level. The single-tile required data is computed as the summation of all stream bandwidths divided by their associated reuse rates. We describe how the bandwidth (BW) and reuse factors are computed at each level: Scratchpad Bandwidth: With scratchpads replicated across tiles, the # of Shared Tiles factor is one, making the bandwidth only depend on vectorization degree. Also, the bandwidth is calculated separately for the read and write port.</p><p>L2 Bandwidth: As L2 Bandwidth is shared amongst tiles, the consumption rate increases with respect to tile count, requiring more banks. Accesses to L2 cache occur when a stream pattern cannot be supported by port reuse or recurrent data stream, without which the required data production rate will be increased -thus demanding more L2 Banks.</p><p>DRAM Bandwidth: Similar to L2 bandwidth, the consumption rate is dependent on both reuse and tile count; however, the total FPGA's DRAM bandwidth is fixed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. ML-based FPGA resource model</head><p>To rapidly predict FPGA resources, the DSE leverages a machine-learning (ML) resource prediction model, which estimates resources on a component-level basis. To generate the ML model, we perform out-of-context synthesis on variations of each hardware unit, shown in Table <ref type="table" target="#tab_3">I</ref>, to train an ML-based FPGA resource model. The component-level ML model implements a 3-layer multi-layer perceptron (MLP), with an 80%/10%/10% test, train, and validation data split. As the FPGA resource model was synthesized out-of-context with no synthesis optimization passes being performed, our model behaves pessimistically -the projected design point is larger than the actual post-PnR result.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. OVERGEN MICROARCHITECTURE &amp; IMPLEMENTATION</head><p>Our implementation of OverGen integrates prior frameworks for spatial architecture generation <ref type="bibr" target="#b38">[38]</ref> and SoC generation <ref type="bibr" target="#b36">[36]</ref> -both implemented in Chisel <ref type="bibr" target="#b60">[60]</ref>. We also extend these frameworks with an implementation of spatial memories and a high-utilization memory pipeline suitable for FPGAs. In this section, we first discuss the microarchitecture of generated accelerators, show how they interact with the rest of the system and introduce our implementation of two key components of OverGen: the stream dispatcher and stream engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Implementation Overview</head><p>Figure <ref type="figure">8</ref> shows a high-level block diagram of an example dual-tile OverGen overlay architecture mapped to a Xilinx VCU118. Each OverGen tile (colored in light-blue) is composed of a RISC-V Rocket <ref type="bibr" target="#b61">[61]</ref> control core (colored in orange) and one instance of the spatial accelerator. The control-core sends commands and synchronizes with the accelerator over the RoCC interface <ref type="bibr" target="#b62">[62]</ref>, and the spatial accelerator uses a TileLink <ref type="bibr" target="#b63">[63]</ref> DMA for memory access.</p><p>Within the spatial accelerator, the stream dispatcher connects the control-core to the spatial memory system, and coordinates stream execution. All units inside the spatial memory system are stream engines, whose responsibility is data movement to and from ports and memories. Stream engines share a common pipelined implementation.</p><p>In the remainder of this section, we discuss how we achieve high utilization in the stream-dispatcher and stream-engines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Stream Dispatcher Microarchitecture</head><p>The stream dispatcher is designed to connect the control core to the spatial memory system, and manage stream execution for an arbitrary number of stream engines. Figure <ref type="figure" target="#fig_10">9</ref> shows the hardware organization, and we explain intuitively by describing streams' execution over their lifetime. Each stream's lifetime has three steps: stream config, stream instantiation and stream synchronization.</p><p>1 The control core communicates stream parameters and commands that finalize stream creation to the stream dispatcher. The stream dispatcher holds a register file for these parameters so that they can be reused if unchanged across streams. The stream config step updates this register file. 2 When a stream finalization command is sent, the stream instantiation step will decode the register values and create an elaborated stream entry for its corresponding stream engine in the stream dispatch queue. 3 The stream dispatch queue uses a basic Tomasulo algorithm <ref type="bibr" target="#b64">[64]</ref> at stream synchronization to see whether its required resource (stream engines, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spad</head><p>Reg.</p><p>In   Performance Characteristics: This unit can dispatch one stream per cycle, and up to N number of streams can complete per cycle (N = number of total stream engines). The minimum latency of RISC-V instruction completion to stream dispatch is 2 cycles (one for parameter configuration, one for dispatch if no resource conflict found).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System Integration &amp; Reconfiguration:</head><p>The stream dispatcher is also responsible for bridging other interfaces to the accelerator side for the purpose of system integration. OverGen-generated accelerators attach to the Network-on-Chip (NoC) directly to coherently share a banked inclusive L2 cache with other cores. The accelerator shares the page table walker (PTW) of control-core for local TLB support. The accelerator also uses D-cache to load its configuration bitstream to re-program the computing substrate (Figure <ref type="figure" target="#fig_10">9</ref> right edge). Such reconfiguration bitstream reload is triggered by a write to bitstream address and bitstream size registers in stream register file. When this bitstream is returned from D-cache, it passes through a customized network to perform reconfiguration on the spatial computing network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Stream Engine Microarchitecture</head><p>Our goal is to design a modular stream engine generator that works for the combinations of supported stream patterns (1D/2D/3D ? Affine/Indirect ? DMA/Scratchpad). Each feature can be turned off individually to save resources if not needed in a given domain. Figure <ref type="figure" target="#fig_11">10</ref> shows the microarchitecture and pipeline design for stream engines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview of Common Stages:</head><p>The first stage, Stream Issue, is where the stream table receives decoded stream entries from the stream dispatcher. The stream table selects one stream entry to be sent to the Stream Request stage  The Stream Request will generate the memory request packet based on the elaborated stream entry. After accessing memory blocks or obtaining the expected value at the Stream Generation stage, the responses (only for memory read or recurrence) will be forwarded to a Re-order Buffer (only for DMA and indirect scratchpad), where the responses are re-ordered in request order. The responses will eventually be sent to its destination input ports and eventually consumed by In Port(s).</p><p>Stream Issue: After being dispatched, the stream entry first arrives at the stream table, where the meta information for each stream are recorded. The stream table aggregates the readiness across all valid streams and selects one to be issued to the stream request generator. The readiness of each stream is determined by whether any associated input ports have enough space (read stream) and output ports have enough data to consume (write stream).</p><p>The stream table is designed to be fully pipelined. The difficult case is when there is only one active stream. Since the stream table needs to hold the outstanding meta info for each stream, it is designed to be flip-flop based. Thus, the updated stream entry can only be reflected in the next cycle and issued in the subsequent cycle, creating a pipeline bubble. To fully-pipeline a single stream, a one-hot detector is added beside the stream table, where if only one stream is active, the stream table will be bypassed by the updated stream entry from the stream request stage. Figure <ref type="figure" target="#fig_13">11(a)</ref> shows the bubble in the waveform without the bypass, where the issue rate is one every two cycles. Figure <ref type="figure" target="#fig_13">11(b)</ref> shows that adding the bypass doubles the issue rate.</p><p>Stream Request: After being issued from the stream table, stream entries will be converted to memory request packets (address, mask, read/write, etc.) in the Stream Request stage. For affine stream patterns, the task of the request generator is to generate a memory access bitmask based on the address and number of bytes to be accessed, described in TileLink protocol <ref type="bibr" target="#b63">[63]</ref>; As for indirect stream patterns, an indirect request generator containing a set of adders is introduced. Such adders are used to add the start address of stream a with its multiple index values (values of stream b) to calculate the actual addresses of indirect streams like a[b <ref type="bibr">[i]</ref>]. The Stream Request stage is also responsible for calculating the next-cycle stream state that will be written back to the stream table for the next request (or bypassed when there is only one stream).</p><p>Stream Generation: The Stream Issue and Stream Request stages create continuous requests that will eventually produce data that will be consumed by the computing fabric in the Stream Generation stage, which is specific to each stream engine.</p><p>DMA accesses virtual memory, where memory requests from Stream Request will 1. reserve an entry in the ROB; 2. access a private TLB and PTW shared with the control-core; 3. Memory request interface connects directly to NoC, which allows accelerator access to L2 cache (LLC) directly; 4. Memory response will be sent to ROB to complete the memory transaction.</p><p>Other units are intuitive: The Generate Engine generates affine value sequences, similar to the patterns supported by affine memory streams. The Recurrence Engine forwards write data payload from output ports directly to input ports. The Register Engine enables scalar value collection from an output port to control-core directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. OverGen Implementation</head><p>Specific design constraints should be followed to maximize the FPGA resource utilization (for larger or more accelerators) and minimize the critical path (for higher frequency). Besides resource constraints, FPGA requires careful consideration on timing since Configurable Logic Blocks (CLB) are pre-placed and clock sources are pre-defined. Bad implementations (e.g. large combinational logics) or complex designs (e.g. multiclock region) can significantly hurt the frequency. Therefore, OverGen follows two design principles to attempt to solve these two challenges: 1) Conservatively design and add extra pipeline stages while maintaining fully-pipelined execution. 2) Build each module by using pre-built FPGA IP for higher frequency and better utilization.</p><p>Conservative pipeline: One challenge is the added delay of cross-die interconnects on the latest FPGAs <ref type="bibr" target="#b65">[65]</ref>. These are present on Xilinx FPGAs, which use multiple dies connected by silicon interposers in order to increase the number of logic elements on a single device. In addition, specialized IP blocks such as the DRAM controllers or HBM controllers have fixed locations, and interacting modules are also more constrained in their layout. Together, these factors lower the final clock frequency.</p><p>To mitigate the timing degradation caused by die-crossing delays, we conservatively insert additional pipelines. We explicitly add extra stages between the stream dispatcher and all stream engines to relax the timing budget on the stream dispatch bus. Moreover, the DMA engine is responsible for main memory access, which requires it to closely interact with the NoC and then the DRAM controller. The fixedlocation of the DRAM channel on the FPGA encourages per-tile DMA engines to be placed near the DRAM controller, as shown in Figure <ref type="figure" target="#fig_2">12</ref>, so we also add extra pipeline stages inside DMA read/write ports that connect to the NoC. The stream engines are also conservatively pipelined, as shown in Figure <ref type="figure" target="#fig_11">10</ref>, because they bridge other accelerator pieces: stream dispatcher, in/out ports, and compute fabric.</p><p>FPGA IP Optimization: We adapt the overlay design to make use of the specialized memory and DSP blocks available on the FPGA fabric. For example, using the Block RAM hard blocks for scratchpad and ROB. Also, mapping floating point computation to dedicated DSPs significantly increases the achievable frequency compared to mapping with LUTs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Limitations &amp; Future works</head><p>Threading Interface: The current pthread-like programming interface assumes a one-to-one mapping of threads to tiles, where threads run to completion uninterrupted. Also, the performance models assume that all tiles are parallelizing the same code region, and this is our convention when implementing kernels. We also do not manage the interaction between host and FPGA in terms of offloading or data movement. A more sophisticated programming interface, task model (e.g. <ref type="bibr" target="#b66">[66]</ref><ref type="bibr" target="#b67">[67]</ref><ref type="bibr" target="#b68">[68]</ref><ref type="bibr" target="#b69">[69]</ref>), and analytical models could significantly expand usability.</p><p>Processing Elements: Our current implementation of processing elements only supports a dedicated instruction execution model; in contrast, the use of shared PEs (either static <ref type="bibr" target="#b70">[70,</ref><ref type="bibr" target="#b71">71]</ref> or dynamically scheduled <ref type="bibr" target="#b56">[56,</ref><ref type="bibr" target="#b72">72,</ref><ref type="bibr" target="#b73">73]</ref>) can potentially support kernels with larger code regions and get higher utilization for kernels with more complex control flow.</p><p>Compilation Support: Although our processing elements already support a predication-based control lookup table for conditional execution, our compiler has only limited support for converting arbitrary control flow to predication based dataflow execution. A more general dataflow control flow model (e.g. <ref type="bibr" target="#b74">[74,</ref><ref type="bibr" target="#b75">75]</ref>) is future work. Meanwhile, our compiler only supports data parallel loop unrolling when exploring DFG resource occupation (i.e. DFG size). When it comes to exploiting overlapping data reuse between subsequent loop iterations, we still require manual unrolling to take advantage. This can be improved by integrating prior work on reuse distance analysis <ref type="bibr" target="#b76">[76]</ref>. Also, our reuse analysis relies on strong assumptions on compilation-time determined loop trip count and array shape. One of our future directions is to support dynamical array shape and loops. Table <ref type="table" target="#tab_3">II</ref>: Workload specification: size, data type, input/output ports, and multiply, add, div ops in the best DFG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. METHODOLOGY</head><p>Benchmarks: We selected 19 workloads from different domains: 9 from Xilinx Vitis computer vision library, 5 from the digital signal processing (DSP) domain targeted by REVEL <ref type="bibr" target="#b56">[56]</ref>, and 5 from MachSuite <ref type="bibr" target="#b77">[77]</ref> for commonlyaccelerated workloads. The data size and data type are shown in Table <ref type="table" target="#tab_3">II</ref>.</p><p>Baseline: We evaluate OverGen in terms of speedup, compilation, DSE time and device reprogram time. We compare against the state-of-the-art HLS technology, AutoDSE <ref type="bibr" target="#b21">[21]</ref>, as our baseline by using Merlin Compiler (2020.3) and Xilinx Vivado (2020.2). Because AutoDSE benefits significantly from manual kernel tuning, we evaluate both against nontuned and tuned code versions for AutoDSE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Compiler support:</head><p>We augment the open-source DSAGEN <ref type="bibr" target="#b38">[38]</ref> compiler with spatial memory support. An extended Clang and LLVM compiler transform the pragma-annotated program into RISC-V assembly, and the RISC-V GNU toolchain is modified for binary generation.</p><p>Hardware Generation &amp; Verification: OverGen augments the Chisel-based DSAGEN hardware generator <ref type="bibr" target="#b38">[38]</ref> by extending it to full system-level with a modular spatial memory system as described in Section IV. After obtaining RTL from hardware generation, we further verify the functional completeness as a full system with RISC-V binaries on RTL cycle-level by using Synopsys VCS before FPGA verification.</p><p>System-Level Integration &amp; Experiment Platform: Each accelerator is integrated into ChipYard <ref type="bibr" target="#b36">[36]</ref> as an RoCC accelerator to a small RISC-V Core (Rocket Core). All designs use an 8-way associative directory-based inclusive L2. The generated RTL is further synthesized to Xilinx VCU118 Evaluation board by using Vivado 2021. Because of FPGA implementation difficulties, we were not able to run on our FPGA when multiple DRAM channels were enabled. Thus, we use a single DRAM channel for most experiments, and study the effect of multiple DRAM channels separately using VCS RTL simulation (Eval. Q7).</p><p>Figure <ref type="figure" target="#fig_2">12</ref> shows the floorplan of a Quad-tile General Over-Gen design at 92.87MHz, including the DRAM controller's location. The critical path is around the L2 MSHR logic, and optimizing is beyond the scope of this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. EVALUATION</head><p>The goal of our evaluation is to provide perspective on the opportunities of synthesized spatial overlays as compared to state-of-the-art automated HLS (AutoDSE). This section is organized around 8 key questions, with the takeaways being:</p><p>? OverGen is able to generate reconfigurable designs that can outperform baseline AutoDSE (without kernel tuning) by mean 1.2?, even though the generated designs are more flexible. ? HLS benefits more heavily from kernel tuning, while</p><p>OverGen's execution model and compiler can handle many code patterns natively without software effort. ? New applications within the same domain can be easily deployed on an existing overlay with only modest performance degradation, due to overlay flexibility.</p><p>Q1: How performant are generated overlays? Figure <ref type="figure" target="#fig_3">13</ref> shows the overall performance of OverGen across all workloads, normalized to AutoDSE without kernel tuning. We demonstrate three different kinds of overlays:</p><p>? General Overlay (second bar): A single hand-designed mesh-based accelerator overlay targeting all workloads with maximum vectorization width (512 bit). ? Suite Overlay (third bar): An overlay specialized to each workload suite. Table <ref type="table" target="#tab_3">III</ref> shows the specs of each. Compared to AutoDSE with manual kernel tuning, Over-Gen is able to achieve 0.71?, 0.37?, 0.65? of performance for DSP, Machsuite and Vision respectively, while still maintaining workload-flexibility. This is sensible, as hardware structures for preserving generality and programmability reduce the maximum resource efficiency; Q2 goes into depth on why kernel tuning is more critical for AutoDSE.</p><p>While most suite overlays were at least half the performance of the AutoDSE designs, there were a few outliers. Both stencil-2d and derivative both apply aggressive reuse optimization through a sliding window, which can be well specialized by line buffer architecture on HLS <ref type="bibr" target="#b78">[78]</ref>.</p><p>For ellpack, we have to load a vector to the scratchpads of all cores, but we currently lack broadcast support from DRAM to scratchpad, which wastes significant bandwidth; incorporating stream-based multicast <ref type="bibr" target="#b79">[79]</ref> would be helpful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q2: Impact of kernel tuning across frameworks?</head><p>We studied 9 workloads that benefit from kernel tuning, as shown in Figure <ref type="figure" target="#fig_5">14</ref>. There are 7 workloads where AutoDSE (and its underlying HLS technology) does not handle some code patterns well, leading to lower performance because of increased initiation interval (II: number of cycles between pipeline compute instances). In general, these patterns are more easily supported on OverGen's ISA/compiler. To substantiate this, we manually transform these 7 workloads to improve their II for AutoDSE, and we found 4 opportunities for kernel tuning in OverGen.</p><p>AutoDSE Kernel Tuning: We find that two main manual transformations are useful in these workloads: eliminating variable loop trip counts, and strength reduction for strided access patterns. Table <ref type="table" target="#tab_3">IV</ref> shows the II's before and after these transformations, and the hatched bar in Figure <ref type="figure" target="#fig_3">13</ref> and Figure <ref type="figure" target="#fig_5">14</ref> shows the tuned workloads' performance. Note that all other workloads achieve II=1, and OverGen always achieves II=1. We next discuss each transformation and the affected workloads. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table IV: HLS Initiation Interval (II) Optimization</head><p>Variable Loop Trip Count: HLS prefers a perfect loop nest with fixed trip-count <ref type="bibr" target="#b78">[78]</ref>, but cholesky, fft, and crs all have variable trip counts or imperfect loop bodies. To transform these programs, we replace variable trip counts with a fixed maximum, and push outer-loop computation into the inner loop. We then guard the conditional execution with ifstatements within the inner loop. OverGen supports variable trip-count streams natively (using REVEL's ISA <ref type="bibr" target="#b56">[56]</ref>).</p><p>Inefficient Strided Access: AutoDSE's toolchain has trouble efficiently performing strided memory access with small strides (including accesses that appear strided when observing only the innermost dimension of the access pattern). Such patterns can limit AutoDSE's ability to exploit memory parallelism, either at the BRAM level with multiple ports, or at the DRAM level with memory request coalescing. To help the underlying HLS tools understand the access pattern better, the solution is to perform a strength reduction on any strided accesses using the innermost induction variable (e.g. instead of using i * 4, increment i by 4 in each iteration). OverGen's compiler natively supports strided streams and coalescing adjacent streams.</p><p>Prebuilt Database: AutoDSE has a pre-built database that records the best explorer configuration of AutoDSE for common workloads. gemm is optimized using this database.</p><p>OverGen Kernel Tuning: These software behaviors of interest are more easily captured by the OverGen compiler, so only 4 workloads benefit from source code transformation on OverGen. For fft, we peel the last several iterations, so that strided scalar access can be coalesced to fully utilize the memory bandwidth <ref type="bibr" target="#b38">[38,</ref><ref type="bibr" target="#b57">57]</ref>. For gemm, to minimize I/O traffic into the accelerator and improve reuse, we unroll across two inner-loop dimensions (similar to tensorization <ref type="bibr" target="#b80">[80]</ref>). For stencil-2d and blur, our compiler has limited support for exploiting reuse from overlapped data access between subsequent iterations. Therefore, we manually unrolled the iterations to reuse the overlapped data.</p><p>Overall, while kernel tuning is a helpful avenue for performance improvement in AutoDSE's HLS-based approach, it also more often requires programmer effort to get competitive performance than OverGen for this set of workloads. Q3: How fast is OverGen's DSE?</p><p>Figure <ref type="figure" target="#fig_15">15</ref> shows the DSE and synthesis time comparison between AutoDSE (first bars in each suite) and the suitewise OverGen overlay (right-most hatched bar). Comparing AutoDSE's combined time of synthesizing each application, our DSE constructs a more general accelerator while using only 47% of the time.  Figure <ref type="figure" target="#fig_16">16</ref> shows the resource breakdown of each component, normalized by the total FPGA resources available for both overlay and AutoDSE designs (with kernel tuning). All the generated overlay designs (both per-workload and suite) consume from 81% to 97% of LUTs, which is the limiting factor. Because we would like to preserve some  generality for potential future workloads, our DSE greedily as many resources as possible, even if there is no parallelism or when we are memory bandwidth bound. One of the biggest components in terms of LUTs is the NoC, due to its crossbar-based implementation (prior work observed similar overheads <ref type="bibr" target="#b42">[42]</ref>). AutoDSE tends to consume fewer resources as it favors utilizing less hardware when memory bound or parallelism bound, as generality is not a goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q5: Can additional workloads be mapped to an overlay?</head><p>We perform a "leave-one-out" experiment to study the overlay flexibility. Specifically, we generate an overlay for all but one workload in a suite, then try to map the remaining workload. If that workload can map with relatively high performance, that indicates a more robust design.</p><p>The results are shown for MachSuite in Figure <ref type="figure" target="#fig_8">17</ref>. Most of the workloads can be mapped to the corresponding leave-oneout accelerator, with mean 49.5% performance degradation. Performance loss is caused by datapath specialization, which prevents the optimal spatial mapping; generally, a lessvectorized version is used, which has commensurately less performance. The modest performance loss may be acceptable to an FPGA programmer making incremental changes. We imagine that the compiler could inform the user when a significant performance improvement is expected, to signal when to perform DSE again.</p><p>We use the same setup to evaluate the compile/reconfiguration time, as compilation time is most meaningful on an overlay that was not specifically designed for that workload. Relative to FPGA Reconfig.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reconfig Time</head><p>Figure <ref type="figure" target="#fig_8">17</ref>: "Leave-one-out" Flexibility Evaluation Comparing against AutoDSE-based HLS, our spatial overlay compilation is 10000? faster. Also, reconfiguration is much faster by mean 54000?. This is useful if the desired FPGA functionality changes rapidly, enabling efficient temporal multiplexing at very fine time scales.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q6: How does overlay-generality affect performance?</head><p>OverGen can be used to generate increasingly general designs by incrementally adding more target workloads. Figure <ref type="figure" target="#fig_19">18</ref> shows the results of such an experiment, where we incrementally add workloads and rerun the DSE to analyze how the number of tiles and resource usage changes. We witness the overall datapath (PE + Port + network) use per tile increases as new workloads added to the target set, because the datapath becomes more general. To compensate, the number of tiles decreases from 15 to 10. Because some of the workloads are memory bound, it only costs mean 8% performance to support all workloads in this suite.  Q7: How do more DRAM channels affect performance? Figure <ref type="figure" target="#fig_10">19</ref> shows the performance with varying DRAM channel count, normalized to single-channel DRAM for each design. For AutoDSE, most MachSuite kernels can benefit from multiple DRAMs by mean 25%. Elementwise memory-intensive workloads like mm, gemm 3 , vecm., accu., acc_sqr, acc_wei and deri. can also benefit Q8: Do schedule-preserving transforms improve DSE? Figure <ref type="figure" target="#fig_21">20</ref> compares the DSE algorithm with and without schedule-preserving transformations. Here the x-axis is time in hours, and the y-axis is the DSE's estimated IPC for the whole FPGA. Schedule-preserving transformations help the DSE converge faster to designs that are more-specialized to the workload datapath topologies. Overall, DSE time is reduced by mean 15%, and the estimated IPC is improved by 1.09? (running on the FPGA confirms 1.08x speedup).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. RELATED WORK</head><p>Overlay Architectures: We highlight significant and recent overlay approaches; Li et al. provide an in-depth survey <ref type="bibr" target="#b81">[81]</ref>.</p><p>Soft CPU: FPGA vendors provide soft processor implementations, e.g. Xilinx MicroBlaze <ref type="bibr" target="#b82">[82]</ref> and Intel Nios II <ref type="bibr" target="#b83">[83]</ref>, and there are also many open source works, e.g. SPREE <ref type="bibr" target="#b84">[84]</ref>, iDEA <ref type="bibr" target="#b85">[85,</ref><ref type="bibr" target="#b86">86]</ref>, and OpenRISC <ref type="bibr" target="#b87">[87]</ref>. Some alternatives provide higher-performance microarchitectures, such as multi-issue (e.g. Leon3 <ref type="bibr" target="#b88">[88]</ref>, FPGA-Nehalem <ref type="bibr" target="#b26">[26]</ref>), multi-thread (e.g. Octavo <ref type="bibr" target="#b24">[24]</ref>, CUSTARD <ref type="bibr" target="#b89">[89]</ref>, MT-MB <ref type="bibr" target="#b90">[90]</ref>), multicore with scalable networks (e.g. Heracles <ref type="bibr" target="#b23">[23]</ref>, Kumar et al. <ref type="bibr" target="#b91">[91]</ref>), vector operations (e.g. SIMD-Octavo <ref type="bibr" target="#b92">[92]</ref>, MXP <ref type="bibr" target="#b25">[25]</ref>), as well as VLIW (e.g. TILT <ref type="bibr" target="#b93">[93]</ref>).</p><p>Soft GPGPU: FlexGrip <ref type="bibr" target="#b30">[30]</ref> and MIAOW <ref type="bibr" target="#b94">[94]</ref> are single compute-unit (CU) overlays based on Nvidia and AMD GPU architectures, respectively. FGPU <ref type="bibr" target="#b28">[28]</ref> was able to synthesize multiple CUs on a single FPGA board, with a follow-up work specialized for persistent deep learning <ref type="bibr" target="#b35">[35]</ref>.</p><p>Reconfigurable Architectures: QUKU <ref type="bibr" target="#b95">[95]</ref> is an early example of a 2D-mesh style CGRA overlay. reMORPH is another 2D mesh-based overlay that is built around the FPGA's DSP blocks as primitives <ref type="bibr" target="#b31">[31]</ref>. VDR <ref type="bibr" target="#b96">[96]</ref> is a CGRA overlay which can map short program traces for JITbased compilation. The DySER heterogeneous core/CGRA architecture was also mapped to FPGA <ref type="bibr" target="#b97">[97,</ref><ref type="bibr" target="#b98">98]</ref>. ZUMA is an example of an FPGA-on-FPGA overlay <ref type="bibr" target="#b99">[99]</ref>.</p><p>Customizable Overlays: Interestingly, some overlays allow architecture customization. For example, CREMA <ref type="bibr" target="#b100">[100,</ref><ref type="bibr" target="#b101">101]</ref> and Quickdough <ref type="bibr" target="#b102">[102,</ref><ref type="bibr" target="#b103">103]</ref> leverage templates to customize PEs for each application and speedup the design process. CGRA-ME <ref type="bibr" target="#b104">[104]</ref><ref type="bibr" target="#b105">[105]</ref><ref type="bibr" target="#b106">[106]</ref><ref type="bibr" target="#b107">[107]</ref> and AHA <ref type="bibr" target="#b44">[44,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b108">108]</ref> further introduced architecture description languages for arbitrary topologies and DSE with CGRA mapper involvement. Mocarabe <ref type="bibr" target="#b109">[109]</ref> introduces the communication cost as a firstclass citizen in the compiler to obtain a design with high frequency while still meeting the targeted II. SCRATCH <ref type="bibr" target="#b29">[29]</ref> is a GPU-based overlay based on MIAOW <ref type="bibr" target="#b94">[94]</ref>, which automatically identifies the application-specific demands regarding the instruction set and computing unit capability, and generates a trimmed down GPU design.</p><p>Key Difference to prior Overlays: As compared to these prior frameworks, our overlay-synthesis approach attempts to perform application specialization automatically and across many aspects of the overlay architecture (instructions/topology/execution model/provisioning).</p><p>FPGA Programming: While the overlay approach improves the programmability by providing another layer of abstraction, there are also efforts to directly tackle this problem with new programming languages with lower-level abstractions. As an example, Dahila <ref type="bibr" target="#b110">[110]</ref> generates predictable HLS designs by incorporating time-sensitive affine types into the language. On the other hand, Reticle <ref type="bibr" target="#b111">[111]</ref> proposes an intermediate representation and low-level assembly that explicitly expresses special resources on FPGAs, e.g. LUTs and DSPs. Spatial <ref type="bibr" target="#b112">[112]</ref> is a language designed for implementing accelerators based on parallel patterns. Although these techniques improve the programmability, they do not tackle reconfiguration overheads. Just-in-time compilation frameworks can also reduce the burden of FPGA synthesis <ref type="bibr" target="#b113">[113,</ref><ref type="bibr" target="#b114">114]</ref>.</p><p>A recent approach integrates separate compilation into an FPGA design flow to enable better usability <ref type="bibr" target="#b115">[115,</ref><ref type="bibr" target="#b116">116]</ref>. These works leverage faster compilation/reconfiguration to subregions of the FPGA, and enable linking through a packetswitched network. The RapidStream framework <ref type="bibr" target="#b117">[117]</ref><ref type="bibr" target="#b118">[118]</ref><ref type="bibr" target="#b119">[119]</ref> also partitions a large design for parallel implementation and final re-assembly, but instead uses customized point-to-point and pipelined channels to address the high area and limited bandwidth of packet-switched NoC's in prior work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X. CONCLUSION</head><p>While FPGAs have proven to be extremely effective computational accelerators, their usability is not ideal. The heart of the problem is the limited design space of existing HLS tools, which is inflexible and requires frequent resynthesis. In this work, we develop and evaluate the idea of an alternate HLS paradigm where a highly-flexible overlay is the target architecture. Surprisingly, even though the generated designs are programmable, the overall performance is on-par with state-of-the-art HLS tools.</p><p>Yet there is much more to be explored, and OverGen should be seen as a proof-of-concept for the potential of multicore spatial overlays. Many aspects of the design space can be further specialized to the chosen applications, leveraging the extreme flexibility of FPGAs. Examples include the NoC topology <ref type="bibr" target="#b120">[120]</ref>, NoC protocol <ref type="bibr" target="#b121">[121,</ref><ref type="bibr" target="#b122">122]</ref>, cache policies <ref type="bibr" target="#b123">[123]</ref>, coherence protocol <ref type="bibr" target="#b124">[124]</ref>, and synchronization <ref type="bibr" target="#b125">[125]</ref> to name a few. One broad, underexplored aspect is heterogeneity: including heterogeneous cores, caches, networks, and memories. While our current framework assumes pure single-program parallelization, real systems (e.g. mobile SoCs <ref type="bibr" target="#b126">[126]</ref>, datacenters, VR <ref type="bibr" target="#b127">[127]</ref> and even brain computer interfaces <ref type="bibr" target="#b128">[128]</ref>) often require heterogeneous mixes of workloads with different throughput and latency requirements on the same fabric -this opens up vast potential for these different forms of architecture and microarchitecture heterogeneity. Supporting heterogeneity is challenging both because it adds another dimension to design-space exploration, and because it requires novel system support in virtualization and runtime management of heterogeneous resources.</p><p>Overall, we see spatial overlay synthesis as a potentially disruptive approach for FPGA HLS, and OverGen as springboard for future spatial architecture research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overlay Generation Compared to HLS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>#</head><label></label><figDesc>pr agma c onf i g f or ( i =0; i &lt;n; ++i )c [ i ] = a[ i ] +b[ i ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Decoupled-Spatial Example of Vector Addition</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Overview of OverGen Framework</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>mDFG enables spatial distributed memories in ADG (a) Arch. Desc. Graph(ADG)    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Spatial Memory Enhancement for ADG Memory-enhanced DFGs (mDFG): We enhance DFGs with data structure and reuse information by introducing array nodes, creating what we call a memory-enhanced DFG (mDFG). Array nodes have edges to streams that consume or produce those arrays, and we include reuse properties on streams. An example is in Figure5for a simplified version of FIR. Here, the input array a is stored in scratchpad for higher bandwidth requirement and reuse. The size parameter describes the total size allocated in either DRAM or scratchpad. If it is in scratchpad, the additional space of double-buffering is included. Also, streams are annotated with additional information for computing the reuse factor, including data traffic, data footprint, stationary reuse, and recurrent reuse (see the "Reuse Analysis" paragraph).There is now sufficient information in the mDFG to decide which scratchpad to use -i.e., if data can be routed between the scratchpad node in the ADG and PE nodes that consume this data, and if there is enough remaining space in the scratchpad. If there is ever a limited capacity, the reuse information can help determine which array node in the mDFG should be mapped to a scratchpad node; for example, if an array has a stream with stationary reuse at the port, the benefit of exploiting reuse at the scratchpad level could be less than another array without stationary reuse. Note that the reuse information in the mDFG will also be used in the DSE for making system-level design decisions (Section V).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Memory Reuse Enhancement for DFG optimization and DSE. Our compiler recognizes these patterns and annotates them on the associated stream nodes. Next, we discuss three typical reuse patterns, general, stationary and recurrent through the example in Figure 5(a) and (b).General Reuse refers to when a memory stream repeatedly accesses a set of data within a program region. Scratchpad is often favored to exploit this reuse, provided there is sufficient capacity. Reuse can be identified by finding a discrepancy between data footprint (array or tile size) and traffic (number of uses). Consider the operand a[i * 32+ii+j] from the innermost loop; the compiler recursively analyzes and joins the memory boundaries touched by each loop, and finally computes that 255 elements are in the memory footprint. To compute the data traffic, the compiler notes that every loop variable is involved in this pointer expression, which means a different element is accessed in each iteration. Thus, the data traffic of this operand is computed by multiplying all loop trip counts, i.e. 32 ? 128 ? 32 = 16384. This indicates that each element is reused an average of16384  255 times. Indirect memory access, e.g. a[b[?]], can also be analyzed similarly. To simplify, we assume: 1. b[?] is linear and can be analyzed by the above techniques; 2. no memory access will overflow, and the indirect memory access is a uniform distribution over array a. Therefore, data traffic is calculated by multiplying loop trip counts, and the data footprint is the size of array a.Stationary Reuse refers to an operand repeatedly reused across the innermost loop so that this operand can be stationary in the compute substrate (e.g. the port FIFO). Consider the b[j] operand: Because the innermost loop ii does not involve the pointer expression, this value is reused across loop ii 32 times. Even though b[j] also has general reuse, it does not provide as much value to map to scratchpad, because much of the reuse is captured as stationary reuse (i.e. in the port).Recurrent Reuse refers to when a pair of memory streams repeatedly update a set of data. When this set of data can concurrently fit in the data path pipeline and port FIFO, this pair of streams are favored to use the recurrence stream engine to avoid memory traffic. Consider the c[io * 32+ii]: it repeatedly reads and writes a set of memory touched</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: OverGen's Unified DSE Flow and a new iteration begins. If not, then the system-level exploration (system DSE) exhaustively searches for the best system-design parameters for ADG * (creating sysADG * ) based on estimated performance and resource constraints.The objective function favors estimated performance first (Section V-C), followed by estimated resources-peraccelerator (Section V-D). This secondary objective encourages the spatial DSE to prune unneeded resources in the ADG, even if it does not lead to more cores or higher performance in the current DSE iteration. The final step is to choose whether to continue with this ADG * , which is done stochastically through a simulated annealing approach.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Schedule-preserving Transformation Examples</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Stream Dispatcher Microarchitecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Stream Engine Microarchitecture &amp; Pipeline different stream entries, preventing data hazard. 4 Stream engine performs stream memory access once the elaborated stream entry is dispatched. It frees the resource in the scoreboards on stream completion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>(b) StreamTable w/ One-hot Bypass (a) Stream Table w/o One-hot Bypass strX.Y: The Y-th issue of stream entry at position X of table Bubble Bubble Issue stopped due to backpressure or ports not ready</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Stream Table One-hot Bypass for every cycle, together with its data payload (e.g. write data, indirect index value).The Stream Request will generate the memory request packet based on the elaborated stream entry. After accessing memory blocks or obtaining the expected value at the Stream Generation stage, the responses (only for memory read or recurrence) will be forwarded to a Re-order Buffer (only for DMA and indirect scratchpad), where the responses are re-ordered in request order. The responses will eventually be sent to its destination input ports and eventually consumed by In Port(s).</figDesc><graphic url="image-19.png" coords="10,347.20,78.82,178.21,143.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>2 .Figure 12 :</head><label>212</label><figDesc>Figure 12: Quad-Core OverGen FPGA Floorplan kernel begin offchip and are loaded from FPGA DRAM.Because of FPGA implementation difficulties, we were not able to run on our FPGA when multiple DRAM channels were enabled. Thus, we use a single DRAM channel for most experiments, and study the effect of multiple DRAM channels separately using VCS RTL simulation (Eval. Q7).Figure12shows the floorplan of a Quad-tile General Over-Gen design at 92.87MHz, including the DRAM controller's location. The critical path is around the L2 MSHR logic, and optimizing is beyond the scope of this work.</figDesc><graphic url="image-20.png" coords="12,300.47,62.79,280.28,227.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 15 :</head><label>15</label><figDesc>Figure 15: DSE and synthesis time comparison. Q4: What are the limiting FPGA resources?Figure16shows the resource breakdown of each component, normalized by the total FPGA resources available for both overlay and AutoDSE designs (with kernel tuning). All the generated overlay designs (both per-workload and suite) consume from 81% to 97% of LUTs, which is the limiting factor. Because we would like to preserve some</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 16 :</head><label>16</label><figDesc>Figure 16: FPGA Resource Breakdown</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 18 :</head><label>18</label><figDesc>Figure 18: Incremental Design Optimization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 20 :</head><label>20</label><figDesc>Figure 20: The effects of schedule-preserving transforms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table I :</head><label>I</label><figDesc>Number of Hardware Modules Synthesized</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>?</head><label></label><figDesc>Workload Overlay (fourth bar): An overlay specialized only to a single workload. We first compare against AutoDSE without manual kernel tuning. The general overlay achieves comparable performance to AutoDSE on the DSP suite and MachSuite, and mean 68% of the performance on vision suite. This is because it can only fit at most 4 general tiles, due to the high overhead of the general overlay's datapath and FUs (about</figDesc><table><row><cell>Speedup over AutoDSE</cell><cell cols="2">1/8 1/4 1/2 1 2 4 8 16</cell><cell>chol</cell><cell>fft</cell><cell>fir dsp solv.</cell><cell>mm</cell><cell>gm</cell><cell>stcl-3d</cell><cell cols="3">crs machsuite gemm stcl-2d ellp. Tuned-AD AutoDSE general-OG suite-OG w/l-OG gm chan. bgr2. blur accu. acc_sqr vecm. acc_wei conv. deri. gm vision</cell><cell>Speedup o/ Vanilla AutoDSE</cell><cell>1/8 1/4 1/2 1 2 4 8 16</cell><cell>chol Hatched bar indicates s/w tuned version. fft stcl-3d crs gemm stcl-2d chan. bgr2. blur AutoDSE w/l-OG</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="7">Figure 13: Overall Performance Comparison</cell><cell>Figure 14: Effect of tuned kernels</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Spec.</cell><cell cols="2">Mach.</cell><cell cols="2">Vitis</cell><cell>DSP</cell><cell>General</cell></row><row><cell cols="2">System</cell><cell cols="4">Tile Count L2 #Bank NoC B/W (Byte)</cell><cell cols="2">10 16 64</cell><cell></cell><cell>13 16 64</cell><cell>7 8 64</cell><cell>4 4 32</cell></row><row><cell></cell><cell></cell><cell cols="2">PEs</cell><cell></cell><cell></cell><cell cols="2">20</cell><cell></cell><cell>16</cell><cell>10</cell><cell>24</cell></row><row><cell></cell><cell></cell><cell cols="3">Switches</cell><cell></cell><cell cols="2">17</cell><cell></cell><cell>11</cell><cell>27</cell><cell>35</cell></row><row><cell></cell><cell></cell><cell cols="3">Avg. Radix</cell><cell></cell><cell cols="2">2.9</cell><cell cols="2">2.61</cell><cell>2.85</cell><cell>4.69</cell></row><row><cell cols="2">Accelerator</cell><cell cols="10">Int +/ ? /? Flt. +/ ? / ? / ? x 4/4/0/0 0/0/0/0 6/6/5/2 24/24/24/24 16/14/0 16/15/13 0/0/0 24/24/24 Spad. Cap. (KB) 64 -8, 32 32 Spad. B/W (B/cyc) 32 -32, 32 32 Spad. Indirect? Yes -No, No Yes</cell></row><row><cell></cell><cell></cell><cell cols="4">GEN/REC/REG</cell><cell cols="2">0/0/0</cell><cell cols="2">0/0/0</cell><cell>0/1/0</cell><cell>1/1/1</cell></row><row><cell></cell><cell></cell><cell cols="4">In Ports B/W (B)</cell><cell cols="2">160</cell><cell cols="2">112</cell><cell>152</cell><cell>224</cell></row><row><cell></cell><cell></cell><cell cols="4">Out Ports B/W (B)</cell><cell cols="2">96</cell><cell></cell><cell>48</cell><cell>104</cell><cell>160</cell></row><row><cell></cell><cell></cell><cell cols="10">Table III: Specification of Suite Specific Overlays</cell></row><row><cell cols="12">52% in LUT). The per-suite specialized overlays outperform</cell></row><row><cell cols="12">baseline AutoDSE by a mean 1.2?, primarily due to having</cell></row><row><cell cols="12">2-3? more tiles (i.e. due to specialized network, FUs,</cell></row><row><cell cols="12">and memories). Additionally, the DSP overlay uses two</cell></row><row><cell cols="12">scratchpads to increase bandwidth without requiring more</cell></row><row><cell cols="12">expensive wider accelerator datapaths. The per-workload</cell></row><row><cell cols="12">specialized designs can outperform AutoDSE without kernel</cell></row><row><cell cols="12">tuning by mean 1.45? for similar reasons; the relative</cell></row><row><cell cols="12">improvement over suite-specialized is modest, especially</cell></row><row><cell cols="12">for Vitis, due to the strong similarity between workloads.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>Figure 19: Effects of DRAM channels from multiple DRAM channels. The OverGen Workload Overlays see benefits on a similar set of workloads by mean 19%.</figDesc><table><row><cell>Speedup</cell><cell>1 2 4</cell><cell>5.1</cell><cell>ad-4 ad-2 ad-1</cell><cell>og-4 og-2 og-1</cell></row><row><cell></cell><cell>1/2</cell><cell cols="3">chol fft fir solv. mm stcl-3d crs gemm stcl-2d ellp. chan. bgr2. blur accu. acc_sqr vecm. acc_wei conv. deri.</cell></row></table><note><p><p>3 </p>gemm is a tiled (blocked) implementation of matrix multiply, mm is not</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>Open-source repository: https://github.com/PolyArch/dsa-framework</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENT</head><p>This work was supported by <rs type="funder">NSF</rs> awards <rs type="grantNumber">CCF-1751400</rs> and <rs type="grantNumber">CCF-1937599</rs>, as well as gift funding from <rs type="funder">VMware</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Wcc92uV">
					<idno type="grant-number">CCF-1751400</idno>
				</org>
				<org type="funding" xml:id="_qwfZPW9">
					<idno type="grant-number">CCF-1937599</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Sparse matrix-vector multiplication on fpgas</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Prasanna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 ACM/SIGDA 13th International Symposium on Field-Programmable Gate Arrays, ser. FPGA &apos;05</title>
		<meeting>the 2005 ACM/SIGDA 13th International Symposium on Field-Programmable Gate Arrays, ser. FPGA &apos;05<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="63" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A high memory bandwidth FPGA accelerator for sparse matrix-vector multiplication</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fowers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ovtcharov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Strauss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE 22nd Annual International Symposium on Field-Programmable Custom Computing Machines</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="36" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Processor assisted worklist scheduling for FPGA accelerated graph processing on a shared-memory platform</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Hoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nurvitadhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 27th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="136" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hitgraph: High-throughput graph processing framework on FPGA</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Prasanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Seetharaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2249" to="2264" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">FPGA acceleration of sequence alignment: a survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Salamat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rosing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.02394</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">FANS: FPGA-accelerated near-storage sorting</title>
		<author>
			<persName><forename type="first">W</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-C</forename><forename type="middle">F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE 29th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="106" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">MAXelerator: FPGA accelerator for privacy preserving multiply-accumulate (mac) on cloud servers</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">U</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Rouhani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghasemzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Koushanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Design Automation Conference, ser. DAC &apos;18</title>
		<meeting>the 55th Annual Design Automation Conference, ser. DAC &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cloud-DNN: An open framework for mapping DNN models to cloud FPGAs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 ACM/SIGDA international symposium on field-programmable gate arrays</title>
		<meeting>the 2019 ACM/SIGDA international symposium on field-programmable gate arrays</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="73" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Throughput-optimized OpenCLbased FPGA accelerator for large-scale convolutional neural networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Suda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dasika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohanty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vrudhula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-S</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays</title>
		<meeting>the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="16" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Bonsai: High-performance adaptive merge tree sorting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Samardzic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-C</forename><forename type="middle">F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM/IEEE 47th Annual International Symposium on Computer Architecture, ser. ISCA &apos;20</title>
		<meeting>the ACM/IEEE 47th Annual International Symposium on Computer Architecture, ser. ISCA &apos;20</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="282" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">End-to-end optimization of deep learning applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sohrabizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, ser. FPGA &apos;20</title>
		<meeting>the 2020 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, ser. FPGA &apos;20<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="133" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">AutoSA: A polyhedral compiler for high-performance systolic arrays on FPGA</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2021 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="93" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sextans: A streaming accelerator for generalpurpose sparse-matrix dense-matrix multiplication</title>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sohrabizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-K</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, ser. FPGA &apos;22</title>
		<meeting>the 2022 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, ser. FPGA &apos;22<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="65" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Serpens: A high bandwidth memory based accelerator for general-purpose sparse matrix-vector multiplication</title>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Design Automation Conference (DAC)</title>
		<meeting>the 59th Annual Design Automation Conference (DAC)</meeting>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">GraphLily: Accelerating graph linear algebra on HBM-equipped FPGAs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ustun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hardware acceleration of long read pairwise overlapping in genome sequencing: A race between FPGA and GPU</title>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 27th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="127" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Accelerating SSSP for powerlaw graphs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays</title>
		<meeting>the 2022 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="190" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A reconfigurable fabric for accelerating large-scale datacenter services</title>
		<author>
			<persName><forename type="first">A</forename><surname>Putnam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Caulfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Constantinides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Demme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Esmaeilzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fowers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Gopal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Haselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hauck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Heil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hormati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lanka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Larus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 41st Annual International Symposium on Computer Architecuture, ser. ISCA &apos;14</title>
		<meeting>eeding of the 41st Annual International Symposium on Computer Architecuture, ser. ISCA &apos;14<address><addrLine>Piscataway, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Serving DNNs in real time at datacenter scale with project brainwave</title>
		<author>
			<persName><forename type="first">E</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fowers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ovtcharov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Papamichael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Caulfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Massengill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Alkalay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Haselman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="8" to="20" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Caulfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Putnam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Angepat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fowers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Haselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Heil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Humphrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kaur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A cloud-scale acceleration architecture</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Massengill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ovtcharov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Papamichael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Woods</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lanka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chiou</surname></persName>
		</author>
		<author>
			<persName><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 49th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">AutoDSE: Enabling software programmers to design efficient fpga accelerators</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sohrabizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Des. Autom. Electron. Syst</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2022-02">feb 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fans: Fpga-accelerated near-storage sorting</title>
		<author>
			<persName><forename type="first">W</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-C</forename><forename type="middle">F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE 29th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="106" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Heracles: Fully synthesizable parameterized MIPS-based multicore system</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Kinsy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pellauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Devadas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 21st International Conference on Field Programmable Logic and Applications</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="356" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">OCTAVO: An FPGAcentric processor family</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Laforest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Steffan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays, ser. FPGA &apos;12</title>
		<meeting>the ACM/SIGDA International Symposium on Field Programmable Gate Arrays, ser. FPGA &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="219" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Embedded supercomputing in FPGAs with the VectorBlox MXP matrix processor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Severance</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Lemieux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Intel Nehalem processor core made FPGA synthesizable</title>
		<author>
			<persName><forename type="first">G</forename><surname>Schelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schuchman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chinya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Plate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mattner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Olbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hammarlund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Steibl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual ACM/SIGDA International Symposium on Field Programmable Gate Arrays, ser. FPGA &apos;10</title>
		<meeting>the 18th Annual ACM/SIGDA International Symposium on Field Programmable Gate Arrays, ser. FPGA &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The potential for a GPU-like overlay architecture for FPGAs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kingyens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Steffan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Reconfigurable Computing</title>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">FGPU: An SIMT-architecture for FPGAs</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Al</forename><surname>Kadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Janssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huebner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, ser. FPGA &apos;16</title>
		<meeting>the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, ser. FPGA &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="254" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">SCRATCH: An end-to-end application-aware soft-GPGPU architecture and trimming tool</title>
		<author>
			<persName><forename type="first">P</forename><surname>Duarte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Falcao</surname></persName>
		</author>
		<idno>ser. MICRO- 50 &apos;17</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 50th Annual IEEE/ACM International Symposium on Microarchitecture<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="165" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">FlexGrip: A soft GP-GPU for FPGAs</title>
		<author>
			<persName><forename type="first">K</forename><surname>Andryc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Merchant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tessier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 International Conference on Field-Programmable Technology (FPT)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="230" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">reMORPH: a runtime reconfigurable architecture</title>
		<author>
			<persName><forename type="first">K</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Moghaddam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 15th Euromicro Conference on Digital System Design</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="26" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">MI-TRACA: A next-gen heterogeneous architecture</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ben Abdelhamid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Boku</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 13th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="304" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A highlyefficient and tightly-connected many-core overlay architecture</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Abdelhamid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Boku</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="65" to="277" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Architecture exploration of standard-cell and FPGA-overlay CGRAs using the open-source CGRA-ME framework</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mertens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 International Symposium on Physical Design, ser. ISPD &apos;18</title>
		<meeting>the 2018 International Symposium on Physical Design, ser. ISPD &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="48" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Specializing FGPU for persistent deep learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nurvitadhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sheffield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Langhammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dasu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 29th International Conference on Field Programmable Logic and Applications (FPL)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="326" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Chipyard: Integrated design, simulation, and implementation framework for custom SoCs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Amid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Biancolin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grubb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Karandikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Magyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pemberton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="10" to="21" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Openpiton: An open source manycore research framework</title>
		<author>
			<persName><forename type="first">J</forename><surname>Balkind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lavrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shahrad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wentzlaff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS &apos;16</title>
		<meeting>the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="217" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">DSAGEN: Synthesizing programmable spatial accelerators</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dadu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="268" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Aurora: Automated refinement of coarse-grained reconfigurable accelerators</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tumeo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 Design, Automation &amp; Test in Europe Conference &amp; Exhibition (DATE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1388" to="1393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Iterative search for reconfigurable accelerator blocks with a compiler in the loop</title>
		<author>
			<persName><forename type="first">M</forename><surname>Willsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bod?k</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ceze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TCAD</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="407" to="418" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">REVAMP: A systematic framework for heterogeneous CGRA realization</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Bandara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wijerathne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-S</forename><surname>Peh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS 2022</title>
		<meeting>the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS 2022<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="918" to="932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">A fully pipelined and dynamically composable architecture of CGRA</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>in 22th FCCM</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">ASAP: automatic synthesis of area-efficient and precision-aware CGRAs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tambe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tumeo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th ACM International Conference on Supercomputing, ser. ICS &apos;22</title>
		<meeting>the 36th ACM International Conference on Supercomputing, ser. ICS &apos;22</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Aha: An agile approach to the design of coarse-grained reconfigurable accelerators and compilers</title>
		<author>
			<persName><forename type="first">K</forename><surname>Koul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Melchert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sreedhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nyengele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Setter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Strange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Donovick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Carsello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Huff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Setaluri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bhagdikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Durst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tsiskaridze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bahr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fatahalian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Torng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kjolstad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Embed. Comput. Syst</title>
		<imprint>
			<date type="published" when="2022-04">apr 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Bahr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bhagdikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Carsello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Donovick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Durst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fatahalian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hofstee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Huff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kjolstad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Melchert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Niemetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nyengele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Setaluri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Setter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sreedhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Strange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Torng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tsiskaridze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<title level="m">Creating an agile hardware design flow</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note>in 2020 57th ACM</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">?ir -an intermediate representation for transforming and optimizing the microarchitecture of application accelerators</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sharifian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hojabr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shriraman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>in 52nd MICRO</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Stream-dataflow acceleration</title>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gangadhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ardalani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sankaralingam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>in 44th ISCA</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">MAERI: enabling flexible dataflow mapping over dnn accelerators via reconfigurable interconnects</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Samajdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Krishna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGPLAN Not</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="461" to="475" />
			<date type="published" when="2018-03">Mar. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Plasticine: A reconfigurable architecture for parallel paterns</title>
		<author>
			<persName><forename type="first">R</forename><surname>Prabhakar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koeplinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hadjis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pedram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Olukotun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>in 44th ISCA</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Towards general purpose acceleration by exploiting common data-dependence forms</title>
		<author>
			<persName><forename type="first">V</forename><surname>Dadu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO &apos;52</title>
		<meeting>the 52nd Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO &apos;52<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="924" to="939" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Stream-based memory access specialization for general purpose processors</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 ACM/IEEE 46th Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="736" to="749" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Infinity Stream: enabling transparent and automated in-memory computing</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Architecture Letters</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Stream Floating: Enabling proactive and decentralized cache optimizations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lowe-Power</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gaur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="640" to="653" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Near-Stream Computing: General and transparent near-cache acceleration</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE International Symposium on High-Performance Computer Architecture (HPCA)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="331" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">PolyGraph: Exposing the value of flexibility for graph processing accelerators</title>
		<author>
			<persName><forename type="first">V</forename><surname>Dadu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 ACM/IEEE 48th Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="595" to="608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A hybrid systolic-dataflow architecture for inductive matrix algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dadu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Unifying spatial accelerator compilation with idiomatic and modular transformations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kupsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>IEEE Micro</publisher>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Breaking SIMD shackles with an exposed flexible microarchitecture and the access execute PDG</title>
		<author>
			<persName><forename type="first">V</forename><surname>Govindaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sankaralingam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Parallel Architectures and Compilation Techniques, ser. PACT &apos;13</title>
		<meeting>the 22nd International Conference on Parallel Architectures and Compilation Techniques, ser. PACT &apos;13<address><addrLine>Piscataway, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="341" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Hybrid optimization/heuristic instruction scheduling for programmable accelerator codesign</title>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ardalani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sankaralingam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>in 27th PACT</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Chisel: Constructing hardware in a Scala embedded language</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Waterman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Avi?ienis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wawrzynek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asanovi?</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>in 49th DAC</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">The rocket chip generator</title>
		<author>
			<persName><forename type="first">K</forename><surname>Asanovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Avizienis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Beamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Biancolin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Celio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dabbelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Izraelevitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Karandikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Koenig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Love</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Magyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moreto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Twigg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Waterman</surname></persName>
		</author>
		<idno>UCB/EECS- 2016-17</idno>
		<imprint>
			<date type="published" when="2016-04">Apr 2016</date>
		</imprint>
		<respStmt>
			<orgName>EECS Department, University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">A RISC-V based hardware accelerator designed for Yolo object detection system</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference of Intelligent Applied Systems on Engineering (ICIASE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="9" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Diplomatic design patterns: A TileLink case study</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Terpstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
		<respStmt>
			<orgName>st Workshop on Computer Architecture Research with RISC-V</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Sparacio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Tomasulo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IBM system/360 model 91: machine philosophy and instruction-handling</title>
		<imprint>
			<date type="published" when="1967">1967</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="8" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">AutoBridge: Coupling coarse-grained floorplanning and pipelining for high-frequency HLS design on multi-die FPGAs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ustun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2021 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, ser. FPGA &apos;21</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="81" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Fifer: Practical acceleration of irregular applications on reconfigurable architectures</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">M</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO &apos;21</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>in MICRO-54: 54th</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Taskstream: Accelerating taskparallel workloads by recovering program structure</title>
		<author>
			<persName><forename type="first">V</forename><surname>Dadu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS &apos;22</title>
		<meeting>the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS &apos;22</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Systematically understanding graph accelerator dimensions and the value of hardware flexibility</title>
		<author>
			<persName><forename type="first">V</forename><surname>Dadu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="87" to="96" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">DynPaC: coarse-grained, dynamic, and partially reconfigurable array for streaming applications</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Agostini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tumeo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE 39th International Conference on Computer Design (ICCD)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">MATRIX: a reconfigurable computing architecture with configurable instruction distribution and deployable resources</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mirsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dehon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FCCM</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="17" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">ADRES: an architecture with tightly coupled vliw processor and coarse-grained reconfigurable matrix</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vernalde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Verkest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>De Man</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lauwereins</surname></persName>
		</author>
		<editor>FPL</editor>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Triggered Instructions: a control paradigm for spatially-programmed architectures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Parashar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pellauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ahsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Crago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lustig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gambhir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jaleel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Allmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rayess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Emer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>in 40th ISCA</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Towards generalpurpose acceleration: Finding structure in irregularity</title>
		<author>
			<persName><forename type="first">V</forename><surname>Dadu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">RipTide: a programmable, energy-minimal dataflow compiler and architecture</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gobieski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Heule</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mowry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lucia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>in MICRO-55: 55th</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">4D-CGRA: introducing branch dimension to spatio-temporal application mapping on CGRAs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Karunaratne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wijerathne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-S</forename><surname>Peh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A reuse-aware prefetching scheme for scratchpad memory</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 48th ACM/EDAC/IEEE Design Automation Conference (DAC)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="960" to="965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">MachSuite: benchmarks for accelerator design and customized architectures</title>
		<author>
			<persName><forename type="first">B</forename><surname>Reagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Adolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IISWC</title>
		<imprint>
			<date type="published" when="2014-10">Oct 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Programming heterogeneous systems from an image processing DSL</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Setter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ragan-Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Horowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Architecture and Code Optimization</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2017-08">Aug 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">The Mozart reuse exposed dataflow processor for AI and beyond: Industrial product</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sankaralingam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gangadhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Galliher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Khare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vijay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Palamuttam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Punde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Thiruvengadam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual International Symposium on Computer Architecture, ser. ISCA &apos;22</title>
		<meeting>the 49th Annual International Symposium on Computer Architecture, ser. ISCA &apos;22</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="978" to="992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">UNIT: Unifying tensorized instruction compilation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE/ACM International Symposium on Code Generation and Optimization</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="77" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Time-multiplexed FPGA overlay architectures: A survey</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Maskell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Des. Autom. Electron. Syst</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2019-07">jul 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">MicroBlaze processor reference guide</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Nios II processor reference guide</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">The microarchitecture of FPGA-based soft processors</title>
		<author>
			<persName><forename type="first">P</forename><surname>Yiannacouras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Steffan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 International Conference on Compilers, Architectures and Synthesis for Embedded Systems, ser. CASES &apos;05</title>
		<meeting>the 2005 International Conference on Compilers, Architectures and Synthesis for Embedded Systems, ser. CASES &apos;05<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="202" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">iDEA: a DSP block based FPGA soft processor</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Cheah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Fahmy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Maskell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 International Conference on Field-Programmable Technology</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="151" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">The IDEA DSP block-based soft processor for FPGAs</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Cheah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Brosser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Fahmy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Maskell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Reconfigurable Technol. Syst</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2014-09">Sep. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Openrisc core-based soc platform design and verification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ryoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ITC-CSCC: International Technical Conference on Circuits Systems, Computers and Communications</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="276" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Leon3 gr-xc3s-1500 template design</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gaisler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Isom?ki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Copyright Gaisler Research</title>
		<imprint>
			<biblScope unit="page" from="1" to="153" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">CUSTARD -a customisable threaded FPGA soft processor and tools</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dimond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mencer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Luk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Field Programmable Logic and Applications</title>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Supporting multithreading in configurable soft processor cores</title>
		<author>
			<persName><forename type="first">R</forename><surname>Moussali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A R</forename><surname>Saghir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 International Conference on Compilers, Architecture, and Synthesis for Embedded Systems, ser. CASES &apos;07</title>
		<meeting>the 2007 International Conference on Compilers, Architecture, and Synthesis for Embedded Systems, ser. CASES &apos;07<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="155" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">120-Core MicroAptiv MIPS overlay for the Terasic DE5-NET FPGA board</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kumar H B</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Modi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kapre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, ser. FPGA &apos;17</title>
		<meeting>the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, ser. FPGA &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="141" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Microarchitectural comparison of the MXP and Octavo soft-processor FPGA overlays</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Laforest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Reconfigurable Technol. Syst</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2017-05">May 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Comparing performance, productivity and scalability of the TILT overlay processor to OpenCL HLS</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rashid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Steffan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Betz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 International Conference on Field-Programmable Technology</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="20" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Enabling GP-GPU lowlevel hardware explorations with MIAOW: An open-source RTL implementation of a GP-GPU</title>
		<author>
			<persName><forename type="first">R</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gangadhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Drumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valathol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sankaralingam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Archit. Code Optim</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2015-06">Jun. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">QUKU: A coarse grained paradigm for FPGAs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Becker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Dagstuhl Seminar Proceedings. Schloss Dagstuhl-Leibniz-Zentrum f?r Informatik</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Towards synthesis-free JIT compilation to commodity FPGAs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Capalija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Abdelrahman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 IEEE 19th Annual International Symposium on Field-Programmable Custom Computing Machines</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="202" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Design, integration and implementation of the DySER hardware accelerator into OpenSPARC</title>
		<author>
			<persName><forename type="first">J</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cofell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Frericks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Govindaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sankaralingam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on High-Performance Comp Architecture</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Performance evaluation of a DySER FPGA prototype system spanning the compiler, microarchitecture, and hardware implementation</title>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Hoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Govindarajuz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nagaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Marzec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Frericks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cofell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sankaralingam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="203" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">ZUMA: An open FPGA overlay architecture</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Lemieux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE 20th International Symposium on Field-Programmable Custom Computing Machines</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="93" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">CREMA: A coarsegrain reconfigurable array with mapping adaptiveness</title>
		<author>
			<persName><forename type="first">F</forename><surname>Garzia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nurmi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 International Conference on Field Programmable Logic and Applications</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="708" to="712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Effects of scaling a coarse-grain reconfigurable array on power and energy consumption</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ahonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nurmi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 International Symposium on System on Chip (SoC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title level="m" type="main">Automatic nested loop acceleration on FPGAs using soft CGRA overlay</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-H</forename><surname>So</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.00042</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Are coarsegrained overlays ready for general purpose application acceleration on FPGAs</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Maskell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Fahmy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE 14th Intl Conf on Dependable, Autonomic and Secure Computing, 14th Intl Conf on Pervasive Intelligence and Computing, 2nd Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="586" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">CGRA-ME: a unified framework for CGRA modelling and exploration</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sakamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hara-Azumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Anderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-07">July 2017</date>
		</imprint>
	</monogr>
	<note>in 28th ASAP</note>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Compact area and performance modelling for CGRA architecture evaluation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">FPT</title>
		<imprint>
			<date type="published" when="2018-12">Dec 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title level="m" type="main">An architecture-agnostic integer linear programming approach to CGRA mapping</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Anderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>in 55th DAC</note>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title level="m" type="main">Generic connectivitybased CGRA mapping via integer linear programming</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Anderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>in 27th FCCM</note>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<title level="m" type="main">Automated design space exploration of CGRA processing element architectures using frequent subgraph analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Melchert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Donovick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raina</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Mocarabe: Highperformance time-multiplexed overlays for FPGAs</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tombs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mellat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kapre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE 29th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="115" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Predictable accelerator design with time-sensitive affine types</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Atapattu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Koti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation, ser. PLDI 2020</title>
		<meeting>the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation, ser. PLDI 2020<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="393" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Reticle: A virtual machine for programming modern FPGAs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Vega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ceze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation, ser. PLDI 2021</title>
		<meeting>the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation, ser. PLDI 2021<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="756" to="771" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Spatial: A language and compiler for application accelerators</title>
		<author>
			<persName><forename type="first">D</forename><surname>Koeplinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Prabhakar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hadjis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fiszel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pedram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Olukotun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Just-in-time compilation for verilog: A new technique for improving the FPGA programming experience</title>
		<author>
			<persName><forename type="first">E</forename><surname>Schkufza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Rossbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS &apos;19</title>
		<meeting>the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="271" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Just-in-time compilation for FPGA processor cores</title>
		<author>
			<persName><forename type="first">A</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sirowy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vahid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 Electronic System Level Synthesis Conference (ESLsyn)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Case for fast FPGA compilation using partial reconfiguration</title>
		<author>
			<persName><forename type="first">D</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Magnezi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dehon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">28th International Conference on Field Programmable Logic and Applications, FPL 2018</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2018">August 27-31, 2018. 2018</date>
			<biblScope unit="page" from="235" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">PLD: fast FPGA compilation to make reconfigurable acceleration compatible with modern incremental refinement software development</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Micallef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Butt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goldsmith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Merczynski-Hait</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dehon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS &apos;22: 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</editor>
		<meeting><address><addrLine>Lausanne, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2022-02-28">28 February 2022 -4 March 2022. 2022</date>
			<biblScope unit="page" from="933" to="945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">RapidStream: parallel physical implementation of FPGA HLS designs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maidee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lavin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kaviani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays</title>
		<meeting>the 2022 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Autobridge: Coupling coarse-grained floorplanning and pipelining for high-frequency HLS design on multi-die FPGAs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ustun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2021 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="81" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Extending high-level synthesis for task-parallel programs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-K</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE 29th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="204" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Adapt-NoC: A flexible network-on-chip design for heterogeneous manycore architectures</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Louri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="723" to="735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">On-chip interconnection network for accelerator-rich architectures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Reinman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Design Automation Conference, ser. DAC &apos;15</title>
		<meeting>the 52nd Annual Design Automation Conference, ser. DAC &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Energyefficient time-division multiplexed hybrid-switched NoC for heterogeneous multicore systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sapatnekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE 28th International Parallel and Distributed Processing Symposium</title>
		<imprint>
			<date type="published" when="2014-05">May 2014</date>
			<biblScope unit="page" from="293" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Ripple: Profile-guided instruction cache replacement for data center applications</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sriraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Devietti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pokam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kasikci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 ACM/IEEE 48th Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="734" to="747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Cohmeleon: Learning-based orchestration of accelerator coherence in heterogeneous socs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zuckerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Giri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mantovani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Carloni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="350" to="365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Syncron: Efficient synchronization support for near-data-processing architectures</title>
		<author>
			<persName><forename type="first">C</forename><surname>Giannoula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vijaykumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papadopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Karakostas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>G?mez-Luna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Orosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Koziris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Goumas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="263" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Accelerator-level parallelism</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Reddi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="36" to="38" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">ILLIXR: enabling end-to-end extended reality research</title>
		<author>
			<persName><forename type="first">M</forename><surname>Huzaifa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Grayson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sinclair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Adve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Workload Characterization, IISWC 2021</title>
		<meeting><address><addrLine>Storrs, CT, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">November 7-9, 2021. 2021</date>
			<biblScope unit="page" from="24" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Hardwaresoftware co-design for brain-computer interfaces</title>
		<author>
			<persName><forename type="first">I</forename><surname>Karageorgos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sriram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vesel?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Borton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Manohar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="391" to="404" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
