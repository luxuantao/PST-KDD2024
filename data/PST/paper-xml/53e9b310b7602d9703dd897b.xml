<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MPEG-4 and Rate-Distortion-Based Shape-Coding Techniques</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">F</forename><forename type="middle">W</forename><surname>Meier</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Northwestern University</orgName>
								<address>
									<postCode>60208-3118</postCode>
									<settlement>Evanston</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">J</forename><surname>Ostermann</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Silicon Graphics</orgName>
								<address>
									<postCode>94043-1389</postCode>
									<settlement>Mountain View</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Schuster</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">AT&amp;T Labs-Research</orgName>
								<address>
									<postCode>07701-7033</postCode>
									<settlement>Red Bank</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MPEG-4 and Rate-Distortion-Based Shape-Coding Techniques</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">164ED9FF71A7C6B82F9EB44AD3C504A7</idno>
					<note type="submission">received August 30, 1997; revised December 15, 1997. The Guest Editor coordinating the review of this paper and approving it for publication was K. J. R. Liu.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Boundary coding</term>
					<term>MPEG-4</term>
					<term>rate-distortion theory</term>
					<term>shape coding</term>
					<term>video coding</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we address the problem of the efficient encoding of object boundaries. This problem is becoming increasingly important in applications such as content-based storage and retrieval, studio and television postproduction, and mobile multimedia applications. The MPEG-4 visual standard will allow the transmission of arbitrarily shaped video objects. The techniques developed for shape coding within the MPEG-4 standardization effort are described and compared first. A framework for the representation of shapes using their contours is presented next. Such representations are achieved using curves of various orders, and they are optimal in the rate-distortion sense. Last, conclusions are drawn.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>With video being a ubiquitous part of modern multimedia communications, new functionalities in addition to the conventional compression provided by existing video-coding standards like H.261, MPEG-1, H.262, MPEG-2, and H.263 are required for new applications. Applications like digital libraries or content-based storage and retrieval have to allow access to video data based on object descriptions, where objects are described by texture, shape, and motion. Studio and television postproduction applications require editing of video content with objects represented by texture and shape. For collaborative scene visualization like augmented reality, we want to place video objects into the scene. Mobile multimedia applications require content-based interactivity and content-based scalability in order to allocate a limited bit rate to different semantic parts of a scene and to fit the individual needs. All these applications share one common requirement: video content has to be easily accessible on an object basis.</p><p>Given the application requirements, video objects have to be described not only by texture but also by shape. The importance of shape for video objects has been realized early on by the broadcast and movie industry by employing the so-called chroma-keying technique. Coding algorithms like object-based analysis-synthesis coding <ref type="bibr" target="#b0">[1]</ref> use shape as a parameter in addition to texture and motion for describing moving video objects. Second-generation image coding segments an image into regions and describes each region by texture and shape <ref type="bibr" target="#b1">[2]</ref>. The purpose of using shape was to achieve better subjective picture quality, increased coding efficiency as well as an object-based video representation.</p><p>MPEG-4 visual will be the first international standard allowing the transmission of arbitrarily shaped video objects (VO's) <ref type="bibr" target="#b2">[3]</ref>. A frame of a VO is called a video object plane (VOP). Following an object-based approach, MPEG-4 visual transmits texture, motion, and shape information of one VO within one bitstream. The bitstreams of several VO's and accompanying composition information can be multiplexed such that the decoder receives all the information to decode the VO's and arrange them into a video scene. This results in a new dimension of interactivity and flexibility for standardized video and multimedia applications.</p><p>After a review of object-based coders and shape coding (Section II), this paper provides an overview of the main algorithms for shape, as investigated within MPEG-4, in Section III. Two types of VO's are distinguished. For opaque objects, binary shape information is transmitted. Two bitmap-based (Section III-A), two contour-based (Section III-B), and an implicit shape coder (Section III-C) are presented. The evaluation criteria for measuring coding performance and the test sequences are discussed in Section III-D. The performance of the five shape coders, verified by bitstream exchange, in terms of coding efficiency, error resilience, and hardware implementation is compared in Section III-E. Transparent objects are described by grayscale -maps (8 bits/pel) defining the outline as well as the transparency of an object (Section III-F).</p><p>In Section IV, contour-based coding is revisited. A framework is presented for obtaining optimal lossy encoding results in the operational rate-distortion sense (Section IV-A). In Section IV-B, different distortion measures that can be used in boundary encoding are described. In Section IV-C, issues concerning the rate required to encode the boundary are discussed. More specifically, we discuss prediction methods to encode the control points or vertices and how this is related to the order of the dynamic programming used to solve the problem. In Sections IV-D and IV-E, we present several solution approaches to the problem, followed by experimental results in Section IV-F. Last, in Section V, we present our conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. REVIEW OF OBJECT-BASED VIDEO CODING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Concepts</head><p>Two concepts were developed that introduced shape coding into image and video coding. In 1985, a regionbased image-coding technique was published <ref type="bibr" target="#b1">[2]</ref>. To encode an image, it is first segmented into regions of homogenous texture. In a second step, each region is encoded by transmitting its contour as well as one value for defining the luminance of the region. Rate control is achieved by controlling the number of segmented regions. The assumption is that the contours of regions are very important for subjective image quality, whereas the texture of the regions is of lower importance. In <ref type="bibr" target="#b3">[4]</ref>, this concept is extended to code video. Since the available data rate is mostly used for the coding of region contours, contours of image regions are very well preserved. The coder is very well suited for coding of objects with flat textures, since any discrete cosine transform (DCT)-based coder has significant problems in representing sharp edges. However, texture detail within a region gets lost. In the case where a fairly homogenous region of the original image gets coded by more than one region, contouring artifacts appear. These coding artifacts did not compare favorably with the block and mosquito artifacts of an H.261 coder. In subjective tests, MPEG-4 confirmed that a block-based coder compares favorably to a region-based coder <ref type="bibr" target="#b4">[5]</ref> when encoding rectangular video sequences.</p><p>Whereas a conventional frame-based video coder like MPEG-1 or H.263 encodes a sequence of rectangular frames, an object-based video coder encodes an arbitrarily shaped video object. This concept was inspired by the development of the object-based analysis-synthesis coder (OBASC) published in 1989 <ref type="bibr" target="#b0">[1]</ref>. An OBASC divides an image sequence into arbitrarily shaped moving objects. Objects are encoded independently. An object is defined by its uniform motion and described by motion, shape, and color parameters, where color parameters denote luminance and chrominance reflectance of the object surface. The image analysis of an OBASC estimates the current motion, shape, and texture parameters of each object. Furthermore, image analysis determines for which part of the object the object does not behave according to the underlying source model and hence cannot be predicted using motion-compensated prediction alone. These regions are called model failures. Parameter coding encodes the motion parameters. Using these motion parameters, motion-compensated prediction is employed to increase the coding efficiency of the shape coder. Last, the shape and texture of the model failures are coded.</p><p>The coding efficiency of OBASC mainly depends on the selection of an appropriate source model and the availability of an automatic image analysis, which estimates the model parameters from the video sequence to be coded. Different source models like two-dimensional (2-D) flexible object with 2-D motion, 2-D rigid objects with three-dimensional (3-D) motion, and 3-D rigid and flexible objects with 3-D motion were investigated <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b9">[10]</ref>. The source models using flexible surfaces proved to be particularly successful and outperformed the H.261 coder <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> for video-phone test sequences at 64 kbit/s and below. For shape coding, a polygon approximation of the object was used. Lossy shape coding was used in order to save bit rate. The degree of lossiness was determined by subjective experiments. However, OBASC was mainly successful for simple video sequences due to lack of a robust image analysis. Therefore, segmentation of moving objects within an object-based coder was investigated <ref type="bibr" target="#b10">[11]</ref>. It has to be noted that the success of OBASC is due to the introduction of shape coding and the use of a motion model able to describe flexible deformation, thus allowing one to limit the areas of model failure to small image regions. MPEG-4 only implements a shape coder but does not allow modeling of flexible motion due to the use of regular block-based motion compensation. There are two reasons for this choice: At the time of subjective testing, OBASC was not able to outperform the block-based reference coder for scenes with complex motion. Furthermore, the computational complexity of source models allowing flexible motion <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref> is significantly higher than block-based motion compensation.</p><p>Since MPEG-4 defines a video decoder, the problem of image analysis was avoided by using presegmented video sequences named VO's as coder input. This decision allowed the development of an object-based video coder. Although automatic segmentation is still an open research topic, segmentation is widely used in controlled environments. Television (TV) and studio industries rely to a large extent on the chroma-keying technique, which provides a reliable segmentation of objects in front of a uniform background in controlled studio environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. 2-D Shape Coding</head><p>In computer graphics, the shape of an object is defined by means of an -map of size pels</p><p>(1) The shape defines for each pel whether it belongs to the VO or not . For an opaque object, the corresponding -values are 255; for transparent objects, they range from 1 to 255 (Fig. <ref type="figure" target="#fig_0">1</ref>). Coded parameters are indicated by , like . Almost the entire literature on shape coding deals with efficient coding of binary shapes with being background and being the object. There are two classes of binary shape coders. A bitmap-based coder encodes for each pel whether it belongs to the object or not. A contour-based coder encodes the outline of the object. To retrieve the bitmap of the object shape, the contour is filled with the object label. In the case where there is also texture transmitted with the shape information, an implicit shape coder can be used where the shape information can be derived from the texture. The already mentioned chromakeying method would fall into this category. It is also specified in GIF89a <ref type="bibr" target="#b13">[14]</ref>. For each image, one number can be used to define the value of the transparent pels. All pels of this value are not displayed. Today, GIF89a is used in Web applications to allow description of arbitrarily shaped image and video objects.</p><p>Bitmap-based shape coders are used in the fax standards G4 <ref type="bibr" target="#b14">[15]</ref> and JBIG <ref type="bibr" target="#b15">[16]</ref>. The modified read (MR) code used in the fax G4 standard scans each line of the document and encodes the location of changing pels where the scan line changes its color. In this line-by-line scheme, the position of each changing pel on the current line is coded with respect to either the position of a corresponding changing pel in the reference line, which lies immediately above the present line, or with respect to the preceding changing pel in the current line <ref type="bibr" target="#b16">[17]</ref>.</p><p>Extensive work has been published on contour-based shape representation and coding. Different applications nurtured this research. For lossless and lossy encoding of object boundaries, chain coders <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref> and polygon approximations <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b19">[20]</ref>- <ref type="bibr" target="#b22">[23]</ref> were developed. For recognition purposes, shape representations like Fourier descriptors were developed to allow translation, rotation, and scale-invariant shape representations <ref type="bibr" target="#b23">[24]</ref>.</p><p>A chain code follows the contour of an object and encodes the direction in which the next boundary pel is located (Fig. <ref type="figure">2</ref>). Algorithms differ by whether they consider a pel having four or eight neighbors for rectangular grids or six neighbors for hexagonal grids. Some algorithms define the object boundary between pels <ref type="bibr" target="#b24">[25]</ref>. Freeman <ref type="bibr" target="#b17">[18]</ref> originally proposed the use of chain coding for boundary quantization and encoding, which has attracted considerable attention over the last 30 years <ref type="bibr" target="#b25">[26]</ref>- <ref type="bibr" target="#b29">[30]</ref>. The curve is quantized using the grid intersection scheme <ref type="bibr" target="#b17">[18]</ref>, and the quantized curve is represented using a string of increments. Since the planar curve is assumed to be continuous, the increments between grid points are limited to the eight grid neighbors, and hence an increment can be represented Fig. <ref type="figure">2</ref>. A chain code follows the contour of an object by describing the direction from one boundary pel to the next. Each arrow is represented by one out of four or one out of eight symbols, respectively. On the right, the symbols for differentially encoding the shape are given. by 3 bits. For lossless encoding of boundary shapes, an average 1.2 bits/boundary pels and 1.4 bits/boundary pels are required, respectively, for a four-and an eight-neighbor grid <ref type="bibr" target="#b18">[19]</ref>. There have been many extensions to this basic scheme, such as the generalized chain codes <ref type="bibr" target="#b25">[26]</ref>, where the coding efficiency has been improved by using links of different length and different angular resolution. In <ref type="bibr" target="#b28">[29]</ref>, a scheme is presented that utilizes patterns in a chain code string to increase the coding efficiency. In <ref type="bibr" target="#b29">[30]</ref>, differential chain codes are presented, which employ the statistical dependency between successive links. There has also been interest in the theoretical performance of chain codes. In <ref type="bibr" target="#b26">[27]</ref>, the performance of different quantization schemes is compared, whereas in <ref type="bibr" target="#b27">[28]</ref>, the rate-distortion characteristics of certain chain codes are studied. In this paper, we are not concerned with the quantization of the continuous curve since we assume that the object boundaries are given with pixel accuracy. Some chain codes also include simplifications of the contour in order to increase coding efficiency <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>. This is similar to filtering the object shape with morphological filters and then coding with a chain code. The entropy coder may code a combination of several directions with just one code word.</p><p>A polygon-based shape representation was developed for OBASC <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b19">[20]</ref>. As a quality measure, the Euclidean distance between the original and the approximated contour is used. During subjective evaluations of common intermediate format (CIF) (352 288 pels) video sequences, it was found that allowing a peak distance of pel is sufficient to allow proper representations of objects in low-bit-rate applications. Hence, the lossy polygon approximation was developed. The polygon approximation is computed by using those two contour points with the maximum distance between them as the starting point. Then, additional points are added to the polygon where the approximation error between the polygon and the contour are maximum (Fig. <ref type="figure">3</ref>). This is repeated until the shape approximation error is less than . In a last step, splines are defined using the polygon points. If the spline approximation does not result in a larger approximation error between two neighboring polygon points, the spline approximation is used. This leads to a smoother representation of the shape (Fig. <ref type="figure">4</ref>). Vertex coordinates and the curve type between two vertices are arithmetically encoded.</p><p>This polygon/spline representation is also used for coding shapes in intermode. For temporal prediction, the texture motion vectors are applied to the vertices defining the predicted shape. Then, all vertices within the allowable approximation error define the new polygon approximation. It is refined as described above such that the entire polygon is within the allowable error . In a final step, it is again decided whether a polygon or spline approximation is used. The reason for not using a complete spline approximation is due to the fact that temporal prediction using splines is less efficient because the refinement of a predicted spline representation requires the definition of many more new vertices when compared to a polygon representation.</p><p>In <ref type="bibr" target="#b32">[33]</ref>, B-spline curves are used to approximate a boundary. An optimization procedure is formulated for finding the optimal locations of the control points by minimizing the mean squared error between the boundary and the approximation. This is an appropriate objective when the smoothing of the boundary is the main problem. When the resulting control points need to be encoded, however, the tradeoff between the encoding cost and the resulting distortion needs to be considered. By selecting the mean squared error as the distortion measure and allowing for the location of the control points to be anywhere on the plane, the resulting optimization problem is continuous and convex and can be solved easily. To encode the positions of the resulting control points efficiently, however, one needs to quantize them, and therefore the optimality of the solution is lost. It is well known that the optimal solution to a discrete optimization problem (quantized locations) does not have to be close to the solution of the corresponding continuous problem.</p><p>The above methods for polygon/spline representation achieve good results but they do not claim optimality. In Section IV, we describe polygon/spline representation Fig. <ref type="figure">3</ref>. Successive polygon approximation of a contour (from <ref type="bibr" target="#b6">[7]</ref>). The initial polygon AB is extended by points B and C. The iteration from a four-point to a five-point approximation is shown here.</p><p>approaches that provide optimality in the operational ratedistortion sense.</p><p>Fourier descriptors were developed for applications in recognition, where shape is an important key. Fourier descriptors allow a translation-, rotation-, and scale-invariant representation <ref type="bibr" target="#b33">[34]</ref>. In a first step, the coordinates of the contour are sampled clockwise in the -plane. This list of 2-D coordinates is transformed into an ordered list , with being the contour point number and the change of direction of the contour. Since the samples are periodic over the object boundary perimeter, they can be expanded into a Fourier series. To preserve the main characteristics of a shape, only the large Fourier coefficients have to be maintained. Fourier descriptors are not very efficient in reconstructing polygon-like shapes with only a few coefficients. This is one of the reasons why they never became very competitive in coding efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SHAPE CODING IN MPEG-4</head><p>The goal of shape coding is to encode the shape information of a moving video object in order to enable applications requiring content-based video access (Fig. <ref type="figure" target="#fig_0">1</ref>). It is assumed that texture and motion information is transmitted for the video object to code its texture efficiently. In this section, bitmap-based, contour-based, and implicit shape coders developed within MPEG-4 for coding of binary shapes are presented. The evaluation leading to the selection of a binary shape coder is also reviewed. In a last section, the coding of grayscale -maps is described.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Binary Bitmap-Based Shape Coder</head><p>In the following sections, two bitmap-based shape coders encoding the shape information on a macroblock basis are described. The first coder uses a nonadaptive context-based arithmetic encoder for encoding the shape information and motion compensation for exploiting temporal redundancies. The second coder is based on an adaptation of the MR coder that is used in place of the arithmetic encoder. Other aspects of the algorithms are identical. 1) Context-Based (CAE) Shape Coder: Within a macroblock, this coder exploits the spatial redundancy of the binary shape information to be coded. Pels are coded in scan-line order and row by row. In the following paragraphs, shape encoding in intramode is described <ref type="bibr" target="#b34">[35]</ref>. Then, this technique is extended to include an intermode <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>.</p><p>a) Intramode: In intramode, three different types of macroblocks are distinguished. Transparent and opaque blocks are signaled as macroblock type. The macroblocks on the object boundary containing transparent as well as opaque pels belong to the third type. For these boundary macroblocks, a template of 10 pels is used to define the causal context for predicting the shape value of the current pel [Fig. <ref type="figure">5(a)</ref>]. For encoding the state transition, a contextbased arithmetic encoder is used. The probability table of the arithmetic encoder for the 1024 contexts was derived from sequences that are outside of the test set used for comparing different shape coders. With two bytes allocated to describe the symbol probability for each context, the table size is 2048 bytes. To avoid emulation of start codes, the arithmetic coder stuffs one "1" into the bitstream whenever a long sequence of "0"'s is sent.</p><p>The template extends up to 2 pels to the left, to the right, and to the top of the pel to be coded [Fig. <ref type="figure">5(a)</ref>]. Hence, for encoding the pels in the two top and left rows of a macroblock, parts of the template are defined by the shape information of the already transmitted macroblocks on the top and on the left side of the current macroblock. For the two right-most columns, each undefined pel of the context is set to the value of its closest neighbor inside the macroblock.</p><p>To increase coding efficiency as well as to allow lossy shape coding, a macroblock can be subsampled by a factor of two or four, resulting in a subblock of size 8 8 or 4 4 pels, respectively. The subblock is encoded using the encoder as described above. The encoder transmits to the decoder the subsampling factor such that the decoder decodes the shape data and then upsamples the decoded subblock to macroblock size. Obviously, encoding the shape using a high subsampling factor is more efficient but the decoded shape after upsampling may or may not be the same as the original shape. Hence, this subsampling is mostly used for lossy shape coding and for rate-control purposes.</p><p>Depending on the upsampling filter, the decoded shape can look somewhat blocky. Several upsampling filters were investigated. The two best performing filters were a simple pel replication filter combined with a 3 3 median filter and an adaptive nonlinear upsampling filter. The context of this upsampling filter as standardized by MPEG-4 is shown in Fig. <ref type="figure" target="#fig_2">6</ref>.</p><p>The efficiency of the shape coder differs depending on the orientation of the shape data. Therefore, the encoder can choose to code the block as described above or transpose the macroblock prior to arithmetic coding.</p><p>b) Intermode: To exploit temporal redundancy in the shape information, the coder described above is extended by an intermode requiring motion compensation and a different template for defining the context. For motion compensation, a 2-D integer pel motion vector is estimated using full search for each macroblock in order to minimize the prediction error between the previously coded shape and the current shape . The shape motion vectors are predictively encoded with respect to the shape motion vectors of neighboring macroblocks. If no shape motion vector is available for prediction, texture motion vectors are used as predictors. The shape motion vector of the current block is used to align a new template designed for coding shape in intermode [Fig. <ref type="figure">5(b)</ref>]. The template defines a context of 9 pels, resulting in 512 contexts. The probability for one symbol is described by 2 bytes, giving a probability table size of 1024 bytes. Four pels of the context are neighbors of the pel to be coded; 5 pels are located at the motion-compensated location in the previous frame. Assuming that the motion vector points from the current to the previous coded , the part of the template located in the previously coded shape is centered at , with being the location of the current pel to be coded.</p><p>In intermode, the same options as in intramode, like subsampling and transposing, are available. For lossy shape coding, the encoder may also decide that the shape representation achieved by just carrying out motion compensation is sufficient, thus saving bits by avoiding the coding of the prediction error. The encoder can select one of seven modes for the shape information of each macroblock: transparent, opaque, intra, inter with/without shape motion vectors, and inter with/without shape motion vectors and prediction error coding. These different options with optional subsampling and transposition allow for encoder implementations of different coding efficiency and implementation complexity.</p><p>2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>) Modified MR (MMR) Shape Coder:</head><p>The MMR shape coder is a macroblock-based shape coder <ref type="bibr" target="#b35">[36]</ref>. In comparison to the CAE shape coder, the MMR shape coder mainly replaces the context-based arithmetic encoder and the templates by a MMR coder. Therefore, the description of the MMR shape coder is limited to the MMR coder. This MMR coder is derived from the modified read coder in the fax G4 standard <ref type="bibr" target="#b14">[15]</ref>. Fig. <ref type="figure" target="#fig_3">7</ref> is used for describing the encoding procedure. For simplicity, it is assumed that the macroblock to be coded is subsampled by a factor of two, resulting in a subblock of size 8 8 pels to be coded. Each block is coded in rasterscan order. Within each line, the position of pels on the object boundary is encoded. In Fig. <ref type="figure" target="#fig_3">7</ref>, it is assumed that the top five rows of the block have already been coded; hence, the coder knows the position of the pels and in the current block as well as pels and in the motion-compensated block when coding in intramode and intermode, respectively. a) Intramode: The unknown point on the object boundary is encoded with reference to the two pels , and .</p><p>is the last changing pel encoded prior to . is the first changing pel on the line above , to the right of , and with the opposite color of , if such a point exists (Fig. <ref type="figure" target="#fig_3">7</ref>). If not, then is the left-most changing pel on the same line as . To encode the distance between and , one of the three modes-vertical, horizontal, or vertical pass-is selected. Assuming that all pels are numbered in raster-scan order starting with zero in the top-left corner of the block, i.e., in Fig. <ref type="figure" target="#fig_3">7</ref> , and columns are numbered from left to right, i.e., , a mode is selected according to</p><formula xml:id="formula_0">mode Vertical if Horizontal if width Vertical Pass otherwise (2)</formula><p>with the threshold for no subsampling, for a subsampling factor of two, for a subsampling factor of four, and width is the width of the block to be coded.</p><p>In vertical mode, the distance is encoded using one of eight variable-length coder (VLC) tables that is selected according to the object boundary direction, as defined by a template positioned above pel (Fig. <ref type="figure" target="#fig_4">8</ref>). In horizontal mode, the position of is encoded as its distance to . Just due to the fact that the horizontal and not the vertical mode is selected, the decoder can sometimes deduct the minimum distance between and . In this case, only the difference with respect to this minimum distance is encoded.</p><p>In vertical pass mode, one code word is sent for each line without an object boundary. One last code word codes the remaining distance to the next point on the object boundary.</p><p>in Fig. <ref type="figure" target="#fig_3">7</ref> (subsampling factor of two) is encoded using vertical pass mode.</p><p>The efficiency of the shape coder differs depending on the orientation of the shape data. Therefore, the encoder can choose to code the block as described above or transpose the macroblock prior to MMR coding. In both cases, the encoder also has the choice of scanning each line from left to right or vice versa.</p><p>These adaptations of MMR to macroblock-based shape coding increased the performance by 30-70% compared to the MMR of the fax G4 standard.</p><p>b) Intermode: In intermode, the previously decoded shape is motion compensated as described in Section III-A1. Fig. <ref type="figure" target="#fig_3">7</ref>(b) shows the motion-compensated shape information. A pel is defined as the first changing pel with a color opposite to the color of in the same row as , if such a pel exists. If not, is the first changing pel in the remaining lines of the block. The mode is selected according to (2), with replaced by (Fig. <ref type="figure" target="#fig_3">7</ref>). The codes for transmitting the distance in vertical mode are not switched by the template but by the mode with which the previous boundary pel was coded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Binary Contour-Based Shape Coder</head><p>Within MPEG-4, two methods were developed: a vertexbased polynomial shape approximation based on work in <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b19">[20]</ref>, and <ref type="bibr" target="#b22">[23]</ref> and a baseline-based shape coder <ref type="bibr" target="#b36">[37]</ref>.</p><p>1) Vertex-Based Shape Coding: Vertex-based shape coding codes the outline of the shape. This shape is approximated using a polygon approximation for lossy shape coding. The placement of vertices allows an easy control of local variations of the shape approximation error. For lossless shape coding, the polygon approximation "degenerates" to a chain code <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>. In the following, the encoding of shapes in intramode is described first. In a second step, the algorithm is extended to exploit temporal redundancy.</p><p>a) Intramode: The efficiency of this shape-coding method depends to a large extent on the encoder. The art of lossy vertex-based shape coding lies in selecting the appropriate vertices for the polygons. The approach chosen by the experimenters <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b39">[40]</ref> starts with finding the longest axis of the shape and uses the two end points as the initial polygon. Let us assume that approximates the original contour between the vertices and . The original contour segment associated with this approximation segment is called with the contour points , with identifying the segment and the number of contour points of . With being the Euclidean distance between contour point and the line , the approximation error for a segment of the original contour is given by <ref type="bibr" target="#b2">(3)</ref> For each side of the polygon, it is checked whether the approximation lies within a given tolerance (Fig. <ref type="figure">3</ref>). If not, a new vertex is inserted at the point of the largest approximation error. Then, for each new polygon side, it is decided whether it lies within the allowable shape approximation, and the process is repeated until the peak approximation error is lower than . The described vertex selection method selects all vertices on the object boundary. For lossy shape coding, however, this might not be optimal. Therefore, the vertices can be shifted by 1 pel within an 8-pel neighborhood (Fig. <ref type="figure" target="#fig_5">9</ref>). The process can be repeated until an optimum approximation given the number of initially selected vertices is reached. This process minimizes the average shape approximation error for two neighboring contour segments and with contour points and , respectively. Given a vertex shifted by with , the average shape approximation error is given by ( <ref type="formula">4</ref>), shown at the bottom of the page, with and the number of contour points of the segments and , respectively. Vertex is shifted to the position that resulted in the smallest . In the case where this shift results in the shifted 's being equal to or , is deleted. After this vertex selection and adjustment, the vertex positions are encoded.</p><p>Vertices are located counterclockwise around the object. To save bits, the vertices are renumbered such that the largest difference in -or -coordinates appears between vertex and . After encoding the position of , each remaining vertex position is encoded differentially to its predecessor. For lossless coding, a differential chain code is used (Fig. <ref type="figure">2</ref>). For lossy coding, the difference vector is computed. Similar to the relative direction used for encoding of lossless shape, relative directions are used in the lossy case, with the exception that the eight directions are replaced by eight octants in the 2-D plane. The octant in which the next vertex is located is defined by and transmitted to the receiver (Fig. <ref type="figure" target="#fig_6">10</ref>). The octant defines whether the -or the -coordinate of is larger. The ranges of the major and the minor component of are transmitted, and finally the values of the two components are coded using VLC tables that are selected according to the range of the major and minor component. The decoder (4)  reconstructs the vertex positions, creates the polygon, and then fills the interior of the polygon with the opaque label of the -map.</p><p>In Section IV, we present a framework for the development of vertex-based shape-coding algorithms, which are optimal in the rate-distortion sense. That is, if polygons are used for approximating the original boundary, their vertices, which may belong on the boundary or lie outside of it, are chosen in such a way that the distortion is minimized while the rate for encoding the location of the vertices satisfies a given bit budget. In other words, the selection of the vertices and their encoding is done simultaneously and optimally. Various ways to define the segment distortion and the total distortion are applicable, also including the definitions used above. The framework accepts curves of any order, such as B-splines.</p><p>b) Intermode: To exploit temporal redundancy, one motion vector is estimated for each contour. The vector is estimated such that the number of overlapping pels between the current shape and the motion-compensated previous shape is maximum. The motion vector can compensate for object motion of up to 24 pels in horizontal and vertical direction.</p><p>Fig. <ref type="figure" target="#fig_0">11</ref> shows the previously coded shape and the current shape . The gray area shows the overlapping area of the two shapes after motion compensation. The bottom of Fig. <ref type="figure" target="#fig_0">11</ref> shows those contour segments that are aligned after motion compensation and those that are unmatched.</p><p>In the case of lossless shape coding, the encoder transmits the positions of the unmatched segments and refines the shape approximation for these segments as described in the intramode.</p><p>In the case of lossy shape coding, the encoder checks where the unmatched segments leave the band around the current shape that is defined by the allowable shape approximation error (Fig. <ref type="figure" target="#fig_0">12</ref>). Now, unmatched segments are those that are located outside of the band. As for lossless shape coding, the encoder transmits the positions of the unmatched segments and then refines the shape approximation for these segments as described in the intramode.</p><p>It appears that this motion compensation can still be improved. Localized motion compensation allowing one vector for each vertex or segment as defined by a boundary macroblock should result in further improvements of this technique.</p><p>2) Baseline-Based Shape Coding: A baseline shape coder also encodes the contour of an object. It places the shape into a 2-D coordinate system such that the projection of the shape onto the -axis is longest <ref type="bibr" target="#b36">[37]</ref>. The -axis is called the baseline, from which the distance ( -coordinate) between the baseline and a point on the shape outline is measured. The shape contour is sampled clockwise. Neighboring contour points usually have increasing or decreasing -coordinates. Those contour points where the direction changes are called turning points. They are signaled to the decoder (Fig. <ref type="figure" target="#fig_7">13</ref>). The contour is subdivided into segments of 16 pels in length.</p><p>a) Intramode: The contour points within one segment can be subsampled by factors of two, four, or eight. For upsampling, the missing contour points are linearly interpolated from the -values of the samples. To minimize the approximation error, coded contour points can be shifted vertically by 1 pel. A contour segment is subsampled if the approximation error due to the subsampling is within given limits. For each segment, the -coordinates are differentially encoded.</p><p>b) Intermode: The baseline-based shape coder allows for global and local motion compensation. Global motion compensation aligns the previously coded shape with the current shape such that the number of overlapping pels is maximized. In a second step, a 2-D motion vector is searched for each segment of the current contour such Fig. <ref type="figure" target="#fig_0">11</ref>. Vertex-based shape coding. Motion compensation aligns the previous and current shape parameters. Unmatched segments of the contours are identified, here (B 1 ; A 2 ), (B 2 ; A 3 ), and (B 3 ; A 1 ) for lossless shape coding. Fig. <ref type="figure" target="#fig_0">12</ref>. For lossy shape coding, a band with the allowable shape distortion reduces and shortens the unmatched segments, here (B 1 ; A 2 ) and (B 2 ; A 3 ) (compare with Fig. <ref type="figure" target="#fig_0">11</ref>).</p><p>that the number of misaligned pels is minimum. If the motion-compensated prediction error is above a threshold, the prediction error is encoded the same way as contour points are encoded in intramode.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Binary Chroma-Key Shape Coder</head><p>This shape-coding technique <ref type="bibr" target="#b40">[41]</ref> was inspired from the blue-screen technique used in film and TV studios. The color of a pel is used to distinguish between object and background. The object to be coded is placed on a static one-colored background. The color of the background (chroma-key) has to be outside of the color space occupied by the texture of the object. Usually, highly saturated colors fulfill this requirement. The image or sequence of images with the object in front of this one-colored background is then encoded using a conventional coder (here, MPEG-4 video in full frame mode). To the decoder, the chroma-key is transmitted. The decoder decodes the images. For each pel, the weighted distance between the chroma-key and the corresponding values of the decoded pel is computed according to <ref type="bibr" target="#b4">(5)</ref> where , , are the weighting factors. For lossless coding, is zero for the background (chromakey) and nonzero for the pels of the object.</p><p>When a sequence is coded using quantization, becomes different from zero also for the background. To allow a good separation of the object from the background, the chroma-key should be chosen such that the distance becomes large for all pels of the object. Pels of the decoded images with a color similar to the chroma-key threshold are considered to be background. To extract the object shape, the decoder considers all pels of the background as transparent. The other pels belong to the object <ref type="bibr" target="#b40">[41]</ref>. In experiments, it was found that it is not necessary to consider the luminance of the background for the object/background separation. For a chroma-key of (128, 220, 100), weights of (0, 1, 1) are appropriate. This segmentation of object and background might become erroneous when very coarse quantization of the images is allowed.</p><p>The color of pels at the object boundary inside the object is influenced by the chroma-key because of the quantization of the DCT coefficients. To reduce this color-bleeding effect, the color can be shifted away from the chroma-key toward the color space occupied by the object.</p><p>The implicit shape coding does not allow the extraction of the object shape without decoding the entire frame. Since the shape information is typically carried by the subsampled chroma signal, this technique is not suited for lossless shape coding. Because the shape information is embedded in the texture, the shape coding is lossy as long as there is quantization of the texture. An important advantage of this method is its low computational and algorithmic complexity. The low computational complexity becomes especially apparent if the location of boundary macroblocks is signaled to the decoder such that the shape extraction has to be performed only on this small number of boundary macroblocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Evaluation Criteria for Coding Efficiency</head><p>To compare the performance of different shape coders, evaluation criteria have to be defined. Within MPEG-4, there are two quality measures for objectively assessing the quality of coded shape parameters. One is the maximum of the minimal Euclidean distance (peak deviation) between each coded contour point and the closest contour point on the original contour, as described in Section II-B. This measure allows for an easy interpretation of the shape quality. However, if lossy shape coding results in changing the topology of an object due to opening, closing, or connecting holes, the peak deviation is not a useful measure. Therefore, we used a second measure that is the number of erroneously represented pels of the coded shape divided by the total number of pels belonging to the original shape. Since different objects can have very different ratios of contour pels to interior pels, a given value for only allows comparison with other of different approximations of the same video object. The measure by itself does not provide sufficient information about the shape quality.</p><p>Subjective evaluation of several sequences indicated that a shape representation with an approximation error of pels is not useful at all for video. All the test sequences were encoded with pel, and the corresponding for the sequences was computed. In the following, each sequence was lossily encoded with between zero and . To obtain reliable results, seven test sequences (Cyclamen, Weather (woman), Kids from sequence Children, Logo from sequence Children, Robot from sequence Destruction, Rain Drops from sequence Destruction, and Speakers from test sequence News) with natural and synthetic content ranging from simple scenes like a news speaker to scenes with deforming objects and camera motion were used as the test set (Fig. <ref type="figure" target="#fig_8">14</ref>). The sequence Weather shows a person explaining the current weather situation along the Japan Sea. The woman turns and partially leaves the picture. The segmentation of the person was obtained using chroma-key studio equipment. The sequence Kids shows two children playing ball. Again, the sequence was recorded in a studio and the segmentation of the persons and the ball was obtained using chromakey equipment. The sequence Robot was generated using animation software. The robot is moving quickly, the ammunition belt consisting of many little pieces moving fast.</p><p>It was found that the objective measures truthfully reflected subjective quality when comparing different bitmap-based shape coders or different contour-based shape coders. For lossy shape coding, the bitmap-based shape coders create blocky object shapes, whereas contour-based shape coders create an object shape showing polygon edges. Since the two classes of shape coders gave different distortions (Fig. <ref type="figure" target="#fig_9">15</ref>), a comparison between these two types had to be done subjectively. Decoded video objects (lossy shape coded at a given average bit rate for shape; texture coded using a quantizer step size of 12) were displayed on TV monitors and informally evaluated by approximately 30 experts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Comparison of Binary Shape Coders</head><p>The shape-coding algorithms described above were thoroughly investigated with respect to their coding efficiency, subjective quality for lossy shape coding, hardware and software complexity, and performance in scalable shape coders. Coding efficiency was compared in rate-distortion diagrams, subjective quality was measured using long sessions to compare coded video sequences, and software complexity was measured using tools developed within the MPEG-4 implementation study group, which count the number of operations and measure the memory bandwidth that a shape coder required on an Ultra-SPARC processor <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>.</p><p>1) Error Resilience: MPEG-4 wants to enable multimedia communications over different networks like satellite and terrestrial broadcast, telephone networks, Internet, and wireless communication links. Although each communication channel has a network interface that provides a certain protection from errors, it is expected that wireless communication channels will contain a significant amount of residual errors after channel error detection and correction. To have video-coding algorithms cope with the corrupted bitstream, MPEG-4 video set up a group to develop an error-resilient mode of the video coder. The work of that group focused mainly on the frame-based video coder and low bit rates between 24 and 48 kbit/s. The bit error patterns used for developing an error-resilient decoder include random bit errors at a rate of 10 , burst errors of 1-20 ms in length with an average bit error rate between 10 and 10 , and loss of packets with 96-400 bits. To ensure that the selected shape coder will also be of use in error-prone environments, a group of error-resilience experts evaluated the five proposals over a period of two months <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b44">[45]</ref>. To do error-resilient shape coding, the decoder should be able to provide these four capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1)</head><p>Error detection: This is the most fundamental requirement. The decoder can encounter a syntactic error, i.e., an illegal code word of variable or fixed length, or a semantic error, i.e., decoding a shape that does not close. The error may not be detected until some point after it actually occurs. 2) Error localization: After an error has been detected, the decoder has to resynchronize with the bitstream without skipping too many bits. One way of achieving this is the introduction of additional resynchronization markers <ref type="bibr" target="#b45">[46]</ref>.</p><p>3) Data recovery: After error localization, data recovery tries to recover some information from the bitstream between the location of the detected error and the determined resynchronization point. Thus, data recovery minimizes information loss. Reversible VLC's (VLC's that can be decoded forward and backward) can be of help. In the case of shape coding, the usefulness of such a feature has yet to be demonstrated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4)</head><p>Error concealment: Last, error concealment tries to hide the effects of the erroneous bitstream by replacing the lost shape information by meaningful data, i.e., copying shape data from the previous frame into the current frame. The smaller the spatial extent of the error, the more accurate the error concealment that can be achieved.</p><p>Of general concern was that arithmetic decoding itself does not provide any syntactic error-detection capabilities. The same is true for VLC tables unless they were designed to be incomplete. The equivalence of incomplete VLC tables would be the insertion of marker bits into the arithmetically coded data. After a given run length of "0" or "1" symbols, the decoder inserts a marker bit of opposite value. If the decoder cannot detect the marker bits at the  right position, it can detect the error. Incomplete VLC's as well as marker bits decrease the efficiency of the coder.</p><p>A list of priorities was assigned to different parts of the bitstream in order to help focus on the critical issues of error resilience:</p><p> shape mode (most important);</p><p> shape motion vectors;</p><p> texture motion vectors;</p><p> shape data;</p><p> texture data (least important). Errors in the decoded shape can change the number of macroblocks within a VOP. This would bring the update of the texture and shape information out of alignment with respect to the previously decoded VOP. To limit the damage that an erroneous shape can induce to the picture quality, it is important to localize the error in the shape. This is a prerequisite for error concealment. The block-based shape coders propose that macroblock shape is decoded independently of neighboring blocks. A contour-based shape coder adds resilience by protecting the sensitive data. For the vertex-based shape coder, a syntax was proposed that allowed the shape of a VO to be encoded in independent slices of macroblocks. By coding the starting point of the contour approximation twice, i.e., as starting point and as end point of the contour, contour-based shape coders provide additional semantic error-detection capabilities since the coded contours have to be closed.</p><p>The experts concluded that all the proposed schemes would be able to provide sufficient error-resilience capabilities for transmission of VO's over wireless channels. Differences in terms of efficiency would be expected, but without experiments, none of the proposed coders seemed to be better suited than another.</p><p>2) Coding Efficiency: The proposed shape coders were evaluated on several sequences in intramode and intermode. Figs. 16-18 compare the four explicit shape coders when coding shapes in intramode. The bit rate and distortion are averaged over 100 frames. As can be seen, the baselinebased shape coder provides the highest coding efficiency, using 0-30% fewer bits than the bitmap-based shape coders. The vertex-based shape coder comes second. The two bitmap-based shape coders perform very similarly. The CAE shape coder is slightly more efficient for lossless shape coding compared to the MMR shape coder.</p><p>In intermode, the comparison of the different shape coders gave a different ranking. Figs. <ref type="figure" target="#fig_13">19</ref><ref type="figure" target="#fig_14">20</ref><ref type="figure" target="#fig_15">21</ref>show bit-rate and distortion averages for three test sequences. For lossless and subjectively lossless coding, the bitmap-based shape coder outperformed the contour-based shape coder by up to 20%. Again, CAE shape coding is more efficient than MMR shape coding. For larger distortions, the vertex-based shape coder performs similarly to or better than the bitmapbased methods. The motion compensation employed in the baseline method does not perform as well as the motion compensation of the other methods, causing this coder to perform worst in terms of coding efficiency in intermode.   When comparing the different shape-coding techniques, chroma-keying was not considered as a candidate for MPEG-4 shape coding because for complex shapes, the topology of the shape was not stable enough and color bleeding was visible along some boundaries. Figs. <ref type="figure" target="#fig_16">22</ref> and<ref type="figure"></ref> 23 show a comparison between the chroma-key shape coder based on video verification model VM 5 and the video verification model VM 5 using its explicit shape coder. Since chroma-keying codes the shape in the chroma signal, the measure SNR for objective picture quality was used, as shown in ( <ref type="formula">6</ref>) at the bottom of the next page, with , , and the number of pels of the and component that belong to the object. VM5 uses a simplified version of the MMR shape coder presented in Section III-A2 <ref type="bibr" target="#b46">[47]</ref>. Both coders encode texture, motion, and shape. They use the same texture motion-  (d n = 0:0). Quantizer step sizes of 8, 12 and 20 are used (from [66]). estimation algorithm and the same quantizer step sizes of 8, 12, and 20 for the quantization of DCT coefficients. Whereas VM5 codes the shape losslessly, the chroma-key shape coder was not able to do so; for the higher quantizer, the shape-coding error was significant. When comparing the bit rates, VM5, with its explicit MMR shape coder, is always more efficient than the implicit chroma-key shape coder at the price of the higher complexity of the explicit shape coder.</p><p>After evaluation of the objective shape-coding performance, the main decision to be taken was whether a bitmap-based or a contour-based shape coder should be mse SNR mse ( <ref type="formula">6</ref>) selected for the MPEG-4 standard. To ease this decision, the group working on shape coding first selected the best contour-based and best block-based shape coders.</p><p>As far as bitmap-based shape coding is concerned, the CAE shape coder outperformed the MMR shape coder. For the contour-based shape coding, the vertex-based coder was chosen. It outperformed the baseline-based coder in coding efficiency for intermode as well as in terms of computational complexity. Furthermore, the baseline coder was implemented only once, whereas all the other shape coders had two independent implementations.</p><p>3) Hardware Implementation: The Implementation Studies Group of MPEG-4 evaluated the vertex-based and context-based shape coders with respect to hardwareimplementation implications. It is assumed that most of the computations will be done using programmable logic like video signal processors.</p><p>When comparing a VLC decoder as used for the vertexbased methods with the arithmetic decoder used in the context-based shape coder, an arithmetic decoder was found to be more difficult to implement and to require more chip surface.</p><p>However, the real bottleneck of a video decoder will be the required bandwidth for off-chip memory access and caching <ref type="bibr" target="#b47">[48]</ref>. Here, the block-based, context-based shape coder has the advantage that the entire shape block can be loaded into on-chip cache and processed. At the end of decoding, the decoded block can be written to memory. Since blocks are processed in predefined order, address generation for memory access is straightforward. The vertex-based shape coder does not allow for predefined memory access since no prior knowledge is available as to how the polygon will extend from one vertex to the next. Hence, cache prefetching will not work efficiently, and loading the entire shape image into on-chip cache is not an option due to the size limitation of the cache. A further disadvantage of the vertex-based shape coder is that the decoding time depends on the number of vertices and the shape of the object. This is in contrast to the fixed processing time required for context-based shape coding, allowing for easier task scheduling on the processor.</p><p>4) Summary: As far as shape-coding requirements are concerned, all explicit shape coders are able to provide lossless, subjectively lossless, and lossy shape coding. The algorithms can be extended to scalable shape coders, bitstream editing, shape-only decoding, and low-delay applications, as well as applications using noisy transmission channels. Table <ref type="table" target="#tab_0">1</ref> compares the context-based and vertexbased shape coders, as done at the Bristol MPEG meeting in April 1997. None of the algorithms clearly outperforms the other. However, it was felt that the simple hardware implementation of the context-based shape coder was a reason to reject the vertex-based shape coder. After that meeting, the competitive phase of shape coding ended, and MPEG-4 focused on optimizing the selected context-based shape coder mainly by developing the adaptive upsampling filter (Fig. <ref type="figure" target="#fig_2">6</ref>) and an error-resilient shape coding mode.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Grayscale Shape Coder</head><p>Grayscale alpha maps allow 8 bits for each luminance pel to define the transparency of that pel. Transparency is an important tool for composing objects into scenes and special effects (Fig. <ref type="figure" target="#fig_0">1</ref>). Two types of transparencies are distinguished: binary alpha maps for objects with constant transparency and arbitrary alpha maps for objects with varying transparency.</p><p>1) Objects with Constant Transparency: For a transparent object that does not have a varying transparency, the shape is encoded using the binary shape coder and the 8-bit value of the alpha map. To avoid aliasing, grayscale alpha maps usually have lower transparency values at the boundary. Blending the alpha map near the object boundary can be supported by transmitting the coefficients of a 3 3 pel finiteduration impulse response filter that is applied to the alpha map within a stripe on the inner object boundary. The stripe can be up to 3 pels wide.</p><p>2) Objects with Arbitrary Transparency: For arbitrary alpha maps, shape coding is done in two steps <ref type="bibr" target="#b48">[49]</ref>. In the first step, the outline of the object is losslessly encoded as a binary shape. In the second step, the actual alpha map is treated like the luminance of an object with binary shape and coded using the MPEG-4 texture-coding tools of padding, motion compensation, and DCT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. OPTIMAL CONTOUR ENCODING IN THE RATE-DISTORTION SENSE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Introduction</head><p>We now present a framework for contour encoding that is optimal in the rate-distortion sense. We formulate the problem in various ways. The contour approximation can be done using a polygon, B-splines, or higher order curves. In all cases, the problem reduces to finding the shortest path in a directed acyclic graph (DAG).</p><p>Before continuing, it is worthwhile to present a review of B-splines. These are a family of parametric curves that have proven to be very useful in boundary encoding <ref type="bibr" target="#b49">[50]</ref>- <ref type="bibr" target="#b51">[52]</ref>. In the following discussion, we will concentrate on secondorder B-splines. However, this theory can be generalized to higher order curves. Also, it should be noted that first-order B-splines are equivalent to polygons.</p><p>A B-spline is a specific curve type from the family of parametric curves <ref type="bibr" target="#b52">[53]</ref>. A parametric curve consists of one or more curve segments. Each curve segment is defined by control points, where defines the degree of the curve. The control points are located around the curve segment, and together with a constant base matrix , the control points solely define the shape of the curve. A 2-D curve segment with control points is defined as follows:</p><p>for otherwise. ( <ref type="formula">7</ref>)</p><p>The points at the beginning and end of a curve segment are called knots and can be found by setting and . The following is the definition for a second-degree curve segment, with as index for the different curve segments and and , respectively, as the horizontal and vertical coordinates of control point : <ref type="bibr" target="#b7">(8)</ref> Both the base matrix , with specific constant parameters for each specific type of parametric curve, and the control point matrix , with control points, define the shape of in a two-dimensional plane. Every point of the curve segment can be calculated with ( <ref type="formula">8</ref>) by letting vary from zero to one. Every curve segment can be calculated independently in order to calculate the entire curve , consisting of curve segments, which is of the following form: <ref type="bibr" target="#b8">(9)</ref> Among common parametric curves are the Bezier curve and the B-spline curve. For the proposed shape-coding method in this section, we chose a second-order (quadratic) basis uniform nonrational B-spline curve <ref type="bibr" target="#b52">[53]</ref> with the following base matrix: <ref type="bibr" target="#b9">(10)</ref> Fig. <ref type="figure" target="#fig_18">24</ref> shows such a second-order B-spline curve. The shape-coding method presented in this section is independent of the matrix and degree , that is, parametric curves of higher order can be used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Double Control Points:</head><p>The beginning and the end of the boundary approximation have to be treated as special cases if the first curve segment should start exactly from the first boundary point and the last curve segment should end exactly at the last boundary point. When we use a double control point (such as ), the curve segment will begin exactly from the double control point (see Fig. <ref type="figure" target="#fig_18">24</ref>). We apply this property to the beginning and end of the curve, so that and . These two special cases can easily be incorporated into the boundary approximation algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Distortion</head><p>To motivate the distortion measures presented here, we mathematically formulate an example where the boundary approximation is done using polygons and the vertices of the polygons must lie on the original boundary. We change the notation used earlier in the paper for convenience purposes. Let denote the connected boundary, which is an ordered set, where is the th point of and is the total number of points in . Note that in the case of a closed boundary, . Let denote the polygon used to approximate , which is also an ordered set, with the th vertex of , the total number of vertices in , and the th segment starting at and ending at . Since is an ordered set, the ordering rule and the set of vertices uniquely define the polygon. We will elaborate on the fact that the polygon is an ordered set later on.</p><p>In general, the polygon that is used to approximate the boundary could be permitted to place its vertices anywhere on the plane. In this example, as mentioned earlier, we restrict the vertices to belong to the original boundary. Let be the set of points that are admissible as vertices. Clearly, in this case, . The th polygon segment that connects two consecutive vertices, and , is an approximation to the partial boundary , which contains boundary points. Therefore, we can measure the quality of this approximation by a segment distortion measure, which we denote by . The polygon distortion can then be expressed as the sum or the maximum of all segment distortion measures.</p><p>There are several different distortion measures that can be employed. One popular distortion measure for curve approximations is the maximum absolute distance, which has also been employed in <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, and <ref type="bibr" target="#b53">[54]</ref>.</p><p>Besides its perceptual relevance, this distortion measure has the advantage that it can be computed efficiently. Let be the shortest distance between the line that goes through and and an arbitrary point . This distance can be expressed as shown in <ref type="bibr" target="#b10">(11)</ref> at the bottom of the page, where the subscripts and indicate theand -coordinates of a particular point.</p><p>Then the maximum absolute distance between the partial boundary and the segment is given by ( <ref type="formula">12</ref>) An example is shown in Fig. <ref type="figure" target="#fig_19">25</ref>. Another popular distortion measure is the mean squared distance (error), which has been used in <ref type="bibr" target="#b32">[33]</ref> and <ref type="bibr" target="#b54">[55]</ref> and is of the following form: <ref type="bibr" target="#b12">(13)</ref> So far, we have only discussed the segment distortion measures, i.e., the measures that judge the approximation of a certain partial boundary by a given polygon segment. In general, we are interested in a polygon distortion measure that can be used to determine the quality of approximation of an entire polygon. We will treat two different classes of polygon distortion measures. The first class is based on the maximum operator (or, equivalently, on the minimum operator) and is of the following form: <ref type="bibr" target="#b13">(14)</ref> where is defined to be zero. We will denote all distortion measures based on the above definition as "class one" distortion measures.</p><p>The second class of distortion measures is based on the summation operator and is of the following form: <ref type="bibr" target="#b14">(15)</ref> where again, is set equal to zero. We will denote all distortion measures based on the above definition as "class two" distortion measures. <ref type="bibr" target="#b10">(11)</ref> The main motivation for considering these two classes of distortion measures stems from the popularity of the maximum absolute distance distortion measure, which is a class one measure, and the mean squared distance distortion measure, which is a class two measure. If we select the maximum absolute distance as the polygon distortion measure, then we have to use <ref type="bibr" target="#b11">(12)</ref> for the segment distortion and ( <ref type="formula">14</ref>) for the polygon distortion. On the other hand, if we select the mean squared distance as the distortion measure, then we have to use <ref type="bibr" target="#b12">(13)</ref> for the segment distortion and (15) for the polygon distortion. Note that there are many other polygon distortion measures that fit into this framework, such as the absolute area or the total number of error pels between the boundary and the polygon.</p><p>1) Admissible Vertex Set Different than Set of Boundary Points: We now extend our discussion on distortion measures so that the set of admissible vertex points is not equal to the set of boundary points . Also, the boundary approximation is done using curves of any order. Usually, , i.e., is a superset of and all original boundary points are eligible to become polygon vertex points. This is not necessary, however, since we can eliminate some boundary points from being candidates for vertex points through a preselection procedure in order to reduce the computational complexity of our algorithm. The preselection procedure indicates which boundary points are unlikely to be selected as optimal vertex points by the boundary encoding algorithm.</p><p>Let us now concentrate on the more usual case where . Thus, we now relax the restriction that the admissible vertices for the polygon belong to the original boundary. The main drawback of this restriction is that one can easily construct an example where for a given maximum polygon distortion, the polygon with the smallest bit rate uses vertices that do not fall onto boundary points. The problem with using vertices that do not belong to the boundary is that for a given polygon segment, no direct correspondence exists between the segment and a subset of boundary points. Hence, the polygon distortion cannot be formulated as the maximum or sum of the segment distortions unless we define segment distortion in a new way, as we will do in Section IV-B3.</p><p>2) Definition of the Admissible Vertex Set: From a theoretical point of view, the set of admissible vertices should contain all the pels in the image plane. On the other hand, the DAG shortest path algorithm, which we will be using, has a time complexity that is polynomial in the number of admissible vertices, and hence we would like to keep that number as small as possible without sacrificing coding efficiency. In this approach, the set of all admissible vertices is defined as all the pels that are within a given maximum distance from a boundary point (see Fig. <ref type="figure" target="#fig_20">26</ref>). Hence, the set of admissible vertices forms a "band" of width around the original boundary. 3) Distortion Measures: As mentioned earlier, in the case under consideration, there is no obvious correspondence between a segment and a subset of boundary points. Thus, ( <ref type="formula">14</ref>) and ( <ref type="formula">15</ref>) cannot be used directly. A straightforward distortion measure that does not have to be expressed in the form of ( <ref type="formula">14</ref>) and ( <ref type="formula">15</ref>) is the area between the original boundary and the polygon approximation. However, we would prefer to have a distortion measure that can be expressed using these equations because then we can use the DAG shortest path algorithm to find the optimum approximation.</p><p>To achieve this in the polygonal approximation case, every admissible vertex (for example, in Fig. <ref type="figure" target="#fig_20">26</ref>) is associated with the closest boundary point (which is in Fig. <ref type="figure" target="#fig_20">26</ref>). Thus, the approximation curve segment is associated with the original boundary segment . Then, we can define the segment distortion in any one of the previously mentioned ways, such as maximum absolute distance, mean squared distance, etc.</p><p>Let us now consider the second-order B-spline approximation case. As mentioned before, a second-order Bspline curve segment is defined by three control points . The points at the beginning and the end of a curve segment are called knots. It can be shown that for the class of B-splines in which we are interested, the knots are in the midpoints of the straight-line segment that connects two consecutive control points. This straight-line segment is tangent to the B-spline. Thus, we need to define a correspondence between a curve segment (the portion of the B-spline that is between two knots) and a portion of the original boundary. Again, we associate every knot (for example, in Fig. <ref type="figure" target="#fig_21">27</ref>) with the closest boundary point ( in Fig. <ref type="figure" target="#fig_21">27</ref>). Then, the approximation curve segment is associated with the original boundary segment , and we can define the segment distortion in any suitable way. Of course, the segment distortion will now be a function of three points, the control points that correspond to the segment . It should be pointed out that we could have defined the correspondence between an approximation curve segment and an original boundary segment in a different way. The above definition, however, is in our opinion the most natural one.</p><p>The same correspondence can be defined in the same way for B-splines of order three or higher. Again, we associate each knot of the B-spline (which can be found for specific values of the parameter ) with the closest boundary point. We then proceed as before.</p><p>4) The Distortion Band: In this section, we present an alternative way of defining the distortion for the maximum approach of the previous section, which is easier to implement. We define a distortion band around the original boundary of width , the desired maximum allowable distortion. Thus, for a faster implementation of the algorithm, we can calculate the locations of the points from where the boundary approximation is allowed to pass in a preliminary step of our algorithm. Then, it is very easy and fast to see if a candidate segment satisfies the distortion requirement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Rate</head><p>As mentioned earlier, we assume that the vertices of the polygon are encoded differentially, which is an efficient method for natural boundaries since the location of the current vertex is strongly correlated with the location of the previous one. This is the only restriction that we impose on the encoding of the vertices of the polygon or the control points of the parametric curve. We denote the required bit rate for the differential encoding of vertex given vertex by . Hence, the bit rate for the entire polygon is <ref type="bibr" target="#b15">(16)</ref> where is set equal to the number of bits needed to encode the absolute position of the first vertex. For a closed boundary, i.e., the first vertex is identical to the last one, the rate is set to zero since the last vertex does not need to be encoded.</p><p>As mentioned earlier, we use a DAG shortest path algorithm in order to determine the optimal control points for our boundary approximation. The DAG shortest path algorithm is a dynamic programming (DP) algorithm. A parametric curve of order requires control points per segment. A straight-line segment, which is a first-order parametric curve, is defined by two control points, the vertices of the polygon. Three control points are required for a second-order B-spline. Thus, in the case of B-splines, the rate required for a segment depends on three control points. Thus <ref type="bibr" target="#b16">(17)</ref> where is set equal to the number of bits needed to encode the absolute position of the first control point . Note that in the formulation we use for secondorder B-splines, there are control points in the approximation curve. It is straightforward to generalize the above discussion to higher order parametric curves.</p><p>The order of the DP algorithm will be equal to the maximum of the order of the curve and the number of vertices used for the prediction of the current vertex. We are interested in minimizing the order of the DP to reduce computational complexity. Thus, it is advantageous for us to use for the prediction of the current vertex a number of vertices that is equal to the order of the curve.</p><p>In the remainder of this paper, we introduce fast and efficient algorithms for both classes of polygon distortion measures that solve the following constrained optimization problem: subject to <ref type="bibr" target="#b17">(18)</ref> where is the maximum bit rate permitted for the encoding of the boundary. We also present algorithms that solve the dual problem subject to <ref type="bibr" target="#b18">(19)</ref> where is the maximum distortion permitted. Note that there is an inherent tradeoff between the rate and the distortion in the sense that a small distortion requires a high rate, whereas a small rate results in a high distortion. As we will see, the solution approaches for problems <ref type="bibr" target="#b17">(18)</ref> and <ref type="bibr" target="#b18">(19)</ref> are related in the sense that the algorithms are symmetric with respect to the rate, and the distortion or the algorithm developed to solve problem ( <ref type="formula">19</ref>) is used iteratively to solve problem <ref type="bibr" target="#b17">(18)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. An Algorithm for Distortion Measures Based on the Summation Operator</head><p>In this section, we derive a solution to problem (18) for a distortion measure based on <ref type="bibr" target="#b14">(15)</ref>, such as the maximum absolute distance. The solution is based on the Lagrange multiplier method <ref type="bibr" target="#b55">[56]</ref>- <ref type="bibr" target="#b57">[58]</ref> and the shortest path algorithm. It should be noted that the algorithm is symmetric in the rate, and the distortion and hence the same technique can be employed for the minimum distortion case <ref type="bibr" target="#b17">(18)</ref> and the minimum rate case <ref type="bibr" target="#b18">(19)</ref>. We will therefore only solve the minimum distortion case, and the minimum rate case can be solved be applying the following relabeling to the function names: and . We will present the method for the polygonal approximation case where only boundary points are admissible as polygon vertices. We will, however, discuss how the method is extended to the more general case.</p><p>The Lagrange multiplier method is extremely useful for solving constrained resource-allocation problems. In this application, we will use the Lagrange multiplier method to relax the constraint so that the relaxed problem can be solved using the shortest path algorithm.</p><p>We first define the Lagrangian cost function <ref type="bibr" target="#b19">(20)</ref> where is called the Lagrange multiplier. It has been shown in <ref type="bibr" target="#b55">[56]</ref> and <ref type="bibr" target="#b56">[57]</ref> that if there is a such that <ref type="bibr" target="#b20">(21)</ref> and which leads to , then is also an optimal solution to <ref type="bibr" target="#b17">(18)</ref>. It is well known that when sweeps from zero to infinity, the solution to <ref type="bibr" target="#b20">(21)</ref> traces out the convex hull of the operational rate-distortion function, which is a nonincreasing function. Hence, bisection <ref type="bibr" target="#b58">[59]</ref> or the fast convex search we presented in <ref type="bibr" target="#b59">[60]</ref> can be used to find . Therefore, if we can find the optimal solution to the unconstrained problem <ref type="bibr" target="#b20">(21)</ref>, then we can find the optimal and the convex hull approximation to the constrained problem of <ref type="bibr" target="#b17">(18)</ref>.</p><p>We can find a very efficient way of minimizing the Lagrangian cost function if we note that <ref type="bibr" target="#b21">(22)</ref> where <ref type="bibr" target="#b22">(23)</ref> are graph weights. It is clear from the above equations that the problem of minimizing the Lagrangian cost function can be formulated in the form of a directed graph (see Fig. <ref type="figure" target="#fig_22">28</ref>). The vertices of the graph correspond to the admissible vertex points (control points in the higher order case), and the edges correspond to the possible segments of the approximation polygon. The edges have weights . The 's in this figure are the admissible vertex points. For the time being, let us assume that only original boundary points are eligible to become vertex points. Thus, our problem reduces to finding the shortest path between the first and last vertex of the graph. This will give us the optimal vertices of the approximation polygon, since it will give us the path that minimizes the Lagrangian cost function.</p><p>We need to start the search for an optimal polygon at a given vertex. If the boundary is not closed, has to be selected as the first vertex . For a closed boundary, the selection of the first vertex is less obvious. Ideally, the algorithm should find all the optimal vertices, including the first one. Unfortunately, the above DAG requires a starting vertex. Hence, we need to fix the first vertex, even for a closed boundary. Therefore, the found solution is optimal, given the constraint of the predetermined first vertex. Clearly, we can drop this constraint by finding all optimal approximations using each boundary point as a starting vertex and then selecting the overall best solution. This exhaustive search with respect to the initial vertex is computationally quite expensive. We therefore propose to select the point with the highest curvature as the first vertex, since it is the most likely point to be included in any polygonal approximation. This heuristic almost always results in the best possible selection of the initial vertex, and, if not, the performance difference is negligible.</p><p>We relabel the boundary so that the first vertex of the polygon coincides with the first point of the boundary . Besides fixing the first vertex of the polygon, we also require that the last vertex is equal to the last point of the boundary . This leads to a closed polygonal approximation for a closed boundary. For a boundary that is not closed, this condition, together with the starting condition, makes sure that the approximation starts and ends at the same points as the boundary.</p><p>The classical algorithm for solving such a shortest path problem is Dijkstra's algorithm <ref type="bibr" target="#b60">[61]</ref>. We can, however, use a simpler algorithm by observing that it is very unlikely for the optimal path to select a boundary point as a vertex when the last selected vertex was , where . In general we cannot guarantee that the optimal path will not do this since the selection process depends on the vertex encoding scheme, which we have not specified yet. On the other hand, a polygon where successive vertices are not assigned to boundary points in increasing order can exhibit rapid direction changes even when the original boundary is quite smooth (see Fig. <ref type="figure" target="#fig_23">29</ref>). Therefore, we add the restriction that not every possible combination of represents a valid edge but only the ones for which . Hence, the edge set is redefined in the following way: (see Fig. <ref type="figure" target="#fig_24">30</ref>). This restriction results in the fact that a given vertex set uniquely specifies the polygon.</p><p>If we impose the above restriction for the admissible solution, our graph becomes a DAG. Thus, we can use the DAG shortest path algorithm <ref type="bibr" target="#b60">[61]</ref>, which has a lower computational complexity than Dijkstra's algorithm.</p><p>1) Extension to the General Case: In this section, we extend the above algorithm to the more general case of higher order approximation curves. Let us now assume that we are using second-order B-splines instead of polygons. For simplicity, let us assume that only boundary points are eligible to become control points. We will revisit the problem of Section IV-D for the case of second-order Bsplines.</p><p>Let us rewrite the Lagrangian cost function as <ref type="bibr" target="#b23">(24)</ref> where <ref type="bibr" target="#b24">(25)</ref> Note that now , , and depend on three control points. Also note that as mentioned earlier, in the beginning and end of the curve, we have double control points.</p><p>The above two points lead us to define the vertices of the graph, which we will now call states, in a different way. The states are now two dimensional, as shown in Fig. <ref type="figure" target="#fig_0">31</ref>. Each state now involves two possible control points . As mentioned earlier, the weights involve three control points. Except for these differences, the resulting graph is a DAG, and the shortest path can be found using the DAG shortest path algorithm. The algorithm can be extended to higher dimensional Bsplines. In this case, the states of the DAG would have a dimension equal to the order of the curves.</p><p>Let us now assume that the set of admissible vertices or control points is a superset of the set of boundary points. The above algorithm can be used intact if we order the admissible vertices or control points in a systematic way. This is necessary in order for the problem to be expressed in the form of a DAG. Any reasonable way for ordering the admissible vertices can be used. The interested reader is referred to <ref type="bibr" target="#b61">[62]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Algorithms for Distortion Measures Based on the Maximum Operator 1) Minimum Rate Case:</head><p>We now consider the minimum rate case, which is stated in <ref type="bibr" target="#b18">(19)</ref>. We assume a distortion measure that is based on the maximum operator. This problem can be solved in exactly the same way shown in Section IV-D by redefining as ( <ref type="formula">26</ref>)</p><p>Fig. <ref type="figure" target="#fig_0">31</ref>. An example of a DAG for the B-spline approximation case. One of these paths is the optimal path.</p><p>Note that the above definition of the weight function leads to a length of infinity for every path (polygon) that includes a line segment, resulting in an approximation error larger than . Therefore a shortest path algorithm will not select these paths. Every path that starts at vertex and ends at vertex and does not result in a path length of infinity results in a path length equal to the rate of the polygon it represents. Therefore, the shortest of all those paths corresponds to the polygon with the smallest bit rate, which is the solution to the problem in <ref type="bibr" target="#b18">(19)</ref>.</p><p>2) Minimum Distortion Case: We now consider the minimum distortion case, which is stated in <ref type="bibr" target="#b17">(18)</ref>. The goal of the proposed algorithm is to find the polygon with the smallest distortion for a given bit budget for encoding its vertices. Sometimes this is also called a rate-constrained approach. Recall that for class one distortion measures, the polygon distortion is defined as the maximum of the segment distortions [see <ref type="bibr" target="#b13">(14)</ref>]. Hence, in this section, we propose an efficient algorithm that finds the polygonal approximation with the smallest maximum distortion for a given bit rate.</p><p>We propose an iterative solution to this problem that is based on the fact that we can solve the dual problem stated in <ref type="bibr" target="#b18">(19)</ref> optimally. Consider in <ref type="bibr" target="#b18">(19)</ref> to be a variable. We derived in Section IV-E1 an algorithm that finds the polygonal approximation that results in the minimum rate for any . We denote this optimal rate by . It was proven in <ref type="bibr" target="#b61">[62]</ref> that the rate is a nonincreasing function of , which means that implies . Thus, we can use bisection <ref type="bibr" target="#b58">[59]</ref> to find the optimal such that . Since this is a discrete optimization problem, the function is not continuous and exhibits a staircase characteristic (see Fig. <ref type="figure" target="#fig_26">33</ref>). This implies that there might not exist a such that . In that case, the proposed algorithm will still find the optimal solution, which is of the form , but only after an infinite number of iterations. Therefore, if we have not found a such that after a given maximum number of iterations, we terminate the algorithm.</p><p>3) The Sliding Window: By using the distortion band (Section IV-B4) for the maximum distortion approach, the solution of the DAG shortest path algorithm may result in a trivial solution (see Fig. <ref type="figure" target="#fig_25">32</ref>). We need a way to force the algorithm along the boundary in order to find a curve. With the introduction of a sliding window, we not only avoid trivial solutions but also are able to control the speed of the algorithm. The sliding window indicates the admissible selections for the next control point (see Fig. <ref type="figure" target="#fig_25">32</ref>). Thus, trivial solutions are eliminated, and the computational complexity of the algorithm is decreased.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Polygonal Approximation Case:</head><p>In this section, we present experimental results of the proposed algorithms using object boundaries from the "Miss America" sequence. We first present results for class one distortion measures, where the employed distortion measure is the minimum absolute distance. In Fig. <ref type="figure">34</ref>, we compare the original segmentation, which is displayed in the left figure, versus the optimal segmentation for a maximum distortion of 1 pel, which is displayed in the right figure. The two objects in the original segmentation require 468 bits if encoded by an eight-connect chain code, whereas the optimal segmentation can be encoded with only 235 bits. By introducing a permissible maximum error of one pel, we are able to reduce the total bit rate by about 50%. As expected, some of the details have been lost, i.e., the boundary has been "straightened." This smoothing of the boundary might be desired since most segmentation algorithms result in noisy boundaries. In Fig. <ref type="figure">35</ref>, we show the resulting segmentation for the minimum distortion case for multiple boundaries. The maximum rate has  been set to 280 bits, and the optimal solution, which uses 274 bits for a pels, is displayed in the left figure. 2) B-Spline Approximation Case: We encoded the same boundaries as in the previous section using the B-spline algorithm. The distortion bandwidth was also set to 1 pel.</p><p>The "neck" object required 127 bits, whereas the "mouth" object required 84 bits for a total of 211 bits (Fig. <ref type="figure" target="#fig_29">36</ref>). The polygonal approximation required 235 bits.</p><p>We also encoded 100 frames of the Kids sequence and averaged the resulting bit rates and . The experiments were run for and pels. The results are shown in Fig. <ref type="figure" target="#fig_30">37</ref>. It can be seen that the results are comparable with the best results achieved by the baseline algorithm in MPEG-4 (Fig. <ref type="figure" target="#fig_11">17</ref>). It should be pointed out here that the control-point encoding scheme used <ref type="bibr" target="#b61">[62]</ref> is very simple, and hence further research will very likely result in an overall scheme that is even more efficient. Fig. <ref type="figure" target="#fig_31">38</ref> shows the reconstructed frame 17 of the Kids sequence using . The resulting was 0.0171, and 979 bits were required for the encoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>Within MPEG-4, several shape-coding algorithms were evaluated. In terms of coding efficiency, a context-based shape coder operating on a macroblock basis and a vertexbased shape coder performed similarly, with the contextbased shape coder providing better coding efficiency for lossless shape coding and the vertex-based shape coder   providing slightly better coding efficiency for lossy shape coding. In terms of hardware-implementation complexity, however, the block-based method allows for a regular memory access to the shape information, whereas the vertex-based method requires irregular access to an offchip cache. Therefore, the macroblock-based context-based shape coder was selected as the base technology of MPEG-4 shape coding. It integrates nicely with the block-based texture motion compensation and coding. Within a macroblock, the context-based shape coder defines a 9-or 10-pel causal context for encoding the binary shape infor-mation of the current pel. An arithmetic encoder is used to encode the current pel given the context. To exploit temporal redundancies, shape motion vectors with integer pel precision are estimated for shape motion compensation. These vectors are encoded predictively with respect to the texture motion vectors. Lossless shape coding of simple head and shoulder scenes at CIF resolution may require 300 bits/frame for the head-and-shoulder object; complicated objects may require an order of magnitude more bits. For transparent objects, the object outline is encoded using the binary shape-coding technique. If the object has constant transparency, this transparency value gets transmitted along with optional boundary filter information. For nonconstant transparency information, the 8-bit -plane is encoded using a hybrid coder with DCT and motion compensation.</p><p>The selection of the shape-coding algorithm was based on information available in April 1997. Considering that shape coding is a relatively new area within image processing, more research is required to gain a complete understanding of all the different aspects of shape coding. MPEG-4 will serve as the baseline against which new shape-coding techniques will have to compete.</p><p>As a first step toward this direction, we presented an efficient vertex-based framework for the lossy encoding of object shapes. The object shape is approximated by a polygon or second-order B-spline curve, which leads to the smallest bit rate for a given distortion. The polygon or Bspline curve is found by a shortest path algorithm since the problem can be described as a single-source DAG. In our discussion, we did not elaborate on the encoding of the vertices for the polygon and the control points for the B-spline. We used a simple extension to eight-connect chain codes in the experimental results. However, a more sophisticated encoding scheme for the control-point vectors might result in lower bit rates. Higher order curves as well as distortion bands of variable width can be incorporated into the proposed framework in a straightforward way.</p><p>MPEG-4 is the first international standard covering shape coding. It will be finalized in November 1998. The main purpose of the shape coder within MPEG-4 is not to increase coding efficiency for conventional video, although that has also been shown to accomplish this for some video sequences. Its primary purpose is to enable many new functionalities and applications such as object-based data base access, content-based image and video representation, video editing, efficient storage of movies prior to composition, and more.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. This image shows a scene composed of an object with constant and with arbitrary transparency on a background.</figDesc><graphic coords="3,80.58,55.02,428.00,320.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Fig. 4. Approximation using a polygon/spline approximation (from [64]).</figDesc><graphic coords="6,133.56,55.02,321.12,213.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. The upsampled pels (x) lie between the location of the subsampled pels (o). Neighboring pels (bold o) defining the values of the pels to be upsampled (bold x).</figDesc><graphic coords="7,121.50,55.02,82.32,80.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Changing pels are used in modified MMR shape coding to define object boundaries.</figDesc><graphic coords="7,304.80,54.96,241.68,121.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. For intracoding, a template positioned relative to b1 is used for selecting VLC tables in vertical mode.</figDesc><graphic coords="8,66.60,55.02,192.00,95.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Example of vertex adjustment (from [63]).</figDesc><graphic coords="9,141.18,54.96,306.00,128.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 10 .</head><label>10</label><figDesc>Fig.10. The difference V d between V k01 and the vertex V k to be coded determines the octant where V k is located.</figDesc><graphic coords="9,61.98,218.04,201.36,137.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Baseline-based shape coder. Clockwise contour tracing from a baseline using turning points and the distance from the baseline to the contour points.</figDesc><graphic coords="11,80.76,55.02,426.72,274.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Three of the test sequences for evaluation of shape coders. (a) Weather. (b) Children. (c) Robot.</figDesc><graphic coords="12,40.62,55.01,507.00,131.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Lossy encoding using a bitmap-based (a) and a contour-based (b) shape coder. The bitmap-based shape coder used pel replication as the upsampling filter (from [65]).</figDesc><graphic coords="13,307.26,256.14,236.64,128.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Comparison of rate-distortion curves in intramode. Bit-rate and distortion averages are given for 100 frames.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. Comparison of rate-distortion curves in intramode. Bit-rate and distortion averages are given for 100 frames.</figDesc><graphic coords="13,307.26,420.06,236.64,126.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 18 .</head><label>18</label><figDesc>Fig. 18. Comparison of rate-distortion curves in intramode. Bit-rate and distortion averages are given for 100 frames.</figDesc><graphic coords="14,44.46,55.02,236.40,127.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 19 .</head><label>19</label><figDesc>Fig. 19. Comparison of rate-distortion curves in intermode. Bit-rate and distortion averages are given for 100 frames.</figDesc><graphic coords="14,307.62,54.96,235.92,123.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 20 .</head><label>20</label><figDesc>Fig. 20. Comparison of rate-distortion curves in intermode. Bit-rate and distortion averages are given for 100 frames.</figDesc><graphic coords="14,307.62,222.24,235.92,123.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 21 .</head><label>21</label><figDesc>Fig. 21. Comparison of rate-distortion curves in intermode. Bit-rate and distortion averages are given for 100 frames.</figDesc><graphic coords="14,306.18,389.46,238.80,125.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 22 .</head><label>22</label><figDesc>Fig. 22. Comparison of chroma-key shape coder and MPEG-4 VM5 with lossless shape coding (dn = 0:0). Quantizer step sizes of 8, 12, and 20 are used (from [66]).</figDesc><graphic coords="15,88.86,55.02,410.64,223.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 23 .</head><label>23</label><figDesc>Fig. 23. Comparison of chroma-key shape coder and MPEG-4 VM5 with lossless shape coding</figDesc><graphic coords="15,89.22,321.60,409.92,223.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 24 .</head><label>24</label><figDesc>Fig. 24. A second-degree B-spline curve with eight curve segments Qu and a double control point at the beginning of the curve.</figDesc><graphic coords="18,44.70,54.96,235.92,171.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 25 .</head><label>25</label><figDesc>Fig. 25. Definition of the distortion d(4; 14) that corresponds to the edge (4; 14).</figDesc><graphic coords="18,325.44,55.02,200.40,165.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 26 .</head><label>26</label><figDesc>Fig. 26. The set of admissible vertices (polygon) or admissible control points (B-spline) forms a band of width 2 1 DM around the boundary.</figDesc><graphic coords="19,309.24,55.02,232.80,221.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Fig. 27 .</head><label>27</label><figDesc>Fig. 27. Definition of the correspondence between B-spline segments and original boundary segments. Round bullets: control points; rectangular bullets: knots.</figDesc><graphic coords="20,45.90,55.02,233.52,111.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Fig. 28 .</head><label>28</label><figDesc>Fig. 28. A specific example of a directed acyclic graph for the polygonal approximation case. The optimal path is shown in bold.</figDesc><graphic coords="21,341.28,55.02,168.72,128.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Fig. 29 .</head><label>29</label><figDesc>Fig. 29. Examples of polygons with rapid changes in direction.</figDesc><graphic coords="22,112.86,55.02,362.64,151.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Fig. 30 .</head><label>30</label><figDesc>Fig. 30. Interpretation of the boundary and the polygon approximation as a weighted directed graph. Note that the set of all segments E equals f(b i ; b j ) 2 B 2 : i &lt; jg. Two representative subsets are displayed. (a) f(b 4 ; b j ) 2 B 2 : 8j &gt; 4g. (b) f(b 8 ; b j ) 2 B 2 : 8j &gt; 8g.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Fig. 32 .</head><label>32</label><figDesc>Fig. 32. The sliding window restricts the selection of control point p u+1 to all the admissible control points within the sliding window. The introduction of a sliding window prevents trivial solutions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Fig. 33 .</head><label>33</label><figDesc>Fig.33. The R 3 (Dmax) function, which is a nonincreasing function exhibiting a staircase characteristic. The selected R max falls onto a discontinuity, and therefore the optimal solution is of the form R 3 (D3  max ) &lt; Rmax instead of R 3 (D 3 max ) = Rmax.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head></head><label></label><figDesc>Fig. 35(b) is a closeup of the lower boundary in Fig. 35(a), and the stars indicate the original boundary with the polygonal approximation drawn on top of it.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Fig. 34 .Fig. 35 .</head><label>3435</label><figDesc>Fig. 34. (a) Original segmentation, which requires 468 bits using the eight-connect chain code. (b) Optimal segmentation with D max = 1 pixel, which requires a rate of 235 bits and results in a distortion of 1 pixel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>Fig. 36 .</head><label>36</label><figDesc>Fig. 36. Results obtained using the B-spline approach. Dotted line: original boundary. Continuous line: B-spline approximation. Stars: control points.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Fig. 37 .</head><label>37</label><figDesc>Fig.37. Rate-distortion curve for the Kids sequence using the B-spline approach in the intramode. Bit rates and distortion averages are given for 100 frames.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Fig. 38 .</head><label>38</label><figDesc>Fig. 38. Frame 17 of the Kids sequence encoded using D max = 0:7. This encoding required 979 bits, resulting in d n = 0:0171.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="4,80.34,55.02,427.68,170.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="5,133.56,55.02,321.12,428.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="10,126.06,55.02,336.24,379.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="10,114.42,496.50,359.52,158.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="16,42.36,83.58,503.52,264.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Comparison Between the Block-Based CAE Shape Coder and the Contour-Based Vertex-Based Shape Coder Based on Seven Test Sequences. Relative Statements Are Always with Respect to the Other Shape Coder. Please Note that This Is a Snapshot as of April 1997</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>PROCEEDINGS OF THE IEEE, VOL. 86, NO. 6, JUNE 1998</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors wish to acknowledge that the material on MPEG-4 shape coding techniques was primarily contributed by J. Ostermann, while the rest of the material was contributed by the remaining authors. The authors wish to thank C. S. Boon, Matsushita, for providing the data for Figs. <ref type="bibr" target="#b20">21</ref> and 22 and C. L. Jordan, EPFL, for providing Fig. 14. J. S. Shin, SAIT, created Figs. 15-20 during the MPEG meeting in Bristol, U.K., to help the evaluation. M. Rong created Fig. 1. They also wish to thank Y. Wang and A. Reibman for their review of parts of this paper related to MPEG-4.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Aggelos K. Katsaggelos (Fellow, IEEE) received the diploma degree in electrical and mechanical engineering from the Aristotelian University of Thessaloniki, Thessaloniki, Greece, in 1979 and the M.S. and Ph.D. degrees in electrical engineering from the Georgia Institute of Technology, Atlanta, GA, in 1981 and 1985, respectively.</p><p>In 1985, he joined the Department of Electrical Engineering and Computer Science at Northwestern University, Evanston, IL, where he is currently a Professor and the Ameritech Chair of Information Technology. During the 1986-1987 academic year, he was an Assistant Professor with the Department of Electrical Engineering and Computer Science, Polytechnic University, Brooklyn, NY. His current research interests include image and video recovery, video compression, motion estimation, boundary encoding, computational vision, and multimedia signal processing. He was an Area Editor for Graphical Models and Image Processing <ref type="bibr">(1992)</ref><ref type="bibr">(1993)</ref><ref type="bibr">(1994)</ref><ref type="bibr">(1995)</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Object-oriented analysis-synthesis coding of moving images</title>
		<author>
			<persName><forename type="first">H</forename><surname>Musmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Htter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ostermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="117" to="138" />
			<date type="published" when="1989-10">Oct. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Second-generation image coding techniques</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1985-04">Apr. 1985</date>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="549" to="574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">International Standards Organization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Koenen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename></persName>
		</author>
		<idno>ISO/IEC JTC1/SC29/WG11 N1730</idno>
	</analytic>
	<monogr>
		<title level="m">Stockholm meeting</title>
		<imprint>
			<date type="published" when="1997-07">July 1997</date>
		</imprint>
	</monogr>
	<note>Overview of the MPEG-4 standard</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Morphological segmentation applied to displaced difference coding</title>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="45" to="56" />
			<date type="published" when="1994-07">July 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Subjective evaluation of MPEG-4 codec proposals: Methodological approach and test procedures</title>
		<author>
			<persName><forename type="first">T</forename><surname>Alpert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Baroncini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Contin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Koenen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="303" to="325" />
			<date type="published" when="1997-05">May 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Object-oriented motion estimation and segmentation in image sequences</title>
		<author>
			<persName><forename type="first">N</forename><surname>Diehl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="23" to="56" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Object-oriented analysis-synthesis coding based on the source model of moving rigid 3D objects</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ostermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="143" to="161" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Optimization and efficiency of an object-oriented analysis-synthesis coder</title>
		<author>
			<persName><forename type="first">M</forename><surname>Htter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="181" to="194" />
			<date type="published" when="1994-04">Apr. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Object-oriented analysis-synthesis coding (OOASC) based on the source model of moving flexible 3D objects</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ostermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="705" to="711" />
			<date type="published" when="1995-09">Sept. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Object-based analysis-synthesis coding of image sequences at very low bit rates</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gerken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="228" to="235" />
			<date type="published" when="1994-06">June 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Shape estimation of articulated objects for objectbased analysis-synthesis coding (OBASC)</title>
		<author>
			<persName><forename type="first">G</forename><surname>Martinez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="175" to="199" />
			<date type="published" when="1997-03">Mar. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Active mesh-A feature seeking and tracking image sequence representation scheme</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="610" to="624" />
			<date type="published" when="1994-09">Sept. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Closed-form connectivitypreserving solutions for motion compensation using 2-D meshes</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Altunbasak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Tekalp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1255" to="1269" />
			<date type="published" when="1997-09">Sept. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Graphics interchange format (sm), version 89a</title>
		<author>
			<persName><forename type="first">Inc</forename><surname>Compuserve</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990-07">July 1990</date>
			<pubPlace>Columbus, OH</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Facsimile coding schemes and coding functions for group 4 facsimile apparatus</title>
	</analytic>
	<monogr>
		<title level="j">CCITT Recommendation T</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Coded representation of picture and audio information-Progressive bi-level image compression</title>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
	<note>International Standards Organization, ISO Draft International Standard 11544</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Digital Pictures, Representation and Compression</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Netravali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Haskell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Plenum</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the encoding of arbitrary geometric configurations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IRE Trans. Electron. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="260" to="268" />
			<date type="published" when="1961-06">June 1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On the performance of a contour coding algorithm in the context of image coding. Part I: Contour segment coding</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="381" to="386" />
			<date type="published" when="1985-07">July 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Object-oriented analysis-synthesis coding based on moving two-dimensional objects</title>
		<author>
			<persName><forename type="first">M</forename><surname>Htter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="409" to="428" />
			<date type="published" when="1990-12">Dec. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An optimal segmentation encoding scheme in the rate distortion sense</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Circuits and Systems</title>
		<meeting>IEEE Int. Symp. Circuits and Systems</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="640" to="643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An optimal boundary encoding scheme in the rate distortion sense</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="13" to="26" />
			<date type="published" when="1998-01">Jan. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Object-adaptive vertex-based shape coding method</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>O'connell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="251" to="255" />
			<date type="published" when="1997-02">Feb. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fourier descriptors for plane closed curves</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Zahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Z</forename><surname>Roskies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="269" to="281" />
			<date type="published" when="1972-03">Mar. 1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Coding of partition sequences</title>
		<author>
			<persName><forename type="first">P</forename><surname>Salembier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gasull</surname></persName>
		</author>
		<editor>Video Coding, L. Torres and M. Kunt</editor>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Kluwer</publisher>
			<biblScope unit="page" from="125" to="170" />
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Analysis of the precision of generalized chain codes for the representation of planar curves</title>
		<author>
			<persName><forename type="first">J</forename><surname>Saghri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="533" to="539" />
			<date type="published" when="1981-09">Sept. 1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On the performance of chain codes for quantization of line drawings</title>
		<author>
			<persName><forename type="first">J</forename><surname>Koplowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="180" to="185" />
			<date type="published" when="1981-03">Mar. 1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A rate and distortion analysis of chain codes for line drawings</title>
		<author>
			<persName><forename type="first">D</forename><surname>Neuhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Castor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="53" to="68" />
			<date type="published" when="1985-01">Jan. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Encoding of arbitrary curves based on the chain code representation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kaneko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Okudaira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="697" to="707" />
			<date type="published" when="1985-07">July 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Relative vector probabilities in differential chain coded linedrawings</title>
		<author>
			<persName><forename type="first">R</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Vieveen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Bons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Arnbak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Pacific Rim Conf. Communication, Computers and Signal Processing</title>
		<meeting>IEEE Pacific Rim Conf. Communication, Computers and Signal essing<address><addrLine>Victoria, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989-06">June 1989</date>
			<biblScope unit="page" from="138" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multi-grid chain coding of binary shapes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Nunes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Marques</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Special Session on Shape Coding, ICIP&apos;97</title>
		<meeting>Special Session on Shape Coding, ICIP&apos;97<address><addrLine>Santa Barbara, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="114" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Very Low Bit Rate Video Coding Based on Statistical Spatio-Temporal Prediction of Motion, Segmentation and Intensity Fields</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ozcelik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Video Data Compression for Multimedia Computing</title>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Sun</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Derin</surname></persName>
		</editor>
		<meeting><address><addrLine>Norwell, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="313" to="353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<title level="m">Fundamentals of Digital Image Processing</title>
		<meeting><address><addrLine>Englewood Cliffs, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">A Contour-Oriented Approach for Shape Analysis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Van Otterloo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Hertfordshire, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Context-based arithmetic encoding of 2D shape sequences</title>
		<author>
			<persName><forename type="first">N</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bossen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Special Session on Shape Coding</title>
		<meeting>Special Session on Shape Coding<address><addrLine>Santa Barbara, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="29" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A binary shape coding method using modified MMR</title>
		<author>
			<persName><forename type="first">N</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Special Session on Shape Coding</title>
		<meeting>Special Session on Shape Coding<address><addrLine>Santa Barbara, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="504" to="508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Binary shape coding using 1-D distance values from baseline</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Special Session on Shape Coding, ICIP97</title>
		<meeting>Special Session on Shape Coding, ICIP97<address><addrLine>Santa Barbara, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="508" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Methodologies used for evaluation of video tools and algorithms in MPEG-4</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ostermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="343" to="365" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Efficiency of shapeadaptive transforms for coding of arbitrarily shaped image segments</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sikora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Makai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="254" to="258" />
			<date type="published" when="1995-06">June 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Predictive shape coding using generic polygon approximation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ISCAS&apos;98</title>
		<meeting>ISCAS&apos;98<address><addrLine>Monterrey, CA</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note>to be published</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Coding of subregions for content-based scalable video</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Swain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Haskell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="256" to="260" />
			<date type="published" when="1997-02">Feb. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Complexity analysis of the emerging MPEG-4 standard as a basis for VLSI implementation</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Stechele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Visual Communications and Image Processing</title>
		<meeting>SPIE Visual Communications and Image essing<address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">3309</biblScope>
			<biblScope unit="page" from="498" to="509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A portable instruction level profiler for complexity analysis documentation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kuhn</surname></persName>
		</author>
		<idno>ISO/IEC JTC1/WG11 MPEG96/M0921</idno>
	</analytic>
	<monogr>
		<title level="m">International Standards Organization</title>
		<meeting><address><addrLine>Tampere</addrLine></address></meeting>
		<imprint>
			<publisher>Finland</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Frater</surname></persName>
		</author>
		<idno>ISO/IEC JTC1/SC29/WG11</idno>
	</analytic>
	<monogr>
		<title level="m">International Standards Organization</title>
		<imprint>
			<date type="published" when="1997-04">Apr. 1997</date>
		</imprint>
	</monogr>
	<note>private communication</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Report of Ad-Hoc Group on Error Resilience</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brailean</surname></persName>
		</author>
		<idno>ISO/IEC JTC1/SC29/WG11 M2113</idno>
	</analytic>
	<monogr>
		<title level="j">Bristol meeting</title>
		<imprint>
			<date type="published" when="1997-04">Apr. 1997</date>
		</imprint>
	</monogr>
	<note>ternational Standards Organization</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">MPEG-4 video verification model version 8.0</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename></persName>
		</author>
		<idno>ISO/IEC JTC1/SC29/WG11 MPEG97/N1796</idno>
		<imprint>
			<date type="published" when="1997-07">July 1997</date>
		</imprint>
	</monogr>
	<note>International Standards Organization</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">MPEG-4 video verification model version 5</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename></persName>
		</author>
		<idno>ISO/IEC JTC1/SC29/WG11 MPEG97/N1469</idno>
		<imprint>
			<date type="published" when="1996-11">Nov. 1996</date>
		</imprint>
	</monogr>
	<note>International Standards Organization</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">New architectures for modified MMR shape coding</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Stroming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ISCAS&apos;97</title>
		<meeting>ISCAS&apos;97<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-06">June 1997</date>
			<biblScope unit="page" from="1205" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Alpha-channel compression in video coding</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Special Session on Shape Coding, ICIP&apos;97</title>
		<meeting>Special Session on Shape Coding, ICIP&apos;97<address><addrLine>Santa Barbara, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="500" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">An efficient shape coding scheme using B-splines which is optimal in the rate-distortion sense</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">W</forename><surname>Meier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997-06">June 1997</date>
			<pubPlace>Evanston, IL</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Northwestern University</orgName>
		</respStmt>
	</monogr>
	<note>master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">An efficient boundary encoding scheme which is optimal in the rate-distortion sense</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">W</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Image Processing</title>
		<meeting>Int. Conf. Image essing<address><addrLine>Santa Barbara, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="9" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">An efficient boundary encoding scheme using B-spline curves which is optimal in the rate-distortion sense</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">W</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd Erlangen Symp., Advances in Digital Image Communication</title>
		<meeting>2nd Erlangen Symp., Advances in Digital Image Communication<address><addrLine>Erlangen, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-04">Apr. 1997</date>
			<biblScope unit="page" from="75" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Computer Graphics: Principles and Practice</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Foley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Dam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hughes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Addison-Wesley</publisher>
			<biblScope unit="page" from="478" to="516" />
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">An optimal lossy segmentation encoding scheme</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Conf. Visual Communications and Image Processing</title>
		<meeting>SPIE Conf. Visual Communications and Image essing</meeting>
		<imprint>
			<date type="published" when="1996-03">Mar. 1996</date>
			<biblScope unit="page" from="1050" to="1061" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">An optimal segmentation encoding scheme in the rate-distortion sense</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp. Circuits and Systems</title>
		<meeting>Int. Symp. Circuits and Systems<address><addrLine>Atlanta, GA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-05">May 1996</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="640" to="643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Generalized Lagrange multiplier method for solving problems of optimum allocation of resources</title>
		<author>
			<persName><forename type="first">H</forename><surname>Everett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="399" to="417" />
			<date type="published" when="1963">1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Efficient bit allocation for an arbitrary set of quantizers</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shoham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gersho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust., Speech, Signal Processing</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1445" to="1453" />
			<date type="published" when="1988-09">Sept. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Bit allocation for dependent quantization with applications to multiresolution and MPEG video coders</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ramchandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="533" to="545" />
			<date type="published" when="1994-09">Sept. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Gerald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Wheatley</surname></persName>
		</author>
		<title level="m">Applied Numerical Analysis</title>
		<meeting><address><addrLine>Reading, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
	<note>th ed.</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Fast and efficient mode and quantizer selection in the rate distortion sense for H.263</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Conf. Visual Communications and Image Processing</title>
		<meeting>SPIE Conf. Visual Communications and Image essing</meeting>
		<imprint>
			<date type="published" when="1996-03">Mar. 1996</date>
			<biblScope unit="page" from="784" to="795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">T</forename><surname>Cormen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rivest</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>McGraw-Hill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Introduction to Algorithms</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Rate-Distortion Based Video Compression, Optimal Video Frame Compression and Object Boundary Encoding</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Kluwer</publisher>
			<pubPlace>Norwell, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Core experiments on MPEG-4 video shape coding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ostermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename></persName>
		</author>
		<idno>ISO/IEC/JTC1/SC29/WG11 N1584</idno>
	</analytic>
	<monogr>
		<title level="m">Seville meeting</title>
		<imprint>
			<date type="published" when="1997-02">Feb. 1997</date>
		</imprint>
	</monogr>
	<note>International Standards Organization</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Objectorientiere analyze-synthese codierung basierend auf dem modell bewegter, zweidimensinalen objekte</title>
		<author>
			<persName><forename type="first">M</forename><surname>Htter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<pubPlace>Hannover, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Universitt Hannover, Fortschritt-Berichte VDI</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Scalable shape representation for content based visual data compression</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bossen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ebrahimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Special Session on Shape Coding</title>
		<meeting>Special Session on Shape Coding<address><addrLine>Santa Barbara, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="512" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Boon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995-07">July 1995</date>
		</imprint>
	</monogr>
	<note>private communications</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
