<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automated Vessel Segmentation Using Infinite Perimeter Active Contour Model with Hybrid Region Information with Application to Retinal Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yitian</forename><surname>Zhao</surname></persName>
							<email>yitian.zhao@liverpool.ac.uk</email>
						</author>
						<author>
							<persName><forename type="first">Lavdie</forename><surname>Rada</surname></persName>
							<email>lavdie.rada@eng.bahcesehir.edu.tr</email>
						</author>
						<author>
							<persName><forename type="first">Ke</forename><surname>Chen</surname></persName>
							<email>cmchenke@liverpool.ac.uk</email>
						</author>
						<author>
							<persName><forename type="first">Simon</forename><forename type="middle">P</forename><surname>Harding</surname></persName>
							<email>sharding@liverpool.ac.uk</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Yalin</forename><surname>Zheng</surname></persName>
							<email>yalin.zheng@liverpool.ac.uk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Eye and Vision Science</orgName>
								<orgName type="department" key="dep2">School of Mechatronical Engineering</orgName>
								<orgName type="institution">University of Liverpool</orgName>
								<address>
									<settlement>Liverpool</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Faculty of Engineering and Natural Sciences</orgName>
								<orgName type="institution">Bahcesehir University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Centre for Mathematical Imaging Techniques and De-partment of Mathematical Sciences</orgName>
								<orgName type="institution">University of Liverpool</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Eye and Vision Science</orgName>
								<orgName type="institution">University of Liverpool</orgName>
								<address>
									<settlement>Liverpool</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Department of Eye and Vision Science</orgName>
								<orgName type="institution">University of Liverpool</orgName>
								<address>
									<settlement>Liverpool</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Automated Vessel Segmentation Using Infinite Perimeter Active Contour Model with Hybrid Region Information with Application to Retinal Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DC79476E80A357B1527F1FE1B0371C67</idno>
					<idno type="DOI">10.1109/TMI.2015.2409024</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TMI.2015.2409024, IEEE Transactions on Medical Imaging This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TMI.2015.2409024, IEEE Transactions on Medical Imaging</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>vessel</term>
					<term>segmentation</term>
					<term>local phase</term>
					<term>infinite perimeter</term>
					<term>active contour</term>
					<term>fundus</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automated detection of blood vessel structures is becoming of crucial interest for better management of vascular disease. In this paper, we propose a new infinite active contour model that uses hybrid region information of the image to approach this problem. More specifically, an infinite perimeter regularizer, provided by using L 2 Lebesgue measure of the γ-neighborhood of boundaries, allows for better detection of small oscillatory (branching) structures than the traditional models based on the length of a feature's boundaries (i.e. H 1 Hausdorff measure). Moreover, for better general segmentation performance, the proposed model takes the advantage of using different types of region information, such as the combination of intensity information and local phase based enhancement map. The local phase based enhancement map is used for its superiority in preserving vessel edges while the given image intensity information will guarantee a correct feature's segmentation. We evaluate the performance of the proposed model by applying it to three public retinal image datasets (two datasets of color fundus photography and one fluorescein angiography dataset). The proposed model outperforms its competitors when compared with other widely used unsupervised and supervised methods. For example, the sensitivity (0.742), specificity (0.982) and accuracy (0.954) achieved on the DRIVE dataset are very close to those of the second observer's annotations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>lead to profound complications, including stroke, diabetes, arteriosclerosis, cardiovascular diseases and hypertension, to name only the most obvious. Vascular diseases are often life-critical for individuals, and present a challenging public health problem for society. The drive for better understanding and management of these conditions naturally motivates the need for improved imaging techniques. The detection and analysis of the vessels in medical images is a fundamental task in many clinical applications to support early detection, diagnosis and optimal treatment. In line with the proliferation of imaging modalities, there is an ever-increasing demand for automated vessel analysis systems for which where blood vessel segmentation is the first and most important step.</p><p>As blood vessels can be seen as linear structures distributed at different orientations and scales in an image, various kernels (or enhancement filters) have been proposed to enhance them in order to ease the segmentation problem <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b10">[11]</ref>. In particular, a local phase based filter recently introduced by Lathen et al. <ref type="bibr" target="#b9">[10]</ref> seems to be superior to intensity based filters <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b7">[8]</ref> as it is immune to intensity inhomogeneity and is capable of faithfully enhancing vessels of different widths. It is worth noting that morphological filters such as path opening in combination with multiscale Gaussian filters has also shown some interesting results <ref type="bibr" target="#b8">[9]</ref>. The main disadvantage of morphological methods is that they do not consider the known vessel cross-sectional shape information, and the use of an overly long structuring element may cause difficulty in detecting highly tortuous vessels <ref type="bibr" target="#b11">[12]</ref>.</p><p>Recent years have witnessed the rapid development of methods for vessel segmentation <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b13">[14]</ref>. Broadly speaking, all of the established segmentation techniques may be categorized as either supervised <ref type="bibr" target="#b7">[8]</ref> or unsupervised segmentation <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref> with respect to the overall system design and architecture. Supervised segmentation methods use training data to train a classifier (e.g. k-nearest neighbors <ref type="bibr" target="#b16">[17]</ref>, support vector machine (SVM) <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, artificial neural networks (ANN) <ref type="bibr" target="#b19">[20]</ref>, Gaussian mixture models (GMM) <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b20">[21]</ref>, AdaBoost <ref type="bibr" target="#b21">[22]</ref>, or conditional random fields (CRFs) <ref type="bibr" target="#b22">[23]</ref>) so that it can be used for the classification of image pixels as either vessel or not in a new, previously unseen image. As such this approach requires hand-labelled gold standard images for training, and discriminative features, such as Gabor features <ref type="bibr" target="#b7">[8]</ref>, to be extracted for each pixel of an image. In contrast, unsupervised segmentation refers to methods that achieve the segmentation of blood vessels without using training data, or explicitly using any classification techniques. The lower requirement on the data and training makes unsupervised segmentation methods more applicable to a wider range of imaging modalities. This category encapsulates most vessel segmentation techniques in the literature, such as <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b23">[24]</ref>- <ref type="bibr" target="#b27">[28]</ref>, and our model as described in this paper.</p><p>For unsupervised segmentation, different segmentation models have been proposed ranging from the primitive thresholding technique <ref type="bibr" target="#b5">[6]</ref>, morphological path opening followed by thresholding and fusion <ref type="bibr" target="#b8">[9]</ref>, to elegant approaches such as active contour models <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>. In general, the main limitations of thresholding based methods <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b8">[9]</ref> are that it is difficult (or impossible) to determine optimum threshold values and one is unable to take into account the geometry information of the objects to be segmented, which limit its potential to be generalizable to wider applications. In contrast, active contour models have demonstrated good performance in dealing with challenging segmentation problems including vessel segmentation <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b29">[30]</ref>. As such we will focus on the development of a new active contour model for improving accuracy in vessel segmentation problems.</p><p>A number of active contour models have been proposed for vessel segmentation problems, including the ribbon of twins (ROT) model <ref type="bibr" target="#b14">[15]</ref>, geodesic active contour (GAC) model <ref type="bibr" target="#b9">[10]</ref>, variations of the active contour without edge model (better known as the CV model <ref type="bibr" target="#b30">[31]</ref>) <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b31">[32]</ref>, and the distance regularization level set evolution (DRLSE) model <ref type="bibr" target="#b32">[33]</ref>. We only make briefly comments on these models and will review them in detail in the next section. As a parametric active contour model, the ROT model is difficult to formulate and optimise <ref type="bibr" target="#b14">[15]</ref>. The GAC model requires careful good initialization <ref type="bibr" target="#b9">[10]</ref>. The CV and DRLSE models are easy to formulate and optimize but the regularization term of the shortest smooth boundary length makes them not necessarily suitable for vessel segmentation problems. Of these models, only the ROT model and the DRLSE model have been evaluated against public datasets <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b29">[30]</ref>. On the other hand, a new infinite perimeter active contour model <ref type="bibr" target="#b33">[34]</ref> has shown convincing performance in the detection of small oscillatory structures. This feature of the model implies good performance expectations with vessel segmentation problems. We also conjecture that models which can include more image information may perform better. As such, we propose a novel extension of the infinite perimeter active contour model so that the newly proposed model is able to take into account different types of image information. We also investigate its performance with three public retinal image datasets. The main reasons of using retinal images are twofold: first, there are well-established public datasets available for research and application purposes. These datasets are often used as benchmarks for developing new segmentation algorithms and for comparing them to state-of-the-art approaches. Secondly, retinal vessel analysis is important to the study of not only retinal diseases but also many systemic diseases (e.g. stroke and cardiovascular diseases) <ref type="bibr" target="#b11">[12]</ref>.</p><p>The remainder of this paper is structured as follows. Section II provides an overview of some classic active contour models with a focus on commonly used ones for the vessel segmentation problem, and a brief introduction to typical vessel enhancement filters. Section III details the proposed infinite perimeter active contour model with hybrid region terms. In Section IV, we describe the validation image dataset, performance metrics and experiment configurations. Section V presents our experimental results. Section VI concludes the paper with a short discussion of our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>In this section, we provide some background knowledge of the work for the benefit of the reader. We will first review some classic active contour models including those used for vessel segmentation applications in the literature, and then briefly introduce some typical filters for vesselness enhancement.</p><p>A. Active Contour Models 1) Chan-Vese (CV) Model <ref type="bibr" target="#b30">[31]</ref>: The CV model was initially proposed by Chan and Vese to solve the piecewise constant segmentation problem <ref type="bibr" target="#b30">[31]</ref>. It has been widely used and extended to address a wide range of segmentation problems.</p><p>Without loss of generality, here we choose the 2dimensional (2D) segmentation problem as an example. Denoting a given image by u 0 (x), x = (x 1 , x 2 ), the CV model can be formulated as the energy minimization problem below:</p><formula xml:id="formula_0">E CV (Γ, c 1 , c 2 ) = µ cv H 1 (Γ) + λ 1cv inside(Γ) |u 0 (x) -c 1 | 2 dx + λ 2cv outside(Γ) |u 0 (x) -c 2 | 2 dx, (1)</formula><p>where c 1 and c 2 are the average of u 0 (x) inside and outside (Γ) respectively, µ cv , λ 1cv and λ 2cv are non-negative fixed parameters while H n-1 is the n -1 dimensional Hausdorff measure which, in the 2D case, denotes the length of a curve. The unknown curve Γ can be represented by the zero level set of Lipschitz function φ : Ω → R and we rewrite the energy function in the form:</p><formula xml:id="formula_1">E CV (φ(x), c 1 , c 2 ) = µ cv Ω |∇H(φ(x))| dx + λ 1cv Ω |u 0 (x) -c 1 | 2 H(φ(x)) dx + λ 2cv Ω |u 0 (x) -c 2 | 2 (1 -H(φ(x))) dx,<label>(2)</label></formula><p>where H denotes the Heaviside function. This model can be solved by alternatively solving c 1 and c 2 , and φ(x), with φ(x) typically solved by gradient decent methods <ref type="bibr" target="#b30">[31]</ref>. Effort has been made to modify the CV model so that it can be used to address more complicated problems than just the piecewise constant problem. For example, the so called Local Morphology Fitting (LMF) model proposed by Sun et al. <ref type="bibr" target="#b15">[16]</ref> merely modifies the data (or region) terms and adds a level set regularization term with a positive weight ν. The energy functional E LMF can be rewritten as:</p><formula xml:id="formula_2">E LMF (φ(x)) = µ |∇H(φ(x))| dx + λ1 Ω |u0(x) -Imax(x)| 2 H(φ(x)) dx + λ2 Ω |u0(x) -Imin(x)| 2 (1 -H(φ(x))) dx + ν Ω 1 2 (|∇φ(x)| -1) 2 dx,<label>(3)</label></formula><p>where µ, λ 1 , λ 2 and ν are positive constants and I min and I max denote the maximum fuzzy opening and minimum fuzzy opening (see Eqs. <ref type="bibr" target="#b10">(11)</ref> and (13) of <ref type="bibr" target="#b15">[16]</ref>). Note that the last term is a distance regularization term proposed by an early version of the DRLSE model <ref type="bibr" target="#b32">[33]</ref> to avoid the re-initialization problem in level set evolution. The Region-Scalable Fitting (RSF) model <ref type="bibr" target="#b31">[32]</ref> is another extension of the CV model in order to solve piecewise smooth segmentation problems (e.g. uneven illumination). In this model, the data terms are reformulated as follows:</p><formula xml:id="formula_3">E RSF (φ(x)) = µ |∇H (φ(x))| dx + λ1 Kσ(x -y)|I(y) -f1(x)| 2 H(φ(y)) dy dx + λ2 Kσ(x -y)|I(y) -f2(x)| 2 (1 -H(φ(y))) dy dx + ν Ω 1 2 (|∇φ(x)| -1) 2 dx,</formula><p>where K σ is chosen as a Gaussian kernel in <ref type="bibr" target="#b31">[32]</ref>, and f 1 (x) and f 2 (x) are two functionals which approximate image intensities inside and outside Γ. Li et al. have shown the potential of using the RSF model to segment blood vessels when there is uneven illumination <ref type="bibr" target="#b31">[32]</ref>. However, only a few examples are shown without quantitative evaluations.</p><p>2) Distance Regularized Level Set Evolution (DRLSE) Model <ref type="bibr" target="#b32">[33]</ref>: The energy of the DRLSE model is defined as</p><formula xml:id="formula_4">E DRLSE (φ(x)) = µR(φ(x)) + λL g (φ(x)) + αA g (φ(x)),<label>(4)</label></formula><p>where R(φ((x))) is the distance regularization term, L g (φ((x))) = Ω gδ (φ(x))|∇φ(x)| dx is the external energy term which indicates the length functional, and A g (φ((x))) = Ω gH (-φ(x)) dx the area penalization term. Both L g and A g include an edge indicator function g. g can be derived from the gradient of the image intensity, g(∇u</p><formula xml:id="formula_5">0 (x)) = 1/(1 + |(∇G σ * u 0 (x))| a )</formula><p>, where G σ is a Gaussian function with the standard deviation σ, the symbol * represents convolution and a is a weighting factor. Dizdaroglu et al. used a phased based form in their vessel segmentation work <ref type="bibr" target="#b29">[30]</ref>. Different forms can be taken for the distance regularization term R(φ(x)): R(φ(x)) = 1/2 (|∇φ(x)| -1) 2 dx has been widely used <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b33">[34]</ref>.</p><p>3) Ribbon of Twins (ROT) Model <ref type="bibr" target="#b14">[15]</ref>: The ROT model was proposed specifically for the vessel segmentation problem. Two twins of contours represent a ribbon along a vessel, with one twin on each edge of the vessel. Each twin consists of two contours, one inside and one outside the vessel. The two outside contours are connected by pull forces to the inside contours, while the inside contours are connected by push forces to each other. The energy of the model is defined as:</p><formula xml:id="formula_6">E ROT (c(s)) = 1 0 E int c (vc(s)) + E pho c (vc(s)) + E rot c (vc(s)) ds,<label>(5)</label></formula><p>where E int c , E pho c , and E rot c denotes the internal, photometric, and ROT mode energy functions, respectively. v c (s) are the four linked active contours, where s ∈ [0, 1]. This model is built on parametric curves and as such it is difficult to formulate and be solved efficiently. Moreover, its stability and performance crucially depends on parameter choice.</p><p>4) Geodesic Active Contour (GAC) Model: Lathen et al. used a GAC model for the segmentation of vessels <ref type="bibr" target="#b9">[10]</ref>. The formula is given below.</p><formula xml:id="formula_7">∂φ(x) ∂t = -Re(LP )|∇φ(x)| + ακ|∇φ(x)|, (<label>6</label></formula><formula xml:id="formula_8">)</formula><p>where t is time, Re(LP ) is the real part of the local phase map LP which will be introduced in the following section, κ is the curvature and α ≥ 0 is a regularization weight parameter.</p><p>Although the model works well with finding the blood vessels, it does crucially depend on the choice of the seeds placed for the initialization of the level set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Infinite Perimeter Active Contour (IPAC) Model [34]:</head><p>The IPAC model was proposed for the segmentation of objects with irregular boundaries. The energy function is given as:</p><formula xml:id="formula_9">F IPAC (Γ, c 1 , c 2 ) = L 2 (γ -Γ) + λ 1 inside(Γ) |u 0 (x) -c 1 | 2 dx + λ 2 outside(Γ) |u 0 (x) -c 2 | 2 dx. (7)</formula><p>where L 2 is the 2D Lebesgue measure of the γ-neighborhood of the edge set Γ and λ 1 and λ 2 are fitting term parameters. Replacing f 0 := χ [0,1] with a smooth version of it, such as f (t) = e -t α or f (t) = 1 1+t α for α ≥ 1, positive decreasing function, and considering the fact that the level set approach consists of working with level set functions φ(x) which are signed distance functions from their zero level set Γ, the L 2 (γ -Γ) term can be rewritten as:</p><formula xml:id="formula_10">L 2 (γ -Γ) := Ω f 0 ( dist(x,Γ) γ ) dx ≈ Ω f ( dist(x,Γ) γ ) dx = Ω f ( |φ(x)| γ ).</formula><p>Considering the above, Eq. 7 has the following form:</p><formula xml:id="formula_11">F IPAC (φ(x)) = Ω f ( |φ(x)| γ ) + R(φ(x)) + λ 1 Ω |u 0 (x) -c 1 | 2 H(φ(x)) dx + λ 2 Ω |u 0 (x) -c 2 | 2 (1 -H(φ(x))) dx.<label>(8)</label></formula><p>where R(φ(x)) is the distance regularization term as defined in <ref type="bibr" target="#b32">[33]</ref>, which forces the level set to be a signed distance function. Similar to the CV model, φ(x) can be solved by a gradient decent method. It has been shown that this model has the capability of removing the noise, the cornering effect, resolution and capability of keeping oscillatory parts of the boundaries and performs better than the CV model <ref type="bibr" target="#b33">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Typical Vesselness Filters</head><p>Filters which can enhance vessel-like structures have played an important role in the vessel segmentation problems <ref type="bibr" target="#b11">[12]</ref>. Here, we review the three most influential filters <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b9">[10]</ref>.</p><p>1) Eigenvalue-based Filter <ref type="bibr" target="#b1">[2]</ref>: Proposed by Frangi et al. <ref type="bibr" target="#b1">[2]</ref>, this filter is based on eigenvalues of the Hessian matrix H(x). For each pixel (x) of a 2D image with intensity f (x), the Hessian matrix can be formed by its 3 second derivatives, f x1x1 , f x2x2 , and f x1x2 , from which two eigenvalues can be computed and ordered as as |λ 1 | ≥ |λ 2 |. The filter is given as</p><formula xml:id="formula_12">F (x) =    0 if λ1 &gt; 0 exp - R 2 β 2β 2 1 -exp -S 2c 2 otherwise. (<label>9</label></formula><formula xml:id="formula_13">)</formula><p>where</p><formula xml:id="formula_14">R β = λ 1 /λ 2 is the blobness measure in 2D while S = (λ 2 1 + λ 2 2 ) 1/2</formula><p>is the second order structureness. Here β and c are constants which can be experimentally chosen for specific applications.</p><p>2) Isotropic Undecimated Wavelet Filter <ref type="bibr" target="#b5">[6]</ref>: The isotropic undecimated wavelet transform (IUWT) has recently been used for vessel segmentation and showed good accuracy and computational efficiency <ref type="bibr" target="#b5">[6]</ref>. Applied to a signal c 0 = f , subsequent scaling coefficients are calculated by convolution with a filter</p><formula xml:id="formula_15">h ↑j c j+1 = c j * h ↑j<label>(10)</label></formula><p>where</p><formula xml:id="formula_16">h 0 = [1, 4<label>, 6, 4, 1]</label></formula><p>/16 is derived from the cubic Bspline, h ↑j is the upsampled filter obtained by inserting 2 j -1 zeros between each pair of adjacent coefficients of h 0 . If f is multidimensional, the filtering can be applied separably along all dimensions. Wavelet coefficients are then the difference between two adjacent sets of scaling coefficients, i.e.</p><formula xml:id="formula_17">w j+1 = c j -c j+1 .<label>(11)</label></formula><p>Reconstruction of the original signal from all wavelet coefficients and the final set of scaling coefficients is straightforward, and requires only addition. After the computation of n wavelet levels</p><formula xml:id="formula_18">f = c n + n j=1 w j .<label>(12)</label></formula><p>In vessel segmentation, the number of levels has to be tailored according to the specific problem and the data in order to achieve good vessel segmentation results.</p><p>3) Local Phase-based Filter <ref type="bibr" target="#b9">[10]</ref>: Local phase is an important local feature that can measure structural information (e.g. lines and edges) of an image. It has recently been shown that this information can be used to enhance vessels in a more precise way and produce promising segmentation results <ref type="bibr" target="#b9">[10]</ref>. It is worth noting that local phase and local energy are often used interchangeably, following convention, here this filter is still referred to as a 'local phase-based' filter only, even though it has been modulated by the local energy.</p><p>For imaging applications, local phase can be estimated by using quadrature filters under the concept of monogenic signals. A quadrature filter comprises a pair of even and odd filters with phase difference of π/2. Let E j n and O j n denote the even symmetric and odd-symmetric parts of a quadrature filter at scale n and orientation j. At each point x in an image I, the filter response q j n (x) is given by q j n = e j n (x) + o j n (x)i, i = √ -1, while e j n (x) = I(x) * E j n and o j n (x) = I(x) * O j n respectively, where * denotes a convolution operation. To avoid problem caused by changes on structural direction, the absolute value of the imaginary part o j n is used, so that q j n = e j n + |o j n |i. The response at scale n is thus defined as q n = J j=1 q j n , where J is the number of directions under consideration (four directions (0, π/4, π/2, and 3π/4) are used in this paper). By combining the responses from each of the scales, the overall response P is given below.</p><formula xml:id="formula_19">P = N n=1 q n |q n | β N n=1 |q n | β , (<label>13</label></formula><formula xml:id="formula_20">)</formula><p>where N is the number of scales and β is a weighting parameter with value ≥ 1. There are numerous quadrature filters that might be used <ref type="bibr" target="#b34">[35]</ref>, but here we will stay with the optimized log-norm filter with a view to optimal performance in both the spatial and frequency domains <ref type="bibr" target="#b35">[36]</ref>. More specifically, the center frequency is 5π/7, the bandwidth is 2 octaves, and the filter has a size of 15 × 15. Following Lathen's work <ref type="bibr" target="#b9">[10]</ref>, in order to make the map more regular for the purpose of segmentation and to minimize noise, P is further normalized to produce the final map,</p><formula xml:id="formula_21">LP = P |P |/(|P | 2 + a 2 )</formula><p>, where a is a small positive number. In practice, the real part of LP , Re(LP ), is used as the 'vesselness map'. This vesselness map has some unique properties. It has a positive value inside the lines (or vessels) but a negative value in the background, and has a zero value at the edge of the line structures. Fig. <ref type="figure" target="#fig_1">1</ref> demonstrates the enhancement results after applying the aforementioned three enhancement methods: Eigenvalue-based <ref type="bibr" target="#b1">[2]</ref>, Waveletbased <ref type="bibr" target="#b5">[6]</ref>, and local phase method <ref type="bibr" target="#b9">[10]</ref>. The example images as shown in Fig. <ref type="figure" target="#fig_1">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. INFINITE PERIMETER ACTIVE CONTOUR WITH HYBRID REGION INFORMATION (IPACHI) MODEL</head><p>Inspired by the IPAC model <ref type="bibr" target="#b33">[34]</ref>, we propose a novel extension so as to integrate hybrid region information into the segmentation model. The energy of the IPACHI model is:</p><formula xml:id="formula_22">F IPACHI (Γ, r n ) = L 2 (γ -Γ) + N n=1 λ n R n ,<label>(14)</label></formula><p>where L 2 is the 2D Lebesgue measure, R n is the nth region information, and N is the total number of different region terms. The first term L 2 is the area of the γ-neighborhood of the edge set Γ. Here we consider</p><formula xml:id="formula_23">L 2 (γ -Γ) ≈ Ω e -( φ(x) γ ) α</formula><p>, for a large and even number α, which is an approximation of the γ-neighborhood area in a given image u 0 (x).</p><p>Different types of region terms can be used alone (N = 1) or combined (N &gt; 1) for the need of specific applications. In particular, when λ 1 Ω1 logP 1 (u 0 (x), Ω 1 ) dx + λ 2 Ω2 logP 2 (u 0 (x), Ω 2 ) dx becomes the set of terms used in region competition models. More importantly, this formulation offers the flexibility of using different types of region information to achieve better segmentation, as shown by the work of using both spatial and frequency information in one model <ref type="bibr" target="#b36">[37]</ref>. The proposed model could be extended for multiphase problems, limited by space, this extension is not presented here.</p><formula xml:id="formula_24">N = 1, λ 1 Ω |u 0 (x) -c 1 | 2 H(φ(x)) dx + λ 2 Ω |u 0 (x)-c 2 | 2 (1-H(φ(x)) dx,</formula><p>For this vessel segmentation application, we propose to use the 'vesselness map' v 0 = Re(LP ) of an image and the image intensity u 0 as two distinct region terms to extract vessels mimicking an object with irregular and oscillatory boundaries. The effectiveness of the local phase based enhancement filter will be studied against two other filters [2], <ref type="bibr" target="#b5">[6]</ref>, which will be described in the following section.</p><p>Using the Lipschitz level set function, the energy function of our new model can be written: min</p><formula xml:id="formula_25">φ(x),c V 1 ,c V 2 ,c I 1 ,c I 2 F IPACHI (φ(x), c V 1 , c V 2 , c I 1 , c I 2 ) = µ 1 Ω g(u 0 (x))e -( φ(x) γ ) α + µ 2 2 Ω (|∇φ(x)| -1) 2 dx +λ V 1 Ω |v 0 (x) -c V 1 | 2 H(φ(x) dx +λ V 2 Ω |v 0 (x) -c V 2 | 2 (1 -H(φ(x)) dx +λ I 1 Ω |u 0 (x) -c I 1 | 2 H(φ(x) dx +λ I 2 Ω |u 0 (x) -c I 2 | 2 (1 -H(φ(x)) dx,<label>(15)</label></formula><p>where</p><formula xml:id="formula_26">µ 1 , µ 2 ,λ V 1 , λ V 2 , λ I 1 ,</formula><p>and λ I 2 are weighting parameters. The parameters λ V 1 and λ V 2 are for the vesselness based term while λ I 1 and λ I 2 for intensity based terms. g(u 0 (x)) is the edge stopping function. Different to the model <ref type="bibr" target="#b33">[34]</ref>, here we use a function based on the concept of local phase since local phase is believed to produce more precise edges. In particular, g(u 0 (x)) = 1/(1 + Img(LP )) where Img(LP ) is the imaginary part of the phase map. Note, the second term of Eq 15 is introduced as distance regularization as proposed by Li et al. <ref type="bibr" target="#b32">[33]</ref>. There are different ways to define the regularized counterpart H (φ(x)) of the Heaviside function H(φ(x)), and here it is defined as</p><formula xml:id="formula_27">H = 1 2 1 + 2 π arctan z<label>(16)</label></formula><p>and its corresponding delta function δ</p><formula xml:id="formula_28">δ = 2 π 2 z 2 + 2 . (<label>17</label></formula><formula xml:id="formula_29">)</formula><p>Now the proposed model can be written:</p><formula xml:id="formula_30">min φ(x),c V 1 ,c V 2 ,c I 1 ,c I 2 F IPACHI (φ(x), c V 1 , c V 2 , c I 1 , c I 2 ) = µ 1 Ω g(u 0 (x))e -( φ(x) γ ) α + µ 2 2 Ω (|∇φ(x)| -1) 2 dx +λ V 1 Ω |v 0 (x) -c V 1 | 2 H (φ(x) dx +λ V 2 Ω |v 0 (x) -c V 2 | 2 (1 -H (φ(x)) dx +λ I 1 Ω |u 0 (x) -c I 1 | 2 H (φ(x) dx +λ I 2 Ω |u 0 (x) -c I 2 | 2 (1 -H (φ(x)) dx.<label>(18)</label></formula><p>By keeping φ(x) fixed and deriving with respect to c</p><formula xml:id="formula_31">V 1 , c V 2 , c I 1 and c I 2 , we have equations for computing c V 1 , c V 2 , c I 1 and c I 2 c V 1 = Ω v 0 (x)H (φ(x))dx Ω H (φ(x)) dx , c V 2 = Ω v 0 (x)(1 -H (φ(x)))dx Ω (1 -H (φ(x))) dx , c I 1 = Ω u 0 (x)H (φ(x)) dx Ω H (φ(x)) dx , c I 2 = Ω u 0 (x)(1 -H (φ(x))) dx Ω (1 -H (φ(x))) dx . (<label>19</label></formula><formula xml:id="formula_32">)</formula><p>By keeping c V 1 , c V 2 , c I 1 and c I 2 fixed we have the equations for φ(x)</p><formula xml:id="formula_33">                           ∂φ(x) ∂t =µ 1 g(x) α γ α φ(x) α-1 e -( φ(x) γ ) α +µ 2 ∇ • (1 -1 |∇φ(x)| )∇φ(x) +δ (φ(x)) -λ V 1 (v 0 (x) -c V 1 ) 2 + λ V 2 (v 0 (x) -c V 2 ) 2 -λ I 1 (u 0 (x) -c I 1 ) 2 + λ I 2 (u 0 (x) -c I 2 ) 2 = 0, in Ω with ∂φ(x) ∂ n = 0 on ∂Ω.<label>(20</label></formula><p>) An approximation can be done by introducing an artificial time step t so as to derive the gradient descent method. Thus for fixed c V 1 , c V 2 , c I 1 and c I 2 , which will be updated at each step, we solve the above equation which can be written shortly:</p><formula xml:id="formula_34">       ∂φ(x) ∂t = µ 1 g(u 0 (x)) α γ α φ(x) α-1 e -( φ(x) γ ) α + µ 2 ∆φ(x) -∇ • ∇φ(x) |∇φ(x)| + δ (φ(x))f (x) = 0,<label>(21)</label></formula><p>with</p><formula xml:id="formula_35">f (x) = -λ V 1 (v 0 (x) -c V 1 ) 2 + λ V 2 (v 0 (x) -c V 2 ) 2 - λ I 1 (u 0 (x) -c I 1 ) 2 + λ I 2 (u 0 (x) -c I 2 ) 2 .</formula><p>After solving these equations, the level set φ ≤ 0 will define the object (vessels in this application).</p><p>In the following we will show the discretization of the new model equation in φ(x), using finite differences in an explicit scheme for a given initial level set φ(x, t = 0) = φ 0 (x). After c V 1 , c V 2 , c I 1 and c I 2 have been computed from Eq. 19 we fix them and then solve the partial differential equation (PDE) for φ(x). Once φ(x) is found, then update c V 1 , c V 2 , c I 1 and c I 2 and so on. To solve the above PDE in Eq. 20, we first recall the usual notations: let the size of a given image u 0 be m 1 ×m 2 , and let h 1 and h 2 be the space step in the x 1 and x 2 directions, let t be the time step and (x 1i , x 2j ) = (ih 1 , jh 2 ), for i = 1, . . . , m 1 and j = 1, . . . , m 2 be the grid points. Let φ k i,j = φ(k t, x 1i , x 2j ) be an approximation of φ(t, x 1 , x 2 ), where k ≥ 0 and φ 0 = φ 0 will be given (initial guess). The finite differences are denoted by</p><formula xml:id="formula_36">x1 -φ ij = φ ij -φ i-1,j , x1 + φ ij = φ i+1,j -φ ij , x2 -φ ij = φ ij -φ i,j-1 , x2 + φ ij = φ i,j+1 -φ ij . (<label>22</label></formula><formula xml:id="formula_37">)</formula><p>For a given</p><formula xml:id="formula_38">φ k (x), first compute c V 1 , c V 2 , c I</formula><p>1 and c I 2 and then discretize Eq. 20, compute φ k+1 by the following discretization and linearization of Eq. 20 in φ(x)</p><formula xml:id="formula_39">φ k+1 ij -φ k ij t = µ 1 g(u 0ij ) α γ α (φ k ij ) α-1 e -( (φ k ij ) γ ) α + µ 2 h 2 1 x1 - x1 + φ k ij + µ 2 h 2 2 x2 - x2 + φ k ij - µ 2 h 2 1 x1 - x1 + φ k ij ( x1 + φ k ij /h 1 ) 2 + ((φ k i,j+1 -φ k i,j-1 )/2h 2 ) 2 + µ 2 h 2 2 x2 - x2 + φ k ij ((φ k i+1,j -φ k i-1,j )/2h 1 ) 2 + ( y + φ k ij /h 2 ) 2 + δ (φ k ij )f k i,j .<label>(23)</label></formula><p>For h 1 = h 2 = h = 1, which has been used in this paper for our experiments, we have</p><formula xml:id="formula_40">φ k+1 ij = φ k ij + t µ 1 g(u 0ij ) α γ α (φ k ij ) α-1 e -( (φ k ij ) γ ) α + µ 2 φ k i+1,j + φ k i-1,j + φ k i,j+1 + φ k i,j-1 -4φ k i,j - φ k i+1,j -φ k i,j (φ k i+1j -φ k ij ) 2 + ((φ k i,j+1 -φ k i,j-1 )/2) 2 - φ k i,j -φ k i-1,j (φ k ij -φ k i-1j ) 2 + ((φ k i-1,j+1 -φ k i-1,j-1 )/2) 2 + (φ k ij+1 -φ k ij ) ((φ k i+1,j -φ k i-1,j )/2) 2 + (φ k ij+1 -φ k ij ) 2 - (φ k ij -φ k ij-1 ) ((φ k i+1,j-1 -φ k i-1,j-1 )/2) 2 + (φ k ij -φ k ij-1 ) 2 + δ (φ k ij )f k i,j .<label>(24)</label></formula><p>For a fast solution of Eq. 20 we can use iterative methods as well, but this is not the purpose of the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. DATASETS AND EVALUATION CRITERIA</head><p>We have employed three public retinal image datasets for the purpose of evaluation of our segmentation model. All of the images in these three datasets are centered at the macula, the center of the retina. In this section, we will first provide a brief introduction to these datasets, followed by an introduction to the evaluation metrics used in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>DRIVE<ref type="foot" target="#foot_1">1</ref> (Digital Retinal Images for Vessel Extraction) consists of a total of 40 color retinal images, obtained in the course of a diabetic retinopathy screening program in the Netherlands. The images were acquired using a Canon CR5 non-mydriatic 3-CCD camera (Canon, Tokyo, Japan) with a 45 degree field of view. Each image resolution is 768×584 pixels. The set of 40 images was divided into a test and a training set, each containing 20 images. STARE<ref type="foot" target="#foot_2">2</ref> (STructured Analysis of the Retina) contains 20 color retinal images, 10 of which show evidence of pathology. The digitized slides were captured by a TopCon TRV-50 fundus camera (Topcon, Tokyo, Japan), and the photos were digitized to 605×700 pixels. VAMPIRE comprises eight ultra-wide field of view retinal angiographic images acquired with an OPTOS P200C camera (Optos PLC, Dunfermline, UK). Four of the images are from an AMD retina, while the other four are from a healthy retina. Each image has a size of 3900×3072 pixels <ref type="bibr" target="#b37">[38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evaluation Metrics</head><p>Four commonly used metrics were employed to evaluate the performance of the competing methods in terms of pixels: sensitivity (Se) = tp/(tp + f n), specificity (Sp) = tn/(tn + f p), accuracy (Acc) = (tp + tn)/(tp + f p + tn + f n), and the area under a receiver operating characteristic curve, AUC = (Se + Sp)/2. tp, tn, fp and fn indicate the true positive (correctly identified vessel pixels), true negative (correctly identified background pixels), false positive (incorrectly identified vessel pixels), and false negative (incorrectly identified background pixels), respectively. Sensitivity is a measure of effectiveness in identifying pixels with positive values: specificity performs the same function for pixels with negative values. Accuracy and AU C indicate the overall classification performance. In essence, vessel segmentation can be viewed as an imbalanced data classification problem, in which there are typically much fewer vessel pixels than the background pixels. In such a case accuracy (Acc) will be skewed by the dominant classes, while AU C on the other hand has the ability to reflect the trade-offs between the sensitivity and specificity. In particular, the above definition of AU C proposed by Hong et al. <ref type="bibr" target="#b38">[39]</ref> is specifically for the case to evaluate the segmentation (or classification) performance when only one operating point is used. In contrast, conventionally AU C is estimated from a number of operating points. Take thresholding segmentation as an example, one can obtain many possible operating points when varying the threshold values. The conventional AU C is then estimated from these operating points. From our observation, this may not be particularly useful for comparing the performance of different models as in practice, to use a classifier, one normally has to choose an operating point (or a threshold). That is, when comparing different methods, the one with the larger AU C may not be the one with the better performance at the chosen threshold (or limited range). From the above observations, it appears that the definition AUC = (Se + Sp)/2 is more suited to comparing the performance of unsupervised segmentation methods.</p><p>A widely used overlap metric, the Dice coefficient (DC), is also introduced for comparing the agreement between the manual annotations (or ground truth) and result of segmentation method: DC = 2(A∩B)/(A + B), where A is the ground truth and B indicates the segmentation result. The DC ranges from 0 (no agreement) to 1 (perfect agreement). A DC value higher than 0.70 generally indicates excellent agreement <ref type="bibr" target="#b39">[40]</ref>.</p><p>Statistical analysis was performed to evaluate the effect of different factors, such as the dataset, enhancement filters and segmentation programs, on the segmentation performance. Analysis of variance (ANOVA) with Tukey post hoc analysis was performed using SPSS version 21.0 (SPSS Inc., Chicago, IL, USA). A p value of 0.05 is deemed statistically significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS AND RESULTS</head><p>In this section we present experiments to evaluate the performance of our proposed model. We first evaluate the effect of vessel enhancement on the performance of the proposed model across all three datasets, and then compare our model with several popular active contour methods in the literature. For the DRIVE dataset, the manual segmentations from set A are used as the ground truth. For the STARE dataset, the first observer's manual segmentations are used as the ground truth. For the VAMPIRE dataset, the manual annotations provided are used as the ground truth and the images were downsampled to a size of 1950×1536 pixels. All of the experiments were performed in Matlab version 2013a (Mathworks, Natick, CA) on a PC with 3.1GHz Intel Core system and 8GB RAM.</p><p>Our proposed segmentation model contains two essential components: Infinite perimeter regularization and hybrid region information. Their effect on the segmentation performance is evaluated under three different datasets.</p><p>First, the effect of three different vessel enhancement filters was evaluated. We used the IPACHI model and included the intensity term all the time, we compared inclusion of the local phase based filter (LP) with inclusion of the other two enhancement filters: Frangi's eigenvalue based filter (FR) <ref type="bibr" target="#b1">[2]</ref> and the wavelet filter (IUWT) <ref type="bibr" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Comparison with the Enhancement Methods</head><p>For reproduction purposes, all of the parameters used on the aforementioned filters are shown as follows. Eigenvaluebased (FR) scales: 1-8, scale ratio: 2; wavelet (IUWT) scales: 2 -3; local phase (LP) scales: 2 -3. Note, these values were recommended by the previous studies <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b9">[10]</ref>, respectively. These free parameters may be adjusted to produce better results according to the nature of the images, but it is unlikely to affect the ranking of the overall segmentation model when compared to other state-of-the-art models. Fig. <ref type="figure" target="#fig_2">2</ref> shows an example of the segmentation results using the IPACHI model when a randomly chosen image from the DRIVE dataset was enhanced by the FR, IUWT, and LP separately. It can be seen from Fig. <ref type="figure" target="#fig_2">2(B</ref>) that the FR tends to only enhance the larger vessels as does the IUWT (Fig. <ref type="figure" target="#fig_2">2(C)</ref>). The IUWT also enhances the non-vessel area (the background), which in turn increases the difficulty of segmentation. As for the LP enhancement results, seen in Fig. <ref type="figure" target="#fig_2">2(D)</ref>, the edges of the vessels at different scales are enhanced, which make them stand out more from the background. The segmentation results derived from the observer, FR, IUWT and LP enhancements are shown in Fig. <ref type="figure" target="#fig_2">2(E)-(H</ref>). As expected, more vessels are segmented when the LP enhancement filter is used. Moreover, the IPACHI method (Fig. <ref type="figure" target="#fig_2">2(H)</ref>) is sensitive in detecting the finer vessels. TABLE I further confirms this observation, the evaluation results of LP in terms of Se, Sp, Acc, AU C and DC reach the highest value in each of the three datasets. For example, the Se of the LP is 0.146 higher than that of the FR in the STARE dataset.</p><p>Statistical analysis results show that there is statistically significant difference in Acc, Se and Sp for three filters (LP, IUWT and FR) (p &lt; 0.001) in the DRIVE dataset. The Se of the LP for all datasets is statistically significantly higher than that of the other two filters. The mean ±standard deviation (STD) of the AUC value is 0.833 ± 0.045, 0.798 ± 0.054 and 0.819 ± 0.036 for the LP, FR and IUWT, respectively. The difference between these values is statistically significant (ANOVA, p &lt; 0.001). The AUC value of the LP is significantly higher than that of the other two filters (both p &lt; 0.001), while the IUWT outperforms the FR (p &lt; 0.001). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Comparison with the Other Active Models</head><p>In this section, the proposed IPACHI segmentation model is compared with four other active contour models: Chan-Vese (CV), Ribbon of Twins (ROT), distance regularized level set evolution (DRLSE) <ref type="bibr" target="#b29">[30]</ref> and infinite perimeter (IPAC) <ref type="bibr" target="#b33">[34]</ref>. The CV and IPAC segmentation models are implemented based on the original papers <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b33">[34]</ref>. The evaluation results of the ROT and DRLSE models from the respective original papers are used <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b29">[30]</ref>. For completeness, the evaluation results of a method described in <ref type="bibr" target="#b37">[38]</ref>, which is referred to as VP, is also included as the VP is the only segmentation method that has previously been tested on the VAMPIRE dataset. The evaluation results of these models on the DRIVE, STARE, and VAMPIRE datasets are demonstrated in  <ref type="figure">AU C</ref>, DC of the IPACHI model also have the highest score: 0.780, 0.978, 0.956, 0.874 and 0.801, respectively. For the VAMPIRE dataset, similar to the results on the other two datasets, the IPACHI model also yields the best results for Se, Sp, Acc, AU C, and DC. ANOVA tests on Acc, Se and Sp were performed to evaluate the difference between different segmentation models with respect to each of the three datasets. The ROT and DRLSE methods were not included in these tests as no results on individual images were provided. The VP method was included as the results on individual cases are available. Briefly, for the DRIVE and STARE datasets the ANOVA test was performed on CV, IPAC and IPACHI. For the VAMPIRE dataset, the ANOVA test was performed on VP, CV, IPAC and IPACHI. The statistical analysis results showed that: the Acc, Se and Sp of the IPACHI is significantly higher than the other two methods (CV and IPAC) for the DRIVE dataset (all p &lt; 0.0001) and for the STARE dataset (p &lt; 0.0001 for Acc, and Sp; p=0.008 for Se), and for the VAMPIRE dataset the Acc, Se, and Sp of the IPACHI are again significantly higher than those of the CV, VP, and IPAC models (all p &lt; 0.0001).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Comparison with the Other Methods</head><p>By means of the previous experiments we have demonstrated that the proposed model is both effective and efficient for vessel segmentation. To emphasize the effectiveness of our model, we compare our model with other existing state-ofthe-art vessel detection methods on two most popular public datasets: DRIVE and STARE. The VAMPIRE dataset is not used here as it is relatively new, and consequently there are relatively few results in the literature. TABLE <ref type="table" target="#tab_2">III</ref> shows the performance of our method and the others on both the DRIVE and STARE datasets in terms of sensitivity, specificity, accuracy, and AUC: the results have been ordered by the category the methods belonging to. The Dice coefficient value is not reported in this table as this is not provided by the other methods. We chose the most recent seven supervised methods <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b20">[21]</ref>- <ref type="bibr" target="#b22">[23]</ref>. We selected nine unsupervised segmentation methods <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b40">[41]</ref>- <ref type="bibr" target="#b42">[43]</ref>. The results on the DRIVE dataset show that the sensitivity of our model is the highest among the unsupervised methods with Se = 0.742, Sp = 0.982 and Acc = 0.954. Although one of the supervised methods <ref type="bibr" target="#b22">[23]</ref> has a higher sensitivity, it has a much lower specificity than most of the other methods. Similarly, on the STARE dataset, our model has the best performance in terms of sensitivity, specificity, and accuracy among the unsupervised methods, and Sp = 0.978, which is only 0.003 lower than the method proposed by <ref type="bibr" target="#b20">[21]</ref>. However, the Se score of our model is 0.086 higher than that of <ref type="bibr" target="#b20">[21]</ref>. In terms of AU C, our model is only behind the second human observer and the COSFIRE filter based method <ref type="bibr" target="#b10">[11]</ref>. However, it is not clear to us why the COSFIRE method <ref type="bibr" target="#b10">[11]</ref> has a higher AU C value than ours while its Se, Sp and Acc are all similar to ours on the DRIVE dataset, and all lower than ours on the STARE dataset. This may be due to the difference in how AU C is computed by the two studies, which suggests it may not be appropriate to directly compare the AU C values between different methods unless the information on how it is computed is provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. DISCUSSION AND CONCLUSIONS</head><p>In this paper, we have proposed a new infinite perimeter active contour model with hybrid region terms for the vessel segmentation problem. This model has been applied to three publicly available retinal datasets and the results demonstrate that it outperforms most of the existing methods in terms of segmentation accuracy.</p><p>Vessel segmentation still remains a challenging medical image analysis problem despite considerable effort in research. Many factors come together to make this problem difficult to be addressed. The images under consideration often come with noise and blur, and suffer from uneven illumination (or biased field in magnetic resonance imaging [MRI]) problems. In addition, although vessels in an image are similar to each other in general, they have different widths and orientations and sometimes different appearances in terms of intensity, color or local shape, which may become more complicated when disease is present. If a segmentation method cannot handle these factors effectively then its performance will be less satisfactory or at least will not be generalizable to wider applications. For example, enhancement based on intensity values may not be able to overcome the intensity variation in the image. In terms of the segmentation algorithm itself, it is expected that it will be robust and accurate in dealing with the aforementioned factors. Active contour models appear to be a natural choice as they can take into account the geometry information of the object as well as other useful information such as intensity. The success of the proposed approach benefits from several novel improvements. By introducing infinite perimeter regularization, the model is better suited to detecting vasculature structures than the conventional shortest length constraint. The new model also benefits from integration of different region forms, such as the local phase map and the </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(A) were randomly chosen from the DRIVE, STARE and VAMPIRE datasets (see Section IV for more details about these three datasets). Illustrative enhancement results are shown in Fig. 1(B)-(D).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Enhancement results produced by the eigenvalue-based method [2], wavelet-based method [6] and local phase method [10], respectively. Three images were randomly chosen from three datasets (one image per dataset). From top to bottom: DRIVE, STARE, and VAMPIRE. (B) Eigenvalue-based enhancement results. (C) Wavelet-based enhancement results. (D) Local phase based enhancement results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Illustrative enhancement results using different enhancement methods and their subsequent IPACHI-based segmentation results. (A) A randomly chosen image from the DRIVE dataset. (B)-(D) Enhancement results on (A) by using the eigenvalue-based (FR), wavelet-based (IUWT), and local phase-based (LP) filters respectively. (E) Expert's annotation. (F)-(H) IPACHI-based segmentation results on (B)-(D).</figDesc><graphic coords="8,50.88,53.14,510.22,255.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="5,65.05,53.14,481.90,340.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I :</head><label>I</label><figDesc>Segmentation performance of using three different enhancement methods (LP, WL, FR) with the proposed segmentation model on the DRIVE, STARE, and VAMPIRE datasets. LP: local phased based filter; WL: wavelet-based (IUWT) filter; FR: Frangi's eigenvalue-based filter; Se: sensitivity; Sp: specificity; Acc: accuracy; AU C: area under curve; DC: Dice coefficient.</figDesc><table><row><cell>Dataset</cell><cell>Enhanc.</cell><cell>Se</cell><cell>Sp</cell><cell>Acc</cell><cell>AUC</cell><cell>DC</cell></row><row><cell></cell><cell>FR</cell><cell cols="5">0.686 0.867 0.853 0.776 0.691</cell></row><row><cell>DRIVE</cell><cell>WL</cell><cell cols="5">0.716 0.978 0.946 0.848 0.729</cell></row><row><cell></cell><cell>LP</cell><cell cols="5">0.742 0.982 0.954 0.862 0.782</cell></row><row><cell></cell><cell>FR</cell><cell cols="5">0.634 0.967 0.938 0.801 0.651</cell></row><row><cell>STARE</cell><cell>WL</cell><cell cols="5">0.776 0.954 0.943 0.865 0.791</cell></row><row><cell></cell><cell>LP</cell><cell cols="5">0.780 0.978 0.956 0.874 0.801</cell></row><row><cell></cell><cell>FR</cell><cell cols="5">0.681 0.970 0.961 0.825 0.694</cell></row><row><cell cols="2">VAMPIRE WL</cell><cell cols="5">0.699 0.975 0.966 0.837 0.711</cell></row><row><cell></cell><cell>LP</cell><cell cols="5">0.729 0.985 0.977 0.857 0.737</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II .</head><label>II</label><figDesc>Note, for the ROT, DRLSE, and VP methods, only the results provided from the original paper are included in TABLE II (i.e., ROT on the DRIVE and STARE datasets, DRLSE on the DRIVE, and VP on the VAMPIRE). It can be observed from TABLE II that the results of IPACHI in terms of Se, Sp, and AUC outperform the competitors in the DRIVE and STARE datasets. In particular, the Se, Sp, Acc, AU C, and DC of the IPACHI model have the highest scores in the DRIVE dataset, which are 0.742, 0.982, 0.954, 0.862, and 0.782, respectively. For the STARE dataset, the Se, Sp, Acc,</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II :</head><label>II</label><figDesc>Performance of different segmentation models on the DRIVE, STARE, and VAMPIRE datasets. Se: sensitivity; Sp: specificity; Acc: accuracy; AU C: area under curve; DC: Dice coefficient.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>DRIVE</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>STARE</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>VAMPIRE</cell><cell></cell></row><row><cell></cell><cell>Se</cell><cell>Sp</cell><cell>Acc</cell><cell>AUC</cell><cell>DC</cell><cell>Se</cell><cell>Sp</cell><cell>Acc</cell><cell>AUC</cell><cell>DC</cell><cell>Se</cell><cell>Sp</cell><cell>Acc</cell><cell>AUC</cell><cell>DC</cell></row><row><cell>CV</cell><cell cols="5">0.679 0.924 0.939 0.802 0.702</cell><cell cols="5">0.775 0.950 0.937 0.863 0.795</cell><cell cols="5">0.715 0.984 0.976 0.850 0.732</cell></row><row><cell>ROT</cell><cell cols="2">0.728 0.955</cell><cell>-</cell><cell>0.842</cell><cell>-</cell><cell cols="2">0.752 0.968</cell><cell>-</cell><cell>0.860</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>DRLSE</cell><cell cols="4">0.718 0.974 0.941 0.846</cell><cell>-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TMI.2015.2409024, IEEE Transactions on Medical Imaging</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>http://www.isi.uu.nl/Research/Datasets/DRIVE/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>http://www.ces.clemson.edu/ ∼ ahoover/stare/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>----------VP ---------</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>intensity of the image. The phase map provides a more reliable and accurate vesselness map while the intensity information helps to exclude some potential outliers in the image. The evaluation results on the three widely used retinal datasets have demonstrated the superiority of our model.</p><p>To the best of the authors' knowledge, this is the first work in which a segmentation model has been evaluated on both color fundus and fluorescein angiography images. Color fundus imaging is the only established imaging technique that has been used in the screening of diabetes and is also widely used by opticians and in hospitals. Fluorescein angiography is primarily used in the differential diagnosis of retinal disease and treatment planning. Our model has shown good performance for both imaging modalities. Incorporation of our proposed method of extracting and analyzing vasculature promises a wide range of applications. For example, the model will be applicable to the management of other eye conditions such as corneal neovascularization <ref type="bibr" target="#b43">[44]</ref>.</p><p>The detection of vessels is essentially the first and an important step for automated vessel analysis tools. After vessel segmentation, it is possible to perform more advanced analysis, such as measurements of diameters and tortuosity of the vessels, classification of veins and arteries, calculation of the arteriovenous ratio, and more importantly the study of the diagnostic and prognostic values of these features on eye disease and systematic diseases (e.g. stroke, hypertension etc).</p><p>Although in this paper we have only evaluated our new model on retinal images, the model is well suited to address segmentation problems in images of other organs acquired using different imaging techniques such as CT, MRI and X-ray images. Three-dimensional (3D) images are becoming widely used in healthcare settings. It would be straightforward to extend our model to 3D. Local phase can be defined in 3D space by means of monogenic signal. In particular, here we used the optimized lognormal filters to derive the local phase: certain other filters, such as the Cauchy filter <ref type="bibr" target="#b34">[35]</ref>, may equally be used. We expect that the possible gain would be small. In addition, filter optimization should be considered to achieve good performance in both the frequency and spatial domains. The program uses standard Matlab tools is not optimized for speed. It is our plan to optimize the code for efficiency and then share the refined source code with the research community in vessel analysis. We are hoping that by doing this more researchers can apply our models to their own applications.</p><p>In conclusion, we have proposed an efficient and effective infinite perimeter active contour model with hybrid region terms for vessel segmentation with good performance. This will be a powerful tool for analyzing vasculature for better management of a wide spectrum of vascular-related diseases.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Detection and measurement of retinal vessels in fundus images using amplitude modified second-order Gaussian filter</title>
		<author>
			<persName><forename type="first">G</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Opas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shankar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="168" to="172" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multiscale vessel enhancement filtering</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Niessen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Vincken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Comput. Comput. Assist. Interv</title>
		<imprint>
			<biblScope unit="volume">1496</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Retinal vessel extraction by matched filter with first-order derivative of Gaussian</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Karray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Biol. Med</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="438" to="445" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Improved detection of the central reflex in retinal vessels using a generalized dual-Gaussian model and robust hypothesis testing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Narasimha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mahadevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Beach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Roysam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Technol. Biomed</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="406" to="410" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Parallel multiscale feature extraction and region growing: application in retinal blood vessel detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Palomera-Prez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martinez-Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bentez-Prez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ortega-Arjona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Technol. Biomed</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="500" to="506" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fast retinal vessel detection and measurement using wavelets and edge location refinement</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bankhead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcgeown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Curtis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>p. e32435</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Retinal vessel segmentation using multiwavelet kernels and multiscale hierarchical decomposition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Trucco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="2117" to="2133" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Retinal vessel segmentation using the 2D Gabor wavelet and supervised classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cree</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1214" to="1222" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A morphological approach for vessel segmentation in eye fundus images, with quantitative evaluation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Rossant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Badellino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chavillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Paques</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Med. Imaging. Health. Inf</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="42" to="49" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Blood vessel segmentation using multi-scale quadrature filtering</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lathen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jonasson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Borga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn. Lett</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="762" to="767" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Trainable COS-FIRE filters for vessel delineation with application to retinal images</title>
		<author>
			<persName><forename type="first">G</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Strisciuglio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vento</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Petkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="46" to="57" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Blood vessel segmentation methodologies in retinal images -a survey</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Fraz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Remagnino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Uyyanonvara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Rudnicka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Owen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Barman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Meth. Prog. Bio</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="407" to="433" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A review of vessel extraction techniques and algorithms</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kirbas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Quek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="81" to="121" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A review of 3D vessel lumen segmentation techniques: Models, features and extraction schemes</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lesagea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Funka-Leaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="819" to="845" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An active contour model for segmenting and measuring retinal vessels</title>
		<author>
			<persName><forename type="first">B</forename><surname>Al-Diri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Steel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1488" to="1497" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Local morphology fitting active contour for automatic vascular segmentation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="464" to="473" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Ridge-based vessel segmentation in color images of the retina</title>
		<author>
			<persName><forename type="first">J</forename><surname>Staal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abramoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niemeijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Viergever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="501" to="509" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Segmentation of retinal blood vessels using the radial projection and semi-supervised approach</title>
		<author>
			<persName><forename type="first">X</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="2314" to="2324" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Retinal blood vessel segmentation using line operators and support vector classification</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Perfetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1357" to="1365" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automated localisation of the optic disc, fovea, and retinal blood vessels from digital colour fundus images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sinthanayothin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boyce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brit. J. Ophthal</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="902" to="910" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A new supervised method for blood vessel segmentation in retinal images by using gray-level and moment invariants-based features</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aquino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gegundez-Arias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bravo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="146" to="158" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">FABC: Retinal vessel segmentation using AdaBoost</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lupascu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tegolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Trucco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Technol. Biomed</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1267" to="1274" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning fully-connected CRFs for blood vessel segmentation in retinal images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Orlando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blaschko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Comput. Comput. Assist. Interv</title>
		<imprint>
			<biblScope unit="page" from="634" to="641" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Detection of blood vessels in retinal images using two-dimensional matched filters</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goldbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="203" to="210" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatic grading of retinal vessel caliber</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="1352" to="1355" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The detection and quantication of retinopathy using digital angiograms</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rzeszotarsk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Singerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chokref</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="619" to="626" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multiscale vessel tracking</title>
		<author>
			<persName><forename type="first">O</forename><surname>Wink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Niessen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="130" to="133" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Retinal vessel segmentation using a probabilistic tracking method</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Adel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bourennane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="1235" to="1244" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Vessel extraction under non-uniform illumination: A level set approach</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Sum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Y S</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="358" to="360" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Level sets for retinal vasculature segmentation using seeds from ridges and edges from phase maps</title>
		<author>
			<persName><forename type="first">B</forename><surname>Dizdaroglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ataer-Cansizoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Keck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erdogmus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Workshop</title>
		<meeting>IEEE Int. Workshop</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Active contours without edges</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="266" to="277" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Minimization of regionscalable fitting energy for image segmentation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1940" to="1949" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Distance regularized level set evolution and its application to image segmentation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="3243" to="3254" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A variational model for infinite perimeter segmentations based on Lipschitz level set functions: Denoising while keeping finely oscillatory boundaries</title>
		<author>
			<persName><forename type="first">M</forename><surname>Barchiesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Morini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ponsiglione</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multiscale Model. Sim</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1715" to="1741" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On the choice of band-pass quadrature filters</title>
		<author>
			<persName><forename type="first">D</forename><surname>Boukerroui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Noble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Imaging Vis</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="53" to="80" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The monogenic signal</title>
		<author>
			<persName><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="3136" to="3144" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Image segmentation using fuzzy region competition and spatial/frequency information</title>
		<author>
			<persName><forename type="first">S</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1473" to="1484" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Improving vessel segmentation in ultra-wide field-of-view retinal fluorescein angiograms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Perez-Rovira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zutis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hubschman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Trucco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2614" to="2617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A kernel-based two-class classifier for imbalanced data sets</title>
		<author>
			<persName><forename type="first">X</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="28" to="41" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Morphometric analysis of white matter lesions in MR images: method and validation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Zijdenbos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Dawant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Margolin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="716" to="724" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Segmentation of retinal blood vessels by combining the detection of centerlines and morphological reconstruction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mendonc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Campilho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1200" to="1213" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Segmentation of blood vessels from red-free and fluorescein retinal images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Martinez-Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bharath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Parker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="47" to="61" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">An effective retinal blood vessel segmentation method using multi-scale line detection</title>
		<author>
			<persName><forename type="first">U</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhuiyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Laurence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamohanarao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page">703715</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Imaging and evaluation of corneal vascularization using fluorescein and indocyanine green angiography</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Anijeet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hodson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sueke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Kaye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Invest. Ophthalmol. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="650" to="658" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
