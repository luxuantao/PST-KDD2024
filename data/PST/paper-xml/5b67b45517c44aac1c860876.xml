<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Graph Convolutional Neural Networks for Web-Scale Recommender Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
							<email>rexying@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kaifeng</forename><surname>Chen</surname></persName>
							<email>kaifengchen@pinterest.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pong</forename><surname>Eksombatchai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><surname>Pinterest</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">†</forename><forename type="middle">2018</forename><surname>Graph</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Convolutional</forename><forename type="middle">Neural</forename><surname>Networks</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Graph Convolutional Neural Networks for Web-Scale Recommender Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3219819.3219890</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. However, making these methods practical and scalable to web-scale recommendation tasks with billions of items and hundreds of millions of users remains a challenge.</p><p>Here we describe a large-scale deep recommendation engine that we developed and deployed at Pinterest. We develop a dataefficient Graph Convolutional Network (GCN) algorithm PinSage, which combines efficient random walks and graph convolutions to generate embeddings of nodes (i.e., items) that incorporate both graph structure as well as node feature information. Compared to prior GCN approaches, we develop a novel method based on highly efficient random walks to structure the convolutions and design a novel training strategy that relies on harder-and-harder training examples to improve robustness and convergence of the model.</p><p>We deploy PinSage at Pinterest and train it on 7.5 billion examples on a graph with 3 billion nodes representing pins and boards, and 18 billion edges. According to offline metrics, user studies and A/B tests, PinSage generates higher-quality recommendations than comparable deep learning and graph-based alternatives. To our knowledge, this is the largest application of deep graph embeddings to date and paves the way for a new generation of web-scale recommender systems based on graph convolutional architectures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b11">12]</ref><p>. The representations learned using deep models can be used to complement, or even replace, traditional recommendation algorithms like collaborative filtering. and these learned representations have high utility because they can be re-used in various recommendation tasks. For example, item embeddings learned using a deep model can be used for item-item recommendation and also to recommended themed collections (e.g., playlists, or "feed" content).</p><p>Recent years have seen significant developments in this spaceespecially the development of new deep learning methods that are capable of learning on graph-structured data, which is fundamental for recommendation applications (e.g., to exploit user-to-item interaction graphs as well as social graphs) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>Most prominent among these recent advancements is the success of deep learning architectures known as Graph Convolutional Networks (GCNs) <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b28">29]</ref>. The core idea behind GCNs is to learn how to iteratively aggregate feature information from local graph neighborhoods using neural networks (Figure <ref type="figure">1</ref>). Here a single "convolution" operation transforms and aggregates feature information from a node's one-hop graph neighborhood, and by stacking multiple such convolutions information can be propagated across far reaches of a graph. Unlike purely content-based deep models (e.g., recurrent neural networks <ref type="bibr" target="#b2">[3]</ref>), GCNs leverage both content information as well as graph structure. GCN-based methods have set a new standard on countless recommender system benchmarks (see <ref type="bibr" target="#b18">[19]</ref> for a survey). However, these gains on benchmark tasks have yet to be translated to gains in real-world production environments.</p><p>The main challenge is to scale both the training as well as inference of GCN-based node embeddings to graphs with billions of nodes and tens of billions of edges. Scaling up GCNs is difficult because many of the core assumptions underlying their design are violated when working in a big data environment. For example, all existing GCN-based recommender systems require operating on the full graph Laplacian during training-an assumption that is infeasible when the underlying graph has billions of nodes and whose structure is constantly evolving.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Present work.</head><p>Here we present a highly-scalable GCN framework that we have developed and deployed in production at Pinterest. Our framework, a random-walk-based GCN named PinSage, operates on a massive graph with 3 billion nodes and 18 billion edges-a graph that is 10, 000× larger than typical applications of GCNs. PinSage leverages several key insights to drastically improve the scalability of GCNs: convolve (2)   convolve (1)   Figure <ref type="figure">1</ref>: Overview of our model architecture using depth-2 convolutions (best viewed in color). Left: A small example input graph. Right: The 2-layer neural network that computes the embedding h</p><p>(2)</p><p>A of node A using the previous-layer representation, h</p><p>A , of node A and that of its neighborhood N (A) (nodes B, C, D). (However, the notion of neighborhood is general and not all neighbors need to be included (Section 3.2).) Bottom: The neural networks that compute embeddings of each node of the input graph. While neural networks differ from node to node they all share the same set of parameters (i.e., the parameters of the convolve (1) and convolve (2) functions; Algorithm 1). Boxes with the same shading patterns share parameters; γ denotes an importance pooling function; and thin rectangular boxes denote densely-connected multi-layer neural networks.</p><p>• On-the-fly convolutions: Traditional GCN algorithms perform graph convolutions by multiplying feature matrices by powers of the full graph Laplacian. In contrast, our PinSage algorithm performs efficient, localized convolutions by sampling the neighborhood around a node and dynamically constructing a computation graph from this sampled neighborhood. These dynamically constructed computation graphs (Fig. <ref type="figure">1</ref>) specify how to perform a localized convolution around a particular node, and alleviate the need to operate on the entire graph during training. • Producer-consumer minibatch construction: We develop a producer-consumer architecture for constructing minibatches that ensures maximal GPU utilization during model training. A large-memory, CPU-bound producer efficiently samples node network neighborhoods and fetches the necessary features to define local convolutions, while a GPU-bound TensorFlow model consumes these pre-defined computation graphs to efficiently run stochastic gradient decent. • Efficient MapReduce inference: Given a fully-trained GCN model, we design an efficient MapReduce pipeline that can distribute the trained model to generate embeddings for billions of nodes, while minimizing repeated computations.</p><p>In addition to these fundamental advancements in scalability, we also introduce new training techniques and algorithmic innovations. These innovations improve the quality of the representations learned by PinSage, leading significant performance gains in downstream recommender system tasks:</p><p>• Constructing convolutions via random walks: Taking full neighborhoods of nodes to perform convolutions (Fig. <ref type="figure">1</ref>) would result in huge computation graphs, so we resort to sampling. However, random sampling is suboptimal, and we develop a new technique using short random walks to sample the computation graph. An additional benefit is that each node now has an importance score, which we use in the pooling/aggregation step. • Importance pooling: A core component of graph convolutions is the aggregation of feature information from local neighborhoods in the graph. We introduce a method to weigh the importance of node features in this aggregation based upon randomwalk similarity measures, leading to a 46% performance gain in offline evaluation metrics. We have deployed PinSage for a variety of recommendation tasks at Pinterest, a popular content discovery and curation application where users interact with pins, which are visual bookmarks to online content (e.g., recipes they want to cook, or clothes they want to purchase). Users organize these pins into boards, which contain collections of similar pins. Altogether, Pinterest is the world's largest user-curated graph of images, with over 2 billion unique pins collected into over 1 billion boards.</p><p>Through extensive offline metrics, controlled user studies, and A/B tests, we show that our approach achieves state-of-the-art performance compared to other scalable deep content-based recommendation algorithms, in both an item-item recommendation task (i.e., related-pin recommendation), as well as a "homefeed" recommendation task. In offline ranking metrics we improve over the best performing baseline by more than 40%, in head-to-head human evaluations our recommendations are preferred about 60% of the time, and the A/B tests show 30% to 100% improvements in user engagement across various settings.</p><p>To our knowledge, this is the largest-ever application of deep graph embeddings and paves the way for new generation of recommendation systems based on graph convolutional architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Our work builds upon a number of recent advancements in deep learning methods for graph-structured data.</p><p>The notion of neural networks for graph data was first outlined in <ref type="bibr" target="#b14">Gori et al. (2005)</ref>  <ref type="bibr" target="#b14">[15]</ref> and further elaborated on in <ref type="bibr" target="#b26">Scarselli et al. (2009)</ref>  <ref type="bibr" target="#b26">[27]</ref>. However, these initial approaches to deep learning on graphs required running expensive neural "message-passing" algorithms to convergence and were prohibitively expensive on large graphs. Some limitations were addressed by Gated Graph Sequence Neural Networks <ref type="bibr" target="#b21">[22]</ref>-which employs modern recurrent neural architectures-but the approach remains computationally expensive and has mainly been used on graphs with &lt;10, 000 nodes.</p><p>More recently, there has been a surge of methods that rely on the notion of "graph convolutions" or Graph Convolutional Networks (GCNs). This approach originated with the work of <ref type="bibr">Bruna et al. (2013)</ref>, which developed a version of graph convolutions based on spectral graph thery <ref type="bibr" target="#b6">[7]</ref>. Following on this work, a number of authors proposed improvements, extensions, and approximations of these spectral convolutions <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b30">31]</ref>, leading to new state-of-the-art results on benchmarks such as node classification, link prediction, as well as recommender system tasks (e.g., the MovieLens benchmark <ref type="bibr" target="#b23">[24]</ref>). These approaches have consistently outperformed techniques based upon matrix factorization or random walks (e.g., node2vec <ref type="bibr" target="#b16">[17]</ref> and DeepWalk <ref type="bibr" target="#b25">[26]</ref>), and their success has led to a surge of interest in applying GCN-based methods to applications ranging from recommender systems <ref type="bibr" target="#b23">[24]</ref> to drug design <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b30">31]</ref>. <ref type="bibr">Hamilton et al. (2017b)</ref>  <ref type="bibr" target="#b18">[19]</ref> and <ref type="bibr" target="#b5">Bronstein et al. (2017)</ref>  <ref type="bibr" target="#b5">[6]</ref> provide comprehensive surveys of recent advancements.</p><p>However, despite the successes of GCN algorithms, no previous works have managed to apply them to production-scale data with billions of nodes and edges-a limitation that is primarily due to the fact that traditional GCN methods require operating on the entire graph Laplacian during training. Here we fill this gap and show that GCNs can be scaled to operate in a production-scale recommender system setting involving billions of nodes/items. Our work also demonstrates the substantial impact that GCNs have on recommendation performance in a real-world environment.</p><p>In terms of algorithm design, our work is most closely related to Hamilton et al. (2017a)'s GraphSAGE algorithm <ref type="bibr" target="#b17">[18]</ref> and the closely related follow-up work of <ref type="bibr" target="#b7">Chen et al. (2018)</ref>  <ref type="bibr" target="#b7">[8]</ref>. GraphSAGE is an inductive variant of GCNs that we modify to avoid operating on the entire graph Laplacian. We fundamentally improve upon GraphSAGE by removing the limitation that the whole graph be stored in GPU memory, using low-latency random walks to sample graph neighborhoods in a producer-consumer architecture. We also introduce a number of new training techniques to improve performance and a MapReduce inference pipeline to scale up to graphs with billions of nodes.</p><p>Lastly, also note that graph embedding methods like node2vec <ref type="bibr" target="#b16">[17]</ref> and DeepWalk <ref type="bibr" target="#b25">[26]</ref> cannot be applied here. First, these are unsupervised methods. Second, they cannot include node feature information. Third, they directly learn embeddings of nodes and thus the number of model parameters is linear with the size of the graph, which is prohibitive for our setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHOD</head><p>In this section, we describe the technical details of the PinSage architecture and training, as well as a MapReduce pipeline to efficiently generate embeddings using a trained PinSage model.</p><p>The key computational workhorse of our approach is the notion of localized graph convolutions. <ref type="foot" target="#foot_0">1</ref> To generate the embedding for a node (i.e., an item), we apply multiple convolutional modules that aggregate feature information (e.g., visual, textual features) from the node's local graph neighborhood (Figure <ref type="figure">1</ref>). Each module learns how to aggregate information from a small graph neighborhood, and by stacking multiple such modules, our approach can gain information about the local network topology. Importantly, parameters of these localized convolutional modules are shared across all nodes, making the parameter complexity of our approach independent of the input graph size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Setup</head><p>Pinterest is a content discovery application where users interact with pins, which are visual bookmarks to online content (e.g., recipes they want to cook, or clothes they want to purchase). Users organize these pins into boards, which contain collections of pins that the user deems to be thematically related. Altogether, the Pinterest graph contains 2 billion pins, 1 billion boards, and over 18 billion edges (i.e., memberships of pins to their corresponding boards).</p><p>Our task is to generate high-quality embeddings or representations of pins that can be used for recommendation (e.g., via nearestneighbor lookup for related pin recommendation, or for use in a downstream re-ranking system). In order to learn these embeddings, we model the Pinterest environment as a bipartite graph consisting of nodes in two disjoint sets, I (containing pins) and C (containing boards). Note, however, that our approach is also naturally generalizable, with I being viewed as a set of items and C as a set of user-defined contexts or collections.</p><p>In addition to the graph structure, we also assume that the pins/items u ∈ I are associated with real-valued attributes, x u ∈ R d . In general, these attributes may specify metadata or content information about an item, and in the case of Pinterest, we have that pins are associated with both rich text and image features. Our goal is to leverage both these input attributes as well as the structure of the bipartite graph to generate high-quality embeddings. These embeddings are then used for recommender system candidate generation via nearest neighbor lookup (i.e., given a pin, find related pins) or as features in machine learning systems for ranking the candidates.</p><p>For notational convenience and generality, when we describe the PinSage algorithm, we simply refer to the node set of the full graph with V = I ∪ C and do not explicitly distinguish between pin and board nodes (unless strictly necessary), using the more general term "node" whenever possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model Architecture</head><p>We use localized convolutional modules to generate embeddings for nodes. We start with input node features and then learn neural networks that transform and aggregate features over the graph to compute the node embeddings (Figure <ref type="figure">1</ref>). Forward propagation algorithm. We consider the task of generating an embedding, z u for a node u, which depends on the node's input features and the graph structure around this node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: convolve</head><p>Input : Current embedding z u for node u; set of neighbor embeddings {z v |v ∈ N (u)}, set of neighbor weights α ; symmetric vector function γ (•)</p><formula xml:id="formula_1">Output : New embedding z new u for node u 1 n u ← γ ({ReLU (Qh v + q) | v ∈ N (u)} , α ); 2 z new u ← ReLU (W • concat(z u , n u ) + w); 3 z new u ← z new u /∥z new u ∥ 2</formula><p>The core of our PinSage algorithm is a localized convolution operation, where we learn how to aggregate information from u's neighborhood (Figure <ref type="figure">1</ref>). This procedure is detailed in Algorithm 1 convolve. The basic idea is that we transform the representations z v , ∀v ∈ N (u) of u's neighbors through a dense neural network and then apply a aggregator/pooling fuction (e.g., a element-wise mean or weighted sum, denoted as γ ) on the resulting set of vectors (Line 1). This aggregation step provides a vector representation, n u , of u's local neighborhood, N (u). We then concatenate the aggregated neighborhood vector n u with u's current representation h u and transform the concatenated vector through another dense neural network layer (Line 2). Empirically we observe significant performance gains when using concatenation operation instead of the average operation as in <ref type="bibr" target="#b20">[21]</ref>. Additionally, the normalization in Line 3 makes training more stable, and it is more efficient to perform approximate nearest neighbor search for normalized embeddings (Section 3.5). The output of the algorithm is a representation of u that incorporates both information about itself and its local graph neighborhood. Importance-based neighborhoods. An important innovation in our approach is how we define node neighborhoods N (u), i.e., how we select the set of neighbors to convolve over in Algorithm 1. Whereas previous GCN approaches simply examine k-hop graph neighborhoods, in PinSage we define importance-based neighborhoods, where the neighborhood of a node u is defined as the T nodes that exert the most influence on node u. Concretely, we simulate random walks starting from node u and compute the L 1 -normalized visit count of nodes visited by the random walk <ref type="bibr" target="#b13">[14]</ref>. <ref type="foot" target="#foot_2">2</ref> The neighborhood of u is then defined as the top T nodes with the highest normalized visit counts with respect to node u.</p><p>The advantages of this importance-based neighborhood definition are two-fold. First, selecting a fixed number of nodes to aggregate from allows us to control the memory footprint of the algorithm during training <ref type="bibr" target="#b17">[18]</ref>. Second, it allows Algorithm 1 to take into account the importance of neighbors when aggregating the vector representations of neighbors. In particular, we implement γ in Algorithm 1 as a weighted-mean, with weights defined according to the L 1 normalized visit counts. We refer to this new approach as importance pooling. Stacking convolutions. Each time we apply the convolve operation (Algorithm 1) we get a new representation for a node, and we can stack multiple such convolutions on top of each other in order to gain more information about the local graph structure around node u. In particular, we use multiple layers of convolutions, where the inputs to the convolutions at layer k depend on the representations output from layer k − 1 (Figure <ref type="figure">1</ref>) and where the initial (i.e., "layer 0") representations are equal to the input node features. Note that the model parameters in Algorithm 1 (Q, q, W, and w) are shared across the nodes but differ between layers.</p><p>Algorithm 2 details how stacked convolutions generate embeddings for a minibatch set of nodes, M. We first compute the neighborhoods of each node and then apply K convolutional iterations to generate the layer-K representations of the target nodes. The output of the final convolutional layer is then fed through a fullyconnected neural network to generate the final output embeddings z u , ∀u ∈ M.</p><p>The full set of parameters of our model which we then learn is: the weight and bias parameters for each convolutional layer (Q (k ) , q (k ) , W (k ) , w (k ) , ∀k ∈ {1, ..., K }) as well as the parameters of the final dense neural network layer, G 1 , G 2 , and g. The output dimension of Line 1 in Algorithm 1 (i.e., the column-space dimension of Q) is set to be m at all layers. For simplicity, we set the output dimension of all convolutional layers (i.e., the output at Line 3 of Algorithm 1) to be equal, and we denote this size parameter by d. The final output dimension of the model (after applying line 18 of Algorithm 2) is also set to be d.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Model Training</head><p>We train PinSage in a supervised fashion using a max-margin ranking loss. In this setup, we assume that we have access to a set of labeled pairs of items L, where the pairs in the set, (q, i) ∈ L, are assumed to be related-i.e., we assume that if (q, i) ∈ L then item i is a good recommendation candidate for query item q. The goal of the training phase is to optimize the PinSage parameters so that the output embeddings of pairs (q, i) ∈ L in the labeled set are close together.</p><p>We first describe our margin-based loss function in detail. Following this, we give an overview of several techniques we developed that lead to the computation efficiency and fast convergence rate of PinSage, allowing us to train on billion node graphs and billions training examples. And finally, we describe our curriculum-training </p><formula xml:id="formula_2">u ← x u , ∀u ∈ S (0) ; 9 for k = 1, ..., K do 10 for u ∈ S (k ) do 11 H ← h (k −1) v , ∀v ∈ N (u) ; 12 h (k ) u ← convolve (k ) h (k −1) u , H 13 end 14 end 15 for u ∈ M do 16 z u ← G 2 • ReLU G 1 h (K ) u + g 17 end</formula><p>scheme, which improves the overall quality of the recommendations. Loss function. In order to train the parameters of the model, we use a max-margin-based loss function. The basic idea is that we want to maximize the inner product of positive examples, i.e., the embedding of the query item and the corresponding related item. At the same time we want to ensure that the inner product of negative examples-i.e., the inner product between the embedding of the query item and an unrelated item-is smaller than that of the positive sample by some pre-defined margin. The loss function for a single pair of node embeddings (z q , z i ) : (q, i) ∈ L is thus</p><formula xml:id="formula_3">J G (z q z i ) = E n k ∼P n (q) max{0, z q • z n k − z q • z i + ∆},<label>(1)</label></formula><p>where P n (q) denotes the distribution of negative examples for item q, and ∆ denotes the margin hyper-parameter. We shall explain the sampling of negative samples below.</p><p>Multi-GPU training with large minibatches. To make full use of multiple GPUs on a single machine for training, we run the forward and backward propagation in a multi-tower fashion. With multiple GPUs, we first divide each minibatch (Figure <ref type="figure">1</ref> bottom) into equal-sized portions. Each GPU takes one portion of the minibatch and performs the computations using the same set of parameters. After backward propagation, the gradients for each parameter across all GPUs are aggregated together, and a single step of synchronous SGD is performed. Due to the need to train on extremely large number of examples (on the scale of billions), we run our system with large batch sizes, ranging from 512 to 4096.</p><p>We use techniques similar to those proposed by Goyal et al. <ref type="bibr" target="#b15">[16]</ref> to ensure fast convergence and maintain training and generalization accuracy when dealing with large batch sizes. We use a gradual warmup procedure that increases learning rate from small to a peak value in the first epoch according to the linear scaling rule. Afterwards the learning rate is decreased exponentially. Producer-consumer minibatch construction. During training, the adjacency list and the feature matrix for billions of nodes are placed in CPU memory due to their large size. However, during the convolve step of PinSage, each GPU process needs access to the neighborhood and feature information of nodes in the neighborhood. Accessing the data in CPU memory from GPU is not efficient. To solve this problem, we use a re-indexing technique to create a sub-graph G ′ = (V ′ , E ′ ) containing nodes and their neighborhood, which will be involved in the computation of the current minibatch. A small feature matrix containing only node features relevant to computation of the current minibatch is also extracted such that the order is consistent with the index of nodes in G ′ . The adjacency list of G ′ and the small feature matrix are fed into GPUs at the start of each minibatch iteration, so that no communication between the GPU and CPU is needed during the convolve step, greatly improving GPU utilization.</p><p>The training procedure has alternating usage of CPUs and GPUs. The model computations are in GPUs, whereas extracting features, re-indexing, and negative sampling are computed on CPUs. In addition to parallelizing GPU computation with multi-tower training, and CPU computation using OpenMP <ref type="bibr" target="#b24">[25]</ref>, we design a producerconsumer pattern to run GPU computation at the current iteration and CPU computation at the next iteration in parallel. This further reduces the training time by almost a half. Sampling negative items. Negative sampling is used in our loss function (Equation <ref type="formula" target="#formula_0">1</ref>) as an approximation of the normalization factor of edge likelihood <ref type="bibr" target="#b22">[23]</ref>. To improve efficiency when training with large batch sizes, we sample a set of 500 negative items to be shared by all training examples in each minibatch. This drastically saves the number of embeddings that need to be computed during each training step, compared to running negative sampling for each node independently. Empirically, we do not observe a difference between the performance of the two sampling schemes.</p><p>In the simplest case, we could just uniformly sample negative examples from the entire set of items. However, ensuring that the inner product of the positive example (pair of items (q, i)) is larger than that of the q and each of the 500 negative items is too "easy" and does not provide fine enough "resolution" for the system to learn. In particular, our recommendation algorithm should be capable of finding 1,000 most relevant items to q among the catalog of over 2 billion items. In other words, our model should be able to distinguish/identify 1 item out of 2 million items. But with 500 random negative items, the model's resolution is only 1 out of 500. Thus, if we sample 500 random negative items out of 2 billion items, the chance of any of these items being even slightly related to the query item is small. Therefore, with large probability the learning will not make good parameter updates and will not be able to differentiate slightly related items from the very related ones.</p><p>To solve the above problem, for each positive training example (i.e., item pair (q, i)), we add "hard" negative examples, i.e., items Notice that the hard negative example is significantly more similar to the query, than the random negative example, though not as similar as the positive example.</p><p>that are somewhat related to the query item q, but not as related as the positive item i. We call these "hard negative items". They are generated by ranking items in a graph according to their Personalized PageRank scores with respect to query item q <ref type="bibr" target="#b13">[14]</ref>. Items ranked at 2000-5000 are randomly sampled as hard negative items. As illustrated in Figure <ref type="figure" target="#fig_2">2</ref>, the hard negative examples are more similar to the query than random negative examples, and are thus challenging for the model to rank, forcing the model to learn to distinguish items at a finer granularity.</p><p>Using hard negative items throughout the training procedure doubles the number of epochs needed for the training to converge. To help with convergence, we develop a curriculum training scheme <ref type="bibr" target="#b3">[4]</ref>. In the first epoch of training, no hard negative items are used, so that the algorithm quickly finds an area in the parameter space where the loss is relatively small. We then add hard negative items in subsequent epochs, focusing the model to learn how to distinguish highly related pins from only slightly related ones. At epoch n of the training, we add n − 1 hard negative items to the set of negative items for each item.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Node Embeddings via MapReduce</head><p>After the model is trained, it is still challenging to directly apply the trained model to generate embeddings for all items, including those that were not seen during training. Naively computing embeddings for nodes using Algorithm 2 leads to repeated computations caused by the overlap between K-hop neighborhoods of nodes. As illustrated in Figure <ref type="figure">1</ref>, many nodes are repeatedly computed at multiple layers when generating the embeddings for different target nodes. To ensure efficient inference, we develop a MapReduce approach that runs model inference without repeated computations.</p><p>We observe that inference of node embeddings very nicely lends itself to MapReduce computational model. Figure <ref type="figure" target="#fig_4">3</ref> details the data flow on the bipartite pin-to-board Pinterest graph, where we assume the input (i.e., "layer-0") nodes are pins/items (and the layer-1 nodes are boards/contexts). The MapReduce pipeline has two key parts:</p><p>(1) One MapReduce job is used to project all pins to a lowdimensional latent space, where the aggregation operation will be performed (Algorithm 1, Line 1). ( <ref type="formula" target="#formula_4">2</ref>) Another MapReduce job is then used to join the resulting pin representations with the ids of the boards they occur in, and the board embedding is computed by pooling the features of its (sampled) neighbors.</p><p>Note that our approach avoids redundant computations and that the latent vector for each node is computed only once. After the embeddings of the boards are obtained, we use two more MapReduce jobs to compute the second-layer embeddings of pins, in a similar fashion as above, and this process can be iterated as necessary (up to K convolutional layers). <ref type="foot" target="#foot_3">3</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Efficient nearest-neighbor lookups</head><p>The embeddings generated by PinSage can be used for a wide range of downstream recommendation tasks, and in many settings we can directly use these embeddings to make recommendations by performing nearest-neighbor lookups in the learned embedding space. That is, given a query item q, the we can recommend items whose embeddings are the K-nearest neighbors of the query item's embedding. Approximate KNN can be obtained efficiently via locality sensitive hashing <ref type="bibr" target="#b1">[2]</ref>. After the hash function is computed, retrieval of items can be implemented with a two-level retrieval process based on the Weak AND operator <ref type="bibr" target="#b4">[5]</ref>. Given that the PinSage model is trained offline and all node embeddings are computed via MapReduce and saved in a database, the efficient nearest-neighbor lookup operation enables the system to serve recommendations in an online fashion,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>To demonstrate the efficiency of PinSage and the quality of the embeddings it generates, we conduct a comprehensive suite of experiments on the entire Pinterest object graph, including offline experiments, production A/B tests as well as user studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>We evaluate the embeddings generated by PinSage in two tasks: recommending related pins and recommending pins in a user's home/news feed. To recommend related pins, we select the K nearest neighbors to the query pin in the embedding space. We evaluate performance on this related-pin recommendation task using both offline ranking measures as well as a controlled user study. For the homefeed recommendation task, we select the pins that are closest in the embedding space to one of the most recently pinned items by the user. We evaluate performance of a fully-deployed production system on this task using A/B tests to measure the overall impact on user engagement.</p><p>Training details and data preparation. We define the set, L, of positive training examples (Equation ( <ref type="formula" target="#formula_0">1</ref>)) using historical user engagement data. In particular, we use historical user engagement data to identify pairs of pins (q, i), where a user interacted with pin i immediately after she interacted with pin q. We use all other pins as negative items (and sample them as described in Section 3. Since PinSage can efficiently generate embeddings for unseen data, we only train on a subset of the Pinterest graph and then generate embeddings for the entire graph using the MapReduce pipeline described in Section 3.4. In particular, for training we use Features used for learning. Each pin at Pinterest is associated with an image and a set of textual annotations (title, description). To generate feature representation x q for each pin q, we concatenate visual embeddings (4,096 dimensions), textual annotation embeddings (256 dimensions), and the log degree of the node/pin in the graph. The visual embeddings are the 6-th fully connected layer of a classification network using the VGG-16 architecture <ref type="bibr" target="#b27">[28]</ref>. Textual annotation embeddings are trained using a Word2Vec-based model <ref type="bibr" target="#b22">[23]</ref>, where the context of an annotation consists of other annotations that are associated with each pin. Baselines for comparison. We evaluate the performance of Pin-Sage against the following state-of-the-art content-based, graphbased and deep learning baselines that generate embeddings of pins:</p><p>(1) Visual embeddings (Visual): Uses nearest neighbors of deep visual embeddings for recommendations. The visual features are described above. (2) Annotation embeddings (Annotation): Recommends based on nearest neighbors in terms of annotation embeddings. The annotation embeddings are described above. (3) Combined embeddings (Combined): Recommends based on concatenating visual and annotation embeddings, and using a 2-layer multi-layer perceptron to compute embeddings that capture both visual and annotation features. (4) Graph-based method (Pixie): This random-walk-based method <ref type="bibr" target="#b13">[14]</ref> uses biased random walks to generate ranking scores by simulating random walks starting at query pin q. Items with top K scores are retrieved as recommendations. While this approach does not generate pin embeddings, it is currently the state-of-the-art at Pinterest for certain recommendation tasks <ref type="bibr" target="#b13">[14]</ref> and thus an informative baseline.</p><p>The visual and annotation embeddings are state-of-the-art deep learning content-based systems currently deployed at Pinterest to generate representations of pins. Note that we do not compare against other deep learning baselines from the literature simply due to the scale of our problem. We also do not consider non-deep learning approaches for generating item/content embeddings, since other works have already proven state-of-the-art performance of deep learning approaches for generating such embeddings <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b23">24]</ref>. We also conduct ablation studies and consider several variants of PinSage when evaluating performance:</p><p>• max-pooling uses the element-wise max as a symmetric aggregation function (i.e., γ = max) without hard negative samples; • mean-pooling uses the element-wise mean as a symmetric aggregation function (i.e., γ = mean); • mean-pooling-xent is the same as mean-pooling but uses the cross-entropy loss introduced in <ref type="bibr" target="#b17">[18]</ref>. • mean-pooling-hard is the same as mean-pooling, except that it incorporates hard negative samples as detailed in Section 3.3. • PinSage uses all optimizations presented in this paper, including the use of importance pooling in the convolution step.</p><p>The max-pooling and cross-entropy settings are extensions of the best-performing GCN model from Hamilton et al. <ref type="bibr" target="#b17">[18]</ref>-other variants (e.g., based on Kipf et al. <ref type="bibr" target="#b20">[21]</ref>) performed significantly worse in development tests and are omitted for brevity. <ref type="foot" target="#foot_4">4</ref> For all the above variants, we used K = 2, hidden dimension size m = 2048, and set the embedding dimension d to be 1024.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Computation resources. Training of PinSage is implemented in</head><p>TensorFlow <ref type="bibr" target="#b0">[1]</ref> and run on a single machine with 32 cores and 16 Tesla K80 GPUs. To ensure fast fetching of item's visual and annotation features, we store them in main memory, together with the graph, using Linux HugePages to increase the size of virtual memory pages from 4KB to 2MB. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Offline Evaluation</head><p>To evaluate performance on the related pin recommendation task, we define the notion of hit-rate. For each positive pair of pins (q, i) in the test set, we use q as a query pin and then compute its top K nearest neighbors NN q from a sample of 5 million test pins. We then define the hit-rate as the fraction of queries q where i was ranked among the top K of the test sample (i.e., where i ∈ NN q ). This metric directly measures the probability that recommendations made by the algorithm contain the items related to the query pin q.</p><p>In our experiments K is set to be 500.</p><p>We also evaluate the methods using Mean Reciprocal Rank (MRR), which takes into account of the rank of the item j among recommended items for query item q:</p><formula xml:id="formula_4">MRR = 1 n (q,i)∈ L 1 R i,q /100 .<label>(2)</label></formula><p>Due to the large pool of candidates (more than 2 billion), we use a scaled version of the MRR in Equation ( <ref type="formula" target="#formula_4">2</ref>), where R i,q is the rank of item i among recommended items for query q, and n is the total number of labeled item pairs. The scaling factor 100 ensures that, for example, the difference between rank at 1, 000 and rank at 2, 000 is still noticeable, instead of being very close to 0. Table <ref type="table" target="#tab_1">1</ref> compares the performance of the various approaches using the hit rate as well as the MRR. <ref type="foot" target="#foot_5">5</ref> PinSage with our new importance-pooling aggregation and hard negative examples achieves the best performance at 67% hit-rate and 0.59 MRR, outperforming the top baseline by 40% absolute (150% relative) in terms of the hit rate and also 22% absolute (60% relative) in terms of MRR. We also observe that combining visual and textual information works much better than using either one alone (60% improvement of the combined approach over visual/annotation only). Embedding similarity distribution. Another indication of the effectiveness of the learned embeddings is that the distances between random pairs of item embeddings are widely distributed. If all items are at about the same distance (i.e., the distances are tightly clustered) then the embedding space does not have enough "resolution" to distinguish between items of different relevance. plots the distribution of cosine similarities between pairs of items using annotation, visual, and PinSage embeddings. This distribution of cosine similarity between random pairs of items demonstrates the effectiveness of PinSage, which has the most spread out distribution. In particular, the kurtosis of the cosine similarities of PinSage embeddings is 0.43, compared to 2.49 for annotation embeddings and 1.20 for visual embeddings.</p><note type="other">Figure 4</note><p>Another important advantage of having such a wide-spread in the embeddings is that it reduces the collision probability of the subsequent LSH algorithm, thus increasing the efficiency of serving the nearest neighbor pins during recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">User Studies</head><p>We also investigate the effectiveness of PinSage by performing headto-head comparison between different learned representations. In the user study, a user is presented with an image of the query pin, together with two pins retrieved by two different recommendation algorithms. The user is then asked to choose which of the two candidate pins is more related to the query pin. Users are instructed to find various correlations between the recommended items and the query item, in aspects such as visual appearance, object category and personal identity. If both recommended items seem equally related, users have the option to choose "equal". If no consensus is reached among 2/3 of users who rate the same question, we deem the result as inconclusive.</p><p>Table <ref type="table">2</ref> shows the results of the head-to-head comparison between PinSage and the 4 baselines. Among items for which the user has an opinion of which is more related, around 60% of the preferred items are recommended by PinSage. Figure <ref type="figure" target="#fig_6">5</ref> gives examples of recommendations and illustrates strengths and weaknesses of the different methods. The image to the left represents the query item. Each row to the right corresponds to the top recommendations made by the visual embedding baseline, annotation embedding baseline, Pixie, and PinSage. Although visual embeddings generally predict categories and visual similarity well, they occasionally make large mistakes in terms of image semantics. In this example, visual information confused plants with food, and tree logging with war photos, due to similar image style and appearance. The graphbased Pixie method, which uses the graph of pin-to-board relations, the training set size did not seem to help), reducing the runtime by a factor of 6 compared to training on the full graph.</p><p>Table <ref type="table" target="#tab_2">3</ref> shows the the effect of batch size of the minibatch SGD on the runtime of PinSage training procedure, using the meanpooling-hard variant. For varying batch sizes, the table shows: When training the PinSage variant with importance pooling, another trade-off comes from choosing the size of neighborhood T . Table <ref type="table" target="#tab_2">3</ref> shows the runtime and performance of PinSage when T = 10, 20 and 50. We observe a diminishing return as T increases, and find that a two-layer GCN with neighborhood size 50 can best capture the neighborhood information of nodes, while still being computationally efficient.</p><p>After training completes, due to the highly efficient MapReduce inference pipeline, the whole inference procedure to generate embeddings for 3 billion items can finish in less than 24 hours.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We proposed PinSage, a random-walk graph convolutional network (GCN). PinSage is a highly-scalable GCN algorithm capable of learning embeddings for nodes in web-scale graphs containing billions of objects. In addition to new techniques that ensure scalability, we introduced the use of importance pooling and curriculum training that drastically improved embedding performance. We deployed PinSage at Pinterest and comprehensively evaluated the quality of the learned embeddings on a number of recommendation tasks, with offline metrics, user studies and A/B tests all demonstrating a substantial improvement in recommendation performance. Our work demonstrates the impact that graph convolutional methods can have in a production recommender system, and we believe that PinSage can be further extended in the future to tackle other graph representation learning problems at large scale, including knowledge graph reasoning and graph clustering.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 2 : 3 S</head><label>23</label><figDesc>minibatch Input : Set of nodes M ⊂ V; depth parameter K; neighborhood function N : V → 2 V Output : Embeddings z u , ∀u ∈ M /* Sampling neighborhoods of minibatch nodes. */ 1 S (K ) ← M; 2 for k = K, ..., 1 do</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Random negative examples and hard negative examples.Notice that the hard negative example is significantly more similar to the query, than the random negative example, though not as similar as the positive example.</figDesc><graphic url="image-6.png" coords="6,60.43,83.69,226.98,74.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>3). Overall, we use 1.2 billion pairs of positive training examples (in addition to 500 negative examples per batch and 6 hard negative examples per pin). Thus in total we use 7.5 billion training examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Node embedding data flow to compute the first layer representation using MapReduce. The second layer computation follows the same pipeline, except that the inputs are first layer representations, rather than raw item features.</figDesc><graphic url="image-7.png" coords="7,66.41,83.69,479.17,113.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Probability density of pairwise cosine similarity for visual embeddings, annotation embeddings, and Pin-Sage embeddings.</figDesc><graphic url="image-8.png" coords="8,337.20,83.69,201.75,137.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Examples of Pinterest pins recommended by different algorithms. The image to the left is the query pin. Recommended items to the right are computed using Visual embeddings, Annotation embeddings, graph-based Pixie, and PinSage.</figDesc><graphic url="image-10.png" coords="9,337.20,256.34,201.76,154.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>(1) the computation time, in milliseconds, for each minibatch, when varying batch size; (2) the number of iterations needed for the model to converge; and (3) the total estimated time for the training procedure. Experiments show that a batch size of 2048 makes training most efficient.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: t-SNE plot of item embeddings in 2 dimensions.</figDesc><graphic url="image-11.png" coords="10,60.43,83.69,227.00,226.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Hit-rate and MRR for PinSage and content-based deep learning baselines. Overall, PinSage gives 150% improvement in hit rate and 60% improvement in MRR over the best baseline.5   </figDesc><table><row><cell>The total amount of memory used</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Batch size Per iteration (ms) # iterations Total time (h) Runtime comparisons for different batch sizes.</figDesc><table><row><cell>512</cell><cell>590</cell><cell>390k</cell><cell>63.9</cell></row><row><cell>1024</cell><cell>870</cell><cell>220k</cell><cell>53.2</cell></row><row><cell>2048</cell><cell>1350</cell><cell>130k</cell><cell>48.8</cell></row><row><cell>4096</cell><cell>2240</cell><cell>100k</cell><cell>68.4</cell></row><row><cell cols="4"># neighbors Hit-rate MRR Training time (h)</cell></row><row><cell>10</cell><cell>60%</cell><cell>0.51</cell><cell>20</cell></row><row><cell>20</cell><cell>63%</cell><cell>0.54</cell><cell>33</cell></row><row><cell>50</cell><cell>67%</cell><cell>0.59</cell><cell>78</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Performance tradeoffs for importance pooling.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Following a number of recent works (e.g.,[13,  </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="20" xml:id="foot_1">]) we use the term "convolutional" to refer to a module that aggregates information from a local graph region and to denote the fact that parameters are shared between spatially distinct applications of this module; however, the architecture we employ does not directly approximate a spectral graph convolution (though they are intimately related)<ref type="bibr" target="#b5">[6]</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2">In the limit of infinite simulations, the normalized counts approximate the Personalized PageRank scores with respect to u.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3">Note that since we assume that only pins (and not boards) have features, we must use an even number of convolutional layers.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4">Note that the recent GCN-based recommender systems of Monti et al.<ref type="bibr" target="#b23">[24]</ref> and Berg et al.<ref type="bibr" target="#b28">[29]</ref> are not directly comparable because they cannot scale to the Pinterest size data.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5">Note that we do not include the Pixie baseline in these offline comparisons because the Pixie algorithm runs in production and is "generating" labeled pairs (q, j) for us-i.e., the labeled pairs are obtained from historical user engagement data in which the Pixie algorithm was used as the recommender system. Therefore, the recommended item j is always in the recommendations made by the Pixie algorithm. However, we compare to the Pixie algorithm using human evaluations in Section 4.3.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors acknowledge Raymond Hsu, Andrei Curelea and Ali Altaf for performing various A/B tests in production system, Jerry Zitao Liu for providing data used by Pixie <ref type="bibr" target="#b13">[14]</ref>, and Vitaliy Kulikov for help in nearest neighbor query of the item embeddings.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="table">2</ref><p>: Head-to-head comparison of which image is more relevant to the recommended query image.</p><p>correctly understands that the category of query is "plants" and it recommends items in that general category. However, it does not find the most relevant items. Combining both visual/textual and graph information, PinSage is able to find relevant items that are both visually and topically similar to the query item.</p><p>In addition, we visualize the embedding space by randomly choosing 1000 items and compute the 2D t-SNE coordinates from the PinSage embedding, as shown in Figure <ref type="figure">6</ref>. 6 We observe that the proximity of the item embeddings corresponds well with the similarity of content, and that items of the same category are embedded into the same part of the space. Note that items that are visually different but have the same theme are also close to each other in the embedding space, as seen by the items depicting different fashion-related items on the bottom side of the plot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Production A/B Test</head><p>Lastly, we also report on the production A/B test experiments, which compared the performance of PinSage to other deep learning content-based recommender systems at Pinterest on the task of homefeed recommendations. We evaluate the performance by observing the lift in user engagement. The metric of interest is repin rate, which measures the percentage of homefeed recommendations that have been saved by the users. A user saving a pin to a board is a high-value action that signifies deep engagement of the user. It means that a given pin presented to a user at a given time was relevant enough for the user to save that pin to one of their boards so that they can retrieve it later.</p><p>We find that PinSage consistently recommends pins that are more likely to be re-pinned by the user than the alternative methods. Depending on the particular setting, we observe 10-30% improvements in repin rate over the Annotation and Visual embedding based recommendations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Training and Inference Runtime Analysis</head><p>One advantage of GCNs is that they can be made inductive <ref type="bibr" target="#b18">[19]</ref>: at the inference (i.e., embedding generation) step, we are able to compute embeddings for items that were not in the training set. This allows us to train on a subgraph to obtain model parameters, and then make embed nodes that have not been observed during training. Also note that it is easy to compute embeddings of new nodes that get added into the graph over time. This means that recommendations can be made on the full (and constantly growing) graph. Experiments on development data demonstrated that training on a subgraph containing 300 million items could achieve the best performance in terms of hit-rate (i.e., further increases in 6 Some items are overlapped and are not visible.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Tensorflow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Andoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Indyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FOCS</title>
				<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Ask the GRU: Multi-task learning for deep text recommendations</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<editor>RecSys</editor>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Curriculum learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient query evaluation using a two-level retrieval process</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Z</forename><surname>Broder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Carmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Herscovici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Soffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Geometric deep learning: Going beyond euclidean data</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Spectral networks and locally connected networks on graphs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Deep neural networks for youtube recommendations</title>
		<author>
			<persName><forename type="first">P</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sargin</surname></persName>
		</author>
		<editor>RecSys</editor>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Discriminative Embeddings of Latent Variable Models for Structured Data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep content-based music recommendation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schrauwen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Convolutional networks on graphs for learning molecular fingerprints</title>
		<author>
			<persName><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Iparraguirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bombarell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Pixie: A System for Recommending 3+ Billion Items to 200+ Million Users in Real-Time</title>
		<author>
			<persName><forename type="first">C</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jindal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sugnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ulrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A new model for learning in graph domains</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Joint Conference on Neural Networks</title>
				<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tulloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
		<title level="m">Large Minibatch SGD: Training ImageNet in 1 Hour</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Inductive Representation Learning on Large Graphs</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Representation Learning on Graphs: Methods and Applications</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Engineering Bulletin</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Molecular graph convolutions: moving beyond fingerprints. CAMD</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Berndl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Riley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Gated graph sequence neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Geometric matrix completion with recurrent multi-graph neural networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In NIPS</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
	</analytic>
	<monogr>
		<title level="m">OpenMP Application Program Interface Version 4.5</title>
				<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">DeepWalk: Online learning of social representations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The graph neural network model</title>
		<author>
			<persName><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="61" to="80" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02263</idno>
		<title level="m">Graph Convolutional Matrix Completion</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">GraphRNN: Generating Realistic Graphs using Deep Auto-regressive Models</title>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Modeling polypharmacy side effects with graph convolutional networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
