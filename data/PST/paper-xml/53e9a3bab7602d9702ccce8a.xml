<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Timing the Application of Security Patches for Optimal Uptime</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Steve</forename><surname>Beattie</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Shostack -Zero Knowledge Systems</orgName>
								<address>
									<region>Inc</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Seth</forename><surname>Arnold</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Shostack -Zero Knowledge Systems</orgName>
								<address>
									<region>Inc</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Crispin</forename><surname>Cowan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Shostack -Zero Knowledge Systems</orgName>
								<address>
									<region>Inc</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Perry</forename><surname>Wagle</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Shostack -Zero Knowledge Systems</orgName>
								<address>
									<region>Inc</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chris</forename><surname>Wright</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Shostack -Zero Knowledge Systems</orgName>
								<address>
									<region>Inc</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">â€  -Wirex</forename><surname>Communications</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Shostack -Zero Knowledge Systems</orgName>
								<address>
									<region>Inc</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Timing the Application of Security Patches for Optimal Uptime</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">431BAC87A72E5A54E71C1AAFE0F53F94</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T05:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Security vulnerabilities are discovered, become publicly known, get exploited by attackers, and patches come out. When should one apply security patches? Patch too soon, and you may suffer from instability induced by bugs in the patches. Patch too late, and you get hacked by attackers exploiting the vulnerability.W eexplore the factors affecting when it is best to apply security patches, providing both mathematical models of the factors affecting when to patch, and collecting empirical data to give the model practical value. Wec onclude with a model that we hope will help provide a formal foundation for when the practitioner should apply security updates.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>''To patch, or not to patch, -that is the question: -Whether 'tis nobler in the mind to suffer The slings and arrows of outrageous script kiddies, Or to take up patches against a sea of troubles, And by opposing, end them?'' <ref type="bibr" target="#b23">[24]</ref> '' W h e n to patch?''p resents a serious problem to the security administrator because there are powerful competing forces that pressure the administrator to apply patches as soon as possible and also to delay patching the system until there is assurance that the patch is not more likely to cause damage than it proposes to prevent. Patch too early,a nd one might be applying a broken patch that will actually cripple the system'sf unctionality.P atch too late, and one is at risk from penetration by an attacker exploiting a hole that is publicly known. Balancing these factors is problematic.</p><p>The pressure to immediately patch grows with time after the patch is released, as more and more script kiddies acquire scanning and attack scripts to facilitate massive attacks <ref type="bibr" target="#b3">[4]</ref>. Conversely,the pressure to be cautious and delay patching decreases with time, as more and more users across the Internet apply the patch, providing either evidence that the patch is defective, or (through lack of evidence to the contrary) that the patch is likely okay to apply.S ince these trends go in opposite directions, it should be possible to choose a time to patch that is optimal with respect to the risk of compromising system availability.F igure 1 conceptually illustrates this effect; where the lines cross is the optimal time to patch, because it minimizes the total risk of loss.</p><p>This paper presents a proposed model for finding the appropriate time to apply security patches. Our approach is to model the cost (risk and consequences) of penetration due to attack and of corruption due to a defective patch, with respect to time, and then solve for the intersection of these two functions.</p><p>These costs are functions of more than just time. We attempt to empirically inform the cost of failure due to defective patches with a survey of security advisories. Informing the cost of security penetration due to failure to patch is considerably more difficult, because it depends heavily on many local factors. While we present a model for penetration costs, it is up to the local administrator to determine this cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Time</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Risk of Loss</head><p>Bad Patch Risk Penetration Risk Optimal Time to Patch Figure1 :Ahypothetical graph of risks of loss from penetration and from application of a bad patch. The optimal time to apply a patch is where the risk lines cross.</p><p>In particular,m any security administrators feel that it is imperative to patch vulnerable systems immediately.T his is just an end-point in our model, representing those sites that have very high risk of penetration and have ample resources to do local patch testing in aid of immediate deployment. Our intent in this study is to provide guidelines to those who do not have sufficient resources to immediately test and patch everything, and must choose where to allocate scarce Timing the Application of Security Patches for Optimal Uptime Beattie, et al. security resources. Wehave used the empirical data to arrive at concrete recommendations for when patches should be applied, with respect to the apparent common cases in our sample data.</p><p>It should also be noted that we are not considering the issue of when to disable a service due to a vulnerability.O ur model considers only the question of when to patch services that the site must continue to offer.I n our view,i fo ne can afford to disable a service when there is a security update available, then one probably should not be running that service at all, or should be running it in a context where intrusion is not critical.</p><p>Lastly,w ed on ot believe that this work is the final say in the matter,b ut rather continues to open a new area for exploration, following on Browne, et al. <ref type="bibr" target="#b3">[4]</ref>. As long as frequent patching consume a significant fraction of security resources, resource allocation decisions will have to be made concerning how to deal with these patches.</p><p>The rest of this paper is structured as follows. The next section presents motivations for the models we use to describe the factors that make patching urgent and that motivate caution. Then, the next section formally models these factors in mathematical terms and presents equations that express the optimal time to apply patches. The subsequent section presents methods and issues for acquiring data to model patch failure rates. The paper then presents the empirical data we have collected from the Common Vulnerabilities and Exposures (CVE) database and describes work related to this study.The paper ends with discussions the implications of this study for future work and our conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem: When ToPatch</head><p>The value of applying patches for known security issues is obvious. A security issue that will shortly be exploited by thousands of script-kiddies requires immediate attention, and security experts have long recommended patching all security problems. However,a pplying patches is not free: it takes time and carries a set of risks. Those risks include that the patch will not have been properly tested, leading to loss of stability; that the patch will have unexpected interaction with local configurations, leading to loss of functionality; that the patch will not fix the security problem at hand, wasting the system administrator's time. Issues of loss of stability and unexpected interaction have a direct and measurable cost in terms of time spent to address them. Tod ate, those issues have not been a focus of security research. There is a related issue: finding a list of patches is a slow and laborintensive process <ref type="bibr" target="#b6">[7]</ref>. While this makes timely application of patches less likely because of the investment of time in finding them, it does not directly interact with the risk that applying the patch will break things. However,the ease of finding and applying patches has begun to get substantial public attention <ref type="bibr" target="#b19">[20]</ref> and is not our focus here.</p><p>Most system administrators understand that these risks are present, either from personal experience or from contact with colleagues. However,weknow of no objective assessment of how serious or prevalent these flaws are. Without such an assessment it is hard to judge when (or even if) to apply a patch. Systems administrators have thus had a tendency to delay the application of patches because the costs of applying patches are obvious, well known, and have been hard to balance against the cost of not applying patches. Other sources of delay in the application of patches can be rigorous testing and roll-out procedures and regulations by organizations such as the US Food and Drug Administration that require known configurations of systems when certified for certain medical purposes <ref type="bibr" target="#b0">[1]</ref>.</p><p>Some organizations have strong processes for triaging, testing, and rolling-out patches. Others have mandatory policies for patching immediately on the release of a patch. Those processes are very useful to them, and less obviously,t oo thers, when they report bugs in patches. The suggestions that we make regarding delay should not be taken as a recommendation to abandon those practices. <ref type="foot" target="#foot_0">1</ref>The practical delay is difficult to measure, but its existence can be inferred from the success of worms such as Code Red. This is illustrative of the issue created by delayed patching, which is that systems remain vulnerable to attack. Systems which remain vulnerable run a substantial risk of attacks against them succeeding. One research project found that systems containing months-old known vulnerabilities with available but unapplied patches exposed to the Internet have a ''life expectancy''m easured in days <ref type="bibr" target="#b13">[14]</ref>. Once a break-in has occurred, it will need to be cleaned up. The cost of such clean-up can be enormous.</p><p>Having demonstrated that all costs relating to patch application can be examined in the ''currency'' of system administrator time, we proceed to examine the relationship more precisely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Solution: Optimize the Time to Patch</head><p>To determine the appropriate time to patch, we need to develop a mathematical model of the potential costs involved in patching and not patching at a given time. In this section we will develop cost functions that systems administrators can use to help determine an appropriate course of action.</p><p>First, we define some terms that we will need to take into account:</p><p>â€¢ e patch is the expense of fixing the problem (applying the patch), which is either an opportunity cost, or the cost of additional staff.</p><p>â€¢ e p.recover is the expense of recovering from a failed patch, including opportunity cost of work delayed. Both this and the next cost may include a cost of lost business.</p><p>â€¢ e breach is the expense of recovering from a secu- rity breach, including opportunity cost of work delayed and the cost of forensics work.</p><p>â€¢ p fail is the likelihood that applying a given patch will cause a failure.</p><p>â€¢ p breach is the likelihood that not applying a given patch will result in a security breach. All of these costs and probabilities are parameterized. The costs e patch , e p.recover ,a nd e breach are all particular to both the patch in question and the configuration of the machine being patched. However, because the factors affecting these costs are so specific to an organization, we treat the costs as constants. This is constant within an organization, not between organizations, which we believe is sensible for a given systems administrator making a decision.</p><p>The probabilities p fail and p breach vary with time. Whether a patch is bad or not is actually a fixed fact at the time the patch is issued, but that fact only becomes known as the Internet community gains experience applying and using the patch. So as a patch ages without issues arising, the probability of a patch turning out to be bad decreases.</p><p>The probability p breach is a true probability that increases with time in the near term. Browne, et al. <ref type="bibr" target="#b3">[4]</ref> examined exploitation rates of vulnerabilities and determined influencing terms such as the release of a scripted attack tool in rates of breaches. However,t he rate of breach is not a simple function 1 |Internet Hosts| or even N |InternetHosts| (where N is the number of hosts or unprotected hosts that a systems administrator is responsible for and |InternetHosts|i st he number of hosts on the Internet). Not every host with a vulnerability will be attacked, although in the wake of real world events such as the spread of Code Red <ref type="bibr" target="#b5">[6]</ref> and its variants, as well as work on Flash <ref type="bibr" target="#b25">[26]</ref> and Warhol <ref type="bibr" target="#b27">[28]</ref> worms, it seems that it may be fair to make that assumption. Thus we will consider both probabilities p fail and p breach as functions of time (t), and write them p fail (t) and p breach (t).</p><p>Next, we want to to develop two cost functions:</p><p>â€¢ e patch (t): cost of patching at a given time t.</p><p>â€¢ e nopatch (t): cost of not patching at a given time t.</p><p>The probable cost of patching a system drops over time as the Internet community grows confidence in the patch through experience. Conversely,the probable cost of not patching follows a 'ballistic' trajectory,asthe vulnerability becomes more widely known, exploitation tools become available, and then fall out of fashion <ref type="bibr" target="#b3">[4]</ref>; but, for the part of the ballistic curve we are concerned with, we can just consider cost of not patching to be monotonically rising. Therefore, the administrator will want to patch vulnerable systems at the earliest point in time where e patch (t) â‰¤ e nopatch (t).</p><p>The cost of patching a system will have two terms: the expense of applying the patch, and the expense of recovering from a failed patch. Applying a patch will likely have a fixed cost that must be paid regardless of the quality of the patch. Recovery cost, however,will only exist if a given patch is bad, so we need to consider the expected risk in a patch. Since a systems administrator cannot easily know a priori whether a patch is bad or not, we multiply the probability that the patch induces failure by the expected recovery expense. This gives us the function e patch (t)=p fail (t)e p.recover + e patch (1) It is possible, although not inexpensive, to obtain much better estimations of the probability of failure through the use of various testing mechanisms, such as having a non-production mirror of the system, patching it, and running a set of tests to verify functionality. However,s uch systems are not the focus of our work.</p><p>The cost of not applying a patch we consider to be the expense of recovering from a security breach. Again, an administrator is not going to know a priori that a breach will occur,s ow ec onsider the cost of recovery in terms of the probability of a security breach occurring. Thus we have: e nopatch (t)=p breach (t) e breach (2) Pulling both functions together,as ystems administrator will want to patch vulnerable systems when the following is true: p fail (t)e p.recover + e patch â‰¤ p breach (t) e breach (3) In attempting to apply the functions derived above, a systems administrator may want to take more precise estimates of various terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>On the Cost Functions</head><p>Expenses for recovering from bad patches and security breaches are obviously site and incident specific, and we have simplified some of that out to ease our initial analysis and aid in its understanding.</p><p>We could argue with some confidence that the cost of penetration recovery often approximates the cost of bad patch recovery.I nm any instances, it probably amounts to ''reinstall.''T his simplifying assumption may or may not be satisfactory.Recovery from a breakin is likely harder than recovery from a bad patch, because recovery from bad patch may simply be a reinstall, or at least does not involve the cost of dealing with malice, while recovery from getting hacked is identifying and saving critical state with tweezers, reformatting, re-installation, applying patches, recovering state from backup, patching some more, ensuring that the recovered state carries no security risk, and performing forensics, a non-trivial expense <ref type="bibr" target="#b9">[10]</ref>. However, it is possible that recovery from a bad patch could have ah igher cost than penetration recovery -consider a patch that introduces subtle file system corruption that is not detected for a year. Furthermore, we note that many vendors are working to make the application of security patches as simple as possible, thereby reducing the expense of applying a security patch <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b28">29]</ref>. As the fixed cost of applying a patch approaches zero, we can simply remove it from the equations: p fail (t) e p.recover â‰¤ p breach (t) e breach (4) Alternately,w ec an assume that recovery from being hacked is C times harder than recovery from bad patch (C may be less than one). While the math is still fairly simple, we are not aware of systemic research into the cost of recovering from security break-ins. However,ap recise formulation of the time is less important to this paper than the idea that the time absorbed by script kiddies can be evaluated as a function of system administrator time. Expenses incurred in recovery are going to be related to installation size and number of affected machines, so an argument that there is some relationship between costs can be made. p fail (t) â‰¤ p breach (t) C (7) Recall our assumptions that p breach (t)r ises with time and p fail (t)drops with time. Therefore, the earliest time t that equation 7 is satisfied is the optimal time to apply the patch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>When to Start the Clock</head><p>While we discuss the value of the equations above at given times, there are actually numerous points from which time can be counted. There is the time from the discovery of a vulnerability,t ime from the public announcement of that vulnerability,a nd time since a patch has been released. Browne, et al. <ref type="bibr" target="#b3">[4]</ref> work from the second, since the first may be unknown, but the spread of the vulnerability information may be better modeled from the first, especially if the vulnerability is discovered by a black hat. A systems administrator may only care from the time a patch is available, although some may choose to shut offservices known to be vulnerable before that as a last resort, and work has been done on using tools such as chroot(2), Janus <ref type="bibr" target="#b11">[12]</ref>, and SubDomain <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b12">13]</ref> to protect services that are under attack. In this paper,w eh ave chosen to start counting time from when the patch is released.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methodology</head><p>The first thing to consider when deciding to experimentally test the equations derived previously is as ource of data. Wec onsidered starting with specific vendors' advisories. Starting from vendor data has flaws: it is difficult to be sure that a vendor has produced advisories for all vulnerabilities, the advisories may not link to other information in useful ways, and different vendors provide very different levels of information in their advisories.</p><p>We decided instead to work from the Common Vulnerabilities and Exposures (CVE) <ref type="bibr" target="#b15">[16]</ref>, a MITREhosted project, to provide common naming and concordance among vulnerabilities. Since MITRE is an organization independent of vendors, using the CVE database reduces the chance of bias. Starting from CVE allows us to create generic numbers, which are useful because many vendors do not have a sufficient history of security fixes. However,there are also many vendors who do have such a history and sufficient process (or claims thereof) that it would be possible to examine their patches, and come up with numbers that apply specifically to them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Gathering</head><p>Starting from the latest CVE (version 20020625), we split the entries into digestible chunks. Each section was assigned to a person who examined each of the references. Some of the references were unavailable, in which case they were ignored or tracked down using a search engine. They were ignored if the issue was one with many references (e.g., CVE-2001-0414 has 22 references, and the two referring to SCO are not easily found.) If there was no apparent patch re-issue, we noted that. If there was, we noted how long it was until the patch was withdrawn and re-released. Some advisories did not make clear when or if a bad patch was withdrawn, and in that case, we treated it as if it was withdrawn by replacement on the day of re-issuance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methodological Issues</head><p>''Thereare morethings in Heaven and Earth, Horatio, Then aredream'tofinour Philosophy.'' <ref type="bibr" target="#b23">[24]</ref> Research into vulnerabilities has an unfortunate tendency to confound researchers with a plethora of data gathering issues. These issues will impact the assessment of how likely a patch is to fail. It is important to choose a method and follow it consistently for the results to have any meaning; unfortunately,a ny method chosen causes us to encounter issues which are difficult and troubling to resolve. Once we select a method and follow it, our estimates may be systematically wrong for several reasons. Cardinality issues are among the worst offenders:</p><p>â€¢ Vendors rolling several issues into one patch: An example of this is found in one vendor patch <ref type="bibr" target="#b18">[19]</ref>  â€¢ Vendors rolling one patch into several advi- sories: An example here is CVE-2001-0414 with a dozen vendors involved. The vulnerability is not independent because Linux and BSD vendors commonly share fixes, and so an update from multiple vendors may be the same patch. If this patch is bad, then in producing a generic recommendation of when to patch, we could choose to count it as N bad patches, which would lead to a higher value for p fail ,and consequently,l ater patching. If the single patch is good, then counting it as N good patches could bias the probability of patch failure downward.</p><p>â€¢ Vendors releasing advisories with work- arounds, but no patches: An example is CVE-2001-0221, where the FreeBSD team issued the statement ''[this program] is scheduled for removal from the ports system if it has not been audited and fixed within one month of discovery.''N oo ne fixed it, so no patch was released. A related situation occurred when a third party,u nrelated to Oracle, released an advisory relating to Oracle'sproduct along with aworkaround, and Oracle remained completely silent about the issue (CVE-2001-0326). We recorded these instances but treated them as non-events -our goal is to measure quality of patches; if no patch was released, there is nothing to measure. There are several other potential sources of bias. We may not have accurate information on whether a vendor released an updated patch, because the CVE entry points to the original, and the vendor released a subsequent/different advisory.T his potentially introduces a bias by reducing our computed probability of aharmful patch.</p><p>When patches are not independent, there is bias in a different direction; consider if one or more vendors released a revised update while others did not (for example, CVE-2001-0318). Wec onsidered each CVE entry as one patch, even if it involved multiple vendors. Wec hose to record the data for the vendor who issued the latest advisory revision (e.g., Debian over Mandrake and Conectiva in CVE-2001-0318). This potentially introduces a bias towards patches being less reliable than they actually are. Systems administrators tracking the advisories of one specific vendor would not have this potential source of bias.</p><p>It may be difficult to decide if a patch is bad or not. For example, the Microsoft patch for CVE-2001-0016 was updated six months after its release. There was a conflict between this patch and Service Pack 2 for Windows 2000. Installing the patch would disable many of the updates in Service Pack 2. Note that SP2 was issued four months after the patch, so there was four months where the patch was harmless, and two months where the patch and Service Pack 2 conflicted. Wet reated it as if was bad for the entire six months.</p><p>There is a potential for concern with the number of CVE entries we have examined. In the next section, we attempt to infer appropriate times to apply patches by observing the knees in the curves shown in Figures <ref type="figure" target="#fig_2">7a nd 9</ref>, and these inferences would be stronger if there were sufficient data points to be confident that the knees were not artifacts of our sample data.</p><p>More data points would be desirable, but obtaining it is problematic. Wef ound the CVE repository to be limiting, in that it was difficult to determine whether any given security patch was defective. For future research, we recommend using security advisory information direct from vendors. In addition to providing more detail, such an approach would help facilitate computing patch failure rate with respect to each vendor.</p><p>We don ot believe that these issues prevent a researcher from analyzing the best time to patch, or a systems administrator from making intelligent choices about when to patch. However,t hese methodological issues do need to be considered in further studies of security patch quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Empirical Data</head><p>In this section, we examine the data we collected as discussed in the previous section. Weexamined 136 CVE entries, dating from 1999, 2000, and 2001. Of these, 92 patches never were revised leading us to believe they were safe to apply,20patches either were updated or pulled, and 24 CVE entries were non-patch events as discussed in 'Methodological Issues.' Table <ref type="table">2s</ref> ummarizes this data. Of the 20 patches that were determined to be faulty,a ll but one (CVE-2001-0341) had an updated patch released. Of these, three were found to be faulty and had a second update released; one subsequently had a third revision released. Table <ref type="table">3</ref> summarizes the data for the revised patches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Total CVE entries examined 136</head><p>Good patches 92 Revised or pulled patches 20 Non-patch entries 24</p><p>Table <ref type="table">2</ref>:Q uality of initial patches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Revised or pulled patches 20 Good revised patches 16</head><p>Re-revised patches 3 Pulled and never re-released patches 1</p><p>Table <ref type="table">3</ref>:Q uality of revised patches.</p><p>Table <ref type="table" target="#tab_1">4</ref> analyzes the properties of the patch revisions. The middle column shows the number of days from the initial patch release until an announcement of some kind appeared indicating that the patch was bad, for the 20 patches that were revised. The right column shows the number of days from the revised patch release until notification that the revised patch was faulty,f or the three issues that had subsequent revisions. Three data points is insufficient to draw meaningful conclusions, so we will disregard doubly or more revised patches from here on. Wef ound one triply revised patch, occurring seven days after the release of the second revision. Figure <ref type="figure">5</ref> presents a histogram over the 20 revised patches of the time from the initial patch release to the time of the announcement of a problem with the patch, while Figure <ref type="figure">8</ref> examines the first 30-day period in detail. Figure <ref type="figure">6</ref> presents the same data set as a probability at a given time since initial patch release that a patch will be found to be bad, i.e., an empirical plot of p fail (t)from equation 7.</p><p>Figure <ref type="figure" target="#fig_2">7</ref> plots the days to resolve an accumulated number of security issues, while Figure <ref type="figure">9</ref> examines the first 30-day period more closely.T hese plots are subtly different from the previous data sets in two ways:</p><p>â€¢ Time to resolution: In the previous graphs, we counted time from when the security patch was announced to the time the patch was announced to be defective. Here, we are measuring to the time the defective patch is resolved. Of the 20 revised patches, 16 provided a revised patch concomitant with the announcement of the patch problem, two had a one-day delay to the release of a revised patch, one had a 97 day delay to the release of a revised patch, and one defective patch was never resolved.</p><p>â€¢ No patch ever released: Of the 136 CVE entries that we surveyed, 24 never had any patch associated with them, and so for these plots, will never be resolved. Ideally,w ew ould like to be able to overlay Figure <ref type="figure">6</ref> with a similar probability plot for ''probability of getting hacked at time t past initial disclosure,''o r p breach (t). Unfortunately,i ti sp roblematic to extract such a probability from Browne, et al.'sd ata <ref type="bibr" target="#b3">[4]</ref> because the numerator (attack incidents) is missing many data points (people who did not bother to report an incident to CERT), and the denominator is huge (the set of all vulnerable nodes on the Internet).</p><p>From Honeynet <ref type="bibr" target="#b13">[14]</ref> one may extract a p breach (t). Honeynet sought to investigate attacker behavior by placing ''honeypot''( deliberately vulnerable) systems on the Internet, and observing the subsequent results. In particular,H oneynet noted that the lifespan of an older,u npatched Red Hat Linux system containing months-old known vulnerabilities could be as short as asmall number of days, as attacker vulnerability scanning tools quickly located and exploited the vulnerable machine. However we note that this probability may not correlate to the system administrator's site. Site specific factors -site popularity,a ttention to security updates, vulnerability,e tc. -affect the local p breach (t), and as such it must be measured locally. After determining local probability of a breach (i.e., p breach (t)), the administrator should apply Figure <ref type="figure">6t</ref> oe quation 7 to determine the first time t where equation 7 is satisfied. However,since p breach (t)isdifficult to compute, the pragmatist may want to observe the knees in the curve depicted in Figures <ref type="figure" target="#fig_2">7</ref> and<ref type="figure">9</ref> and apply patches at either ten or thirty days.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>This paper was inspired by the ''Code Red''a nd '' N i m d a '' worms, which were so virulent that some analysts conjectured that the security administrators of the Internet could not patch systems fast enough to stop them <ref type="bibr" target="#b19">[20]</ref>. Even more virulent worm systems have been devised <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b25">26]</ref> so the problems of ''when to patch?'' and ''can we patch fast enough?''are very real.</p><p>The recent survey of rates of exploitation <ref type="bibr" target="#b3">[4]</ref> was critical to our work. In seeking to optimize the tradeoffb etween urgent and cautious patching, it is important to understand both forms of pressure, and Browne, et al. provided the critical baseline of the time-sensitive need to patch.</p><p>Schneier <ref type="bibr" target="#b22">[23]</ref> also studied rates of exploitation versus time of disclosure of security vulnerabilities. However,S chneier conjectured that the release of a vendor patch would peak the rate of exploitation. The subsequent study by Browne, et al. of CERTi ncident data above belied this conjecture, showing that exploitation peaks long after the update is released, demonstrating that most site administrators do not apply patches quickly.</p><p>Reavis <ref type="bibr" target="#b20">[21]</ref> studied the timeliness of vendor-supplied patches. Reavis computed the average ''days of recess''( days when a vulnerability is known, but no patch is available) for each of Microsoft, Red Hat Linux, and Solaris. Our clock of ''when to patch?'' starts when Reavis' clock of ''patch available''stops.</p><p>Howard <ref type="bibr" target="#b14">[15]</ref> studied Internet security incident rates from 1989 to 1995. He found that, with respect to the size of the Internet, denial-of-service attacks were increasing, while other attacks were decreasing. The cause of these trends is difficult to establish without speculation, but it seems plausible that the exponential growth rate of the Internet exceeded the growth rate of attackers knowledgeable enough to perpetrate all but the easiest (DoS) attacks.</p><p>In 1996, Farmer <ref type="bibr" target="#b10">[11]</ref> surveyed prominent web hosting sites and found that nearly two-thirds of such sites had significant vulnerabilities, well above the onethird average of randomly selected sites. Again, root causes involve speculation, but it is likely that this resulted from the complex active content that prominent web sites employ versus randomly selected sites. It is also likely that this trend has changed, as e-commerce sites experienced the pressures of security attacks.</p><p>In recent work, Anderson <ref type="bibr" target="#b1">[2]</ref> presents the viewpoint that many security problems become simpler when viewed through an economic lens. In this paper, we suggest that the system administrator's failure to patch promptly is actually not a failure, but a rational choice. By analyzing that choice, we are able to suggest a modification to that behavior which addresses the concerns of the party,rather than simply exhorting administrators to patch. Also worth mentioning is the ongoing study of perception of risk. In McNeil, et al. <ref type="bibr" target="#b16">[17]</ref>, the authors point out that people told that a medical treatment has a10% risk of death react quite differently than people told that 90% of patients survive. It is possible that similar framing issues may influence administrators behavior with respect to security patches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>As we performed this study,weencountered several practical issues. Some were practical impediments to the execution of the study,w hile others were of larger concern to the community of vendors and users. Addressing these issues will both make future research in this area more consistent and valid, and also may improve the situation of the security practitioner.</p><p>The first issue is that of setting the values for the constants in our equations, e.g., the cost of breach recovery versus the cost of bad patch recovery,and the probability of a breach for a given site. These values are site-specific, so we cannot ascertain them with any validity:</p><p>â€¢ Aw eb server that is just a juke box farm of CD-ROMs is not as susceptible to data corruption as an on-line gambling house or a credit bureau, affecting the relative costs of recovery.</p><p>â€¢ Ap rivate corporate server behind a firewall is less likely to be attacked than a public web server hosting a controversial political advocacy page. We wish to comment that the administrator's quandary is made worse by vendors who do a poor job of quality assurance on their patches, validating the systems administrator's decision to not patch. Our ideas can be easily taken by a vendor as advice as to how to improve their patch production process and improve their customer's security.Ifthe standard deviation of patch failure times is high, then administrators will rationally wait to patch, leaving themselves insecure. Extra work in assurance may pay great dividends. In future work, it would be interesting to examine vendor advance notice (where vendors are notified of security issues ahead of the public) and observe whether the reliability of subsequent patches are more reliable, i.e., do vendors make good use of the additional time.</p><p>In collecting data, we noticed but have not yet analyzed a number of trends: Cisco patches failed rarely,w hile other vendors often cryptically updated their advisories months after issue. The quality of advisories varies widely.W ef eel it is worth giving kudos to Caldera for the ease with which one can determine that they have issued a new patch <ref type="bibr" target="#b4">[5]</ref>. However,t hey could learn a great deal from some Cisco advisories <ref type="bibr" target="#b7">[8]</ref> in keeping detailed advisory revision histories. Red Hat'sa dvisories included an ''issue date,''w hich we later discovered is actually the first date that they were notified of the issue, not the date they issued the advisory.T here has not, to our knowledge, been a paper on ''how to write an advisory,''o r on the various ways advisories are used.</p><p>If one assumes that all problems addressed in this paper relating to buggy patches have been solved, the administrator must still reliably ascertain the validity of an alleged patch. Various forms of cryptographic authentication, such as PGP signatures on Linux RPM packages <ref type="bibr" target="#b2">[3]</ref> and digital signatures directly on binary executables <ref type="bibr" target="#b26">[27]</ref> can be used. Such methods become essential if one employs automatic patching mechanisms, as proposed by Browne, et al. <ref type="bibr" target="#b3">[4]</ref> and provided by services such as Debian apt-get <ref type="bibr" target="#b24">[25]</ref>, Ximian Red Carpet <ref type="bibr" target="#b28">[29]</ref>, the Red Hat Network <ref type="bibr" target="#b21">[22]</ref>, and the automatic update feature in Microsoft Windows XP <ref type="bibr" target="#b17">[18]</ref>.  The diligent systems administrator faces a quandary: to rush to apply patches of unknown quality to critical systems, and risk resulting failure due to defects in the patch? Or to delay applying the patch, and risk compromise due to attack of a now wellknown vulnerability? We have presented models for the pressures to patch early and to patch later,formally modeled these pressures mathematically,a nd populated the model with empirical data of failures in security patches and rates of exploitation of known flaws. Using these models and data, we have presented a notion of an optimal time to apply security updates. We observe that the risk of patches being defective with respect to time has two knees in the curve at 10 days and 30 days after the patch'sr elease, making 10 days and 30 days ideal times to apply patches. It is our hope that this model and data will both help to inspire follow-on work and to form a best-practice for diligent administrators to follow.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>which is referenced by seven candidates and entries in the CVE (CAN-2001-0349, CAN-2001-0350, CVE-2001-0345, CVE-2001-0346, CVE-2001-0348, CVE-2001-0351, and CVE-2001-0347).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure5:Figure7:</head><label></label><figDesc>Figure5:Ahistogram of the number of faulty initial patches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure8:Figure9:Aclose-up cumulative graph of the first 30 days in Figure 7 .</head><label>7</label><figDesc>Figure8:Aclose-up histogram of the first class interval in Figure5. It shows the number of faulty initial patch notifications occurring within 30 days of initial patch release.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>2</head><label>2</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Conclusions''</head><label></label><figDesc>Never do today what you can put off till tomorrowiftomorrow might improve the odds.''-Robert Heinlein</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>This allows us to state that: e breach = Ce p . recover (5) We can substitute this into equation 4: p fail (t) e p.recover â‰¤ p breach (t) Ce p . recover (6) Dividing each side by e p.recover ,w ea rrive at the decision algorithm:</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 4 :</head><label>4</label><figDesc>A nalysis of revision data.</figDesc><table><row><cell>Notification time in days</cell><cell>Initial revision (20 data points)</cell><cell>Subsequent revision (3 data points)</cell></row><row><cell>Maximum</cell><cell>500</cell><cell>62</cell></row><row><cell>Minimum</cell><cell>1</cell><cell>1</cell></row><row><cell>Average</cell><cell>64.2</cell><cell>22.7</cell></row><row><cell>Median</cell><cell>17.5</cell><cell>5</cell></row><row><cell>Std deviation</cell><cell>117.0</cell><cell>34.1</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>As a perhaps amusing aside, if everyone were to follow our suggested delay practice, it would become much less effective. Fortunately,w eh ave no expectation that everyone will listen to us.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2002" xml:id="foot_1"><p>LISA XVI -November 3-8, 2002 -Philadelphia, PA</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1102" xml:id="foot_2"><p>002 LISA XVI -November 3-8, 2002 -Philadelphia, PA</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"> â€   <p>This work supported by DARPAC ontract F30602-01-C-0172.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Information</head><p>Seth Arnold graduated from Willamette University in 2001 with a B.Sc. in Computer Science, Mathematics, and Religious Studies. He has been a system administrator,h as played cryptographer,a nd is currently employed at WireX Communications in the research group. He can be reached via email at sarnold@wirex.com .</p><p>Steve Beattie is employed in the Research Group at WireX Communications and was involved in the development of the StackGuard, SubDomain, Race-Guard and FormatGuard security tools. He received a Masters Degree in Computer Science from the Oregon Graduate Institute, and was previously employed as a Systems Administrator for a Knight-Ridder newspaper.Hecan be reached via email at steve@wirex.com .</p><p>Dr.Crispin Cowan is co-founder and Chief Scientist of WireX, and previously was a Research Assistant Professor at the Oregon Graduate Institute. His research focuses on making existing systems more secure 2 We have not verified the cryptographic integrity of any of these automatic update mechanisms.</p><p>without breaking compatibility or compromising performance. Dr.Cowan has co-authored 34 refereed publications, including those describing the StackGuard compiler for defending against buffer overflow attacks. He can be reached via email at crispin@wirex.com .</p><p>Adam Shostack is currently on sabbatical from his role as Most Evil Genius for Zero-Knowledge systems. Prior to that, he was director of technology for Netect, Inc, where he built vulnerability scanners. He has published on topics including cryptography,p rivacy,a nd the economics of security and privacy.H e can be reached via email at adam@homeport.org.</p><p>Perry Wagle received his M.Sc. in Computer Science at Indiana University in 1995, then dabbled in evolutionary biology until 1997, when he headed to the Oregon Graduate Institute to join the Immunix project'ss urvivability research. For Immunix, he was, among a number of things, the primary programmer of the first released version of the StackGuard enhancement to GCC. When Immunix spun offinto the WireX startup in 1999, he generated a second version of StackGuard, but stayed at OGI to work on the Infosphere project and is still participating in the Timber project there. He recently joined WireX to research various compiler enhancements to building secure Linux distributions, including a third and never-again version of StackGuard. He can be reached via email at wagle@wirex.com .</p><p>Chris Wright is one of the maintainers of the Linux Security Module project. He has been with the project since its inception and is helping guide LSM into the mainstream Linux kernel. He is employed by WireX where he gets to do security research and Linux kernel hacking. He can be reached via email at chris@wirex.com .</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Ross</forename><surname>Anderson</surname></persName>
		</author>
		<title level="m">Security Engineering: A Guide to Building Dependable Distributed Systems</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons, Inc</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page">372</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Why Information Security is Hard -An Economic Perspective</title>
		<author>
			<persName><forename type="first">Ross</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">17th Annual Computer Security Applications Conference (ACSAC)</title>
		<meeting><address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-12">December 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">E</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rpm</forename><surname>Maximum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>R ed Hat Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Trend Analysis of Exploitations</title>
		<author>
			<persName><forename type="first">Hilary</forename><forename type="middle">K</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Arbaugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Mchugh</surname></persName>
		</author>
		<author>
			<persName><surname>Fithen</surname></persName>
		</author>
		<ptr target="http://www.cs.umd.edu/Ëœwaa/pubs/CS-TR-4200.pdf" />
	</analytic>
	<monogr>
		<title level="m">InProceedings of the 2001 IEEE Security and Privacy Conference</title>
		<meeting><address><addrLine>Oakland, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-05">May 2001</date>
			<biblScope unit="page" from="214" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<ptr target="http://www.caldera.com/support/security/" />
		<title level="m">Caldera Security Advisories</title>
		<imprint>
			<publisher>Caldera, Inc</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">C</forename><surname>Certc Oordination Center</surname></persName>
		</author>
		<author>
			<persName><surname>Erta</surname></persName>
		</author>
		<author>
			<persName><surname>Ca</surname></persName>
		</author>
		<ptr target="http://www.cert.org/advisories/CA-2001-19.html" />
	</analytic>
	<monogr>
		<title level="j">Code Red&apos;&apos;W orm Exploiting Buffer Overflow In IIS Indexing Service DLL</title>
		<imprint>
			<date type="published" when="2001-08-19">2001-19. August 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An Informal Analysis of Ve ndor Acknowledgement of Vulnerabilities</title>
		<author>
			<persName><forename type="first">S</forename><surname>Christey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<ptr target="http://www.securityfocus.com/cgi-bin/archive.pl?id=1&amp;mid=168287" />
	</analytic>
	<monogr>
		<title level="j">Bugtraq Mailing List</title>
		<imprint>
			<date type="published" when="2001-03">March 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Security Advisory: Cisco Content Services Switch Vulnerability</title>
		<ptr target="ttp://www.cisco.com/warp/public/707/arrowpoint-cli-filesystem-pub.shtml" />
		<imprint>
			<date type="published" when="2001-04">April 2001</date>
			<publisher>Cisco Systems, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Crispin</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Beattie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Calton</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Perry</forename><surname>Wagle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Virgil</forename><surname>Gligor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ubdomain</surname></persName>
		</author>
		<title level="m">Parsimonious Server Security, USENIX 14th Systems Administration Conference (LISA)</title>
		<meeting><address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-12">December 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The Forensic Challenge</title>
		<author>
			<persName><forename type="first">Dave</forename><surname>Dittrich</surname></persName>
		</author>
		<ptr target="ttp://project.honeynet.org/challenge/" />
		<imprint>
			<date type="published" when="2001-01">January 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Shall WeD ust Moscow? Security Survey of Key Internet Hosts &amp; Various Semi-Relevant Reflections</title>
		<author>
			<persName><forename type="first">D</forename><surname>Farmer</surname></persName>
		</author>
		<author>
			<persName><surname>An</surname></persName>
		</author>
		<ptr target="ttp://www.fish.com/survey/" />
		<imprint>
			<date type="published" when="1996-12">December 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Secure Environment for Untrusted Helper Applications</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><surname>Brewer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th USENIX Security Conference</title>
		<meeting><address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-07">July 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">SAM: Security Adaptation Manager</title>
		<author>
			<persName><forename type="first">Heather</forename><forename type="middle">M</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Crispin</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lois</forename><surname>Delcambre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shawn</forename><surname>Bowers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Computer Security Applications Conference (ACSAC),P hoenix</title>
		<meeting><address><addrLine>AZ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-12">December 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m">The Honeynet Project, Know Your Enemy: Revealing the Security Tools, Tactics and Motives of the BlackHat Community,A ddison Wesley</title>
		<meeting><address><addrLine>Boston</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">An Analysis of Security Incidents on the Internet 1989 -1995</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">D</forename><surname>Howard</surname></persName>
		</author>
		<ptr target="ttp://www.cert.org/research/JHThesis/Start.html" />
		<imprint>
			<date type="published" when="1997-10">October 1997</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note>P h.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Managing Vulnerabilities in Networked Systems</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">A</forename><surname>Martin</surname></persName>
		</author>
		<ptr target="http://cve.mitre.org/" />
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Society COMPUTER Magazine</title>
		<imprint>
			<biblScope unit="page" from="32" to="38" />
			<date type="published" when="2001-11">November 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the Elicitation of Preferences for Alternative Therapies</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Mcneil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Pauker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New England Journal of Medicine</title>
		<imprint>
			<biblScope unit="issue">306</biblScope>
			<biblScope unit="page" from="1259" to="1262" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automatic Update Featurei nW indows XP</title>
		<ptr target="ttp://support.microsoft.com/directory/article" />
	</analytic>
	<monogr>
		<title level="m">asp?ID=KB;EN-US;Q294871</title>
		<imprint>
			<publisher>Microsoft</publisher>
			<date type="published" when="2001-10">October 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<ptr target="http://www.microsoft.com/technet/security/bulletin/MS01-031.asp?frame=true" />
		<title level="m">Microsoft Security Bulletin MS01-031 Predictable Name Pipes Could Enable Privilege Elevation via Telnet</title>
		<imprint>
			<publisher>Microsoft Corporation</publisher>
			<date type="published" when="2001-06">June 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Nimda Worm Shows You Can&apos;t Always Patch Fast Enough</title>
		<author>
			<persName><forename type="first">John</forename><surname>Pescatore</surname></persName>
		</author>
		<ptr target="ttp://www.gartner.com/DisplayDocument?id=340962" />
		<imprint>
			<date type="published" when="2001-09">September 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Microsoft: Who Solves Security Problems Faster?</title>
		<author>
			<persName><forename type="first">Jim</forename><surname>Reavis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linux</forename><surname>Vs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000-01">January 2000</date>
		</imprint>
	</monogr>
	<note>no longer available on the web</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<ptr target="https://rhn.redhat.com/help/sm/up2date.html" />
		<title level="m">Red Hat Update Agent</title>
		<imprint>
			<publisher>Red Hat, Inc</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Schneier</surname></persName>
		</author>
		<author>
			<persName><surname>Ruce</surname></persName>
		</author>
		<ptr target="http://www.counterpane.com/crypto-gram-0009" />
		<title level="m">Full Disclosurea nd the Window of Exposure</title>
		<imprint>
			<date type="published" when="2000-09">September 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A ct I, Scenes 3 and 4</title>
		<author>
			<persName><forename type="first">William</forename><surname>Shakespeare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamlet</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1946">1946</date>
			<publisher>F.S.Crofts &amp; Co</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><surname>Noronha</surname></persName>
		</author>
		<ptr target="http://www.debian.org/doc/manuals/apt-howto/index.en.html" />
		<title level="m">Debian APT Howto</title>
		<imprint>
			<date type="published" when="2001-09">September 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Flash Worms: Thirty Seconds to Infect the Internet</title>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Staniford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gary</forename><surname>Grim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roelof</forename><surname>Jonkman</surname></persName>
		</author>
		<ptr target="ttp://www.silicondefense.com/flash/" />
		<imprint>
			<date type="published" when="2001-08">August 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><surname>Van Doorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerco</forename><surname>Leendert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">A</forename><surname>Ballintijn</surname></persName>
		</author>
		<author>
			<persName><surname>Arbaugh</surname></persName>
		</author>
		<idno>UMD CS-TR-4259</idno>
		<title level="m">Signed Executables for Linux</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>University of Maryland</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">T echnical Report</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Nicholas</forename><forename type="middle">C</forename><surname>Weaver</surname></persName>
		</author>
		<ptr target="ttp://www.cs.berkeley.edu/Ëœnweaver/warhol.html" />
		<title level="m">Warhol Worms: The Potential for Very Fast Internet Plagues</title>
		<imprint>
			<date type="published" when="2001-08">August 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Ximian</forename><surname>Inc</surname></persName>
		</author>
		<title level="m">Ximian Red Carpet Automated Soft-wareM aintenance and Version Management</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
