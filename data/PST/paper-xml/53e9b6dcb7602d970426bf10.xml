<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Locality-constrained and Spatially Regularized Coding for Scene Categorization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Aymen</forename><surname>Shabou</surname></persName>
							<email>aymen.shabou@cea.frherve.le-borgne@cea.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Hervé Le Borgne CEA, LIST, Vision &amp; Content Engineering Laboratory Gif-sur-Yvettes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Locality-constrained and Spatially Regularized Coding for Scene Categorization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DA4C3820F11E1B25EBC166A73CB96906</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Improving coding and spatial pooling for bag-of-words based feature design have gained a lot of attention in recent works addressing object recognition and scene classification. Regarding the coding step in particular, properties such as sparsity, locality and saliency have been investigated. The main contribution of this work consists in taking into acount the local spatial context of an image into the usual coding strategies proposed in the state-ofthe-art. For this purpose, given an imgae, dense local features are extracted and structured in a lattice. The latter is endowed with a neighborhood system and pairwise interactions. We propose a new objective function to encode local features, which preserves locality constraints both in the feature space and the spatial domain of the image. In addition, an appropriate efficient optimization algorithm is provided, inspired from the graph-cut framework. In conjunction with the maximum-pooling operation and the spatial pyramid matching, that reflects a global spatial layout, the proposed method improves the performances of several state-of-the-art coding schemes for scene classification on three publicly available benchmarks (UIUC 8-sport, Scene-15 and Caltech-101).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent works addressing object recognition and scene classification tasks, the bag-of-words (BoW) is one of the most popular model for feature design. Inspired by the seminal work of <ref type="bibr" target="#b25">[26]</ref>, different approaches have been proposed to improve both its generative property to describe accurately images and its discriminatory power for classification. Despite remarkable progresses, it remains challenges concerning the extraction of local descriptors, codebook design, local descriptors coding and pooling, including a spatial layout into the final feature, and the final classification.</p><p>Given a training dataset, the first step of the BoW method consists in extracting local features, such as SIFT <ref type="bibr" target="#b20">[21]</ref>, HOG <ref type="bibr" target="#b7">[8]</ref> and SURF <ref type="bibr" target="#b0">[1]</ref>, from images. Then a codebook (or</p><formula xml:id="formula_0">X p X q X r</formula><p>1. Locality-constrained assignement 2. Locality-constrained and spatially regularized assignement 1 2 { X p X q X r : Local features 0.9: similarity between X p , X q 0.9 0.7</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X p X q X r</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spatial domain of dense local features</head><p>Codebook 0.7: similarity between X p , X r</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Selected visual word</head><p>Visual word <ref type="bibr">Figure 1</ref>. Schematic comparison of basis selection methods to code dense descriptors. The first configuration is the one adopted by some recent coding approaches <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b19">20]</ref>. The second configuration corresponds to the proposed LCSR method.</p><p>a dictionary), which is a set of visual words, is built to represent them. Initial methods are based on clustering techniques, such as K-means <ref type="bibr" target="#b25">[26]</ref>. Despite their efficiency, the obtained codebooks suffer from several drawbacks such as distortion errors and low discriminative ability <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b27">28]</ref>. A more appropriate unsupervised dictionary learning method is sparse coding which aims to learn an over-complete codebook ensuring sparse representation of local descriptors <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b21">22]</ref>. However, this approach is computationally expensive even if progress was made toward accelerating the process <ref type="bibr" target="#b15">[16]</ref>. Other approaches have rather attempted to improve the discriminative power of the codebook while compacting it relying on supervised methods <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b1">2]</ref>. However, recent works of <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b23">24]</ref> show that, for the recognition task, codebook design is less critical than the next stages (coding, pooling and spatial layout).</p><p>Coding consists in decomposing local features over a codebook in order to satisfy some desirable properties. Various strategies are proposed in the literature. The earliest one is the hard coding <ref type="bibr" target="#b25">[26]</ref>, a voting scheme that is simple yet highly sensitive to reconstruction errors induced by the codebook. A more robust voting approach is the soft coding <ref type="bibr" target="#b27">[28]</ref>, which assigns a descriptor to all the visual words according to their distances. Sparse coding is an alternative <ref type="bibr" target="#b31">[32]</ref> that is time consuming and which is, moreover, non-consistent to encode similar descriptors <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b10">11]</ref>. Authors of <ref type="bibr" target="#b32">[33]</ref> introduced another coding property, called locality, that ensures sparsity while remaining efficient. Several implementations have been proposed by <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b19">20]</ref>, where each descriptor is coded on locally selected bases. Note also that in <ref type="bibr" target="#b11">[12]</ref>, the authors give another explanation about the success of the locality coding, which is saliency. Indeed, for a given descriptor and corresponding local bases, the closer the nearest visual word to the descriptor in comparison to the remaining local bases, the stronger its coding response should be.</p><p>The next step of BoW design is pooling the obtained codes to obtain a compact signature. Usually, the maxpooling operation is used, leading to signatures that are appropriate to linear classifiers <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b19">20]</ref>. Finally, the Spatial Pyramid Matching (SPM) step, proposed in <ref type="bibr" target="#b14">[15]</ref>, is usually exploited to include some spatial layout information to the BoW. Such vectors of fixed size can then feed a machine learning algorithm such as SVM <ref type="bibr" target="#b6">[7]</ref> or Boosting <ref type="bibr" target="#b24">[25]</ref>.</p><p>In the current work, the local feature coding step is investigated. While several techniques have outperformed the classic hard assignment by introducing either the locality or the similarity constraints in the feature space <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b10">11]</ref>, we propose a new formalism that implicitly preserves these properties while adding the local contextual information from the spatial domain of the image. Figure <ref type="figure">1</ref> shows a schematic comparison.</p><p>The proposed coding approach is divided into two steps.</p><p>1. The first step is an optimal basis selection for each local feature, formulated as a labeling problem. For this purpose, we introduce a novel objective function that includes locality and similarity (or coherency) constraints in both the feature space and the spatial domain of the image. Furthermore, we provide an appropriate efficient optimization algorithm, called α knnexpansion, which is inspired from the fast optimization tools dedicated to Markov Random Field (MRF) based energy minimization task <ref type="bibr" target="#b3">[4]</ref>.</p><p>2. The second step consists in assigning responses (or values) to the selected optimal bases. This new approach enriches the BoW signature leading to more accurate features for classification than the state-of-the-art methods. Furthermore, it is generic and can thus be added to several recent coding strategies. The remainder of this paper is as follows. In section 2, some details about related work to the coding step within the BoW feature generation framework are discussed. The new coding strategy is introduced in section 3. Section 4 highlights experimental studies and results on the following benchmarks: UIUC 8-sport <ref type="bibr" target="#b16">[17]</ref> and scenes-15 <ref type="bibr" target="#b14">[15]</ref> for event and scene classification respectively and Caltech-101 <ref type="bibr" target="#b8">[9]</ref> for object recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Let us consider a codebook denoted by B = {b i ; b i ∈ d ; i ∈ N ; N = 1, ..., K}, with |N | = K the size of the codebook and d the dimensionality of a visual word (or a basis vector). The codebook is constructed on a subset of local descriptors {x i ; x i ∈ d ; i = 1, ..., N } extracted from the training dataset.</p><p>In the original BoW method <ref type="bibr" target="#b25">[26]</ref>, coding local descriptors is performed with hard assignment. Each local descriptor is assigned to the nearest visual word, i.e.,</p><formula xml:id="formula_1">z i,j =    1 if j = argmin j=1,...,K ||x i -b j || 2 2 ,<label>0 otherwise, (1)</label></formula><p>with z i the code of size K associated to the descriptor x i .</p><p>As reported in <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b27">28]</ref>, such coding has several limitations, mainly the sensitivity to distortion errors of the codebook. Using sparse coding <ref type="bibr" target="#b31">[32]</ref> as an alternative has significantly improved its robustness to these problems. Therefore, coding is performed by solving the l 1 -norm regularized approximate problem:</p><formula xml:id="formula_2">z i = argmin z∈ K ||x i -Bz|| 2 2 + λ||z|| 1 , λ ∈ .<label>(2)</label></formula><p>Nevertheless, this optimization problem is computationally expensive and leads to non consistent encoding of similar descriptors <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b10">11]</ref>. Indeed, it might select different bases for similar descriptors due to the over-completeness of the codebook, which results in large deviations in representing similar local features. Therefore, authors of <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b19">20]</ref> propose more efficient and consistent coding methods relying on the locality property introduced by <ref type="bibr" target="#b32">[33]</ref>. Their hypothesis is that descriptors approximately reside on a lower dimensional manifold in an ambient descriptor space. Then, using Euclidean distances for assigning descriptors to visual words is only meaningful within a local region. Hence, local bases are selected to perform the coding. The generalized formulation of the locality constrained coding (LCC) problem is the following:</p><formula xml:id="formula_3">z i = argmin z∈ K ||x i -Bz|| 2 2 + λ||d i z|| 2 2 , s.t. 1 T z i = 1 ,<label>(3)</label></formula><p>with</p><formula xml:id="formula_4">d i = exp( dist(xi,B) σ ), dist(x i , B) = [dist(x i , b 1 ), ..., dist(x i , b K )]</formula><p>T the Euclidean distances between x i and the basis vectors; and σ a parameter controlling the weight decay speed for the locality.</p><p>An alternative to improve the consistency of sparse coding has been proposed by <ref type="bibr" target="#b10">[11]</ref>. It consists in adding the Laplacian matrix to the objective function <ref type="bibr" target="#b1">(2)</ref> to perform codebook learning as well as coding local features, i.e., argmin</p><formula xml:id="formula_5">B,Z ||X -BZ|| 2 2 + λ i ||z i || 1 + βtr(ZLZ T ) , s.t. ||b j || 2 ≤ 1 , ∀j ∈ N ,<label>(4)</label></formula><p>with L = A -W the Laplacian matrix obtained form the similarity matrix W encoding the relationship between local features and A m,m = n W m,n . Due to the extremely high number of local descriptors in a dataset, constructing the Laplacian matrix and learning sparse codes simultaneously is computationally infeasible. A restriction to a selected set of local features, called template features, was necessary. But this technique is still computationally expensive due to the search of the k-nearest template features followed by the similarity constrained sparse coding. Salient coding <ref type="bibr" target="#b11">[12]</ref> is another alternative approach that has shown interesting results while remaining efficient. It exploits the locality constraint to replace the conventional hard assignment in (1) with a saliency degree regarding the nearest bases b j to x i , which is defined as:</p><formula xml:id="formula_6">ψ i,j = φ ||x i -b j || 2 2 1 k-1 k m =j ||x i -bm || 2 2 ,<label>(5)</label></formula><p>where φ(.) is a monotonically decreasing function and { bm } m=1,...,k is the set of the k-nearest bases to x i . Salient coding improves the consistency of the locality coding when it is performed on a small number of local bases compared to the dimension of the descriptors. All the aforementioned coding schemes are applied on local features independently, except for the Laplacian sparse coding, where a global similarity between local features is considered to constrain sparsity. However, dense local features share some contextual information locally in the spatial domain of a given image. This could be seen simply by computing a local pairwise similarity map between local features extracted from a given image, that shows local correlations in some regions of the image (see figure <ref type="figure" target="#fig_3">4</ref>). Discarding this contextual information in the coding step would induce codes that are non-consistent in term of contextual spatial information, and also less reliable when the spatial pooling operation is conducted to design the final signature. In the same figure, we can show indexes of bases assigned to local features (as colored maps) using localityconstrained hard and soft coding strategies. We note that considering the local spatial information improves the consistency of the coding regarding to the context of the image.</p><p>To our knowledge, introducing the local contextual information in the coding step of the BoW approach has not been proposed in any of the previous works. In the next section, we propose a robust and fast method to achieve this type of coding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Locality-constrained and spatially regularized coding</head><p>We propose here an energy based formulation to achieve a robust basis selection, required to encode dense local features of a given image. Then, a new fast resolution algorithm is provided relying on the graph-cut framework. Finally, we present the additional operations required to generate the final BoW signature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Energy model</head><p>Considering the Markovian assumption on a given image I, we can assume that neighboring patches within a constant or a smooth region of an image have to be coded on shared, or even similar bases from the codebook. In contrast, for neighboring patches within a discontinuous region, the corresponding local bases can be different, depending on the local descriptor information.</p><p>Such an assumption leads to some interesting properties on the final coding:</p><p>• less noisy assignment considering the local contextual spatial information;</p><p>• saliency property is extended to take into account the spatial neighborhood;</p><p>• coding similar descriptors is consistent with the Markovian prior assumed on images.</p><p>In order to obtain a robust basis selection following the proposed spatial assumption as well as the locality assumption stated in <ref type="bibr" target="#b32">[33]</ref>, we reformulate the problem as a labeling one. Formally, let us consider an image I. We denote by P = {1, ..., N I } the set of indexes of dense patches (or more generally sites) in I. A set of local features X = {x p ; x p ∈ d ; p ∈ P} is extracted from I at all sites. Given a codebook B = {b i ; b i ∈ K ; i ∈ N }, we consider that each local feature is assigned to a subset of basis vectors, with cardinality m, belonging to the codebook. For simplicity of notations, a local feature x p is assigned to a set of indexes y p of bases in B. Therefore, Y = {y p ; y p ∈ N m ; p ∈ P} denotes the assignment of all the local features of the image I. In the LCC case for instance, each vector y p reflects the indexes of the mnearest visual words to x p . The set of basis vectors related to the indexes in y p is denoted Bp = { bp,i ; i = 1, ..., m}, and we define B = { Bp ; p ∈ P}. We also denote by L p = {l 1 p , l 2 p , ..., l k p } the set of indexes of the k-nearest visual words to a local feature x p and call it the set of possible labels that a site p can take.</p><p>Following the locality assumption, each local feature should be assigned to bases of cardinality m within the set of the k-nearest visual words in the codebook (k is set large enough to consider a large neighborhood in the feature space, i.e., k &gt; m).</p><p>The labeling problem we consider here consists in retrieving optimal basis for each local feature among the knearest ones, under the spatial contextual constraint. As a result, the locality assumptions both in the feature space and in the spatial domain of the image would be enforced. We introduce the following energy function to model the current problem:</p><formula xml:id="formula_7">E(Y) = p∈P f data (x p , Bp ) Ep(yp) E data +β p∼q w p,q f prior ( Bp , Bq ) Ep,q(yp,yq) Eprior ,<label>(6)</label></formula><p>where</p><formula xml:id="formula_8">• f data (x p , Bp )) = m i=1 ||x p -bp,i || 2</formula><p>2 is the total distance between a descriptor x p and its m selected bases;</p><p>• p ∼ q indicates the indexes of two spatially neighboring patches under a fixed neighboring system (the grid of 4-nearest neighbors for instance);</p><formula xml:id="formula_9">• f prior ( Bp , Bq ) = m i=1 || bp,i -bq,i</formula><p>|| is a sum of the distances between the bases assigned to neighboring patches x p and x q ;</p><p>• w p,q is a local regularization parameter that corresponds to the similarity between local patches x p and x q . The more similar the local patches are, the higher we regularize the basis selection operation. Among the existing similarity measures of local features, we consider the histogram intersection kernel <ref type="bibr" target="#b30">[31]</ref>, denoted by K(., .), since it has shown interesting performances when dealing with histogram based local features. We set the local hyper-parameters as the following:</p><formula xml:id="formula_10">w p,q = K(x p , x q ) if K(x p , x q ) ≥ T , 0 otherwise. (<label>7</label></formula><formula xml:id="formula_11">)</formula><p>On the one hand, this binary form of local hyperparameters ensures regularization only on similar neighboring patches, above a similarity threshold T . On the other hand, it reduces the sensitivity of the model to the global regularization parameter β;</p><p>E data is then a likelihood term that penalizes assigning visual words far from descriptors, whereas E prior is a prior term that penalizes assigning different visual words to similar neighboring patches. Minimizing (6) leads to an optimal assignment configuration:</p><formula xml:id="formula_12">Ỹ = argmin Y E(Y|X, B, W) .<label>(8)</label></formula><p>We shall note that some particular cases of the proposed energy function lead to the state-of-the-art basis selection required for the coding, e.g.,</p><p>• β = 0 and m = 1: hard and salient coding <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b11">12]</ref>,</p><p>• β = 0 and m &gt; 1: approximate LCC as implemented in <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b19">20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Fast optimization algorithm</head><p>The proposed energy function ( <ref type="formula" target="#formula_7">6</ref>) is non-convex for general forms of distance functions f prior and f data . Its minimization can be performed efficiently inspiring with fast optimization tools dedicated to pairwise multi-label MRF energies <ref type="bibr" target="#b17">[18]</ref>. In particular, the graph-cut approach has been successfully used to efficiently solve many labeling problems in computer vision <ref type="bibr" target="#b26">[27]</ref>. One of the most popular iterative graph-cut based approximate multi-label optimization algorithms is the α-expansion <ref type="bibr" target="#b3">[4]</ref>, which relies on iterative binary moves of the desired configuration <ref type="bibr" target="#b28">[29]</ref>. At a given iteration (i), each site can keep its current label or change it to a new one α (i) ∈ L, with L a discrete set of labels. This binary move is performed optimally by building an appropriate graph where a minimum-cut/maximum-flow is computed <ref type="bibr" target="#b9">[10]</ref>. Several binary partition moves are iterated until convergence to a local optimum of the energy. Such large partition moves efficiently reach good local optima of nonconvex energy functions. Besides its effectiveness, it can be applied to various labeling problem, even with unordered labels.</p><p>To solve the optimization problem (8), we propose an appropriate optimization algorithm extending the α-expansion in two directions. On the one hand, it deals with vectorial labels, i.e., a finite set of labels is assigned to each site. On the other hand, we constrain each site to take a label within an associated subset of labels, that can change from one site to another. The proposed optimization algorithm will be called α knn -expansion. It performs, at each iteration, a binary expansion move to a set of labels α = {α 1 , α 2 , ..., α m } ∈ N m only for a subset of sites S α ⊂ P that have α within the set of the k-nearest visual words indexes, i.e., S α = {p ∈ P ; such that α ⊂ L p }. These sites are called active sites. Thereby, at each iteration of the optimization algorithm, a global binary move of all active sites is performed. Binary moves are iterated for a number of vectorial labels {α 1 , α 2 , ..., α n } within a cycle. If the energy decreases, a new cycle is started, until convergence to a local optimum (figure <ref type="figure" target="#fig_0">2</ref>). We note that a possible Input: Y (0) , W, B, X Output: Ŷ</p><p>For each cycle c do 1. Select n vectors of labels {αi} n i=1 within the set of k-nearest basis indexes to the local features 2. For each iteration i ≤ n do (a) Perform an optimal binary expansion move to αi: initialization Y (0) could be the m-nearest bases, as used for LCC.</p><formula xml:id="formula_13">Y (i) = argmin Y E(Y|X, B, W) , such that: y (i) p ∈ {y (i-1) p , αi} , ∀p ∈ P (b) Ỹ := Y (i) 3. If E( Ỹ) &lt; E(Y (c-1) ) , Then Y (c) := Ỹ Else return Ỹ</formula><p>In order to achieve an optimal binary move (step 2.a in figure <ref type="figure" target="#fig_0">2</ref>), a directed graph G α = (A α , E α ) is built, where A α is a set of nodes related to active sites and E α is a set of oriented edges connecting neighboring nodes. Two auxiliary nodes s and t are added for the maximum-flow computation. Based on the efficient graph construction originally proposed in <ref type="bibr" target="#b12">[13]</ref> for the α-expansion, a graphical illustration of the graph topography for the proposed α knnexpansion move as well as the capacities on edges are described in figure <ref type="figure" target="#fig_2">3</ref>.</p><p>Once the graph is constructed, the maximum-flow is computed in a polynomial time due to the sub-modular property of the proposed energy function <ref type="bibr" target="#b12">[13]</ref>. Indeed, for a binary expansion move, the sub-modularity constraint on the energy function is verified for any likelihood terms and metric prior terms <ref type="bibr" target="#b3">[4]</ref>. This is the case of ( <ref type="formula" target="#formula_7">6</ref>), since we are using a metric as a priori to compute distances between optimal bases. The efficient polynomial time maximumflow algorithm, proposed by <ref type="bibr" target="#b12">[13]</ref> 1 , is well suited to gridstructured graphs, and thus to our problem. Additionally, minimizing <ref type="bibr" target="#b5">(6)</ref> with the proposed α knn -expansion algorithm is fast, since expansion moves are restricted to active sites only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Coding and pooling</head><p>Once optimal bases are selected, assigning a response to each one of the basis vector can be achieved with various strategies. We consider recent strategies in the literature, namely hard responses <ref type="bibr" target="#b14">[15]</ref>, salient responses <ref type="bibr" target="#b11">[12]</ref> and soft responses either by solving a linear system <ref type="bibr" target="#b29">[30]</ref> or by com-1 http : //pub.ist.ac.at/ ∼ vnk/sof tware.html </p><formula xml:id="formula_14">p q r E s → p E s → q E p → t E q → t E p → q</formula><p>E s→p E p (y p ) + E p,q (y p , y q ) E p→t E p (α) + E p,q (α, y q ) E p→q E p,q (y p , α) + E p,q (α, y q ) -E p,q (y p , y q ) E s→q E p,q (α, y q ) + E q (y q ) + E q,r (y q , y r ) E q→t E q (α) + E q,r (α, y r ) puting a posteriori probabilities of local features belonging to the selected optimal bases <ref type="bibr" target="#b19">[20]</ref>.</p><p>For each image, the obtained codes are then aggregated with a max-pooling operation, following recent works <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b19">20]</ref>, resulting in a unique and compact signature vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental results</head><p>In this section the proposed approach is tested for scene classification and object recognition tasks and evaluated on three well known benchmarks, intensively used in the literature <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b19">20]</ref>: UIUC 8-sport <ref type="bibr" target="#b16">[17]</ref>, 15-natural scenes <ref type="bibr" target="#b14">[15]</ref> and Caltech-101 object categories <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Pipeline</head><p>In all the experiments we conduct, the same processing chain is considered following the literature settings to ensure consistency. The pipeline is as follows:</p><p>• dense local features (SIFTs) of size 128 are extracted within a regular spatial grid, and only one scale from images downsized to no more than 300 × 300 pixels (resp. 400 × 400 pixels) for 15-natural scenes (resp. UIUC 8-sport). The step-size is fixed to 4 pixels and patch size to 16 × 16 pixels;</p><p>• a codebook of size 1024 is created using the K-means clustering method on a randomly selected subset of SIFTs belonging to the training dataset (∼ 10 5 SIFTs); { (w h p,q ) 2 + (w v p,q ) 2 ; p ∼ q ; (p, q) ∈ P 2 } to zero under the threshold T = 0.7 , (d) the conventional hard assignment (color map corresponds to indexes of selected visual words from the codebook) , (e) 3-nearest bases selected for each local feature as performed with LLC (we use a RGB color map to visualize the three visual words indexes for each local patch), spatially regularized (f) hard assignment and (g) LLC based assignment using the proposed approach.</p><p>• for coding we fix the step-size for patch extraction to 4 pixels and patch size to 16 × 16 pixels. Even if the theoretical coding formalism conducted in section 3 concerns patches surrounding all the pixels, using a small step-size does not reduce the consistency of the coding, and accelerates its computation.</p><p>Regarding the computation time required to retrieve the optimal bases, the choice of the two parameters m and k is crucial. In order to accelerate the convergence, we set the number of optimal bases retrieved for each local feature to m = 3 among the k = 10 nearest visual words. It results in a reduced number of possible vectorial labels α i ∈ N 3 to be visited within each cycle of the optimization algorithm. We observed empirically that enlarging the size of the set of retrieved optimal bases improves slightly the classification performances while augmenting the computational time.</p><p>• the max-pooling operation is performed (even with hard assignment codings) and the SPM <ref type="bibr" target="#b14">[15]</ref> with 3 levels 1 × 1, 2 × 2 and 4 × 4 is adopted, leaving a same weight at each layer;</p><p>• a one-vs-all linear SVM classifier is used, since it has shown good performances in categorization when paired with the max-pooling operation <ref type="bibr" target="#b31">[32]</ref>.</p><p>Our method is integrated into several coding schemes, namely hard assignment coding (HC) <ref type="bibr" target="#b14">[15]</ref>, localityconstrained linear coding (LLC) <ref type="bibr" target="#b29">[30]</ref>, saliency coding (SC) <ref type="bibr" target="#b11">[12]</ref> and localized soft assignment coding (LSC) <ref type="bibr" target="#b19">[20]</ref>, showing the improvement achieved when the local spatial context within images is included into the coding process.</p><p>We have to mention that for some of the state-of-the-art works, results shown in the original papers are obtained using different pipelines than that we adopt here. For instance, sparse coding is used as an alternative to the K-means algorithm for learning the codebook in <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b10">11]</ref>, dense SIFTs are extracted with three scales in <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b11">12]</ref>, a mix-order maxpooling operation is applied in <ref type="bibr" target="#b19">[20]</ref>, and the number of the selected local bases varies from 5 to 10, etc. Therefore, in order to achieve fair comparisons to these works and obtain a coherent assessment, it was necessary to conduct all the experiments with the same pipeline and a common implementation. Since source codes of existing methods are not always available, we had to re-implement them and, as it often happens, our engineering choices led to minor performance differences compared to results reported in the original papers. Nevertheless, performances we obtained remain fully consistent with existing works. Our experimental approach, consisting in using a common implementation and pipeline to insure consistency, was also suggested by <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">UIUC 8-sport</head><p>codebook distortions. We note that classification accuracy with such a regularized hard assignment reaches the performances of recent locality based coding methods. On the other hand, it improves the optimal basis selection step required by the locally-constrained coding strategies (LLC, SLC and SC). We note that for the saliency based coding (SC), our approach extends the saliency property originally considered in the feature space only, to cope with the local spatial information. Hence, non-salient patches in the spatial domain of the image will be discarded at the maxpooling step. More discriminative features in term of classrelative salient visual words are obtained, which are well suited to linear classifiers.</p><p>We shall indicate that the LCSR operation is computationally fast and so does not affect the computational time required for several coding methods. As an order of magnitude, for an image of size 256 × 256, leading to 61 × 61 SIFTs, time required to select optimal 3 bases for each SIFT among the 10-nearest bases to each one is less than 1 second using a CPU with a frequency of 2.66 GHz.</p><p>To compare our result to other recent works, we outperform the best classification rate (85.31%) of <ref type="bibr" target="#b10">[11]</ref> with a different and highly computationally demanding pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classification accuracies (%)</head><p>Coding method original approach using the LCSR HC <ref type="bibr" target="#b14">[15]</ref> 79.98 ± 1.67 83.83 ± 1.68 LLC <ref type="bibr" target="#b29">[30]</ref> 81.77 ± 1.51 85.67 ± 1.52 LSC <ref type="bibr" target="#b19">[20]</ref> 82.79 ± 2.01 85.81 ± 1.56 SC <ref type="bibr" target="#b11">[12]</ref> 85.44 ± 1.54 87.23 ± 1.14 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">15-natural scenes</head><p>This dataset <ref type="bibr" target="#b14">[15]</ref> contains 4485 images of 15 scene categories, each one containing 200 to 400 images. Scenes vary from indoor to outdoor environments. Following the standard setup, we use 10 random splits of the data, while considering 100 random images per class for training and the rest for testing. In table 2 classification accuracies using several approaches are provided. Similarly to the previous dataset, adding the spatial context into local feature coding always improves the performances by 2% on average. Classification accuracies (%) Coding method original approach using the LCSR HC <ref type="bibr" target="#b14">[15]</ref> 78.87 ± 0.52 80.80 ± 0.5 LLC <ref type="bibr" target="#b29">[30]</ref> 80.50 ± 0.63 82.35 ± 0.36 LSC <ref type="bibr" target="#b19">[20]</ref> 80.25 ± 0.57 82.67 ± 0.51 SC <ref type="bibr" target="#b11">[12]</ref> 79.21 ± 0.59 81.17 ± 0.5 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Caltech-101</head><p>This dataset <ref type="bibr" target="#b8">[9]</ref> has 101 object categories containing from 31 to 800 images each one. We use 10 random splits of the data, while considering 30 random images per class for training and the rest for testing and provide the average classification rates in table 3. In contrast to the two previous datasets, containing scene images, the current task rather deals with object recognition. Local spatial context is then less relevant for image understanding. Nevertheless, it leads to some improvement in classification accuracies. Indeed, the local spatial information may improve the coding step by reducing assignment errors that are mainly due to some artifacts characterizing images of the current dataset (often resulted from transformations synthetically made on images to evaluate the classification's robustness toward them).</p><p>Classification accuracies (%) Coding method original approach using the LCSR HC <ref type="bibr" target="#b14">[15]</ref> 69.43 ± 0.52 70.17 ± 0.52 LLC <ref type="bibr" target="#b29">[30]</ref> 71.67 ± 0.86 72.04 ± 1.23 LSC <ref type="bibr" target="#b19">[20]</ref> 72.58 ± 1.08 73.23 ± 0.81 SC <ref type="bibr" target="#b11">[12]</ref> 69.55 ± 0.83 70.47 ± 0.75 Table <ref type="table">3</ref>. Classification accuracies on the Caltech-101 data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we presented a promising local feature encoding method that exploits interesting locality properties in both the features space and the spatial domain of the image. Results show that our contribution improves state-ofthe-art coding schemes, increasing the classification rates by ∼ 1% to ∼ 4% on UIUC 8-sport, 15-natural scenes and Caltech-101, using a standard experimental pipeline. Ongoing efforts are devoted to analyze the proposed method in case of multi-label and multi-instance recognition tasks, since incorporating the local spatial information into features would be beneficial to recognize multiple objects in a given image.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. α knn -expansion based optimization algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Illustrative example of the graph construction on an image with 4 × 4 sites. (a) Graph topography to compute one optimal move of the α knn -expansion algorithm for a given label α. Active sites (the gray ones) are connected to the source and sink nodes, whereas black points are non-active sites at the current iteration; (b) detailed construction for two possible neighboring configurations: active-active and active-nonactive with corresponding edge capacities depicted in the table.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Illustrative example of local basis selection required for coding: (a) original image, (b) visualization of extracted dense SIFTs using the method of<ref type="bibr" target="#b18">[19]</ref>, (c) a pairwise local features similarity map for visualization only, obtained by setting the map elements { (w h p,q ) 2 + (w v p,q ) 2 ; p ∼ q ; (p, q) ∈ P 2 } to zero under the threshold T = 0.7 , (d) the conventional hard assignment (color map corresponds to indexes of selected visual words from the codebook) , (e) 3-nearest bases selected for each local feature as performed with LLC (we use a RGB color map to visualize the three visual words indexes for each local patch), spatially regularized (f) hard assignment and (g) LLC based assignment using the proposed approach.</figDesc><graphic coords="6,120.07,158.00,85.03,56.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Classification accuracies on the UIUC 8-sport data set.</figDesc><table><row><cell>Rock</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Climbing Badminton Bocce Croquet Polo Rowing Sailing Snowboardin Rock Climbing Badminton Bocce Croquet Polo Rowing Sailing Snowboardin 95.8 93.5 64.8 84.5 84.7 90 96.5 88</head><label></label><figDesc></figDesc><table /><note><p>Figure 5. Confusion matrix for the UIUC 8-sport data set.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Classification accuracies on the 15-natural scenes data set.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>This dataset contains 8 sport categories for image-based event classification<ref type="bibr" target="#b16">[17]</ref>. There are 1579 images. Each class has 137 to 250 images. Following the standard setting on this data set, we use 10 random splits of the data, we randomly select 70 training images and 60 test images for each category. In table 1, the classification accuracies resulting from the state-of-the-art coding approaches and the use of the proposed LCSR coding method are reported. As we can see, for all the coding strategies, adding the contextual spatial information improves the classification accuracy significantly. On the one hand, it improves the classic hard assignment method (HC) by reducing assignment errors due</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgment: This work has been partially funded by I2S in the context of the project Polinum. We acknowledge support from the French ANR (Agence Nationale de la Recherche) via the YOJI (ANR-09-CORD-104) and PERIPLUS (ANR-10-CORD-026) projects .</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Surf: Speeded up robust features</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning mid-level features for recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A theoretical analysis of feature pooling in vision algorithms</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast approximate energy minimization via graph cuts</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<date type="published" when="2001">2001. 2, 4, 5</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The devil is in the details: an evaluation of recent feature encoding methods</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chatfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The importance of encoding versus training with sparse coding and vector quantization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICMA</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Support-vector networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVIU</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Classic papers in combinatorics</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Ford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Fulkerson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
	<note>Maximal flow through a network</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Local features are not lonely -Laplacian sparse coding for image classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007">2010. 2, 3, 6, 7</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Salient coding for image classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007">2011. 1, 2, 3, 4, 5, 6, 7</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">What energy functions can be minimized via graph cuts?</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>PAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Supervised learning of quantizer codebooks by information loss minimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raginsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006">2006. 2, 4, 5, 6, 7</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Efficient sparse coding algorithms</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Battle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">What, where and who? classifying events by scene and object recognition</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<title level="m">Markov random field modeling in image analysis</title>
		<imprint>
			<publisher>Springer-Verlag New York Inc</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sift flow:dense correspondence across scenes and its applications</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">In defense of softassignment coding</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007">2011. 1, 2, 4, 5, 6, 7</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distinctive image features from scaleinvariant keypoints</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Discriminative learned dictionaries for local image analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Sparse coding with an overcomplete basis set: A strategy employed by v1? Vision research</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Are sparse representations really relevant for image classification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rigamonti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lepetit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The strength of weak learnability. Machine learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Video google: A text retrieval approach to object matching in videos</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2003">2003. 1, 2, 4</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A comparative study of energy minimization methods for Markov random fields with smoothness-based priors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tappen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><surname>Van Gemert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Veenman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Geusebroek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual word ambiguity</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Efficient Graph-Based Energy Minimization</title>
		<author>
			<persName><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>Cornell University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Locality-constrained linear coding for image classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007">2010. 1, 2, 4, 5, 6, 7</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Beyond the Euclidean distance: Creating effective visual codebooks using the histogram intersection kernel</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Linear spatial pyramid matching using sparse coding for image classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Nonlinear learning using local coordinate coding</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
