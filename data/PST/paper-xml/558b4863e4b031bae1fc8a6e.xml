<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robust Local Optical Flow for Feature Tracking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Student Member, IEEE, Volker Eiselein</roleName><forename type="first">Tobias</forename><surname>Senst</surname></persName>
							<email>senst@nue.tu-berlin.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Communication Systems Group</orgName>
								<orgName type="institution">Technische Universität Berlin</orgName>
								<address>
									<postCode>10623</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Student Member, IEEE</roleName><forename type="first">Thomas</forename><surname>Sikora</surname></persName>
							<email>sikora@nue.tu-berlin.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Communication Systems Group</orgName>
								<orgName type="institution">Technische Universität Berlin</orgName>
								<address>
									<postCode>10623</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Robust Local Optical Flow for Feature Tracking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E30C08C0BD1A002E75E83527B3247753</idno>
					<idno type="DOI">10.1109/TCSVT.2012.2202070</idno>
					<note type="submission">received July 20, 2011; revised November 29, 2011; accepted June 1, 2012. Date of publication June 1, 2012; date of current version August 30, 2012.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T10:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Feature tracking</term>
					<term>Hampel</term>
					<term>Kanade-Lucas-Tomasi (KLT)</term>
					<term>long-term trajectories</term>
					<term>optical flow</term>
					<term>robust estimation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper is motivated by the problem of local motion estimation via robust regression with linear models. In order to increase the robustness of the motion estimates, we propose a novel robust local optical flow approach based on a modified Hampel estimator. We show the deficiencies of the least squares estimator used by the standard Kanade-Lucas-Tomasi (KLT) tracker when the assumptions made by Lucas-Kanade are violated. We propose a strategy to adapt the window sizes to cope with the generalized aperture problem. Finally, we evaluate our method on the Middlebury and MIT dataset and show that the algorithm provides excellent feature tracking performance with only slightly increased computational complexity compared to KLT. To facilitate further development, the presented algorithm can be downloaded from http://www. nue.tu-berlin.de/menue/forschung/projekte/rlof.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Introduction</head><p>T HE COMPUTATION of 2-D image velocities, or optical flow, is a common topic in computer vision. Our challenge is to estimate the scene or object motion as precisely and computationally efficiently as possible. Common optical flow techniques exploit two constraints: data conservation and spatial coherence. Data conservation is derived from the observation that the observed objects generally persist in time. Thus, the intensity of a small region in two consecutive images remains constant, although its position is changing. This leads to the mathematical formulation of the intensity constancy assumption as follows: I(x, y, t) = I(x + uδt, y + vδt, t + δt) <ref type="bibr" target="#b0">(1)</ref> with I(x, y, t) as the image intensity of a grayscaled image, d = (u, v) T denoting the displacement of a point, and δt as a small time difference at a position x = (x, y). Different approaches to solve this equation have been described widely in the literature <ref type="bibr" target="#b0">[1]</ref>. The most successful methods to compute d use a linearization of (1) performed by a first-order Taylor approximation and are therefore gradient based. This leads to an underdetermined linear system. To solve this system, two kinds of spatial coherence conditions have been introduced and established: the techniques of global and local gradient-based approach. By introducing an additional global constraint, Horn and Schunck <ref type="bibr" target="#b1">[2]</ref> applied a soft spatial coherence forcing the partial derivatives of neighboring motion vectors to be minimal. A strong spatial coherence was introduced by Lucas and Kanade <ref type="bibr" target="#b2">[3]</ref> that is categorized as local constraint expecting the motion in a small region to be constant. These assumptions are simplifications and hence may be violated in practice. For example, motion boundaries violate the common assumption that the optical flow varies smoothly. As described by Black and Anandan <ref type="bibr" target="#b3">[4]</ref>, the violations result in gross measurement errors that are referred to as outliers. Since Horn-Schunck and Lucas-Kanade penalized the minimization in a quadratic way, the model does not handle outliers robustly. Black and Anandan <ref type="bibr" target="#b4">[5]</ref> proposed a robust estimation framework exploiting the Lorentzian robust norm.</p><p>Most of the state-of-the-art global optical flow methods are using robust estimation frameworks. Common norms are the modified L 1 , which is successfully used in different solutions, e.g., by Brox et al. <ref type="bibr" target="#b5">[6]</ref> or the Huber-L 1 norm used by Werlberger et al. <ref type="bibr" target="#b6">[7]</ref>. An additional benefit can be achieved by combining this with more sophisticated totalvariation techniques, as in Papenberg et al. <ref type="bibr" target="#b7">[8]</ref> and Zach et al. <ref type="bibr" target="#b8">[9]</ref>. Generally, global optical flow methods achieve a superior accuracy compared to local optical flow methods. Sand and Teller <ref type="bibr" target="#b9">[10]</ref> proposed the particle video framework to compute a dense set of long-term trajectories from dense optical flow, which is rather slow. In <ref type="bibr" target="#b10">[11]</ref>, a large displacement optical flow as introduced in <ref type="bibr" target="#b11">[12]</ref> was used to create dense point trajectories with a high performance.</p><p>Yet applications such as robot navigation, augmented reality, visual attention, and camera self-calibration require very fast detection of interest points and the subsequent search for potential correspondences in real time. Methods with excellent runtime performance exploiting local optical flow techniques, such as the popular Kanade-Lucas--Tomasi (KLT) tracking algorithm <ref type="bibr" target="#b12">[13]</ref>, are still applied in many cases. Comparative studies indicate that the Lucas-Kanade algorithms provide accurate results <ref type="bibr" target="#b0">[1]</ref> while being significantly more efficient <ref type="bibr" target="#b13">[14]</ref> than other optical flow methods.</p><p>Research of local methods is often motivated by improving the runtime performance, e.g., Senst et al. <ref type="bibr" target="#b14">[15]</ref> proposed integral images to decrease the computational complexity per interest point. Sinha et al. <ref type="bibr" target="#b15">[16]</ref>, Zach et al. <ref type="bibr" target="#b16">[17]</ref>, and Fassold et al. <ref type="bibr" target="#b17">[18]</ref> improved the runtime performance by parallelizing the algorithm and porting it onto a graphics processing unit (GPU). Although in many global optical flow methods, robust estimation techniques are established, most local methods are currently based on least square optimization. Gain adaptive modifications were proposed by Zach et al. <ref type="bibr" target="#b16">[17]</ref> and Kharbat et al. <ref type="bibr" target="#b18">[19]</ref>. <ref type="bibr">Kim et al. [20]</ref> proposed an approach robust to varying illumination using a least median of squares method that is robust but increases the runtime drastically. Robust motion estimation for tracking has also been investigated in <ref type="bibr" target="#b20">[21]</ref> as an application of <ref type="bibr" target="#b21">[22]</ref>. Baker et al. <ref type="bibr" target="#b22">[23]</ref> have investigated Lucas-Kanade in detail regarding the image alignment problem and a higher ordered parameterized warping model.</p><p>The aim of this paper is to introduce an efficient and robust local gradient-based feature tracking system that was earlier motivated and proposed in <ref type="bibr" target="#b23">[24]</ref>. In this paper, we evaluate shortcomings of the established KLT method. Based on empirical findings, we establish a novel robust local optical flow (RLOF) algorithm based on a modified Hampel estimator. We show that this algorithm provides excellent feature tracking performance with only slightly increased computational complexity compared to KLT.</p><p>The remainder of this paper is organized as follows. Section II describes the Lucas-Kanade approach analogous to the regression of a linear model. It will be shown that this least squares estimate behaves badly when assumptions are violated. In Sections III and IV, we introduce our feature tracker based on a robust estimation framework, and in Section V, we evaluate our results regarding the MIT database <ref type="bibr" target="#b24">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. Lucas-Kanade in a Statistical Context</head><p>In this section, we focus on the Lucas-Kanade algorithm viewed in a statistical context.</p><p>The general gradient-based local optical flow constraint is formulated as follows:</p><formula xml:id="formula_0">E local = w(x) • ρ(∇I(x) T • d + I t (x), σ). (<label>2</label></formula><formula xml:id="formula_1">)</formula><p>To find a displacement d, the residual error E local is minimized for a small image region x ∈ , with the spatial derivatives ∇I(x) = (I x (x, t), I y (x, t)) T and the temporal derivative I t (x) = I(x, t) -I(x, t + 1), w(x) a weighting function, and a norm ρ, with its scale parameters σ and x = (x, y) image pixel positions. Consider a linear model and its residual as follows:</p><formula xml:id="formula_2">i = ýi -xi0 θ 0 -. . . -xij θ j (3)</formula><p>for the ith of n observations (x i0 , . . . , xij , ýi ). If i are independent and normally distributed, Gauss proved that the optimal fit θ of parameters θ = (θ 0 , . . . , θ j ) can be estimated with the least sum of squares</p><formula xml:id="formula_3">min θ n-1 i=0 2 i . (<label>4</label></formula><formula xml:id="formula_4">)</formula><p>The least squares estimator relies on a very efficient computational complexity. The optimal parameter θ (4) can be directly computed by an explicit formulation. However, this estimator is very sensitive to outliers <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Lucas-Kanade Locally Constant Flow</head><p>The Lucas-Kanade method is given by the gradient-based formulation as follows:</p><formula xml:id="formula_5">min d ∇I(x) T • d + I t (x) 2 . (<label>5</label></formula><formula xml:id="formula_6">)</formula><p>To find a displacement d, the sum of least squares is minimized for a small image region . In the statistical context, a regression for a linear model ý -xT • θ with the parameters θ = d is done using the observations (x 0 , x1 , ý) = (I x , I y , I t ) of the region . 1) Linearization Problem: The original Lucas-Kanade method <ref type="bibr" target="#b2">[3]</ref> is restricted by the first-order Taylor approximation. The assumption of a linear relation between the gradients ∇I and the motion is only accurate for small motions. To cope with small linearization errors, Bouguet <ref type="bibr" target="#b27">[28]</ref> proposed an iterative solution in a Newton-Raphson fashion. d is iteratively solved for increments to the displacement d as follows:</p><formula xml:id="formula_7">d i = G -1 • ∇I(x) • I i-1 t (x)<label>(6)</label></formula><p>where G denotes the Hessian. The resulting displacement is updated as follows:</p><formula xml:id="formula_8">d i ← d i-1 + d i<label>(7)</label></formula><p>with the second frame being updated at each iteration i so that</p><formula xml:id="formula_9">I i-1 t (x) = I(x, t) -I(x + d i-1 , t + 1)</formula><p>. The iterative solution is initialized with d = (0, 0) T . In the literature, (6) has also been described by <ref type="bibr" target="#b22">[23]</ref> as the inverse compositional algorithm for translational warps. To cope with motion larger than a single pixel, a coarse-to-fine strategy is employed in which pyramids of spatially filtered and subsampled images are created.</p><p>2) Aperture Problem: Equation (6) has a limitation, which is commonly referred to as the aperture problem. There exists only a solution of d if G is not singular. This implies the existence of gradients in x and y direction in the observed region . In consequence, the Lucas-Kanade algorithm could not be applied on homogeneous image content. To overcome this problem, a large region is needed to increase the probability that the region contains edges.</p><p>3) Generalized Aperture Problem: While a large region is needed to constrain the solution and provide insensitivity to noise, it also increases the risk of violating the local constancy assumption, whereby a region should be described by only one motion. Contrarily, a small region decreases the probability that a region contains discriminative edges. That dilemma is referred to as generalized aperture problem <ref type="bibr" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Observation Distributions</head><p>As discussed in Section II-A, the assumptions underlying the Lucas-Kanade algorithm can be violated by homogeneous regions, motion boundaries, the appearance and disappearance of pixels, e.g., by occlusion, and changes of illumination. This section studies the characteristics and distribution of the observed data I x , I y , and I t to motivate the robust framework proposed in Section IV. It should not be seen as a complete investigation but as an illustration of the potential problems of the standard Lucas-Kanade method. Similar experiments for settings of different motion were already conducted by Black and Anandan <ref type="bibr" target="#b4">[5]</ref>. By the use of two different synthetic moving patterns they show that a robust estimation could suppress the nondominant motion efficiently in theory. To apply the experiments in a more realistic scene, the RubberWhale sequence of the Middlebury dataset <ref type="bibr" target="#b29">[30]</ref> is used. The Middlebury dataset includes synthetic and realistic pairs of consecutively captured images and provides the optical flow as ground truth for each pair. To show the distribution of the observed data, two types of plots are used. At first, the distribution of the residual (3) is displayed (see Fig. <ref type="figure" target="#fig_0">1</ref>, bottom left). To get a more detailed view, the distribution of the observed data is displayed with a scatter plot for each region (see Fig. <ref type="figure" target="#fig_0">1</ref>, bottom right). The used region size (17 × 17) corresponds to a common size for the Lucas-Kanade algorithm. Additionally, the spatial gradients I x , I y and different temporal pixel values I 1 , I 2 contained by the region are shown at the top left while the coarse position of the region can be seen at the top right. The picture contains a magnification of the relevant area and a magnification of the color-coded ground truth, see <ref type="bibr" target="#b29">[30]</ref>.</p><p>The first test is shown by Fig. <ref type="figure" target="#fig_0">1(a)</ref>, where the data is captured at position <ref type="bibr" target="#b16">(17,</ref><ref type="bibr">213)</ref> and the region fulfils the Lucas-Kanade assumption. It includes a single motion; constant illuminations and spatial gradients in x and y direction prevent the gradient matrix G from singularity. The distribution of the residual and data is near to be normally distributed. The second test shown in Fig. <ref type="figure" target="#fig_0">1(b</ref>) is captured at the position <ref type="bibr" target="#b32">(33,</ref><ref type="bibr">64)</ref> in which the region contains two different motions. The plane of the second motion is displayed with transparent faces.</p><p>Obviously, the distribution of the residual and observed data does not follow a Gaussian distribution.</p><p>A test of changing illumination is shown in Fig. <ref type="figure" target="#fig_0">1(c</ref>), captured at the position (50, 374). The different illumination is affected by the moving shadow of the red wheel. Obviously, the distribution of the residual and data is biased and not normally distributed. The last test at Fig. <ref type="figure" target="#fig_0">1(d</ref>) plots a sample of a region that includes an appearing texture. It is captured at position <ref type="bibr">(386,</ref><ref type="bibr">312)</ref>. In contrast to the experiment shown in Fig. <ref type="figure" target="#fig_0">1</ref>(b), the data includes outliers, which are not affected and do not belong to one of the two motions. This results in an asymmetric and non-Gaussian distribution.</p><p>Most of the problems in realistic scenes occur at motion boundaries. The violation of the local constancy assumption mostly coincides with the violation of the intensity constancy assumption by occlusion. In relation to the KLT-Tracker <ref type="bibr" target="#b12">[13]</ref>, this becomes an important aspect. To avoid the aperture problem, this often-used tracker performs a feature selection algorithm (e.g., good features to track <ref type="bibr" target="#b30">[31]</ref>) to detect corner points with high edges in both directions and thus a high minimal eigenvalue of G. In practice, these edges lie in all likelihood at motion boundaries. This gives the motivation to use a more robust estimator than the least squares estimator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. Robust Estimator With Piecewise Linear</head><p>Influence Functions Huber <ref type="bibr" target="#b31">[32]</ref> formed the first basis for a theory of robust estimation and introduced a class of estimator, called Mestimator as follows:</p><formula xml:id="formula_10">min θ n-1 i=0 ρ( i , σ) (<label>8</label></formula><formula xml:id="formula_11">)</formula><p>where ρ is an error norm, with its scale parameters σ, which may or may not be present. The M-estimator is a generalization of the well-known maximum likelihood estimator without assuming that ρ is of the form -logf for any probability density f . The robustness of the estimator depends on its error norm. An approach based on the influence function was introduced by Hampel <ref type="bibr" target="#b32">[33]</ref>. The influence function ψ(y, σ) as the derivative of the estimator ρ(y, σ) characterizes the bias that a particular measurement has on the solution. The estimation of θ can be given by the influence function</p><formula xml:id="formula_12">n-1 i=0 ψ( i , σ) • ∂ i ∂θ = 0<label>(9)</label></formula><p>Fig. <ref type="figure" target="#fig_1">2</ref> shows the drawback of the least squares solution: outliers are assigned a too high weight by the quadratic error norm ρ = y 2 . More robust norms are the L 1 norm <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b31">[32]</ref> and Huber's minmax norm <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b33">[34]</ref> because their influence functions are limited. Both are equivalent for large values, but for normally distributed data, the L 1 norm produces estimates with higher variance than the optimal quadratic L 2 norm <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>. In contrast, Huber's minmax norm is designed to be quadratic for small values, which makes it applicable for Newton. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Redescending Influence Function</head><p>To increase the robustness, the influence of extremely discordant observations should be reduced to zero. So ψ should be designed to vanish for large values. This was a reason to develop redescending M-estimators that Huber described in <ref type="bibr" target="#b34">[35]</ref>. An advantage of redescending M-estimators is that they have very low breakdown points <ref type="bibr" target="#b32">[33]</ref>. Black and Anandan <ref type="bibr" target="#b4">[5]</ref> proposed an implementation for the optical flow using the Lorentzian norm</p><formula xml:id="formula_13">ψ( i , σ) = 2 i 2σ 2 + 2 i (10)</formula><p>to improve the behavior of motion computation at motion boundaries. Odobez and Bouthemy <ref type="bibr" target="#b21">[22]</ref> proposed a redescending M-estimator implementation based on Tukey's biweight norm <ref type="bibr" target="#b35">[36]</ref> as follows:</p><formula xml:id="formula_14">ψ( i , σ) = i σ 2 -2 i 2 , | i | &lt; σ 0, else.<label>(11)</label></formula><p>The M-estimator problems using the robust norms ( <ref type="formula" target="#formula_14">11</ref>) and ( <ref type="formula">10</ref>) cannot be solved analytically, which is a drawback with regard to computational complexity. The solution can instead be found using the iteratively reweighted least squares method by transforming the M-estimation problem into an equivalent weighted least squares problem <ref type="bibr" target="#b21">[22]</ref> as follows:</p><formula xml:id="formula_15">n-1 i=0 ρ( i , σ) = 1 2 n-1 i=0 w i • 2 i (<label>12</label></formula><formula xml:id="formula_16">)</formula><p>where the weight at each observation x i is given by Another alternative to the M-estimator is the least median of squares estimator (LMedS), advantages of which lie in its theoretical high robustness. But as Odobez and Bouthemy stated, the computational cost of LMedS is very high and increases rapidly with the amount of data. A primary aim of this paper is to keep the computational effort as low as possible. We therefore want to focus on estimator classes with an influence function composed of linear functions. Fig. <ref type="figure" target="#fig_1">2</ref> shows common error norms based on composed quadratic functions. We base our approach on the Hampel estimator but reduce the number of its parameters by shrinking the high and low flat segment to</p><formula xml:id="formula_17">w i = ψ( i ) i . (<label>13</label></formula><formula xml:id="formula_18">)</formula><formula xml:id="formula_19">ρ( i , σ) = ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ 2 i , | i | ≤ σ 1 σ 1 σ 2 , | i | ≥ σ 2 σ 1 (| i | -σ 2 ) 2 σ 1 -σ 2 + σ 1 σ 2 , else<label>(14)</label></formula><p>with the influence function</p><formula xml:id="formula_20">ψ( i , σ) = ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ 2 i , | i | ≤ σ 1 0, | i | ≥ σ 2 σ 1 ( i -sign( i ) • σ 2 ) 0.5(σ 1 -σ 2 ) , else.<label>(15)</label></formula><p>Several algorithms were investigated by Dutter <ref type="bibr" target="#b36">[37]</ref> including Newton's method, which we want to use to solve (9). Newton's method has the remarkable property of reaching the theoretically exact solution in one single step, if the start value is close to the solution and a (composed) quadratic error norm is used <ref type="bibr" target="#b34">[35]</ref>. A comparative study of these redescending M-estimators is given by Shevlyakov et al. <ref type="bibr" target="#b37">[38]</ref>. Table <ref type="table" target="#tab_0">I</ref> shows the evaluation of dense optical flow from different Mestimator for images in the Middlebury dataset. The reference KLT method based on the quadratic norm is compared to the M-estimator implementations regarding <ref type="bibr" target="#b21">[22]</ref>, available at http://www.irisa.fr/vista/Motion2D/about.html, for the Talwar, Tukey, Cauchy, and Welsh norm, and to the RLOF. RLOF </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experiments With Composed Quadratic Error Norms</head><p>In this section, we want to study the effect of the different norms (see Fig. <ref type="figure" target="#fig_1">2</ref>) to the Lucas-Kanade method with regard to exemplary data distributions shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Figs. <ref type="figure" target="#fig_2">3</ref> and<ref type="figure" target="#fig_4">4</ref> show error surfaces of the observations rendered for a region of size 17 × 17. The error surfaces display the sum of the residual error i (u, v) weighted with the L 2 , truncated L 2 , and Huber or shrinked Hampel error function while varying (u, v). Ground truth motion is taken from the dataset and used as solution information for the center pixel of the region.</p><p>To validate the normally distributed data, the experiment with Fig. <ref type="figure" target="#fig_0">1(a</ref>) is shown in Fig. <ref type="figure" target="#fig_2">3(a)</ref>. The minima of all error surfaces are near the expected ground truth value.</p><p>Fig. <ref type="figure" target="#fig_4">4</ref>(a) and (b) shows cases of appearing pixels, in Fig. <ref type="figure" target="#fig_4">4</ref>(a), the appearance of the shadow at the right region side, and in Fig. <ref type="figure" target="#fig_4">4</ref>(b), uncovered pixels, both violating the intensity constancy assumption.</p><p>Minima of the Huber norm are closer to the ground truth than the minimum of the least squares norm. However, redescending influence (i.e., bounded influence) gives an additional improvement of the behavior concerning gross outliers. As stated by Hampel <ref type="bibr" target="#b32">[33]</ref>, nonmonotone influence functions should be used with caution. In general, they should also not descend too steeply. Fig. <ref type="figure" target="#fig_4">4(b)</ref> shows that the truncated L 2 norm produces a more nonconvex error surface with local minima that could corrupt the minimization of (8).  RLOF* (RLOF without adaptive region size, see Section IV) shows similar accuracy compared to the Talwar, Tukey, Cauchy, and Welsh robust norms <ref type="bibr" target="#b21">[22]</ref> but a relatively short runtime. RLOF# denotes the RLOF without using the modified estimator. R0.5 denotes the ratio of pixels that have an endpoint error above 0.5 and illustrates the outlier resulting from each method.</p><p>While the result of Fig. <ref type="figure" target="#fig_4">4</ref>(b) corresponds to the multiple motion experiments of Black and Anandan, Fig. <ref type="figure" target="#fig_2">3(b)</ref> shows different characteristics. The minimum is nearer to the second motion of the region border than to the motion of the region center, while a second minimum is not visible. This behavior can be observed at motion boundaries where at least one object is homogeneous. The data at homogeneous areas has no or only a small impact on the result of the estimates of the linear Lucas-Kanade model because the derivative ∂ i /∂θ at homogeneous regions is zero and shrinks its influence. In consequence, the improvement of distinguishing different motions in a region by robust estimation depends on the ratio of the textures introduced by each object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. Robust Local Optical Flow</head><p>The outcome of our experiments leads us to propose a variation of the Lucas-Kanade method using the shrinked Hampel norm ( <ref type="formula" target="#formula_19">14</ref>): the RLOF method. The inverse compo-sitional RLOF residual error is formulated as</p><formula xml:id="formula_21">E RLOF = 1 ⊂ 2 + 3 ⊂ σ 1 σ 2 + 2 ⊂ σ 1 σ 1 -σ 2 (| | -σ 2 ) 2 + σ 1 σ 2 (16) with = ∇I(x) T • d + I t (x)<label>(17)</label></formula><p>and 1 as the subset of data in fulfilling | i | ≤ σ 1 , 2 denoting the subset fulfilling σ 1 &lt; | i | &lt; σ 2 , and 3 for which holds | i | ≥ σ 2 . As stated in Section III-A, (7) can be solved as where G RLOF is the modified Hessian matrix</p><formula xml:id="formula_22">d i = G -1 RLOF • 1 ⊂ ∇I(x) • I i-1 t (x) + 2 ⊂ σ 1 σ 1 -σ 2 • ∇I(x) • I i-1 t (x) -sign(I i-1 t (x)) • σ 2<label>(18)</label></formula><formula xml:id="formula_23">G RLOF = 1 ⊂ ∇I(x) • ∇I(x) T + 2 ⊂ σ 1 σ 1 -σ 2 ∇I(x) • ∇I(x) T . (<label>19</label></formula><formula xml:id="formula_24">)</formula><p>As stated in <ref type="bibr" target="#b34">[35]</ref>, it is important that the influence function ψ of the norm does not descend too steeply as long as the value of ψ is still high. We incorporate this by using the L 2 norm as a monotone ψ for the first iteration. This can easily be done by setting σ 1 = ∞ and σ 2 = ∞. For the following iterations, we append cycles with the nonmonotone ψ, since the corresponding shrinked Hampel norm is nonconvex and the determination of the minimum may be trapped in local minima far away from the true minimum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Generalized Aperture Problem</head><p>As shown in Fig. <ref type="figure" target="#fig_4">4</ref>(a) and (b) and by the experiments done in <ref type="bibr" target="#b28">[29]</ref>, redescending norms are able to cope with perturbations affecting the local constancy and brightness constancy assumption. An essential requirement therefore is that the observed underlying moving object owns the dominant textures in the observed domain. For example, this is not fulfilled in Fig. <ref type="figure" target="#fig_2">3(b</ref>). The motion boundaries example contains two moving objects: the wooden fence in the foreground containing the dominant textures and the background. While the center of the observed region lies in the background, we are interested in computing its motion. The observations of the background x ij (which correspond to its spatial and temporal derivatives) are less correlated than the observations of the foreground fence. Thus, the estimation of the parameter set θ is determined by the fence motion, while the background motion is treated as outlier. This example shows that the observation done in Fig. <ref type="figure" target="#fig_4">4</ref>(a) and (b) and <ref type="bibr" target="#b28">[29]</ref> cannot always be valid. To cope with the violation of the local constancy assumption, the observed region has to be as small as possible with regard to the generalized aperture problem to increase the probability to contain no motion boundary. An additional reason to set the observed region as small as possible is caused by the computational effort.</p><p>Therefore, we propose a strategy to adapt the region size depending on the residual error E RLOF and the contained texture. At first, d is computed for a few number of iterations i l applying a large region large . This results in an overall coarse solution, containing most likely all texture. To achieve a better performance at motion boundaries, the iteration is applied to a drastically shrinked region small after one cycle. To avoid the aperture problem, the minimal eigenvalue of the matrix G RLOF is computed to decide if the feature is trackable <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b30">[31]</ref>. Another criterion to decide if the feature could be tracked with the small region is taken by comparing the normalized residual error E RLOF of the current and the large region. In the positive case, the iteration is continued until reaching final convergence or a maximal number of iterations, otherwise the region size is increased step by step by the default value two until a trackable size or large is reached. In this field, there are still a lot of research opportunities, but topics such as variable window shapes or an exact investigation on the influence of the size step are far beyond the focus of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Empirical Validation</head><p>We experiment with the four case studies of Section II-B comparing the convergence of RLOF with the original KLT applied to the small and the large region size used in RLOF. The iterative solution for each of the four displacements is shown in Fig. <ref type="figure" target="#fig_5">5</ref>. The termination criteria are set to a maximal number of 20 iterations and a minimal change of d by 0.001. The black dashed lines display ground truth motion at the respective positions. The results confirm our expectation that a small region favors a higher resolved motion field, in particular at motion boundaries [see Fig. <ref type="figure" target="#fig_5">5(b)</ref> and<ref type="figure">(c)]</ref>. A large region converges on average with fewer iterations. It achieves a low resolved motion (in our case, it is not able to separate the motions). We observe in Fig. <ref type="figure" target="#fig_5">5(d</ref>) that the small region KLT fails to converge with the appearing pixels, while a large region converges to an inaccurate solution. By adapting the region size and applying a robust estimator, the capability of the RLOF to separate different motions and to neglect outliers introduced by appearing pixels is increased. We observe that RLOF can increase the accuracy and stability of current KLT methods that is paid for by a higher number of iterations than the KLT with the large region.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Computational Complexity</head><p>With n as the number of computed motion vectors and N being the number of pixels of the region , the computational cost of the Lucas-Kanade method for one iterative step is given by: 1) computing the warped spatial derivative ∇I (O(nN)); 2) computing the gradient matrix G (O(nN)); and 3) computing the incremental solution (O(nN)), <ref type="bibr" target="#b5">(6)</ref>. Baker and Matthews proved in <ref type="bibr" target="#b22">[23]</ref> that the inverse compositional algorithm also used in <ref type="bibr" target="#b27">[28]</ref> is the same as the Lucas-Kanade algorithm but far more efficient because the spatial derivatives and the gradient matrix only have to be computed initially. The computational cost of this variation, used by the KLT method, is given by O(nNi). Thus, for a fast tracking method, on the one hand, the convergence must be fast while the region size should be kept small. As N is quadratic to the region size in most cases, a small region size is preferred. However, Fig. <ref type="figure" target="#fig_5">5</ref> shows how a small region tends to converge more slowly to the correct solution as the region is more likely to contain less gradient information (see Fig. <ref type="figure" target="#fig_0">1</ref> for the respective regions).</p><p>Within the robust norm, the gradient matrix <ref type="bibr" target="#b18">(19)</ref> has to be computed for each iterative step by revalidating each pixel N. Thus, the computational complexity O(inN) is increased by recalculating G RLOF (O(nNi)). Through the varying region size, the computational complexity of the RLOF is bounded by O(nN small i) and O(nN large i). Fig. <ref type="figure" target="#fig_6">6</ref> shows the runtime of the KLT and RLOF method related to the number of tracked points. The implementation is tested on an AMD Phenom II X4 960 running at 2.99 GHz and without multithreading.</p><p>As the computation of each motion vector is independent, the runtime can be decreased by parallelization (using, e.g., OpenMP). Generally, due to the changing window size, the RLOF converges more slowly than the KLT using one large region (see Fig. <ref type="figure" target="#fig_5">5</ref>). This is due to the smaller amount of gradi-Fig. <ref type="figure">7</ref>. Robustness test is performed with different JPEG compressions. This kind of error is not Gaussian distributed. ent information contained in small windows. However, thanks to the adaptive region size, the RLOF is less time consuming. So the adaptive region size is not only advantageous for accuracy at motion boundaries but also results in a decreased computational cost compared to KLT with large region size. A general advantage of local optical flow methods is shown in Fig. <ref type="figure" target="#fig_6">6</ref> with the linear scalability due to the number of tracked points n. In our experiment, we vary the number of motion vectors by applying a grid with different sizes to find the points to track. The RLOF processes 551 features in 44.38 f/s using the CPU on an image of the size 584 × 388. Thus, it needs only 70% of the runtime of KLT using a large region. By using not more than a few sets of points to track, the runtime depends mainly on the initial calculation of the image gradients and is thus in this experiment bounded by 6.7 ms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. Experiments on Video Sequences</head><p>In the following section, we show the results of our experiments for long-term trajectories. We compare the RLOF to the KLT and the state-of-the-art dense trajectory methods LDOF <ref type="bibr" target="#b10">[11]</ref> and particle video <ref type="bibr" target="#b9">[10]</ref>. To deal with the large motions, the RLOF and KLT are implemented in a pyramidal manner <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b27">[28]</ref>. For our experiments, we apply four levels. The small and large region sizes are set to 7 × 7 and 17 × 17 and the maximal number of iterations is 20. RLOF works with a robust norm specified by σ 1 = 5 and σ 2 = 50. The KLT experiments are performed with all valid region sizes between 7 × 7 and 17 × 17.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Evaluation Methodology</head><p>We evaluate the performance of the tracking methods with the MIT dataset <ref type="bibr" target="#b24">[25]</ref>. In contrast to the Middlebury dataset, this dataset provides the ground truth optical flow for whole sequences of up to 75 frames. We compare the accuracy of the trackers for the entire length of the sequences by comparing trajectories. A trajectory is created for each pixel of the first image and tracked through all the frames. Ground truth trajectories are obtained from the ground truth optical flow. To compute subpixel accurate tracks, a bilinear interpolation is applied. A trajectory is stopped as soon as a point gets occluded or is incorrectly tracked. We detect these for the KLT and RLOF method by checking the consistency of the forward and backward flow. The consistency check is done by thresholding the forward displacement from image I(t) → I(t + 1) and the respective warped reverse one I(t + 1) → I(t) as follows:</p><formula xml:id="formula_25">d I(t)→I(t+1) + d I(t+1)→I(t) &lt; d . (<label>20</label></formula><formula xml:id="formula_26">)</formula><p>The measurement is based on two criteria: 1) the average endpoint error (AEE) between the set of trajectories T and the set of ground truth trajectories</p><formula xml:id="formula_27">T GT AEE = 1 |T | |T | ||ẋ T -ẋT GT || 2<label>(21)</label></formula><p>with ẋ as the endpoint of each trajectory, and 2) the tracking efficiency (η)</p><formula xml:id="formula_28">η = 1 |T GT | • L |T | l T . (<label>22</label></formula><formula xml:id="formula_29">)</formula><p>In contrast to <ref type="bibr" target="#b23">[24]</ref>, this measure is defined as the quotient of the average of l T , the length of all successfully tracked features, and L, the total number of frames of each sequence. The combination of these two criteria is plotted as tracking performance by varying d (see Fig. <ref type="figure" target="#fig_7">8</ref>). Note that the AEE is accumulated for all trajectories T and not only for the trajectories, which are tracked until the last images successfully.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Results</head><p>In real-life scenarios, e.g., video surveillance, videos are provided in a compressed way, e.g., H.264, MPEG4, or motion JPEG. Thus, the video is affected by compression artifacts. In the statistical point of view, these artifacts are a source of noise, which is not Gaussian distributed (see Fig. <ref type="figure">7</ref>). This is why we are in addition interested to compare the tracking methods related to different compressions. The results for the Toy, Fish, and Table sequence are shown in Fig. <ref type="figure" target="#fig_7">8</ref>.</p><p>In the Toy sequence (18 frames), the camera is moving transversally in front of a set of teddy bears. Large areas behind the bear (left) are uncovered while computation of optical flow is hampered by the very homogeneous areas of the black and white panda. The Table sequence (13 frames) shows a circular motion around a table with different objects on top occluding each other. Due to depth of field, the background is very blurred and contains little texture information that makes it a hard area for estimating optical flow. The Fish sequence (75 frames) is the longest of the sequences. The backgrounds are blurry while the video also suffers from strong noise and low brightness. The motion estimation is further aggravated by the transparent motion that covers the whole sequence caused by dust particles moving in the water.</p><p>As described above, the tracking efficiency η is a value between 0 and 1 that describes the percentage of the trajectories the algorithm is able to maintain in relation to their length. Tracking all trajectories over all frames would correspond to η = 1 while tracking only half of the pixels for the full length (or all pixels for half the number of frames) corresponds to η = 0.5.</p><p>Fig. <ref type="figure" target="#fig_7">8</ref> shows the tracking efficiency compared to the AEE. Regardless of the compression level and the salt and pepper noise with a density of 0.02, by these examples it can be seen that RLOF usually achieves better results than the KLT variants. While the proposed CPU implementation of the RLOF achieves a frame rate of 44 f/s by tracking 551 features, we provided in <ref type="bibr" target="#b23">[24]</ref> a parallelized version of the RLOF, which is able to compute up to 10.000 feature points on high-definition content in real time (&gt;25 f/s). The implementation was done using OpenCL and runs on a NVidia GTX 275 GPU.</p><p>The region size used in RLOF is varied between 7 × 7 and 17 × 17 that are the minimal and maximal region sizes of the KLT algorithm used in these experiments. We conduct thus from the higher performance that varying the region size is a favorable extension of the standard KLT. The performance of all algorithms decreases with higher compression </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. Conclusion</head><p>In this paper, we illustrated the benefit of a robust framework for feature tracking via local optical flow. Motivated by an extensive analysis of data distributions, we proposed the RLOF approach based on a modified Hampel estimator with robust characteristics. To cope with the generalized aperture problem, a strategy to adapt the region size was developed. The effectiveness of our approach was shown under various scenarios as motion boundaries, changing illuminations, and appearing pixels, all violating standard Lucas-Kanade assumptions. In our experiments, it could be shown that a robust estimator gives better results. Evaluations on the MIT database showed an excellent long-term feature tracking performance of RLOF with only slightly increased computational complexity compared to KLT. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) Distribution of the residual error (bottom right) and the data of the spatial and temporal derivatives (bottom left) fulfilling the Lucas-Kanade assumptions. The data scatter plot includes the ground truth motion as plane. (b) Different motions where the motion of the region center is illustrated as gray plane and the motion of the bottom-right region border as transparent plane. (c) Setting with changing illuminations affected by shadows. (d) Appearance of occluded pixels by different motions. The illustration at the top shows the derivatives of the region (left) and an overview of the region position containing a magnification of the relevant area and a magnification of the color-coded ground truth.</figDesc><graphic coords="3,59.22,54.23,492.19,440.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Common error norms ρ with piecewise linear influence functions ψ. (a) Quadratic. (b) Huber. (c) Shrinked Hampel.</figDesc><graphic coords="4,319.52,53.93,239.76,262.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Error surfaces of the residual error sum obtained by varying (u, v) with the error functions shown in Fig. 2 in the scenario of Fig. 1. (a) Not violated. (b) Motion boundaries. The ground truth motion of (a) is d(17, 213) = (1.36, -0.01) and the center motion of (b) is d(33, 64) = (0.09, 0.15) including a second motion at a neighboring pixel d(41, 70) = (0.91, -0.08). Ideally, the minima in the plots should be at the ground truth motion and smooth surfaces should simplify the gradient descent. Black dot: ground truth of the center motion. Red circle: corresponding second motion. Blue lines: small values. Red lines: big values.</figDesc><graphic coords="5,59.72,53.92,492.05,191.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>shown in three variants: 1) as described in Section IV; 2) with the shrinked Hampel norm and having a fixed region size (RLOF*); and 3) with quadratic norm and adapted region size (RLOF#). With a relatively short runtime, the accuracy of the RLOF* is comparable to the other robust norms. Further improvement is reached by adapting the region size of the RLOF*. The runtime was computed at the Grove3 640 × 480 sequence by CPU specification regarding Section V. All methods use default parameters and a region size of 17 × 17.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Error surfaces of the residual error sum obtained by varying (u, v) with the error functions shown in Fig. 2 in the scenario of Fig. 1. (a) Changing illuminations. (b) Appearing pixels. The ground truth motion of (a) is d(50, 374) = (1.06, 0.02) and the center motion of (b) is d(386, 312) = (0.96, -0.02) including a second motion d(378, 312) = (-1.94, -0.76). Ideally, the minima in the plots should be at the ground truth motion and smooth surfaces should simplify the gradient descent. The ground truth of the center motion are shown as a black dot and the corresponding second motion as a red circle. The blue lines denote small values while the red lines denote big values.</figDesc><graphic coords="6,62.01,54.18,491.76,195.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Example of the RLOF and KLT algorithm with different region sizes converging at the four case studies (Section II-B). The resulting motion (u, v) is plotted against the iteration number. Black dashed line: ground truth. Termination criteria are set with 20 maximal iterations and a minimal change of d by 0.001. (a) Not violated. (b) Motion boundaries. (c) Changing illuminations. (d) Appearing pixels.</figDesc><graphic coords="7,59.72,54.33,491.47,194.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Comparison of execution times: KLT and RLOF method with varying number of tracked points. Black dashed line: 25 f/s threshold.</figDesc><graphic coords="8,56.50,54.00,240.05,145.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Evaluation of the tracking performance for the (a) Toy, (b) Fish, and (c) Table sequence with different compression rates of the MIT [25] dataset and salt and pepper noise with a noise density of 0.02. The region size of the KLT varied from 7 × 7 to 17 × 17, which is the range of the window sizes for RLOF. 7 × 7, 11 × 11, and 17 × 17 are shown.</figDesc><graphic coords="9,66.22,53.85,478.66,524.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Tobias</head><label></label><figDesc>Senst (S'11) received the Dipl.-Ing. degree in computer engineering from Otto von Guericke Universität Magdeburg, Magdeburg, Germany. He is currently pursuing the Ph.D. degree with the Communication Systems Group, Technische Universität Berlin, Berlin, Germany. His current research interests include image and video processing, optical flow, feature tracking, and video surveillance. Volker Eiselein (S'11) received the Dipl.-Ing. degree in computer engineering from Technische Universität Berlin, Berlin, Germany, where he is currently pursuing the Ph.D. degree with the Communication Systems Group. His current research interests include image and video processing, video surveillance, object tracking, and optical flow. Thomas Sikora (SM'97) received the Dipl.-Ing. and Dr.-Ing. degrees in electrical engineering from Bremen University, Bremen, Germany, in 1985 and 1989, respectively. He is currently is a Professor and Director of the Communication Systems Group, Technische Universität Berlin, Berlin, Germany. In 1990, he joined Siemens Ltd. and Monash University, Melbourne, Australia, as a Project Leader responsible for video compression research activities in the Australian Universal Broadband Video Codec Consortium. From 1994 to 2001, he was the Director of the Department of Interactive Media, Heinrich Hertz Institute, Berlin GmbH, Germany. Prof. Sikora was a recipient of the German Society for Information Technology (ITG) Award in 1996. He was the Co-Founder of 2SK Media Technologies and Vis-a-Pix GmbH, two Berlin-based start-up companies involved in research and development of audio and video signal processing and compression technology. He has been involved in international ITU and ISO standardization activities as well as in several European research activities for a number of years. As the Chairman of the ISO-MPEG Video Group, he was responsible for the development and standardization of the MPEG-4 and MPEG-7 video algorithms. He was also the Chairman of the European COST 211ter Video Compression Research Group. He was appointed as the Research Chair of VISNET and 3DTV European Networks of Excellence. He is an Advisory and Supervisory Board Member of a number of German companies and international research organizations. He is an Industry Consultant on issues related to interactive digital audio and video. He is a member of the ITG. He has published more than 150 papers related to audio and video processing. He was the Editor-in-Chief of the IEEE Transactions on Circuits and Systems for Video Technology. From 1998 to 2002, he was an Associate Editor of the IEEE Signal Processing Magazine. He is an Advisory Editor of EURASIP Signal Processing: Image Communication. He was an Associate Editor of EURASIP Signal Processing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I</head><label>I</label><figDesc>AEE and the R0.5 Error for Middlebury Dataset</figDesc><table><row><cell></cell><cell cols="2">Dimetrodon</cell><cell cols="2">Grove2</cell><cell></cell><cell>Grove3</cell><cell></cell><cell cols="2">Hydrangea</cell><cell cols="2">RubberWhale</cell><cell cols="2">Urban2</cell><cell cols="2">Urban3</cell><cell cols="2">Venus</cell></row><row><cell></cell><cell cols="11">AEE R0.5 AEE R0.5 AEE R0.5 Runtime (s) AEE R0.5 AEE R0.5</cell><cell cols="6">AEE R0.5 AEE R0.5 AEE R0.5</cell></row><row><cell>KLT</cell><cell>1.24</cell><cell>0.14</cell><cell>2.50</cell><cell>0.15</cell><cell>1.75</cell><cell>0.36</cell><cell>76</cell><cell>2.13</cell><cell>0.24</cell><cell>1.76</cell><cell>0.15</cell><cell>1.83</cell><cell>0.21</cell><cell>2.30</cell><cell>0.25</cell><cell>0.96</cell><cell>0.16</cell></row><row><cell cols="2">RLOF* 0.93</cell><cell>0.14</cell><cell>0.30</cell><cell>0.10</cell><cell>1.04</cell><cell>0.29</cell><cell>75</cell><cell>1.07</cell><cell>0.22</cell><cell>0.32</cell><cell>0.13</cell><cell>1.27</cell><cell>0.20</cell><cell>1.31</cell><cell>0.24</cell><cell>0.86</cell><cell>0.15</cell></row><row><cell cols="2">RLOF# 2.69</cell><cell cols="3">0.16 12.78 0.26</cell><cell>6.33</cell><cell>0.39</cell><cell>72</cell><cell>0.79</cell><cell>0.30</cell><cell>0.39</cell><cell>0.15</cell><cell cols="2">10.36 0.30</cell><cell>9.12</cell><cell>0.37</cell><cell>0.93</cell><cell>0.23</cell></row><row><cell>RLOF</cell><cell>0.20</cell><cell>0.13</cell><cell>0.23</cell><cell>0.09</cell><cell>0.78</cell><cell>0.26</cell><cell>73</cell><cell>0.35</cell><cell>0.20</cell><cell>0.25</cell><cell>0.11</cell><cell>0.80</cell><cell>0.17</cell><cell>0.85</cell><cell>0.23</cell><cell>0.48</cell><cell>0.16</cell></row><row><cell>Talwar</cell><cell>0.24</cell><cell>0.14</cell><cell>0.27</cell><cell>0.09</cell><cell>1.27</cell><cell>0.28</cell><cell>839</cell><cell>0.50</cell><cell>0.23</cell><cell>0.32</cell><cell>0.13</cell><cell>5.90</cell><cell>0.41</cell><cell>4.81</cell><cell>0.40</cell><cell>1.33</cell><cell>0.27</cell></row><row><cell>Tukey</cell><cell>0.24</cell><cell>0.14</cell><cell>0.27</cell><cell>0.09</cell><cell>1.27</cell><cell>0.28</cell><cell>789</cell><cell>0.50</cell><cell>0.24</cell><cell>0.32</cell><cell>0.13</cell><cell>5.89</cell><cell>0.41</cell><cell>4.84</cell><cell>0.40</cell><cell>1.31</cell><cell>0.27</cell></row><row><cell cols="2">Cauchy 0.24</cell><cell>0.14</cell><cell>0.28</cell><cell>0.10</cell><cell>1.22</cell><cell>0.29</cell><cell>811</cell><cell>0.48</cell><cell>0.23</cell><cell>0.32</cell><cell>0.14</cell><cell>5.75</cell><cell>0.39</cell><cell>4.80</cell><cell>0.40</cell><cell>1.29</cell><cell>0.26</cell></row><row><cell>Welsh</cell><cell>0.24</cell><cell>0.14</cell><cell>0.27</cell><cell>0.09</cell><cell>1.24</cell><cell>0.28</cell><cell>819</cell><cell>0.49</cell><cell>0.23</cell><cell>0.32</cell><cell>0.13</cell><cell>5.82</cell><cell>0.40</cell><cell>4.85</cell><cell>0.40</cell><cell>1.28</cell><cell>0.27</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II</head><label>II</label><figDesc>Evaluation of Tracking Performance for the LDOF andParticle Video Methods Over MIT Sequences RLOF is able to achieve better results than standard KLT trackers. The evaluation of the dense LDOF (available at http://lmb.informatik.uni-freiburg. de/resources/binaries) and the particle video tracker (available at http://rvsn.csail.mit.edu/pv) are shown in Table II using the default parameter set given by the authors. While the LDOF outperforms the RLOF and KLT in terms of accuracy except in the Fish sequence caused by its transparent motion, the RLOF still achieves a good accuracy compared to the particle video method. We observed that the optimization step of the particle video method, which often improves this method, fails at areas containing little textured information, e.g., the table in the Table sequence. The runtime of the dense optical flow methods was measured for the Toy sequence of size 972 × 723. The runtime is almost constant and independent of the number of tracked points, which is why we prefer local optical flow methods in time-critical applications. The CPU implementation of the LDOF requires about 139 s and the particle video requires about 135 s per frame. While we evaluate a dense trajectory set, i.e., 702 756 points to track at the first image, the RLOF also requires 173 s.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>LDOF</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Toy</cell><cell></cell><cell>Fish</cell><cell></cell><cell>Table</cell><cell></cell></row><row><cell></cell><cell>AEE</cell><cell>η</cell><cell>AEE</cell><cell>η</cell><cell>AEE</cell><cell>η</cell></row><row><cell>JPEG quality 30%</cell><cell>3.10</cell><cell>0.87</cell><cell>19.18</cell><cell>0.37</cell><cell>3.85</cell><cell>0.65</cell></row><row><cell>JPEG quality 10%</cell><cell>5.78</cell><cell>0.65</cell><cell>21.85</cell><cell>0.38</cell><cell>5.08</cell><cell>0.49</cell></row><row><cell>Salt and pepper</cell><cell>3.32</cell><cell>0.63</cell><cell>27.40</cell><cell>0.26</cell><cell>3.51</cell><cell>0.45</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Particle Video</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Toy</cell><cell></cell><cell>Fish</cell><cell></cell><cell>Table</cell><cell></cell></row><row><cell></cell><cell>AEE</cell><cell>η</cell><cell>AEE</cell><cell>η</cell><cell>AEE</cell><cell>η</cell></row><row><cell>JPEG quality 30%</cell><cell>13.07</cell><cell>0.84</cell><cell>68.45</cell><cell>0.69</cell><cell>24.09</cell><cell>0.75</cell></row><row><cell>JPEG quality 10%</cell><cell>10.21</cell><cell>0.83</cell><cell>49.35</cell><cell>0.63</cell><cell>31.31</cell><cell>0.71</cell></row><row><cell>Salt and pepper</cell><cell>34.70</cell><cell>0.76</cell><cell>102.86</cell><cell>0.58</cell><cell>52.01</cell><cell>0.69</cell></row><row><cell cols="7">rates, which shows that all methods suffer from the loss</cell></row><row><cell cols="7">of information during JPEG compression. Especially, smaller</cell></row><row><cell cols="7">window sizes have disadvantages with increasing compression</cell></row><row><cell cols="7">rate as they suffer more from compression noise. Still, by</cell></row><row><cell cols="3">varying different region sizes,</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by the European Community FP7, under Grant 261743 (NoE VideoSense). This paper was recommended by Associate Editor J. F. Arnold.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Performance of optical flow techniques</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Beauchemin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="77" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Determining optical flow</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K P</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Schunck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artifical Intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="185" to="203" />
			<date type="published" when="1981-08">Aug. 1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An iterative image registration technique with an application to stereo vision</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="page" from="674" to="679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A framework for the robust estimation of optical flow</title>
		<author>
			<persName><forename type="first">M</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Anandan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICCV</title>
		<meeting>IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="1993-05">May 1993</date>
			<biblScope unit="page" from="231" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The robust estimation of multiple motion: Parametric and piecewise-smooth flow fields</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Anandan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vision Image Understand</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="75" to="104" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">High accuracy optical flow estimation based on a theory for warping</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bruhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="25" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Anisotropic Huber-L1 optical flow</title>
		<author>
			<persName><forename type="first">M</forename><surname>Werlberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Trobin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="231" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Highly accurate optic flow computation with theoretically justified warping</title>
		<author>
			<persName><forename type="first">N</forename><surname>Papenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bruhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Didas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="141" to="158" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A duality based approach for realtime TV-L1 optical flow</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DAGM Symp</title>
		<meeting>DAGM Symp</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Particle video: Long-range motion estimation using point trajectories</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Teller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="72" to="91" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dense point trajectories by gpuaccelerated large displacement optical flow</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sundaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="438" to="451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Large displacement optical flow</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Comput. Soc. Conf. Comput. Vision Patt. Recog</title>
		<meeting>IEEE Comput. Soc. Conf. Comput. Vision Patt. Recog</meeting>
		<imprint>
			<date type="published" when="2009-06">Jun. 2009</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Detection and tracking of point features</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<idno>CMU-CS-91-132</idno>
	</analytic>
	<monogr>
		<title level="j">School Comput. Sci., Carnegie Mellon Univ</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<pubPlace>Pittsburgh, PA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Accuracy vs efficiency trade-offs in optical flow algorithms</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Camus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vision Image Understand</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="271" to="286" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">II-LK: A real-time implementation for sparse optical flow</title>
		<author>
			<persName><forename type="first">T</forename><surname>Senst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Eiselein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sikora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICIAR</title>
		<meeting>ICIAR</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="240" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">GPU-based video feature tracking and matching</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Genc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Sci., Univ. North Carolina</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<pubPlace>Chapel Hill, Chapel Hill</pubPlace>
		</imprint>
	</monogr>
	<note>Tech. Rep. 06-012</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fast gain-adaptive KLT tracking on the GPU</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gallup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Frahm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Vis. CVGPU Workshop</title>
		<meeting>Vis. CVGPU Workshop</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Realtime KLT feature point tracking for high definition video</title>
		<author>
			<persName><forename type="first">H</forename><surname>Fassold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rosner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Schallauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bailer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Comput. Graphics, Comput. Vision Math. (GraVisMa)</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Robust brightness description for computing optical flow</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kharbat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Aouf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tsourdos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="46" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A local approach for robust optical flow estimation under varying illumination</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="91" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A region tracking method with failure detection for an interactive video indexing environment</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gelgon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bouthemy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dubois</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Int. Conf. Vis</title>
		<meeting>3rd Int. Conf. Vis</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="261" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Robust multiresolution estimation of parametric motion models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Odobez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bouthemy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vis. Commun. Image Represent</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="348" to="365" />
			<date type="published" when="1995-12">Dec. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Lucas-Kanade 20 years on: A unifying framework</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="221" to="255" />
			<date type="published" when="2004-02">Feb. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Robust modified L2 local optical flow estimation and feature tracking</title>
		<author>
			<persName><forename type="first">T</forename><surname>Senst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Eiselein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Heras</forename><surname>Evangelio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sikora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE WMVC</title>
		<meeting>IEEE WMVC</meeting>
		<imprint>
			<date type="published" when="2011-01">Jan. 2011</date>
			<biblScope unit="page" from="685" to="690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Human-assisted motion annotation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Robust regression: Asymptotics, conjectures and Monte Carlo</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="799" to="821" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Robuste regression mit ausreissern in den erklärenden variablen</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Österreichische Zeitschrift für Statistik und Informatik (ZSI)</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="36" to="42" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Pyramidal implementation of the Lucas Kanade feature tracker</title>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Bouguet</surname></persName>
		</author>
		<ptr target="http://robots.stanford.edu/cs223b04/algo-tracking.pdf" />
	</analytic>
	<monogr>
		<title level="j">Microprocessor Res. Lab., Intel Corp</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<pubPlace>Hillsboro, OR</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Mixture models for optical flow computation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jepson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="760" to="761" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A database and evaluation methodology for optical flow</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<idno>MSR-TR-2009-179</idno>
	</analytic>
	<monogr>
		<title level="j">Microsoft Res</title>
		<imprint>
			<date type="published" when="2009-12">Dec. 2009</date>
			<pubPlace>Redmond, WA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Good features to track</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="593" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Robust estimation of a location parameter</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Statist</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="73" to="101" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Hampel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Ronchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Stahel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robust Statistics: The Approach Based on Influence Functions</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Wiley-Interscience</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Robust anisotropic diffusion</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Marimont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="421" to="432" />
			<date type="published" when="1998-03">Mar. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Robust methods of estimation of regression coefficients</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="53" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Robust regression using iteratively reweighted least-squares</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Welsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Statist.: Theory Methods</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="813" to="828" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Numerical solution of robust regression problems: computational aspects, a comparison</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Statist. Computat. Simulat</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="207" to="238" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Robust detection of a weak signal with redescending m-estimators: A comparative study</title>
		<author>
			<persName><forename type="first">G</forename><surname>Shevlyakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Adap. Contr. Signal Process</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="40" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
