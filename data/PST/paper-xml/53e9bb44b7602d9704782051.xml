<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Query Complexity of Derivative-Free Optimization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kevin</forename><forename type="middle">G</forename><surname>Jamieson</surname></persName>
							<email>kgjamieson@wisc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Wisconsin Madison</orgName>
								<address>
									<postCode>53706</postCode>
									<region>WI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><forename type="middle">D</forename><surname>Nowak</surname></persName>
							<email>nowak@engr.wisc.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Wisconsin Madison</orgName>
								<address>
									<postCode>53706</postCode>
									<region>WI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
							<email>brecht@cs.wisc.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Wisconsin Madison</orgName>
								<address>
									<postCode>53706</postCode>
									<region>WI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Query Complexity of Derivative-Free Optimization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">922FE7220DA4B7381C8FC6CB58115B6C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper provides lower bounds on the convergence rate of Derivative Free Optimization (DFO) with noisy function evaluations, exposing a fundamental and unavoidable gap between the performance of algorithms with access to gradients and those with access to only function evaluations. However, there are situations in which DFO is unavoidable, and for such situations we propose a new DFO algorithm that is proved to be near optimal for the class of strongly convex objective functions. A distinctive feature of the algorithm is that it uses only Boolean-valued function comparisons, rather than function evaluations. This makes the algorithm useful in an even wider range of applications, such as optimization based on paired comparisons from human subjects, for example. We also show that regardless of whether DFO is based on noisy function evaluations or Boolean-valued function comparisons, the convergence rate is the same.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Optimizing large-scale complex systems often requires the tuning of many parameters. With training data or simulations one can evaluate the relative merit, or incurred loss, of different parameter settings, but it may be unclear how each parameter influences the overall objective function. In such cases, derivatives of the objective function with respect to the parameters are unavailable. Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>. When function evaluations are noiseless, DFO methods can achieve the same rates of convergence as noiseless gradient methods up to a small factor depending on a low-order polynomial of the dimension <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b9">10]</ref>. This leads one to wonder if the same equivalence can be extended to the case when function evaluations and gradients are noisy.</p><p>Sadly, this paper proves otherwise. We show that when function evaluations are noisy, the optimization error of any DFO is ⌦( p 1/T ), where T is the number of evaluations. This lower bound holds even for strongly convex functions. In contrast, noisy gradient methods exhibit ⇥(1/T ) error scaling for strongly convex functions <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b10">11]</ref>. A consequence of our theory is that finite differencing cannot achieve the rates of gradient methods when the function evaluations are noisy.</p><p>On the positive side, we also present a new derivative-free algorithm that achieves this lower bound with near optimal dimension dependence. Moreover, the algorithm uses only boolean comparisons of function values, not actual function values. This makes the algorithm applicable to situations in which the optimization is only able to probably correctly decide if the value of one configuration is better than the value of another. This is especially interesting in optimization based on human subject feedback, where paired comparisons are often used instead of numerical scoring. The convergence rate of the new algorithm is optimal in terms of T and near-optimal in terms of its dependence on the ambient dimension. Surprisingly, our lower bounds show that this new algorithm that uses only function comparisons achieves the same rate in terms of T as any algorithm that has access to function evaluations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem formulation and background</head><p>We now formalize the notation and conventions for our analysis of DFO. A function f is strongly convex with constant ⌧ on a convex set B ⇢ R d if there exists a constant ⌧ &gt; 0 such that </p><formula xml:id="formula_0">f (y) f (x) + hrf (x), y xi + ⌧ 2 ||x</formula><formula xml:id="formula_1">P (C f (x, y) = sign{f (y) f (x)}) 1 2 + min 0 , µ|f (y) f (x)|  1<label>(1)</label></formula><p>for some 0 &lt; 0  1/2, µ &gt; 0 and  1. When  = 1, without loss of generality assume µ  0  1/2. Note  = 1 implies that the comparison oracle is correct with a probability that is greater than 1/2 and independent of x, y. If  &gt; 1, then the oracle's reliability decreases as the difference between f (x) and f (y) decreases.</p><p>To illustrate how the function comparison oracle and function evaluation oracles relate to each other, suppose C f (x, y) = sign{E f (y) E f (x)} where E f (x) is a function evaluation oracle with additive noise w. If w is Gaussian distributed with mean zero and variance 2 then  = 2 and µ 4⇡ 2 e 1/2 (see supplementary materials). In fact, this choice of w corresponds to Thurston's law of comparative judgment which is a popular model for outcomes of pairwise comparisons from human subjects <ref type="bibr" target="#b11">[12]</ref>. If w is a "spikier" distribution such as a two-sided Gamma distribution with shape parameter in the range of (0, 1] then all values of  2 (1, 2] can be realized (see supplementary materials).</p><p>Interest in the function comparison oracle is motivated by certain popular derivative-free optimization procedures that use only comparisons of function evaluations (e.g. <ref type="bibr" target="#b6">[7]</ref>) and by optimization problems involving human subjects making paired comparisons (for instance, getting fitted for prescription lenses or a hearing aid where unknown parameters specific to each person are tuned with the familiar queries "better or worse?"). Pairwise comparisons have also been suggested as a novel way to tune web-search algorithms <ref type="bibr" target="#b12">[13]</ref>. Pairwise comparison strategies have previously been analyzed in the finite setting where the task is to identify the best alternative among a finite set of alternatives (sometimes referred to as the dueling-bandit problem) <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>. The function comparison oracle presented in this work and its analysis are novel. The main contributions of this work and new art are as follows (i) lower bounds for the function evaluation oracle in the presence of measurement noise (ii) lower bounds for the function comparison oracle in the presence of noise and (iii) an algorithm for the function comparison oracle, which can also be applied to the function evaluation oracle setting, that nearly matches both the lower bounds of (i) and (ii).</p><p>We prove our lower bounds for strongly convex functions with Lipschitz gradients defined on a compact, convex set B, and because these problems are a subset of those involving all convex functions (and have non-empty intersection with problems where f is merely Lipschitz), the lower bound also applies to these larger classes. While there are known theoretical results for DFO in the noiseless setting <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b9">10]</ref>, to the best of our knowledge we are the first to characterize lower bounds for DFO in the stochastic setting. Moreover, we believe we are the first to show a novel upper bound for stochastic DFO using a function comparison oracle (which also applies to the function evaluation oracle). However, there are algorithms with upper bounds on the rates of convergence for stochastic DFO with the function evaluation oracle <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>. We discuss the relevant results in the next section following the lower bounds .</p><p>While there remains many open problems in stochastic DFO (see Section 6), rates of convergence with a stochastic gradient oracle are well known and were first lower bounded by Nemirovski and Yudin <ref type="bibr" target="#b14">[15]</ref>. These classic results were recently tightened to show a dependence on the dimension of the problem <ref type="bibr" target="#b16">[17]</ref>. And then tightened again to show a better dependence on the noise <ref type="bibr" target="#b10">[11]</ref> which matches the upper bound achieved by stochastic gradient descent <ref type="bibr" target="#b8">[9]</ref>. The aim of this work is to start filling in the knowledge gaps of stochastic DFO so that it is as well understood as the stochastic gradient oracle. Our bounds are based on simple techniques borrowed from the statistical learning literature that use natural functions and oracles in the same spirit of <ref type="bibr" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Main results</head><p>The results below are presented with simplifying constants that encompass many factors to aid in exposition. Explicit constants are given in the proofs in Sections 4 and 5. Throughout, we denote the minimizer of f as x ⇤ f . The expectation in the bounds is with respect to the noise in the oracle queries and (possible) optimization algorithm randomization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Query complexity of the function comparison oracle</head><p>Theorem 1. For every f 2 F ⌧,L,B let C f be a function comparison oracle with parameters (, µ, 0 ). Then for n 8 and sufficiently large</p><formula xml:id="formula_2">T inf b x T sup f 2F ⌧,L,B E ⇥ f (b x T ) f (x ⇤ f ) ⇤ 8 &lt; : c 1 exp c 2 T n if  = 1 c 3 n T 1 2( 1) if  &gt; 1</formula><p>where the infimum is over the collection of all possible estimators of x ⇤ f using at most T queries to a function comparison oracle and the supremum is taken with respect to all problems in F ⌧,L,B and function comparison oracles with parameters (, µ, 0 ). The constants c 1 , c 2 , c 3 depend the oracle and function class parameters, as well as the geometry of B, but are independent of T and n.</p><p>For upper bounds we propose a specific algorithm based on coordinate-descent in Section 5 and prove the following theorem for the case of unconstrained optimization, that is, B = R n . Theorem 2. For every f 2 F ⌧,L,B with B = R n let C f be a function comparison oracle with parameters (, µ, 0 ). Then there exists a coordinate-descent algorithm that is adaptive to unknown  1 that outputs an estimate b</p><p>x T after T function comparison queries such that with probability</p><formula xml:id="formula_3">1 sup f 2F ⌧,L,B E ⇥ f (b x T ) f (x ⇤ f ) ⇤  8 &gt; &lt; &gt; : c 1 exp n c 2 q T n o if  = 1 c 3 n n T 1 2( 1) if  &gt; 1 where c 1 , c 2 , c</formula><p>3 depend the oracle and function class parameters as well as T ,n, and 1/ , but only poly-logarithmically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Query complexity of the function evaluation oracle</head><p>Theorem 3. For every f 2 F ⌧,L,B let E f be a function evaluation oracle with variance 2 . Then for n 8 and sufficiently large T</p><formula xml:id="formula_4">inf b x T sup f 2F ⌧,L,B E ⇥ f (b x T ) f (x ⇤ f ) ⇤ c ✓ n 2 T ◆ 1 2</formula><p>where the infimum is taken with respect to the collection of all possible estimators of x ⇤ f using just T queries to a function evaluation oracle and the supremum is taken with respect to all problems in F ⌧,L,B and function evaluation oracles with variance 2 . The constant c depends on the oracle and function class parameters, as well as the geometry of B, but is independent of T and n.</p><p>Because a function evaluation oracle can always be turned into a function comparison oracle (see discussion above), the algorithm and upper bound in Theorem 2 with  = 2 applies to many typical function evaluation oracles (e.g. additive Gaussian noise), yielding an upper bound of n 3 2 /T 1/2 ignoring constants and log factors. This matches the rate of convergence as a function of T and 2 , but has worse dependence on the dimension n.</p><p>Alternatively, under a less restrictive setting, Nemirovski and Yudin proposed two algorithms for the class of convex, Lipschitz functions that obtain rates of n 1/2 /T 1/4 and p(n)/T 1/2 , respectively, where p(n) was left as an unspecified polynomial of n <ref type="bibr" target="#b14">[15]</ref>. While focusing on stochastic DFO with bandit feedback, Agarwal et. al. built on the ideas developed in <ref type="bibr" target="#b14">[15]</ref> to obtain a result that they point out implies a convergence rate of n 16 /T 1/2 in the optimization setting considered here <ref type="bibr" target="#b15">[16]</ref>. Whether or not these rates can be improved to those obtained under the more restrictive function classes of above is an open question.</p><p>A related but fundamentally different problem that is somewhat related with the setting considered in this paper is described as online (or stochastic) convex optimization with multi-point feedback <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b18">19]</ref>. Essentially, this setting allows the algorithm to probe the value of the function f plus noise at multiple locations where the noise changes at each time step, but each set of samples at each time experiences the same noise. Because the noise model of that work is incompatible with the one considered here, no comparisons should be made between the two.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Lower Bounds</head><p>The lower bounds in Theorems 1 and 3 are proved using a general minimax bound [20, Thm. 2.5]. Our proofs are most related to the approach developed in <ref type="bibr" target="#b20">[21]</ref> for active learning, which like optimization involves a Markovian sampling process. Roughly speaking, the lower bounds are established by considering a simple case of the optimization problem in which the global minimum is known a priori to belong to a finite set. Since the simple case is "easier" than the original optimization, the minimum number of queries required for a desired level of accuracy in this case yields a lower bound for the original problem.</p><p>The following theorem is used to prove the bounds. In the terms of the theorem, f is a function to be minimized and P f is the probability model governing the noise associated with queries when f is the true function. Theorem 4. [20, Thm. 2.5] Consider a class of functions F and an associated family of probability measures {P f } f 2F . Let M 2 be an integer and f 0 , f 1 , . . . , f M be functions in F. Let d(•, •) : F ⇥ F ! R be a semi-distance and assume that:</p><formula xml:id="formula_5">1. d(f i , f j ) 2s &gt; 0, for all 0  i &lt; j  M , 2. 1 M P M j=1 KL(P i ||P 0 )  a log M , where the Kullback-Leibler divergence KL(P i ||P 0 ) := R log dPi dP0 dP</formula><p>i is assumed to be well-defined (i.e., P 0 is a dominating measure) and 0 &lt; a &lt; 1/8 . Then</p><formula xml:id="formula_6">inf b f sup f 2F P(d( b f, f) s) inf b f max f 2{f0,...,f M } P(d( b f, f) s) p M 1+ p M ⇣ 1 2a 2 q a log M ⌘ &gt; 0 ,</formula><p>where the infimum is taken over all possible estimators based on a sample from P f . We are concerned with the functions in the class F := F ⌧,L,B . The volume of B will affect only constant factors in our bounds, so we will simply denote the class of functions by F and refer explicitly to B only when necessary. Let x f := arg min x f (x), for all f 2 F. The semi-distance we use is d(f, g) := kx f x g ||, for all f, g 2 F. Note that each point in B can be specified by one of many f 2 F. So the problem of selecting an f is equivalent to selecting a point x 2 B. Indeed, the semi-distance defines a collection of equivalence classes in F (i.e., all functions having a minimum at x 2 B are equivalent). For every f 2 F we have inf g2F f (x g ) = inf x2B f (x), which is a useful identity to keep in mind.</p><p>We now construct the functions f 0 , f 1 , . . . , f M that will be used for our proofs.</p><formula xml:id="formula_7">Let ⌦ = { 1, 1} n so that each ! 2 ⌦ is a vertex of the d-dimensional hypercube. Let V ⇢ ⌦ with cardinality |V| 2 n/8</formula><p>such that for all ! 6 = ! 0 2 V, we have ⇢(!, ! 0</p><p>) n/8 where ⇢(•, •) is the Hamming distance. It is known that such a set exists by the Varshamov-Gilbert bound [20, Lemma 2.9]. Denote the elements of V by ! 0 , ! 1 , . . . , ! M . Next we state some elementary bounds on the functions that will be used in our analysis. Lemma 1. For ✏ &gt; 0 define the set B ⇢ R n to be the `1 ball of radius ✏ and define the functions on B:</p><formula xml:id="formula_8">f i (x) := ⌧ 2 ||x ✏! i || 2</formula><p>, for i = 0, . . . , M, ! i 2 V, and x i := arg min x f i (x) = ✏! i . Then for all 0  i &lt; j  M and x 2 B the functions f i (x) satisfy 1. f i is strongly convex-⌧ with Lipschitz-⌧ gradients and</p><formula xml:id="formula_9">x i 2 B 2. ||x i x j || ✏ p n 2 3. |f i (x) f j (x)|  2⌧ n✏ 2 .</formula><p>We are now ready to prove Theorems 1 and 3. Each proof uses the functions f 0 , . . . , f M a bit differently, and since the noise model is also different in each case, the KL divergence is bounded differently in each proof. We use the fact that if X and Y are random variables distributed according to Bernoulli distributions P X and P Y with parameters 1/2 + µ and 1/2 µ, then KL(P</p><formula xml:id="formula_10">X ||P Y )  4µ 2 /(1/2 µ). Also, if X ⇠ N (µ X , 2 ) =: P X and Y ⇠ N (µ Y , 2 ) =: P y then KL(P X ||P Y ) = 1 2 2 ||µ X µ Y || 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Proof of Theorem 1</head><p>First we will obtain the bound for the case  &gt; 1. Let the comparison oracle satisfy</p><formula xml:id="formula_11">P (C fi (x, y) = sign{f i (y) f i (x)}) = 1 2 + min µ|f i (y) f i (x)|  1 , 0 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>In words, C</head><p>fi (x, y) is correct with probability as large as the right-hand-side of above and is monotonic increasing in f </p><formula xml:id="formula_12">i (y) f i (x). Let {x k , y k } T</formula><formula xml:id="formula_13">given {x k , y k , C fi (x k , y k )} ` 1 k=1 .</formula><p>Note that S `is only a function of the underlying optimization algorithm and does not depend on i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>KL(P</head><formula xml:id="formula_14">i,T ||P j,T ) = E P i,T  log P i,T P j,T = E P i,T " log Q T `=1 Q i,`SQ T `=1 Q j,`S`# = E P i,T " log Q T `=1 Q i,Q T `=1 Q j,`# = T X `=1 E P i,T  E P i,T  log Q i,Q j,` {x k , y k } T k=1  T sup x1,y12B E Pi,1  E Pi,1  log Q i,1 Q j,1 x 1 , y 1 By the second claim of Lemma 1, |f i (x) f j (x)|  2⌧ n✏ 2</formula><p>, and therefore the bound above is less than or equal to the KL divergence between the Bernoulli distributions with parameters 1  2 ± µ 2⌧ n✏ 2 ( 1) , yielding the bound</p><formula xml:id="formula_15">KL(P i,T |P j,T )  4T µ 2 2⌧ n✏ 2 2( 1) 1/2 µ (2⌧ n✏ 2 ) ( 1)  16T µ 2 2⌧ n✏ 2 2( 1)</formula><p>provided ✏ is sufficiently small. We also assume ✏ (or, equivalently, B) is sufficiently small so that</p><formula xml:id="formula_16">|f i (x) f j (x)|  1  0 .</formula><p>We are now ready to apply Theorem 4. Recalling that M 2 n/8 , we want to choose ✏ such that</p><formula xml:id="formula_17">KL(P i,T |P j,T )  16T µ 2 2⌧ n✏ 2 2( 1)  a n 8 log(2)  a log M</formula><p>with an a small enough so that we can apply the theorem. By setting a = 1/16 and equating the two sides of the equation we have</p><formula xml:id="formula_18">✏ = ✏ T := 1 2 p n 2 ⌧ 1/2 ⇣ n log(2) 2048µ 2 T</formula><p>⌘ 1 4( 1) (note that this also implies a sequence of sets B T by the definition of the functions in Lemma 1). Thus, the semi-distance satisfies</p><formula xml:id="formula_19">d(f j , f i ) = ||x j x i || p n/2✏ T 1 2 p 2 ✓ 2 ⌧ ◆ 1/2 ✓ n log(2) 2048µ 2 T ◆ 1 4( 1)</formula><p>=: 2s T .</p><p>Applying Theorem 4 we have</p><formula xml:id="formula_20">inf b f sup f 2F P(kx b f x f k s T ) inf b f max i2{0,...,M } P(kx b f x i k s T ) = inf b f max i2{0,...,M } P(d( b f, f i ) s T ) p M 1+ p M ⇣ 1 2a 2 q a log M ⌘ &gt; 1/7 ,</formula><p>where the final inequality holds since M 2 and a = 1/16. Strong convexity implies that f (x)</p><formula xml:id="formula_21">f (x f ) ⌧ 2 ||x x f || 2 for all f 2 F and x 2 B. Therefore inf b f sup f 2F P ⇣ f (x b f ) f (x f ) ⌧ 2 s 2 T ⌘ inf b f max i2{0,...,M } P ⇣ f i (x b f ) f i (x i ) ⌧ 2 s 2 T ⌘ inf b f max i2{0,...,M } P ⇣ ⌧ 2 kx b f x i k 2 ⌧ 2 s 2 T ⌘ = inf b f max i2{0,...,M } P ⇣ kx b f x i k s T ⌘ &gt; 1/7 .</formula><p>Finally, applying Markov's inequality we have</p><formula xml:id="formula_22">inf b f sup f 2F E h f (x b f ) f (x f ) i 1 7 ✓ 1 32 ◆ ✓ n log(2) 2048µ 2 T . ◆ 1 2( 1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Proof of Theorem 1 for  = 1</head><p>To handle the case when  = 1 we use functions of the same form, but the construction is slightly different. Let `be a positive integer and let M = `n. Let {⇠ i } M i=1 be a set of uniformly space points in B which we define to be the unit cube in R n , so that k⇠ i ⇠ j k ` 1 for all i 6 = j. Define</p><formula xml:id="formula_23">f i (x) := ||x ⇠ i || 2 , i = 1, . . . , M. Let s := 1 2`s o that d(f i , f j ) := ||x ⇤ i x ⇤ j || 2s. Because  = 1, we have P (C fi (x, y) = sign{f i (y) f i (x)}</formula><p>) µ for some µ &gt; 0, all i 2 {1, . . . , M}, and all x, y 2 B. We bound KL(P i,T ||P j,T ) in exactly the same way as we bounded it in Section 4.1 except that now we have</p><formula xml:id="formula_24">C fi (x k , y k ) ⇠ Bernoulli( 1 2 + µ) and C fj (x k , y k ) ⇠ Bernoulli( 1<label>2</label></formula><p>µ). It then follows that if we wish to apply the theorem, we want to choose s so that</p><formula xml:id="formula_25">KL(P i,T |P j,T )  2T µ 2 /(1/2 µ)  a log M = an log 1 2s</formula><p>for some a &lt; 1/8. Using the same sequence of steps as in Section 4.1 we have</p><formula xml:id="formula_26">inf b f sup f 2F E h f (x b f ) f (x f ) i 1 7 ✓ 1 2 ◆ 2 exp ⇢ 128T µ 2 n(1/2 µ) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Proof of Theorem 3</head><p>Let f i for all i = 0, . . . , M be the functions considered in Lemma 1. Recall that the evaluation oracle is defined to be E f (x) := f (x) + w, where w is a random variable (independent of all other random variables under consideration) with</p><formula xml:id="formula_27">E[w] = 0 and E[w 2 ] = 2 &gt; 0. Let {x k } n k=1 be a sequence of points in B ⇢ R n and let {E f (x k )} T k=1 denote the corresponding sequence of noisy evaluations of f 2 F. For `= 1, . . . , T let P i,`d enote the joint probability distribution of {x k , E fi (x k )} k=1 , let Q i,`d enote the conditional distribution of E fi (x k ) given x k , and let S `denote the conditional distribution of x `given {x k , E f (x k )} ` 1 k=1 . S</formula><p>`is a function of the underlying optimization algorithm and does not depend on i. We can now bound the KL divergence between any two hypotheses as in Section 4.1:</p><formula xml:id="formula_28">KL(P i,T ||P j,T )  T sup x12B E Pi,1  E Pi,1  log Q i,1 Q j,1 x 1 .</formula><p>To compute a bound, let us assume that w is Gaussian distributed. Then KL(P</p><formula xml:id="formula_29">i,T ||P j,T )  T sup z2B KL N (f i (z), 2 )||N (f j (z), 2 ) = T 2 2 sup z2B |f i (z) f j (z)| 2  T 2 2 2⌧ n✏ 2 2</formula><p>by the third claim of Lemma 1. We then repeat the same procedure as in Section 4.1 to attain</p><formula xml:id="formula_30">inf b f sup f 2F E h f (x b f ) f (x f ) i 1 7 ✓ 1 32 ◆ ✓ n 2 log(2) 64T ◆ 1 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Upper bounds</head><p>The algorithm that achieves the upper bound using a pairwise comparison oracle is a combination of standard techniques and methods from the convex optimization and statistical learning literature.</p><p>The algorithm is explained in full detail in the supplementary materials, and is summarized as follows. At each iteration the algorithm picks a coordinate uniformly at random from the n possible dimensions and then performs an approximate line search. By exploiting the fact that the function is strongly convex with Lipschitz gradients, one guarantees using standard arguments that the approximate line search makes a sufficient decrease in the objective function value in expectation <ref type="bibr" target="#b21">[22,</ref><ref type="bibr">Ch.9.3]</ref>. If the pairwise comparison oracle made no errors then the approximate line search is accomplished by a binary-search-like scheme, essentially a golden section line-search algorithm <ref type="bibr" target="#b22">[23]</ref>. However, when responses from the oracle are only probably correct we make the line-search robust to errors by repeating the same query until we can be confident about the true, uncorrupted direction of the pairwise comparison using a standard procedure from the active learning literature <ref type="bibr" target="#b23">[24]</ref> (a similar technique was also implemented for the bandit setting of derivate-free optimization <ref type="bibr" target="#b7">[8]</ref>). Because the analysis of each component is either known or elementary, we only sketch the proof here and leave the details to the supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Coordinate descent</head><p>Given a candidate solution x k after k 0 iterations, the algorithm defines a search direction d k = e i where i is chosen uniformly at random from the possible n dimensions and e i is a vector of all zeros except for a one in the ith coordinate. We note that while we only analyze the case where the search direction d k is a coordinate direction, an analysis with the same result can be obtained with d k chosen uniformly from the unit sphere. Given d k , a line search is then performed to find an</p><formula xml:id="formula_31">↵ k 2 R such that f (x k+1 ) f (x k ) is sufficiently small where x k+1 = x k + ↵ k d k .</formula><p>In fact, as we will see in the next section, for some input parameter ⌘ &gt; 0, the line search is guaranteed to return an</p><formula xml:id="formula_32">↵ k such that |↵ k ↵ ⇤ |  ⌘ where ↵ ⇤ = min ↵2R f (x k + d k ↵ ⇤ ).</formula><p>Using the fact that the gradients of f are Lipschitz (L) we have</p><formula xml:id="formula_33">f (x k + ↵ k d k ) f (x k + ↵ ⇤ d k )  L 2 ||(↵ k ↵ ⇤ )d k || 2 = L 2 |↵ k ↵ ⇤ | 2  L 2 ⌘ 2 .</formula><p>If we define ↵k = hrf (x k ),d k i L then we have</p><formula xml:id="formula_34">f (x k + ↵ k d k ) f (x k )  f (x k + ↵ ⇤ d k ) f (x k ) + L 2 ⌘ 2  f (x k + ↵k d k ) f (x k ) + L 2 ⌘ 2  hrf (x k ), d k i 2 2L + L 2 ⌘ 2</formula><p>where the last line follows from applying the fact that the gradients are Lipschitz (L). Arranging the bound and taking the expectation with respect to d k we get</p><formula xml:id="formula_35">E [f (x k+1 ) f (x ⇤ )] L 2 ⌘ 2  E [f (x k ) f (x ⇤ )] E[||rf (x k )|| 2 ] 2nL  E [f (x k ) f (x ⇤ )] 1 ⌧ 4nL</formula><p>where the second inequality follows from the fact that f is strongly convex (⌧ ). If we define ⇢</p><formula xml:id="formula_36">k := E [f (x k ) f (x ⇤ )] then we equivalently have ⇢ k+1 2nL 2 ⌘ 2 ⌧  ⇣ 1 ⌧ 4nL ⌘ ✓ ⇢ k 2nL 2 ⌘ 2 ⌧ ◆  ⇣ 1 ⌧ 4nL ⌘ k ✓ ⇢ 0 2nL 2 ⌘ 2 ⌧</formula><p>◆ which leads to the following result.</p><p>Theorem 5. Let f 2 F ⌧,L,B with B = R n . For any ⌘ &gt; 0 assume the line search returns an ↵ k that is within ⌘ of the optimal after at most T `(⌘) queries from the pairwise comparison oracle. If x K is an estimate of x ⇤ = arg min x f (x) after requesting no more than K pairwise comparisons, then</p><formula xml:id="formula_37">sup f E[f (x K ) f (x ⇤ )]  4nL 2 ⌘ 2 ⌧ whenever K 4nL ⌧ log ⇣ f (x0) f (x ⇤ ) ⌘ 2 2nL 2 /⌧ ⌘ T `(⌘)</formula><p>where the expectation is with respect to the random choice of d k at each iteration. This implies that if we wish sup</p><formula xml:id="formula_38">f E[f (x K ) f (x ⇤ )]  ✏ it suffices to take ⌘ = p ✏⌧ 4nL 2 so that at most 4nL ⌧ log ⇣ f (x0) f (x ⇤ ) ✏/2 ⌘ T ` p ✏⌧ 4nL<label>2</label></formula><p>pairwise comparisons are requested.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Line search</head><p>This section is concerned with minimizing a function f</p><formula xml:id="formula_39">(x k +↵ k d k ) over some ↵ k 2 R.</formula><p>In particular, we wish to find an ↵</p><formula xml:id="formula_40">k 2 R such that |↵ k ↵ ⇤ |  ⌘ where ↵ ⇤ = min ↵2R f (x k +d k ↵ ⇤</formula><p>). First assume that the function comparison oracle makes no errors. The line search operates by maintaining a pair of boundary points ↵ + , ↵ such that if at some iterate we have ↵ ⇤ 2 [↵ , ↵ + ] then at the next iterate, we are guaranteed that ↵ ⇤ is still contained inside the boundary points but</p><formula xml:id="formula_41">|↵ + ↵ | 1 2 |↵ + ↵ |.</formula><p>An initial set of boundary points ↵ + &gt; 0 and ↵ &lt; 0 are found using simple binary search. Thus, regardless of how far away or close ↵ ⇤ is, we converge to it exponentially fast. Exploiting the fact that f is strongly convex (⌧ ) with Lipschitz (L) gradients we can bound how far away or close ↵ ⇤ is from our initial iterate. Theorem 6. Let f 2 F ⌧,L,B with B = R n and let C f be a function comparison oracle that makes no errors. Let x 2 R n be an initial position and let d 2 R n be a search direction with ||d|| = 1. If ↵ K is an estimate of ↵ ⇤ = arg min ↵ f (x + d↵) that is output from the line search after requesting no more than K pairwise comparisons, then for any ⌘ &gt; 0</p><formula xml:id="formula_42">|↵ K ↵ ⇤ |  ⌘ whenever K 2 log 2 ⇣ 256L(f (x) f (x+d ↵ ⇤ )) ⌧ 2 ⌘ 2 ⌘ .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Making the line search robust to errors</head><p>Now assume that the responses from the pairwise comparison oracle are only probably correct in accordance with the model introduced above. Essentially, the robust procedure runs the line search as if the oracle made no errors except that each time a comparison is needed, the oracle is repeatedly queried until we can be confident about the true direction of the comparison. This strategy applied to active learning is well known because of its simplicity and its ability to adapt to unknown noise conditions <ref type="bibr" target="#b23">[24]</ref>. However, we mention that when used in this way, this sampling procedure is known to be sub-optimal so in practice, one may want to implement a more efficient approach like that of <ref type="bibr" target="#b20">[21]</ref>. Nevertheless, we have the following lemma. Lemma 2. <ref type="bibr" target="#b23">[24]</ref> For any x, y 2 B with P (C f (x, y) = sign{f (y) f (x)}) = p, with probability at least 1 the coin-tossing algorithm of <ref type="bibr" target="#b23">[24]</ref> correctly identifies the sign of E [C f (x, y)] and requests no more than log(2/ ) 4|1/2 p| 2 log It would be convenient if we could simply apply the result of Lemma 2 to our line search procedure.</p><p>Unfortunately, if we do this there is no guarantee that |f (y) f (x)| is bounded below so for the case when  &gt; 1, it would be impossible to lower bound |1/2 p| in the lemma. To account for this, we will sample at multiple locations per iteration as opposed to just two in the noiseless algorithm to ensure that we can always lower bound |1/2 p|. Intuitively, strong convexity ensures that f cannot be arbitrarily flat so for any three equally spaced points x, y, z on the line d k , if f (x) is equal to f (y), then it follows that the absolute difference between f (x) and f (z) must be bounded away from zero. Applying this idea and union bounding over the total number of times one must call the coin-tossing algorithm, one finds that with probability at least 1 </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2 ⇣ffor  = 1 ,</head><label>21</label><figDesc>, the total number of calls to the pairwise comparison oracle over the course of the whole algorithm does not exceed e O (x0) f (x ⇤ ) ✏ ⌘ log(n/ ) ⌘ . By finding a T &gt; 0 that satisfies this bound for any ✏ we see that this is equivalent to a rate of O ⇣ n log(n/ ) ignoring polylog factors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The class of strongly convex functions with Lipschitz gradients defined on a nonempty, convex set B ⇢ R n which take their minimum in B with parameters ⌧ and L is denoted by F ⌧,L,B . The problem we consider is minimizing a function f 2 F ⌧,L,B . The function f is not explicitly known. An optimization procedure may only query the function in one of the following two ways.Function Evaluation Oracle: For any point x 2 B an optimization procedure can observe E</figDesc><table /><note><p>y|| 2 for all x, y 2 B. The gradient of f , if it exists, denoted rf , is Lipschitz with constant L if ||rf (x) rf (y)||  L||x y|| for some L &gt; 0. f (x) = f (x) + w where w 2 R is a random variable with E[w] = 0 and E[w 2 ] = 2 . Function Comparison Oracle: For any pair of points x, y 2 B an optimization procedure can observe a binary random variable C f (x, y) satisfying</p></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Efficient optimization of support vector machine learning parameters for unbalanced datasets</title>
		<author>
			<persName><forename type="first">T</forename><surname>Eitrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computational and applied mathematics</title>
		<imprint>
			<biblScope unit="volume">196</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="425" to="436" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A new derivative-free algorithm for the medical image registration problem</title>
		<author>
			<persName><forename type="first">R</forename><surname>Oeuvray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bierlaire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Modelling and Simulation</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="124" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Introduction to derivative-free optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Conn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Scheinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">N</forename><surname>Vicente</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Society for Industrial Mathematics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Warren</forename><forename type="middle">B</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><forename type="middle">O</forename><surname>Ryzhov</surname></persName>
		</author>
		<title level="m">Optimal Learning</title>
		<imprint>
			<publisher>John Wiley and Sons</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Random gradient-free minimization of convex functions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>CORE Discussion Papers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Gaussian process optimization in the bandit setting: No regret and experimental design</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Seeger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0912.3995</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">Arxiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of global optimization</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Stochastic convex optimization with bandit feedback</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rakhlin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1107.1744</idno>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="report_type">Arxiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Robust stochastic approximation approach to stochastic programming</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nemirovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Juditsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">1574</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Algorithms for approximate calculation of the minimum of a convex function from its values</title>
		<author>
			<persName><forename type="first">V</forename><surname>Protasov</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02312467</idno>
	</analytic>
	<monogr>
		<title level="s">Mathematical Notes</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="69" to="74" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Information-based complexity, feedback, and dynamics in convex programming. Information Theory</title>
		<author>
			<persName><forename type="first">M</forename><surname>Raginsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rakhlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A law of comparative judgment</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Thurstone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review; Psychological Review</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">273</biblScope>
			<date type="published" when="1927">1927</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The k-armed dueling bandits problem</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Broder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Active ranking using pairwise comparisons</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Jamieson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Nowak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Problem complexity and method efficiency in optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Nemirovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Yudin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Stochastic convex optimization with bandit feedback</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rakhlin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1107.1744</idno>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="report_type">Arxiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Information-theoretic lower bounds on the oracle complexity of stochastic convex optimization. Information Theory</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Optimal algorithms for online convex optimization with multi-point bandit feedback</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Dekel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory (COLT)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Stochastic first-and zeroth-order methods for nonconvex stochastic programming</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ghadimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Introduction to nonparametric estimation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Tsybakov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Minimax bounds for active learning. Information Theory</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Nowak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2339" to="2353" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vandenberghe</surname></persName>
		</author>
		<title level="m">Convex optimization</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>Cambridge Univ Pr</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Algorithms for minimization without derivatives</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Brent</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Dover Pubns</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Active learning in the non-realizable case</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kääriäinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Algorithmic Learning Theory</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="63" to="77" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
