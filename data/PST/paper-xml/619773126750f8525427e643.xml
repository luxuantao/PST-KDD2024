<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Discerning Decision-Making Process of Deep Neural Networks with Hierarchical Voting Transformation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ying</forename><surname>Sun</surname></persName>
							<email>sunying17g@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">IIP</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Baidu Talent Intelligence Center</orgName>
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
							<email>zhuhengshu@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="department">Baidu Talent Intelligence Center</orgName>
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chuan</forename><surname>Qin</surname></persName>
							<email>chuanqin0426@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="department">Baidu Talent Intelligence Center</orgName>
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fuzhen</forename><surname>Zhuang</surname></persName>
							<email>zhuangfuzhen@buaa.edu.cn</email>
							<affiliation key="aff2">
								<orgName type="department">Institute of Artificial Intelligence</orgName>
								<orgName type="institution">Beihang University</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department" key="dep1">SKLSDE</orgName>
								<orgName type="department" key="dep2">School of Computer Science</orgName>
								<orgName type="institution">Beihang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qing</forename><surname>He</surname></persName>
							<email>heqing@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">IIP</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
							<email>xionghui@ust.hk</email>
							<affiliation key="aff3">
								<orgName type="laboratory">Artificial Intelligence Thrust</orgName>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="laboratory">35th Conference on Neural Information Processing Systems</orgName>
								<address>
									<postCode>2021)</postCode>
									<settlement>Sydney</settlement>
									<region>NeurIPS</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Discerning Decision-Making Process of Deep Neural Networks with Hierarchical Voting Transformation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">Concept Observation Voting Channel Counting Layer Decision Score Voting Layer 1 Voting Layer 2 Voting Layer D … Model Pruning Relevance Analysis Decision Path Recognition</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Neural network based deep learning techniques have shown great success for numerous applications. While it is expected to understand their intrinsic decisionmaking processes, these deep neural networks often work in a black-box way. To this end, in this paper, we aim to discern the decision-making processes of neural networks through a hierarchical voting strategy by developing an explainable deep learning model, namely Voting Transformation-based Explainable Neural Network (VOTEN). Specifically, instead of relying on massive feature combinations, VOTEN creatively models expressive single-valued voting functions between explicitly modeled latent concepts to achieve high fitting ability. Along this line, we first theoretically analyze the major components of VOTEN and prove the relationship and advantages of VOTEN compared with Multi-Layer Perceptron (MLP), the basic structure of deep neural networks. Moreover, we design efficient algorithms to improve the model usability by explicitly showing the decision processes of VOTEN. Finally, extensive experiments on multiple real-world datasets clearly validate the performances and explainability of VOTEN.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Neural network based deep learning techniques have attracted great attention from both academia and industry in the past decade. Compared with classic machine learning models, deep neural networks have much higher expressiveness and adaptability for complicated data input, and thus have made tremendous success in various application domains, such as Computational Vision <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b55">56]</ref>, Natural Language Processing <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b19">20]</ref>, and Recommender Systems <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b23">24]</ref>. Nevertheless, since deep neural networks usually have complicated connections of hidden units, a long-standing challenge is how to decipher what's inside the black box of models for understanding their intrinsic decision-making processes. Indeed, in many real-world scenarios, such as business analysis <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b48">49]</ref> and human resource management <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b43">44]</ref>, the lack of model explainability makes people less likely to be convinced when the decision-making process of the model is not understandable. This prevents a broader application of deep neural networks.</p><p>While many research efforts have been made in developing explainable deep learning models <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b9">10]</ref>, most of existing works focus on post-hoc explanation <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18]</ref>, i.e., designing metrics to measure the feature relevance/contribution to the outputs of a trained model. Although these methods have made progress on finding important features, the decision-making process of deep learning models is still not available for users. For example, users often need to guess the reason why a prediction is made from the relevant features instead of understanding the decision-making process. Indeed, understanding the intrinsic decision-making process of deep neural networks is a non-trivial task. A major reason is that deep neural networks usually involve massive feature combinations to gain expressiveness on fitting complicated functions. During this process, the effect of features and hidden units may be largely coupled with each other. This indicates that the decision logic of models is inherently buried in the massive feature combinations. Meanwhile, it is difficult for human to understand the intrinsic modeling process of deep learning in a natural manner. Therefore, a key point on improving the explainability of deep neural networks is to decouple the feature combinations and make the modeling process consistent with human decision process. In this way, the model will have an explicit decision-making process and become human-understandable.</p><p>To this end, in this paper, we propose an explainable deep learning model, namely Voting Transformation-based Explainable Neural Network (VOTEN). Specifically, VOTEN assumes the transformation from the input to the output to be a hierarchical voting process. During this process, lower-level concepts vote for higher-level concepts layer-by-layer in an expressive but explainable way. Instead of relying on massive feature combinations, VOTEN creatively models expressive single-valued voting functions between explicitly modeled hidden concepts to gain expressiveness on fitting complicated functions. This process is explainable for its consistency with human decisionmaking process. We first theoretically analyze the major components of VOTEN and prove the relationship and advantages of VOTEN compared with Multi-Layer Perceptron (MLP), which is the basic structure of deep neural networks. The results show that MLP can be derived from VOTEN by using the inexpressive voting functions. Accordingly, we further analyze the effect of inherent votings and design efficient algorithms for pruning and explaining VOTEN. Finally, we evaluated VOTEN on multiple real-world datasets with comprehensive experiments. The experimental results demonstrate that VOTEN generally promotes powerful and explainable deep learning. Specifically, VOTEN (1) significantly raises prediction performance; (2) exponentially decreases feature combinations; and (3) supports efficient pruning and effective feature analysis. Meanwhile, we also visualize the intrinsic decision-making process of VOTEN through case studies, which show VOTEN is explainable and can discover meaningful latent concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">VOTEN</head><p>In this section, we introduce the technical details of VOTEN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Structure</head><p>When dealing with complicated information, we usually aggregate them step-by-step to form complicated inference. Although deep neural networks also extract abstract features layer-by-layer, they are still difficult to be explained. A major difference is that we can induce explicit concepts, which makes us able to explain our inference in a straightforward way.</p><p>For example, we can predict that "This student may get high GPA because he/she works very hard". If the more explicit explanation is needed, we can further explain that "I observed that he/she stay long in the library". In this process, with the observation that "stay long in the library", we first infer "hard-working", then infer "high GPA". Moreover, when trying to make more comprehensive inference, we may get more observations for existing concepts (e.g., "little missing of classes" may also imply "hard-working"), or induce more concepts (e.g., "learning-efficiency"). This kind of process is straightforward and conforms with our way of understanding. However, deep neural networks cannot model concepts in an explicit way. Instead, concept information are embedded in massive hidden units. As we cannot understand these induced concepts, neural networks are like unified, inseparable complicated functions, even though they are actually performing information aggregation. Along this line, we believe a natural way to understand how a model decides the output is to make the intrinsic concepts explicit for human.</p><p>Therefore, we propose VOTEN, whose structure overview is shown in Figure <ref type="figure" target="#fig_0">1</ref>. VOTEN hierarchically models a small number of explicit concepts. During inference, the higher-level concepts will be induced via information aggregation from the lower-level concepts. To achieve meaningful information aggregation, VOTEN focuses on quantifying relationship between individual concepts of different levels. For better understanding, in VOTEN, observations and concepts can be regarded as voters. Based on their own value, each voter independently votes for the higher-level concepts. The votes are aggregated to get the value estimation of each higher-level concept. These concepts will further vote for the next level. In the training process, the model learns to builds intermediate concepts and their quantitative voting functions.</p><p>Formally, for a VOTEN model with D levels of concepts, we use C d i to denote the i-th concept in the d-th layer, where C 0 i denotes an input feature. We refer to transformations between adjacent levels of concepts as a voting layer. In the d-th voting layer, each concept C d i votes for each higher-level concept C d+1 j with an independent voting channel V d i,j . V d i,j takes the value of C d i as the input and votes with a single-valued nonlinear function f d i,j : R → R. Then, a counting layer gets weighted average of the votes and estimates the value of C d+1 j as</p><formula xml:id="formula_0">x d+1 j = n d k=1 a d k,j f d k,j (x d k ) s.t. ∀d, j, n d k=1 a d k,j = 1,<label>(1)</label></formula><p>where n d denotes the number of concepts in the d-th layer, x d k denotes the value of C d k , a d k,j denotes the weight of V d i,j . The concepts of the last layer is regarded as the decision score, which generates the model output with o = F V OT EN (x D ). In particular, to assure the ability of the voting functions on effective concept transformation, VOTEN models each voting function with a voting network. The voting network can be designed in complicated ways without influencing model explainability, as long as the function is still single-valued. For example, we can adopt weight-sharing structures to reduce model complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Why is VOTEN more explainable than MLP?</head><p>In this part, we theoretically discuss VOTEN's advantages over MLP. Specifically, we claim that voting expressiveness is the core proposition of VOTEN that raises explainability.</p><p>Theorem 1 MLP can be derived from a subset of degenerated VOTEN models whose voting functions in the form of</p><formula xml:id="formula_1">f d i,j (x d i ) = w d i,j σ(x d i ) + b d i,j</formula><p>, where σ is a predefined activation function, the scalars</p><formula xml:id="formula_2">w d i,j , b d i,j ∈ R are trainable parameters. Proof. Please refer to Appendix A.</formula><p>From this point of view, MLP also conforms to human inference. However, MLP is still difficult to explain. Indeed, we can more easily understand an inference process with (1) fewer concepts, (2) shorter concept transformations, and (3) fewer reasoning patterns. Under VOTEN schema, we show how inexpressive voting channels make MLP disobey these three traits. This means individual voters in MLP are weak in distinguishing different concepts in the next level. Therefore, MLP relies on highly complicated feature combinations of a large number of deeply tiled voters to achieve high fitting ability. During this process, necessary intermediate information is inherently modeled through combinatorial effects of hidden concepts with inexplicit meanings. Indeed, previous works have proved that human-understandable concepts are inherently mounted in the hidden units of neural network models <ref type="bibr" target="#b27">[28]</ref>.</p><p>Corollary 2 In MLP, the hypothesis space for voting distribution is limited to scaling and shifting an input distribution.</p><p>This means that MLP voters cannot always induce complicated concepts that have different distribution from their value. As a result, the input needs to go through a long path of transformations between similar concepts until it contributes to the output. Moreover, the deeply tiled massive concepts make each input feature has massive paths to the output, which brings a large number of possible decision-making patterns of the model. In addition, the effect of votings can easily couple and cancel each other out in the downstream calculations. As a result, separately analyzing the role of individual concepts or decision paths becomes meaningless.</p><p>Different from MLP, VOTEN has far more expressive voting functions. It directly models nonlinear transformations between essential intermediate concepts without relying on massive feature combinations and naive transformations. As a result, VOTEN's decision-making process is explicit with only a small number of meaningful concepts, thus is explainable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Explaining the effect of votings</head><p>In VOTEN, individual voting channels play explicit roles in influencing the model decision. In this part, we analyze the effect of votings. First, we use a concept function g d i : R n0 → R to represent the transformation from model inputs x 0 ∈ R n0 to C d i , which decides the meaning of the concept. Definition 1 In VOTEN, we refer to two concept functions g and g as equivalent iff. there exists an invertible function Φ, so that ∀x 0 ∈ R n0 , Φ(g(x 0 )) = g (x 0 ). Since Φ is invertible, the outputs of two equivalent concept functions have one-to-one correspondence over all the possible inputs. Then, they can effect equally in the decision-making process. Theorem 2 In VOTEN, if replacing a concept function with an equivalent form, there exists a way to replace its voting functions so that all the downstream concept functions stay unchanged. Proof. Please refer to Appendix A.</p><p>To analyze how voting channels effect on concept functions, we can reformulate Equation 1 as</p><formula xml:id="formula_3">x d+1 j = g d+1 j (x 0 ) = n d i=1 a d i,j (f d i,j (g d i (x 0 )) − E x [f d i,j (g d i (x))]) + b d+1 j ,<label>(2)</label></formula><p>where</p><formula xml:id="formula_4">E x [f d i,j (g d i (x))</formula><p>] denotes the expectation of f d i,j over all the instances, b d+1 j is a sampleindependent bias. In particular,</p><formula xml:id="formula_5">b d+1 j = n d i=1 a d i,j E x [f d i,j (g d i (x))] = E x [g d+1 j (x)].<label>(3)</label></formula><p>For simplicity, we use</p><formula xml:id="formula_6">h d i,j to denote E x [f d i,j (g d i (x))].</formula><p>Notably, by adding an arbitrary bias to g d+1 j , we obtain an equivalence of the original concept. According to Theorem 2, we can construct a model with exactly the same expression (i.e., equivalent concepts and the same predictions) as the previous one. This implies that VOTEN may converge to models with differed internal bias but exactly the same decision-making process, indicating VOTEN explanation should be independent of concept bias. According to Equation 2 and 3, voting channels' average only influence concept bias while the voting deviation</p><formula xml:id="formula_7">f d i,j (g d i (x 0 )) − h d i,j reveals the effect of V d i,j</formula><p>for the decision. This can be intuitively explained as each voter can vote with different basic scores and only the deviation from the basic score reflects their judgement for a specific instance. Similarly, from the global view, we reformulate the concept function as</p><formula xml:id="formula_8">x d+1 j = i a d i,j σ d i,j K d i,j (x 0 ) + b d+1 j , where K d i,j (x 0 ) = f d i,j (g d i (x 0 ))−h d i,j σ d i,j<label>.</label></formula><p>Notably, K d i,j (•) generates a distribution with mean 0 and variance 1 over all the instances. Therefore, a d i,j and σ d i,j jointly decide the overall effect of votings. Specifically, the counting layer explicitly adjusts a d i,j so that reliable voters have stronger influences. Meanwhile, the voter implicitly adjusts σ d i,j . When the concept is less related to the target concept and cannot support proper votes, they decrease σ d i,j and tend to always vote the basic score to avoid disturbing the model. Otherwise, they increase σ d i,j and vote confidently to lead the model to correct estimation. Based on the above analysis, we can easily design algorithms to ease both VOTEN local and global explanation, such as recognizing decision paths and quantifying the concept/feature relevance to the prediction, which can be found in Appendix B and Appendix C. Table <ref type="table">1</ref>: Model Performance. We conducted 10 independent runs on each dataset and show the average ± standard deviation of AUC and AP. In particular, for multi-classifications, we estimated the macro average of each metric. We also did significance test, where * and ** denote significantly (i.e., p-value ≤ 0.05) and very significantly (i.e., p-value ≤ 0.01) worse than VOTEN.</p><p>DT <ref type="bibr" target="#b42">[43]</ref> RF <ref type="bibr" target="#b47">[48]</ref> LGB <ref type="bibr" target="#b26">[27]</ref> MLP <ref type="bibr" target="#b21">[22]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">VOTEN supports effective model pruning</head><p>In VOTEN, concepts are estimated by averaging the votes. This means we can delete a voting channel while keeping the physical meaning of the target concept unchanged. This supports effective link pruning. Specifically, since only the voting deviation from the average decides the effect, we can assume the absent channel votes the basic score regardless of the input. Formally, the value of C d+1 j is estimated as</p><formula xml:id="formula_9">xd+1 j = n d i=1 I d i,j a d i,j (f d i,j (x d i ) − h d i,j ) + b d+1 j</formula><p>, where</p><formula xml:id="formula_10">I d i,j ∈ {0, 1} indicates if V d i,j</formula><p>is not absent. Furthermore, since only involving a small number of voting channels, we can achieve network pruning on VOTEN by exhaustively exploring how the performance will get influenced if some voting channels are absent, which is infeasible for MLP. In MLP, we usually prune unimportant hidden units to reduce model complexity. However, usually not all the voting channels from an important concept are necessary. In VOTEN, these unnecessary concept transformations can be further eliminated to not only reduce model complexity but also raises the explainability of the model.</p><p>In Appendix D, we give an efficient VOTEN pruning algorithm with a lazy updating strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment</head><p>To evaluate the effectiveness and explainability of VOTEN for seizing comprehensive decisionmaking patterns. We conducted experiments<ref type="foot" target="#foot_0">1</ref> with 6 large public datasets, including Context-aware Multi-Modal Transportation Recommendation (MR) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b57">58]</ref>, IJCAI-18 Search Conversion Rate Prediction (RP) <ref type="bibr" target="#b2">[3]</ref>, Forest Cover Type Prediction (CT) <ref type="bibr" target="#b11">[12]</ref>, Census-Income Prediction (CI) <ref type="bibr" target="#b37">[38]</ref>, Allstate Claim Prediction (AS) <ref type="bibr" target="#b0">[1]</ref>, and Higgs boson dataset (HG) <ref type="bibr" target="#b10">[11]</ref>. The detailed descriptions of experimental setup can be found in Appendix E.</p><p>3.1 Performance Evaluation: Can VOTEN achieve higher performance than MLP?</p><p>We used two widely adopted metrics for imbalanced classification performance evaluation, including Area Under ROC Curve (AUC) <ref type="bibr" target="#b13">[14]</ref> and average precision (AP) <ref type="bibr" target="#b18">[19]</ref>, whose higher value means higher performance. In Table <ref type="table">1</ref>, we compare the performance of VOTEN with several baselines, including Decision Tree (DT) <ref type="bibr" target="#b42">[43]</ref>, Random Forest (RF) <ref type="bibr" target="#b47">[48]</ref>, LightGBM (LGB) <ref type="bibr" target="#b26">[27]</ref>, MLP <ref type="bibr" target="#b21">[22]</ref>, and Neural Additive Model (NAM) <ref type="bibr" target="#b6">[7]</ref> (see Appendix E.2 for detail). For each dataset, we have carefully tuned the parameters of the baselines to achieve their best performance. Especially, detailed analysis on MLP parameters can be found in Appendix E.3. It can be observed that, while deep neural networks are powerful when incorporated with purposely designed modules or prior knowledge for specific tasks, its standard form (i.e., MLP) without task-specific structures may perform worse than LightGBM, which have also been shown by many previous studies <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b3">4]</ref>. Indeed, LightGBM is believed to be powerful in handling structured data and often appears as the major model of the top solutions in data-mining competitions <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b34">35]</ref>. In contrast, VOTEN, also in its standard form, significantly outperforms MLP for all these tasks and comparable with LightGBM. Indeed, on many datasets, it outperforms LightGBM if complicated feature engineering is not performed. This shows the effectiveness of VOTEN in terms of handling real-world problems. Indeed, VOTEN is more suitable for handling data-mining tasks since it has more reasonable decision-making process. It should be noticed that, similar to MLP, VOTEN is a standard and generic model that can be easily expanded to task-specific networks to raise model performance (for example, we can replace MLP with VOTEN in DeepFM <ref type="bibr" target="#b23">[24]</ref>). While this paper focuses on the generic performance of standard VOTEN, it shows the possibility of building more powerful deep learning solutions for a wide range of applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Explanation</head><p>Complexity: Is the decision-making process of VOTEN recognizable? In Table <ref type="table" target="#tab_1">2</ref>, we compare the explanation complexity of MLP and VOTEN. As we have discussed in Section 2.2, we use the number of feature combinations, the length of decision paths, and the number of possible decisionmaking patterns to show the explanation complexity of a model. In particular, we trained two VOTEN models with different settings for each dataset. Specifically, "VOTEN − " is comparable to the best performance of MLP, with the least feature combinations. "VOTEN" is the one with the best performance. It can be observed that VOTEN greatly reduces feature combinations and decision paths. For example, on the MR dataset, MLP needs 7 voting layers that each contain 128 concepts. This brings an exponentially large number of long decision paths. In contrast, VOTEN achieves comparable performance with 16 hidden concepts in total. Then, each feature only has 16 possible paths with a length of 2 to reach the output. This significantly eases the understanding of the decision-making process. For some datasets, VOTEN with no intermediate concepts (i.e., features directly vote for the prediction) can achieve comparable performance to MLP. Moreover, even when reaching its best performance, VOTEN still has a much smaller explanation complexity than MLP. It should be noticed that we have listed the maximum possible number of decision paths for convincing illustration. In practice, we can easily distinguish a fewer number of important decision paths, which will be shown in the following experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Case Study: How to explain a VOTEN model?</head><p>We show how to explain a VOTEN model with an example in the MR dataset. Specifically, we first analyze the global decision-making process and discover the meaning of concepts by observing voting functions on important decision paths. Then, we locally explain how the inputs of an instance hierarchically vote the final prediction.</p><p>Task Description. The task is to recommend the transport mode for online map app users, given a user and an Origin-Destination (OD) pair. The features mainly contain user portraits and an ordered list of recommended plans of the map app. Each plan consists of transport mode, time, distance, and price. We deleted the first recommended plan's mode information since it is too strongly correlated with the label (many users choose the first recommendation as default). In this way, we can better observe how the model incorporates complicated information for meaningful decisions.</p><p>Global Decision-Making Process. We focus on the decision-making process for the class "Subway". First, we discover the important transformations from observations to the prediction with our decision path recognition algorithm. The results are shown in Figure <ref type="figure">2</ref>. Next, we analyze the meaning of concepts from the bottom to top. L1H8 gets larger when modes of more recommended plans are "Subway", which we regard as "OD pair with flexible subway-based plans". L1H12 decreases with higher prices and lower distances, which we regard as "OD pair's distance-cost performance". L1H14 observes if the OD pair is distant but still available with inexpensive and fast transportation. Besides, it also observes if modes of public transportation ever appear in the plan list. Therefore, we regard L1H14 as "distant OD pair with convenient and economical public transportation". L1H15 is sensitive to a time-consuming top-1 plan. It also observes the other plans' modes and prices to estimate if trading money for efficiency is infeasible. Therefore, we regard L1H15 as "no choice but a time-consuming transportation". In the second layer, L2H7 is estimated based on L1H8, L1H12, L1H14, and L1H15. It gets higher if many subway-based plans available (higher L1H8), transportation with balanced distance-cost is recommended (has a peak for L1H12), distant OD pair but still has convenient public transportation (higher L1H14), or costly time-saving transportation is infeasible (higher L1H15). Comprehensively considering these reasons, it implies "OD pair suitable for subway transportation, which votes for the score of "Subway" with a monotonic transformation.</p><p>Along the other path, L1H4 is a concept "OD pair with inexpensive transportation". Then, L2H5 is also about the price since it is mainly based on L1H4. It should be noticed that its estimation may still be enhanced by other lower-level concepts when dealing with specific instances, although they are less important from the global view. Finally, L2H5 and L2H7 vote nonlinearly to the score so that the model can make accurate quantitative predictions. With the above analysis, we can qualitatively understand the logic of VOTEN on recommending "Subway". Actually, the decision-making process is quantitatively more complicated and can handle more special cases. In practice, domain experts can thoroughly analyze the shape and gradients of the voting functions to get more insights into the concepts. This may help researchers to find new concepts and develop new theories, especially in fields such as psychology and management, where scientists work on finding mechanisms linking observations to outcomes. Extra visualizations on global decision path and voting functions can be found in Appendix F and Appendix G.</p><p>Local Decision-Making Process. Then, we analyze the decision paths for specific instances. In Figure <ref type="figure" target="#fig_3">3</ref>, we visualize the most important paths for a sample with a high score for "Subway", which are filtered with a small threshold in our local decision path recognition algorithm. Based on the global analysis, we can easily tell how the observations gradually transformed to higher-level concepts. Specifically, for L1H12, the vote from price is filtered out, showing the OD pair's price is normal over the dataset. However, it finds the OD pair to be distant, which contributes to a relatively larger distance-cost performance than average, given the normal price. This indicates the plan to be relatively more economical. L2H7 observes the value of L1H12, and finds that the OD pair can  choose transportation whose distance-cost performance more balanced than average cases (reaches the peak of voting). In this case, L2H7 votes high for subway, which is an economical and balanced transportation mode. On the other decision path, L1H8 thinks "Subway" may not be suitable since subway-based plans seldom appear in the list, thus votes negatively for L2H7. But L1H12 makes a very confident judgment based on the balance of distance-price performance, which dominates L2H7 and makes the model predict correctly. Interestingly, we find one of the most important strategies in this task is to guess the transportation mode most recommended by the app (the information that we hide in prior), which is reasonable. On the one hand, the app's recommender system trained with abundant information can naturally achieve high performance. On the other hand, many users will click the first recommendation as default. In addition to this strategy, the model will use more important decision paths to achieve more accurate predictions. As we gradually increase the threshold, more decision-making patterns appeared. Extra visualizations on local explanation of other datasets can be found in Appendix H. Single-Sighted Prediction Strength. We can also estimate the feature relevance from the view of model performance when the prediction is supported by a single voter in some layer. Specifically,  we disable the other voters in a similar way as we do in model pruning. Table <ref type="table" target="#tab_2">3</ref> shows 5 MR features achieving the highest AUC when conducting single-sighted prediction for class 0 and class 1 in VOTEN. As a comparison, we also show the AUC of directly ranking with the feature, which reveals the feature's linear correlation with the prediction. In particular, since there can be negative correlations, we evaluate AUC for the rank in increasing and decreasing order, and use the larger one as the performance. Moreover, Figure <ref type="figure" target="#fig_6">5</ref> shows the results on all the features. It can be observed that, even if approximated into single-sighted, VOTEN significantly raises AUC, showing VOTEN to recognize important features and strengthen their effectiveness with nonlinear transformations. Especially, while feature #85 originally seems not correlated with the output, VOTEN finds it in practice nonlinearly very relevant to the output. This proves the effectiveness of VOTEN on quantifying the inherent nonlinear relationships between the observations and the prediction. Interestingly, VOTEN weakens the effect of some features (e.g., feature #3 for RP) to prevent them from disturbing the prediction. Extra visualizations can be found in Appendix J. We conducted pruning experiments on VOTEN for MR and CT datasets with our pruning algorithm. As we gradually deleted voting channels, we monitored the change of AUC during this process, which are shown in Figure <ref type="figure" target="#fig_7">6</ref>. For MR, AUC is still near 0.924 after pruning nearly half of the voting channels. For CT, AUC is still near 0.998 after pruning a quarter of the channels. Interestingly, proper pruning may slightly raise model performance, which is reasonable as a simple model has less chance of over-fitting. In practice, operations like fine-tuning can be adopted to further raise the performance of the pruned VOTEN model. Then, the model can be further compressed without affecting the prediction much. These results prove VOTEN to support effective pruning, which is helpful. We can use complicated information for training and prune the model to decrease the complexity for storage, calculation and explanation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Post-Hoc Deep Learning Explanation. Post-Hoc explaining algorithms analyze the relevance of features in a model-free way, mainly including propagation-based methods <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b5">6]</ref> and perturbationbased methods <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b55">56]</ref>. Propagation-based methods propagate the relevance score backward to the inputs. For example, Simonyan et al. <ref type="bibr" target="#b44">[45]</ref> generates saliency maps with the gradients of the output category with respect to the inputs. Bach et al. <ref type="bibr" target="#b9">[10]</ref> proposed Layer-wise Relevance Propagation (LRP), which designed effective rules for the propagation. Perturbation-based methods explain model behavior by observing how the output reacts to purposely perturbed or constructed inputs. For example, Local Interpretable Model-Agnostic Explanations (LIME) <ref type="bibr" target="#b41">[42]</ref> trains a local explainable approximation model around the prediction with randomly perturbed features and the corresponding outputs. SHapley Additive exPlanations (SHAP) <ref type="bibr" target="#b33">[34]</ref> estimates the Shapley value of features to measure their contribution to model performance. In addition to features, some works estimate concept importance for a model <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b27">28]</ref>. For example, Kim et al. <ref type="bibr" target="#b27">[28]</ref> learn the representation of humanunderstandable concepts with labeled concept-relevant examples and estimate concept sensitivity according to the directional derivative towards the concepts. Along this line, abundant works have been proposed to further raise the effectiveness of post-hoc interpretation algorithms <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b14">15]</ref>. However, these algorithms regard models as blackboxes and heuristically explain with their own metrics, which cannot give explicit understandings of the actual decision-making process. Different from existing works, we proposed a naturally understandable neural network model.</p><p>Intrinsically Explainable Machine Learning Techniques. Intrinsically explainable models can be explained without relying on post-hoc algorithms <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b4">5]</ref>, mainly including classic models such as logistic regression <ref type="bibr" target="#b36">[37]</ref>, linear support vector machine <ref type="bibr" target="#b25">[26]</ref>, decision trees <ref type="bibr" target="#b42">[43]</ref>, generalized additive models <ref type="bibr" target="#b24">[25]</ref> and Bayesian models <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b51">52]</ref>. Recently, Agarwal et al. <ref type="bibr" target="#b6">[7]</ref> proposed Neural Additive Model that predicts with a linear combination of neural networks. However, all these models usually have tight restrictions on the hypothesis space, which limits their fitting ability on complicated realworld problems. Based on these methods, complicated models are developed for higher performance. However, even with intrinsically explainable base models, these complicated models still need posthoc algorithms for explanation <ref type="bibr" target="#b8">[9]</ref>. For example, ensemble tree models <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b26">27]</ref> predict with a large number of weak learners. However, the joint decision-making process of massive decision trees is difficult to understand. Kernel functions <ref type="bibr" target="#b38">[39]</ref> are incorporated in support vector machines to seize high dimensional feature interactions. However, the dimension transformation is implicit and not understandable. In recent years, researchers also try to design explainable neural network models by incorporating purposely designed task-specific constraints or structures <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b39">40]</ref>. However, these models cannot be adopted by the general tasks. Besides, they only provide heuristic and domain-specific intermediate information instead of telling the complete decision-making process. Different from these works, we aim at a general explainable neural network model, which has an intrinsically explainable decision-making process while retaining the high fitting ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Concluding Remarks</head><p>In this paper, we have proposed an explainable deep learning model, VOTEN. Specifically, we theoretically analyzed the major components of VOTEN and discussed its priority over MLP, and accordingly proposed some efficient algorithms to raise the model usability. Experimental results on multiple real-world datasets clearly demonstrated that VOTEN can significantly improve the explainability and performance of deep learning.</p><p>Limitations. In this paper, we focused on comparing VOTEN with MLP, which is the generic and basic structure of deep learning models. Many powerful problem-specific structures can be derived from MLP by adding operations such as weight sharing (e.g., CNN). Similar to MLP, VOTEN is a basic and generic structure. It can be adopted to problem-specific models (e.g., we can simply use VOTEN to replace MLPs in deepFM <ref type="bibr" target="#b23">[24]</ref> or MMoE <ref type="bibr" target="#b35">[36]</ref>). Indeed, recent studies show that if properly designed, simple MLP-based structure achieves comparable performance to complicated SOTA models <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b50">51]</ref>. VOTEN's advantages over MLP provides great possibility on further improving a wide range of deep learning applications. In the future, we will also explore building VOTEN-based task-specific structures. In addition, since VOTEN automatically extracts concepts during training, human effort is needed to observe the voting functions for understanding the concepts, which is a common issue in unsupervised concept modeling, such as Latent Dirichlet Allocation <ref type="bibr" target="#b12">[13]</ref>. In the future, we will work on easing the concept understanding of VOTEN, such as recognizing concept-related samples or aligning VOTEN with human-understandable concepts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Structure overview of VOTEN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Corollary 1</head><label>1</label><figDesc>In MLP, votings from the same concept are linearly correlated.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 Figure 2 :</head><label>12</label><figDesc>Figure 2: Case study of VOTEN global decision-making process in MR dataset. We show the important paths from inputs to one output, where wide lines indicate important voting channels. The concept LxHy indicates the y-th concept in the x-th layer. We visualize the important voting functions for each concept along the paths relevant to L2H7, where blue lines show the function while green lines show the average vote.</figDesc><graphic url="image-21.png" coords="7,444.77,72.89,59.97,112.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>L1H8Figure 3 :</head><label>3</label><figDesc>Figure 3: Case study of VOTEN local decision-making process in MR dataset, where wider and darker lines indicate stronger influence (negatively in blue and positively in red). The bottom left shows filtered paths when we gradually bring up the thresholds. We also show the important voting functions, where the green lines show the average and red points show vote for the current instance.</figDesc><graphic url="image-23.png" coords="8,304.87,69.82,170.37,122.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Heatmap for the propogation-based relevance in VOTEN. The x-axis represents features and the y-axis represents the instance-output pairs, where #I_O indicates the feature relevance of the I-th instance to class O. Red means positive relevance while blue means negative relevance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>3. 4</head><label>4</label><figDesc>Relevance Analysis: Can VOTEN help quantify feature relevance? Propagation-Based Relevance. Motivated by relevance propagation<ref type="bibr" target="#b9">[10]</ref>, we propose an algorithm (see Appendix D) to quantify the relevance of features and concepts, based on the important decision paths. The short decision paths of VOTEN decreases error accumulation during the propagation and enables more accurate relevance estimation. In Figure4, we visualize the propagation-based feature relevance with heatmaps. Obviously, features from #69 to #86 are generally important in the MR dataset, among which the first several features (information about the top-1 plan in the list) are the most relevant. Furthermore, the relevant features vary for different samples in terms of different classes, which indicates VOTEN to predict in multiple patterns. For example, Figure4(b)shows that VOTEN assigns high score to class 2 for sample 4 and sample 5 with different reasons. Specifically, feature #3 and #53 contribute positively for sample 5 while negatively for sample 4. Instead, #50 is more positively relevant for sample 4. Extra visualizations can be found in Appendix I.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure5: Single-sighted prediction strength in VOTEN. We also show the AUC of linearly ranking the samples as comparisons. Darker color means higher AUC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: VOTEN pruning experiments. The x-axis shows the ratio of pruned channels while the y-axis shows AUC. The green line shows MLP's performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Explanation complexity. "#C/L" counts hidden concepts in each layer. "#P/F" counts possible decision paths from each feature.</figDesc><table><row><cell>Data</cell><cell>Model</cell><cell cols="2">Performance AP AUC</cell><cell>#C/L</cell><cell>Depth</cell><cell>#P/F</cell></row><row><cell></cell><cell>MLP</cell><cell>0.487</cell><cell>0.920</cell><cell>128</cell><cell>7</cell><cell>2 49</cell></row><row><cell>MR</cell><cell>VOTEN − VOTEN</cell><cell>0.497 0.501</cell><cell>0.922 0.924</cell><cell>16 16</cell><cell>1 2</cell><cell>16 256</cell></row><row><cell></cell><cell>MLP</cell><cell>0.052</cell><cell>0.725</cell><cell>12</cell><cell>3</cell><cell>1,728</cell></row><row><cell>RP</cell><cell>VOTEN − VOTEN</cell><cell>0.055 0.055</cell><cell>0.732 0.732</cell><cell>0 8</cell><cell>0 2</cell><cell>1 64</cell></row><row><cell></cell><cell>MLP</cell><cell>0.966</cell><cell>0.996</cell><cell>128</cell><cell>7</cell><cell>2 49</cell></row><row><cell>CT</cell><cell>VOTEN − VOTEN</cell><cell>0.969 0.978</cell><cell>0.997 0.998</cell><cell>32 64</cell><cell>2 2</cell><cell>1,024 4,096</cell></row><row><cell></cell><cell>MLP</cell><cell>0.622</cell><cell>0.945</cell><cell>32</cell><cell>2</cell><cell>1,024</cell></row><row><cell>CI</cell><cell>VOTEN − VOTEN</cell><cell>0.652 0.652</cell><cell>0.950 0.951</cell><cell>0 4</cell><cell>0 2</cell><cell>1 16</cell></row><row><cell></cell><cell>MLP</cell><cell>0.830</cell><cell>0.816</cell><cell>64</cell><cell>4</cell><cell>2 24</cell></row><row><cell>HG</cell><cell>VOTEN − VOTEN</cell><cell>0.831 0.862</cell><cell>0.816 0.848</cell><cell>8 64</cell><cell>1 2</cell><cell>8 4,096</cell></row><row><cell></cell><cell>MLP</cell><cell>0.011</cell><cell>0.592</cell><cell>64</cell><cell>4</cell><cell>2 24</cell></row><row><cell>AS</cell><cell>VOTEN − VOTEN</cell><cell>0.012 0.012</cell><cell>0.594 0.598</cell><cell>16 64</cell><cell>1 2</cell><cell>16 4,096</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Features with top-5 single-sighted prediction strength for class 0 and class 1 of MR dataset in VOTEN. "Input" indicates the AUC of ranking the samples according to the feature's value.</figDesc><table><row><cell></cell><cell cols="5">Model</cell><cell></cell><cell cols="42">Class 0 Top-1 Top-2 Top-3 Top-4 Top-5 Top-1 Top-2 Top-3 Top-4 Top-5 Class 1</cell></row><row><cell></cell><cell cols="48">VOTEN 0.675 0.653 0.647 0.606 0.592 0.747 0.632 0.625 0.587 0.566</cell></row><row><cell></cell><cell></cell><cell cols="3">Input</cell><cell></cell><cell></cell><cell cols="42">0.596 0.533 0.572 0.600 0.586 0.535 0.527 0.534 0.555 0.525</cell></row><row><cell>Input</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.6</cell><cell>Input</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.60</cell></row><row><cell>0 Vote</cell><cell>5</cell><cell>10</cell><cell>15</cell><cell>20</cell><cell>25</cell><cell>30</cell><cell>35</cell><cell>40</cell><cell>45</cell><cell>50</cell><cell>55</cell><cell>60</cell><cell>65</cell><cell>70</cell><cell>75</cell><cell>80</cell><cell>85</cell><cell>90</cell><cell>95</cell><cell>100</cell><cell>105</cell><cell>110</cell><cell>0.5</cell><cell>0 Vote</cell><cell>5</cell><cell>10</cell><cell>15</cell><cell>20</cell><cell>25</cell><cell>30</cell><cell>35</cell><cell>40</cell><cell>45</cell><cell>50</cell><cell>55</cell><cell>60</cell><cell>65</cell><cell>70</cell><cell>75</cell><cell>80</cell><cell>85</cell><cell>90</cell><cell>95</cell><cell>100</cell><cell>105</cell><cell>110</cell><cell>115</cell><cell>0.55</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="10">(a) MR (Class 0)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">(b) RP</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Our code is available at https://github.com/sunyinggilly/VOTEN</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments and Disclosure of Funding</head><p>The research work supported by the National Key Research and Development Program of China under Grant No. 2017YFB1002104, the National Natural Science Foundation of China under Grant No. U1836206, U1811461, 62176014, 91746301, 61836013, 61773361.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Allstate claim prediction challenge</title>
		<ptr target="https://www.kaggle.com/c/ClaimPredictionChallenge" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Context-aware multi-modal transportation recommendation</title>
		<ptr target="https://dianshi.bce.baidu.com/competition/29/question" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Ijcai-18 alimama sponsored search conversion rate(cvr) prediction contest</title>
		<ptr target="https://tianchi.aliyun.com/competition/entrance/231647/information" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<ptr target="https://mljar.com/machine-learning/lightgbm-vs-neural-network/" />
		<title level="m">Lightgbm vs neural network</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Peeking inside the black-box: a survey on explainable artificial intelligence (xai)</title>
		<author>
			<persName><forename type="first">Amina</forename><surname>Adadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Berrada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="52138" to="52160" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Julius</forename><surname>Adebayo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Muelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Been</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.03292</idno>
		<title level="m">Sanity checks for saliency maps</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Rishabh</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Frosst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhou</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.13912</idno>
		<title level="m">Neural additive models: Interpretable machine learning with neural nets</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Robot failure mode prediction with explainable machine learning</title>
		<author>
			<persName><forename type="first">Aneseh</forename><surname>Alvanpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><forename type="middle">Kumar</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Kevin Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olfa</forename><surname>Nasraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Popa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE 16th International Conference on Automation Science and Engineering (CASE)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="61" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Explainable artificial intelligence (xai): Concepts, taxonomies, opportunities and challenges toward responsible ai</title>
		<author>
			<persName><forename type="first">Alejandro</forename><surname>Barredo Arrieta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Díaz-Rodríguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Del Ser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrien</forename><surname>Bennetot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siham</forename><surname>Tabik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Barbado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salvador</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergio</forename><surname>Gil-López</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Benjamins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="82" to="115" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grégoire</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederick</forename><surname>Klauschen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus-Robert</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Samek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">e0130140</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Searching for exotic particles in high-energy physics with deep learning</title>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Sadowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Whiteson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Comparative accuracies of artificial neural networks and discriminant analysis in predicting forest cover types from cartographic variables</title>
		<author>
			<persName><forename type="first">Jock</forename><forename type="middle">A</forename><surname>Blackard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><forename type="middle">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and electronics in agriculture</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="131" to="151" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>David M Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The use of the area under the roc curve in the evaluation of machine learning algorithms</title>
		<author>
			<persName><forename type="first">Bradley</forename><surname>Andrew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern recognition</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1145" to="1159" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Qlime-a quadratic local interpretable model-agnostic explanation approach</title>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bramhall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hayley</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Tieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nibhrat</forename><surname>Lohia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SMU Data Science Review</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Xgboost: A scalable tree boosting system</title>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining</title>
				<meeting>the 22nd acm sigkdd international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Personalized fashion recommendation with visual explanations based on multimodal attention network: Towards visually explainable recommendation</title>
		<author>
			<persName><forename type="first">Hanxiong</forename><surname>Xu Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongteng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyuan</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="765" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Opportunities and challenges in explainable artificial intelligence (xai): A survey</title>
		<author>
			<persName><forename type="first">Arun</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Rad</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.11371</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The relationship between precision-recall and roc curves</title>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Goadrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on Machine learning</title>
				<meeting>the 23rd international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Repmlp: Re-parameterizing convolutions into fully-connected layers for image recognition</title>
		<author>
			<persName><forename type="first">Xiaohan</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jungong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guiguang</forename><surname>Ding</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">2105</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Artificial neural networks (the multilayer perceptron)-a review of applications in the atmospheric sciences</title>
		<author>
			<persName><forename type="first">Matt</forename><forename type="middle">W</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><surname>Dorling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Atmospheric environment</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">14-15</biblScope>
			<biblScope unit="page" from="2627" to="2636" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Towards automatic concept-based explanations</title>
		<author>
			<persName><forename type="first">Amirata</forename><surname>Ghorbani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Wexler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Been</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.03129</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Deepfm: a factorization-machine based neural network for ctr prediction</title>
		<author>
			<persName><forename type="first">Huifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunming</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuqiang</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.04247</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Generalized additive models</title>
		<author>
			<persName><forename type="first">Trevor</forename><forename type="middle">J</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">J</forename><surname>Tibshirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>CRC press</publisher>
			<biblScope unit="volume">43</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Applications of support vector machine (svm) learning in cancer genomics</title>
		<author>
			<persName><forename type="first">Shujun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nianguang</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">Penzuti</forename><surname>Pacheco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shavira</forename><surname>Narrandes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Genomics-Proteomics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="51" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Lightgbm: A highly efficient gradient boosting decision tree. Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">Guolin</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Finley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weidong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiwei</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="3146" to="3154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav)</title>
		<author>
			<persName><forename type="first">Been</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrie</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Wexler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernanda</forename><surname>Viegas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2668" to="2677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unmasking clever hans predictors and assessing what machines really learn</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Lapuschkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Wäldchen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grégoire</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus-Robert</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Beyond saliency: understanding convolutional neural networks from saliency prediction on layer-wise relevance propagation</title>
		<author>
			<persName><forename type="first">Heyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunke</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="70" to="86" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Xing Xie, and Guangzhong Sun. xdeepfm: Combining explicit and implicit feature interactions for recommender systems</title>
		<author>
			<persName><forename type="first">Jianxun</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongxia</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1754" to="1763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Collaborative company profiling: Insights from an employee&apos;s perspective</title>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Hao Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Scott</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Su-In</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07874</idno>
		<title level="m">A unified approach to interpreting model predictions</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Accuair: Winning solution to air quality prediction for kdd cup</title>
		<author>
			<persName><forename type="first">Zhipeng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xue</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018. 2019</date>
			<biblScope unit="page" from="1842" to="1850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Modeling task relationships in multi-task learning with multi-gate mixture-of-experts</title>
		<author>
			<persName><forename type="first">Jiaqi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyang</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichan</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining, KDD &apos;18</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining, KDD &apos;18</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1930" to="1939" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Marginal effects-quantifying the effect of changes in risk factors in logistic regression models</title>
		<author>
			<persName><forename type="first">Bryan</forename><forename type="middle">E</forename><surname>Edward C Norton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">L</forename><surname>Dowd</surname></persName>
		</author>
		<author>
			<persName><surname>Maciejewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jama</title>
		<imprint>
			<biblScope unit="volume">321</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1304" to="1305" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Experimental comparisons of online and batch versions of bagging and boosting</title>
		<author>
			<persName><forename type="first">C</forename><surname>Nikunj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Oza</surname></persName>
		</author>
		<author>
			<persName><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the seventh ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="359" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A novel formulation of orthogonal polynomial kernel functions for svm classifiers: the gegenbauer family</title>
		<author>
			<persName><forename type="first">Luis</forename><surname>Carlos Padierna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Carpio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alfonso</forename><surname>Rojas-Dominguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hector</forename><surname>Puga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hector</forename><surname>Fraire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="211" to="225" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Enhancing person-job fit for talent recruitment: An ability-aware neural network approach</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st international ACM SIGIR conference on research &amp; development in information retrieval</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="25" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Bayesian model selection in social research</title>
		<author>
			<persName><forename type="first">Adrian</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological methodology</title>
		<imprint>
			<biblScope unit="page" from="111" to="163" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">why should i trust you?&quot; explaining the predictions of any classifier</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Tulio Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining</title>
				<meeting>the 22nd ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1135" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A survey of decision tree classifier methodology</title>
		<author>
			<persName><forename type="first">Safavian</forename><surname>Rasoul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Landgrebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on systems, man, and cybernetics</title>
				<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="660" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Joint representation learning with relation-enhanced topic models for intelligent job interview assessment</title>
		<author>
			<persName><forename type="first">Dazhong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6034</idno>
		<title level="m">Deep inside convolutional networks: Visualising image classification models and saliency maps</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The impact of person-organization fit on talent management: A structure-aware convolutional neural network approach</title>
		<author>
			<persName><forename type="first">Ying</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzhen</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1625" to="1633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Market-oriented job skill valuation with cooperative composition neural network</title>
		<author>
			<persName><forename type="first">Ying</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzhen</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Random forest: a classification and regression tool for compound classification and qsar modeling</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Svetnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Christopher Culberson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">P</forename><surname>Sheridan</surname></persName>
		</author>
		<author>
			<persName><surname>Bradley P Feuston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and computer sciences</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1947" to="1958" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Diversified social influence maximization</title>
		<author>
			<persName><forename type="first">Fangshuang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feida</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2014)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="455" to="459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Exploiting network fusion for organizational turnover prediction</title>
		<author>
			<persName><forename type="first">Mingfei</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanren</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Management Information Systems (TMIS)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Mlp-mixer: An all-mlp architecture for vision</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Tolstikhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.01601</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Personalized employee training course recommendation with career development awareness</title>
		<author>
			<persName><forename type="first">Chao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference 2020</title>
				<meeting>The Web Conference 2020</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1648" to="1659" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Towards global explanations of convolutional neural networks with concept attribution</title>
		<author>
			<persName><forename type="first">Weibin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xixian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shenglin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irwin</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu-Wing</forename><surname>Michael R Lyu</surname></persName>
		</author>
		<author>
			<persName><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8652" to="8661" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Hierarchical attention networks for document classification</title>
		<author>
			<persName><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies</title>
				<meeting>the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1480" to="1489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Dlime: a deterministic local interpretable model-agnostic explanations approach for computer-aided diagnosis systems</title>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Rehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zafar</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Naimul</forename><surname>Mefraz Khan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.10263</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="818" to="833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A sequential approach to market state modeling and analysis in online p2p lending</title>
		<author>
			<persName><forename type="first">Hongke</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junping</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics: Systems</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="33" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<author>
			<persName><forename type="first">Wenjun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taposh Dutta</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Skrypnyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The kdd cup 2019 report</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="8" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><surname>Luisa M Zintgraf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tameem</forename><surname>Taco S Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Adel</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.04595</idno>
		<title level="m">Visualizing deep neural network decisions: Prediction difference analysis</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
