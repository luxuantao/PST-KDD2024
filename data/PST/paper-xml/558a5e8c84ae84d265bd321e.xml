<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Non-parametric Similarity Measures for Unsupervised Texture Segmentation and Image Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jan</forename><surname>Puzicha</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institut für Informatik III</orgName>
								<orgName type="institution">University of Bonn</orgName>
								<address>
									<addrLine>Römerstraße 164</addrLine>
									<postCode>D-53117</postCode>
									<settlement>Bonn</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institut für Informatik III</orgName>
								<orgName type="institution">University of Bonn</orgName>
								<address>
									<addrLine>Römerstraße 164</addrLine>
									<postCode>D-53117</postCode>
									<settlement>Bonn</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joachim</forename><forename type="middle">M</forename><surname>Buhmann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institut für Informatik III</orgName>
								<orgName type="institution">University of Bonn</orgName>
								<address>
									<addrLine>Römerstraße 164</addrLine>
									<postCode>D-53117</postCode>
									<settlement>Bonn</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Non-parametric Similarity Measures for Unsupervised Texture Segmentation and Image Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B5EE808544A8B8F925BBF6C565C3384A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we propose and examine non-parametric statistical tests to define similarity and homogeneity measures for textures. The statistical tests are applied to the coefficients of images filtered by a multi-scale Gabor filter bank. We will demonstrate that these similarity measures are useful for both, texture based image retrieval and for unsupervised texture segmentation, and hence offer an unified approach to these closely related tasks. We present results on Brodatz-like micro-textures and a collection of real-word images.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Color, Shape, Motion and Texture are the basic modes to describe low-level image content and have been used to both, measure similarity of images, and segment images into homogeneous regions. The definition of suitable similarity and homogeneity measures for these modes is a fundamental task in many important applications, ranging from vision-guided autonomous robotics and remote sensing to medical diagnosis and similarity-based retrieval in large image databases such as the QBIC system <ref type="bibr" target="#b0">[1]</ref> or the MIT Photo-book <ref type="bibr" target="#b7">[8]</ref>.</p><p>With the restriction to a set of known textures, retrieval and segmentation problems are essentially reduced to a supervised classification task, which is amenable for standard techniques from pattern recognition and statistics. As opposed to supervised methods which rely on labeled data to learn decision boundaries in some appropriate feature space, the central topic of unsupervised segmentation is concerned with the weaker notion of texture proximity, based on a general (not class-or texture-specific) similarity measure. Inspired by the supervised approach, the majority Supported by the German Research Foundation (DFG # BU 914/3-1) and by the Federal Ministry for Education, Science and Technology (BMBF # 01 M 3021 A/4). It is a pleasure to thank the MIT Media Lab for providing the VisTex database.</p><p>of unsupervised methods formulate the retrieval and segmentation problems in a feature-based fashion. This conception inevitably leads to the difficult problem of specifying a metric in the utilized feature space which appropriately represents visual dissimilarities between textures <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b2">3]</ref>. In contrast to this widely appreciated approach, we follow the ideas of <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7]</ref> and advocate non-parametric statistical tests to measure texture similarity. Statistical tests have the advantage to be applicable without parametric assumptions about the underlying pixel distribution. This guarantees the similarities to be assessable in terms of statistical significance, but avoids statistical parameter estimation.</p><p>There exists a tight relationship between similaritybased image retrieval and unsupervised texture segmentation. Image retrieval often requires to select those (parts of) images in a database which are most similar to a given query image, while the goal of image segmentation is to partition a given image into maximally homogeneous regions. Therefore these tasks are closely related to similarity measures, since homogeneity can be defined as the average similarity between pairs of local texture patches within a region. While similarity-based retrieval is straightforward for a given measure, we model the texture segmentation problem as a combinatorial optimization problem specified by a pairwise data clustering objective function. The choice of a suitable objective function is crucial, and has been motivated by certain invariance properties <ref type="bibr" target="#b3">[4]</ref>, i.e., linear transformations of the dissimilarities. Experimental evidence, too, suggests that these invariant functions are superior to the standard graph partitioning cost function utilized in <ref type="bibr" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Image Representation</head><p>The differential structure of an image I(x) is completely extracted by the classical scale-space representation. But in many applications it is convenient to use filters which are tuned to the features of interest, e.g., a particular spatial frequency k. The tuning operation can be formalized and, in Gabor filters perform a local Fourier analysis and exhibit excellent discrimination properties over a broad range of textures <ref type="bibr" target="#b4">[5]</ref>. The Gabor multi-scale image representation is especially useful for unsupervised texture processing, where little is known a priori about the characteristic frequencies of occurring textures. In this work, an image I is represented by a set of filtered images I r , defined by the modulus of the filter outputs, I r (x) = jI(x) G(x; r ; kr )j:</p><p>We have chosen 12 Gabor filters at 4 orientations and 3</p><p>scales separated by octaves with r = 3=jjk r jj in our experiments. Although we are convinced of the advantages offered by the Gabor representation for defining meaningful and robust similarity measures, the techniques presented in the sequel can be easily adapted to other feature sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Similarity Measures and Image Retrieval</head><p>To evaluate the dissimilarity between two textured images or image regions I and J, a statistical test D is applied to the distribution of Gabor coefficients, either independently for each pair I r and J r of filtered images, or to the joint distribution of coefficients in all channels. If the significance that both samples were drawn from the same distribution is </p><p>and by f k r (I) = f r (t k ; I) the empirical density (histogram) obtained by suitable binning t 0 &lt; t 1 &lt; &lt; t K . The generalization to the multidimensional case for joint distributions is straightforward and is omitted for brevity.</p><p>Several non-parametric test statistics are empirically investigated:</p><p>The Kolmogorov-Smirnov distance as originally proposed in <ref type="bibr" target="#b1">[2]</ref>. It is defined as the maximal distance of the PDFs, D r (I; J) = max t jF r (t; I) ? F r (t; J)j .</p><p>A statistic of the Cramer/von Mises type defined as the Euclidean distance of the PDFs, D r (I; J) = R (F r (t; I)?F r (t; J)) 2 dt; which is rescaled by the co- efficient variance to achieve comparable statistics for all channels.</p><p>The 2 -statistic D r (I; J)=</p><formula xml:id="formula_1">P K k=1 (f k r (I)? f k r ) 2 f k r ; where fk r = f k r (I) + f k r (J)]=2.</formula><p>The empirical Jeffrey-divergence defined by</p><formula xml:id="formula_2">D r (I; J) = P k f k r (I) log f k r (I) f k r + f k r (J) log f k r (J ) f k r</formula><p>, which in contrast to the Kullback-Leibler divergence suggested in <ref type="bibr" target="#b6">[7]</ref> is numerically stable, symmetric and robust with respect to noise and the size of histogram bins.</p><p>The Weighted-Mean-Variance (WMV) proposed in <ref type="bibr" target="#b5">[6]</ref>. For empirical means r (I); r (J) and standard deviations r (I); r (J) the distance is defined by D r (I; J) = j r (I) ? r (J)j j ( r )j + j r (I) ? r (J)j j ( r )j ; (3)   where ( ) denotes an estimate of the standard deviation of the respective entity. This measure based on a Gabor filter image representation has outperformed several other parametric models <ref type="bibr" target="#b5">[6]</ref>.</p><p>While a statistical test is a reliable measure to judge the dissimilarity of two sample sets in a single channel, the question arises how to combine the independently evaluated comparisons. We have investigated Minkowski norms D(I; J) = P r (D r (I; J)) p ; including the limiting case of the maximum norm (p = 1) utilized in <ref type="bibr" target="#b1">[2]</ref>. The Minkowski norm is less sensitive to differences in single channels for small p, while large p avoid the 'curse of dimensionality'. For a medium number of 10 ? 30 dimensions, the choice of p = 1 empirically showed the best performance.</p><p>Once a dissimilarity measure D(I; J) has been specified, the retrieval for a query J is obtained by sorting all database images I (n) ; 1 n N in ascending order of the dissimilarities D(I (n) ; J). Either a fixed number of matches or all matches with dissimilarity below a predefined threshold are displayed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Unsupervised Texture Segmentation</head><p>In our approach, textured image segmentation is formulated as a combinatorial optimization problem belonging to the class of partitioning or clustering problems, where a set of N sites xi is mapped to a set of texture labels. For nota- tional convenience we introduce an indicator function representation M i 2 f0; 1g denoting that site i is mapped to label . If the number of distinctive textures K is known a priori, a segmentation is summarized in terms of a Boolean assignment matrix M 2 M, with</p><formula xml:id="formula_3">M = ( M 2 f0; 1g N K : K X =1 M i = 1; 1 i N ) :</formula><p>For the image segmentation problem, we evaluate proximities D ij between pairs of image windows located at positions xi and xj . For simplicity we consider squared areas around the center point, where the size of the window is chosen proportional to the scale parameter r of the Ga- bor filter <ref type="bibr" target="#b4">[5]</ref>. The data clustering cost function thus has to rely on the proximity matrix D = (D ij ) 2 IR N N .</p><p>While vector-valued data with a fixed number of features scales linear with the number of sites N, pairwise comparison results in a scaling with N 2 . Yet, it is obvious, that a complete proximity matrix possesses a significant inherent redundancy. To guarantee computational efficiency, the calculation of dissimilarities is restricted to positions xi on a regular sub-lattice of the image. Moreover, comparisons are only made with a substantially reduced set of pairs (x i , xj ). This subset is specified in terms of a neighborhood system N = (N i ) i=1;::: ;N , N i f1; : : : ; Ng, which is an irreflexive and symmetric binary relation. Following <ref type="bibr" target="#b1">[2]</ref>, we define the neighborhood N i , jN i j N of a site xi to consist of the four connected neighborhood in the image and a larger number of random neighbors. The main problem from a modeling perspective is the specification of an objective function H : M ! IR to assess the qual- ity of image partitionings M. In this work, we focus on functions measuring intra-cluster compactness, which only depend on the homogeneity of a segment. Additionally, we demand invariance of H with respect to linear transformations of the dissimilarity matrix. This has the advantage not to introduce a dependency on the minimum of the dissimilarity function. Indeed, it has been noticed <ref type="bibr" target="#b1">[2]</ref> that data have to be shifted appropriately in order to keep the right balance between negative and positive contributions, when using the standard graph-partitioning function</p><formula xml:id="formula_4">H gp (M) = P K =1 P N i=1 P j2Ni M i M j D ij . However, if</formula><p>an image contains many different textures, it is often impossible to globally shift the data, such that all textures are well-discriminated. Furthermore it is impossible to select a correct shift for a larger set of images <ref type="bibr" target="#b3">[4]</ref>.</p><p>Taking the invariance properties as our major guideline for an axiomatic derivation of clustering functions <ref type="bibr" target="#b3">[4]</ref>, we arrive at the following objective function</p><formula xml:id="formula_5">H(M) = K X =1 " N X i=1 M i # P N i=1 P j2Ni M i M j D ij P N i=1 P j2Ni M i M j ;<label>(4)</label></formula><p>which weights average cluster homogeneities proportional to the cluster size. The total cost thus corresponds to the sum of the average dissimilarities between pairs of objects in the same cluster.</p><p>To minimize the cost function in (4) we apply an annealing technique. Optimization methods based on annealing treat the unknown Boolean variables as random variables, introduce a scale parameter T, often called the computational temperature, and calculate equilibrium Gibbs averages, e.g., of assignments M i . This is achieved either by Monte Carlo sampling or (at least approximately) by analytical methods. The temperature T is gradually lowered and for T 0 an admissible solution for the combinatorial optimization problem is found.</p><p>Denote by s i (M) the matrix obtained by replacing the i-th row of M with the unit vector ẽ and let g i = H(s i ).</p><p>Then an efficient Monte Carlo algorithm is defined by the Gibbs-Sampler, which samples from the conditional probability spanned by site xi for fixed assignments of sites xj ; j 6 = i: P(s i (M)) = exp (?g i =T) P exp (?g i =T) :</p><p>(5) Note that the calculation of P(s i (M)) is invariant with respect to additive shifts of the partial costs g i . This can be used to derive an efficient formula for the Gibbs weights of (4).</p><p>Using the abbreviations</p><formula xml:id="formula_6">a i = P k6 =i M k , b i = 2 P k2Ni M k D ik , c i = P k6 =i P l2Nk;l6 =i M k M l D kl , o i = 2 P k2Ni M k and n i = P k6 =i P l2Nk;l6 =i M k M l this yields g i = (a i + 1)b i + c i n i + o i</formula><p>? o i a i c i n i (n i + o i ) : (6)   By the fundamental relationship</p><formula xml:id="formula_7">hM i i Q = exp (?hg i i Q =T) P exp (?hg i i Q =T) ;<label>(7)</label></formula><p>which is valid for factorizing distributions Q minimizing the KL-divergence to P,an even more efficient approximative, deterministic and convergent algorithm with global optimization properties is obtained known as deterministic annealing. For the details and a convergence proof, the reader is refered to <ref type="bibr" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>To empirically evaluate the performance of a dissimilarity measure relative to a given set of textures, we have adopted the performance measure proposed in <ref type="bibr" target="#b5">[6]</ref> to achieve comparable results. Assume a database of size m n containing m  samples of each of n textures. For each entry i the distances d(i; j) to all other samples are computed and sorted in ascending order. In the ideal case the first (m ? 1) textures are of the same type as i. The performance is defined as the average percentage of textures of the same type within the top (m ? 1) matches. It is applied to a database containing 16 random samples for each of 40 Brodatz-like reference textures. For all dissimilarity measures the same Gabor features were used. In Fig. <ref type="figure" target="#fig_4">4</ref> the performance is depicted for the distance measures presented in Sect. 3 and different image (block) sizes. Two important observations are in place:</p><p>The quality for all measures drastically deteriorates for smaller images.</p><p>The statistical similarity measures perform uniformly better than the parametric WMV-measure. The empirical Jeffrey-divergence and the 2 -test do better than the Cramer/von Mises measure and the KS-statistic.</p><p>The first fact was expected, as it becomes even visually more and more difficult to identify small texture patches.</p><p>WMV implicitly relies on an invalid Gaussian assumption, explaining the inferior quality of the measure, as illustrated  by two example queries in Fig. <ref type="figure" target="#fig_0">1</ref>, 2. The measure performs significantly worse than 2 . We like to stress that the WMV-measure has outperformed several feature-based methods including multiresolution autoregressive models and the tree-structured wavelet transform <ref type="bibr" target="#b5">[6]</ref>. The inferior performance of the KS-distance and the Cramer/von Mises measure is explained by the fact, that samples of a not completely uniform texture regularly exhibit a shift in the feature distribution. This results in high dissimilarity values for measures relying on the PDFs. The quality of a measure depends on the rule to integrate the clues of different feature channels. In Sect. 3 we proposed a family of rules depending on a parameter p. As shown in Fig. <ref type="figure" target="#fig_5">5</ref> for the 2 distance adding information from the different channels is superior to the max-rule. Alternatively, the Jeffrey-divergence and 2 can be applied to multivariate density estimates. This yields superior results for large sample sizes, but suffers from the difficulty to efficiently estimate a multivariate density for few samples. As an example, Fig. <ref type="figure" target="#fig_5">5</ref> shows the results for 2 applied to an estimate of the multivariate density of four orientations for a given scale. The univariate 2 statistic with p = 1 was selected for the subsequent experiments, due to excellent performance and faster computational evaluation compared to the Jeffrey-divergence.</p><p>In Fig. <ref type="figure" target="#fig_3">3</ref> three example retrievals for the 2 -statistic using a large collection of images taken from the VisTex database are shown. The retrieved images are even for the street scene visually similar. Another application is image annotation, where for a given labeled image block similar image regions should be identically labeled in a semiautomatic fashion to speed the annotating process <ref type="bibr" target="#b7">[8]</ref>. From the collection of 40 reference textures we constructed a database containing 100 random mixtures, each of 512x512 pixels and containing five textures (as depicted in Fig. <ref type="figure" target="#fig_7">7(a)</ref>). For each image a sub-grid of 64x64 sites and a window size of 16x16 pixels was selected. A typical segmentation example is shown in Fig. <ref type="figure" target="#fig_7">7</ref>. All databases and additional examples are available via World Wide Web (WWW). To remove the speckle like noise a simple postprocessing step was applied. Note that with the same segmentation algorithm, 2 yields a significantly better segmentation than the WMV-measure. Further evidence is given in Fig. <ref type="figure" target="#fig_8">8</ref> which shows the histogram of misclassified blocks with respect to ground truth. The median error rate of 2.65% (7.12% before post-processing) is remarkably good compared to 7.1% (15.7% before post-processing) for the WMV-measure. For 2 the essential structure of the image is detected in almost all cases. A typical application for texture segmentation, e.g., in autonomous robotics, are indoor and outdoor images which contain textured objects. An example image of an office environment is presented in Fig. <ref type="figure" target="#fig_10">9</ref>. The achieved segmentation is both visually and semantically satisfying. Untextured parts of the image are grouped together irrespectively of there absolute luminance value as expected and the discrimination of the remaining three textures we found highly convincing. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Summary and Conclusion</head><p>We proposed a novel approach for defining similarity measure for textures based on statistical tests to compare the empirical distributions of Gabor coefficients. The major drawback of all feature-based methods, namely the need to specify a suitable metric in parameter space, is hence avoided. An efficient segmentation algorithm operating on the same pairwise similarity values has been presented. The advantages of the unifying framework have been demonstrated by a benchmark on Brodatz-like micro-textures and on real-word images.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Example retrieval 1.) for the 2 -statistic and 2.) for WMV. Images are 64x64 pixels each. The database consists of 16 samples of each of 40 reference textures. The image captions depict the retrieval rank r and the measured distance D. the case of frequency tuning, yields the family of complex Gabor filters G(x; ; k) = 1 p 2 exp ? ?x t x=2 exp i kt x : (1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>high (low), their dissimilarity D(I; J) is judged low (high). More formally, we denote by F r ( ; I) the empirical probability distribution function (PDF) of Gabor coefficients in the filtered image I r of size L M, F r (t; I) = jfx 2 I r : I r (x) tgj = (L M)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Example retrieval for the same database as in Fig. 1. The WMV-measure (2) performs significantly worse and does not correspond well to visual similarity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Example image retrievals: (a)-(h) bark, (i)-(p) plant, (q)-(x) street scene. The database consists of 668 images with 64x64 pixels each ranging from homogeneous textures to inhomogeneous textured outdoor scenes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Average percentage of correctly identified blocks according to the performance measure proposed by Manjunath and Ma (see text). The results for the Jeffrey-divergence are almost identical to 2 and therefore omitted.</figDesc><graphic coords="5,343.22,18.60,168.68,168.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Average percentage of correctly identified blocks for 2 using different channel integration rules.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Image annotation: The image blocks most similar to the two test blocks, marked by arrows, are depicted by white and gray boxes.</figDesc><graphic coords="5,313.83,239.48,112.34,112.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Typical segmentation results with K = 5: (a) Randomly generated image. (b) Segmentation based on 2 . (c) Segmentation after post-processing. (d) Segmentation based on WMV. (e) Segmentation after post-processing.</figDesc><graphic coords="5,434.84,298.03,53.17,53.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Empirical densities of the percentage of misclassified blocks over 100 random images using identical segmentation algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Figure 6 depicts two test regions and the corresponding most similar regions for an SAR image of Orange County.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. (a) Indoor image of a typical office environment containing an old-style sofa. (b) Contrast based image segmentation with a region merging algorithm, (c) a texture segmentation with K = 4. The image partitioning is visualized in (d)-(g).</figDesc><graphic coords="6,339.35,18.22,112.69,112.69" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Query by image and video content: The QBIC system</title>
		<author>
			<persName><forename type="first">M</forename><surname>Flickner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="page" from="23" to="32" />
			<date type="published" when="1995-09">Sept. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Boundary detection by constrained optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Graffigne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="609" to="628" />
			<date type="published" when="1990-07">July 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On retrieving textured images from image database</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gimel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1461" to="1483" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A deterministic annealing framework for textured image segmentation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buhmann</surname></persName>
		</author>
		<idno>IAI-TR-96-2</idno>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>Institut für Informatik III</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unsupervised texture segmentation using Gabor filters</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Farrokhnia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1167" to="1186" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Texture features for browsing and retrieval of image data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Manjunath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A comparative study of texture measures with classification based feature distributions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="59" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Vision texture for annotation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Minka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimedia Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="3" to="14" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
