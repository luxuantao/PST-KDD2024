<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Licheng</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Science</orgName>
								<orgName type="institution">University of Macau</orgName>
								<address>
									<postCode>999078</postCode>
									<settlement>Macau</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DBDC6C726740E22CDDB90091F9268F96</idno>
					<idno type="DOI">10.1109/TIP.2015.2456432</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the proposed model, the complicated relationships between the reconstructed and the noisy images are exploited to make the coding coefficients more appropriate to recover the noise-free image. Moreover, the image pixels are classified into clear, slightly corrupted, and heavily corrupted ones. Different data-fidelity regularizations are then accordingly applied to different pixels to further improve the denoising performance. In our proposed method, the dictionary is directly trained on the noisy raw data by addressing a weighted rank-one minimization problem, which can capture more features of the original data. Experimental results demonstrate that the proposed method is superior to several state-of-the-art denoising methods.</p><p>Index Terms-Image denoising, couple sparse representation, dictionary learning, classified regularization, impulse noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>I MAGE denoising is a fundamental but challenging topic and plays an important role in the image processing field <ref type="bibr" target="#b0">[1]</ref>. Noisy images have bad characteristics, hence they can not be directly used for the subsequent image processing, e.g., segmentation, recognition, and retrieval. One of the most frequently encountered noise is the impulse noise (IN), which is mainly introduced into images by imperfect acquisition processes, transmission errors, and bit errors in analog-to-digital conversions.</p><p>The goal of image denoising is to remove noise as much as possible while preserve more image details. To suppress IN, a variety of techniques have been developed, among which the median filter (MF) <ref type="bibr" target="#b1">[2]</ref> is widely used due to its simplicity. One limitation of MF is its poor denoising capacity since it just replaces each pixel intensity by the local median value. The improvements, such as the weighted median filter (WMF) <ref type="bibr" target="#b2">[3]</ref> and the center weighted median (CWM) filter <ref type="bibr" target="#b3">[4]</ref>, still can not suppress IN thoroughly because they modify all pixels indifferently.</p><p>Because the IN just affects partial pixels in images and leaves the remaining ones untouched, noise detectors can be designed to identify the noisy pixels before filtering. Then the noisy pixels are filtered while the clean ones remain unchanged. Such kind of techniques are usually median-or mean-type filters based, including the adaptive center weighted median (ACWM) filter <ref type="bibr" target="#b4">[5]</ref>, Luo-iterative method <ref type="bibr" target="#b5">[6]</ref>, the contrast enhancement filter (CEF) <ref type="bibr" target="#b6">[7]</ref>, the adaptive switching median (ASWM) filter <ref type="bibr" target="#b7">[8]</ref>, the robust outlyingness ratio based non-local mean (ROR-NLM) <ref type="bibr" target="#b8">[9]</ref>, and the two-phase detector based weighted mean filter (TPD-WMF) <ref type="bibr" target="#b9">[10]</ref>. These methods employ the noise detectors and more information from local neighborhood to estimate the center pixel. Nevertheless, they still distort some image edges and bring in many artifacts due to the limited denoising performance of the filters they used.</p><p>In <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr">Garnett et al.</ref> presented an image statistic rank-ordered absolute difference (ROAD) to measure the probability of a pixel to be corrupted by IN. The ROAD is further incorporated into the bilateral filter to remove mixed noise. Later, Dong et al. <ref type="bibr" target="#b11">[12]</ref> improved this idea and proposed a more robust statistic rank-ordered logarithmic difference (ROLD) which is integrated into the edgepreserving regularization (EPR) <ref type="bibr" target="#b11">[12]</ref> for IN reduction.</p><p>In recent years, sparse representation (SR) <ref type="bibr" target="#b12">[13]</ref> has been emerging as a powerful tool for handling various image processing tasks, such as denoising <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, superresolution <ref type="bibr" target="#b15">[16]</ref>- <ref type="bibr" target="#b17">[18]</ref>, deblurring <ref type="bibr" target="#b18">[19]</ref>, inpainting <ref type="bibr" target="#b19">[20]</ref>, recognition <ref type="bibr" target="#b20">[21]</ref>- <ref type="bibr" target="#b22">[23]</ref>, etc. The basic idea of SR is that the signal can be well reconstructed by the linear combination of a few atoms from an appropriate database called dictionary. For image denoising, image patches arranged in lexicographic order as vectors are extracted from the noisy image and served as units of SR. The reconstructed image is then obtained by averaging all the overlapping denoised patches for each position. Recent works <ref type="bibr" target="#b23">[24]</ref>- <ref type="bibr" target="#b25">[26]</ref> have shown that SR models have good performance in removing Gaussian noise (GN). Unfortunately, due to the totally different distributions of GN and IN, the traditional SR based methods that have fantastic performance in GN removal always fail in IN reduction.</p><p>In <ref type="bibr" target="#b26">[27]</ref>, Xiao and Zeng first incorporated noise detectors into SR model for IN removal. Later, Liu et al. <ref type="bibr" target="#b27">[28]</ref> presented a weighted dictionary learning model for removing mixed noise (GN mixed with IN), in which the dictionary learning, image reconstruction, noise detection, and parameter estimation are integrated into a four-step framework. Recently, by forcing the distribution of the sparse coding residual more Gaussian-like, Jiang et al. <ref type="bibr" target="#b28">[29]</ref> proposed a weighted encoding model to handle the mixed noise. Instead of employing noise detectors, they chose to detect noisy pixels by a soft rule according to the encoding residual.</p><p>Though the SR based methods mentioned above have achieved encouraging denoising performance for mixed noise, they may face some troubles when deal with the single IN removal problem. Firstly, none of those methods takes into account the IN characteristics, hence many image details may be lost when they are used to remove single IN. Secondly, since just the clean pixels are used for sparse coding, these methods may fail in the high noise level environment, where the number of useful clean pixels are limited. Finally, the values of clean pixels are also changed in the reconstruction stage, while for IN removal, leaving the clean pixels unchanged can significantly improve the quality of reconstructed image.</p><p>To address the above concerns, in this paper we proposed a Weighted Couple SR (WCSR) model for IN removal. In our proposed method, a weight matrix is incorporated to classify the pixels into three categories and to subtly determine the contribution of each pixel offered in the sparse coding stage, which makes the SR model more suitable for IN removal. Besides, the reconstructed and noisy images are coupled in sparse coding to explore the complicated relationships between them. More specifically, because the reconstructed image contains less noise and share the similar scenario with the original noise-free one, it is used in our method to compensate the lost information in the noisy image. Coupled coding of the reconstructed and noisy images yields the sparse coefficients much closer to those of the underlying degradation-free image than the coefficients that would result from coding of the single noisy image. Therefore, the sparse coding coefficients produced by the proposed WCSR model are more appropriate for reconstruction. The contributions of this paper are listed as follows.</p><p>• The cleanliness of each pixel is measured by a fuzzy membership function, which is more suitable for IN since the inherent feature of IN is uncertainty <ref type="bibr" target="#b29">[30]</ref>. Moreover, the weight determines how much contribution each pixel should offer in the sparse coding stage, which can suppress the effects of outliers. • The WCSR model simultaneously codes the noisy and the reconstructed images to explore the complicated relationships between them, which helps to improve the reconstruction accuracy. • All the image pixels are classified into three categories, and different categories are assigned with different regularizations according to their characteristics. This preserves more image details and makes the proposed model more robust to outliers.</p><p>• To search the best basis to represent the noisy image, we propose a novel dictionary learning method to train the dictionary directly on the raw data with outliers. The dictionary is learned by jointly updating the dictionary atoms and the corresponding coefficient vectors, which is convergent and efficient. The remainder of this paper is organized as follows. In Section II, the noise detection rule and the proposed weighted sparse-land model are described in detail. Experimental results are shown in Section III. Finally, section IV reaches a conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. THE PROPOSED ALGORITHM</head><p>In this section, we first introduce the IN model and the detection rule. Then we describe in detail the proposed WCSR model and its solutions. Throughout the paper, we use the uppercase and lowercase letters to denote vectors (images) and entries (pixels), respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Impulse Noise Model</head><p>Let x i, j and o i, j denote the (i, j )-th pixel values in the corrupted and clean images, respectively. Supposing the pixel values are bounded by m min and m max , the IN model is described as, </p><formula xml:id="formula_0">x i, j = o i, j ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Outlier Detection</head><p>In our approach, we use two different rules for SPN and RVIN detection, namely "hard rule" for the former and "soft rule" for the latter. The reason is that SPN corrupted pixel values are extremely large or small, which can be easily detected. It is sufficient to detect them in a "hard rule". While for RVIN, the noisy pixel values may not be so different from those of corresponding clean pixels, hence it is more appropriate to detect them in a "fuzzy way" <ref type="bibr" target="#b29">[30]</ref>.</p><p>The adaptive median filter (AMF) <ref type="bibr" target="#b30">[31]</ref> is used in our approach to detect SPN. For simplicity, suppose Y is the filtered result by a median-type filter, the detection result of AMF is recoded in a binary matrix W , w i, j = 0; x i, j = y i, j and y i, j ∈ {0, 255} 1; otherwise <ref type="bibr" target="#b1">(2)</ref> in which w i, j = 0 means the pixel x i, j be corrupted by noise, while w i, j = 1 denotes x i, j be clean.</p><p>For RVIN, the "soft detection rule" is achieved by introducing a fuzzy membership function on the ROLD values of the noisy image. The ROLD is a local image statistic describing the noisy pixels based on the assumption that the absolute differences between the noisy pixels and their neighbors are relatively larger than those between the clean ones and their neighbors. Readers are referred to <ref type="bibr" target="#b10">[11]</ref> for more details of ROLD. Here, we choose the exponential function for simplicity,</p><formula xml:id="formula_1">w i, j = ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ 1; RO L D(x i, j ) ≤ τ 1 exp -(α-ROL D(x i, j )) 2 σ 2 ; τ 1 &lt; RO L D(x i, j ) ≤τ 2 0; RO L D(x i, j ) &gt; τ 2<label>(3)</label></formula><p>where 0 ≤ w i, j ≤ 1 denotes the cleanliness of pixel x i, j . Especially, w i, j = 1 means x i, j to be a clean pixel and w i, j = 0 indicates x i, j to be a noisy one. We set the parameter σ = 1 in our method.</p><p>In this paper, all the pixels in noisy image are divided into three categories based on the fuzzy weights, namely, clean, slightly corrupted, and heavily corrupted pixels. For simplicity, we use C = {(i, j )|w i, j = 1}, S = {(i, j )|0 &lt; w i, j &lt; 1}, and H = {(i, j )|w i, j = 0} to denote the coordinates of these three classes, respectively. In the following, we will denote X C , X S , and X H as the set of clean pixels, the set of slightly corrupted pixels, and the set of heavily corrupted pixels, respectively. Obviously, X S is null for SPN corrupted images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Weighted Sparse-Land Model</head><p>For an image contaminated by IN, not all the pixel values are changed, and there are still some clean pixels that are useful. One can use these clean pixels to reconstruct the original image. For sparse-land model, we should exclude the noisy pixels and restrain the sparse coding on these clean ones. This can be achieved by introducing a weight matrix into the SR model <ref type="bibr" target="#b31">[32]</ref>, αi, j = arg min</p><formula xml:id="formula_2">α i, j R i, j W ⊗ R i, j X -Dα i, j 2 2 s.t. α i, j 0 ≤ L (4)</formula><p>where the symbol ⊗ denotes Hadamard (element-wise) product; X is the corrupted image with size of</p><formula xml:id="formula_3">√ N × √ N .</formula><p>W is a weight matrix generated by a noise detector, and with the same size of X; D ∈ R n×K (n &lt; K ) is a redundant dictionary, whose each column represents an atom; R i, j denotes a n × N matrix that is used to extract the (i, j )-th √ n × √ n patch (reshaped as a vector) from the image; α is the representation coefficient expected to be sparse, that is, just a few entries in α are nonzero; L is the sparse ratio.</p><p>The above model is called weighted sparse representation (WSR). The basic assumption of SR based denoising framework is that the noisy and original images share the same coefficients on a certain dictionary. Hence once the coefficients are calculated from the noisy patches, the reconstructed patches can be estimated by the product of the dictionary and the coefficients. The restored image is then directly obtained Fig. <ref type="figure">1</ref>. PSNR values of recovered images by using WSR (Eq. ( <ref type="formula">4</ref>)) and WCSR (Eq. ( <ref type="formula">6</ref>)). The x-coordinate denotes the image index shown in Fig. <ref type="figure" target="#fig_7">2:</ref> 1: lena, 2: pepper, 3: barbara, 4: boat, 5: bridge, 6: house, 7: pentagon, 8: F16.</p><p>by averaging all the overlapping reconstructed patches,</p><formula xml:id="formula_4">X = ⎛ ⎝ i, j R T i, j R i, j ⎞ ⎠ -1 • i, j R T i, j Dα i, j<label>(5)</label></formula><p>Though WSR performs well in suppressing most of the IN, it has two main shortcomings. First, since it uses clean pixels for sparse coding, model (4) will be failed when the noise density is high, where the number of clean pixels can be used is limited. Second, the weight matrix in (4) generated by the noise detector is not always credible, especially for RVIN corrupted image. Some noisy pixels may be judged as clean ones and used for sparse coding. This will cause severe distortion of the sparse coefficients and make them not able to accurately reconstruct the noise-free image. Inspired by the fact that the reconstructed image contains less noise but the same scenario of the original noise-free one, a weighted couple SR (WCSR) model is presented to simultaneously encode the reconstructed and the noisy images. In WCSR, the reconstructed image is used to compensate the lost information in the noisy one, which drags as much as possible the sparse coefficients back to those that would generated from coding of the noise-free image. Hence the coefficients generated by the WCSR are more appropriate for image reconstruction. The WCSR model is formulated as follows, αi, j = arg min</p><formula xml:id="formula_5">α i, j i, j 1 2 R i, j W ⊗ (R i, j X -Dα i, j ) 2 2 + i, j 1 2 R i, j (I -W ) ⊗ (R i, j Y -Dα i, j ) 2 2 s.t. α i, j 0 ≤ L (6)</formula><p>where Y denotes the estimation of X, I is a matrix with proper size, and its entries all are ones. To verify the superiority of WCSR (Eq. ( <ref type="formula">6</ref>)) over WSR (Eq. ( <ref type="formula">4</ref>)), we utlize the two models to restore all the tested images (shown in Fig. <ref type="figure" target="#fig_0">2</ref>) corrupted by RVIN with 40% noise density, respectively. The dictionary D is chosen as DCT dictionary. Fig. <ref type="figure">1</ref> shows the PSNR values of restoration results. From this figure, we can see that, the results generated by the WCSR are better than those of the WSR for all the tested images. This owes to the fact that the information of reconstructed image utilized in the sparse coding helps to generate more appropriate coefficients to estimate the noise-free image.</p><p>Inspired by the fact that the global prior knowledge can further improve the denoising performance of SR model <ref type="bibr" target="#b13">[14]</ref>, we choose to minimize the following regularization term</p><formula xml:id="formula_6">W ⊗ (Y -X) 2 2 (7)</formula><p>as the global prior. It can been see that <ref type="bibr" target="#b6">(7)</ref> forces the estimations close to the clean pixels, that is, the pixels in the reconstructed image should approximate to these corresponding clean ones as much as possible. This preserves more image details and improves the quality of final output.</p><p>Though the l 2 -norm in ( <ref type="formula">7</ref>) makes the final model well in keeping the image details, it is sensitive to the noise detector that generates the weight matrix, especially when the noise level is high. To enhance its robustness, one thing we can do is to introduce a l 1 -norm penalty term into the SR model, since l 1 -norm has been demonstrated more suitable for IN than l 2 -norm <ref type="bibr" target="#b32">[33]</ref>. According to <ref type="bibr" target="#b32">[33]</ref>, minimizing of l 1 -norm involves an implicit detection of IN which is very crucial in IN reduction.</p><p>In <ref type="bibr" target="#b26">[27]</ref>, Xiao et al. introduced the following l 1 -term on noise candidates into SR model to make it more robust to outliers,</p><formula xml:id="formula_7">(i, j )∈N y i, j -x i, j 1<label>(8)</label></formula><p>where y i, j denotes the (i, j )-th estimation, N is the index set of all the noisy pixels. Minimization of ( <ref type="formula" target="#formula_7">8</ref>) means that the estimations should close to noisy pixels under the rule of l 1 -norm data fidelity. One disadvantage of ( <ref type="formula" target="#formula_7">8</ref>) is that all the noisy pixels are covered in the l 1 -term. Unfortunately, the heavily corrupted pixels have no relationships with the corresponding original clean ones, and their use in the loss function can only be harmful. On the contrary, for the slightly corrupted pixels, although their values are also changed, the biases are relatively smaller, and the original pixel values can still be mined by the l 1 -norm. Inspired by this, we choose to use the following l 1 -term, (i, j )∈S (1 -w i, j ) y i, jx i, j 1 <ref type="bibr" target="#b8">(9)</ref> Note that the difference between ( <ref type="formula">9</ref>) and ( <ref type="formula" target="#formula_7">8</ref>) is that in (9) just the slightly corrupted pixels are considered in l 1 -norm, and there is a weight determining how much contribution each pixel should offer.</p><p>Combining the WCSR with ( <ref type="formula">7</ref>) and ( <ref type="formula">9</ref>), we present the following IN removal model which is named as WCSR-l 2 l 1 ,</p><formula xml:id="formula_8">( α, D, Ŷ ) = arg min α,D,Y i, j 1 2 R i, j W ⊗ R i, j X -Dα i, j 2 2 + i, j 1 2 R i, j (I -W ) ⊗ R i, j Y -Dα i, j 2 2 + λ 1 2 W ⊗ (Y -X) 2 2 + λ 2 (i, j )∈S (1 -w i, j )(y i, j -x i, j ) 1 s.t. α i, j 0 ≤ L (<label>10</label></formula><formula xml:id="formula_9">)</formula><p>where λ 1 and λ 2 are two control parameters. By introducing another matrix W with each entry wi, j = (1-w i, j )•sign(w i, j ), where sign is the symbolic function. Model ( <ref type="formula" target="#formula_8">10</ref>) is rewritten as,</p><formula xml:id="formula_10">( α, D, Ŷ ) = arg min α,D,Y i, j 1 2 R i, j W ⊗ R i, j X -Dα i, j 2 2 + i, j 1 2 R i, j (I -W ) ⊗ R i, j Y -Dα i, j 2 2 + λ 1 2 W ⊗ (Y -X) 2 2 + λ 2 W ⊗ (Y -X) 1 s.t. α i, j 0 ≤ L. (<label>11</label></formula><formula xml:id="formula_11">)</formula><p>The proposed WCSR-l 2 l 1 model that aims to optimize three variables simultaneously is not easy to solve. A tractable optimization problem can be obtained by relaxing <ref type="bibr" target="#b10">(11)</ref>. Fixed the other two variables, the optimization of the third one changes into a convex subproblem, which admits an efficient solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Alternating Minimization</head><p>In this subsection, we introduce an alternating minimization method to solve the proposed model. The three variables α, D, and Y can be updated alternatively by solving three optimization subproblems.</p><p>(1) Sparse coding: given Y, D, the coefficient α is calculated by</p><formula xml:id="formula_12">αi, j = arg min α i, j 1 2 R i, j W ⊗ R i, j X -Dα i, j 2 2 + i, j 1 2 R i, j (I -W ) ⊗ R i, j Y -Dα i, j 2 2 s.t. α i, j 0 ≤ L (<label>12</label></formula><formula xml:id="formula_13">)</formula><p>by introducing the following auxiliary variables,</p><formula xml:id="formula_14">Ri, j W = R i, j W R i, j (I -W ) , Ri, j Ỹ = R i, j X R i, j Y , D = D D (13) (12) is rewritten as, αi, j = arg min α i, j i, j Ri, j W ⊗ Ri, j Ỹ -Dα i, j 2 2 s.t. α i, j 0 ≤ L (<label>14</label></formula><formula xml:id="formula_15">)</formula><p>Eq. ( <ref type="formula" target="#formula_14">14</ref>) is a weighted sparse coding problem due to the existence of the weight matrix and the Hadamard product operator. In <ref type="bibr" target="#b26">[27]</ref>, forcing the weight to be a binary matrix, Xiao and Zeng, et al. solved such a problem by using the strategy of SR based image inpainting, in which the OMP algorithm is chosen and slightly changed by projecting only the clean pixels on the dictionary. Unfortunately, that strategy no longer works for our problem because the weight W in ( <ref type="formula" target="#formula_14">14</ref>) is a fuzzy weight matrix with each entry 0 ≤ wi, j ≤ 1. To solve Eq. ( <ref type="formula" target="#formula_14">14</ref>), we derive each α i, j by a minimization problem as follows,</p><formula xml:id="formula_16">αi, j = arg min α Q(R i, j Ỹ ) -Q Dα i, j 2 2 s.t. α i, j 0 ≤ L (<label>15</label></formula><formula xml:id="formula_17">)</formula><p>where</p><formula xml:id="formula_18">Q = diag Ri, j W is a diagonal matrix. Replaced by ȳi, j = Q • (R i, j Ỹ ) and D = Q • D, the problem is transformed into, αi, j = arg min α i, j ȳi, j -Dα i, j 2 2 , s.t. α i, j 0 ≤ L (<label>16</label></formula><formula xml:id="formula_19">)</formula><p>which is a sparse coding problem of projecting the signal ȳi, j on the new dictionary D, and can be efficiently solved by OMP algorithm.</p><p>(2) Dictionary learning: given Y and α, the dictionary D is updated as</p><formula xml:id="formula_20">D = arg min D i, j 1 2 R i, j W ⊗ R i, j X -Dα i, j 2 2 + i, j 1 2 R i, j (I -W ) ⊗ R i, j Y -Dα i, j<label>2 2 (17)</label></formula><p>Note that there are two dictionaries, one is for representing the reconstructed image Y , the other is for decomposing the noisy image X. Indeed, (17) suggests we train the two dictionaries simultaneously by combing the two dictionaries as a new one, D new = D T , D T T , however, this will be time consuming. Actually, we experimentally found that it works well if we manually set the two dictionaries equally and just train one on X. This is because Y is the estimation of X, then the trained dictionary D can also reduce the residual term i, j</p><formula xml:id="formula_21">1 2 R i, j (I -W )⊗(R i, j Y -Dα i, j ) 2 2 .</formula><p>Hence the dictionary is trained as,</p><formula xml:id="formula_22">D = arg min D i, j R i, j W ⊗ R i, j X -Dα i, j 2 2 . (<label>18</label></formula><formula xml:id="formula_23">)</formula><p>Due to the existence of weight matrix, the above problem can not be directly solved by the K-SVD <ref type="bibr" target="#b33">[34]</ref> algorithm. Denote by <ref type="formula" target="#formula_22">18</ref>) is rewritten as,</p><formula xml:id="formula_24">W B = [R i, j W ] ∈ R n×N , X B = [R i, j X] ∈ R n×N , and A = [α] i, j ∈ R K ×N , where i, j ∈ 1, 2, • • • , √ N , (</formula><formula xml:id="formula_25">D = arg min D, d k =1 W B ⊗ (X B -D A) 2 2 (19)</formula><p>A natural choice is to update one atom d k of D with other atoms fixed each time,</p><formula xml:id="formula_26">dk , αk X = arg min α k X , d k 2 2 =1 W B ⊗ E k -d k α k X 2 2 (20)</formula><p>where α k X is a row vector composed by all the non-zero entries of the k-th row of coefficient matrix A. E k = X B -K l=1,l =k d l α l X is the residual error corresponding to the training samples that currently use the d k . This is a weighted rank one matrix approximation problem, which cannot be directly solved via KSVD but can be solved by the iterative weighted KSVD algorithm <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>. However, the weighted KSVD can not work for the unweighted case when W = τ I is a scalar matrix <ref type="bibr" target="#b27">[28]</ref>.</p><p>By adopting the alternating optimization strategy <ref type="bibr" target="#b36">[37]</ref>, we introduce a dictionary learning method to efficiently approximate the solution of (20). To update d k and α k X , we have the following property.</p><p>Property 1: For a multivariate function</p><formula xml:id="formula_27">F(d, α) = W ⊗ (E -dα) 2 F , the minimum point ( d, α) is calculated as d = -1 •( W ⊗ Eα T ), and α = d T ( W ⊗ E)• -1 , where W = W ⊗ W , = diag(W (α ⊗ α) T ), and = diag W T • (d • d) .</formula><p>Proof: See Appendix. According to Property 1, the solutions of ( <ref type="formula">20</ref>) are given by</p><formula xml:id="formula_28">⎧ ⎨ ⎩ dk = -1 • W ⊗ E k • (α k X ) T αk X = (d k ) T • W ⊗ E k • -1<label>(21)</label></formula><p>The convergence is guaranteed and achieved by a single iteration <ref type="bibr" target="#b36">[37]</ref>.</p><p>(3) Image estimation: given D and α, the reconstructed image Y can be estimated from the following minimization problem,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ŷ= arg min</head><formula xml:id="formula_29">Y i, j 1 2 R i, j (I -W ) ⊗ R i, j Y -Dα i, j 2 2 + λ 1 2 W ⊗ (Y -X) 2 2 + λ 2 W ⊗ (Y -X) 1 (<label>22</label></formula><formula xml:id="formula_30">)</formula><p>By introducing another variable U = Y -X, the above objective function is replaced by,</p><formula xml:id="formula_31">G(U ) = i, j 1 2 R i, j (I -W ) ⊗ (R i, j U + R i, j X -Dα i, j ) 2 2 + λ 1 2 W ⊗ U 2 2 + λ 2 W ⊗ U 1 (<label>23</label></formula><formula xml:id="formula_32">)</formula><p>calculating the derivative of G(U ) with respect to U , and considering the properties of Hadamard product, we have</p><formula xml:id="formula_33">∂ G(U ) ∂U = ((I -W ) ⊗ (I -W )) ⊗ (M ⊗ U + M ⊗ X -Z ) + λ 1 (W ⊗ W ) ⊗ U + λ 2 ( W ⊗ W ) ⊗ sign(U ) (<label>24</label></formula><formula xml:id="formula_34">)</formula><p>where M = i, j R T i, j R i, j and Z = i, j R T i, j Dα i, j . Here both M and Z have their own physical meanings, e.g., M denotes the overlapping weight matrix, and Z is the estimation via the dictionary without averaging.</p><p>Setting the derivative to zero, (24) can be solved in an element-wise manner. Let u i, j , m i, j , and z i, j be the entry of U , M, and Z , respectively. Considering each (i, j )-th pixel, u i, j can be calculated according to the following three cases.</p><p>Case 1: If the (i, j )-th pixel is a clean one, that is, the weight for this pixel is w i, j = 1, then according to (24) the solution is,</p><formula xml:id="formula_35">u i, j = 0. (<label>25</label></formula><formula xml:id="formula_36">)</formula><p>Case 2: If the (i, j )-th pixel is a heavily corrupted one, which means the corresponding weight is w i, j = 0, according to <ref type="bibr" target="#b23">(24)</ref> we have,</p><formula xml:id="formula_37">u i, j = z i, j m i, j -x i, j . (<label>26</label></formula><formula xml:id="formula_38">)</formula><p>Case 3: If the (i, j )-th pixel is a slightly corrupted one, and the corresponding weight is 0 &lt; w i, j &lt; 1. Then the solution can be obtained by the following equation,</p><formula xml:id="formula_39">∂ G(u i, j ) ∂u i, j = 1 -w i, j 2 m i, j u i, j + m i, j x i, j -z i, j + λ 1 w 2 i, j u i, j + λ 2 w i, j sign(u i, j ) = 0. (<label>27</label></formula><formula xml:id="formula_40">)</formula><p>According to <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b26">(27)</ref> has a closed form formula for the optimal solution for u i, j , which is a shrinkage operation,</p><formula xml:id="formula_41">u i, j = S( f (x i, j , z i, j ), v i, j ) (<label>28</label></formula><formula xml:id="formula_42">)</formula><p>where S is the soft threshold operator, defined as,</p><formula xml:id="formula_43">S(t, λ) = ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ t -λ; t &gt; λ 0; -λ ≤ t ≤ λ t + λ; t &lt; -λ<label>(29)</label></formula><p>and f (x i, j , z i, j ) and v i, j are as follows,</p><formula xml:id="formula_44">f (x i, j , z i, j ) = 1 -w i, j 2 z i, j -m i, j x i, j 1 -w i, j 2 m i, j + λ 1 w 2 i, j (<label>30</label></formula><formula xml:id="formula_45">)</formula><formula xml:id="formula_46">v i, j = λ 2 w i, j 1 -w i, j 2 m i, j + λ 1 w 2 i, j<label>(31)</label></formula><p>Note that Y = U + X, then the estimated value for the (i, j )-th pixel is given by,</p><formula xml:id="formula_47">y i, j = ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ x i, j ; if w i, j = 1 z i, j m i, j ; if w i, j = 0 x i, j + S( f (x i, j , z i, j ), v i, j ); if 0 &lt; w i, j &lt; 1 (<label>32</label></formula><formula xml:id="formula_48">)</formula><p>The proposed model in <ref type="bibr" target="#b10">(11)</ref> will become much simpler when deal with SPN. For SPN corrupted images, there is no entry between 0 and 1 in the weight matrix W because each entry w i, j = 0 or 1, then the proposed model in <ref type="bibr" target="#b10">(11)</ref> is</p><formula xml:id="formula_49">Algorithm 1 The Proposed Algorithm for IN Removal simplified into, Ŷ = arg min Y,α i, j 1 2 R i, j (I -W ) ⊗ R i, j Y -Dα i, j 2 2 + i, j 1 2 R i, j W ⊗ R i, j X -Dα i, j 2 2 + λ 1 2 W ⊗ (Y -X) 2 2 s.t. α i, j 0 ≤ L</formula><p>After some similar manipulations, the reconstructed image can also be calculated pixel by pixel,</p><formula xml:id="formula_50">y i, j = x i, j ; if w i, j = 1 z i, j m i, j ; if w i, j = 0 (<label>33</label></formula><formula xml:id="formula_51">)</formula><p>From ( <ref type="formula" target="#formula_47">32</ref>) and <ref type="bibr" target="#b32">(33)</ref>, one can see that in the (i, j )-th position without IN (w i, j = 1), the pixel value is reasonably unchanged and this is crucial in preserving image details. On the other hand, if the (i, j )-th pixel is heavily corrupted (w i, j = 0), the estimated value is calculated from the information around it. Finally, if the (i, j )-th position is just a slightly corrupted pixel (0 &lt; w i, j &lt; 1), the estimated value is calculated from both the neighborhood suggested value and the noisy pixel itself, shrinking the neighborhood suggested value toward x i, j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Iterative Denoising Algorithm</head><p>For IN removal, we iteratively apply the WCSR-l 2 l 1 model to improve the denoising performance. That is, the output of current iteration is used as the input of next iteration. In each iteration, the weight matrix is updated via (2) for SPN and (3) for RVIN based on the current input image.</p><p>In our iterative denoising method, the initial image for Y in ( <ref type="formula" target="#formula_12">12</ref>) is reconstructed from ( <ref type="formula">4</ref>) and ( <ref type="formula" target="#formula_4">5</ref>), and the initial dictionary is chosen as discrete cosine transform (DCT). The details of the proposed iterative IN removal algorithm is summarized in algorithm 1.</p><p>In algorithm 1, instead of updating the dictionary D each time, we choose to update it every q (e.g., q = 2) iterations to save the computation time. In step 7, the two thresholds τ 1 and τ 2 are decreasing along with the increase of iteration number to detect more potential outliers <ref type="bibr" target="#b11">[12]</ref>, and p is the noise density estimated as p = 1 N i, j 1 -w i, j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SIMULATION RESULTS</head><p>In this section, experiments are conducted and compared with several existing methods to assess the noise reduction capability of the proposed algorithm. Simulations are carried out on various standard test images corrupted by RVIN or SPN. Fig. <ref type="figure" target="#fig_0">2</ref> shows some examples of the original noise-free images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Implementation and Parameter Setting</head><p>Our proposed method can be implemented according to Algorithm 1. There are some parameters should be predetermined: two control parameters λ 1 , λ 2 , thresholds τ 1 , τ 2 , and the maximum iteration number k max .</p><p>By our extensive experiments, the restoration results are not so sensitive to the two control parameters. The parameter pair chosen from λ 1 ∈ [40, 65] and λ 2 ∈ [560, 780] can achieve satisfactory results. Here, we set λ 1 = 60 and λ 2 = 780 in all our experiments. Experimentally, the initial values of τ 1 and τ 2 are set as τ 1 = 3 and τ 2 = 3.8 for all the tested images except for barbara image, which is rich in textures and requires relative larger thresholds. Hence, we set τ 1 = 4 and τ 2 = 5 for barbara images with low noise densities (e.g., 40% and 50%), while τ 1 = 3.5 and τ 2 = 4.5 for the high noise case (e.g., 60%).</p><p>The stopping criterion is very important for an iterative algorithm because iterative filtering should be stopped before it begins to severely destroy image details. We choose to stop the iterative filtering when</p><formula xml:id="formula_52">Y cur -Y pre 2 2 Y pre 2 2 ≤ η, (<label>34</label></formula><formula xml:id="formula_53">)</formula><p>where η = 0.003 for SPN and 0.01 for RVIN; Y cur and Y pre represent the outputs of current and previous iterations, respectively. For the maximum iteration number, we set k max = 6. For sparse coding, the 8 × 8 patches with an overlap of 6 pixels between adjacent patches are extracted from the noisy image. The dictionary size is chosen as D ∈ R 64×256 , which means there are totally 256 atoms in the dictionary. The sparse ratio is set as L = 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Comparison of Image Restoration</head><p>The PSNR (peak signal to noise ratio) and SSIM (structural similarity) <ref type="bibr" target="#b40">[41]</ref> are used to quantitatively evaluate the qualities of restored results. Generally, the higher PSNR and SSIM values indicate better qualities of the restored images.</p><p>For SPN removal, we compare our method with some recently developed methods, namely, UTMF <ref type="bibr" target="#b37">[38]</ref>, IBDND <ref type="bibr" target="#b38">[39]</ref>, and WESNR <ref type="bibr" target="#b28">[29]</ref>. For RVIN reduction, the proposed method is compared with ACWM <ref type="bibr" target="#b4">[5]</ref>, Luo-iterative <ref type="bibr" target="#b5">[6]</ref>, CEF <ref type="bibr" target="#b6">[7]</ref>, ASWM <ref type="bibr" target="#b7">[8]</ref>, ROR-NLM <ref type="bibr" target="#b8">[9]</ref>, l 1 -l 0 method <ref type="bibr" target="#b26">[27]</ref>, ROLD-EPR <ref type="bibr" target="#b11">[12]</ref>, and WESNR <ref type="bibr" target="#b28">[29]</ref>. The codes of ROR-NLM, ROLD-EPR, and WESNR are provided by the authors, while other algorithms are implemented with the optimal parameters and iterations suggested by the original papers.</p><p>Table <ref type="table" target="#tab_2">I</ref> and II list the PSNR and SSIM values from the methods for all the tested images with different noise densities about the SPN and RVIN, respectively. In both tables, the best values are marked in bold for convenient comparisons. From Table <ref type="table" target="#tab_2">I</ref>, it is clear to observe that the proposed method achieves competitive or higher PSNR scores in comparison with the three state-of-the-art SPN removal methods. Though the SSIM values of our method are slightly less than the best ones in three cases (house image with 50% SPN, F16 and bridge images with 80% SPN), our method outperforms other methods in all the rest cases.  From Table <ref type="table" target="#tab_3">II</ref>, it is obvious to see that our proposed method generates the best results almost for all the tested images with different noise densities. Actually, in Table <ref type="table" target="#tab_2">I</ref> and II, the proposed method obtains the highest averaged PSNR and SSIM values for all the tested images with different noise densities. This demonstrates that our method is more robust for images corrupted by IN with different noise levels.</p><p>The enlarged parts of recovered barbara images with 50% and 80% noise densities by all the tested methods are shown in Fig. <ref type="figure" target="#fig_1">3</ref> to give a visual impression. 1 From this figure, we can 1 More restored results can be found in the website http:// www.cis.umac.mo/cybernetics/WCSR-L2L1/DenoisedResults.htm. Matlab code available upon email request (yb27408@umac.mo or lichenghnu@gmail.com)  see that the SR based methods outperform filter based methods in reduction of SPN. The UIMF and IBDND methods not only cannot completely remove the SPN, but also bring in many artifacts. On the contrary, the WESNR produces much better results. However, it still lost lots of image details and destroy the edges, especially when the noise density is high, where the number of clean pixels can be used for sparse coding is limited. The results generated by the proposed method have very good visual qualities. Even though the noise density is 80%, our method still can remove almost all the SPN and preserve most of the image details.</p><p>Fig. <ref type="figure" target="#fig_2">4</ref> and 5 list the enlarged parts of the restored barbara and pepper images corrupted by 40% and 50% RVIN, respectively. From these two figures, we can see that other methods, except for l 1 -l 0 , ROR-NLM, ROLD-EPR, and WESNR, show very bad performance in suppressing RVIN. By comparison, ROR-NLM generates relative better results, nevertheless, it blurs the outputs and brings in some artifacts. Though l 1 -l 0 and WESNR can removal most of noise, the results are somehow over filtered. This is because none of them takes into account the IN characteristics in sparse coding or reconstruction. The results produced by ROLD-EPR method verify that this method indeed has a good capability of preserving image edges. However, there are still some noticeable noise unremoved due to the imperfect filtering technique it used. In contrast, the results generated by our method show very good visual qualities, which illustrates that the proposed method is very effective in reduction of IN. Both the noise Fig. <ref type="figure">6</ref>. The trained dictionaries by different methods: The first column: trained dictionaries for barbara image with 50% SPN (shown in Fig. <ref type="figure" target="#fig_1">3(a)</ref>). The second column: trained dictionaries for barbara image with 40% RVIN (shown in Fig. <ref type="figure" target="#fig_2">4(a)</ref>). (a) the proposed dictionary learning method, (b) the proposed dictionary learning method, (c) K-SVD, (d) K-SVD.</p><p>are removed thoroughly and the image details (e.g., edges and textures) are well preserved. Especially for the images rich in textures (e.g., barbara image in Fig. <ref type="figure" target="#fig_2">4</ref>), the superiority our method is more obvious. Fig. <ref type="figure">6</ref> shows the dictionaries trained by our proposed dictionary learning method and the K-SVD <ref type="bibr" target="#b33">[34]</ref> algorithm for the barbara image corrupted by 50% SPN and 40% RVIN, respectively. From this figure, one can see that, compared with those trained from K-SVD, the two dictionaries learned by the proposed method are less noisy and contains more features of barbara image (e.g., the texture), hence they are more appropriate to reconstruct the original image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Effectiveness of the L 2 -Norm and L 1 -Norm</head><p>In the proposed model, the l 2 -norm is used to make the reconstructed pixels approach to the corresponding clean ones to preserve more image details. The l 1 -norm is designed to regularize the IN corrupted pixels, which improves the robustness of the final model. Both of them are very important in the proposed WCSR-l 2 l 1 model.</p><p>To further verify the effectiveness of the l 1 -norm and l 2 -norm in <ref type="bibr" target="#b10">(11)</ref>. We implement two variants of the final denoising model. Let the "WCSR-l 2 " denote the IN removal method using SR and l 2 -norm, which solves the following minimization problem, The other variant denoted by "WCSR-l 1 " intends to remove IN by minimizing</p><formula xml:id="formula_54">( α, D, Ŷ ) = arg min α,D,Y i, j 1 2 R i, j W ⊗ R i, j X -Dα i, j 2 2 + i, j 1 2 R i, j (I -W ) ⊗ R i, j Y -Dα i, j 2 2 + λ 1 2 W ⊗ (Y -X) 2 2 , s.t. α i, j 0 ≤ L.</formula><formula xml:id="formula_55">( α, D, Ŷ ) = arg min α,D,Y i, j 1 2 R i, j W ⊗ R i, j X -Dα i, j 2 2 + i, j 1 2 R i, j (I -W ) ⊗ R i, j Y -Dα i, j 2 2 + λ 2 W ⊗ (Y -X) 1 , s.t. α i, j 0 ≤ L.</formula><p>The two variants can be implemented by modifying Algorithm 1 slightly. They were then used to recover the images shown in Fig. <ref type="figure" target="#fig_0">2</ref> corrupted by 40% RVIN. The restored results were compared to those of WCSR-l 2 l 1 and the PSNR values were plotted in Fig. <ref type="figure" target="#fig_4">7</ref>.</p><p>From Fig. <ref type="figure" target="#fig_4">7</ref>, one can see that WCSR-l 2 gains higher PSNR scores than WCSR-l 1 , which indicates l 2 -norm plays a more important role compared to l 1 -norm in the final model. This is because that l 2 -norm forces the reconstructed pixels approach to the clean ones, which preserves more details of the original image, while l 1 -norm just makes the model robust to outliers. In contrast, the WCSR-l 2 l 1 obtains the best performance than the WCSR-l 2 and WCSR-l 1 . This means that both the l 2 -norm and l 1 -norm in the final model are necessary and meaningful. Without any of them, the denoising performance of the final model will be weakened.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Running Time</head><p>The main computation cost of our proposed algorithm comes from the sparse coding and dictionary learning subproblems. The reason is that both these two subproblems adopt the OMP algorithm to calculate the coefficients and the OMP is time-consuming. As a result, our method is somehow slower than some other two-phase methods <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b11">[12]</ref>. More specifically, for the 256 × 256 house image, it costs about 48 seconds CPU time for each outer iteration of our proposed method by using our unoptimized Matlab codes on a computer equipped with 3.40 GHz CPU.</p><p>It is worth to note that there are several ways to speed up the proposed algorithm. On the one hand, the fast split or greedy algorithms can be used instead of OMP to solve the l 0 minimization problem more effectively. On the other hand, the proposed method can be parallelized and run on a more powerful GPU machine to further reduce the running time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSION</head><p>In this paper, we propose a weighted couple sparse representation based algorithm to remove IN in images. In summary, a weight matrix is introduced to describe the cleanliness of a pixel and to determine the contribution of each pixel offered in the sparse coding stage. The noisy and reconstructed images are coupled in the SR model where the reconstructed image is used to compensate the lost information in the noisy image and to make the coefficients more appropriate to reconstruct the noise-free image. To further improve the denoising performance, the pixels are classified into three categories, and different types of pixels are assigned with different regularizations. Besides, the dictionary is trained directly on the raw data to capture more features of the original image. Extensive experiments demonstrate that the proposed method achieves better performance in reduction of IN compared with several state-of-the-art denoising algorithms with respect to both the quantitative measurements and the visual effects.</p><p>It is worth to extend the proposed method for color image restoration, considering the correlations among R (red), G (green), and B (blue) channels. Besides, integrating the non-local self similarity priors <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref> into the weighted SR model may preserve more image details and texture information. This can be a good direction of future work to produce much higher quality outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX PROOF OF PROPERTY 1</head><p>Proof: The dictionary atom updating is reformulated as</p><formula xml:id="formula_56">d = arg min d F(d, α)<label>(35)</label></formula><p>This can be achieved by calculating the derivative of F(d) with respect to d, and set it to 0.  where = diag(W (α ⊗ α) T ) is a diagonal matrix. Substituting <ref type="bibr" target="#b37">(38)</ref> into <ref type="bibr" target="#b36">(37)</ref>, one can obtain</p><formula xml:id="formula_57">d = -1 • ( W ⊗ Eα T ) (<label>39</label></formula><formula xml:id="formula_58">)</formula><p>After the atom d has been updated, the coefficient can then be updated by the similar way, calculating the derivative of F(d, α) with respect to α and setting it to 0, as follows,</p><formula xml:id="formula_59">∂ F(d, α) ∂α = d T • W ⊗ (E -dα) = 0 (40)</formula><p>in which W is defined the same in <ref type="bibr" target="#b36">(37)</ref>. ( <ref type="formula">40</ref>) leads to</p><formula xml:id="formula_60">d T ( W ⊗ (dα)) = d T ( W ⊗ E) (<label>41</label></formula><formula xml:id="formula_61">)</formula><p>After some manipulations, the left side in (41) can be rewritten as, </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Test images. From left to right: lena, pepper, barbara, boat, bridge, house, pentagon, and F16.</figDesc><graphic coords="4,115.07,58.13,63.14,63.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Results of different algorithms in restoring the test barbara image corrupted by SPN with 50% and 80% noise densities respectively. Top row: 50% noise, bottom row: 80% noise. (a) Noisy image, (b) UTMF, (c) IBDND, (d) WESNR, (e) proposed; (f) Noisy image, (g) UTMF, (h) IBDND, (i) WESNR, (j) WCSR-l 2 l 1 . Please zoom into pdf file for a detailed view.</figDesc><graphic coords="8,57.71,508.97,97.82,97.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Results of different algorithms in restoring lena image corrupted by 40% RVIN: (a) Noisy image, (b) ACWM, (c) Luo', (d) ASWM, (e) l 1l 0 (f) CEF; (g) ROR-NLM, (h) ROLD-EPR, (i) WESNR, (j) WCSR-l 2 l 1 . Please zoom into pdf file for a detailed view.</figDesc><graphic coords="9,66.95,321.53,94.70,94.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Results of different algorithms in restoring pepper image corrupted by 50% RVIN: (a) Noisy image, (b) ACWM, (c) Luo', (d) ASWM, (e) l 1l 0 (f) CEF; (g) ROR-NLM, (h) ROLD-EPR, (i) WESNR, (j) WCSR-l 2 l 1 . Please zoom into pdf file for a detailed view.</figDesc><graphic coords="9,66.95,429.89,94.70,94.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. PSNR values of recovered images by using WCSR-l 2 , WCSR-l 1 , and WCSR-l 2 l 1 . The x-coordinate denotes the image index shown in Fig. 2: 1: lena, 2: pepper, 3: barbara, 4: boat, 5: bridge, 6: house, 7: pentagon, 8: F16.</figDesc><graphic coords="10,178.43,168.89,96.50,96.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>∂</head><label></label><figDesc>F(d, α) ∂d = (W ⊗ W ) ⊗ (Edα)α T = 0 (36) (36) leads to W ⊗ (dα)α T = W ⊗ Eα T (37)where W = W ⊗ W , and the superscript T denotes the transposition. The left side of (37) can be rewritten as W ⊗ (dα)α T =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>wi1 d 2 i</head><label>2</label><figDesc>, • • • , n i=1 wiN d 2 i = diag W T • (d ⊗ d) is a diagonal matrix. Substituting (42) into (41), then α is updated as,α = d T ( W ⊗ E) • -1(43)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Abstract-Many impulse noise (IN) reduction methods suffer from two obstacles, the improper noise detectors and imperfect filters they used. To address such issue, in this paper, a weighted couple sparse representation model is presented to remove IN.</head><label></label><figDesc>Fellow, IEEE, Licheng Liu, Long Chen, Member, IEEE, Yuan Yan Tang, Fellow, IEEE, and Yicong Zhou, Senior Member, IEEE</figDesc><table><row><cell>Weighted Couple Sparse Representation</cell></row><row><cell>With Classified Regularization for</cell></row><row><cell>Impulse Noise Removal</cell></row><row><cell>Chun Lung Philip Chen,</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I COMPARISON</head><label>I</label><figDesc>OF RESTORATION RESULTS IN PSNR AND SSIM FOR IMAGES CORRUPTED BY SPN</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II COMPARISON</head><label>II</label><figDesc>OF RESTORATION RESULTS IN PSNR AND SSIM FOR IMAGES CORRUPTED BY RVIN</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank the associate editor and anonymous reviewers for their valued comments and constructive criticisms which are very helpful to improve the quality of this paper. They thank Prof. Dong and Prof. Chan for supplying the code of their algorithm in <ref type="bibr" target="#b11">[12]</ref>, Dr. Xiong for providing the MATLAB implementation of the method in <ref type="bibr" target="#b8">[9]</ref>, and Dr. Jiang and Prof. Zhang for sharing their code in <ref type="bibr" target="#b28">[29]</ref>. They also would like to thank Prof. Pun Chi Man for his help of editing this paper.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the Multiyear Research Grants, in part by the Macau Science and Technology Development Fund under Grant 008/2010/A1, and in part by the Macau Science and Technology Development Fund under Grant 017/2012/A1.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Woods</surname></persName>
		</author>
		<title level="m">Digital Image Processing</title>
		<meeting><address><addrLine>Englewood Cliffs, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>rd ed</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Median filters: Some modifications and their properties</title>
		<author>
			<persName><forename type="first">T</forename><surname>Nodes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Gallagher</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust., Speech, Signal Process</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="739" to="746" />
			<date type="published" when="1982-10">Oct. 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The weighted median filter</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R K</forename><surname>Brownrigg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Commun</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="807" to="818" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Center weighted median filters and their applications to image enhancement</title>
		<author>
			<persName><forename type="first">S.-J</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="984" to="993" />
			<date type="published" when="1991-09">Sep. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adaptive impulse detection using centerweighted median filters</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="2001-01">Jan. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A new efficient impulse detection algorithm for the removal of impulse noise</title>
		<author>
			<persName><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEICE Trans. Fund. Electron., Commun. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2579" to="2586" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A contrast enhancementbased filter for removal of random valued impulse noise</title>
		<author>
			<persName><forename type="first">U</forename><surname>Ghanekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pandey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="50" />
			<date type="published" when="2010-01">Jan. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A new adaptive switching median filter</title>
		<author>
			<persName><forename type="first">S</forename><surname>Akkoul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ledee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Leconge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Harba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="587" to="590" />
			<date type="published" when="2010-06">Jun. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A universal denoising framework with a new impulse detector and nonlocal means</title>
		<author>
			<persName><forename type="first">B</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1663" to="1675" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A new weighted mean filter with a two-phase detector for removing impulse noise</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>You</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">315</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2015-09">Sep. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A universal noise removal algorithm with an impulse detector</title>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huegerich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1747" to="1754" />
			<date type="published" when="2005-11">Nov. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A detection statistic for randomvalued impulse noise</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1112" to="1120" />
			<date type="published" when="2007-04">Apr. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">From sparse solutions of systems of equations to sparse modeling of signals and images</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Bruckstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="34" to="81" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Image denoising via sparse and redundant representations over learned dictionaries</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3736" to="3745" />
			<date type="published" when="2006-12">Dec. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sparsity-based image denoising via dictionary learning and structural clustering</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2011-06">Jun. 2011</date>
			<biblScope unit="page" from="457" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Image super-resolution via sparse representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2861" to="2873" />
			<date type="published" when="2010-11">Nov. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Face super-resolution via multilayer locality-constrained iterative neighbor embedding and intermediate dictionary learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4220" to="4231" />
			<date type="published" when="2014-10">Oct. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Noise robust face hallucination via locality-constrained representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1268" to="1281" />
			<date type="published" when="2014-08">Aug. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sparse representation prior and total variation-based image deblurring under impulse noise</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imag. Sci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2258" to="2284" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Group-based sparse representation for image restoration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3336" to="3351" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Robust face recognition via sparse representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="2009-02">Feb. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Robust sparse coding for face recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2011-06">Jun. 2011</date>
			<biblScope unit="page" from="625" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Robust face recognition via adaptive sparse representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2368" to="2378" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An efficient dictionary learning algorithm and its application to 3D medical image denoising</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="417" to="427" />
			<date type="published" when="2012-02">Feb. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Image noise reduction via geometric multiscale ridgelet support vector transform and dictionary learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4161" to="4169" />
			<date type="published" when="2013-11">Nov. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Nonlocal hierarchical dictionary learning using wavelets for image denoising</title>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4689" to="4698" />
			<date type="published" when="2013-12">Dec. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Restoration of images corrupted by mixed Gaussian-impulse noise via 1 -0 minimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1708" to="1720" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A weighted dictionary learning model for denoising images corrupted by mixed noise</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-C</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1108" to="1120" />
			<date type="published" when="2013-03">Mar. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Mixed noise removal by weighted encoding with sparse nonlocal regularization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2651" to="2662" />
			<date type="published" when="2014-06">Jun. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cognition and removal of impulse noise with uncertainty</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3157" to="3167" />
			<date type="published" when="2012-07">Jul. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Adaptive median filters: New algorithms and results</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Haddad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="499" to="502" />
			<date type="published" when="1995-04">Apr. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Impulse noise removal using sparse representation with fuzzy weights</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Syst., Man Cybern. (SMC)</title>
		<meeting>IEEE Int. Conf. Syst., Man Cybern. (SMC)</meeting>
		<imprint>
			<date type="published" when="2014-10">Oct. 2014</date>
			<biblScope unit="page" from="4052" to="4057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A variational approach to remove outliers and impulse noise</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nikolova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Imag. Vis</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="99" to="120" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bruckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4311" to="4322" />
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Weighted low-rank approximations</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="720" to="727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Sparse representation for color image restoration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="69" />
			<date type="published" when="2008-01">Jan. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Convergence of alternating optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bezdek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Hathaway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Parallel Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="351" to="368" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Removal of high density salt and pepper noise through modified decision based unsymmetric trimmed median filter</title>
		<author>
			<persName><forename type="first">S</forename><surname>Esakkirajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Veerakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Subramanyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Premchand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="287" to="290" />
			<date type="published" when="2011-05">May 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Efficient improvements on the BDND filtering algorithm for the removal of highdensity impulse noise</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">F</forename><surname>Jafar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Alna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Darabkh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1223" to="1232" />
			<date type="published" when="2013-03">Mar. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">De-noising by soft-thresholding</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="613" to="627" />
			<date type="published" when="1995-05">May 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Image quality assessment: From error visibility to structural similarity</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004-04">Apr. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2005-06">Jun. 2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">He worked at U.S. for 23 years as a Tenured Professor, as a Department Head, and the Associate Dean in two different universities. He is currently the Dean of the Faculty of Science and Technology, University of Macau, Macau, China, and a Chair Professor of the Department of Computer and Information Science. Dr. Chen&apos;s research areas are systems, cybernetics, and computational intelligence</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2003, the M.S. degree in computer engineering from the University of Alberta, Canada, in 2005, and the Ph.D. degree in electrical engineering from The University of Texas at San Antonio, USA, in 2010. From 2010 to</title>
		<title level="s">IEEE Trans. Circuits Syst. Video Technol.</title>
		<meeting><address><addrLine>Ann Arbor; Wuhan, China; Changsha, China; Macau, China; Beijing, China; China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">Jun. 2014. 2012-2013. 2012. 2011. 2009. 2012. 2014</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="915" to="928" />
		</imprint>
		<respStmt>
			<orgName>Computer and Information Science, Faculty of Science and Technology, University of Macau ; Doctoral Fellow with The University of Texas at San Antonio. He is currently an Assistant Professor with the Department of Computer and Information Science, University of Macau</orgName>
		</respStmt>
	</monogr>
	<note>His current research interests include computational intelligence, Bayesian methods, and other machine learning techniques and their applications. He has been working in publication matters for many IEEE conferences, and was the Publication Co-Chair</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
