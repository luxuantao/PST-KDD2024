<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MPSO: Modified particle swarm optimization and its applications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Dongping</forename><surname>Tian</surname></persName>
							<email>tiandp@ics.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Software</orgName>
								<orgName type="institution">Baoji University of Arts and Sciences</orgName>
								<address>
									<postCode>721007</postCode>
									<settlement>Baoji, Shaanxi</settlement>
									<country>P.R China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhongzhi</forename><surname>Shi</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country>P.R China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MPSO: Modified particle swarm optimization and its applications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">32629E7602A1AD482A10E884CC943558</idno>
					<idno type="DOI">10.1016/j.swevo.2018.01.011</idno>
					<note type="submission">Received Date: 30 August 2017 Revised Date: 28 January 2018 Accepted Date: 28 January 2018</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Swarm and Evolutionary Computation BASE DATA particle swarm optimization</term>
					<term>maximal focus distance</term>
					<term>inertial weight</term>
					<term>premature convergence</term>
					<term>local optima</term>
					<term>Logistic map</term>
					<term>wavelet mutation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Particle swarm optimization (PSO) is a population based meta-heuristic search algorithm that has been widely applied to a variety of problems since its advent. In PSO, the inertial weight not only has a crucial effect on its convergence, but also plays an important role in balancing exploration and exploitation during the evolution. However, PSO is easily trapped into the local optima and premature convergence appears when applied to complex multimodal problems. To address these issues, we present a modified particle swarm optimization with chaos-based initialization and robust update mechanisms. On the one side, the Logistic map is utilized to generate uniformly distributed particles to improve the quality of the initial population. On the other side, the sigmoid-like inertia weight is formulated to make the PSO adaptively adopt the inertia weight between linearly decreasing and nonlinearly decreasing strategies in order to achieve better tradeoff between the exploration and exploitation. During this process, a maximal focus distance is formulated to measure the particle's aggregation degree. At the same time, the wavelet mutation is applied for the particles whose fitness value is less than that of the average so as to enhance the swarm diversity. In addition, an auxiliary velocity-position update mechanism is exclusively applied to the global best particle that can effectively guarantee the convergence of MPSO. Extensive experiments on CEC'13/15 test suites and in the task of standard image segmentation validate the effectiveness and efficiency of the MPSO algorithm proposed in this paper.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Inspired by social behavior observed in nature, such as schools of fish, flocks of birds, swarms of bees, and even human social behavior, particle swarm optimization was first introduced in 1995 for the task of optimization of continuous nonlinear functions <ref type="bibr" target="#b30">[31]</ref>. PSO is similar to other population based evolutionary algorithms (EAs) <ref type="bibr" target="#b77">[78]</ref> in that it is initialized with a population of random solutions (here refers to the positions of each particle), such as genetic algorithm (GA) <ref type="bibr" target="#b28">[29]</ref>, ant colony optimization (ACO) <ref type="bibr" target="#b20">[21]</ref>, firefly algorithm (FA) <ref type="bibr" target="#b78">[79,</ref><ref type="bibr" target="#b81">82,</ref><ref type="bibr" target="#b83">84,</ref><ref type="bibr" target="#b85">86]</ref> and cuckoo search (CS) <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b96">97]</ref>, etc. It is unlike most of other population based evolutionary algorithms, however, in that PSO is motivated by the simulation of social behavior instead of survival of the fittest, and each candidate solution is associated with a velocity rather than the evolutionary</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head><p>operators like selection, crossover and mutation. Compared with other EAs, it's obvious that PSO has the advantages of fewer control parameters, better convergence and easy implementation. Due to these desirable merits, PSO has attracted much attention worldwide in the field of evolutionary computation since its advent. At present, it becomes one of the most preferred choices for optimization problems and has been extensively applied to a wide range of application areas such as neural networks <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b35">36]</ref>, engineering design <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b64">65]</ref>, optimal scheduling <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b75">76]</ref>, and so on. However, similar to other nature-inspired evolutionary algorithms, PSO also suffers from the bane of premature convergence and being trapped into local optima when solving complex multimodal problems <ref type="bibr" target="#b26">[27]</ref>. Based on this recognition, a huge amount of particle swarm optimization variants have been proposed to deal with these issues. As the representative work, HCLPSO was developed in <ref type="bibr" target="#b46">[47]</ref> which adopted the comprehensive learning particle swarm optimizer <ref type="bibr" target="#b39">[40]</ref> to enhance the exploration and utilized the global version of PSO to enhance the exploitation. Subsequently, the ensemble PSO (EPSO) <ref type="bibr" target="#b47">[48]</ref> was proposed to solve real-parameter optimization problems by integrating the merits of a pool of particle swarm optimization strategies. Experiments on CEC'05 bore out that the superiority of the EPSO algorithm. From the literature, it can be clearly observed that most of the current existing PSOs can be roughly divided into four categories: swarm initialization, parameter selection, topology structure and hybrid versions respectively.</p><p>Swarm initialization. Like other swarm based stochastic optimization algorithm, PSO is initialized with a population of random solutions (position of each particle) in the search space, and subsequently begins to enter a loop in order to continue to search for optimal solutions by updating the particle's velocities and positions until some termination conditions are satisfied. The early notable work <ref type="bibr" target="#b73">[74]</ref> used two kinds of chaotic maps to attempt to improve the quality of initial population for PSO with promising results. Subsequent work <ref type="bibr" target="#b25">[26]</ref> came up with a similar chaotic opposition-based population initialization instead of the purely random strategy to improve PSO performance. In <ref type="bibr" target="#b36">[37]</ref>, two kinds of chaotic maps have been applied to initialize the swarm in which Logistic map was for positions while Cubic map was for velocities of the particles. Note that both of the two PSOs, to some extent, can achieve certain success compared to the PSO with usual random initialization in the same conditions. Particularly, the recent work of Tian et al. <ref type="bibr" target="#b74">[75]</ref> introduced chaotic map based initialization and Gaussian mutation as well as a local re-initialization strategies into the standard PSO.</p><p>Extensive experiments on several well-known benchmark functions demonstrated its effectiveness. In the context of swarm initialization for PSO, there has been very little research on this topic. However, it is reported that PSO tends to the characteristics of low stability due to the non-uniformly distributed initial particles <ref type="bibr" target="#b27">[28]</ref>. Moreover, it's obvious that the convergence speed of the particle swarm also depends on the initial population. So how to generate high-quality initial particles is a worthy research direction in the PSO field. This is one of the original intentions of this work, which will be discussed in detail in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head><p>Parameter selection. The proper selection of control parameters, such as inertia weight and acceleration coefficient, can significantly influence the convergence of PSO. Concerning the acceleration coefficient, it has been studied for many years because of its effect on the self and social cognitions for the convergence of particle swarm optimization <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b69">70]</ref>. As a pioneer work on this topic, Clerc et al. <ref type="bibr" target="#b13">[14]</ref> introduced a constriction factor into the standard PSO that was a function of 1 c and 2 c to insure the convergence of particle swarm optimization.</p><p>Subsequent work <ref type="bibr" target="#b59">[60]</ref> put forward a self-organizing hierarchical particle swarm optimizer (HPSO) with time-varying acceleration coefficients (TVAC) to control the local search and convergence to the global optimum solution. Conducted experiments revealed that the performance of HPSO with TVAC was markedly better than that of HPSO with fixed acceleration coefficients ( 1 2 2 c c = = ). In <ref type="bibr" target="#b69">[70]</ref>,</p><p>a modified particle swarm optimization was brought forward by exploiting the exponential time-varying acceleration coefficients. Besides, various acceleration coefficients <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref> have been formulated for PSO to improve its performance in recent years, and more details of them can be gleaned from the corresponding literature. Note that with regard to different inertia weight strategies, they will be comprehensively reviewed in the next section. Topology structure. To enhance the performance of PSO, different types of topology structures have been studied in the literature. In <ref type="bibr" target="#b52">[53]</ref>, a fully informed particle swarm (FIPS) was presented based on an information flow process to update the position of each particle. In FIPS, all members in the neighborhood could fairly offer their search information and the velocity adjustment was not only influenced by the best position in the particle's neighborhood but also by the positions in other neighborhoods. Followed by Liang et al. <ref type="bibr" target="#b42">[43]</ref> constructed the DMSPSO by exploiting a dynamic neighborhood strategy rather that a fixed one to improve PSO, which involved a random selection of small swarms with small neighborhood in the early stage to provide better exploration and then dynamically increase the neighborhood by regrouping the swarms to incorporate social interaction and perform better exploitation in the later stage of the search process. In <ref type="bibr" target="#b50">[51]</ref>, a PSO with expanding neighborhood topology was developed by combining particle swarm optimization with variable neighborhood search to solve the well-known constrained shortest path problem. In recent work <ref type="bibr" target="#b48">[49]</ref>, the fluid neural network was employed to create dynamic neighborhood topologies. As a result, the fluid neural network PSO was introduced with a dynamic neighborhood mechanism. Experiments indicated that this PSO outperformed the standard PSO algorithm and the other PSOs based on partially connected grid topologies. In addition, a hybrid topology scale free Gaussian-dynamic PSO was proposed for real power loss problem involving the fully connected topology and ring topology <ref type="bibr" target="#b79">[80]</ref> simultaneously. Besides, a dynamic tournament topology strategy was also exploited to improve particle swarm optimization (DTT-PSO) in <ref type="bibr" target="#b84">[85]</ref> apart from the other PSO variants <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b43">44]</ref>. In sum, a suitable topology has been shown to be able to effectively improve the performance of PSO. Hybrid versions. It is expected that the performance of PSO can be improved by</p><formula xml:id="formula_0">M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</formula><p>integrating it with other search techniques, such as chaos search <ref type="bibr" target="#b58">[59]</ref>, differential evolution (DE) <ref type="bibr" target="#b63">[64]</ref>, genetic algorithm (GA) <ref type="bibr" target="#b62">[63]</ref>, simulated annealing (SA) <ref type="bibr" target="#b67">[68]</ref>, and neighborhood search <ref type="bibr" target="#b80">[81]</ref>. The work of <ref type="bibr" target="#b18">[19]</ref> combined a quantum-behavior PSO with the simplex algorithm to solve the load flow problem. In literature <ref type="bibr" target="#b37">[38]</ref>, a hybrid PSO with artificial bee colony (ABC) was proposed (PS-ABC). Simulation results on 13 high-dimensional benchmark functions validated that PS-ABC had the ability to accelerate the convergence and avoid the local optima. Besides, notice that integrating PSO with other evolutionary paradigms like selection <ref type="bibr" target="#b0">[1]</ref>, crossover <ref type="bibr" target="#b53">[54]</ref> and mutation <ref type="bibr" target="#b82">[83]</ref> has become a popular research topic in the community of particle swarm optimization in recent years. Since both PSO and evolutionary algorithms (evolution strategy, evolution programming, GA and genetic programming) are based on population, as a result such hybridization can be readily formulated. This is a desirable strategy to achieve better tradeoff between exploration and exploitation as well as to prevent stagnation and premature convergence by harnessing the strengths of each of the components in the corresponding algorithm. Despite the PSO variants mentioned above belonging to different categories, most of them can achieve encouraging performance and motivate us to better explore PSO methods with the help of their excellent experiences and knowledge. From the literature, it is clearly observed that researchers have paid less attention to the topic on swarm initialization even though it has a direct effect on the performance of PSO. Besides, most existing inertia weights behave either linear or non-linear to attempt to keep the balance between exploration and exploitation. Integrating the characteristics of linear and non-linearly inertia weight together seems to be more efficient for PSO to enhance its search ability and keep fast convergence. Finally, although some PSO variants propose to conduct search process in the context of dynamic environment, they usually lack a certain measure strategy to be followed. To this end, a modified PSO with chaos-based initialization and robust update mechanism is proposed in this paper. On the one hand, the Logistic map is utilized to generate uniformly distributed particles to improve the quality of the initial population. On the other hand, the sigmoid-like inertia weight is formulated to make the PSO adaptively adopt the inertia weight between the linear decreasing and nonlinear decreasing strategies based on the maximal focus distance, which is able to effectively prevent the PSO from plunging into local optima and make the particles proceed with searching in other regions of the solution space. At the same time, the wavelet mutation is applied for the particles whose fitness value is less than that of the average so as to enhance the population diversity. In addition, an auxiliary velocity-position update mechanism is introduced exclusively for the global best particle to ensure the convergence of MPSO. Extensive experiments bear out the effectiveness and efficiency of the proposed PSO algorithm.</p><p>The rest of this paper is organized as follows. Section 2 introduces some background and related work, especially various kinds of inertia weight from the aspects of the linear, nonlinear, fuzzy rules, random and other strategies respectively. Section 3 elaborates the MPSO algorithm, including the chaos-based swarm initialization, formulated sigmoid-like inertia weight, maximum focus distance,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head><p>exclusive update strategy and the wavelet mutation respectively. Experiments on CEC'13/15 test suites and in the task of standard image segmentation are reported in Section 4. Finally, we end this paper with some important conclusions and future work in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and related work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Standard PSO</head><p>Particle swarm optimization is a population-based stochastic optimization algorithm. It is known that PSO maintains two populations: a population of particle's current positions (i.e. pbest) and a population of particle's best positions (i.e. gbest) achieved to date. The former is regarded as the candidate solutions in the search space while the latter is used to guide the former's update. In PSO system, each particle is associated with two properties (velocity vector V and position vector X) and it moves in the search space with a velocity that is dynamically adjusted according to the particle's experience and the particles companion's experience simultaneously. Mathematically, the velocity and position of the particles are updated according to the following formula:</p><formula xml:id="formula_1">1 1 2 2 ( 1) ( ) [ ( ) ( )] [ ( ) ( )] id id id id gd id v t v t c r p t x t c r p t x t ω + = × + × × - + × × -<label>(1) ( 1) ( ) ( 1)</label></formula><formula xml:id="formula_2">id id id x t x t v t + = + +<label>(2)</label></formula><p>where 1 c and 2 c are acceleration coefficients reflecting the weight of the stochastic acceleration terms that pull each particle toward pbest and gbest positions respectively. [ , , , , , ]</p><formula xml:id="formula_3">i i i ij iD X x x x x = L L where [ , ] ij min max x x x ∈</formula><p>denotes the position of the jth dimension of the ith particle, and the corresponding velocity is 1 2</p><p>[ , , , , , ]</p><formula xml:id="formula_4">i i i ij iD V v v v v = L L where [ , ] ij min max v v v ∈ is used</formula><p>to reduce the likelihood of the particles leaving the search space. The best previous position (the position giving the best fitness value) of the ith particle is recorded pbest and denoted by while (number of iterations or the stopping criterion is not met) 4.</p><p>Evaluate fitness of the particle swarm 5.</p><p>for n=1 to number of particles 6.</p><p>Find pbest 7.</p><p>Find gbest 8.</p><p>for d=1 to number of dimensions of particle 9.</p><p>Update the velocity of particles by Eq.(1) 10.</p><p>Update the position of particles by Eq.(2) 11.</p><p>next d 12.</p><p>next n 13.</p><p>Update the inertia weight by some corresponding strategy 14. next generation until stopping criterion 15. End Fig. <ref type="figure" target="#fig_1">1</ref> illustrates the graphical representation of the particle evolution in PSO system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Review of different inertia weights</head><p>As is well known, inertia weight plays an important role in controlling the process of exploration (global search) and exploitation (local search) by maintaining a balance in their capabilities. From the perspective of statistical analysis, it is believed that the overall performance of PSO is strongly affected by the inertia weight <ref type="bibr" target="#b57">[58]</ref>. In view of this, several kinds of inertia weight will be comprehensively reviewed in this section, including the linear, nonlinear, fuzzy rules, random, and other strategies based inertia weights. The ultimate goal is to gain the comparative analysis and understanding of the merits and demerits of each inertia weight so as to formulate more effective</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head><p>strategies for PSO algorithm. In addition, it should be noted that for the sake of clarity and consistency, the notations t and max t appeared in this section denote the current iteration and the maximum allowed number of iterations respectively. ( ) t ω is used to represent the inertia weight of the tth iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Linear strategies to adjust inertia weight</head><p>It is known that the tradeoff between global and local search during the evolution is critical to the success of an optimization algorithm. Considering this, the inertia weight was initially set as a constant (such as 0.4) during the search process in the early years of PSO research, but the results illustrated that a constant inertia weight can hardly work due to the failure of balancing exploration and exploitation. In the meanwhile, it was found that a large inertia weight facilitates a global search while a small inertia weight facilitates a local search. As a consequence, a large number of inertia weights have been developed in the area of PSO research. In <ref type="bibr" target="#b21">[22]</ref>, a linear decreasing inertia weight was introduced and shown to be effective in improving the fine-tuning characteristic of PSO. In this method, the value of ω is linearly decreased from an initial value max ω to a final value min ω as the number of iterations increases according to the following equation:</p><formula xml:id="formula_5">( ) ( ) max max min min max t -t t t ω ω ω ω = - +<label>(3)</label></formula><p>As observed from the literature, this strategy based inertia weight has been widely applied in the field of particle swarm optimization researches.</p><p>In subsequent works <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b91">92,</ref><ref type="bibr" target="#b99">100]</ref>, the inertial weight was dynamically adjusted via increasing or decreasing mechanism. In the case of the increasing, initially a small value of inertia weight increased linearly or nonlinearly to be a larger value. On the contrary, a larger value of inertia weight decreased linearly or nonlinearly to be a small one in the decreasing situation. Specifically, Zheng et al. <ref type="bibr" target="#b99">[100]</ref> constructed an increasing inertia weight defined by Eq.( <ref type="formula" target="#formula_6">4</ref>) and confirmed its validity in terms of the convergence speed and solution precision. Experiments showed that PSO with the increasing inertia weight (increasing from 0.4 to 0.9) outperforms that with the decreasing inertia weight in all benchmark functions used in their tests.</p><formula xml:id="formula_6">( ) 0.5 0.4 max t t t ω = × +<label>(4)</label></formula><p>Enlightened by the pros and cons of the increasing and decreasing strategies, an inertia weight that first increased and then decreased has been proposed by reference <ref type="bibr" target="#b16">[17]</ref>, in which the value of inertia weight along the line of linearly increased from 0.4 to 0.9, and then linearly decreased to 0.4 again. </p><formula xml:id="formula_7">× + ≤ ≤   =   -× + &lt; ≤   (5)</formula><p>In addition, a linear function relationship between inertia weight and the average </p><formula xml:id="formula_8">D D t D t D D D D ω ω ω ω ω - - = × + - -<label>(6)</label></formula><p>where ( ) D t denotes the average distance amongst particles and ( )</p><formula xml:id="formula_9">min max D D t D ≤ ≤ , (<label>)</label></formula><formula xml:id="formula_10">min max t ω ω ω ≤ ≤ .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Nonlinear strategies to adjust inertia weight</head><p>Inspired by the basic idea of the decreasing inertia weight, Chen et al. <ref type="bibr" target="#b8">[9]</ref> proposed two natural exponent inertia weights (as shown in Tab. 1). Experiments validated that PSO with these two strategies was able to converge faster than that with the linear ones during the early period of the search process. In the meantime, they came up with another group of three nonlinear decreasing strategies to adjust inertia weight <ref type="bibr" target="#b9">[10]</ref>, including a parabola opening upwards, a parabola opening downwards and an exponential curve respectively. Simulation results showed that for most continuous optimization problems, the performance of the concave function based decreasing inertia weight surpasses that of the linear strategy, and the linear strategy is superior to the convex function based strategy. Subsequently, a sigmoid increasing inertia weight was developed by combining the sigmoid function with the linear increasing inertia weight <ref type="bibr" target="#b49">[50]</ref> to produce a great improvement in quick convergence and aggressive movement narrowing towards the solution space. Feng et al. <ref type="bibr" target="#b24">[25]</ref> made use of a chaotic model (Logistic map) of inertia weight in which a chaotic term was introduced into the linear decreasing inertia weight to improve the performance of PSO. Note that in <ref type="bibr" target="#b92">[93]</ref>, a PSO with an adaptive inertia weight was presented for designing IIR digital filter. In this PSO, the modified Versoria function was employed in the new relation of the adaptive inertia weight factor function instead of the commonly used sigmoid function for avoiding the exponential computation and ensuring the small final misadjustment. In addition, a group of nonlinear strategies with multi-stage linear decreasing inertia weight (MLDW) <ref type="bibr" target="#b87">[88]</ref> have been put forward for the purpose of easily refining the decreasing process of the inertia weight. A recent work by Tanweer et al. <ref type="bibr" target="#b70">[71]</ref> proposed a self regulating particle swarm optimization (SRPSO) that incorporated the self-regulating inertia weight determined by the best particle for better exploration and the self-perception on the global search direction determined by the rest particles for exploitation in the search space. Experiments confirmed that SRPSO has the capability of achieving faster convergence and better solutions in most of the problems. All in all, these nonlinear inertia weights mentioned above were shown to be able to improve the search ability of PSO to some extent, but they still struggled to obtain a good balance between the global convergence and the convergent efficiency. Table <ref type="table">1</ref> summarizes several nonlinear inertia weights mentioned in this subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1 Summary of nonlinear inertia weights mentioned in this subsection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Literatures</head><p>Different inertia weights Related description</p><formula xml:id="formula_11">M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT Ref. [9] ( ) 10 ( ) ( ) max t t min max min t e ω ω ω ω - = + - - 2 [ ( )] 4 ( ) ( ) max t t min max min t e ω ω ω ω - = + - - Ref. [10] 2 max ( ) ( ) ( ) start end start t t t ω ω ω ω = - - + convex function based ω 2 2 ( ) ( ) ( ) ( )( ) start end end start start max max t t t t t ω ω ω ω ω ω = - + - + concave function based ω 3 1 (1 / ) ( ) ( ) max c t t start end end t ω ω ω ω + = exponential function based ω</formula><p>Ref. <ref type="bibr" target="#b24">[25]</ref> ( ) ( )</p><formula xml:id="formula_12">max max min min max t t t z t ω ω ω ω - = - + z : formula of Logistic map</formula><p>Ref. <ref type="bibr" target="#b29">[30]</ref> ( )  </p><formula xml:id="formula_13">t start t u ω ω = × [1.0001,1.005] u∈ Ref. [37] max max ( ) ( ) ( ) ( ) n start end end n t t t t ω ω ω ω   - = - +     n : nonlinear modulation index Ref. [39] 1 ( ) ( ) 0.875 [1 ( ) ] k start end end max t t tan t ω ω ω ω   = - * - +     1 0.6 k = 2 ( ) ( ) 1.56 [1 ( ) ] k start end end max t t arctan t ω ω ω ω   = - * - +     2 0.4 k = Ref. [50] ( ) ( ) 1 max max min min u t n t t e ω ω ω ω -× -× - = + + (log 2) 10 max t u - = Ref. [71] ( ) ( ) i t t ω ω ω = -∆ start end t N ω ω ω - ∆ = η : a constant ( ) ( ) i t t ω ω η ω = + ∆ Ref. [88] 1 1 1 1 2 2 2 ( )( )<label>0 ( ) ( )( )</label></formula><formula xml:id="formula_14">ω ω ω ω ω - -  +  ≤ ≤   = &lt; ≤   - - &lt; ≤  + -   s ω , m ω , e ω ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Fuzzy rules to adjust inertia weight</head><p>As a pioneer work on this topic, Shi et al. <ref type="bibr" target="#b66">[67]</ref> first constructed a two-input and one-output fuzzy logic controller (FLC) to improve the performance of PSO. The basic idea behind this fuzzy PSO (FPSO) algorithm is to adjust the inertia weight by applying adaptive FLC to dynamically optimize the inertia weight. To be specific, the two-input variables include the current best performance evaluation (CBPE) and the current inertia weight, while the only one-output variable is the change of inertia weight ( ω ∆ ). The obtained results indicated that the performance of this FPSO can be satisfactory on many issues, but it is difficult to implement due to various factors.</p><p>In literature <ref type="bibr" target="#b45">[46]</ref>, a two-input and two-output FLC was developed. One of the input variables is the normalized CBPE whereas the other is the current velocity (CV) of particles. In addition, one of the output variables is ρ , the scaling factor to control</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head><p>the domain of the particle's oscillation, another is ck V used to control the change of the velocity threshold according to the following Eq.( <ref type="formula" target="#formula_15">7</ref>):</p><formula xml:id="formula_15">[10(1 )] c ck V e V = - +<label>(7)</label></formula><p>Correspondingly, a new velocity update strategy was formulated as below:</p><formula xml:id="formula_16"># * 1 1 2 2 ( 1) ( ( ) ( )) ( ( ) ( )) ij ij ij j ij V t v c r x t x t c r x t x t ω ∧ + = + - + -<label>(8) , ( 1,1)</label></formula><p>,</p><formula xml:id="formula_17">ij ij c max ij c v if v v v u v if v v ρ ∧  ≥  =  - &lt;  <label>(9)</label></formula><p>where</p><formula xml:id="formula_18">( 1,1) u - is the random number uniformly distributed in the interval [-1,1]. c v</formula><p>is the minimum velocity threshold, a tunable threshold parameter to limit the minimum of the particle's velocity. Through numerical experiment, it validated that the performance of the FPSO does not degrade drastically as the problem dimension increases.</p><p>Subsequent work <ref type="bibr" target="#b88">[89]</ref> presented a two-input ( t and ( ) v t ∆</p><p>) and one-output (ω ) FLC based particle swarm optimization. In our previous studies <ref type="bibr" target="#b71">[72,</ref><ref type="bibr" target="#b72">73]</ref>, two fuzzy PSOs were developed based on the two-input and two-output FLC, in which the increment of global optimum (IGO) in successive generations and deviation (Dev) of particle fitness values as well as the fitness variance (Delt) and mean extremal deviation (Total) are considered as the input parameters of FLC respectively, while the two-output variables in both methods include the inertia weight and the acceleration coefficients. Simulation results revealed that the increase of the problem dimension cannot significantly deteriorate the performance of these fuzzy PSOs. Besides, in the work of <ref type="bibr" target="#b60">[61]</ref>, a balanced fuzzy particle swarm optimization (BF-PSO) was put forward to solve the fundamental optimization problem entitled traveling salesman problem. At the same time, a fuzzy logic based multi-objective PSO was developed to efficiently solve the distributed local area networks topology design problem <ref type="bibr" target="#b32">[33]</ref>. Especially in the more recent work <ref type="bibr" target="#b54">[55]</ref>, to make up for the drawbacks of the trapping into local optima and the premature convergence, a fuzzy adaptive informed particle swarm optimization (FAIPSO) was formulated based on six-input and two-output FLC with ten fuzzy rules. Note that all the FPSO methods mentioned above possess respective advantages and disadvantages, and their common goal is to dynamically adjust the control parameters of PSO during the search process so as to achieve better optimization performance. Table <ref type="table">2</ref> summarizes the fuzzy rules based inertia weights described in this subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2 Summary of fuzzy rules based inertia weights mentioned in this subsection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Literatures</head><p>Input variables Output variables Related description</p><p>Ref. <ref type="bibr" target="#b45">[46]</ref> normalized CBPE</p><formula xml:id="formula_19">ρ , ck V - CV Ref. [67] CBPE ω ∆ - current inertia weight M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</formula><p>Ref. <ref type="bibr" target="#b71">[72]</ref> ( 1) ( )  </p><formula xml:id="formula_20">N i avg i Dev f f N = = - ∑ Ref. [73] 2 1 1 ( ) N i ave i Delt f f N = = - ∑ ω , 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>∑</head><p>Ref. <ref type="bibr" target="#b88">[89]</ref> current iteration ω 1 ( )</p><formula xml:id="formula_21">av id m D v t v m D = ⋅ ∑∑ ( ) ( ) (<label>1</label></formula><formula xml:id="formula_22">)</formula><formula xml:id="formula_23">av av av v t v t v t ∆ = - -</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Random strategies to adjust inertia weight</head><p>Considering the dynamic nature of the most real-world applications, a random inertia weight was proposed for PSO to track the optima in dynamic systems <ref type="bibr" target="#b22">[23]</ref>. To be specific, the inertia weight was set to change randomly according to Eq.( <ref type="formula" target="#formula_24">10</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0.5">( ) 2 rand</head><formula xml:id="formula_24">ω = + ⋅<label>(10)</label></formula><p>where ( ) rand ⋅ denotes a random number uniformly distributed within the range [0,1].</p><p>Alternatively, it is difficult to predict whether in a given time the exploration or exploitation would be better in the dynamic environment. So a random value of the inertia weight is selected to address this problem. Note that when the random inertia weight is employed the acceleration coefficients are generally kept constant at 1.494 that coincides well with literature <ref type="bibr" target="#b13">[14]</ref>. In view of this, the random strategy was widely applied by the other researches <ref type="bibr" target="#b97">[98,</ref><ref type="bibr" target="#b98">99]</ref>. Among these, a strategy developed in literature <ref type="bibr" target="#b97">[98]</ref> could tune the expectations of the inertia weight adaptively when they are selected randomly and thus lead to effective balance between the global and local search abilities. </p><formula xml:id="formula_25">r k r k ω α ω α = + ≥   = + &lt; <label>(11)</label></formula><p>where </p><formula xml:id="formula_26">( ( ) (<label>10</label></formula><formula xml:id="formula_27">)) / ( 10) k f t f t f t = - -</formula><formula xml:id="formula_28">ω µ µ σ = + - × + ×<label>(12)</label></formula><p>here min µ and max µ are the minimum and maximum of the random inertia weight, () rand denotes a random number uniformly distributed in the interval [0,1] while () randn represents the normally distributed numbers. σ is used to measure the deviation degree between the random variable weight and its average value. To sum up, it has been identified experimentally that the random inertia weight has the advantage of rapid convergence in the early stage of evolution, and it is shown to be able to find fairly good solutions for most of the well-known benchmark functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.5">Other strategies to adjust inertia weight</head><p>Different from previous proposals to improve PSO by utilizing an adaptive value of the inertia weight in each iteration, an adaptive inertia weight was expressed as the function of the evolution speed and aggregation degree of the swarm in <ref type="bibr" target="#b94">[95]</ref>. Similarly, almost the same strategy was proposed by <ref type="bibr" target="#b89">[90]</ref> in which inertia weight was given by a function of evolution speed and aggregation degree factors, and the value of inertia weight was dynamically adjusted according to the evolution speed and aggregation degree of particles. At the same time, Feng et al. <ref type="bibr" target="#b23">[24]</ref> put forward an inertia weight depending on the particle's search states including its location and velocity instead of the iteration times. Table <ref type="table" target="#tab_6">3</ref> describes the adaptive inertia weight strategy applied in this PSO algorithm. Note that many other PSO variants belonging to this category can be available in references <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b90">91]</ref>. For more details and a more complete explanation on them, please refer to the corresponding literature. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Modified particle swarm optimization</head><p>In this section, the modified particle swarm optimization is discussed from five aspects of the chaos-based initialization, formulated sigmoid-like inertia weight, maximal focus distance, exclusive update strategy, and position mutation mechanism respectively. More details of them will be elaborated in sequence in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Chaos-based swarm initialization</head><p>As discussed in Section 1, to generate uniformly distributed initial particles in the search space plays a critical role in particle swarm optimization. From the literature, it can be observed that a huge number of chaos-based PSOs have been proposed [2,13, <ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b76">77]</ref>. Among these PSO variants, most of them can be roughly classified into three categories, that is, chaotic sequence based initialization for PSO <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b74">75]</ref>, chaotic sequence based parameters update for PSO <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15]</ref>, and hybrid PSO and chaotic search techniques <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b76">77]</ref>. As the representative work of the first category, Tian et al. <ref type="bibr" target="#b73">[74]</ref> exploited two kinds of chaos (Tent and Logistic map) to attempt to improve the quality of the initial population for standard PSO in 2010. Gao et al. <ref type="bibr" target="#b25">[26]</ref> employed a similar chaotic opposition-based population initialization instead of a pure random initialization for PSO to improve its performance. Conducted experiments verified that these two PSO methods can achieve promising results compared to those with usual random initialization in the same conditions. Besides, it should be noted that both the standard PSO and various improved PSOs, such as HPSO <ref type="bibr" target="#b59">[60]</ref>, AEPSO <ref type="bibr" target="#b13">[14]</ref> and other PSO variants, behave the characteristics of low stability. One of the main reasons, just as proved in literature <ref type="bibr" target="#b27">[28]</ref>, is that the initial population is non-uniformly distributed. He et al. <ref type="bibr" target="#b27">[28]</ref> have just pointed out the reasons of low stability for PSO, but no specific strategies were given to solve this problem. Based on this recognition, our recent work <ref type="bibr" target="#b74">[75]</ref> attempted to deal with the foregoing issue by applying chaotic map based initialization for the standard particle swarm optimization.</p><formula xml:id="formula_29">M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</formula><p>Extensive experiments demonstrated the merits of the PSO method. In sum, the application of chaotic sequence rather than random sequence in PSO is a powerful strategy to diversify the swarm of particles and improve the performance of PSO by preventing the premature convergence. In addition, as for the latter two kinds of chaos-based PSO algorithms, we will not go into much detail here since it is beyond the scope of our focus in this paper.</p><p>To summarize, most of these methods can achieve encouraging performance and motivate us to better explore PSOs with the help of their excellent experiences and knowledge. Without loss of generality, following the core idea of our prior work <ref type="bibr" target="#b74">[75]</ref>, the chaos-based initialization is exploited here to improve the quality of initial particles. As one of the simplest chaos, Logistic map <ref type="bibr" target="#b51">[52]</ref> has been paid much attention by researchers over the last two decades. It can be described as follows:</p><formula xml:id="formula_30">1 ( , )<label>(1 ), 0,1, 2,</label></formula><formula xml:id="formula_31">n n n n x f x x x n µ µ + = = - = L<label>(13)</label></formula><p>where n x represents the nth chaotic variable, (0,1) n x ∈ under the conditions that the initial 0 (0,1)</p><p>x ∈ except for some periodic fixed points (0,0.25,0.5,0.75,1). µ is a predetermined constant, also called bifurcation coefficient. When µ increases from zero, the dynamic system generated by Eq.( <ref type="formula" target="#formula_31">13</ref>) will change from one fixed point to two, and until 2 n . During this process, a large number of multiple periodic components will locate in the narrower and narrower intervals of µ as it increases. This phenomenon is obviously free from constraint. But µ has a limit value 3.569945672</p><formula xml:id="formula_32">t µ =</formula><p>. Note that when µ approaches the t µ , the period will become infinite or even non-periodic. At this time, the whole system evolves into the chaotic state. On the other hand, when µ is greater than 4, the whole system becomes </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 2 Bifurcation diagram of Logistic map</head><p>Note that the key idea of Logistic map based initialization is to generate the same number of chaotic variables corresponding to the optimization problem. More specifically, when a preset number of chaotic iterations are executed, the chaotic variables will be generated accordingly. Afterwards remapping these variables into the optimization space, it will yield the real initial variables for the original optimization problem. Here, Eq.( <ref type="formula" target="#formula_31">13</ref>) is chosen as the chaotic signal generator, in which µ is set to be 4. As previously mentioned, the pseudocode of Logistic map can be described as below, which is able to generate uniformly distributed data sequence and avoid plunging into the small periodic cycles effectively. Randomly initialize chaotic variables 3.</p><p>while (number of maximal iterations is not met) 4.</p><p>if chaotic variable plunges into fixed points or the small periodic cycles 5.</p><p>Implement a very small positive random perturbation 6.</p><p>Map them by Eq.( <ref type="formula" target="#formula_31">13</ref> To further illustrate the distribution performance of chaos-based initialization, Fig. <ref type="figure">3</ref> shows the histogram comparison of the Logistic map and random map for 3000 iterations in the range [0,1] respectively. It should be noted that the histogram of Logistic map is depicted under the condition that its initial value and the number of</p><formula xml:id="formula_33">M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</formula><p>iteration are set to 0.4567 and 3000 respectively. By comparing the histograms illustrated below, it can be clearly observed that in Logistic map, the maximal frequency is 216 while the minimal frequency is 11, corresponding to 42 and 19 in random map. In addition, the overall average frequency of Logistic map is about 30 in the range [0.2,0.8] whereas it approximates 27 between [0.3,0.5] for random map, which fully demonstrates that the Logistic map based initialization can yield more uniformly distributed particles in more wider ranges. On the other hand, it is obvious that the histogram trend of Logistic map is intuitively superior to that of random map. This can be easily validated by the empirical cumulative distribution function (ECDF) in case they are stochastically ordered. In sum, the Logistic map based initialization is able to generate more uniformly distributed particles in the allowable search space to enhance the stability of PSO algorithm. This is one of the main motivations for this study.</p><p>0 </p><formula xml:id="formula_34">ϕ = + -</formula><p>) in the neural network, which is able to get excellent balance between linear and nonlinear behavior as displayed in Fig. <ref type="figure" target="#fig_7">4(a)</ref>. Note that ( ) 0 v ϕ = when 9.903438 av &lt; -. On the contrary, ( ) 1 v ϕ = when 9.903438 av ≥ -. Based on this recognition, a novel sigmoid-like inertia weight is formulated as follows. The key idea behind this strategy is to achieve the smooth transition from linear inertia weight to nonlinear inertia weight. It can be defined as below: <ref type="bibr">(10 2 )</ref> 0.9, ( )</p><formula xml:id="formula_35">1 0.4, 1 max max max t t t t t t otherwise e α ω - ≤   =  +  +  (14)</formula><p>where t denotes the current iteration, max t is the allowable maximal number of iterations, α is a constant predefined.</p><p>It should be noted that in the early stage of evolution 0.9</p><formula xml:id="formula_36">ω = when max t t α ≤</formula><p>while in the end stage ω approximates to 0.4 when t is equal to max t . Except for these two cases, the values of ω calculated by Eq.( <ref type="formula">14</ref>) at any time during the process of evolution will be ranging from 0.4 to 0.9, which coincide well with the conclusions obtained in <ref type="bibr" target="#b21">[22]</ref> because the performance of PSO can be significantly improved at the time of the inertia weight belonging to the interval [0. ω keeps a larger value so as to speed up the search process. Quite the reverse, the inertia weight keeps a smaller value in the later stage in order to prevent the PSO from falling into local optima and make the particles proceed with searching in other regions of the solution space. The curve illustrated between these two cases behaves the smooth transition from the early stage to the end stage. Note that with respect to the superiority of the sigmoid-like inertia weight, it will be discussed in detail in the experiment section. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D</head><note type="other">ACCEPTED MANUSCRIPT</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Maximal focus distance</head><p>As one of the inherent drawbacks of PSO, to suffer entrapment in local optima should be given priority to except for the premature convergence. Considering this, how to appropriately measure the swarm diversity or the aggregation degree of swarm plays a crucial role in balancing the exploration and exploitation for PSO. A recent work by Ruan et al. <ref type="bibr" target="#b61">[62]</ref> exploited population density to estimate the particle's distribution in the search space by introducing the swarm size, the size of the solution space and a saturated population density respectively. In addition, an aggregation degree (AD) of particles <ref type="bibr" target="#b36">[37]</ref> was defined to evaluate the particle's current state of the swarm as denote the best and average fitness of particles in the tth iteration respectively, and in general, the larger the value is, the higher the aggregation degree. Different from the above-mentioned strategies, in this work, the maximal focus distance (MFD) is formulated to reflect the particle's aggregation degree so as to judge whether PSO algorithm gets stuck in the local optima or not:</p><formula xml:id="formula_37">2 1 1 ( ) D ld id i m d p x MFD max D = =   - =       ∑ L (<label>15</label></formula><formula xml:id="formula_38">)</formula><p>where m is the number of neighborhood particles, ld p is the previous best position, and id x denotes the sub-vector of the dth dimension of the ith particle in the search space.</p><p>According to the MFD calculated during the search process, the proposed particle swarm optimization is expected to be able to identify the forthcoming search strategy. That is, either to execute wavelet mutation for the particles whose fitness is less than or equal to the average fitness of the whole swarm, or to reinitialize the same number of particles by the Logistic map based on the average fitness of particles, or to directly update the velocity and position of particles by Eqs.( <ref type="formula" target="#formula_1">1</ref>)-( <ref type="formula" target="#formula_2">2</ref>) and ( <ref type="formula" target="#formula_39">16</ref>)-( <ref type="formula">17</ref>) based on the newly formulated inertia weight respectively. By this way, the modified particle swarm optimization can be guaranteed to obtain the global optima without sacrificing too much of its convergence speed, and this is another key motivation for our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Exclusive update strategy</head><p>In order to ensure the convergence of PSO, Clerc et al. <ref type="bibr" target="#b13">[14]</ref> introduced a constriction factor into the standard particle swarm optimization. Just as discussed in Section 1, this method actually guaranteed the convergence of PSO algorithm via the parameter selection. Similar to our prior work <ref type="bibr" target="#b74">[75]</ref>, another set of velocity-position update strategy is exploited to keep the global best particle moving until it has reached a local minimum under the assumption of minimization <ref type="bibr" target="#b3">[4]</ref>, which is able to guarantee the convergence of the MPSO effectively. The corresponding update strategy is described </p><formula xml:id="formula_39">M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT as below: 2 ( 1) ( ) ( ) ( ) ( )(1 2 ( )) d d gd d d v t x t p t v t t r t ξ ξ ξ ω ρ + = - + + + -<label>(16) 2 ( 1)</label></formula><formula xml:id="formula_40">ρ ρ ρ ρ &gt;   + = &gt;    (18)</formula><p>where the terms #successes and #failures denote the number of consecutive successes and failures respectively. Here, a failure is defined as ( ( )) ( ( <ref type="formula" target="#formula_1">1</ref>))</p><formula xml:id="formula_41">g g f p t f p t =</formula><p>while a success is just the opposite. c s and c f denote the preset thresholds. In common cases, a default initial value (0) 1.0 ρ = has been found empirically to produce acceptable results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Position mutation strategy</head><p>From the literature, it can be clearly observed that some evolutionary operators such as selection <ref type="bibr" target="#b0">[1]</ref>, crossover <ref type="bibr" target="#b53">[54]</ref> and mutation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b86">87]</ref> are widely exploited to sustain the diversity of the particle swarm. In <ref type="bibr" target="#b2">[3]</ref>, an adaptive mutation mechanism was introduced into the conventional particle swarm optimization to enhance the global search ability, in which an extended mutation step size was recommended to facilitate a search phase at new regions when the search population was far away from the optimum point. Alternatively the mutation step size was reduced to initiate local exploration about the isolated search region at the concluding stages of the optimization cycle. In the work of <ref type="bibr" target="#b33">[34]</ref>, a Gaussian based operator was implemented to induce particle search diversity with probability through mutation. More recent works <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b86">87]</ref> exploited Cauchy mutation <ref type="bibr" target="#b86">[87]</ref>, wavelet mutation <ref type="bibr" target="#b44">[45]</ref>, Gaussian mutation <ref type="bibr" target="#b74">[75]</ref> and random strategies <ref type="bibr" target="#b6">[7]</ref> to maintain the swarm diversity respectively. Thus, without loss of generality, the wavelet mutation rather than Cauchy, Gaussian, Levy or other mutation mechanism is employed here to retain the swarm diversity in this paper due to its fine-tuning ability in terms of the performance under the same settings compared to other mutation operators.</p><p>It is known that the mutation operation is usually used to mutate the position of particles. The details of the wavelet mutation can be described as follows. Each particle has a chance to mutate that is controlled by a probability of mutation [0,1] m p ∈ . For the position of each particle, a random number between 0 and 1 will be generated such that if it is less than or equal to m p , the mutation will take place on</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head><p>that position of the particle. Specifically, let </p><formula xml:id="formula_42">( ) ( ( )), 0 ( ) ( ) ( ( ) ), 0 ij jmax ij ij ij ij jmin x t p x t if x t x t x t p if σ σ σ σ + × - &gt;  =  + × - ≤  (19) with 2 2</formula><p>1 e cos 5 ( )</p><formula xml:id="formula_43">a a a ϕ ϕ σ   -      = ×     (<label>20</label></formula><formula xml:id="formula_44">)</formula><p>where a denotes the dilation parameter, it is usually set to vary with the iteration of particles so as to meet the fine-tuning purpose. So far, the pseudocode of MPSO algorithm can be succinctly described as follows.</p><p>Algorithm 3: Pseudocode of the proposed MPSO algorithm 1. Begin 2.</p><p>Randomly initialize the velocity of the particles and employ Logistic map to initialize the position of the particles, let f i denote the fitness of each particle, MFD * denotes the preset threshold of MFD, f avg presents the average fitness of the whole swarm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>while (number of maximal iterations is not met) 4.</p><p>for n=1 to number of particle 5.</p><p>Find pbest 6.</p><p>Find gbest 7.</p><p>Calculate MFD by Eq.( <ref type="formula" target="#formula_37">15</ref>) 8.</p><p>if MFD ≤ MFD * 9.</p><p>Calculate f i and f avg 10.</p><p>if f i ≤ f avg 11.</p><p>Execute wavelet mutation for the position of the particles whose fitness is less than or equal to the average fitness of the whole swarm 12. else 13.</p><p>Reinitialize the same number of particles using the Logistic map 14. end 15. else 16.</p><p>Calculate ω by Eq.( <ref type="formula">14</ref>) 17.</p><p>Update the velocity and position of the global best particle by Eqs.( <ref type="formula" target="#formula_39">16</ref>)-( <ref type="formula">17</ref>) 18.</p><p>Update the velocity and position of the other particles by Eqs.( <ref type="formula" target="#formula_1">1</ref> To better understand the proposed MPSO algorithm described above, we provide a concise yet complete flowchart to illustrate it as shown in Fig. <ref type="figure">5</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiments based on basic numerical functions</head><p>To validate the effectiveness of the MPSO proposed in this paper, we first conduct experiments on four well-known benchmark functions in this section to determine the related optimal parameters. In particular, the performance of PSO with different initialization methods and different inertia weights is compared and investigated respectively. Note that all the test functions are shown in Table <ref type="table" target="#tab_14">4</ref>, including their expressions, dimensions, search space, allowable search range and global optimum values respectively.  To illustrate the effect of the sigmoid-like inertia weight formulated in subsection 3.2, note that PSOs that are randomly initialized but with different inertia weights are compared with each other. For the sake of fair comparison, the parameters are set as follows: the linearly decreasing inertia weight varies from 0.9 implies that the algorithm is quicker to punish a poor ρ setting than it is to reward a successful ρ value to produce acceptable results. In addition, the threshold of MFD is predetermined to be MFD * =2.80e-006 by trial and error. It is shown that the performance of MPSO encounters a sharp decline when MFD * is less than or greater than 2.80e-006. For each test function, 30 independent runs are performed by each PSO variant, and each run is with 1000 iterations. The PSO algorithm terminates when it reaches the maximum allowed number of iterations. Without loss of generality, the best solution, average solution and standard deviation are employed to measure the performance of different PSOs. Table <ref type="table" target="#tab_15">5</ref> presents the optimization results of PSO with different inertia weights. It should be noted that ω 0 -PSO, ω 1 -PSO, ω 2 -PSO, ω 3 -PSO and ω 4 -PSO denote the PSO with linear decreasing inertia weight, convex function decreasing based inertia weight, concave function decreasing based inertia weight, exponential function decreasing based inertia weight and the sigmoid-like inertia weight respectively. As expected, ω 4 -PSO is apparently superior to all the other PSO variants on these four benchmark functions except for the standard deviation of the Griewank, which validates the promising performance of MPSO over the test functions. In other words, this further indicates the importance of the sigmoid-like inertia weight during the search process of particles for the better tradeoff between exploration and exploitation. ω 4 -PSO 0.00e-000 0.00e-000 0.00e-000 Fig. <ref type="figure" target="#fig_11">7</ref> illustrates the convergence curves of PSO with different inertia weights for the four test functions. To show the evolutionary processes clearly, here, the y axes adopt the fitness logarithm values. From the results shown in Fig. <ref type="figure" target="#fig_11">7</ref>, one can see that ω 4 -PSO is an effective method with fast convergence speed at the early stage of evolution in almost all cases. Especially in Fig. <ref type="figure" target="#fig_11">7</ref>(b), it can be clearly observed that, compared with its counterparts, ω 4 -PSO evolves slightly slower for the first 100 iterations, but after that it quickly converges to the global optimum very significantly. Besides, it should be noted that the former part of Fig. <ref type="figure" target="#fig_11">7(b</ref>) is specially scaled up to a certain extent so as to illustrate the variation trends of each curve more clearly. In actual fact, each PSO corresponding to each evolution curve is still run for 1000 iterations. Likewise, it is clear to observe that ω 0 -PSO, ω 2 -PSO and ω 4 -PSO in Fig. <ref type="figure" target="#fig_11">7(d</ref>) can achieve the global best solution without being trapped in the local optima. Although the convergence of ω 4 -PSO in the later period is slightly worse than that of ω 0 -PSO, its optimizing speed markedly outperforms ω 0 -PSO in the first 100 iterations. At the same time, both ω 0 -PSO and ω 4 -PSO are apparently superior to the ω 2 -PSO. Another interesting observation comes from the evolution curve of ω 1 -PSO, note that which evolves very slowly before the first 400 iterations, followed by even occurs deterioration in convergence performance. After that ω 1 -PSO improves consistently before 750 generations with the increase of iterations, subsequently it almost keeps in a smooth state until the end of the search process. Besides, it can be obviously seen that ω 3 -PSO has the worst performance throughout the iteration. To sum up, PSO with the sigmoid-like inertia weight formulated in this paper is able to get the best performance in most cases by adaptively regulating the balance of exploration and exploitation in the solution space. To better understand the effectiveness of the chaos-based initialization and the formulated sigmoid-like inertia weight strategies proposed in this paper, different combinations for PSO with an initial population of random map or Logistic map and a constant inertia weight ( 1 ω = ), a linearly decreasing inertia weight or the formulated sigmoid-like inertia weight are exploited respectively. To increase the readability of different PSO paradigms, acronyms PSORC, PSORL, PSORS, PSOLC, PSOLL and PSOLS are specified by Table <ref type="table" target="#tab_16">6</ref>.  <ref type="table" target="#tab_17">7</ref>, it can be clearly observed that PSOLS outperforms all the others. That is to say, PSO with the Logistic map based initialization and the formulated sigmoid-like inertia weight can get the best optimization performance. To be specific, the performance of PSO with the Logistic map based initialization is far superior to that of the corresponding PSOs with random particles, which means that the distribution of initial particles can be improved by the Logistic map. As can be seen from Table <ref type="table" target="#tab_17">7</ref>, the standard deviations of PSOLS are consistently smaller than that of other PSO variants, which implies that the PSO with an initial population of Logistic map solutions can alleviate its inherent defects of low stability. In other words, this further illustrates the importance of the uniformly distributed initial particles to the convergent performance of PSO and the non-linearly sigmoid-like decreasing inertia weight to the tradeoff of exploration and exploitation. At the same time, note that PSO with the formulated sigmoid-like inertia weight also surpasses the corresponding PSO algorithms with a constant inertia weight and a linearly decreasing inertia weight respectively. Meanwhile, the premature convergence is avoided by adopting the wavelet mutation and the local re-initialization strategies based on the maximal focus distance among particles. By this way, the performance of the standard PSO algorithm can be improved to a large extent. To summarize, the Logistic map based initialization, formulated sigmoid-like inertia weight and the newly update mechanism, to some extent, play a good complementary role each other in the particles evolution and should be used together to obtain better optimization performance. Fig. <ref type="figure" target="#fig_12">8</ref> displays the evolution curves of the MFD in each PSO algorithm for the four test functions. As can be seen from Fig. <ref type="figure" target="#fig_12">8</ref>, at the points where the curves of different PSO variants encounter a sharp decline imply that particles tend to trap into the local optima. Subsequently the wavelet mutation as well as the local re-initialization strategy based on the Logistic map is timely leveraged to help PSO escape from the local optima and make the particles proceed with searching in other regions of the solution space. In particular, the introduced velocity-position update mechanism for the global best particle, which is able to keep the search proceeding and effectively guarantee the convergence of MPSO. By comparison, the curves of PSORC and PSORL decrease slowly as the search proceeds. Moreover, both of them behave to be interweaved with each other except for the Sphere function. On the contrary, the curves of PSOLL and PSOLS descend rapidly than that of PSORS and PSOLC for Sphere, Rastrigin and Schaffer functions respectively. In addition, it is noticeable that the evolution curve of the maximal focus distance by PSOLC for Griewank function declines quickly than that of the other PSO algorithms. Particularly, the turning point appears when the iteration approximates 200. On the whole, all the curves of the MFD corresponding to different PSO variants on the test functions remain in a downward trend, which further demonstrates the fact that PSO tends to trap into the local optima especially in the later stage of evolution. In the meanwhile, it also shows the necessity of adopting some effective strategies to help the PSO algorithm escape from the local optima. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiments based on CEC'13 test suite</head><p>As observed from the experimental results shown above, our method is remarkably superior to the others in most cases, which verifies the effectiveness and efficiency of it in the task of the basic function optimization. To investigate its performance in relatively complex multimodal problems, a series of experiments are conducted on CEC'13 test suite <ref type="bibr" target="#b40">[41]</ref> in this subsection, which consists of 28 functions, including 5 unimodal functions, 15 multimodal functions and 8 composition functions respectively. Note that nearly half of CEC'13 functions are used to test and analyze here, viz., 4 unimodal functions, 4 multimodal functions and 4 composition functions, resulting in 12 benchmark functions described in Table <ref type="table" target="#tab_18">8</ref>. To make a fair comparison with several state-of-the-art PSO variants, including GPSO <ref type="bibr" target="#b65">[66]</ref>, OLPSO-L <ref type="bibr" target="#b93">[94]</ref>, DMPPSO <ref type="bibr" target="#b34">[35]</ref>, SRPSO <ref type="bibr" target="#b70">[71]</ref> and IDE-PSO <ref type="bibr" target="#b26">[27]</ref>, the fitness mean (Mean) and standard deviation (Std) of the fitness errors are utilized to estimate their performance. It should be noted that the fitness error denotes the fitness deviation between the solution yielded by MPSO and the ideal solution. Likewise, each PSO is run 30 times on every test function with 1000 iterations for each run, and the stopping criterion is set as reaching the total number of iterations. Besides, it's worth noting that all the experimental parameters are the same as those in subsection 4.1 except for the function dimension with 10 and 30, and the failure threshold 3 c f = .  From Tables <ref type="table" target="#tab_19">9</ref> and<ref type="table" target="#tab_20">10</ref>, we can find that MPSO is superior or highly competitive to several state-of-the-art PSO variants. Specifically, there exist the following aspects can be easily observed. First, the smaller Mean value can be obtained by MPSO for most functions with D=10 except for f 1 tested by GPSO, OLPSO-L, DMPPSO-L and SRPSO as well as f 4 tested by OLPSO-L and SRPSO respectively. In particular,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head><p>compared with the most competitive particle swarm optimization variants SRPSO and IDE-PSO, the Mean value of our method is consistently smaller than that of IDE-PSO despite with the marginal difference for f 10 and obviously outperforms that of SRPSO except for f 1 and f 4 . Besides, it should be noted that the Std value is markedly superior to that of IDE-PSO, especially for the f 6 and f 9 with one order of magnitude lower, which implies that the PSO with an initial population of Logistic map based solutions can alleviate its inherent shortcomings of low stability. Second, with regard to the experimental results comparison under D=30, MPSO is also able to achieve good performance with smaller Mean value such as for f 2 , f 3 , f 5 , f 7 , f 8 and f 10 out of the twelve test functions. As for other PSO variants with higher Mean value, however, all of them have obtained the better Std, such as for f 1 , f 4 , f 9 and f 11 with one or more orders of magnitude lower than the competitive IDE-PSO and other PSO variants respectively. This further demonstrates the effect of the chaos-based particle swarm initialization. Third, without exception, it is noticeable that the performance of each PSO mentioned above declines as the function's dimension scale increasing from 10 to 30. At the same time, there is no doubt that the computational time increases accordingly. In addition, it is worth noting that like other studies, it seems that the difference of the experimental results among some PSO variants is relatively small, but as far as the intelligent computation itself is concerned, even though a little improvement from the experiments on the surface, they are still of great significance in the field of population based meta-heuristic search algorithm, at least on the experimental results reported in this subsection. To this end, we have validated it from the perspective of statistical analysis by trial and error, and the results indicated that MPSO outperforms the other PSO variants such as SRPSO and IDE-PSO with a 95% confidence level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiments based on CEC'15 test suite</head><p>To further investigate the effect of MPSO, extensive experiments are also conducted on the latest CEC'15 test suite <ref type="bibr" target="#b41">[42]</ref>, which consists of 15 learning-based benchmark functions that have several shift vectors and rotation matrices. As a result, it's very difficult to get the optimal solutions with lower minor errors. In Table <ref type="table" target="#tab_21">11</ref>, 2 unimodal functions, 3 multimodal functions, 3 hybrid functions and 4 composition functions are selected to be tested in this subsection. Note that all of the problems can be treated as the black-box issues. To ensure a fair comparison with the counterparts such as GPSO <ref type="bibr" target="#b65">[66]</ref>, LPSO <ref type="bibr" target="#b31">[32]</ref>, SPSO <ref type="bibr" target="#b5">[6]</ref>, CLPSO <ref type="bibr" target="#b39">[40]</ref>, FIPS <ref type="bibr" target="#b52">[53]</ref> and DMSPSO <ref type="bibr" target="#b42">[43]</ref>, the swarm size is set to 40, the maximum number of iterations of MPSO is the same as that used in literature <ref type="bibr" target="#b95">[96]</ref>, that is, 2500 and 7500 for 10-and 30-dimensional problems respectively. Without loss of generality, the performance is also estimated in terms of the fitness mean (Mean) and standard deviation (Std) of the fitness errors.  The comparison of Means and Stds between MPSO and the other PSO variants is illustrated in Tables <ref type="table" target="#tab_22">12</ref><ref type="table" target="#tab_23">13</ref>. Note that the results of the other six PSO methods to be compared here are directly referenced from literature <ref type="bibr" target="#b95">[96]</ref>, and the lowest mean and standard deviation values in each line are highlighted in boldface. From the results, one can see that MPSO is able to obtain better Mean values for most of the test functions with 10 dimensions except for f 2 , f 7 , f 8 , f 10 and f 11 . As for Std, the proposed method still performs significantly better than the others for almost all cases with the exception of DMSPSO on f 8 , CLPSO on f 10 and f 11 as well as SPSO and CLPSO on f 12 respectively, which indicates that MPSO has better solution stability owing to the Logistic map based swarm initialization that yields uniformly distributed initial particles together with the wavelet mutation that enriches the swarm diversity. Similarly, compared with other PSO variants on the selected CEC'15 functions under D=30, even though the Std performance of MPSO is worse or slightly worse than that of DMSPSO on f 7 , CLPSO and SPSO on f 7 and f 12 , MPSO is still advantageous in its robustness and stability, which is largely ascribed to the initialization strategy and the update mechanism adopted in the PSO algorithm. In sum, compared with other PSO variants mentioned in this subsection, the proposed MPSO is quite competitive in terms of the stability, robustness and scalability. In addition, to thoroughly and fairly discern the experimental results of different PSOs mentioned in this subsection, the nonparametric Wilcoxon rank sum test is conducted with significance level=0.05 between MPSO and its competitors to judge the significance of performance. Table <ref type="table" target="#tab_14">14</ref> summarizes the experimental results under D=10 and D=30 respectively. Note that the number of benchmark functions (out of the 12 tests) that MPSO is significantly better than (Better), almost the same as (Same) and significantly worse than (Worse) its peer algorithm, and the total score (Merit) is calculated by subtracting Worse from Better. From Table <ref type="table" target="#tab_14">14</ref>, it can be seen that the number of functions that MPSO outperforms its peers is much larger than the number of functions in which it significantly performs worse than the compared PSO methods. In particular, the Merit values shown here apparently demonstrate the significance of MPSO over other selected particle swarm optimization algorithms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 r and 2 r</head><label>2</label><figDesc>denote two random numbers uniformly distributed in the range (0,1). It has characteristics that are reminiscent of the temperature parameter in the simulated annealing (SA). ω is the inertia weight used for balancing the global and local search. In general, a large inertia weight facilitates the global exploration while a small inertia weight tends to facilitate the local exploitation. The position of the ith particle can be represented by a D-dimensional vector 1 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 Graphical representation of the particle evolution</figDesc><graphic coords="7,131.28,374.28,333.00,195.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>was established through analyzing the dynamic relationship between the inertia weight and the population diversity<ref type="bibr" target="#b91">[92]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>.</head><label></label><figDesc>denotes the change rate of the optimal adaptive value, r is a random number uniformly distributed in the range [0,1Note that the expectation value of ω varies adaptively with the change rate of the optimal adaptive value. As a result the balance between the global search and local search can be flexibly adjusted.In recent work<ref type="bibr" target="#b98">[99]</ref>, a simplified PSO was developed based on the stochastic inertia weight. It is clearly seen that this variant removes the velocity parameter and obtains the inertia weight by means of the random distribution to enhance the global and local M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT search abilities of PSO algorithm. Meanwhile, the learning coefficients are based on the asynchronous change strategy to improve the search ability of particles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>unstable. Hence the range [ , 4] t µ is generally considered as the chaotic region of the whole system. Its bifurcation diagram is illustrated in Fig.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Algorithm 2 :</head><label>2</label><figDesc>Pseudocode of Logistic map for initialization 1. Begin 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 Curves of sigmoid function and different inertia weights</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 5 Flowchart of the MPSO algorithm 4</head><label>54</label><figDesc>Fig. 5 Flowchart of the MPSO algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 6 Fig. 6</head><label>66</label><figDesc>Fig. 6 depicts the graphical shows of the test functions with 2-dimensional decision variables respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>and the swarm size is 40.Besides, the dimension of the test functions is set to 10 except for Schaffer with 2. The success and failure thresholds are 15</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 7</head><label>7</label><figDesc>Fig. 7 The convergence curves of PSO with different inertia weights</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 8</head><label>8</label><figDesc>Fig. 8 The evolution curves of MFD with different experimental settings</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 1: Pseudocode of the standard PSO algorithm</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>ACCEPTED MANUSCRIPT</cell></row><row><cell cols="2">1. Begin</cell></row><row><cell>2.</cell><cell>Randomly initialize particle swarm</cell></row><row><cell>3.</cell><cell></cell></row><row><cell></cell><cell>M A N U S C R I P T</cell></row><row><cell cols="2">1 ( , , , , , ) 2 i i ij iD p p p p L L whole swarm achieved so far is recorded gbest and indicated as i P = , while the global best position of the 1 2 ( , , , , , ) g g g gj gD P p p p p = L L . The pseudocode of the standard PSO algorithm can be A C C E P T E D</cell></row><row><cell cols="2">succinctly described as follows:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 Adaptive inertia weight constructed in literature [24]</head><label>3</label><figDesc></figDesc><table><row><cell>The value of i ω</cell><cell></cell><cell>--</cell><cell cols="2">The value of | | / | | i i F V small middle large</cell></row><row><cell>The directions of i V r</cell><cell>and i r F</cell><cell cols="2">same opposite large small</cell><cell>middle middle small large</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Histograms of 3000 observations for Logistic and random maps</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="5">ACCEPTED MANUSCRIPT</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="5">(b) Random map (max.42-min.19)</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Fig. 3 3.2 Formulated sigmoid-like inertia weight</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="10">As is known, the most common method for constructing neural activation functions is</cell></row><row><cell cols="2">the sigmoid ( ( ) 1/ (1 v</cell><cell>( exp av</cell><cell>))</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">M A N U S C R I P T</cell></row><row><cell cols="7">.1 A C C E P T E D 0.2 0.3 0.4 0.5 (a) Logistic map (max.216-min.11) 0.6 0.7</cell><cell>0.8</cell><cell>0.9</cell><cell>1</cell></row><row><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell><cell>0.6</cell><cell>0.7</cell><cell>0.8</cell><cell>0.9</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>denotes the position of the jth dimension of the ith particle in the tth iteration, and it should not exceeds the allowable search range for this dimension, viz.</figDesc><table><row><cell></cell><cell cols="8">1 ( ) [ ( ), ( ), , ( ), , ( )] 2 i i ij iD x t i x t x t x t x t = L L</cell></row><row><cell>be the current selected particle, where</cell><cell>( )</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>( ) [ x t ij ∈</cell><cell>p</cell><cell>jmin</cell><cell>,</cell><cell>p</cell><cell>jmax</cell><cell>]</cell><cell>. Hence the</cell></row><row><cell>resulting particle can be expressed as:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>ij x t</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 4 Basic benchmark functions employed in this subsection</head><label>4</label><figDesc></figDesc><table><row><cell>Function</cell><cell cols="3">Expression</cell><cell cols="2">Search space X max V max Global optimum</cell></row><row><cell>Sphere</cell><cell>1 = d ∑ i</cell><cell>i x</cell><cell>2</cell><cell>[-100,100] n 100 100</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 5 Optimization results comparison of PSO with different inertia weights</head><label>5</label><figDesc></figDesc><table><row><cell>Functions</cell><cell>PSO algorithm</cell><cell>Best solution</cell><cell>Average solution</cell><cell>Standard deviation</cell></row><row><cell></cell><cell>ω 0 -PSO</cell><cell>1.39e-187</cell><cell>1.45e-179</cell><cell>0.00e-000</cell></row><row><cell></cell><cell>ω 1 -PSO</cell><cell>1.13e-058</cell><cell>7.62e-017</cell><cell>2.21e-016</cell></row><row><cell>Sphere</cell><cell>ω 2 -PSO</cell><cell>1.40e-058</cell><cell>2.06e-036</cell><cell>5.44e-036</cell></row><row><cell></cell><cell>ω 3 -PSO</cell><cell>3.65e-244</cell><cell>4.01e-221</cell><cell>0.00e-000</cell></row><row><cell></cell><cell>ω 4 -PSO</cell><cell>1.65e-266</cell><cell>4.13e-261</cell><cell>0.00e-000</cell></row><row><cell></cell><cell>ω 0 -PSO</cell><cell>0.00e-000</cell><cell>0.00e-000</cell><cell>0.00e-000</cell></row><row><cell></cell><cell>ω 1 -PSO</cell><cell>0.00e-000</cell><cell>6.36e-231</cell><cell>8.31e-230</cell></row><row><cell>Rastrigin</cell><cell>ω 2 -PSO</cell><cell>0.00e-000</cell><cell>1.63e-271</cell><cell>8.31e-168</cell></row><row><cell></cell><cell>ω 3 -PSO</cell><cell>0.00e-000</cell><cell>0.00e-000</cell><cell>0.00e-000</cell></row><row><cell></cell><cell>ω 4 -PSO</cell><cell>0.00e-000</cell><cell>0.00e-000</cell><cell>0.00e-000</cell></row><row><cell>Griewank</cell><cell>ω 0 -PSO ω 1 -PSO</cell><cell>1.61e-001 1.77e-001</cell><cell>5.28e-001 1.02e-000</cell><cell>5.32e-001 5.46e-001</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 6 Each acronym and its corresponding PSO variant</head><label>6</label><figDesc></figDesc><table><row><cell>Initialization method</cell><cell>Inertia weight</cell><cell>Acronym</cell></row><row><cell></cell><cell>constant inertia weight</cell><cell>PSORC</cell></row><row><cell>Random map</cell><cell>linearly decreasing inertia weight</cell><cell>PSORL</cell></row><row><cell></cell><cell>sigmoid-like inertia weight</cell><cell>PSORS</cell></row><row><cell></cell><cell>constant inertia weight</cell><cell>PSOLC</cell></row><row><cell>Logistic map</cell><cell>linearly decreasing inertia weight</cell><cell>PSOLL</cell></row><row><cell></cell><cell>sigmoid-like inertia weight</cell><cell></cell></row></table><note><p><p>PSOLS</p>From Table</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 7 Optimization results comparison among different PSO variants</head><label>7</label><figDesc></figDesc><table><row><cell>Function</cell><cell>Methods</cell><cell>Best solution</cell><cell>Average solution</cell><cell>Standard deviation</cell></row><row><cell>Sphere</cell><cell>PSORC</cell><cell>1.30e-006</cell><cell>1.57e-004</cell><cell>1.42e-004</cell></row><row><cell></cell><cell>PSORL</cell><cell>2.13e-181</cell><cell>2.94e-171</cell><cell>0.00e-000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 8 CEC'13 functions employed in this subsection</head><label>8</label><figDesc></figDesc><table><row><cell>Type</cell><cell>No.</cell><cell>Function name</cell><cell>Search range</cell></row><row><cell></cell><cell>1</cell><cell>rotated high conditioned elliptic function</cell><cell></cell></row><row><cell>Unimodal</cell><cell>2</cell><cell>rotated bent cigar function</cell><cell></cell></row><row><cell>functions</cell><cell>3</cell><cell>rotated discus function</cell><cell></cell></row><row><cell></cell><cell>4</cell><cell>different powers function</cell><cell></cell></row><row><cell></cell><cell>5</cell><cell>rotated rosenbrock's function</cell><cell></cell></row><row><cell>Multimodal functions</cell><cell>6 7</cell><cell>rotated weierstrass function rotated schwefel's function</cell><cell>[-100,100]</cell></row><row><cell></cell><cell>8</cell><cell>rotated katsuura function</cell><cell></cell></row><row><cell></cell><cell>9</cell><cell>composition function 1 (n=5, rotated)</cell><cell></cell></row><row><cell>Composition</cell><cell>10</cell><cell>composition function 6 (n=5, rotated)</cell><cell></cell></row><row><cell>functions</cell><cell>11</cell><cell>composition function 7 (n=5, rotated)</cell><cell></cell></row><row><cell></cell><cell>12</cell><cell>composition function 8 (n=5, rotated)</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 9 Comparison of Means and Stds of MPSO and the other six PSO variants under D=10</head><label>9</label><figDesc></figDesc><table><row><cell cols="2">Func. Item</cell><cell>GPSO</cell><cell cols="3">OLPSO-L DMPPSO-G DMPPSO-L</cell><cell>SRPSO</cell><cell>IDE-PSO</cell><cell>MPSO</cell></row><row><cell>f</cell><cell cols="2">Mean 7.30e+05 Std 1.17e+06</cell><cell>1.52e+04 8.62e+03</cell><cell>2.77e+06 3.33e+06</cell><cell>5.82e+05 6.33e+05</cell><cell>1.54e+05 3.64e+06 1.82e+06 1.72e+05 3.17e+06 2.68e+05</cell></row><row><cell>f</cell><cell cols="2">Mean 3.39e+08 Std 7.44e+08</cell><cell>9.12e+07 2.46e+08</cell><cell>5.54e+08 1.10e+09</cell><cell>8.85e+07 2.84e+08</cell><cell>4.65e+07 2.68e+07 2.12e+07 1.33e+08 3.31e+07 2.39e+07</cell></row><row><cell>f</cell><cell cols="2">Mean 2.63e+03</cell><cell>1.52e+04</cell><cell>1.46e+04</cell><cell>5.20e+03</cell><cell>3.61e+02 1.34e+02 1.32e+02</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 10 Comparison of Means and Stds of MPSO and the other six PSO variants under D=30</head><label>10</label><figDesc></figDesc><table><row><cell cols="2">Func. Item</cell><cell>GPSO</cell><cell cols="3">OLPSO-L DMPPSO-G DMPPSO-L</cell><cell>SRPSO</cell><cell>IDE-PSO</cell><cell>MPSO</cell></row><row><cell>f</cell><cell cols="3">Mean 5.94e+07 6.37e+05 Std 3.34e+07 1.97e+05</cell><cell>2.22e+07 1.99e+07</cell><cell>7.03e+07 3.10e+08</cell><cell>1.75e+09 5.16e+07 6.28e+07 7.09e+08 3.47e+07 7.06e+06</cell></row><row><cell>f</cell><cell cols="3">Mean 3.71e+15 3.06e+09 Std 1.82e+16 3.63e+09</cell><cell>1.50e+10 7.73e+09</cell><cell>1.80e+15 8.76e+15</cell><cell>7.73e+19 5.46e+07 4.31e+07 2.50e+20 7.14e+07 8.01e+06</cell></row><row><cell>f</cell><cell cols="3">Mean 4.21e+04 9.93e+04 Std 1.01e+04 1.72e+04</cell><cell>6.36e+04 1.38e+04</cell><cell>1.48e+04 3.54e+04</cell><cell>4.61e+05 8.20e+03 6.85e+03 3.12e+05 6.09e+03 5.26e+03</cell></row><row><cell>f</cell><cell cols="3">Mean 8.79e+02 0.00e+00 Std 2.83e+02 0.00e+00</cell><cell>3.17e+01 6.70e+01</cell><cell>1.28e+03 4.28e+03</cell><cell>3.71e+04 2.44e+01 3.76e+01 1.18e+04 9.23e+01 6.81e+00</cell></row><row><cell>f</cell><cell cols="3">Mean 5.29e+02 7.75e+01 Std 2.57e+02 2.19e+01</cell><cell>8.49e+01 4.33e+01</cell><cell>6.80e+01 3.49e+01</cell><cell>1.75e+04 2.45e+01 2.29e+01 6.13e+03 2.31e+01 2.18e+01</cell></row><row><cell>f</cell><cell cols="3">Mean 4.13e+01 3.83e+01 Std 3.35e+00 2.29e+00</cell><cell>4.15e+01 2.20e+00</cell><cell>3.97e+01 6.01e+00</cell><cell>4.38e+01 3.11e+01 3.64e+01 1.22e+00 3.56e+00 1.75e+00</cell></row><row><cell>f</cell><cell cols="3">Mean 5.44e+03 7.16e+03 Std 8.38e+02 5.67e+02</cell><cell>7.59e+03 1.35e+03</cell><cell>4.81e+03 1.74e+03</cell><cell>9.42e+03 4.59e+03 4.38e+03 5.17e+02 1.03e+02 8.16e+01</cell></row><row><cell>f</cell><cell cols="3">Mean 2.33e+00 2.23e+00 Std 5.77e-01 3.74e-01</cell><cell>3.14e+00 5.01e-01</cell><cell>2.76e+00 3.91e-01</cell><cell>0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00</cell></row><row><cell>f</cell><cell cols="3">Mean 1.34e+03 1.30e+03 Std 5.29e+02 4.63e+02</cell><cell>3.39e+02 8.74e+01</cell><cell>3.08e+02 9.87e+01</cell><cell>5.33e+03 2.87e+02 3.17e+02 7.52e+02 1.49e+02 9.32e+01</cell></row><row><cell>f 10</cell><cell cols="3">Mean 3.72e+02 2.34e+02 Std 8.81e+01 7.18e+01</cell><cell>2.82e+02 1.06e+02</cell><cell>2.83e+02 1.03e+02</cell><cell>4.13e+02 2.03e+02 1.98e+02 2.36e+01 3.56e+00 2.81e+00</cell></row><row><cell>f 11</cell><cell cols="3">Mean 1.61e+03 1.25e+03 Std 1.82e+02 7.90e+01</cell><cell>1.44e+03 3.81e+01</cell><cell>1.45e+03 4.63e+01</cell><cell>1.47e+03 1.21e+03 1.72e+03 4.42e+01 1.03e+02 3.06e+01</cell></row><row><cell>f 12</cell><cell cols="3">Mean 4.80e+03 3.56e+03 Std 9.73e+02 5.47e+02</cell><cell>2.86e+03 9.95e+02</cell><cell>8.23e+02 1.62e+03</cell><cell>8.87e+03 3.15e+02 5.39e+02 1.42e+03 6.46e+01 3.66e+01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 11 CEC'15 functions employed in this subsection</head><label>11</label><figDesc></figDesc><table><row><cell>Type</cell><cell>No.</cell><cell>Function name</cell><cell>Search range</cell></row><row><cell>Unimodal functions</cell><cell>1 2</cell><cell>rotated high conditioned elliptic function rotated cigar function</cell><cell>[-100,100]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 12 Comparison of Means and Stds of MPSO and the other six PSO variants under D=10</head><label>12</label><figDesc></figDesc><table><row><cell cols="2">Func. Item</cell><cell>GPSO</cell><cell>LPSO</cell><cell>SPSO</cell><cell>CLPSO</cell><cell>FIPS</cell><cell>DMSPSO</cell><cell>MPSO</cell></row><row><cell>f</cell><cell cols="2">Mean 5.05e+06 Std 2.31e+07</cell><cell>1.17e+05 7.30e+04</cell><cell>2.78e+04 1.01e+04</cell><cell>5.53e+05 7.42e+04</cell><cell cols="3">2.51e+05 9.64e+04 2.63e+04 3.50e+04 2.46e+05 6.61e+03</cell></row><row><cell>f</cell><cell cols="2">Mean 6.02e+08 Std 1.05e+09</cell><cell>2.94e+07 7.79e+07</cell><cell>6.15e+03 2.83e+04</cell><cell>4.73e+04 8.12e+04</cell><cell cols="3">6.49e+03 1.38e+04 6.36e+03 3.86e+02 5.47e+03 2.12e+02</cell></row><row><cell>f</cell><cell cols="2">Mean 2.03e+01 Std 1.12e-01</cell><cell>2.02e+01 4.07e-02</cell><cell>2.02e+01 2.99e-02</cell><cell>2.02e+01 2.41e+00</cell><cell cols="3">2.03e+01 2.01e+01 1.87e+01 1.51e-01 1.64e-01 1.18e-02</cell></row><row><cell>f</cell><cell cols="2">Mean 1.48e+01 Std 1.12e+01</cell><cell>1.35e+01 9.61e+00</cell><cell>4.87e+00 4.98e+00</cell><cell>1.02e+01 3.73e-01</cell><cell cols="3">6.75e+00 9.19e+00 3.23e+00 1.72e+00 6.16e+00 1.76e-02</cell></row><row><cell>f</cell><cell cols="2">Mean 5.76e+02 Std 9.36e+01</cell><cell>2.91e+02 8.95e+02</cell><cell>4.14e+02 6.49e+02</cell><cell>6.11e+02 1.46e+02</cell><cell cols="3">5.14e+02 3.34e+02 1.89e+02 4.58e+02 1.76e+02 8.85e+01</cell></row><row><cell>f</cell><cell cols="2">Mean 4.69e+03 Std 6.41e+03</cell><cell>5.83e+03 1.04e+04</cell><cell>1.13e+03 5.75e+03</cell><cell>1.72e+03 3.96e+02</cell><cell cols="3">7.11e+02 1.78e+03 5.20e+02 7.15e+02 1.38e+04 3.17e+02</cell></row><row><cell>f</cell><cell cols="2">Mean 5.56e+00 Std 2.12e+00</cell><cell>3.60e+00 4.30e-01</cell><cell>1.34e+00 1.99e-01</cell><cell>1.53e+00 4.24e-01</cell><cell cols="3">8.87e-01 1.96e+00 8.99e-01 2.39e-01 4.07e-01 1.23e-01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 13 Comparison of Means and Stds of MPSO and the other six PSO variants under D=30</head><label>13</label><figDesc></figDesc><table><row><cell cols="2">Func. Item</cell><cell>GPSO</cell><cell>LPSO</cell><cell>SPSO</cell><cell>CLPSO</cell><cell>FIPS</cell><cell>DMSPSO</cell><cell>MPSO</cell></row><row><cell>f</cell><cell cols="2">Mean 2.72e+08 Std 3.54e+08</cell><cell>3.52e+07 5.92e+07</cell><cell>2.23e+05 2.42e+05</cell><cell>5.56e+06 5.80e+06</cell><cell cols="3">4.00e+06 6.72e+06 1.79e+06 2.42e+05 1.15e+07 2.38e+05</cell></row><row><cell>f</cell><cell cols="2">Mean 2.23e+10 Std 1.96e+09</cell><cell>1.91e+09 2.09e+09</cell><cell>3.70e+03 2.44e+04</cell><cell>4.48e+03 1.70e+03</cell><cell cols="3">6.29e+03 3.37e+03 1.46e+03 1.43e+04 2.92e+03 7.28e+01</cell></row><row><cell>f</cell><cell cols="2">Mean 2.08e+01 Std 7.54e-03</cell><cell>2.08e+01 3.58e-01</cell><cell>2.09e+01 8.30e-02</cell><cell>2.09e+01 1.90e-02</cell><cell cols="3">2.10e+01 2.05e+01 2.03e+01 9.90e-02 1.53e-01 2.33e-03</cell></row><row><cell>f</cell><cell cols="2">Mean 1.55e+02 Std 8.14e+01</cell><cell>1.03e+02 1.29e+01</cell><cell>3.55e+01 3.38e+00</cell><cell>9.02e+01 3.63e+00</cell><cell cols="3">1.54e+02 8.32e+01 1.91e+01 4.96e+01 1.54e+01 4.06e-01</cell></row><row><cell>f</cell><cell cols="2">Mean 3.54e+03 Std 3.22e+02</cell><cell>3.19e+03 8.32e+02</cell><cell>3.97e+03 1.39e+02</cell><cell>4.62e+03 6.03e+02</cell><cell cols="3">6.31e+03 3.79e+03 2.62e+03 1.51e+03 5.40e+02 1.24e+02</cell></row><row><cell>f</cell><cell cols="2">Mean 1.00e+07 Std 7.16e+07</cell><cell>1.30e+06 5.56e+05</cell><cell>1.14e+05 3.13e+04</cell><cell>3.53e+05 1.71e+05</cell><cell cols="3">4.37e+05 1.70e+05 4.41e+04 5.05e+05 8.56e+04 7.17e+03</cell></row><row><cell>f</cell><cell cols="2">Mean 4.77e+01 Std 3.55e+01</cell><cell>2.46e+01 3.69e+01</cell><cell>9.20e+00 1.25e+00</cell><cell>9.10e+00 8.60e-01</cell><cell cols="3">1.24e+01 1.29e+01 9.98e+00 4.09e+00 9.84e-02 3.15e+00</cell></row><row><cell>f</cell><cell cols="2">Mean 1.73e+06 Std 2.05e+07</cell><cell>2.36e+05 4.11e+05</cell><cell>3.22e+04 2.60e+04</cell><cell>6.36e+04 9.24e+04</cell><cell cols="3">4.73e+04 7.95e+04 2.64e+04 9.13e+03 1.91e+05 3.36e+03</cell></row><row><cell>f</cell><cell cols="2">Mean 2.15e+02 Std 8.37e+01</cell><cell>1.29e+02 5.08e+00</cell><cell>1.03e+02 1.98e-01</cell><cell>1.04e+02 1.81e-01</cell><cell cols="3">1.03e+02 1.04e+02 1.03e+02 8.50e-02 7.00e-02 8.07e-03</cell></row><row><cell>f 10</cell><cell cols="2">Mean 1.24e+03 Std 3.88e+02</cell><cell>1.04e+03 2.09e+02</cell><cell>5.91e+02 7.22e+01</cell><cell>3.55e+02 4.81e+01</cell><cell cols="3">4.39e+02 5.98e+02 6.03e+02 8.05e+01 7.56e+02 1.88e+01</cell></row><row><cell>f 11</cell><cell cols="2">Mean 4.86e+04 Std 4.47e+04</cell><cell>3.85e+04 4.23e+03</cell><cell>3.36e+04 3.82e+03</cell><cell>2.89e+04 3.80e+02</cell><cell cols="3">2.73e+04 3.07e+04 2.73e+04 2.97e+03 1.27e+03 9.13e+02</cell></row><row><cell>f 12</cell><cell cols="2">Mean 7.58e+02 Std 3.01e+03</cell><cell>1.22e+02 2.77e+01</cell><cell>1.00e+02 0.00e+00</cell><cell>1.00e+02 1.88e-13</cell><cell cols="3">1.00e+02 1.00e+02 1.00e+02 3.50e-10 1.59e-05 2.12e-10</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors would like to sincerely thank the editors and anonymous reviewers for their valuable comments and insightful suggestions that have helped us to improve the paper. In addition, this work is partially supported by the National Program on Key Basic Research Project ( <ref type="formula">973</ref>Program) (No.2013CB329502), National Natural Science Foundation of China (No.61035003, No.61202212) and Key Research Project of Baoji University of Arts and Sciences (No.ZK2018061).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Experiments based on standard image segmentation</head><p>To further illustrate the effect of the proposed MPSO algorithm, we apply it in the task of standard image segmentation. Note that the threshold segmentation is a basic method in the field of image segmentation, and the most commonly used threshold method is the Otsu algorithm <ref type="bibr" target="#b56">[57]</ref> whose core idea can be described as follows: let the pixels of a given image be represented in l gray levels </p><p>Similarly, the probabilities of class occurrence and the class mean levels for the background can be described as:</p><p>Note that the variance formula between these two groups (object and background) can be defined by . So it can be seen that how to determine the threshold value of Otsu method is the key to the task of image segmentation. Here, we exploit the MPSO algorithm proposed in this paper to solve the segmentation threshold. Note that due to the limited space, the standard images Lena and Peppers with 512*512 pixels are employed here to validate the performance of the MPSO. At the same time, we compare it with the standard PSO (SPSO) and genetic algorithm (GA) respectively. The main parameter settings of GA are as follows: elite selection strategy, crossover rate is 0.7, mutation rate is 0.4, migration fraction is 0.2, population size is 50 and the maximum generation is 100 served as the stopping criteria. Due to the effect on particle swarm optimization, we have proposed a modified PSO algorithm in this paper. The main contributions of this work can be summarized as follows. First, the chaos-based (Logistic map) solutions are utilized to initialize the uniformly distributed initial particles to enhance the stability of PSO. Second, a novel sigmoid-like inertia weight is formulated to make the PSO adaptively adopt the inertia weight between linear decreasing and nonlinear decreasing strategies based on the maximal focus distance, which is able to keep the balance between exploration and exploitation. Conducted experiments in subsection 4.1 validate its effectiveness and efficiency. Third, the wavelet mutation is applied for the particles whose fitness value is less than that of the average in order to effectively prevent the PSO from plunging into local optima and make the particles proceed with searching in other regions of the solution space. Besides, an auxiliary velocity-position update strategy is introduced exclusively for the global best particle to guarantee the convergence of the MPSO.</p><p>Extensive experiments on the benchmark test suites and in the task of standard image segmentation validate its effectiveness, robustness and scalability.</p><p>For future work, we intend to compare MPSO with other state-of-the-art PSO variants, such as HCLPSO and EPSO, in the task of solving complex problems. More importantly, we will apply the novel initialization method proposed in this paper to these state-of-the-art PSOs in the future research. In addition, we plan to introduce MPSO into some real-world research fields, such as integrated circuit design, multi-objective optimization, multimedia semantic understanding and engineering optimal scheduling, etc. Besides, we also intend to delve deeper into the parallelization of MPSO for large-scale optimization problems and exploring the use of different inertia weights in different scenarios simultaneously, especially for the adequate parameter tuning in a wide range of problems. Lastly, and arguably most importantly, the qualitative relationship between the chaos-based initialization and the </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Efficient player selection strategy based diversified particle swarm optimization algorithm for global optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Agarwalla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mukhopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">397</biblScope>
			<biblScope unit="page" from="69" to="90" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Chaos embedded particle swarm optimization algorithms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Alatas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Akin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ozer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chaos, Solitons and Fractals</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1715" to="1734" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">PSO with adaptive mutation and inertia weight and its application in parameter estimation of dynamic systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alireza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Automatica Sinica</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="541" to="549" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A new locally convergent particle swarm optimizer</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bergh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Engelbrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Systems, Man and Cybernetics (SMC&apos;02)</title>
		<meeting>the IEEE International Conference on Systems, Man and Cybernetics (SMC&apos;02)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="94" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A hybrid particle swarm with a time-adaptive topology for constrained optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bonyadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="22" to="37" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Defining a standard for particle swarm optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bratton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Swarm Intelligence Symposium (SIS&apos;07)</title>
		<meeting>the IEEE Swarm Intelligence Symposium (SIS&apos;07)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Improved bat algorithm with optimal forage strategy and random disturbance strategy</title>
		<author>
			<persName><forename type="first">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Bio-inspired Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="205" to="214" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An aerial robot for rice farm quality inspection with type-2 fuzzy neural networks tuned by particle swarm optimization-sliding mode control hybrid algorithm</title>
		<author>
			<persName><forename type="first">E</forename><surname>Camci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kripalani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.swevo.2017.10.003</idno>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Natural exponential inertia weight strategy in particle swarm optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the World Congress on Intelligent Control and Automation (WCICA&apos;06)</title>
		<meeting>the World Congress on Intelligent Control and Automation (WCICA&apos;06)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="3672" to="3675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Study on the strategy of decreasing inertia weight in particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Xi&apos;an Jiaotong University</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="56" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A hybrid particle swarm optimizer with sine cosine acceleration coefficients</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">422</biblScope>
			<biblScope unit="page" from="218" to="241" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Particle swarm optimization with time-varying acceleration coefficients for the multidimensional knapsack problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematical Modelling</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1338" to="1350" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Chaotic particle swarm optimization for data clustering</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hsiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="14555" to="14563" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The particle swarm -explosion, stability, and convergence in a multidimensional complex space</title>
		<author>
			<persName><forename type="first">M</forename><surname>Clerc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="58" to="73" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A quantum particle swarm optimizer with chaotic mutation operator</title>
		<author>
			<persName><forename type="first">L</forename><surname>Coelho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chaos, Solitons and Fractals</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1409" to="1418" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A novel oriented cuckoo search algorithm to improve DV-Hop performance for cyber-physical systems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Parallel and Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="42" to="52" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Convergence analysis and parameter selection in particle swarm optimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Engineering and Applications</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="89" to="91" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A hybridization of an improved particle swarm optimization and gravitational search algorithm for multi-robot path planning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Behera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Panigrahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="14" to="28" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A hybrid improved quantum-behaved particle swarm optimization-simplex method (IQPSOS) to solve power system load flow problems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Davoodi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hagh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="171" to="179" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Quantum inspired genetic algorithm and particle swarm optimization using chaotic map model based interference for gray level image thresholding</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Maulik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="38" to="57" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ant colony system: a cooperative learning approach to the traveling salesman problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gambardella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="66" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Comparing inertia weights and constriction factors in particle swarm optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Congress on Evolutionary Computation (CEC&apos;00)</title>
		<meeting>the IEEE Congress on Evolutionary Computation (CEC&apos;00)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="84" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Tracking and optimizing dynamic systems with particle swarms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Congress on Evolutionary Computation (CEC&apos;01)</title>
		<meeting>the IEEE Congress on Evolutionary Computation (CEC&apos;01)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="94" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A new adaptive inertia weight strategy in particle swarm optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Congress on Evolutionary Computation (CEC&apos;07)</title>
		<meeting>the IEEE Congress on Evolutionary Computation (CEC&apos;07)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="4186" to="4190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Comparing with chaotic inertia weights in particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning and Cybernetics (ICMLC&apos;07)</title>
		<meeting>the International Conference on Machine Learning and Cybernetics (ICMLC&apos;07)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="329" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Particle swarm optimization with chaotic opposition-based population initialization and stochastic search technique</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Nonlinear Science and Numerical Simulation</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4316" to="4327" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A novel improved particle swarm optimization algorithm based on individual difference evolution</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="468" to="481" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">ACCEPTED MANUSCRIPT self-adaptive escape velocity</title>
		<author>
			<persName><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Software</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2036" to="2044" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>An improved particle swarm optimization based on</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Adaptation in natural and artificial systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Holland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>University of Michigan Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A dynamic inertia weight particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chaos, Solitons and Fractals</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="698" to="705" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Neural Networks (ICNN&apos;95)</title>
		<meeting>the IEEE International Conference on Neural Networks (ICNN&apos;95)</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Population structure and particle swarm performance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mendes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Congress on Evolutionary Computation (CEC&apos;02)</title>
		<meeting>the IEEE Congress on Evolutionary Computation (CEC&apos;02)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1671" to="1676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A fuzzy particle swarm optimization algorithm for computer communication network topology design</title>
		<author>
			<persName><forename type="first">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Engelbrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="161" to="177" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Swarm algorithm with adaptive mutation for airfoil aerodynamic design</title>
		<author>
			<persName><forename type="first">M</forename><surname>Khurana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Massey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">An improved particle swarm optimizer with difference mean based perturbation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mukherjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="315" to="333" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A hybrid particle swarm optimization and its application in neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="395" to="405" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Chaotic particle swarm optimization algorithm based on adaptive inertia weight</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Chinese Control and Decision Conference (CCDC&apos;14</title>
		<meeting>the Chinese Control and Decision Conference (CCDC&apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1310" to="1315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">PS-ABC: A hybrid algorithm based on particle swarm and artificial bee colony for high-dimensional optimization problems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="8881" to="8895" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The novel non-linear strategy of inertia weight in particle swarm optimization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Bio-Inspired Computing: Theories and Applications (BICTA&apos;09</title>
		<meeting>the IEEE International Conference on Bio-Inspired Computing: Theories and Applications (BICTA&apos;09</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="183" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Comprehensive learning particle swarm optimizer for global optimization of multimodal functions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="281" to="295" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Problem definitions and evaluation criteria for the CEC 2013 special session on real-parameter optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suganthan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<pubPlace>Singapore</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Nanyang Technological University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Problem definitions and evaluation criteria for the CEC 2015 competition on learning-based real-parameter single objective optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suganthan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<pubPlace>China</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Nanyang Technological University (Singapore) and Zhengzhou University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Dynamic multi-swarm particle swarm optimizer</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Swarm Intelligence Symposium (SIS&apos;05)</title>
		<meeting>the IEEE Swarm Intelligence Symposium (SIS&apos;05)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="124" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Particle swarm optimization with increasing topology connectivity</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Isa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering Applications of Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="80" to="102" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Hybrid particle swarm optimization with wavelet mutation and its industrial applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Iu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="743" to="763" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Fuzzy adaptive turbulent particle swarm optimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abraham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Hybrid Intelligent Systems (HIS&apos;05)</title>
		<meeting>the International Conference on Hybrid Intelligent Systems (HIS&apos;05)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="445" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Heterogeneous comprehensive learning particle swarm optimization with enhanced exploration and exploitation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Lynn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="11" to="24" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Ensemble particle swarm optimizer</title>
		<author>
			<persName><forename type="first">N</forename><surname>Lynn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="533" to="548" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Using fluid neural networks to create dynamic neighborhood topologies in particle swarm optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Majercik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Swarm Intelligence (ICSI&apos;14</title>
		<meeting>the International Conference on Swarm Intelligence (ICSI&apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="270" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">New particle swarm optimizer with sigmoid increasing inertia weight</title>
		<author>
			<persName><forename type="first">R</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hashim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Science and Security</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="35" to="44" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A hybrid particle swarm optimization -variable neighborhood search algorithm for constrained shortest path problems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Marinakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Migdalas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sifaleras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">261</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="819" to="834" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Simple mathematical models with very complicated dynamics</title>
		<author>
			<persName><forename type="first">R</forename><surname>May</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">261</biblScope>
			<biblScope unit="page" from="459" to="467" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The fully informed particle swarm: simpler, maybe better</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="204" to="210" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Accelerating particle swarm optimization using crisscross search</title>
		<author>
			<persName><forename type="first">A</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">329</biblScope>
			<biblScope unit="page" from="52" to="72" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">FAIPSO: fuzzy adaptive informed particle swarm optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Neshat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="95" to="116" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A novel particle swarm optimization algorithm with adaptive inertia weight</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nickabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ebadzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Safabakhsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="3658" to="3670" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A threshold selection method from gray-level histograms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Otsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="62" to="66" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Statistic analysis on parameter efficiency of particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Electronica Sinica</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="209" to="213" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Chaos particle swarm optimization with ensemble of chaotic systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pluhacek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Senkerik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Davendra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="29" to="35" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Self-organizing hierarchical particle swarm optimizer with time-varying acceleration coefficients</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ratnaweera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Halgamuge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="240" to="255" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Balanced fuzzy particle swarm optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Robati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Barani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematical Modelling</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2169" to="2177" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A new multi-function global particle swarm optimization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="279" to="291" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">An efficient GA-PSO approach for solving mixed-integer nonlinear programming problem in reliability optimization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sahoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhunia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="43" to="51" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Hybrid particle swarm optimization and differential evolution for optimal design of water distribution systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sedki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ouazar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advanced Engineering Informatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="582" to="591" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Service allocation in the cloud environments using multi-objective particle swarm optimization algorithm based on crowding distance</title>
		<author>
			<persName><forename type="first">F</forename><surname>Sheikholeslami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navimipour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="53" to="64" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">A modified particle swarm optimizer</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Congress on Evolutionary Computation (CEC&apos;98</title>
		<meeting>the IEEE Congress on Evolutionary Computation (CEC&apos;98</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="69" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Fuzzy adaptive particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Congress on Evolutionary Computation (CEC&apos;01)</title>
		<meeting>the IEEE Congress on Evolutionary Computation (CEC&apos;01)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="101" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Modified particle swarm optimization algorithm with simulated annealing behavior and its numerical verification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">218</biblScope>
			<biblScope unit="page" from="4365" to="4383" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Hybrid improved binary particle swarm optimization approach for generation maintenance scheduling problem</title>
		<author>
			<persName><forename type="first">K</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kumarappan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="69" to="89" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">A modified particle swarm optimization with adaptive acceleration coefficients</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Asia-Pacific Conference on Information Processing</title>
		<meeting>the Asia-Pacific Conference on Information Processing</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="330" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Self regulating particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tanweer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sundararajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">294</biblScope>
			<biblScope unit="page" from="182" to="202" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Fuzzy particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence (JCAI&apos;09</title>
		<meeting>the International Joint Conference on Artificial Intelligence (JCAI&apos;09</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="263" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Particle swarm optimization algorithm based on fuzzy controller</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Engineering and Design</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="5335" to="5338" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Particle swarm optimization based on Tent map and Logistic map</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Shaanxi University of Science and Technology</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="17" to="23" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Particle swarm optimization with chaos-based initialization for numerical optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tian</surname></persName>
		</author>
		<idno type="DOI">10.1080/10798587.2017.1293881</idno>
	</analytic>
	<monogr>
		<title level="j">Intelligent Automation and Soft Computing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A hybrid multi-objective particle swarm optimization for scientific workflow scheduling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaushal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Parallel Computing</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A hybrid intelligent algorithm by combining particle swarm optimization with chaos searching technique for solving nonlinear bilevel programming problems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="26" to="32" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">High performance computing for cyber physical social systems by using evolutionary multi-objective optimization algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<idno type="DOI">10.1109/TETC.2017.2703784</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Emerging Topics in Computing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Randomly attracted firefly algorithm with neighborhood search and dynamic parameter adjustment mechanism</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Computing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="5325" to="5339" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">ACCEPTED MANUSCRIPT swarm optimization algorithm applied to real power loss minimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering Applications of Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="63" to="75" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>A hybrid topology scale-free Gaussian-dynamic particle</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Diversity enhanced particle swarm optimization with neighborhood search</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">223</biblScope>
			<biblScope unit="page" from="119" to="135" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Firefly algorithm with random attraction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Bio-Inspired Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="41" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Particle swarm optimization with adaptive mutation for multimodal optimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">221</biblScope>
			<biblScope unit="page" from="296" to="305" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Firefly algorithm with neighborhood attraction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">382</biblScope>
			<biblScope unit="page" from="374" to="387" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Particle swarm optimization using dynamic tournament topology</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Orchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="584" to="596" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Firefly algorithm with adaptive control parameters</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Computing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="5091" to="5102" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Cauchy mutation for decision-making variable of Gaussian particle swarm optimization applied to parameters selection of SVM</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="4929" to="4934" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">A particle swarm optimizer with multi-stage linearly-decreasing inertia weight</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Computational Sciences and Optimization</title>
		<meeting>the International Joint Conference on Computational Sciences and Optimization</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="505" to="508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">A new fuzzy inertia weight particle swarm optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Yadmellat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Salehizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Menhaj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computational Intelligence and Natural Computing (CINC&apos;09</title>
		<meeting>the International Conference on Computational Intelligence and Natural Computing (CINC&apos;09</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="507" to="510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">A modified particle swarm optimizer with dynamic adaptation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">189</biblScope>
			<biblScope unit="page" from="1205" to="1213" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Adaptive weight particle swarm optimization algorithm with constriction factor</title>
		<author>
			<persName><forename type="first">Z</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Information Science and Management Engineering (ISME&apos;10)</title>
		<meeting>the International Conference on Information Science and Management Engineering (ISME&apos;10)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="245" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Adaptive particle swarm optimization algorithm based on feedback mechanism</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Zhejiang University (Engineering Science)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1286" to="1291" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">An adaptive inertia weight particle swarm optimization algorithm for IIR digital filter</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Artificial Intelligence and Computational Intelligence (AICI&apos;09</title>
		<meeting>the International Conference on Artificial Intelligence and Computational Intelligence (AICI&apos;09</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="114" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Orthogonal learning particle swarm optimization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="832" to="847" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Adaptive particle swarm algorithm with dynamically changing inertia weight</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Xi&apos;an Jiaotong University</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1039" to="1042" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Vector coevolving particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">394</biblScope>
			<biblScope unit="page" from="273" to="298" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Hybrid multi-objective cuckoo search with dynamical local</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12293-017-0237-2</idno>
	</analytic>
	<monogr>
		<title level="j">Memetic Computing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Analysis and improvement of particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Control</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="513" to="517" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Simplified particle swarm optimization algorithm based on stochastic inertia weight</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Application Research of Computers</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="361" to="364" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">On the convergence analysis and parameter selection in particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning and Cybernetics (ICMLC&apos;03)</title>
		<meeting>the International Conference on Machine Learning and Cybernetics (ICMLC&apos;03)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="1802" to="1807" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
