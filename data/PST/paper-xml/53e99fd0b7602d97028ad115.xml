<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Menon</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Tolerant Computing Group</orgName>
								<orgName type="institution">University of Potsdam</orgName>
								<address>
									<settlement>Potsdam</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical and Computer Engineer-ing</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<postCode>01003</postCode>
									<settlement>Amherst</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">905A5A6F0BAD43A1A21BE881D929A157</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T05:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Logic Optimization and Equivalence</head><p>Checking by Implication Analysis Wolfgang Kunz, Member, IEEE, Dominik Stoffel, Member, IEEE, and Prem R. Menon, Fellow, IEEE Abstract-This paper proposes a new approach to multilevel logic optimization based on automatic test pattern generation (ATPG). It shows that an ordinary test generator for single stuckat faults can be used to perform arbitrary transformations in a combinational circuit and discusses how this approach relates to conventional multilevel minimization techniques based on Boolean division. Furthermore, effective heuristics are presented to decide what network manipulations are promising for minimizing the circuit. By identifying indirect implications between signals in the circuit, transformations can be derived which are "good" candidates for the minimization of the circuit. A main advantage of the proposed approach is that it operates directly on the structural netlist description of the circuit so that the technical consequences of the performed transformations can be evaluated in an easy way, permitting better control of the optimization process with respect to the specific goals of the designer. Therefore, the presented technique can serve as a basis for optimization techniques targeting nonconventional design goals. This has already been shown for random pattern testability <ref type="bibr" target="#b10">[11]</ref> and low-power consumption <ref type="bibr" target="#b27">[28]</ref>. This paper only considers area minimization, and our experimental results show that the method presented is competitive with conventional technologyindependent minimization techniques. For many benchmark circuits, our tool Hannover implication tool based on learning (HANNIBAL) achieves the best minimization results published to date. Furthermore, the optimization approach presented is shown to be useful in formal verification. Experimental results show that our optimization-based verification technique works robustly for practical verification problems on industrial designs. Index Terms-ATPG, implication analysis, logic synthesis, logic verification, miter, permissible function, recursive learning, redundancy elimination, transduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>M ULTILEVEL logic optimization figures prominently in the synthesis of highly integrated circuits. The goal of multilevel logic optimization is transforming an arbitrary combinational circuit into a functionally equivalent circuit , circuit being less expensive than according to some cost function. The cost function typically incorporates area, speed, power consumption, and testability as the main objectives of the optimization procedure. This research focuses on optimizing a given circuit with respect to its area, a minimal area representation of the circuit being a good basis for sub-sequent steps targeting high speed, low power consumption, and high testability.</p><p>The field of multilevel logic optimization is not as well delineated as the field of two-level optimization <ref type="bibr" target="#b6">[7]</ref>, and there exist many different views on the multilevel optimization problem. An early systematic approach was proposed by Ashenhurst and Curtis <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b12">[13]</ref> and is known as functional decomposition. Functional decomposition, in general terms, is the process of expressing a switching function of variables as a composition of a number of functions, each depending on less than variables. Due to their complexity, early methods based on functional decomposition have been of limited use in practice. However, research in this area is still active. Recent contributions <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b37">[38]</ref> are encouraging, and have proven to be very useful in field programmable gate array (FPGA) synthesis.</p><p>Presently, the most flexible and powerful synthesis techniques for combinational circuits are based on Boolean and algebraic manipulations of Boolean networks, pioneered by Brayton et al. <ref type="bibr" target="#b7">[8]</ref>. Since they provide good optimization results and can handle circuits of realistic size, these methods have become widely accepted.</p><p>Even with much recent progress, e.g., <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b24">[25]</ref>- <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b33">[34]</ref>, and <ref type="bibr" target="#b37">[38]</ref>, the size and complexity of today's integrated circuits leave multilevel logic optimization a major challenge in the field of computeraided circuit design. In particular, high-memory requirements represent the dominating limitation for many methods.</p><p>An important attribute of most common synthesis procedures is that they divide the synthesis process into an technology-independent minimization phase and a cell-binding procedure which maps the design to a specific target technology (technology mapping). However, the strict separation of logic minimization from the specific technical design information can sometimes be of disadvantage since the powerful concepts for deriving circuit transformations cannot be oriented at the specific technical data.</p><p>Therefore, an important goal of this research is to work toward general logic minimization techniques which operate directly on the structural gate netlist description of the circuit so that the specific technological information of the given gate library is immediately available to guide the optimization process.</p><p>Our work is motivated by recent advances in test generation. Over the years, considerable progress has been achieved in combinational ATPG, and it seems wise to utilize the power of modern ATPG methods also in synthesis. ATPG methods are attractive for two reasons. First, in order to obtain effective test sets, ATPG techniques operate directly on a gate-level description of the circuit. Second, ATPG methods are very memory efficient and typically have memory requirements linear in the size of the gate-level description.</p><p>An important contribution exploiting testing techniques in logic minimization has recently been presented by Entrena and Cheng <ref type="bibr" target="#b15">[16]</ref>. They propose an extension to redundancy removal (see, e.g., <ref type="bibr" target="#b0">[1]</ref>) and describe an effective method which is based on adding and removing connections in the circuit. The approach to be presented in this paper can be seen as a generalization of the technique in <ref type="bibr" target="#b15">[16]</ref> applied to combinational circuits. The advantage of operating directly on the gate netlist has also been recognized by Rohfleisch and Brglez <ref type="bibr" target="#b31">[32]</ref> who presented a technique based on permissible bridges which can effectively optimize a circuit after technology mapping.</p><p>The methods of <ref type="bibr" target="#b15">[16]</ref> and <ref type="bibr" target="#b31">[32]</ref> have been shown to be very useful for postprocessing networks that were preoptimized by traditional techniques. On the other hand, they only consider a restricted set of possible network manipulations and, therefore, do not provide the same reasoning power and flexibility as traditional technology-independent synthesis methods.</p><p>Therefore, our goal is to develop a multilevel logic minimization method which is competitive with technologyindependent minimization techniques such as <ref type="bibr" target="#b7">[8]</ref> and which uses a test generator as the basic Boolean reasoning engine. In this paper, we present a method which is general in the sense that, in principle, it can derive arbitrary transformations in a combinational network. The second contribution of this paper is to introduce a new heuristic guidance for logic optimization. We show how logic minimization (for area) can be guided effectively by a single heuristic concept: the optimization process can be controlled by analyzing implications between circuit nodes. The complexity of reasoning required to derive logic implications is seen to be related to the optimality of the circuit structure and is used in optimization.</p><p>A major strength of our method is that it efficiently identifies or creates permissible functions <ref type="bibr" target="#b26">[27]</ref>. Therefore, it relates to Muroga's transduction method. There are two main ingredients to our method: the D-calculus of Roth <ref type="bibr" target="#b32">[33]</ref> and Recursive Learning <ref type="bibr" target="#b21">[22]</ref>. The latter, which is discussed briefly in Section II, is used to derive logic implications in combinational circuits. Analyzing implications is crucial for deriving good circuit transformations. In this aspect our method also relates to <ref type="bibr" target="#b2">[3]</ref> and <ref type="bibr" target="#b17">[18]</ref>.</p><p>Throughout the paper, we attempt to relate the concepts of our ATPG-based method to common concepts in logic synthesis ("division," "permissible functions," "don't cares," and "common kernel extraction").</p><p>As pointed out <ref type="bibr" target="#b7">[8]</ref>, "division" is central to Boolean/algebraic methods of logic optimization. For example, take the function . A simpler representation of the same function is . This representation can be obtained by defining a division operation ' ' such that . The expression is referred to as a "divisor" of . When developing an ATPGbased method for logic minimization, the following two central issues have to be addressed. 1) How can an ATPG-based method perform Boolean division? 2) How can an ATPG-based method provide "good" divisors? The paper is outlined as follows. The first of the above questions will be addressed in Section III, and the second question is discussed in Section IV. Section V describes and illustrates the general flow of our optimization procedure. Section VI is dedicated to an unconventional application of an optimization technique; we formulate the formal logic verification problem as an optimization problem and demonstrate how the described method can be tailored for logic verification. Section VII shows experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. INDIRECT IMPLICATIONS</head><p>The optimization method to be presented heavily depends on analyzing implications derived by recursive learning <ref type="bibr" target="#b21">[22]</ref>. A more general method to determine implicants in a multilevel network based on AND/OR graphs has been presented recently in <ref type="bibr" target="#b35">[36]</ref>. The optimization procedure described in the following sections does not yet exploit the concepts of <ref type="bibr" target="#b35">[36]</ref> but only uses recursive learning. Some previous results and terminology are briefly summarized. Recursive learning is a method to determine all value assignments which are necessary for the detection of a single stuck-at fault in a combinational circuit. This involves finding all value assignments necessary for the consistency of a given assignment of values to a set of nodes in the circuit. Determining value assignments necessary for the consistency of a given set of value assignments is often referred to as performing implications.</p><p>Consider the gate-level circuit of Fig. <ref type="figure" target="#fig_0">1</ref>. Assume that the value assignments have been made in the circuit. By considering the truth table of an AND-gate, we imply . The variable is an input variable of , and by another implication, we obtain . Variables and are input variables of , and we perform the implications and . In <ref type="bibr" target="#b21">[22]</ref>, this type of implication has been referred to as direct implication.</p><p>As defined in <ref type="bibr" target="#b21">[22]</ref>, direct implications are identified by evaluating the value assignments at each gate and by propagating the signal values according to the connectivity in the circuit. An implication which cannot be determined in this simple way has been called indirect.</p><p>While the performance of direct implications is a straightforward procedure, it is more difficult to perform implications which are not direct. Reconsider the circuit in Fig. <ref type="figure" target="#fig_0">1</ref> and assume a value assignment of . A closer study reveals that implies <ref type="bibr" target="#b34">[35]</ref>. The implication is not direct, and more sophisticated techniques are required to derive such indirect implications. Recursive learning as presented in <ref type="bibr" target="#b21">[22]</ref> represents a technique which allows us to derive all direct and indirect implications for a given situation of value assignments.</p><p>Indirect implications play an important role in our strategy for circuit optimization. As will be shown, indirect implications identify promising divisors for transforming the circuit. For a more detailed description on how the reasoning in recursive learning can be used to identify circuit transformations, see also <ref type="bibr" target="#b35">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. MANIPULATING COMBINATIONAL NETWORKS BY ATPG</head><p>Assume we are given a combinational circuit with primary inputs and primary outputs and containing only the primitive gates AND , OR , NOT . The ANDand OR-gates can only have two inputs. These restrictions are made in order to simplify the theoretical analysis of our method. In the following, such circuits will be referred to as combinational networks. (Of course, a reasonable implementation of our approach can also handle multi-input gates including NAND, NOR, and possibly XOR.) Furthermore, signals in the circuit can have constant values of '0' or '1.' All gates in the circuit have unique labels, and their output signals realize Boolean functions with , where the variables correspond to the primary input signals of the circuit . Following the usual representation of a combinational circuit as a directed acyclic graph (DAG), we say, as in <ref type="bibr" target="#b7">[8]</ref>, that a signal lies in the transitive fanout of if and only if there exists a directed path from to in the image of as DAG. Avoiding formalism, depending on the context, we will refer to the primary input signals and the output signals of the gates in circuit as "signals," "functions," or "nodes." Furthermore, we assume that there are no external don't cares; the function of the combinational network with is completely specified. An extension to our method using external don't cares is possible but will not be further considered in this work.</p><p>Two combinational networks, and , are called equivalent, denoted , if they implement the same function with . They are called structurally identical or simply identical if there exists a one-to-one mapping between and , such that for every node in there is a in and vice versa, where and implement the same function. We denote identical combinational networks by . A basic technique to describe many manipulations of switching functions is the well-known Shannon expansion. Let be a Boolean function of variables . The Shannon expansion for with respect to is given by (1)</p><p>Shannon's expansion can be understood as a special case of an orthonormal expansion <ref type="bibr" target="#b5">[6]</ref> where the functions represent an orthonormal basis, i.e., i) ;</p><p>ii)</p><p>The functions are called the (generalized) cofactors with respect to the functions . Shannon's expansion is the special case of the above expansion where and and is some variable of . Next, we consider another special case of the above orthonormal expansion where, more generally than in Shannon's expansion, we choose and where is some arbitrary Boolean function . This means we obtain an expansion given by the following equation: short notation:</p><p>(2)</p><p>The terms and denote the cofactors of this expansion. In the special case of Shannon's expansion, the cofactors are chosen by restricting the original function with respect to a particular variable, as in <ref type="bibr" target="#b0">(1)</ref>. We obtain the cofactor for with respect to a variable by setting in the expression for , similarly, the cofactor for results when setting . Note that there is no such simple rule in the more general case of <ref type="bibr" target="#b1">(2)</ref>.</p><p>Let the cofactors be denoted , with . Further, let denote an incompletely specified function . The cofactors in (2) must be chosen such that the following equation holds: if X (don't care) otherwise.</p><p>(3) It is easy to see why (3) is true. Assume that the truth table of is divided into two parts such that is false for all rows in the first part and true for all rows in the second part. If we first consider the part of the truth table of for which is true, we can set to the don't care value for all rows in which is false. This means that the cofactor function must only have the same value as in those rows where is not don't care. Therefore, any valid cofactor for the expansion of (2) covers (denoted ' ') the incompletely specified function as given by (3). This first part of the function is described by the expression . In the second part, we are looking at those rows of the truth table for which is false and obtain . Equation ( <ref type="formula">2</ref>) is the basis of our approach to transforming a combinational network. In order to relate our approach to the Boolean/algebraic techniques of <ref type="bibr" target="#b7">[8]</ref>, we can refer to function as divisor of . Similarly, can be referred to as quotient, and represents the remainder of the division. Further, note that the combined don't care sets of the two cofactors in (3) are identical to the don't care set passed to a minimization algorithm for Boolean division, described in <ref type="bibr" target="#b7">[8]</ref>. The main issue in our approach, as well as in <ref type="bibr" target="#b7">[8]</ref>, is to find appropriate (divisor) functions such that the internally created don't cares as given by ( <ref type="formula">3</ref>) provide "degrees of freedom" in the combinational network which can be exploited to minimize its area.</p><p>Obviously, the result of such an orthonormal expansion (or Boolean division) depends on how the don't cares are used in order to minimize the circuit. (Boolean division is not unique.) In <ref type="bibr" target="#b7">[8]</ref>, the don't cares are explicitly passed to an optimization run by ESPRESSO. The approach to be described here, proceeds in a different way and uses a test generator to determine the cofactors in the above expansion. As already observed by Brand in <ref type="bibr" target="#b3">[4]</ref>, circuitry tends to have an increased number of untestable single stuckat faults if it is not properly optimized with respect to a given don't care set. This suggests that the don't cares created by the expansion of ( <ref type="formula">2</ref>) can also cause untestable stuck-at faults which can be removed by the standard procedure of redundancy elimination. In fact, redundancy elimination is a simple way to minimize the circuit with respect to don't care conditions. Note that redundancy elimination does not require any explicit knowledge about the don't care sets. Throughout this paper, transformations are examined that create internal don't cares. However, these don't care conditions are not explicitly calculated or represented. They are only considered in our theoretical analysis to illuminate where the redundant faults to be eliminated come from.</p><p>Example 3.1: To illustrate how don't cares as given by (3) lead to untestable stuck-at faults, consider Shannon's expansion as an example, i.e., take the special case where the divisor is some variable . Note that the original function is a possible cover for both and so that according to (2) we can form the expression . In Fig. <ref type="figure" target="#fig_1">2(b)</ref>, this is implemented as combinational circuit for the example, and . Note that the choice of the original function as a (trivial) cofactor ignores the don't care conditions as given by (3). The fact that the cofactors are not optimized with respect to these don't cares leads to untestable stuck-at faults as indicated. (The cofactors are shaded grey). It is determined by ATPG that , stuck-at-one, and , stuck-at-zero, in the respective cofactor are untestable and can be removed by setting to a constant one or zero, respectively. Fig. <ref type="figure" target="#fig_1">2(c</ref>) shows the circuit after redundancy removal. Redundancy removal in this case obviously corresponds to setting to one or zero in the respective cofactors of <ref type="bibr" target="#b0">(1)</ref>.</p><p>By viewing redundancy elimination as a method to set signals in cofactors to constant values, we have just described an ATPG-based method to perform a Shannon expansion. Clearly, it is not sensible to use a test generator in order to prove that in the Shannon expansion of ( <ref type="formula">1</ref>) can be set to constant values. However, this ATPG interpretation of Shannon's expansion is quite useful in the more general case of (2), i.e., when we expand in terms of some arbitrary function . In the general case, it is a priori not known if and what signals in the cofactors can be set to constant values. This, however, can be determined by means of a test generator.</p><p>Let be an arbitrary node in a combinational network and be some Boolean function represented as a combinational network. The variables of may or may not be nodes of the combinational network . A new combinational network is constructed as follows. We duplicate all nodes in the transitive fanin of so that there are two implementations of node . This has been illustrated in Fig. <ref type="figure" target="#fig_1">2</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a) and 2(b). One version is ANDed with , the other version is ANDed with</head><p>, and the outputs of the AND gates are combined by an OR gate whose output replaces the node in the original network. In the following, this construction will be represented by the equation . Letting and be Boolean functions represented as a combinational network, we propose to expand function in terms of function by the following method:</p><p>1) transform network:</p><p>2) redundancy elimination with an appropriate fault list.</p><p>(4) This expansion can also be understood as a special ATPGbased transduction <ref type="bibr" target="#b26">[27]</ref> as it consists of a transformation and a reduction. In the following, we use the terms expansion and transduction synonymously. Since this ATPG-based transduction is one out of many possibilities to perform a Boolean division or orthonormal expansion in a combinational network, it is important to investigate what network transformations are theoretically possible using it. In the following theorem, we prove that the construction of ( <ref type="formula">4</ref>) and redundancy elimination are sufficient for performing arbitrary Boolean transformations in a network.</p><p>Theorem 3.1: Let be a node of a combinational network . The gates in the combinational network can have no more than two inputs. Further, let be a divisor which is represented as a combinational network and realizes a Boolean function of no more than two variables which may or may not be nodes in such that 1) The transformation of node into given by followed by 2) Redundancy removal (with an appropriate fault list) generates a combinational network . For an arbitrary pair of equivalent combinational networks and there exists a sequence of combinational networks such that and . Proof: Switching algebra is isomorphic to two-valued Boolean algebra. A Boolean algebra can be defined by Huntington's axioms. First, we show that all operations (transformations) defined by the axioms can equally be performed by the above manipulations in a combinational network.</p><p>For each axiom, it has to be shown that the corresponding transformation can be performed in both directions. In order to complete the proof, it must be shown that the above expansion also allows arbitrary sharing of logic. This follows easily from the following construction. Let be the original network and be the target network. Further, let denote a network that has tree structure and results from if all sharing of logic is removed by duplication. Similarly, let denote the tree version of the target network. Consider the following construction. First we remove all sharing of logic between the different output cones of the original network so that we obtain . It is easy to derive by the above expansion. Let be some internal fanout branch and assume its stem is the output of an AND gate with input signals and . By choosing a divisor and by performing the above expansion with an appropriate fault list, the AND gate is duplicated, and the fanout point is moved to the inputs of the AND gate. For other gate types, the procedure is analogous. This process is repeated until no more internal fanout points exist and has been obtained. After all sharing of logic has been removed, each output cone is isomorphic to a Boolean expression that can be manipulated arbitrarily as shown using the above axioms. Therefore, it is also possible to obtain the network by the above expansion. The target network results if the duplicated logic is removed. This can be accomplished if equivalent nodes are substituted. If node is to be substituted by node , this can be accomplished by selecting and performing the above expansion. This process can be repeated for well-selected nodes in until network is reached. Suppose is the given combinational network and is the combinational network which is optimal with respect to the given cost function. Theorem 3.1 states that there always exists a sequence of the specified expansion operations such that the optimal combinational network is obtained. However, it does not say which divisors shall be used when applying <ref type="bibr" target="#b3">(4)</ref>. As stated in the theorem, if the network has gates with no more than two inputs, it is sufficient to only consider divisors created as function of two nodes in the network. This reduces the number of divisors that (theoretically) have to be examined. Of course, this restriction does not imply that more complex divisors are of no use in the presented expansion scheme. If more complex divisors are used, the network is transformed in bigger steps. Theorem 3.1 does not put any restriction on the choice of divisors to transform the network. Further degrees of freedom for the expansions lie within redundancy elimination. The result of redundancy elimination depends on what faults are targeted and in which order they are processed.</p><p>Theorem 3.1 represents the theoretical basis of a general ATPG-based framework to logic optimization. As mentioned, redundancy elimination and the transformation of (4) per se do not represent an optimization technique. However, they provide the basic tool kit to modify a combinational network. In order to obtain good optimization results, efficient heuristics have to be developed to decide what divisors to choose and how to set up the fault list for redundancy elimination. This will be described in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. IDENTIFYING DIVISORS BY IMPLICATIONS</head><p>Our method of identifying divisors has been motivated by an observation first mentioned in <ref type="bibr" target="#b29">[30]</ref>. Indirect implications indicate suboptimality in the circuit. This is illustrated in Fig. <ref type="figure" target="#fig_3">3</ref>.</p><p>In the left circuit of Fig. <ref type="figure" target="#fig_3">3</ref>, we consider as the initial situation of value assignments for which we can indirectly imply . This is can be accomplished by means of recursive learning. Note that the existence of the indirect implication is due to the fact that the circuit is not properly optimized. In the optimized right circuit which is functionally equivalent to the left circuit, we note that the implication is direct. One may verify that all examples of indirect implications shown in <ref type="bibr" target="#b21">[22]</ref> or <ref type="bibr" target="#b34">[35]</ref> are also due to poorly optimized circuitry. Apparently, indirect implications are a key to identifying and optimizing suboptimal circuitry.</p><p>Before developing an optimization strategy based on distinguishing between direct and indirect implications, we first study the role of implications in general for multilevel minimization.</p><p>Consider again the example of Fig. <ref type="figure" target="#fig_3">3</ref>. For the above expansion, the circuit transformation of (4) requires that all combinational circuitry in the transitive fanin of is duplicated before redundancy elimination is applied. This seems impractical and in the following, we, therefore, consider special cases of the expansion where only one cofactor has to be considered. These special cases are obtained if only such divisor functions are considered which follow from by implication. For the following lemmas, let and be nodes of the combinational network such that is not in the transitive fanout of . (This restriction ensures that the circuit remains combinational after the transformation).</p><p>Lemma 4.1: Consider the transformation . Then if and only if the implication is true.</p><p>Proof: " ": in Eq. ( <ref type="formula">2</ref>) can be set to '1' and we obtain:</p><p>" ": (Eq. *)</p><p>for it follows that , for the function assumes the same values as (by definition), hence the implication must be true and by contraposition the implication must also be true if Eq. * can be fulfilled. The lemmas state that implications determine exactly those functions with respect to which function has only one cofactor. In other words, in a combinational network, the expansion of Theorem 3.1 can be simplified without any circuit duplication if the specified implications are present. It is interesting to note that this does not sacrifice the generality of the approach.</p><p>Theorem 4.1: Let be a node of a combinational network . The gates in the combinational network can have no more than two inputs. Further, let be a divisor which is represented as combinational network and realizes a Boolean function of no more than two variables which may or may not be nodes in such that</p><p>1) The transformation of node into given by for for for for followed by 2) Redundancy removal (with appropriate fault list) generates a combinational network . For an arbitrary pair of equivalent combinational networks and , there exists a sequence of combinational networks such that and . Proof: Follows from the proof of Theorem 3.1, by noting that all functions and divisors used satisfy one of the implications specified above.</p><p>Note that Lemmas 4.1-4.4 only cover those cases where a node in a combinational network can be replaced by some equivalent function . A function at node can also be replaced by some nonequivalent function if this does not change the function of the combinational network as a whole. Such functions are called permissible functions <ref type="bibr" target="#b26">[27]</ref>. By considering permissible functions rather than only equivalent functions as candidates for substitution at each node, we exploit additional degrees of freedom as given by observability don't cares <ref type="bibr" target="#b7">[8]</ref>. Permissible functions can also be obtained by recursive learning: Definition 4.1: For an arbitrary node in a combinational network , assume the single fault stuck-at-. If is a value assignment at a node which is necessary to detect the fault at at least one primary output of , then follows from by " -implication" and is denoted . The conventional implications are a special case of suchimplications. Replacing the implications in Lemmas 4.1-4.4 by -implications, we obtain the following generalization.</p><p>Theorem 4.2: Let and be arbitrary nodes in a combinational network where is not in the transitive fanout of and both stuck-at faults at node are testable. The function with is a permissible function at node if and only if the -implication is true. Proof: " ": If is true, then is true. We partition the set of possible combinations of input assignments (rows in the truth table) into two disjoint subsets, where each fulfills one of the following conditions:</p><p>Case 1: ( and ) or : For these inputs, is true and Lemma 4.1 applies, for these inputs and always assume the same value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case 2:</head><p>and : For these inputs, can have a different value than . With the function can only assume the faulty value '1.' However, this cannot lead to a wrong value at the primary outputs of because the fault stuck-at-one at node cannot be tested since and .</p><p>" ": The transformation is permissible if one of the following cases is fulfilled:</p><p>Case 1: and are equivalent Lemma 4.1 applies, if is true then is true. Case 2:</p><p>and and stuck-at-zero is untestable under this condition , i.e., this case cannot occur. Case 3:</p><p>and and stuck-at-one is untestable under this condition. With and can only occur if is true. The term in the above transformation means that this node can be implemented as an arbitrary function assuming the same values as for . As a special case, assume that . In this special case, if then is sufficient to produce a "faulty" signal '1' at node . Now consider the set of all test vectors for stuck-at-one in the original circuit that produce . Every such test will result in a faulty response of the transformed circuit. Therefore, the transformation is only allowed if such a test does not exist. However, if a test for stuck-at-one exists in general, it is required that there is none which produces . This means that is necessary for fault detection and must be true. If this condition is necessary for the special case that , it is also necessary for the general statement since is one of the possible choices to implement .  <ref type="formula">2</ref>), they also provide simplified cases of (4). As will be illustrated in Section V, the constructions based on (4) and the above theorems provide good candidates for the expansion of Theorem 3.1.</p><p>Recursive learning can be used to determine all value assignments necessary to detect a single stuck-at fault, i.e., it is a technique to perform all -implications. This is accomplished by two routines make_all_implications(), and fault_propagation_learning() as given in <ref type="bibr" target="#b21">[22]</ref> if they are performed for the five-valued logic alphabet of Roth <ref type="bibr" target="#b32">[33]</ref>. Therefore, by recursive learning it is possible to derive all cases where Theorems 4.2-4.5 apply.</p><p>The number of implications and -implications can be very large so that it is impossible to examine all transformations. At this point, however, we come back to the observation discussed earlier. Implications which can only be derived by "great effort" represent the promising candidates for the transformations as given in Theorems 4.2-4.5. These indirect implications are only a small fraction of all possible implications. In the following, we refer to aimplication as indirect if it can neither be derived by direct implication nor by unique sensitization <ref type="bibr" target="#b16">[17]</ref> at the dominators <ref type="bibr" target="#b20">[21]</ref> of . In other words, all those necessary assignments obtained by the learning case of routines fault_ propagation-_ learning() and make_ all_ implications() are implied indirectly and provide the set of promising candidates for the circuit transformations.</p><p>As it turns out, the concept of relating the complexity of the implication problem to minimality of the combinational network permits a new and promising approach to guiding logic minimization techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. OPTIMIZATION PROCEDURE</head><p>The described concepts have been implemented as part of the HANNover Implication Tool Based on Learning (HAN-NIBAL) tool system. Table <ref type="table">I</ref> summarizes the general program flow for circuit optimization. HANNIBAL performs logic optimization by applying the described concepts stepwise to all nodes in the combinational network. The optimization procedure moves from node to node in the combinational network. Experiments showed that the optimization results are only moderately sensitive to the order in which the different circuit nodes are processed. However, best results were generally obtained by processing the nodes according to their topological level moving from the primary inputs toward the primary outputs. For a selected node, recursive learning is used to derive promising divisor functions. The candidates found promising stored in lists and tried in sequence. When identifying implications, it is important that we run recursive learning only for one node at a time and then transform the given node by the implications obtained. Therefore, after modifying the circuit, we have to update the data only for the current node.</p><p>For each candidate implication, the circuit is transformed according to the rules given in Section IV. After each transformation, redundancy elimination is employed. To make this process as fast as possible, the deterministic test set is always maintained for the most recent version of the circuit. After each circuit transformation, this test set is simulated to quickly discard many faults from further consideration so that a only few faults have to be targeted explicitly by deterministic ATPG. After redundancy elimination has been completed, it is checked whether the circuit became smaller or not. If it became smaller, the current circuit is maintained, otherwise the previous version is recovered. This is continued for all nodes in the network until no more improvements can be found. In HANNIBAL, several runs are made through the circuit varying the recursion depth and the number of candidate implicants being tried at each node in different runs.</p><p>For each step of redundancy removal, we determine the fault list as follows:</p><p>1) include in the fault list both stuck-at faults at all signals that were "touched" by recursive learning when deriving the current divisor; 2) exclude from the fault list, all faults in the circuitry added for the current transformation. Limiting the fault list to signals being processed by the eventdriven recursive learning routine proved to be a very good heuristic to speed up fault simulation and ATPG (up to a factor of 4) without significantly sacrificing optimization quality. Example 5.1-"Good" Boolean Division: Consider Fig. <ref type="figure">4</ref>. By recursive learning, it is possible to identify the indirect implication . (Please refer to <ref type="bibr" target="#b21">[22]</ref> for details of recursive learning.) The fact that the implication is indirect means that it is promising to attempt a Boolean division at node using the divisor . This could be performed by any traditional method of Boolean division. Instead, we use the ATPG-based expansion introduced in Section III.</p><p>Applying Theorem 4.4, we obtain the combinational network as shown in Fig. <ref type="figure" target="#fig_6">5</ref>. Actually, in this case we could also apply Lemma 4.3 since is obtained without using any requirements for fault propagation. Note that Theorem 4.4 states that is a permissible function for . (In this case, and are equivalent.) By transformation as shown in Fig. <ref type="figure" target="#fig_6">5</ref>, we introduce the node . Since is used as a cover for , it is likely that the internal don't cares result in untestable single stuck-at faults. This is used in the next step (reduction).  By ATPG, the untestable faults indicated in Fig. <ref type="figure" target="#fig_6">5</ref> can be identified. Performing redundancy removal (e.g., <ref type="bibr" target="#b0">[1]</ref>) results in the minimized combinational network as shown in Fig. <ref type="figure" target="#fig_7">6</ref>. Note that we have to exclude the stuck-at faults in the added circuitry in the shaded area of Fig. <ref type="figure" target="#fig_6">5</ref>. If we performed redundancy elimination on line in Fig. <ref type="figure" target="#fig_6">5</ref>, we would return to the original network.</p><p>In the example, node in Fig. <ref type="figure">4</ref> is implemented by . By indirect implication, we identified the Boolean divisor as "promising" and performed the (nonunique) division , resulting in in Fig. <ref type="figure" target="#fig_7">6</ref>. Note that this is a Boolean-as opposed to algebraic-division <ref type="bibr" target="#b7">[8]</ref>. As the example shows, indirect implications help to identify good divisors that justify the effort to attempt a Boolean division.</p><p>Example 5.2-"Common Kernel Extraction": Consider the circuitry of Fig. <ref type="figure" target="#fig_8">7</ref>. The circuit implements two Boolean functions: and , each of which cannot be optimized any further. Note, however, that the two functions have a common kernel, , which can be extracted and shared so that a smaller circuit is obtained with with It is interesting to examine how the suboptimality of the original circuit is reflected by the indirectness of implications.</p><p>Consider Fig. <ref type="figure" target="#fig_8">7</ref>. By recursive learning, it is possible to identify the -implication . Remember that this means that is necessary for detection of , stuck-atone. As can be noted, the necessary assignment is not "obvious." It can neither be derived by direct implications nor by sensitization at the dominators of . The reader may verify   that can be obtained by the learning case of recursive learning using fault_ propagation_ learning() <ref type="bibr" target="#b21">[22]</ref>. Now the transduction is performed in the usual way. According to Theorem 4.3, the circuit can be modified as shown in Fig. <ref type="figure" target="#fig_9">8</ref>, and redundancy elimination yields the optimized circuit in Fig. <ref type="figure" target="#fig_10">9</ref>.</p><p>Note that our method can perform transformations which cannot be performed by the method of Entrena and Cheng <ref type="bibr" target="#b15">[16]</ref> and the method of <ref type="bibr" target="#b9">[10]</ref>. To the best of our understanding, in the above example, the minimization cannot be obtained by only adding and removing connections as in <ref type="bibr" target="#b9">[10]</ref> and <ref type="bibr" target="#b15">[16]</ref>. This is because the methods of <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b15">[16]</ref> require the existence of gates of a certain type at the location where the added connection (gate) is anchored. Based on the expansion described in Section III, our approach uses a wider spectrum of circuit transformation. This could possibly impose higher computational costs, however, our results show that the heuristic strategy of only using indirect implications for circuit transformation can effectively limit the search space.</p><p>As presented in <ref type="bibr" target="#b21">[22]</ref>, recursive learning consists of two techniques, make_ all_ implications() and fault_ propagation_ learning(). It is interesting to note that implications obtained by make_ all_ implications() result in transductions that, in conventional terms, often lead to transformations that are most adequately described by Boolean division or Boolean resubstitution. This was illustrated in Example 5.1. If the implication is obtained by fault_ propagation_ learning() as in Example 5.2, the expansion often performs what is commonly referred to as common kernel extraction.</p><p>Limitations: 1) The examples also show the limitation of our method. By implication analysis we only consider divisors that are already present as nodes in the network. Therefore, we do not completely utilize the generality of our basic approach as given by Theorem 4.1. Extensions are under way to derive implicants and D-implicants <ref type="bibr" target="#b35">[36]</ref> for a given node in the network which are not explicitly present as nodes in the network. AND/OR graphs, using which such implications can be derived, have been introduced in <ref type="bibr" target="#b35">[36]</ref>.</p><p>2) Our techniques operate on a gate-level netlist description. As mentioned, this is of advantage if specific technical information shall be considered in the optimization process. However, it has not yet been considered how the presented techniques can handle circuits with complex gates in an efficient way. Our tool, HANNIBAL, at this point, is limited to handling only the basic gate types, AND, OR, NAND, NOR, INV, XOR. Future work will therefore extend our techniques to handling complex gates so that arbitrary libraries can be processed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. APPLICATION TO LOGIC VERIFICATION</head><p>The described minimization approach can also be applied to logic verification. Formal logic verification of integrated circuits has become of great interest for many industrial designers and manufacturers of highly integrated circuits. Especially, in safety-critical applications, it is of great importance to verify that the implemented logic circuit is equivalent to its specification. When verifying digital circuits, an important subproblem is to check whether two combinational circuits are functionally equivalent. Traditionally, this problem is approached by generating a canonical ( unique) form of the circuits to be verified. The circuits are equivalent if their canonical forms are isomorphic. Unfortunately, canonical forms of Boolean functions may grow extremely large even for relatively small designs. The most compact canonical forms known to date are Reduced Ordered Binary Decision Diagrams (ROBDD's) <ref type="bibr" target="#b8">[9]</ref> and related graph representations of Boolean functions. Therefore, binary decision diagrams (BDD's) have become very popular for solving logic verification problems. Some classes of circuits, however, are not amenable to a BDD analysis, since the size of the BDD's grows exponentially with the size of the circuit.</p><p>More recently, to overcome the limitations of BDD-based approaches, a different approach to logic verification has been proposed in <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b22">[23]</ref> which exploits the structural "similarity" between the designs. Instead of producing canonical forms these techniques extract the similarity between designs by ATPG and implications between signals in the two circuits. These techniques have only little memory requirements and proved successful in verifying circuits that cannot be verified by BDD-based approaches. Further developments based on these techniques have been proposed in <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b28">[29]</ref>, and <ref type="bibr" target="#b36">[37]</ref>. Note, however, that such techniques may require excessive amounts of central processing unit (CPU)-time if the circuits have little structural similarity. Therefore, it is an important problem to study how to exploit the "similarity" between designs as efficiently as possible. In this section, we propose to use the presented optimization procedure for this purpose. There is a wealth of powerful synthesis methods, and it should be noted that many of these methods can also be useful in logic verification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Logic Verification by Optimization</head><p>Logic verification as proposed by <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b22">[23]</ref> relies on combining the circuits to be verified as shown in Fig. <ref type="figure" target="#fig_11">10</ref>. This construction has been called miter in <ref type="bibr" target="#b4">[5]</ref> and represents a circuit, which maps the verification problem to solving the satisfiability problem for the output line . In <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b22">[23]</ref>, a test generator is used for this purpose. Proving whether the output of the miter is satisfiable or not is generally a very complex problem. To overcome this difficulty, the approaches in <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b22">[23]</ref> make use of the fact that structural similarity between the two designs can help to break the problem down. In <ref type="bibr" target="#b22">[23]</ref>, implications are identified between different signals of the subcircuits, and these implications are stored at the respective nodes. Similarly, the complexity of the verification problem can be reduced by identifying signals in one circuit which can be used to substitute signals in the other circuit <ref type="bibr" target="#b4">[5]</ref>.</p><p>Making physical connections between the circuits or storing of implications have a similar effect. They simplify the reasoning for the satisfiability solver by introducing "short cuts" between the circuits so that the satisfiability solver does not necessarily need to fully exhaust both circuits. This has been shown in <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b22">[23]</ref> if the satisfiability solver is a test generator and in <ref type="bibr" target="#b19">[20]</ref> and <ref type="bibr" target="#b28">[29]</ref> if the satisfiability solver is based on BDD's.</p><p>Note that this type of approach works well if the circuits for comparison have a certain degree of similarity but it may fail otherwise. Therefore, it is important to investigate what techniques can capture a wide spectrum of similarity in an efficient way. The techniques of <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b22">[23]</ref> rely on relatively strict requirements. The approach of <ref type="bibr" target="#b4">[5]</ref> requires that lines in one circuit can be replaced by lines in the other circuit exploiting observability don't cares. In <ref type="bibr" target="#b19">[20]</ref> or <ref type="bibr" target="#b22">[23]</ref>, it is required that there exist logic implications, e.g., in circuit implies in circuit . This can be a looser requirement than demanding a substitution, but on the other hand, <ref type="bibr" target="#b19">[20]</ref> and <ref type="bibr" target="#b22">[23]</ref> do not exploit observability don't cares.</p><p>Taking all of this into account suggests that the verification problem should be simplified effectively by performing logical transformations in the miter so that logic common to the two designs can be extracted and shared. If the circuits are equivalent, then one circuit must eventually be merged into the other circuit. As a special case, the substitutions of <ref type="bibr" target="#b4">[5]</ref> perform such an operation. More generally, any known synthesis technique can be used to accomplish this task. The general goal is to optimize the miter. If the miter is reduced to a constant zero, the two circuits are proved equivalent. If this is not (or only partially) possible, then it must be attempted to generate a distinguishing vector using ATPG.</p><p>If the circuits have a fair amount of structural similarity, this means that the miter can be optimized by a sequence of fairly local circuit transformations. If the circuits become less similar, then deriving these transformations becomes more and more complex, and it becomes important to fully exploit the range and power of modern synthesis techniques. The advantage of formulating verification as a miter optimization problem is that the power of modern synthesis techniques becomes available to the difficult problem of logic verification.</p><p>As experimentally confirmed in Section VII, circuit transformations derived by indirect implications cover a large spectrum of the circuit manipulations performed in standard synthesis procedures like <ref type="bibr" target="#b7">[8]</ref>. Further, since implications permit an easy and effective guidance of the optimization process, we base our verification procedure on the optimization procedure of Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Heuristic Guidance in a Miter</head><p>Optimization in a miter has special characteristics which are discussed in this section with respect to the optimization procedure of Section V.</p><p>Selecting Implications: Using our approach, it must be attempted to identify implications that are valid between two nodes that belong to different subcircuits of the miter. If the corresponding transformations are performed, this introduces a sharing of logic between the circuits. Enforcing a sharing of logic between the circuits has two beneficial effects. It generally reduces the size of the miter, and it tends to increase the degree of similarity in the remaining, unshared parts of the circuits if the original circuits are equivalent. If the two networks are forced to share the same subfunctions, this leaves less "freedom" for the implementation of the remaining parts. This is illustrated in the following example.</p><p>Example 6.1: Fig. <ref type="figure" target="#fig_12">11</ref> shows two circuit examples that shall be verified to be equivalent. The circuits are combined to form a miter. For reasons of clarity, we depict the circuits without the extra logic to form the miter. Consider signal in the upper circuit and signal in the lower circuit. By recursive learning, it is possible to identify the -implication . The reader may verify that any test for , stuck-at-one produces the value assignment . According to Section VI, we can perform the circuit transformation as shown in Fig. <ref type="figure" target="#fig_2">12</ref>.</p><p>In the transformed circuit, untestable faults can be identified as indicated in Fig. <ref type="figure" target="#fig_2">12</ref>. Removing these redundancies leads to the circuit in Fig. <ref type="figure" target="#fig_14">13</ref>. Note that this transformation has not only introduced a sharing of logic between the two circuits and reduced the size of the miter, it has also increased the degree of structural similarity in the remaining unshared portions of the circuit. As a matter of fact, in this example, the remaining circuit portions are now structurally identical and can be shared by a sequence of very simple circuit transformations.</p><p>Substitution: Often, a lot of CPU-time can be saved by restricting the circuit transformations to node substitutions. Notice in Example 6.1 that node in the upper circuit is substituted by node in the lower circuit after removing the redundancy , stuck-at-zero. Often it may be sufficient to restrict all transformations to only finding such substitutions <ref type="bibr" target="#b4">[5]</ref>. In this case, if a transformation has been performed for an implication between two nodes and as given in Theorems 4.2-4.5, redundancy elimination needs to be performed only for the appropriate fault at signal . This is faster than considering all faults in the circuit, but on the other hand, it overlooks miter transformations which cannot be obtained by a simple substitution. Therefore, we pass through the circuit several times. In the early passes of our verification procedure, we restrict the redundancy check to the node to be substituted. In the later passes we perform redundancy elimination in the whole circuit.</p><p>ATPG in a Miter: Finally, another important aspect should be considered when running the optimization approach of Section V in a miter. The described method heavily relies on evaluating circuit transformations by ATPG. However, for many target faults in the circuits for comparison, the ATPG problem becomes severely more difficult if the circuits are connected to form a miter. In fact, a large number of faults become redundant, but proving these redundancies practically has the same complexity as the verification problem itself. The reason for this is the global reconvergence created by the miter. Therefore, the ATPG tool may waste a lot of time on numerous target faults which eventually have to be aborted.</p><p>The effect of the global miter reconvergence on the ATPG process can be eliminated by the following trick. When performing ATPG or fault simulation, faults are declared "detected" as soon as the fault signal has reached the outputs of the subcircuits, i.e., if it has reached the inputs of the XOR-tree that forms signal . In Fig. <ref type="figure" target="#fig_11">10</ref>, these signals are labeled to . Alternatively, the XOR-portion of the miter could be removed during the ATPG-procedure. Note that this is extremely important for an efficient ATPG-process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. EXPERIMENTAL RESULTS</head><p>The described methods have been implemented by making extensions to the HANNIBAL tool system. For efficient fault simulation, we integrated the public domain fault simulator FSIM <ref type="bibr" target="#b23">[24]</ref> into HANNIBAL. HANNIBAL contains the recursive learning technique of <ref type="bibr" target="#b21">[22]</ref> and has options to apply this technique to test generation <ref type="bibr" target="#b21">[22]</ref>, logic verification <ref type="bibr" target="#b22">[23]</ref>, and logic optimization. Section VII-A shows the results for logic optimization. The results for logic verification using implications and BDD's have been shown in <ref type="bibr" target="#b28">[29]</ref>. In Section VII-B, we show results for the verification part of HANNIBAL enhanced by the optimization approach presented in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Results for Logic Minimization</head><p>We compare HANNIBAL with other state-of the art optimization tools. For a fair comparison, it is very important to take into account that several different ways of measuring the area costs are currently common practice. HANNIBAL and RAMBO <ref type="bibr" target="#b15">[16]</ref> operate on a gate netlist description and measure the area in terms of the number of connections. A connection is an input to a gate with at least two inputs, i.e., single-input gates (inverters, buffers) are not counted. Technology-independent optimization tools like SIS measure the area in terms of numbers of literals. A literal is a variable or its complement used to describe the Boolean function at a node in the Boolean network. In a gate netlist, the number of literals can be obtained by counting the number of inputs of the fanout-free zones (FFZ's) in the network. For a fair evaluation of our tool, we present our results in terms of both, number of connections and number of literals. For RAMBO and HANNIBAL, the number of literals (factored form) has been obtained by reading the optimized circuits into SIS and postprocessing them such that a technology-independent factored form is obtained. For this purpose, we used a SIS script obtained from <ref type="bibr" target="#b11">[12]</ref> which performs some standard network manipulations. To count connections for SIS, we map the optimized circuit to a generic library which contains the basic gates that are allowed in our netlist description.</p><p>Note that comparing connections or literals may slightly bias the results. Since RAMBO and HANNIBAL optimize in terms of connections whereas SIS uses literals, comparing connections can bias the results in favor of HANNIBAL and RAMBO. Comparing literals gives a certain advantage to SIS. Therefore, for all circuits we always present both area measures.</p><p>In all experiments, HANNIBAL passes through the circuit four times performing expansions at every node where recursive learning can identify indirect implications. The recursion depth is 'one' for the first two passes and 'two' for the final two passes. We also experimented with higher depth of recursion. It turned out that recursion depth higher than 'two' did not lead to improved optimization results because a transformation that can be derived by high recursion depth can usually also be obtained by a sequence of local transformations derived by small recursion depth. (Anyway, for the larger designs a recursion depth of 'four' and more is usually not affordable in terms of CPU-time.)</p><p>Table <ref type="table" target="#tab_1">II</ref> shows results for SIS 1.2, RAMBO C and HAN-NIBAL. SIS 1.2 is run using script.rugged which includes the powerful techniques of <ref type="bibr" target="#b30">[31]</ref> and <ref type="bibr" target="#b33">[34]</ref>. No preoptimization is used to process the circuits in RAMBO and HANNIBAL. As can be noted, for most benchmark circuits, HANNIBAL produces the smallest circuits. This is quite remarkable because it shows that most circuit manipulations performed by conventional technology-independent minimization techniques are covered by the netlist transformations presented in this paper. In particular, heuristic guidance by indirect implications proved surprisingly powerful.</p><p>In the next experiment, it is examined how much optimization is possible by HANNIBAL if the circuits are preprocessed by SIS. As shown in Table <ref type="table" target="#tab_2">III</ref>, substantial area gains are possible in many cases. For seven out of 25 circuits, the gain is more than 20%. Also note that the CPU-times for HANNIBAL are significantly shorter in many cases if the circuits are run through a technology-independent minimization first, like in the experiment of Table <ref type="table" target="#tab_2">III</ref>.</p><p>Finally, we also compare our results with <ref type="bibr" target="#b9">[10]</ref>. In <ref type="bibr" target="#b9">[10]</ref> the circuit is mapped to a library with only two-input gates, and results are only shown after preprocessing with SIS. Table <ref type="table" target="#tab_3">IV</ref> shows the results for RAMBO (taken from <ref type="bibr" target="#b9">[10]</ref>), PERTURB/SIMPLIFY <ref type="bibr" target="#b9">[10]</ref>, and HANNIBAL if the area is measured in terms of two-input gates. We take the subset of the above benchmarks for which results are shown in <ref type="bibr" target="#b9">[10]</ref>, and all circuits are preoptimized by SIS. As can be noted, HANNIBAL obtains smaller or equal circuits than RAMBO or PERTURB/SIMPLIFY for all circuits. Note that the results of HANNIBAL and RAMBO could be somewhat improved when compared with <ref type="bibr" target="#b9">[10]</ref> if their cost function was changed to optimize the number of two-input gates.</p><p>Further experiments confirmed the heuristic that indirect implications indicate promising divisors. We examined how many indirect -implications existed in the circuits before and after optimization. For the ISCAS85 circuits, Table <ref type="table" target="#tab_4">V</ref> shows the number of indirect -implications that have been identified by recursive learning with depth '2' for the original circuits as  well as for the optimized circuits. We note that HANNIBAL reduces the number of indirect -implications drastically for all circuits. It is interesting that this is also true for SIS in most cases, which confirms that optimization in general is related to reducing the number of indirect implications in the circuit. The results of Table V reflect that many (but not all) "good" divisors for optimization can be obtained by indirect implication. Also, note that Table V explains why the CPUtimes for HANNIBAL are generally shorter if HANNIBAL is run after SIS. If SIS is used first, there are less indirect implications and, hence, less expansions need to be performed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Results for Logic Verification</head><p>We demonstrate the performance of our verification technique based on optimization by means of the public domain multiplier c6288 which we verified against its optimized version. The optimized version has been obtained by SIS1.2 <ref type="bibr" target="#b7">[8]</ref> using script.rugged. The other circuits listed in Table VI have been obtained from Mentor Graphics Autologic II Logic Synthesis Team. The designs are highly datapath oriented, contain multipliers and rotators and were created in Verilog, synthesized by Autologic II to a commercial ASIC vendor library. The designs were synthesized with different design goals in mind (such as area or performance). The test cases also contain (intentionally) nonequivalent designs. The results show that logic verification based on the optimization procedure performs efficiently and robustly for these practical verification problems. The proposed technique may be outperformed by techniques such as <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b22">[23]</ref> if the circuits have a high degree of similarity. On the other hand, for circuits with less structural similarity, logic verification by optimization provides a general framework for a more robust verification approach. Our results show that the optimization procedure of Section V can be tailored for efficient miter optimization. In all examined cases the miter could be minimized to a constant signal '0' within short CPU-times.</p><p>As described in Section VI, our verification approach uses two phases. The first phase performs substitution only, and the second phase considers more general transformations by running redundancy elimination in the whole circuit. In all cases, the first phase helped to significantly reduce the size of the miter before starting the more CPU-time expensive phase two. All circuit transformations have been derived by recursive learning with recursion depth '2'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</head><p>This work has introduced an ATPG-based generalization of Shannon's expansion that provides an adequate theoretical description for ATPG-based logic synthesis. Our research was originally motivated by the observation that indirect implications indicate suboptimal circuitry. We have presented an ATPG-based approach to logic optimization deriving circuit transformations from implications. It has been shown that implications can be used to determine for each node those functions in the network with respect to which this node has only one cofactor. Furthermore, it has been shown that the complexity of performing implications can be related to potential area reduction by Boolean division. This introduces new heuristic guidance and a different view on logic optimization problems. Our results clearly prove the great potential of our method. They also show that our notion of "indirect" implications is indeed most helpful to identify good Boolean divisors.</p><p>As has been shown, netlist optimization by HANNIBAL is competitive with technology independent minimization techniques. Future work will, therefore, exploit the main advantage of this approach. Optimization on the gate netlist provides much better insight in the technical properties of the design and, therefore, permits a better guidance when trying to achieve specific optimization goals. It has already been shown that the presented approach is very useful when optimizing for random pattern testability <ref type="bibr" target="#b10">[11]</ref> and for low-power consumption <ref type="bibr" target="#b27">[28]</ref>.</p><p>Further, we formulated logic verification as an optimization problem and demonstrated the usefulness of our optimization approach for logic verification. Our verification method successfully verified a number of industrial designs. Current research examines extending the set of circuit transformations using the concept of AND/OR graphs <ref type="bibr" target="#b35">[36]</ref>. This is expected to improve the capabilities of HANNIBAL for both logic synthesis and formal verification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Implications in combinational circuit<ref type="bibr" target="#b34">[35]</ref>.</figDesc><graphic coords="2,375.84,59.58,111.60,51.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Shannon's expansion by ATPG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 ) 2 )</head><label>12</label><figDesc>Idempotent laws: Commutative laws: fulfilled by construction (definition) of primitive gates AND, OR. 3) Associative laws: redundancy elimination for stuck-at-one fault at in second summand: redundancy elimination for stuck-at-one at signal with constant one: 7) Unary operation:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Indirect implication and optimization.</figDesc><graphic coords="6,44.40,59.58,248.40,72.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Lemma 4 . 2 :</head><label>42</label><figDesc>Consider the transformation . Then if and only if the implication is true. Lemma 4.3: Consider the transformation . Then if and only if the implication is true. Lemma 4.4: Consider the transformation . Then if and only if the implication is true.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Theorem 4 . 3 :</head><label>43</label><figDesc>Analogous to Lemma 4.2. Theorem 4.4: Analogous to Lemma 4.3. Theorem 4.5: Analogous to Lemma 4.4. Theorems 4.2-4.5 represent the basis for the circuit transformations in our optimization method. As the transformations given in Theorems 4.2-4.5 represent special simplified cases of (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Combinational network after transformation       using internal node  as divisor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Combinational network after reduction by redundancy elimination.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Extraction of common kernel, , by -implication.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Replacing by permissible function  .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Optimized circuit with logic sharing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Exploiting structural similarity in a miter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Circuits to be verified.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Circuit transformation for -implication        .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Miter subcircuits after redundancy elimination.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II MINIMIZATION</head><label>II</label><figDesc>RESULTS FOR SIS_1.2, RAMBO, AND HANNIBAL (SUNSPARC 5)    </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III RESULTS</head><label>III</label><figDesc>FOR HANNIBAL AFTER PREPROCESSING WITH SIS (SUNSPARC 5)    </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV EXPERIMENTAL</head><label>IV</label><figDesc>COMPARISON WITH<ref type="bibr" target="#b9">[10]</ref> </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V INDIRECT</head><label>V</label><figDesc>-IMPLICATIONS BEFORE AND AFTER OPTIMIZATION</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE VI LOGIC</head><label>VI</label><figDesc>VERIFICATION WITH HANNIBAL (SPARC 5)</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank Mentor Graphics Inc. and in particular, A. Srinivasan for providing us with industrial designs for our experimental evaluation. The authors are also grateful to M. Cobenuss for his help in various ways.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper was recommended by Associate Editor, F. Somenzi. This work was supported in part by NSF Grant MIP-9311185. W. Kunz and D. Stoffel are with the Max-Planck-Society, Fault-</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Wolfgang <ref type="bibr">Kunz</ref>  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><surname>Abramovici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Breuer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Digital Systems Testing and Testable Design</title>
		<meeting><address><addrLine>Rockville, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The decomposition of switching functions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Ashenhurst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp. Theory Switching</title>
		<meeting>Int. Symp. Theory Switching<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1959">1959</date>
			<biblScope unit="page" from="74" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Global flow optimization in automatic logic design</title>
		<author>
			<persName><forename type="first">L</forename><surname>Berman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Trevillyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Computer-Aided Design</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="557" to="564" />
			<date type="published" when="1991-05">May 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Redundancy and don&apos;t cares in logic synthesis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="947" to="952" />
			<date type="published" when="1983-10">Oct. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Verification of large synthesized designs</title>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Computer-Aided Design</title>
		<meeting>Int. Conf. Computer-Aided Design<address><addrLine>Santa Clara, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993-11">Nov. 1993</date>
			<biblScope unit="page" from="534" to="537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">F</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boolean</forename><surname>Reasoning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Kluwer</publisher>
			<pubPlace>Norwell, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Logic Minimization Algorithms for VLSI Synthesis</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Hachtel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Mcmullen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Norwell</title>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>Kluwer</publisher>
			<pubPlace>MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">MIS: Multi-level interactive logic optimization system</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rudell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Computer-Aided Design</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1062" to="1081" />
			<date type="published" when="1987-11">Nov. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Graph-based algorithms for Boolean function manipulation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bryant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="677" to="691" />
			<date type="published" when="1986-08">Aug. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Perturb and simplify: Multilevel Boolean network optimizer</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marek-Sadowska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Computer-Aided Design</title>
		<meeting>Int. Conf. Computer-Aided Design<address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-11">Nov. 1994</date>
			<biblScope unit="page" from="2" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">LOT: Optimization with testability-New transformations using recursive learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kunz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Computer-Aided Design</title>
		<meeting>Int. Conf. Computer-Aided Design<address><addrLine>San Jose</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-11">Nov. 1995</date>
			<biblScope unit="page" from="318" to="325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Cheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994-04">Apr. 1994</date>
		</imprint>
	</monogr>
	<note>private communication</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A generalized tree circuit</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Curtis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Assoc. Comput. Mach</title>
		<imprint>
			<biblScope unit="page" from="484" to="496" />
			<date type="published" when="1961-08">Aug. 1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Optimization of combinational logic circuits based on compatible gates</title>
		<author>
			<persName><forename type="first">M</forename><surname>Daminani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">De</forename><surname>Micheli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Des. Automat. Conf</title>
		<meeting>Des. Automat. Conf</meeting>
		<imprint>
			<date type="published" when="1993-06">June 1993</date>
			<biblScope unit="page" from="631" to="636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">New verification framework using generalized logic relationships and structural transformations</title>
		<author>
			<persName><forename type="first">P</forename><surname>Debjyoti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Pradhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Sci</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<pubPlace>College Station, TX</pubPlace>
		</imprint>
	</monogr>
	<note>Texas A&amp;M Univ.. Tech. Rep. 95-045</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sequential logic optimization by redundancy addition and removal</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Entrena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Computer-Aided Design</title>
		<meeting>Int. Conf. Computer-Aided Design</meeting>
		<imprint>
			<date type="published" when="1993-11">Nov. 1993</date>
			<biblScope unit="page" from="310" to="315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the acceleration of test generation algorithms</title>
		<author>
			<persName><forename type="first">H</forename><surname>Fujiwara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shimono</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th Int. Symp. Fault Tolerant Comput</title>
		<meeting>13th Int. Symp. Fault Tolerant Comput</meeting>
		<imprint>
			<date type="published" when="1983">1983</date>
			<biblScope unit="page" from="98" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Performance enhancements in BOLD using implications</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hachtel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jacoby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moceyunas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Morrison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Computer-Aided Design</title>
		<meeting>Int. Conf. Computer-Aided Design</meeting>
		<imprint>
			<date type="published" when="1988-11">Nov. 1988</date>
			<biblScope unit="page" from="94" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Exploiting communication complexity for multi-level logic synthesis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Irwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Computer-Aided Design</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1017" to="1027" />
			<date type="published" when="1990-10">Oct. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Advanced verification techniques based on learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fujita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Des. Automat. Conf. (DAC)</title>
		<meeting>Des. Automat. Conf. (DAC)</meeting>
		<imprint>
			<date type="published" when="1995-06">June 1995</date>
			<biblScope unit="page" from="420" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A topological search algorithm for ATPG</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kirkland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th Des. Automat. Conf</title>
		<meeting>24th Des. Automat. Conf</meeting>
		<imprint>
			<date type="published" when="1987-06">June 1987</date>
			<biblScope unit="page" from="502" to="508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Recursive learning: A new implication technique for efficient solutions to CAD problems: Test, verification, and optimization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Kunz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Pradhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Computer-Aided Design</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1143" to="1158" />
			<date type="published" when="1994-09">Sept. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">HANNIBAL: An efficient tool for logic verification based on recursive learning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Kunz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Computer-Aided Design</title>
		<meeting>Int. Conf. Computer-Aided Design<address><addrLine>Santa Clara, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993-11">Nov. 1993</date>
			<biblScope unit="page" from="538" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An efficient forward fault simulation algorithm based on the parallel pattern single fault propagation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Ha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Test Conf</title>
		<meeting>Int. Test Conf</meeting>
		<imprint>
			<date type="published" when="1991-09">Sept. 1991</date>
			<biblScope unit="page" from="946" to="953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">BDD-based computation of common decomposition functions of multi-output boolean functions</title>
		<author>
			<persName><forename type="first">P</forename><surname>Molitor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Scholl</surname></persName>
		</author>
		<idno>TR-02/1993</idno>
		<imprint>
			<date type="published" when="1993">1993</date>
			<pubPlace>Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Universitt des Saarlandes</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Optimum functional decomposition using encoding</title>
		<author>
			<persName><forename type="first">R</forename><surname>Murgai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vincentelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM/IEEE Des. Automat. Conf. (DAC)</title>
		<meeting>ACM/IEEE Des. Automat. Conf. (DAC)</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="408" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The transduction method-Design of logic networks based on permissible functions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Muroga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kambayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Culliney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="page" from="1404" to="1424" />
			<date type="published" when="1989-10">Oct. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Implication-based gate level synthesis for low power</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Swarna</surname></persName>
		</author>
		<idno>TR-95-042</idno>
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Sci</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<pubPlace>College Station, TX</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
	<note>Texas A&amp;M Univ.</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A novel verification framework combining structural and OBDD methods in a synthesis environment</title>
		<author>
			<persName><forename type="first">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kunz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pradhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Des. Automat. Conf. (DAC)</title>
		<meeting>Des. Automat. Conf. (DAC)</meeting>
		<imprint>
			<date type="published" when="1995-06">June 1995</date>
			<biblScope unit="page" from="414" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A method to calculate necessary assignments in algorithmic test pattern generation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rajski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Test Conf</title>
		<meeting>Int. Test Conf</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="25" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Testability preserving transformations in multi-level logic synthesis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rajski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vasudevamurthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Test Conf</title>
		<meeting>Int. Test Conf</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="265" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Introduction of permissible bridges with application to logic optimization after technology mapping</title>
		<author>
			<persName><forename type="first">B</forename><surname>Rohfleisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Brglez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EDAC/ETC/EUROASIC 1994</title>
		<meeting>EDAC/ETC/EUROASIC 1994</meeting>
		<imprint>
			<biblScope unit="page" from="87" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Diagnosis of automata failures: A calculus and a method</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM J. Res. Develop</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="278" to="291" />
			<date type="published" when="1966-07">July 1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Extracting local don&apos;t cares for network optimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Savoj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Touati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Computer-Aided Design</title>
		<meeting>Int. Conf. Computer-Aided Design</meeting>
		<imprint>
			<date type="published" when="1991-11">Nov. 1991</date>
			<biblScope unit="page" from="514" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">SOCRATES: A highly efficient automatic test pattern generation system</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sarfert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Computer-Aided Design</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="1991-04">Apr. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">AND/OR graphs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Stoffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kunz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gerber</surname></persName>
		</author>
		<idno>MPI-I-95-602</idno>
		<imprint>
			<date type="published" when="1995">1995</date>
			<pubPlace>Germany</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Logic and transistor circuit verification using regression testing and hierarchical recursive learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><surname>Shao</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>submitted for publication</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Functional multiple-output decomposition: Theory and an implicit algorithm</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wurth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Eckl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Antreich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Des. Automat. Conf. (DAC)</title>
		<meeting>Des. Automat. Conf. (DAC)</meeting>
		<imprint>
			<date type="published" when="1995-06">June 1995</date>
			<biblScope unit="page" from="54" to="59" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
