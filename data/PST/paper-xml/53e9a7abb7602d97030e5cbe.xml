<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Differential evolution algorithm with ensemble of parameters and mutation strategies</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010-05-10">10 May 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">R</forename><surname>Mallipeddi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Electronic Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<postCode>639798</postCode>
									<settlement>Singapore</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Electronic Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<postCode>639798</postCode>
									<settlement>Singapore</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Q</forename><forename type="middle">K</forename><surname>Pan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science</orgName>
								<orgName type="institution">Liaocheng University</orgName>
								<address>
									<postCode>252059</postCode>
									<settlement>Liaocheng</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Tasgetiren</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Industrial Engineering</orgName>
								<orgName type="institution">Yasar University</orgName>
								<address>
									<settlement>Bornova, Izmir</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Differential evolution algorithm with ensemble of parameters and mutation strategies</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2010-05-10">10 May 2010</date>
						</imprint>
					</monogr>
					<idno type="MD5">3048B1892D6F454C14D8D6D5C0E61750</idno>
					<idno type="DOI">10.1016/j.asoc.2010.04.024</idno>
					<note type="submission">Received 30 July 2009 Received in revised form 4 March 2010 Accepted 30 April 2010</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Differential evolution Global optimization Parameter adaptation Ensemble Mutation strategy adaptation</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Differential evolution (DE) has attracted much attention recently as an effective approach for solving numerical optimization problems. However, the performance of DE is sensitive to the choice of the mutation strategy and associated control parameters. Thus, to obtain optimal performance, time-consuming parameter tuning is necessary. Different mutation strategies with different parameter settings can be appropriate during different stages of the evolution. In this paper, we propose to employ an ensemble of mutation strategies and control parameters with the DE (EPSDE). In EPSDE, a pool of distinct mutation strategies along with a pool of values for each control parameter coexists throughout the evolution process and competes to produce offspring. The performance of EPSDE is evaluated on a set of boundconstrained problems and is compared with conventional DE and several state-of-the-art parameter adaptive DE variants.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Evolutionary algorithms (EAs), inspired by Darwinian theory of evolution, are well known for their ability to deal with nonlinear and complex optimization problems. The primary advantage of EAs over other numerical methods is that they just require the objective function values, while properties such as differentiability and continuity are not necessary. However the performance of an EA depends on the encoding schemes, evolutionary operators and parameter settings such as probability of mutation and population size. Choosing suitable parameter values is a problem dependant task and generally requires time-consuming trial-anderror parameter tuning process. This approach is not appropriate if the global optimization is required in an automated environment or if the user has no experience in the fine art of the control parameter tuning. To overcome this, different parameter adaptation schemes have been presented <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref>. The parameter adaptation techniques can be categorized as <ref type="bibr" target="#b4">[5]</ref>: deterministic, adaptive and self-adaptive. Deterministic rules modify the parameters according to certain predefined rationales without utilizing any feedback from the search process. Adaptive rules incorporate feedback from the search process to guide the parameter adaptation. Self-adaptive rules directly encode parameters into the individuals and evolve them together with the encoded solutions. The most appropriate parameter values produce better offspring that are more likely to survive and propagate the better parameter values <ref type="bibr" target="#b6">[7]</ref>. Generally speaking, selfadaptive rules refer to those that mainly utilize the feedback from the search process to guide the updating of parameters. In this paper, we propose an ensemble approach, where each parameter has a pool of values competing to produce future offspring based on their success in the past generations. Although the ensemble concept is general and can be applied with any evolutionary algorithm framework, we demonstrate it using the differential evolution (DE) algorithm.</p><p>DE proposed by Storn and Price <ref type="bibr" target="#b7">[8]</ref> is a fast and simple technique which performs well on a wide variety of problems. DE is a population based stochastic search technique, which is inherently parallel. DE has been successfully applied in diverse fields such as mechanical engineering <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>, communication <ref type="bibr" target="#b10">[11]</ref>, optics <ref type="bibr" target="#b11">[12]</ref>, pattern recognition <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref>, signal processing <ref type="bibr" target="#b15">[16]</ref> and power systems <ref type="bibr" target="#b16">[17]</ref>. The performance <ref type="bibr" target="#b17">[18]</ref> of the DE algorithm is sensitive to the mutation strategy and respective control parameters such as the population size (NP), crossover rate (CR) and the scale factor (F). The best settings for the control parameters can be different for different optimization problems and the same functions with different requirements for consumption time and accuracy. Therefore, to successfully solve a specific optimization problem, it is generally necessary to perform a time-consuming trial-and-error search for the most appropriate strategy and to tune its associated parameter values. However, such a trial-and-error search process suffers from high computational costs. The population of DE may evolve through different regions in the search space, within which different strategies <ref type="bibr" target="#b18">[19]</ref> with different parameter settings may be more effective than others. Although different partial adaptation schemes have been proposed <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref> to overcome the time-consuming trialand-error procedure, we demonstrate the superior performance of the proposed ensemble strategy with adaptation of all parameters and mutation strategies.</p><p>The reminder of this paper is organized as follows: Section 2 presents the classical DE algorithm, while Section 3 presents a literature survey on different mutation strategies and parameter settings used in DE. Section 4 presents the proposed ensemble of mutation strategies and parameters in DE (EPSDE) algorithm. Section 5 presents the experimental results and discussions while Section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The DE aLGORITHM</head><p>Differential evolution (DE) is a parallel direct search method which utilizes NP D-dimensional parameter vectors, so-called individuals, which encode the candidate solutions, i.e. X i,G = {x 1 i,G , . . . , x D i,G }, i = 1, . . . , NP. The initial population should cover the entire search space as much as possible by uniformly randomizing the initial individuals within the search space constrained by the prescribed minimum and maximum parameter bounds X min = {x 1 min , . . . , x D min } and X max = {x 1 max , . . . , x D max }. For example, the initial value of the jth parameter of the ith individual at generation G = 0 is generated by:</p><formula xml:id="formula_0">x j i,0 = x j min + rand(0, 1) • (x j max -x j min ) j = 1, 2, . . . , D<label>(1)</label></formula><p>where rand(0, 1) represents a uniformly distributed random variable within the range [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Mutation operation</head><p>After initialization, DE employs the mutation operation to produce a mutant vector V i,G with respect to each individual X i,G , so-called target vector, in the current population. For each target vector X i,G at the generation G, its associated mutant vector</p><formula xml:id="formula_1">V i,G = {v 1 i,G , v 2 i,G , . . . , v D</formula><p>i,G } can be generated via certain mutation strategy. The most frequently used mutation strategies are "DE/best/1" <ref type="bibr" target="#b10">[11]</ref> </p><formula xml:id="formula_2">: V i,G = X best,G + F • (X r j 1 ,G -X r i 2 ,G )<label>(2)</label></formula><p>"DE/best/2" <ref type="bibr" target="#b10">[11]</ref> :</p><formula xml:id="formula_3">V i,G = X best,G + F • (X r 1 i ,G -X r i 2 ,G ) + F.(X r 3 i ,G -X r i 4 ,G )<label>(3)</label></formula><p>"DE/rand/1" <ref type="bibr" target="#b10">[11]</ref> :</p><formula xml:id="formula_4">V i,G = X r 1 i ,G + F • (X r 2 i ,G -X r i 3 ,G )<label>(4)</label></formula><p>"DE/rand/2" <ref type="bibr" target="#b18">[19]</ref> :</p><formula xml:id="formula_5">V i,G = X r 1 i ,G + F • (X r 2 i ,G -X r i 3 ,G ) + F • (X r i 4 ,G -X r i 5 ,G )<label>(5)</label></formula><p>"DE/rand-to-best/1" <ref type="bibr" target="#b10">[11]</ref> or "DE/target-to-best/1" <ref type="bibr" target="#b22">[23]</ref> V</p><formula xml:id="formula_6">i,G = X i,G + K • (X best,G -X i,G ) + F • (X r 1 i ,G -X r i 2,G )<label>(6)</label></formula><p>"DE/rand-to-best/2" <ref type="bibr" target="#b18">[19]</ref> or "'DE/target-to-best/2"</p><formula xml:id="formula_7">V i,G = X i,G + K • (X best,G -X i,G ) + F • (X r i 1 ,G -X r i 2 ,G + X r i 3 ,G -X r i 4 ,G )<label>(7)</label></formula><p>"DE/current-to-rand/1" <ref type="bibr" target="#b23">[24]</ref> U</p><formula xml:id="formula_8">i,G = X i,G + K • (X r i 1 ,G -X i,G ) + F • (X r i 2 ,G -X r i 3 ,G )<label>(8)</label></formula><p>The indices r i 1 , r i 2 , r i 3 , r i 4 , r i 5 are mutually exclusive integers randomly generated within the range <ref type="bibr" target="#b0">[1,</ref><ref type="bibr">NP]</ref>, which are also different from the index i. These indices are randomly generated once for each mutant vector. The scale factor F is a positive control parameter for scaling the difference vector. X best,G is the best individual vector with the best fitness value in the population at generation G. K is randomly chosen within the range [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Crossover operation</head><p>After the mutation phase, crossover operation is applied to each pair of the target vector X i,G and its corresponding mutant vector V i,G to generate a trial vector:</p><formula xml:id="formula_9">U i,G = {u 1 i,G , u 2 i,G , . . . , u D i,G }.</formula><p>In the basic version, DE employs the binomial (uniform) crossover defined as follows <ref type="bibr" target="#b24">[25]</ref>:</p><formula xml:id="formula_10">u j i,G = v i i,G if (rand j [0, 1] ≤ CR) or (j = j rand ) x j i,G otherwise j = 1, 2, . . . , D<label>(9)</label></formula><p>In Eq. ( <ref type="formula" target="#formula_10">9</ref>), the crossover rate CR is a user-specified constant within the range [0, 1], which controls the fraction of parameter values copied from the mutant vector. j rand is a randomly chosen integer in the range <ref type="bibr">[1, D]</ref>. The binomial crossover operator copies the jth parameter of the mutant vector V i,G to the corresponding element in the trial vector U i,G if rand j [0, 1] or j = j rand . Otherwise, it is copied from the corresponding target vector X i,G . There exists another exponential crossover operator, in which the parameters of trial vector U i,G are inherited from the corresponding mutant vector V i,G starting from a randomly chosen parameter index till the first time rand j [0, 1]. The remaining parameters of the trial vector U i,G are copied from the corresponding target vector X i,G . The condition j = j rand is introduced to ensure that the trial vector U i,G will differ from its corresponding target vector X i,G by at least one parameter. DE's exponential crossover operator is functionally equivalent to the circular two-point crossover operator <ref type="bibr" target="#b18">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Selection operation</head><p>If the values of some parameters of a newly generated trial vector exceed the corresponding upper and lower bounds, we randomly and uniformly reinitialize them within the pre-specified range. Then the objective function values of all trial vectors are evaluated. After that, a selection operation is performed. The objective function value of each trial vector f(U i,G ) is compared to that of its corresponding target vector f(X i,G ) in the current population. If the trial vector has less or equal objective function value (in a minimization problem) than the corresponding target vector, the trial vector will replace the target vector and enter the population of the next generation. Otherwise, the target vector will remain in the population for the next generation. The selection operation can be expressed as follows:</p><formula xml:id="formula_11">X i,G+1 = U i,G , X i,G , if f (U i,G ) ≤ f (X i,G ) otherwise<label>(10)</label></formula><p>The above three steps are repeated generation after generation until a termination criterion (reaching the maximum number of function evaluations set) is satisfied. The algorithmic description of the DE is summarized in Table <ref type="table">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Literature review</head><p>Differential evolution (DE) algorithm is a floating-point encoded evolutionary algorithm for global optimization over continuous spaces <ref type="bibr" target="#b24">[25]</ref>. Although the DE has attracted much attention recently, the performance of the conventional DE algorithm depends on the chosen mutation strategy and the associated control parameters. The performance of DE becomes more sensitive to the strategy and the associated parameter values when the problem is complex <ref type="bibr" target="#b25">[26]</ref>. Inappropriate choice of mutation strategy and parameters may lead to premature convergence, stagnation or wastage of computational resources <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref>. Initially it was thought that <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b28">29]</ref> the control parameters of DE are not difficult to choose. But due to the complex interaction of control parameters with the DE's performance on hard optimization problems <ref type="bibr" target="#b6">[7]</ref>, choosing an appropriate Table <ref type="table">1</ref> The standard DE algorithm. mutation strategy and control parameters require some expertise. Since DE was proposed various empirical guidelines were suggested for choosing a mutation strategy and its associated control parameter settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Population size (NP)</head><p>Initially NP = 10D was considered as a good choice <ref type="bibr" target="#b10">[11]</ref> for DE to find a global optimum. However, to balance the speed (number of function evaluations) and reliability (ability to find global optimum) different ranges of NP values such as 5D to 10D <ref type="bibr" target="#b24">[25]</ref>, 3D to 8D <ref type="bibr" target="#b25">[26]</ref> and 2D to 40D <ref type="bibr" target="#b29">[30]</ref> were suggested.</p><p>The larger the population size, the higher the probability of finding a global optimum for multi-modal problems is. But, a larger population implies a slower convergence rate requiring a larger number of function evaluations. Therefore, separable and uni-modal functions require smaller population sizes to speed up the convergence, while parameter-linked multi-modal functions require larger populations to avoid premature convergence. In <ref type="bibr" target="#b22">[23]</ref> it is stated that NP = 5D × CR is usually a good low-end default setting, while for highly multi-modal, parameter dependant functions, NP may need to be 10D or higher. However, NP should be larger than a critical value depending on the mutation strategy used <ref type="bibr" target="#b25">[26]</ref>. For example, NP must be at least 4 for DE/rand/1/bin and 5 for DE/best/2/bin, respectively to ensure that DE will have enough mutually different vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Mutation strategies</head><p>The classical DE proposed by Price and Storn uses DE/rand/1/bin, which is most widely used. Later, different DE mutation strategies were proposed with different mutations strategies <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b30">31]</ref>. In <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref> it was stated that a 2 difference vector strategies such as DE/rand/2/bin and DE/best/2/bin are better than DE/rand/1/bin and DE/best/1/bin due to their ability to improve diversity by producing more trial vectors <ref type="bibr" target="#b27">[28]</ref>. DE/best/1/bin and DE/rand-to-best/1/bin are faster on easier optimization problems, but become unreliable when solving highly multi-modal problems. To balance the exploration and exploitation abilities of DE, DE/target-to-best/1/bin scheme with the concept of neighborhood of each population member was proposed <ref type="bibr" target="#b31">[32]</ref>. Even increasing the population size (NP) had a little impact on the convergence probabilities. Classical DE was slower, but more robust than the other strategies that rely on the best-so-far vector. DE/current-to-rand/1/bin being a rotationinvariant strategy can solve rotated problems better than other strategies <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Crossover rate (CR)</head><p>The crossover rate controls which and how many components are mutated in each element of the current population <ref type="bibr" target="#b32">[33]</ref>. The crossover rate CR is a probability 0 ≤ CR ≤ 1 of mixing between trial and target vectors. A large CR speeds up convergence <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref>. In <ref type="bibr" target="#b24">[25]</ref>, it is said that CR = 0.1 is a good initial choice while CR = 0.9 or 1.0 can be tried to increase the convergence speed. In <ref type="bibr" target="#b25">[26]</ref>, a good choice for CR is said to be between 0.3 and 0.9. For separable problems, CR from the range (0, 0.2) is the best while for multimodal, parameter dependant problems CR in the range (0.9, 1.0) is best <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b29">30]</ref>. Based on these observations, CR with non-continuous ranges are also used <ref type="bibr" target="#b33">[34]</ref>. When CR = 1.0 is chosen, the number of trial solutions will be reduced dramatically which may lead to stagnation <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b29">30]</ref>. Therefore, CR = 0.9 or 0.99 can be used instead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Scaling factor (F)</head><p>Scaling factor, F is usually chosen in [0.5, 1] <ref type="bibr" target="#b10">[11]</ref>. The upper limit of F = 1.2 is empirically determined and optimization problems requiring F greater than 1.2 to solve efficiently have not been encountered. In <ref type="bibr" target="#b24">[25]</ref>, it is said that values of F smaller than 0.4 and greater than 1.0 are occasionally effective. The scale factor F, is strictly greater than zero. A larger F increases the probability of escaping from a local optimum <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b29">30]</ref>. While F &gt; 1 can solve many problems the convergence speed decreases making it difficult to converge as the perturbation is larger than the distance between two members. F ≤ 1 is usually both faster and reliable. F must be above a certain critical value to avoid premature convergence to a sub-optimal solution <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b29">30]</ref>, but if F becomes too large, the number of function evaluations to find the optimum grows very quickly. In <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref>, it is said that F = 0.6 or 0.5 would be a good initial choice while in <ref type="bibr" target="#b29">[30]</ref> it is said that F = 0.9 would be a good initial choice. Typical values of F are 0.4-0.95 according to <ref type="bibr" target="#b29">[30]</ref>.</p><p>Zaharie <ref type="bibr" target="#b34">[35]</ref> theoretically proved that DE could converge to global optimum in the long time limit if F can be transformed into a Gaussian random variable. Despite the theoretical proof, it <ref type="bibr" target="#b35">[36]</ref> was proved that transforming F into a Gaussian random variable did not significantly enhance DE's performance. In addition, Price et al. <ref type="bibr" target="#b22">[23]</ref> demonstrated that unless the variance of the randomizing distribution is very small, DE will suffer a significant performance loss on highly conditioned non-separable functions <ref type="bibr" target="#b29">[30]</ref>. Similar to CR, F = 1.0 is not recommended since it reduces the number of potential trial solutions and may lead to stagnation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Overall parameter tuning methods</head><p>Even though the above guidelines are useful for choosing the individual parameters of DE to some extent, the performance of DE is more sensitive to the combination of the mutation strategy and its associated parameters. For a mutation strategy <ref type="bibr" target="#b6">[7]</ref>, a particular value of CR makes the parameter F sensitive while some other values of CR make the same F robust. It was recommended in <ref type="bibr" target="#b30">[31]</ref> to use the mutation strategy DE/current-to-rand/1/bin and parameter setting NP = 20D, K = 0.5, F = 0.8. If the DE converges prematurely, one should increase the value of NP or F, or randomly choose K within the range [0, 1]. If none of the above configuration works, one may try the strategy DE/rand/1/bin with a small CR value.</p><p>From the above, it can be observed that various conflicting conclusions had been drawn regarding the manual parameter tuning of DE, which lack sufficient justifications. To avoid the tuning of parameters by trial-and-error procedure, various techniques have been developed. The scale factor F can be linearly reduced from a maximum to a minimum value with increasing generation count <ref type="bibr" target="#b26">[27]</ref>, or randomly varied in the range (0.5, 1) or a uniform distribution between 0.5 and 1.5 (with mean of 1) can be employed <ref type="bibr" target="#b36">[37]</ref>. Recently, several researchers <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref> focused on the adaptation of the control parameters F and CR. FADE adapts the control parameters F and CR based on fuzzy logic controllers whose inputs are the relative function values and individuals of successive generations <ref type="bibr" target="#b38">[39]</ref>. FADE outperformed the conventional DE on higher dimensional problems. A parameter adaptation of DE (ADE) based on controlling the population diversity, and multipopulation approach <ref type="bibr" target="#b20">[21]</ref> was proposed, which was later extended to form an adaptive Pareto DE algorithm for multi-objective optimization <ref type="bibr" target="#b39">[40]</ref>. Abbas <ref type="bibr" target="#b37">[38]</ref> self-adapted the crossover rate of DE for multi-objective optimization problems, by encoding the crossover rater into each individual, to simultaneously evolve with other parameters. The scale factor F was generated using a Gaussian distribution N(0, 1) for each individual.</p><p>Qin et al. <ref type="bibr" target="#b18">[19]</ref> proposed a self-adaptive DE algorithm (SaDE) in which the mutation strategies and the respective control parameter are self-adapted based on their previous experiences of generating promising solutions. The scale factor, F was randomly generated with a mean and standard deviation of 0.5 and 0.3, respectively. Omran et al. <ref type="bibr" target="#b19">[20]</ref> introduced a self-adaptation scheme (SDE) in which CR is generated randomly for each individual using a normal distribution N(0.5, 0.15), while scale factor F is adapted analogous to the adaptation of crossover rate CR in <ref type="bibr" target="#b37">[38]</ref>. In addition to control parameters F and CR, Teo proposed differential evolution with selfadapting populations (DESAP) <ref type="bibr" target="#b40">[41]</ref>, based on Abbas's self-adaptive Pareto DE. Brest et al. <ref type="bibr" target="#b6">[7]</ref> proposed a self-adaptation scheme (JDE), in which control parameters F and CR are encoded into the individuals and are adjusted by introducing two new parameters 1 and 2 . Initially, F and CR values of each individual were assigned to 0.5 and 0.9, respectively. Then, a random number rand is uniformly generated in the range of [0, 1]. If rand &lt; 1 , the F value was reinitialized to a new random value in the range [0.1, 1.0]. Otherwise, it was kept unchanged. Similarly, if rand &lt; 2 , then CR was reinitialized in the range [0, 1]. Otherwise, it is kept unchanged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Ensemble of mutation strategies and parameters in DE (EPSDE)</head><p>The effectiveness of conventional DE in solving a numerical optimization problem depends on the selected mutation strategy and its associated parameter values. However, different optimization problems require different mutation strategies with different parameter values depending on the nature of problem (uni-modal and multi-modal) and available computation resources. In addition, to solve a specific problem, different mutation strategies with different parameter settings may be better during different stages of the evolution than a single mutation strategy with unique parameter settings as in the conventional DE. Motivated by these observations, we propose an ensemble of mutation strategies and parameter values for DE (EPSDE) in which a pool of mutation strategies, along with a pool of values corresponding to each associated parameter competes to produce successful offspring population. The candidate pool of mutation strategies and parameters should be restrictive to avoid the unfavorable influences of less effective mutation strategies and parameters <ref type="bibr" target="#b18">[19]</ref>. The mutation strategies or the parameters present in a pool should have diverse characteristics, so that they can exhibit distinct performance characteristics during different stages of the evolution, when dealing with a particular problem. The EPSDE is described in detail below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Selection of pool of mutation strategies</head><p>The different mutation strategies in DE literature are presented in Section 2.1. The different mutation strategies can be classified as:</p><p>1. Strategy without crossover (Eq. ( <ref type="formula" target="#formula_8">8</ref>)). 2. Strategies with crossover.</p><p>2.1. Individuals forming the mutant vector are randomly selected (Eqs. ( <ref type="formula" target="#formula_4">4</ref>) and ( <ref type="formula" target="#formula_5">5</ref>)). 2.2. Strategies relying on the best solution found so far (Eqs.</p><p>(2), ( <ref type="formula" target="#formula_3">3</ref>), ( <ref type="formula" target="#formula_6">6</ref>) and ( <ref type="formula" target="#formula_7">7</ref>)).</p><p>From the different mutation strategies available, we select a few of them to form a pool with diverse characteristics as follows: </p><formula xml:id="formula_12">• DE/best/1/</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Selection of parameter ranges</head><p>The crucial parameters that affect the performance of DE are the population size (NP), crossover rate (CR) and the scale factor (F). In the proposed EPSDE, the population size (NP = 50) is maintained constant throughout the evolution process.</p><p>Separable uni-modal problems require low CR values while parameter-linked mulimodal problems require higher CR values. In order to balance the speed and efficiency while solving problems with different characteristics, the pool of CR values is taken in the range 0.1-0.9 in steps of 0.1. Based on the literature presented in Section 3.4, the pool of F values is taken in the range 0.4-0.9 in steps of 0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Overall implementation</head><p>EPSDE consists of a pool of mutation strategies with diverse characteristics and a pool of values for each of the associated control parameters. Each member in the initial population is randomly assigned with a mutation strategy and associated parameter values taken from the respective pools. The population members (target vectors) produce offspring (trial vectors) using the assigned mutation strategy and parameter values. If the generated trial vector produced is better than the target vector, the mutation strategy and parameter values are retained with trial vector which becomes the parent (target vector) in the next generation. The combination of the mutation strategy and the parameter values that produced a better offspring than the parent are stored. If the target vector is better than the trial vector, then the target vector is randomly reinitialized with a new mutation strategy and associated parameter values from the respective pools or from the successful combinations stored with equal probability. This leads to an increased probability of production of offspring by the better combination of mutation strategy and the associated control parameters in the future generations ( </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Numerical experiments and results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Test functions</head><p>In the following, 14 benchmark problems are listed, among which functions f 1 -f 4 are uni-modal and functions f 5 -f 14 are multimodal. These 14 test functions (f 1 -f 14 ) are dimension-wise scalable <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b41">42]</ref>.</p><p>(1) Shifted sphere function</p><formula xml:id="formula_13">f 1 (x) = D i=1 z 2 i , z = x -o, o = [o 1 , o 2 , . . . , o D ] :</formula><p>the shifted global optimum  </p><formula xml:id="formula_14">f 3 (x) = D-1 i=1 (100(x 2 i -x i+1 ) 2 + (x i -1) 2 )</formula><p>(4) Shifted Schwefel's Problem 1.2 with noise in fitness   (13) Composition function 1 (CF1) in <ref type="bibr" target="#b41">[42]</ref> The function f 13 (CF1) is composed by using 10 sphere functions. The global optimum is easy to find once the global basin is found. The details of constructing such functions are presented in <ref type="bibr" target="#b41">[42]</ref>. <ref type="bibr" target="#b13">(14)</ref> Composition function 6 (CF6) in <ref type="bibr" target="#b41">[42]</ref> The function f 14 (CF6) is composed by using 10 different benchmark functions, i.e. 2 rotated Rastrigin's functions, 2 rotated Weierstrass functions, 2 rotated Griewank's functions, 2 rotated Ackley's functions and 2 rotated Sphere functions (Table <ref type="table" target="#tab_4">3</ref>).</p><formula xml:id="formula_15">f 4 (x) = ⎛ ⎜ ⎝ D i=1 ⎛ ⎝ i j=1 z j ⎞ ⎠ 2 ⎞ ⎟ ⎠ (1 + 0.4|N(0, 1)|), z = x -o, o = [o 1 ,</formula><formula xml:id="formula_16">f 11 (x) = D i=1 (y 2 i -10 cos(2 y i ) + 10), y i = z i |z i | &lt; 1/2 round(2z i )/2 |z i | ≥ 1/2 for i = 1, 2, . . . , D, z = x -o, o = [o 1 ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Algorithms for comparison</head><p>Experiment 1. First, we form an ensemble with a single mutation strategy (DE/rand/1/bin), which is referred to as ensemble of parameters in DE (EPDE). The performance of EPDE is compared with classical DE with different fixed parameter settings.</p><p>Experiment 2. EPDE is formed with different mutation strategies DE/best/2/bin (EPDE1), DE/rand/1/bin (EPDE2) and DE/current-torand/1/bin (EPDE3) and the performance is compared with EPSDE.</p><p>Experiment 3. Finally, we compare the performance of EPSDE with various state-of-the-art self-adaptive methods such as SaDE <ref type="bibr" target="#b18">[19]</ref>, JDE <ref type="bibr" target="#b6">[7]</ref>, ADE <ref type="bibr" target="#b20">[21]</ref>, JADE <ref type="bibr" target="#b42">[43]</ref> and SDE <ref type="bibr" target="#b19">[20]</ref>.</p><p>In all the above experiments, the maximum number of function evaluations is set to 100,000 for 10D problems and 300,000 for 30D problems. All experiments were run 30 times, independently on each problem. The performance of different algorithms is compared with ensemble by statistical t-test with a significance level of 0.05. Numerical values -1, 0, 1 represent that the ensemble is inferior to, equal to and superior to the algorithm with which it is compared, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Experimental results and discussions</head><p>Experiment 1. The results (mean, standard deviation values and ttest results) of experiment 1 are presented in Tables <ref type="table">4</ref> and<ref type="table">5</ref> for 10D and 30D problems, respectively. The t-test comparison is between the classical DE with different parameter settings and EPDE.</p><p>In Tables <ref type="table">4</ref> and<ref type="table">5</ref>, to compare the performance, the statistically significant result is highlighted. To compare the performance of classical DE with different parameter settings the significantly best results obtained by classical DE are underlined. From the underlined results it can be observed that the significantly best results are well scattered. Thus no single parameter setting is apt for all the problems.</p><p>For 10D problems from the t-test results present in Table <ref type="table">4</ref>, it can be observed that EPDE is inferior to, equal to and superior to classical DE with F = 0.9 and CR = 0.1 in 1, 8 and 5 problems, respectively. EPDE is inferior to, equal to and superior to classical DE with F = 0.9 and CR = 0.9 in 1, 0 and 13 problems, respectively. EPDE is inferior to, equal to and superior to classical DE with F = 0.5 and CR = 0.3 in 0, 8 and 6 problems, respectively.  For 30D problems from the t-test results present in Table <ref type="table">5</ref>, it can be observed that EPDE is inferior to, equal to and superior to classical DE with F = 0.9 and CR = 0.1 in 1, 7 and 6 problems, respectively. EPDE is inferior to, equal to and superior to classical DE with F = 0.9 and CR = 0.9 in 0, 0 and 14 problems, respectively. EPDE is inferior to, equal to and superior to classical DE with F = 0.5 and CR = 0.3 in 1, 7 and 6 problems, respectively.</p><p>Experiment 2. The results (mean, standard deviation values and t-test results) of experiment 2 are presented in Tables <ref type="table" target="#tab_6">6</ref> and<ref type="table" target="#tab_7">7</ref> for 10D and 30D problems, respectively.</p><p>In Tables <ref type="table" target="#tab_6">6</ref> and<ref type="table" target="#tab_7">7</ref>, to compare the performance, the statistically significant result is highlighted. To compare the performance of EPDE with different mutation strategies the significantly best results obtained are underlined. From the underlined results it can be observed that the underlined results are well scattered and thus no single mutation strategy is apt for all the problems.</p><p>For 10D problems from the t-test results present in Table <ref type="table" target="#tab_6">6</ref>, it can be observed that EPSDE is inferior to, equal to and superior to EPDE1 in 0, 7 and 7 problems, respectively. EPSDE is inferior to, equal to and superior to EPDE2 in 0, 10 and 14 problems, respectively. EPSDE is inferior to, equal to and superior to EPDE3 in 0, 5 and 9 problems, respectively.</p><p>For 30D problems from the t-test results present in Table <ref type="table" target="#tab_7">7</ref>, it can be observed that EPSDE is inferior to, equal to and superior to EPDE1 in 0, 3 and 11 problems, respectively. EPSDE is inferior to, equal to and superior to EPDE2 in 0, 9 and 5 problems, respectively. EPSDE is inferior to, equal to and superior to EPDE3 in 0, 0 and 14 problems, respectively.</p><p>Experiment 3. The results (mean, standard deviation values and t-test results) of experiment 3 are presented in Tables 8-10 for 10D, 30D and 50D problems, respectively.</p><p>In Tables <ref type="table" target="#tab_8">8</ref><ref type="table" target="#tab_10">9</ref><ref type="table" target="#tab_11">10</ref>, to compare the performance of different algorithms the significantly best results obtained for a problem are highlighted. Out of the five algorithms used for comparison, if ESPDE is the statistically better than all the algorithms, the second best result is underlined to enable better comparison. From the results, it can be observed that EPSDE can perform better than other algorithms in most of the cases. Among the algorithms used for comparison, SDE is weaker in performance. ADE performs better on multi-modal problems f 5 -f 14 than on uni-modal problems f 1 -f 4 . JDE, JADE and SaDE perform equally well on both uni-modal and multi-modal problems, but SaDE is slightly better on some of the problems. The clear difference in performance can be observed as the dimensionality of the problems increase from 10D to 50D.</p><p>For 10D problems from the t-test results present in Table <ref type="table" target="#tab_8">8</ref>, it can be observed that EPSDE is inferior to, equal to and superior to SaDE in 1, 12 and 1 problems, respectively. EPSDE is inferior to, equal to and superior to JDE in 1, 9 and 4 problems, respectively. EPSDE is inferior to, equal to and superior to ADE in 0, 9 and 5 problems, respectively. EPSDE is inferior to, equal to and superior to SDE in 0, 6 and 8 problems, respectively. EPSDE is inferior to, equal to and superior to JADE in 1, 9 and 7 problems, respectively.</p><p>For 30D problems from the t-test results present in Table <ref type="table" target="#tab_10">9</ref>, it can be observed that EPSDE is inferior to, equal to and superior to SaDE in 1, 6 and 7 problems, respectively. EPSDE is inferior to, equal to and superior to JDE in 1, 6 and 7 problems, respectively. EPSDE is inferior to, equal to and superior to ADE in 0, 8 and 6 problems, respectively. EPSDE is inferior to, equal to and superior to SDE in 1, 0 and 13 problems, respectively. EPSDE is inferior to, equal to and superior to JADE in 1, 6 and 7 problems, respectively.</p><p>For 50D problems from the t-test results present in Table <ref type="table" target="#tab_11">10</ref>, it can be observed that EPSDE is inferior to, equal to and superior to SaDE in 1, 3 and 10 problems, respectively. EPSDE is inferior to, equal to and superior to JDE in 1, 4 and 9 problems, respectively. EPSDE is inferior to, equal to and superior to ADE in 0, 9 and 5 problems, respectively. EPSDE is inferior to, equal to and superior to SDE in 1, 1 and 12 problems, respectively. EPSDE is inferior to, equal to and superior to JADE in 2, 5 and 7 problems, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Analysis of EPSDE</head><p>When solving an optimization problem using DE, different mutation strategies combined with different parameter settings perform better during different stages of the evolution. In EPSDE, initially each target vector is assigned a mutation strategy and parameter values chosen randomly from the respective pool. As the evolution progresses the inefficient combination of mutation strategies and parameters are replaced with a new mutation strategy and parameters randomly selected from the respective pools. Initially all the mutation strategies and parameter values in respective pools have equal probability of producing an offspring. But the process of replacing the ineffective mutation strategy and associated parameters, leads to an increase in the probability of producing an offspring by the best suited mutation strategy and parameters, which is indicated in the graphs in Figs. <ref type="figure">1</ref> and<ref type="figure">2</ref>.</p><p>In Figs. <ref type="figure">1</ref> and<ref type="figure">2</ref>, X-axis represents the generation count in the evolution process, while Y-axis represents the probability of an offspring being produced by a particular mutation strategy or a particular parameter value. For better representation, the probability values corresponding to a mutation vector or parameter value, represented on the Y-axis are averaged over every 50 generations. Figs. 1 and 2 correspond to 10D problems f 3 and f 7 , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 4</head><p>Comparison between classical DE and EPDE on 10D problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fcn</head><p>Rand/1/bin (F = 0.9, CR = 0.1) Rand/1/bin (F = 0.9, CR = 0.9) Rand/1/bin (F = 0. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5</head><p>Comparison between classical DE and EPDE on 30D problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fcn</head><p>Rand/1/bin (F = 0.9, CR = 0.1) Rand/1/bin (F = 0.9, CR = 0.9) Rand/1/bin (F = 0.     </p><formula xml:id="formula_17">F11 0 0 0 0 1.19E+01 2.85E+00 0 0 0 0 1 - F12 3.95E+00 2.16E+01 0 0 1.69E+03 2.13E+02 0 0 1 0 1 - F13 3.33E+01 6.61E+01 0 0 1.67E+01 3.59E+01 0 0 1 0 1 - F14 1.67E+01 3.80E+01 0 0 6.32E+03 3.30E+02 0 0 1 0 1 -</formula><formula xml:id="formula_18">0 0 0 0 0 1 1 0 - f5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 - f6 0 0 0 0 0 0 0 0 2.04E+01 8.48E-01 0 0 0 0 0 0 1 - f7 0 0 0 0 0 0<label>4</label></formula><formula xml:id="formula_19">.39E+00 -1 -1 0 0 -1 - f11 0 0 0 0 0 0 1.40E+00 1.19E+00 0 0 0 0 0 0 0 1 0 - f12 0 0 1.18E+01 3.61E+01 0 0 7.90E+00 3.01E+01 0 0 0 0 0 1 0 1 0 - f13 0 0 6.67E+00 2.54E+01 1.20E-03 3.00E-03 1.67E+01 3.79E+01 2.33E+01 4.30E+01 0 0 0 1 1 1 1 -<label>f14</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>The performance of DE depends on the selected mutation strategy and its associated parameter values. Different optimization problems require different mutation strategies with different parameter values depending on the nature of problem and available computation resources. For a problem at hand different mutation strategies with different parameter settings may be more effective during different stages of the evolution than a single mutation strategy with unique parameter settings as in the conventional DE. Based on these observations, we propose an ensemble of mutation strategies and parameter values in which a pool of mutation strategies, along with a pool of values corresponding to each associated parameter compete to produce offspring population. The performance of EPSDE is evaluated on set of benchmark problems and is favorably compared with the state-of-the-art DE methods in the literature.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>( 2 ) 2 f 2 2 ,</head><label>2222</label><figDesc>Shifted Schwefel's Problem 1.z = xo, o = [o 1 , o 2 , . . . , o D ] : the shifted global optimum (3) Rosenbrock's function</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( 5</head><label>5</label><figDesc>o 2 , . . . , o D ] : the shifted global optimum z i ) + 20 + e, z = xo, o = [o 1 , o 2 , . . . , o D ]: the shifted global optimum (6) Shifted rotated Ackley's function f 6 (x) = -20 exp z i ) + 20 + e, z = M(xo), cond b (M) = 1 o = [o 1 , o 2 , . . . , o D ]: the shifted global optimum b Cond(M) means the condition number of rotation matrix M.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 , 8 ) 8 1 , 3 o</head><label>18813</label><figDesc>z = xo, o = [o 1 , o 2 , . . . , o D ] : the shifted global optimum (Shifted rotated Griewank's function f z = M(xo), cond(M) = = [o 1 , o 2 , . . . o D ]: the shifted global optimum (9) Shifted Rastrigin's function f 9 (x) = D i=1 (z 2 i -10 cos(2 z i ) + 10), z = xo, o = [o 1 , o 2 , . . . , o D ] : the shifted global optimum (10) Shifted rotated Rastrigin's function f 10 (x) = D i=1 (z 2 i -10 cos(2 z i ) + 10), z = M(xo), cond(M) = 2 o = [o 1 , o 2 , . . . , o D ]: the shifted global optimum (11) Shifted non-continuous Rastrigin's function</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>o 2 , . . . , o D ]: the shifted global optimum (12) Schwefel's function f 12 (x) = 418.9829 × D -D i=1 x i sin(|x i | 1/2 )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>o</head><label></label><figDesc>is the shifted vector. o1 is the shifted vector for the first basic function in the composition function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 1 .Fig. 2 .</head><label>12</label><figDesc>Fig. 1. (a) Probability of an offspring production by a mutation strategies versus generations. (b) Probability of an offspring production by a particular CR value versus generations. (c) Probability of an offspring production by a particular F value versus Generations. Fig. 2. (a) Probability of an offspring production by a mutation strategies versus generations. (b) Probability of an offspring production by a particular CR value versus generations. (c) Probability of an offspring production by a particular F value versus generations.</figDesc><graphic coords="17,316.00,55.66,243.72,524.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="3,48.71,75.19,354.60,341.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="3,48.71,419.40,353.52,244.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="6,37.90,267.90,354.60,471.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>-to-best/2/bin rely on the best solution found so far. DE/best/1/bin and DE/best/2/bin are degenerate cases of DE/rand-to-best/1/bin and DE/rand-to-best/2/bin with K = 1. However, a strategy with two difference vectors is more robust than a strategy with one difference vector. Therefore, to make the strategy pool diverse, we select DE/best/2/bin out the four mutation strategies which use the best solution so far found.</figDesc><table><row><cell>bin,</cell><cell>DE/best/2/bin,</cell><cell>DE/rand-to-best/1/bin</cell><cell>and</cell></row><row><cell>DE/rand</cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p>• DE/rand/1/bin and DE/rand/2/bin are two mutation strategies which bear stronger exploration capabilities. Out of the two strategies we include DE/rand/1/bin into pool, since it is faster, robust and is one of the most widely used mutation strategy in the DE literature.</p>• DE/current-to-rand/1/bin being a rotation-invariant strategy without crossover is different from the other strategies. Hence, it is included in the pool.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 )</head><label>2</label><figDesc>.4.4. Comparison of EPSDE with SaDE, JDE, ADE, JADE and SDE</figDesc><table><row><cell>Algorithm</cell><cell>Comparison</cell></row><row><cell>SDE</cell><cell>CR is generated randomly for each individual using normal</cell></row><row><cell></cell><cell>distribution N(0.5, 0.15), while F is adapted. The mutation</cell></row><row><cell></cell><cell>strategy is not adapted.</cell></row><row><cell>ADE</cell><cell>Parameters F and CR are adapted such the population diversity</cell></row><row><cell></cell><cell>is preserved in every generation. The lower and upper bounds</cell></row><row><cell></cell><cell>for CR are 0.1 and 1.0, respectively. The lower and upper bounds for F are 1/ √ NP and 2.0, respectively. There is no</cell></row><row><cell></cell><cell>adaptation of the mutation strategy.</cell></row><row><cell>JDE</cell><cell>The mutation strategy is not adapted. The ranges of F and CR</cell></row><row><cell></cell><cell>values are [0.1, 1.0] and [0, 1], respectively. The F and CR values</cell></row><row><cell></cell><cell>are adapted based on two constants 1 and 2 , which are set to</cell></row><row><cell></cell><cell>0.1.</cell></row><row><cell>SaDE</cell><cell>The F values are randomly generated with a mean and</cell></row><row><cell></cell><cell>standard deviation of 0.5 and 0.3, respectively. The mutation</cell></row><row><cell></cell><cell>strategy and the parameter CR are self-adapted based on their</cell></row><row><cell></cell><cell>previous performance.</cell></row><row><cell>JADE</cell><cell>JADE implements a new mutation strategy</cell></row><row><cell></cell><cell>"DE/current-to-pbest" with optional external archive. In every</cell></row><row><cell></cell><cell>generation, the CR value corresponding to each individual is</cell></row><row><cell></cell><cell>randomly initialized with a normal distribution of mean CR</cell></row><row><cell></cell><cell>and standard deviation 0.1, while the F value is randomly</cell></row><row><cell></cell><cell>initialized with a Cauchy distribution with a location</cell></row><row><cell></cell><cell>parameter</cell></row></table><note><p><p><p>F and standard deviation 0.1. After every generation, the CR is updated based on the arithmetic mean of the successful CR values, while F is updated based on the Lehar mean of the successful F values.</p>EPSDE</p>Each member in the initial population is assigned a mutation strategy and parameter values randomly selected from the respective pools. The mutation strategy and parameter values producing better offspring survive while those fail to produce better offspring are reinitialized.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Ensemble of mutation strategies and parameters in DE (EPSDE).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 (</head><label>2</label><figDesc>Continued )    </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>Global optimum, search ranges and initialization ranges of the test functions.</figDesc><table><row><cell>f</cell><cell>Dimension</cell><cell>Global optimum x *</cell><cell>f(x * )</cell><cell>Search range</cell><cell>Initialization range</cell></row><row><cell>f1</cell><cell></cell><cell>o</cell><cell>0</cell><cell>[ -100, 100] D</cell><cell>[-100, 100] D</cell></row><row><cell>f2</cell><cell></cell><cell>o</cell><cell>0</cell><cell>[ -100, 100] D</cell><cell>[-100, 100] D</cell></row><row><cell>f3</cell><cell></cell><cell>(1, 1, . . ., 1)</cell><cell>0</cell><cell>[-100, 100] D</cell><cell>[-100, 100] D</cell></row><row><cell>f4</cell><cell></cell><cell>o</cell><cell>0</cell><cell>[ -100, 100] D</cell><cell>[-100, 100] D</cell></row><row><cell>f5</cell><cell></cell><cell>o</cell><cell>0</cell><cell>[ -32, 32] D</cell><cell>[-32, 32] D</cell></row><row><cell>f6</cell><cell>10</cell><cell>o</cell><cell>0</cell><cell>[ -32, 32] D</cell><cell>[-32, 32] D</cell></row><row><cell></cell><cell>and</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>30</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6</head><label>6</label><figDesc>Comparison of EPDE with different mutation strategies with EPSDE on 10D problems.</figDesc><table><row><cell>5, CR = 0.3)</cell><cell>EPDE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7</head><label>7</label><figDesc>Comparison of EPDE with different mutation strategies with EPSDE on 30D problems.</figDesc><table><row><cell>Fcn</cell><cell>EPDE1</cell><cell></cell><cell></cell><cell>EPDE2</cell><cell></cell><cell></cell><cell>EPDE3</cell><cell></cell><cell></cell><cell>EPSDE</cell><cell></cell><cell></cell></row><row><cell></cell><cell>MEAN</cell><cell></cell><cell>STD</cell><cell>MEAN</cell><cell></cell><cell>STD</cell><cell>MEAN</cell><cell></cell><cell>STD</cell><cell>MEAN</cell><cell></cell><cell>STD</cell></row><row><cell>F1</cell><cell>8.41E-30</cell><cell>0</cell><cell>3.77E-29</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>2.58E-01</cell><cell>1</cell><cell>1.39E+00</cell><cell>0</cell><cell>-</cell><cell>0</cell></row><row><cell>F2</cell><cell>1.14E+02</cell><cell>1</cell><cell>6.28E+02</cell><cell>6.51E+01</cell><cell>1</cell><cell>2.47E+02</cell><cell>8.38E-06</cell><cell>1</cell><cell>4.57E-05</cell><cell>2.78E-12</cell><cell>-</cell><cell>1.26E-11</cell></row><row><cell>F3</cell><cell>9.47E+00</cell><cell>1</cell><cell>1.98E+01</cell><cell>4.54E+01</cell><cell>1</cell><cell>2.73E+01</cell><cell>2.00E+02</cell><cell>1</cell><cell>5.49E+02</cell><cell>2.69E-22</cell><cell>-</cell><cell>9.92E-22</cell></row><row><cell>F4</cell><cell>5.62E+02</cell><cell>1</cell><cell>2.39E+03</cell><cell>4.22E+03</cell><cell>1</cell><cell>6.89E+03</cell><cell>4.92E-02</cell><cell>1</cell><cell>2.13E-01</cell><cell>1.32E-05</cell><cell>-</cell><cell>5.41E-05</cell></row><row><cell>F5</cell><cell>7.43E-12</cell><cell>1</cell><cell>4.06E-11</cell><cell>6.99E-15</cell><cell>0</cell><cell>6.49E-16</cell><cell>4.62E-02</cell><cell>1</cell><cell>1.47E-01</cell><cell>3.55E-15</cell><cell>-</cell><cell>0.00E+00</cell></row><row><cell>F6</cell><cell>6.99E-15</cell><cell>0</cell><cell>6.49E-16</cell><cell>6.76E-15</cell><cell>0</cell><cell>1.08E-15</cell><cell>1.28E-03</cell><cell>1</cell><cell>4.07E-03</cell><cell>3.55E-15</cell><cell>-</cell><cell>0.00E+00</cell></row><row><cell>F7</cell><cell>4.11E-04</cell><cell>1</cell><cell>2.20E-03</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>3.73E-01</cell><cell>1</cell><cell>1.69E+00</cell><cell>0</cell><cell>-</cell><cell>0</cell></row><row><cell>F8</cell><cell>3.00E-03</cell><cell>1</cell><cell>5.40E-03</cell><cell>2.47E-04</cell><cell>1</cell><cell>1.40E-03</cell><cell>5.07E-01</cell><cell>1</cell><cell>1.45E+00</cell><cell>3.97E-17</cell><cell>-</cell><cell>8.51E-17</cell></row><row><cell>F9</cell><cell>5.60E-01</cell><cell>1</cell><cell>3.07E+00</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1.62E+02</cell><cell>1</cell><cell>8.31E+00</cell><cell>0</cell><cell>-</cell><cell>0</cell></row><row><cell>F10</cell><cell>1.29E+02</cell><cell>1</cell><cell>2.07E+02</cell><cell>1.39E+02</cell><cell>1</cell><cell>1.78E+01</cell><cell>1.65E+02</cell><cell>1</cell><cell>1.04E+01</cell><cell>7.81E+01</cell><cell>-</cell><cell>1.33E+01</cell></row><row><cell>F11</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1.32E+02</cell><cell>1</cell><cell>1.03E+01</cell><cell>0</cell><cell>-</cell><cell>0</cell></row><row><cell>F12</cell><cell>1.22E-13</cell><cell>1</cell><cell>4.62E-13</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>8.40E+03</cell><cell>1</cell><cell>2.73E+02</cell><cell>0</cell><cell>-</cell><cell>0</cell></row><row><cell>F13</cell><cell>3.33E+00</cell><cell>1</cell><cell>1.80E+01</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>7.62E+03</cell><cell>1</cell><cell>4.71E+02</cell><cell>0</cell><cell>-</cell><cell>0</cell></row><row><cell>F14</cell><cell>7.63E+00</cell><cell>1</cell><cell>4.32E+00</cell><cell>3.46E+00</cell><cell>0</cell><cell>1.63E+00</cell><cell>8.35E+03</cell><cell>1</cell><cell>6.25E+02</cell><cell>4.94E+00</cell><cell>-</cell><cell>7.19E-01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8</head><label>8</label><figDesc>Comparison between EPSDE and various state-of-the-art methods on 10D problems.</figDesc><table><row><cell>Fcn</cell><cell>SaDE</cell><cell></cell><cell>jDE</cell><cell></cell><cell>ADE</cell><cell></cell><cell>SDE</cell><cell></cell><cell>JADE</cell><cell></cell><cell>EPSDE</cell><cell></cell></row><row><cell></cell><cell>MEAN</cell><cell>STD</cell><cell>MEAN</cell><cell>STD</cell><cell>MEAN</cell><cell>STD</cell><cell>MEAN</cell><cell>STD</cell><cell>MEAN</cell><cell>STD</cell><cell>MEAN</cell><cell>STD</cell></row><row><cell>f1</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell>0</cell><cell></cell><cell>0</cell><cell></cell><cell>0</cell><cell></cell><cell>0</cell><cell></cell><cell>0</cell><cell></cell><cell>-</cell><cell></cell></row><row><cell>f2</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>7.50E-03</cell><cell>6.60E-03</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell>0</cell><cell></cell><cell>0</cell><cell></cell><cell>1</cell><cell></cell><cell>0</cell><cell></cell><cell>0</cell><cell></cell><cell>-</cell><cell></cell></row><row><cell>f3</cell><cell>0</cell><cell>0</cell><cell>2.66E-01</cell><cell>1.01E+00</cell><cell>7.59E-01</cell><cell>7.38E-01</cell><cell>2.21E+00</cell><cell>1.77E+00</cell><cell>5.30E-01</cell><cell>1.40E+00</cell><cell>7.13E-10</cell><cell>3.90E-09</cell></row><row><cell></cell><cell>0</cell><cell></cell><cell>1</cell><cell></cell><cell>1</cell><cell></cell><cell>1</cell><cell></cell><cell>1</cell><cell></cell><cell>-</cell><cell></cell></row><row><cell>f4</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1.02E+00</cell><cell>5.93E-01</cell><cell>1.83E-09</cell><cell>1.00E-08</cell><cell>0</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9</head><label>9</label><figDesc>Comparison between EPSDE and various state-of-the-art methods on 30D problems.</figDesc><table><row><cell>2.54E-01</cell><cell>5.21E-01</cell><cell>1.27E+00</cell><cell>3.20E+00</cell><cell>5.87E+00</cell><cell>4.85E+00</cell><cell>8.26E+00</cell><cell>1.82E+01</cell><cell>3.33E+00</cell><cell>1.83E+01</cell><cell>0</cell><cell>0</cell></row><row><cell>1</cell><cell></cell><cell>1</cell><cell></cell><cell>1</cell><cell></cell><cell>1</cell><cell></cell><cell>1</cell><cell></cell><cell>-</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 10</head><label>10</label><figDesc>Comparison between EPSDE and various state-of-the-art methods on 50D problems.</figDesc><table><row><cell>Fcn</cell><cell>SaDE</cell><cell></cell><cell></cell><cell>jDE</cell><cell></cell><cell></cell><cell>ADE</cell><cell></cell><cell></cell><cell>SDE</cell><cell></cell><cell></cell><cell>JADE</cell><cell></cell><cell></cell><cell>EPSDE</cell><cell></cell><cell></cell></row><row><cell></cell><cell>MEAN</cell><cell></cell><cell>STD</cell><cell>MEAN</cell><cell></cell><cell>STD</cell><cell>MEAN</cell><cell></cell><cell>STD</cell><cell>MEAN</cell><cell></cell><cell>STD</cell><cell>MEAN</cell><cell></cell><cell>STD</cell><cell>MEAN</cell><cell></cell><cell>STD</cell></row><row><cell>f1</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>2.57E-29</cell><cell>0</cell><cell>6.61E-29</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>2.17E+01</cell><cell>1</cell><cell>3.85E+01</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>-</cell><cell>0</cell></row><row><cell>f2</cell><cell>1.47E-09</cell><cell>0</cell><cell>5.93E-09</cell><cell>2.11E-04</cell><cell>1</cell><cell>2.72E-04</cell><cell>1.70E+04</cell><cell>1</cell><cell>2.72E+03</cell><cell>3.26E+02</cell><cell>1</cell><cell>3.57E+02</cell><cell>5.20E-23</cell><cell>-1</cell><cell>1.13E-22</cell><cell>4.47E-09</cell><cell>-</cell><cell>1.75E-08</cell></row><row><cell>f3</cell><cell>1.42E+00</cell><cell>1</cell><cell>2.44E+00</cell><cell>7.25E+00</cell><cell>1</cell><cell>1.77E+01</cell><cell>4.55E+01</cell><cell>1</cell><cell>1.08E+00</cell><cell>5.54E+06</cell><cell>1</cell><cell>1.36E+07</cell><cell>1.20E+00</cell><cell>1</cell><cell>1.93E+00</cell><cell>0</cell><cell>-</cell><cell>0</cell></row><row><cell>f4</cell><cell>3.05E+03</cell><cell>1</cell><cell>1.98E+03</cell><cell>1.26E+03</cell><cell>1</cell><cell>1.39E+03</cell><cell>4.15E+04</cell><cell>1</cell><cell>4.98E+03</cell><cell>9.46E+03</cell><cell>1</cell><cell>3.38E+03</cell><cell>1.42E+03</cell><cell>1</cell><cell>1.55E+03</cell><cell>5.47E+02</cell><cell>-</cell><cell>9.47E+02</cell></row><row><cell>f5</cell><cell>6.45E-01</cell><cell>1</cell><cell>7.09E-01</cell><cell>4.62E-15</cell><cell>0</cell><cell>1.63E-15</cell><cell>7.11E-11</cell><cell>0</cell><cell>8.45E-12</cell><cell>1.17E+00</cell><cell>1</cell><cell>7.35E-01</cell><cell>7.11E-15</cell><cell>0</cell><cell>1.52E-16</cell><cell>8.05E-15</cell><cell>-</cell><cell>2.46E-15</cell></row><row><cell>f6</cell><cell>1.05E+00</cell><cell>1</cell><cell>6.58E-01</cell><cell>4.38E-15</cell><cell>0</cell><cell>1.50E-15</cell><cell>6.87E-15</cell><cell>0</cell><cell>8.86E-16</cell><cell>9.90E-01</cell><cell>1</cell><cell>7.95E-01</cell><cell>1.08E+00</cell><cell>1</cell><cell>7.78E-01</cell><cell>7.11E-15</cell><cell>-</cell><cell>2.46E-15</cell></row><row><cell>f7</cell><cell>6.40E-03</cell><cell>1</cell><cell>1.15E-02</cell><cell>2.00E-04</cell><cell>1</cell><cell>1.30E-03</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1.40E+01</cell><cell>1</cell><cell>1.20E+01</cell><cell>5.70E-03</cell><cell>1</cell><cell>1.09E-01</cell><cell>0</cell><cell>-</cell><cell>0</cell></row><row><cell>f8</cell><cell>5.00E-03</cell><cell>1</cell><cell>1.26E-02</cell><cell>7.00E-04</cell><cell>1</cell><cell>2.90E-03</cell><cell>6.49E-12</cell><cell>0</cell><cell>2.56E-11</cell><cell>1.14E+01</cell><cell>1</cell><cell>1.40E+01</cell><cell>3.20E-03</cell><cell>1</cell><cell>5.30E-03</cell><cell>0</cell><cell>-</cell><cell>0</cell></row><row><cell>f9</cell><cell>2.09E+00</cell><cell>1</cell><cell>1.34E+00</cell><cell>1.99E-01</cell><cell>1</cell><cell>3.99E-01</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>2.39E+01</cell><cell>1</cell><cell>5.54E+00</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>-</cell><cell>0</cell></row><row><cell>f10</cell><cell>7.33E+01</cell><cell>-1</cell><cell>1.65E+01</cell><cell>4.09E+01</cell><cell>-1</cell><cell>5.98E+00</cell><cell>1.27E+02</cell><cell>0</cell><cell>9.79E+01</cell><cell>5.94E+01</cell><cell>-1</cell><cell>1.23E+01</cell><cell>7.75E+01</cell><cell>-1</cell><cell>1.96E+01</cell><cell>2.00E+02</cell><cell>-</cell><cell>2.9E+01</cell></row><row><cell>f11</cell><cell>1.57E+00</cell><cell>1</cell><cell>1.28E+00</cell><cell>3.33E-01</cell><cell>1</cell><cell>4.71E-01</cell><cell>2.00E-01</cell><cell>1</cell><cell>4.00E-01</cell><cell>3.46E+01</cell><cell>1</cell><cell>5.71E+00</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>-</cell><cell>0</cell></row><row><cell>f12</cell><cell>3.95E+00</cell><cell>1</cell><cell>2.16E+01</cell><cell>1.10E+02</cell><cell>1</cell><cell>1.36E+02</cell><cell>1.82E-11</cell><cell>0</cell><cell>3.45E-12</cell><cell>1.07E+03</cell><cell>1</cell><cell>3.29E+02</cell><cell>5.92E+01</cell><cell>1</cell><cell>1.15E+02</cell><cell>0</cell><cell>-</cell><cell>0</cell></row><row><cell>f13</cell><cell>1.67E+01</cell><cell>1</cell><cell>4.61E+01</cell><cell>2.33E+01</cell><cell>1</cell><cell>4.96E+01</cell><cell>1.19E-08</cell><cell>1</cell><cell>6.52E-08</cell><cell>2.24E+01</cell><cell>1</cell><cell>5.44E+01</cell><cell>1.00E+01</cell><cell>1</cell><cell>3.16E+01</cell><cell>0</cell><cell>-</cell><cell>0</cell></row><row><cell>f14</cell><cell>5.01E+01</cell><cell>0</cell><cell>1.75E+02</cell><cell>2.41E+01</cell><cell>0</cell><cell>4.02E+01</cell><cell>1.26E+01</cell><cell>0</cell><cell>2.16E+00</cell><cell>2.14E+01</cell><cell>0</cell><cell>2.55E+01</cell><cell>1.52E+01</cell><cell>0</cell><cell>3.11E+01</cell><cell>3.15E+01</cell><cell>-</cell><cell>4.13E+01</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>Authors acknowledge the financial support offered by the A*Star (Agency for Science, Technology and Research, Singapore) under the grant #052 101 0020.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Computational Intelligence: A Dynamic System Perspective</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Angeline</surname></persName>
		</author>
		<editor>M. Palaniswami, Y. Attikiouzel, R.J. Marks, D.B. Fogel, T. Fukuda</editor>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>IEEE Press</publisher>
			<biblScope unit="page" from="152" to="161" />
		</imprint>
	</monogr>
	<note>Adaptive and self-adaptive evolutionary computation</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Parameter control in evolutionary algorithms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Eiben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hinterding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="124" to="141" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Using adaptive operators in genetic search</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gonazalez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference 2003 (GECCO&apos;03)</title>
		<meeting>the Genetic and Evolutionary Computation Conference 2003 (GECCO&apos;03)<address><addrLine>Chicago, Illinois, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="1580" to="1581" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">What have you done for me lately? Adapting operator probabilities in a steady-state genetic algorithm</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Julstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Genetic Algorithms</title>
		<meeting>the 6th International Conference on Genetic Algorithms<address><addrLine>Pittsburgh, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="81" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Operator and parameter adaptation in genetic algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Fogarty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Computing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="81" to="87" />
			<date type="published" when="1997-06">June. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adapting operator settings in genetic algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tuson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="161" to="184" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Self-adapting control parameters in differential evolution: a comparative study on numerical benchmark problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Boscovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mernik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zumer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="646" to="657" />
			<date type="published" when="2006-12">December. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Differential Evolution -A Simple and Efficient Adaptive Scheme for Global Optimization Over Continuous Spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
		<idno>TR-95-012</idno>
		<ptr target="http://http.icsi.berkeley.edu/∼storn/litera.html" />
	</analytic>
	<monogr>
		<title level="j">ICSI</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Minimal representation multisensor fusion using differential evolution</title>
		<author>
			<persName><forename type="first">R</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics Part A: Systems and Humans</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="63" to="76" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Differential evolution in aerodynamic optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Rogalsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Derksen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kocabiyik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of 46th Annual Conference of Canadian Aeronautics and Space</title>
		<meeting>eeding of 46th Annual Conference of Canadian Aeronautics and Space<address><addrLine>Institute, Montreal, Quebec</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="29" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On the usage of differential evolution for function optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biennial Conference of the North American Fuzzy Information Processing Society (NAFIPS)</title>
		<meeting><address><addrLine>Berkeley</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="519" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fiber Bragg grating sensor array interrogation using differential evolution</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Venu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mallipeddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optoelectronics and Advanced Materials -Rapid Communications</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="682" to="685" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Differential evolution training algorithm for feed-forward neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ilonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Kamarainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lampinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Processing Letters</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="93" to="105" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automatic image pixel clustering with an improved differential evolution</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Konar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="226" to="236" />
			<date type="published" when="2009-01">January. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Modified differential evolution based fuzzy clustering for pixel classification in remote sensing imagery</title>
		<author>
			<persName><forename type="first">U</forename><surname>Maulik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Saha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="2135" to="2149" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<title level="m">IEEE International Conference on Evolutionary Computation</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="268" to="273" />
		</imprint>
	</monogr>
	<note>Differential evolution design of an IIR-filter</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Differential evolution approach for optimal reactive power dispatch</title>
		<author>
			<persName><forename type="first">M</forename><surname>Varadarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Swarup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1549" to="1561" />
			<date type="published" when="2008-09">September. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On setting the control parameter of the differential evolution method</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lampinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Soft Computing</title>
		<meeting>the 8th International Conference on Soft Computing</meeting>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Differential evolution algorithm with strategy adaptation for global numerical optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="398" to="417" />
			<date type="published" when="2009-04">April. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Self-adaptive differential evolution</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G H</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Salman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Engelbrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence and Security</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="192" to="199" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>PT</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Control of population diversity and adaptation in differential evolution algorithms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zaharie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Soft Computing</title>
		<meeting>the 9th International Conference on Soft Computing<address><addrLine>Brno</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="41" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adaptation in differential evolution: a numerical comparison</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tvrdik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1149" to="1155" />
			<date type="published" when="2009-06">June. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Differential evolution: a practical approach to global optimization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Lampinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Natural Computing Series</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Solving rotated multi-objective optimization problems using differential evolution</title>
		<author>
			<persName><forename type="first">A</forename><surname>Iorio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Australian Conference on Artificial Intelligence</title>
		<meeting><address><addrLine>Cairns, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="861" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Differential evolution -a simple and efficient heuristic for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Global Optimization</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A parameter study for differential evolution</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gämperle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Koumoutsakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Intelligent Systems, Fuzzy Systems, Evolutionary Computation</title>
		<meeting><address><addrLine>Interlaken, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>WSEAS Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="293" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Two improved differential evolution schemes for faster global search</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Konar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">K</forename><surname>Chakraborty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 Conference on Genetic and Evolutionary Computation</title>
		<meeting>the 2005 Conference on Genetic and Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="991" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On stagnation of the differential evolution algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Zelinka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MENDEL 2000, 6th International Mendel Conference on Soft Computing</title>
		<meeting>MENDEL 2000, 6th International Mendel Conference on Soft Computing</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="76" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Differential evolution: a simple evolution strategy for fast optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dr. Dobb&apos;s Journal</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="18" to="24" />
			<date type="published" when="1997-04">April. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Real-parameter optimization with differential evolution</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rönkkönen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kukkonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Price</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>IEEE Congress on Evolutionary Computation</publisher>
			<biblScope unit="page" from="506" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Price</surname></persName>
		</author>
		<title level="m">An introduction to differential evolution</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Corne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Dorgio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</editor>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="79" to="108" />
		</imprint>
	</monogr>
	<note>New Ideas in Optimization</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Differential evolution using a neighborhood-based mutation operator</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">K</forename><surname>Chakraborthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="526" to="553" />
			<date type="published" when="2009-06">June. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Influence of crossover on the behavior of differential evolution algorithms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zaharie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1126" to="1138" />
			<date type="published" when="2009-06">June. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Modified differential evolution for constrained optimization</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mezura-Montes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Velazquez-Reyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Coello Coello</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>IEEE Congress on Evolutionary Computation</publisher>
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Critical values for the control parameters of differential evolution</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zaharie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MENDEL 2002, Eighth International Conference on Soft Computing</title>
		<meeting>MENDEL 2002, Eighth International Conference on Soft Computing<address><addrLine>Brno, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="62" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">On using normally distributed mutation step length for the differential evolution algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rönkkönen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lampinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MENDEL 2003,Ninth International MENDEL Confernce on Soft Computing</title>
		<meeting>MENDEL 2003,Ninth International MENDEL Confernce on Soft Computing<address><addrLine>Brno, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Differential evolution with local neighborhood</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">K</forename><surname>Chakraborthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Konar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Congress on Evolutionary Computation</title>
		<meeting>Congress on Evolutionary Computation<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="2042" to="2049" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The self-adaptive Pareto differential evolution algorithm, in: Proceedings of the</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Abbass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Congress on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="831" to="836" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A fuzzy adaptive differential evolution algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lampinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="448" to="462" />
			<date type="published" when="2005-06">June. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Adaptive Pareto differential evolution and its parallelization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zaharie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Petcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Conference on Parallel Processing and Applied Mathematics</title>
		<meeting>5th International Conference on Parallel Processing and Applied Mathematics<address><addrLine>Czestochowa, Poland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="261" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Exploring dynamic self-adaptive populations in differential evolution</title>
		<author>
			<persName><forename type="first">J</forename><surname>Teo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Computing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="673" to="686" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Novel composition test functions for numerical global optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Swarm Intelligence Symposium</title>
		<meeting><address><addrLine>Pasadena, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="page" from="68" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">JADE: adaptive differential evolution with optional external archive</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="945" to="958" />
			<date type="published" when="2009-10">October. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
