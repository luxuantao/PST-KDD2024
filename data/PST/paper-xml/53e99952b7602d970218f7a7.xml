<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Implementation of H.264 encoder and decoder on personal computers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2005-07-19">19 July 2005</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Yen-Kuang</forename><surname>Chen</surname></persName>
							<email>yen-kuang.chen@intel.com</email>
						</author>
						<author>
							<persName><forename type="first">Eric</forename><forename type="middle">Q</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiaosong</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Steven</forename><surname>Ge</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Corporate Technology Group</orgName>
								<orgName type="department" key="dep2">Mission College Blvd</orgName>
								<orgName type="institution">Intel Corp</orgName>
								<address>
									<postCode>2200, 95052</postCode>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Southern California</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Implementation of H.264 encoder and decoder on personal computers</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2005-07-19">19 July 2005</date>
						</imprint>
					</monogr>
					<idno type="MD5">C810EE69F243CD55E8F7D1D74422F060</idno>
					<idno type="DOI">10.1016/j.jvcir.2005.05.004</idno>
					<note type="submission">Received 27 April 2004; accepted 10 May 2005</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.264</term>
					<term>Video codec</term>
					<term>Multimedia</term>
					<term>MMX/SSE Technologies</term>
					<term>SIMD</term>
					<term>Hyper-Threading Technology</term>
					<term>Multi-threading</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>H.264 is an emerging video coding standard, which aims at compressing high-quality video contents at low-bit rates. While the new encoding and decoding processes are similar to many previous standards, the new standard includes a number of new features and thus requires much more computation than most existing standards do. The complexity of H.264 standard poses a large amount of challenges to implementing the encoder/decoder in real-time via software on personal computers. This work analyzes software implementation of H.264 encoder and decoder on general-purpose processors with media instructions and multi-threading capabilities. Specifically, we discuss how to optimize the algorithms of H.264 encoders and decoders on Intel Pentium 4 processors. We first analyze the reference implementation to identify the time-consuming modules, and present optimization methods using media instructions to improve the speed of these modules. After appropriate optimizations, the speed of the codec improves by more than 3•. Nonetheless, the H.264 encoder is still too complicated to be implemented in real-time on a single processor. Thus, we also study how to partition the H.264 encoder into multiple threads, which then can be run on systems with multiple processors or multi-threading capabilities. We analyze different multi-threading schemes that have different quality/performance, and propose a scheme with good scalability (i.e., speed) and good quality. Our encoder can obtain another 3.8• speedup on a four-processor system or 4.6• speedup on a four-processor system with Hyper-Threading Technology. This work</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>H.264 <ref type="bibr" target="#b6">[7]</ref> is an emerging video coding standard proposed by the Joint Video Team (JVT). The new standard is aimed at high-quality coding of video contents at very low-bit rates. H.264 uses the same hybrid block-based motion compensation and transform coding model as some existing standards, such as H.263 and MPEG-4 <ref type="bibr" target="#b7">[8]</ref>. Furthermore, a number of new features and capabilities have been introduced in H.264 to effectively improve the compression efficiency. As the standard becomes more complex, the encoding and decoding processes require much more computation power than most existing standards. For example, the reference encoder on the state-of-the-art processors run at orders of magnitude slower than real-time even for CIF sized video sequences.</p><p>While the complexity of emerging video codec (and many other multimedia applications) imposes new demands on processor performance, most modern microprocessors have multimedia instructions and multi-threading capabilities to facilitate multimedia applications. First, the single-instruction-multiple-data (SIMD) execution model was introduced to execute several computations in parallel with a single instruction. Examples include MMX and SSE Technologies <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b11">12]</ref> in Intel architectures. Second, simultaneous multi-threading <ref type="bibr" target="#b19">[20]</ref> and chip-multi-processor <ref type="bibr" target="#b4">[5]</ref> were introduced to enable a processor to execute multiple threads simultaneously. Examples include Hyper-Threading Technology in Intel architectures. Because multimedia applications tend to exhibit large amounts of computation with parallelism, we can also exploit the parallelism in the thread level besides executing multiple data in a single instruction. These advances in personal computers in addition to higher clock frequency have provided the necessary computation power for many multimedia applications.</p><p>Nonetheless, to implement multimedia applications on personal computers requires some hardware-specific algorithm modifications. In this paper, we analyze software implementation and optimize the algorithms of H.264 encoder and decoder on general-purpose processors with media instructions and multi-threading capabilities.</p><p>The contributions of this paper include:</p><p>(1) By analyzing the decoder and encoder software implementation, we identified: (i) the time-consuming modules of the H.264 codec on personal computers and (ii) the hardware-specific algorithm modifications to implement those modules efficiently on the modern microprocessors.</p><p>(2) Using the latest MMX/SSE technologies, we speeded up the H.264 decoder and encoder significantly. While previously <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b16">17]</ref> demonstrated how to use MMX technology for MPEG-4 decoder and H.263 encoder, this work is on H.264-specific modules. (3) Using the latest multi-threading architectures with Hyper-Threading Technology, we speeded up the H.264 encoder by another substantial amount. Moreover, we have done an in-depth study on different trade offs in video quality and parallelization.</p><p>The novelties in this paper include:</p><p>(1) We implemented a sub-pixel interpolation procedure illustrated in Fig. <ref type="figure" target="#fig_1">3</ref> (Section 3.3) to reduce unaligned memory loads. Our proposed scheme is 3• faster than the reference implementation. <ref type="bibr" target="#b1">(2)</ref> We designed a chain matrix multiplication procedure depicted in Fig. <ref type="figure" target="#fig_5">8</ref> (Section 3.4) to avoid data rearrangement for integer-transform implementation. Our SIMD matrix multiplication scheme is 4• faster than the reference implementation using the multiplication-free algorithm. (3) We multi-threaded the H.264 encoder in a fine granularity (using a wavefront order as shown in Fig. <ref type="figure" target="#fig_3">14</ref> in Section 4.3) and demonstrated good speedup with limited video quality degradation. While there are some works in parallel MPEG encoders <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23]</ref>, all of them are based on coarser granularities (either on group-of-picture level or slice level). To our best knowledge, we are the first one in the literature that demonstrated the above <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b24">25]</ref>. Previously, Iverson et al. <ref type="bibr" target="#b12">[13]</ref> demonstrated algorithmic-level optimization to motion estimation of H.264. And, Lappalainen et al. <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref> analyzed the complexity of H.264 decoder and encoder on personal computers.</p><p>The rest of the paper is organized as follows: Section 2 provides a brief introduction of the uniqueness in H.264 standard. Section 3 shows our SIMD optimization methods used to improve the speed. Section 4 discusses the design consideration of multi-threading implementation of the encoder, including performance and quality trade off. Section 5 discusses the required hardware-specific algorithm modifications to implement multimedia applications on the modern microprocessors. Finally, conclusions are presented in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Uniqueness of the H.264 standard</head><p>H.264 has similar coding schemes as H.263 and MPEG-4. The standard includes the use of block-based motion compensation, DCT-like transform coding, scalar quantization, zigzag scanning, and entropy coding. However, specific new concepts and features differentiate H.264 from the other standards. Here, we briefly introduce a number of the unique features included in the baseline profile of H.264 coding standard.</p><p>First, the motion compensation model used in H.264 is more flexible and efficient than those in the early standards. Multiple reference frames for prediction is supported in the standard, and more choices of motion compensation block sizes and shapes are provided for each macroblock (e.g., 16  . High-motion vector resolution is specified, where sub-pel interpolation could provide higher spatial accuracy at fractional positions. In addition, a well-designed in-loop deblocking filter is used to reduce visual artifact. The new methods provide a more precise model for motion compensation, which can dramatically minimize the impact of the difference of predicted blocks, and yield a much better perceptual quality for the decoded video stream.</p><p>Another uniqueness of H.264 is that the conventional DCT transform is replaced by a DCT-like integer transform. The transform can be implemented with additions and shifts only (therefore, so-called Ômultiplication-freeÕ), which is believed to have a significant computational advantage compared with DCT transforms. Moreover, the precise integer transform eliminates any mismatch between the encoder and the decoder <ref type="bibr" target="#b15">[16]</ref>.</p><p>The standard also allows flexible choices for slice size-even one slice per frame. For video streaming, the slice size is usually decided by the packet size of the network protocol. For other purposes, the whole frame can be coded into a single slice for better compression efficiency. In MPEG-2, baseline MPEG-4, or H.263, a picture must be divided into slices. This breaks the dependence between macroblocks. When a macroblock in one slice cannot exploit other macroblocks in another slice for compression, the compression efficiency decreases. H.264, without compulsorily breaking a frame into multiple slices, can offer better coding efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Implementation of H.264 decoder using SIMD media instructions</head><p>While todayÕs H.264 reference code can decode approximately 30 frames of CIF images/s on state-of-the-art personal computers, it is an order of magnitude slower than a well-optimized MPEG-2 decoder <ref type="bibr" target="#b5">[6]</ref>. This is because of two factors: (1) algorithmic complexities and (2) implementation optimality. In this section, we present optimization methods using media instructions to improve the speed of the H.264 decoder.</p><p>Section 3.1 briefly introduces the media instructions available on Intel microprocessors. Section 3.2 identified the time-consuming modules of H.264 decoder before exploiting the benefits of media instructions. Sections 3.3 and 3.4 illustrate the techniques of speeding up two of the most time-consuming modules-motion compensation and integer transform. Section 3.5 shows that after appropriate optimizations, the speed of the codec improves by more than 3•.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Introduction of Intel SIMD instructions</head><p>The Single Instruction, Multiple Data (SIMD) execution model was introduced in the Intel architectures, with MMX technology and streaming SIMD extensions (SSE). The SIMD technology enables multiple arithmetic or logic operations to be executed simultaneously, in order to improve the speed of the program. This is realized by introducing longer registers (64-bit MMX registers and 128-bit SSE registers) and processing multiple data units stored in these registers simultaneously. For example, a 128-bit SSE register can be used to store up to 16 units of 8-bit integers, and thus up to 16 arithmetic operations can be executed simultaneously by using two SSE registers. This results in a significant speed improvement.</p><p>Nevertheless, there are restrictions on these SIMD instructions. While loading data into these longer registers, an unaligned data access can incur significant performance penalties. This is particularly true for cache line splits. The size of a cache line is 64 bytes in the Pentium 4 processor and is 32 bytes in Pentium III processors. On the Pentium 4 processor, an access to data that are not aligned on 64-byte boundary leads to two memory accesses and requires several micro-operations to be executed instead of one. Memory accesses that span either 16 byte (but not 64 byte) boundaries are still likely to incur a large performance penalty. This is because they are executed near instruction retirement, and can incur stalls that are on the order of the depth of the microprocessor pipeline. For best performance, we should access data on natural operand size address boundaries, such as, access 64-bit data whose base address is a multiple of eight and access 128-bit data whose base address is a multiple of 16. Otherwise, the memory access is unaligned.</p><p>The rest of Section 3 demonstrates how to implement the H.264 decoder using the benefits of media instructions while circumventing the restrictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Identifying time-consuming modules of the H.264 reference decoder</head><p>Our first step is to identify time-consuming modules in H.264 decoder. Fig. <ref type="figure" target="#fig_0">1</ref> shows the breakdown of the execution time of the H.264 reference decoder on a 2.4 GHz Pentium 4 processor with 512 MB memory. The on-chip first-level cache and second-level cache are 8K and 512 KB, respectively. The decoder runs under Microsoft Windows XP. In the experiment, we choose CIF-resolution foreman sequence with the IBBP structure. (The decoding rate is approximately 30.7 frames/s.)</p><p>From the diagram, it is easy to identify the following time-consuming modules in the decoder: luminance and chrominance motion compensation, inverse integer transform, entropy decoding, and deblocking filtering. (Due to space limitation, the time breakdown for different test conditions is not included here. Readers can find the execution time profiles for two different bit rates from <ref type="bibr" target="#b24">[25]</ref>. Basically, time-consuming modules are roughly the same.) We are interested in implementing these most time-consuming modules using SIMD technologies in order to improve the speed of the decoder. In the following sub-sections, we will discuss implementation techniques in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Motion compensation</head><p>Among many time-consuming modules in H.264, motion compensation is the most time-consuming one. As H.264 uses a 1/4 pixel resolution for motion vectors and motion compensation, intensive computation is required for interpolating pixels at fractional positions in the H.264 decoder. As described before, H.264 uses seven different block sizes to perform motion estimation on each macroblock. For the interpolation process, all of the blocks are based on 4 • 4 block size. In this case, for SIMD implementation SSE registers could hardly be utilized fully. This is because only four pixels are calculated at one time. From a number of experiments, we have found that the total number of 4 • 4, 4 • 8, and 8 • 4 blocks used in motion estimation takes up only a small portion among different block sizes ($5% in Pframes and $1% in B-frames). Therefore, we developed an efficient sub-pixel interpolation method for 8 • 8 blocks, while similar SIMD implementations can also be applied to macroblocks for 4 • 4 blocks. This approach makes full use of the 128-bit register, and improves the speed for pixel interpolation during both luminance and chrominance motion compensation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Luminance motion compensation and filter design</head><p>In H.264 decoder, a 6-tap FIR filter is implemented for 1/4 pixel interpolation. The filter coefficients are constants and pre-stored. The interpolation process conducts vector product between the coefficient vector and the image data vector. An SSE instruction PMADDWD <ref type="bibr" target="#b9">[10]</ref> can facilitate this implementation. Fig. <ref type="figure" target="#fig_2">2</ref> shows how the instruction PMADDWD works: the instruction will take two 128-bit SSE registers as its operands, where each data unit must be 16-bit integers. Eight multiplications will be performed on the pairs of 16-bit integers simultaneously. And, the results in pairs are added together and stored in one SSE register as 32-bit integers. Therefore, the vector product mentioned above can be implemented by loading the image data vector and the filter coefficient vector into two SSE registers and performing PMADDWD instruction on them, then summing up the four 32-bit data units in the resulting register to get the final result.</p><p>It seems that a different image data vector must be loaded each time while calculating a new pixel. For interpolating an 8 • 8 block in one dimension, the vectors must be loaded 64 times. Because most of these data loading will be unaligned loads, 2 the loading penalty and overhead will be huge. Thus, it will be more desirable to reuse the previously loaded image data in order to avoid the abundant loading operations.</p><p>Here is our scheme for row interpolation. We can first load 6 + 8 À 1 = 13 relative pixels into a 128-bit register (as the image data are stored in bytes). We then unpack and shift them into two SSE registers (R1 and R2) with required 16-bit length as shown in Fig. <ref type="figure" target="#fig_1">3</ref>. Since the filter coefficients must be shifted along the row, we can load four different copies of the filter coefficients with different shift phases, and then perform PMADDWD instruction on R1 and the four copies of the filter coefficients to get the first four pixels. Please note that while calculating the fourth pixel, since the coefficient c5 (equals to 1) cannot fit into the fourth coefficient register, one more addition operation will be performed on x (i + 6) to calculate the fourth interpolated pixel separately. By using the same approach, the next four pixels can be calculated using R2. As this method avoids penalties introduced by repetitive unaligned loads and reduces the data loading overhead, it greatly outperforms the original method.</p><p>For column interpolation, simple packed shifts and additions can facilitate the interpolation process. The filter coefficients are (1, À5, 20, 20, 5, and 1), which can be simply substituted with shifts and additions (e.g., 20 = 2 Ù 4 + 2 Ù 2). Therefore, six rows of data will be first loaded into six 128-bit registers, followed by paced shifts and additions to calculate the final result. Because the SSE registers can hold eight 16-bit data, we can calculate eight interpolated pixels in a row. The advantage of  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Chrominance motion compensation</head><p>Unlike many previous video coding standards, chrominance motion compensation occupies a significant percentage in the total motion compensation process of the H.264 reference decoder. As shown in Fig. <ref type="figure" target="#fig_3">4</ref>, the interpolated chrominance pixel E is derived from the four corresponding pixels (A, B, C, D) with the formula:</p><formula xml:id="formula_0">E ¼ ððs À d x Þðs À d y ÞA þ d x ðs À d y ÞB þ ðs À d x Þd y C þ d x d y D þ s 2 =2Þ=s 2 ;</formula><p>where A, B, C, and D are the integer position reference picture samples surrounding the fractional sample location, and d x and d y are the fractional parts of the sample position in units of one-eighth samples for quarter sample interpolation. Because d x , d y , (s À d x ), and (s À d y ) stay the same in the same block, we can calculate the coefficients (s À d x ) (s À d y ), d x (s À d y ), (s À d x )d y , and d x d y in advance. After that, we can simply use SIMD instructions on multiple pixels (e.g., 4 • 4 block) to compute the interpolated chrominance pixels with similar idea described in Section 3.3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Inverse transform and matrix multiplication</head><p>Instead of using DCT/IDCT, H.264 uses a 4 • 4 integer transform to convert spatial-domain signals into frequency-domain and vice versa. Fig. <ref type="figure">5</ref> shows the mathematical form of the inverse integer transform in H.264 decoder, which can be calculated using matrix multiplications. Since the first and the last matrices have only constant coefficients of ±1 and ±1/2, it is possible to implement the calculation by using only additions, subtractions, and shifts. This Ômultiplication-freeÕ method is quite efficient and, thus, has been implemented in the reference code. Nonetheless, it is hard to further optimize it by utilizing SIMD instructions because the operations on each operand are different. However, the original form of the integer and inverse integer transform are 4 • 4 matrix multiplications, which can be implemented by using SIMD instructions, hopefully yielding better performance than the Ômultiplication-freeÕ method.</p><p>Fig. <ref type="figure">6</ref> shows a typical 4 • 4 matrix multiplication. As PMADDWD can be used to optimize the operation of vector products in the FIR filtering, we can store a row vector of X and a column vector of Y into two registers, and then use PMADDWD to produce the results. However, this simplest scheme is not the optimal. First, to calculate each element after PMADDWD instruction, we must shift the result, retrieve, and add the 32-bit integers 3•. Also, it is costly to load column vector of matrix Y into an SSE register. There will be overhead for these operations. Thus, we must utilize the structure of matrix multiplication to avoid this problem. The following shows an efficient matrix multiplication method that can be completed without shifting or abundant loading operations. Fig. <ref type="figure">7</ref> shows an example of computing the first row of the resulting matrix. Matrix X and Y are loaded into SSE registers in a particular form. The loading process can be realized efficiently with combinations of SIMD instructions. After that, PMADDWD is performed on these registers in pairs. Then the two resulting 128-bit data are added together in the 32-bit integer precision, hence the first row of the resulting matrix is obtained right away. For the next three rows, similar methods will be utilized, in this case there is no need to reload matrix Y, and the final results are well aligned in rows that do not need any additional operations to rearrange their orders. This method can be applied for multiple 4 • 4 matrix multiplications, and it can also be revised to fit for matrix multiplication of other sizes.</p><p>The realization of our H.264 integer transform extends the above general approach. We prepare the data in advance so that the result of the first matrix multiplication is in order for the second matrix multiplication to use immediately. In this case, no extra data rearrangement is needed in the middle of the processing. Moreover, as shown in Fig. <ref type="figure">5</ref>, the first and last matrices in the equation are constant. Thus, minimal extra cost to pre-arrange data in the right format.</p><p>We first multiply the last two matrices A and B together and store the result in matrix Y. Next, we multiply the first matrix X with the matrix Y to get the final resulting matrix R. Because we have pre-arranged the data before the multiplications, the results of the multiplications and additions are in order during the chain matrix multiplication process. Fig. <ref type="figure" target="#fig_5">8</ref> illustrates the whole inverse integer-transform process. First, we load matrix A as 16-bit integer operands into an SSE register and shuffle their positions to the right order. Second, we load the first two columns in matrix B into another two registers, where the data are all constant and have been prepared in advance. After that, PMADDWD instruction will be performed on these two registers in pairs. Therefore, we get y 00 , y 10 , y 01 , and y 11 in the first SSE register. Similar operations will be utilized on the last two columns in matrix B to calculate the temporary results y 02 , y 12 , y 03 , and y 13 . In this case, we can use a pack operation on these two registers to form the final result, and their positions are shown in the matrix of Fig. <ref type="figure">5</ref>. Now, the resulting register contains the data just in the right order for the next step of matrix multiplication. Because we have considered the data position ahead of time, there will be no need to further rearrange their positions during the processing. This reduces the middle-processing time compared with the original method.</p><p>Table <ref type="table" target="#tab_2">1</ref> shows a comparison of three different implementations for the inverse transform. It shows the time used by 50 million runs of each of the programs. It is clear that the ÔMultiplication-freeÕ method implemented in the reference code outperforms the original matrix multiplication implementation substantially. However, with the method described above, we achieve another 4• speedup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Seedup of SIMD-optimized H.264 decoder</head><p>As a result of our implementation described above, the optimized H.264 decoder is about 2.5-3• faster than the reference decoder.</p><p>Table <ref type="table">2</ref> shows the speedup for the kernel modules in the decoder, where chrominance motion compensation gets a remarkable improvement mainly as a result of our efficient implementation on sub-pixel interpolation. (Similar techniques can be applied to the encoders as well. Table 2 also shows the speedup for each key module residing in H.264 encoder.) Fig. <ref type="figure">9</ref> shows the speedup of the optimized decoder on different encoded video streams. It is clear that for video streams with higher bit rates (such as Coastguard, and video streams with smaller quantization steps), it is harder to achieve large speedup. This is due to the fact that the entropy decoding process, which will have a much larger impact on the system speed, is one of the modules not yet optimized in our work. Video streams in IBBP modes achieve better speedup because the motion compensation module in their decoding process is more critical than video streams in IPPP mode. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Multi-threaded implementation of H.264 encoder</head><p>As Section 3 demonstrated that using MMX/SSE technologies can speed up the H.264 decoder by 2-4•, we applied the similar techniques to the H.264 reference encoder and achieve 2-3• speed improvement. Additionally, similar to many other works in the literature <ref type="bibr" target="#b12">[13]</ref>, we implemented fast motion estimation and mode decision algorithms on top of the SIMD-optimized reference encoder. As motion estimation and mode decision are the performance bottlenecks, we got another 2-4• speedup after algorithmic optimization. <ref type="foot" target="#foot_1">3</ref> While it is much faster than it was, the speed of the encoder is still too slow on a single processor. Even with SIMD media technology and algorithmic optimization, it only encodes about 1 frame/s for CIFresolution sequences on state-of-the-art personal computers. This means that there is a lot of room for us to continue improving the speed of the H.264 encoder. In this section, we demonstrate how to partition the H.264 encoder into multiple threads, which then can be run faster on systems with multiple processors or multi-threading capabilities. Fig. <ref type="figure">9</ref>. Decoder speedup on different video streams. The first parameter in the x-axis label is the video sequence (C, coastguard; MD, mother and daughter; F, foreman). The second parameter is the quantization step. The third parameter is the group-of-picture structure. The fourth parameter is the video resolution.</p><p>Section 4.1 briefly introduces IntelÕs simultaneous multi-threading technology. Section 4.2 discusses possible parallelism available in the H.264 encoder and analyzes different multi-threading schemes that demonstrate different quality/performance. Section 4.3 depicts our proposed fine-granularity parallel implementation, which is with good scalability (i.e., speed) and good quality. Section 4.4 shows that our multi-threaded encoder has 3.8• speedup on a four-processor system or 4.6• speedup on a four-processor system with Hyper-Threading Technology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Introduction to Hyper-Threading Technology</head><p>Recently, processors/systems that can run multiple software threads have received increasing attention as a means of boosting overall performance. This is because multimedia applications tend to exhibit large amounts of computation and parallelism. We can also exploit the parallelism in the thread level besides executing multiple data in a single instruction.</p><p>In 2002, Intel introduced Hyper-Threading Technology, which runs multiple threads simultaneously, into Intel Xeon processors and Pentium 4 processors <ref type="bibr" target="#b19">[20]</ref>. In a processor with Hyper-Threading Technology, one physical processor exposes two logical processors. Similar to a dual-core or dual-processor system, a processor with Hyper-Threading Technology appears to an application as two processors. Two applications or threads can be executed in parallel. The major difference between processors with Hyper-Threading Technology and dualprocessor systems is the different amounts of duplicated resources. In processors with Hyper-Threading Technology, only a small amount of the hardware resources is duplicated, while the front-end logic, execution units, out-of-order retirement engine, and the memory hierarchy components are shared. Thus, compared to processors without Hyper-Threading Technology, the die-size is increased by less than 5% <ref type="bibr" target="#b19">[20]</ref>.</p><p>As Intel Corporation and many other companies are making future processors capable of multi-threading <ref type="bibr" target="#b4">[5]</ref>, the rest of Section 4 demonstrates how to improve the speed of H.264 encoder on systems with multi-threading capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Possible parallelism vs. quality</head><p>Before we determine the multi-threading scheme, we should decide the thread granularity. A video sequence typically is composed of group of pictures (GOP), which consists of frames. Frames can further be decomposed into slices, which contain macroblocks. The most straightforward approach to encode the video sequences is by GOPs. This is because each GOP acts independently from each other <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b21">22]</ref>. Another approach is based on slice level. This is because slices are self-content and independent of other slices <ref type="bibr" target="#b22">[23]</ref>. These decompositions are naturally the opportunities in parallelizing the H.264 encoder. While these places are good opportunities for parallelism, these places may not be the best places. For example, GOP-level parallelism is simple, but multi-threading at the GOP-level parallelism incurs a very long latency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Slice-level parallelism</head><p>One possible scheme of decomposition is to divide a frame into small slices. The advantage of parallelizing among slices is that the slices in a frame are independent. Thus, we can simultaneously encode all slices in any order. However, the disadvantage is that (different from MPEG-2 standard) slices in H.264 may significantly increase the bit rate at the same video quality. Fig. <ref type="figure" target="#fig_0">10</ref> shows the compression efficiency of the video encoder (rate-distortion) when a frame is divided into different numbers of slices. When a frame is divided into nine slices, the bit rate at the same quality is about 10-15% higher. This is because slices break the dependence between macroblocks. When a macroblock in one slice cannot exploit another macroblock in another slice for compression, the compression efficiency decreases. In order not to increase the bit rate at the same video quality of the parallelized encoder, we should exploit other parallelism in the video encoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Frame-level parallelism</head><p>Another possible scheme of exploiting parallelism is to identify independent frames. Normally, we encode a sequence of frames using an IBBPBBP. . . structure. While some frames (e.g., P-frames) are reference frames for others, some frames are not necessary. To increase parallelism, we treat B-frames as non-referenced frames in our implementation of H.264 encoder. The dependence among the frames is shown in Fig. <ref type="figure" target="#fig_7">11</ref>. In this PBB encoding structure, the completion of encoding a P-frame will make the subsequent one P-frame and two B-frames ready for encoding. The more frames encoded simultaneous, the more parallelism we can explore. Therefore, the P-frame is on the critical point in the encoder. Accelerating P-frame encoding will bring more frames ready for encoding, and avoid the idle of threads. In our implementation, we will encode I or P-frames first, then B-frames.</p><p>Unlike dividing a frame into slices, utilizing parallelism among frames will not increase the bit rate. However, the dependence among them will limit the thread Fig. <ref type="figure" target="#fig_0">10</ref>. Encoded picture quality vs. the number of slices in a picture.</p><p>scalability. One scheme is to combine the above two approaches into one implementation. First, the parallelism among frames is explored; we can gain performance from it without bit rate increase. After we reach the upper limit of the number of threads in the frame-level parallelism, the parallel among slices is explored subsequently. As a result, processor resources are utilized as much as possible and the compression ratio is kept as high as possible (i.e., the bit rate as low as possible).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3.">Performance analysis</head><p>Because dividing a frame into multiple slices increases not only the parallelism, but also the bit rate, we should carefully choose the number of slices per frame. Fig. <ref type="figure" target="#fig_6">12</ref> shows the relationship of the execution time and the bit rate vs. the number of slices in a frame. We change the number of slices from 1 to 18, while keeping the encoded picture quality constant. On a dual-processor system, the execution has a big speedup when the number of slices in a frame changes from one to two, but nearly keeps unchanged while the number of slices changes from 2 to 18. Meanwhile, the bit-rate increase is small if the number of slices is smaller than three, but starts to become larger after three slices. In this case, dividing a frame to two or three slices is a good-enough tradeoff point between the bit rate and the execution time. On our four-processor system with Hyper-Threading Technology, we need much more than three slices to keep eight logical processors busy. We need nine threads to achieve roughly the best performance. In this case, the bit-rate increases more than 10%.  In order not to increase the bit rate at the same video quality of the parallelized encoder, we should exploit other parallelism in the video encoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Our fine-granularity parallel implementation of H.264 encoder</head><p>As illustrated in Section 4.2, slice-level parallelism is not an optimal choice for the multi-threading of H.264 video encoding. We should find some finer data partitioning, i.e., macroblock-level parallelism, to provide enough parallel capabilities without any video quality losses. Our work is inspired by <ref type="bibr" target="#b23">[24]</ref>, where a fine-grained parallel decoder implementation is demonstrated. Data partitions used are basically built from the macroblock level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Macroblock-level parallelism</head><p>The current coding macroblock has dependencies on its adjacent left, upper-left, upper, and upper-right macroblocks, as shown in Fig. <ref type="figure" target="#fig_8">13</ref>.</p><p>(1) Intra prediction: pixels in the current macroblock may be predicted from pixels of its left, upper-left, upper, and upper-right macroblocks. (2) Motion vector prediction: motion vectors are predicted from those of its left, upper-left, upper, and upper-right macroblocks. (3) Deblocking filter: filtering is performed on the top four rows of pixels and leftmost four columns of pixel of the current macroblock, with the bottom four rows of the upper macroblock and the rightmost four columns of the left macroblock. Due to the data dependencies described above, macroblocks can only be encoded after the adjacent partitions are already encoded.</p><p>The spatial dependencies within one frame imply a specific processing-order restriction. For example, the top-left macroblock should be processed at first and other macroblocks must wait because they have data dependencies on it. On the other hand, after the second macroblock has been encoded, there are possibilities to select either the top-right or bottom-left macroblock for encoding. Fig. <ref type="figure" target="#fig_3">14</ref> shows our macroblock data-partition scheme. Let the horizontal and vertical numbers of macroblocks in a frame be w and h, and MB (i) denotes the ith macroblock in the frame (in the raster scan order). According to the restriction of data dependencies in a frame, MB (i) and MB (i + w À 2) can be encoded simultaneously and thus they have the same time stamp. MB (w + 2) in the second row requires the information from MB (1), MB (2), MB (3), and MB (w + 1). At the same time, MB (4) can be encoded as well. In general, the scheduling of MB encoding should be like this: {MB (1)}, {MB (2)}, {MB (3), MB (w + 1)}, {MB (4), MB (w + 2)}, {MB <ref type="bibr" target="#b4">(5)</ref>, MB (w + 3), MB (2w + 1)}, . . . , {MB ((h À 1) * w), MB (h * w À 2)}, {MB (h * w À 1)}, and {MB (h * w)}. Numbers in Fig. <ref type="figure" target="#fig_3">14</ref> indicate the time stamp.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Inter-frame parallelism</head><p>While the maximum number of simultaneous threads in this scheme is (w + 1)/2 (e.g., 11, 23, and 60 threads for CIF, SD, and HD video), there are only limited amount of speedup if we only exploit the concurrency within one frame. This is because parallelism is dramatically limited at the beginning and at the end of encoding a frame, where only one or two macroblocks can be simultaneously encoded. In this case, it is hard for the encoder to gain good performance when the number of available hardware threads is larger. For instance, for CIF images, the speed of eightthread encoders over that of four-thread encoders is very small (31/27 = 1.15).</p><p>To improve the whole paralleling performance of video encoding, temporal dependencies should also be considered. As shown in the right side of Fig. <ref type="figure" target="#fig_3">14</ref>, the top-left most macroblock of Img1 can be predicted from the quarter-pel reconstructed Img0. However, it cannot be immediately encoded when the first row of Img0 has been processed. This is because of the range of motion estimation/compensation is normally larger than a couple of macroblocks. To accurately estimate/compensate the motion from the predicted frames, we must wait until the encoded macroblocks are reconstructed after deblocking filter and quarter-pixel interpolation. If the motion search range is twice as large as macroblock size, the first top-left macroblock in Img1 cannot be encoded until the third row of Img0 is coded. After that, the Fig. <ref type="figure" target="#fig_3">14</ref>. Macroblock-level dependency scheme and coding model. macroblocks in the first row of the Img1 can be encoded simultaneously together with some macroblocks in Img0. The line with time stamp 17 in Fig. <ref type="figure" target="#fig_3">14</ref> demonstrates that the first macroblock in Img1 can be concurrently encoded with the other six macroblocks in Img0. By adding inter-frame parallelism, our final scheme provides more parallelism in H.264 encoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3.">Our multi-threading implementation of H.264 encoder</head><p>Our multi-threading scheme has N + 1 simultaneous threads when there are N processors available. A main thread handles the pre-and post-image processing tasks. Other N threads act as the working threads to encode the macroblocks between these two adjacent images alternatively. As shown in right-hand side of Fig. <ref type="figure" target="#fig_0">15</ref>, the image pre-processing module reads in the raw image data and assigns the parameters accordingly. The image post-processing module checks the encoding status, generates Fig. <ref type="figure" target="#fig_0">15</ref>. Outline of the proposed multi-threading scheme. the output bitstream, and fulfills quarter-pel image interpolation and reconstruction works. Image pre-processing and image post-processing procedures must be handled sequentially to guarantee the correctness. Hence, we assigned one main thread to handle these. The main thread takes 2-5% of the CPU time. The majority of encoding time is spent on macroblock encoding process, dealing with the motion estimation and mode decision functions to select the best coding mode for each macroblock. Thus, there are N threads to handle the left-hand side of Fig. <ref type="figure" target="#fig_0">15</ref>.</p><p>Here are some details of how it actually works when the encoded GOP structure is IPPP. If bi-directional frames are utilized, we can have even more parallelism.</p><p>(1) The raw data of Img0 is read in and pre-processed in the main thread. After that, Img0 is ready to be encoded. (2) Once the working threads get the ready message, they select candidate macroblocks and encode them subsequently. The macroblocks are encoded in the wavefront order as described in Section 4. (5) The working threads encode these two adjacent images according to the following sequential order: if there is no more ready macroblock to be encoded in Img0, the ready macroblock in Img1 will be encoded. ( <ref type="formula">6</ref>) When all the macroblocks in Img0 have been encoded, the main thread will take over the macroblock encoding process and start the post-encoding procedure-generating the final VLC and output bitstream and finishing the residual deblocking filtering, quarter-pel interpolation, and frame reconstructions. ( <ref type="formula">7</ref>) After (6), Img0 is released. Another new image is read and pre-processed. The above procedure continues until all candidate images are encoded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Speedup of multi-threaded H.264 encoder</head><p>This section summarizes speed improvements of our multi-threaded H.264 encoder. We compare the encoding execution time of our encoder on a first uni-processor system and the first uni-processor system with Hyper-Treading Technology as well as a second system with one processor, the second system with four processors, and the quad-processor system with Hyper-Threading Here is our experimental set up. Our first single-processor system has a 3.06 GHz Intel Pentium 4 processor with a 512 KB second-level cache. Additionally, the second system has four 2.8 GHz Intel Xeon processors, each of which has a 256 KB second-level cache and 2 MB third-level cache. In this case, we can have as many as eight logical processors. To measure single-thread performance on the quad-processor system, we disable the other three physical processors and run a single-thread version of the application. In our experiments, we use a variety of test sequences, covering from CIF to HD resolution. Additionally, we choose high-motion as well as low-motion sequences to make the experiments more comprehensive. The simulations presented here are performed with IPPP GOP structure, i.e., no B frames. Search range has been set to two macroblock size. Rate-distortion-based mode decision is utilized in the experiments. Fig. <ref type="figure" target="#fig_10">16</ref> summarizes the average speedup. Nearly optimal linear speedup has been achieved for the four-processor platform. With Hyper-Threading Technology, an average of 1.18• speedup has been obtained, which is more than the 5% extra cost in chip area to implement Hyper-Threading Technology. However, when comparing the performance of four-processor platform without and with Hyper-Threading Technology, we observe that CIF format sequences only get slightly lower than the normal Hyper-Threading speedup. According to the detailed time profile for each thread, the problem comes from the synchronization overhead and load imbalance, especially: (1) during the starting up or ending encoding process and (2) for high-motion sequences. This is because: (1) the size of CIF format image is comparatively smaller for eight simultaneous working threads and (2) the computational loads have higher variance in high-motion sequences. Therefore, it is very crucial to efficiently allocate and balance the computation loads for small-resolution and high-motion sequences.</p><p>In short, our multi-threaded encoder has 3.8• speedup on a four-processor system or 4.6• speedup on a four-processor system with Hyper-Threading Technology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussions</head><p>In the process of optimizing H.264 decoder and encoder, we discovered a few interesting points regarding efficient video-processing application design, with consideration of the characteristics of general-purpose processor architectures with media instructions and with multi-threading capabilities. The performance improvement techniques demonstrated in this work can be applied not only to H.264, but also to other video, image, or multimedia processing applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Algorithm simplification and optimization</head><p>In many literatures, the way to estimate the computational complexity of a given algorithm is to count the number of different types of operations needed. Algorithms were designed in a way to minimize the number of required operations. Under the newly developed processor architectures, this criterion remains critical but not as accurate. Algorithms with larger number of operations, but simpler program flows, may have a better performance.</p><p>For instance, in the H.264 decoder, the new integer transform were designed such that it can be implemented by using only additions, subtractions, and shifts. The number of multiplications, which was considered one of the most time-consuming operations, was reduced to zero. However, as we described in Section 3.4, this implementation makes it difficult for further SIMD optimization. On the contrary, by implementing the simple traditional matrix multiplication with SIMD instructions and utilizing special implementation techniques, the integer transform actually runs faster.</p><p>As the current and future processors can process multiple data units simultaneously, computational complexity should be counted as the number of operations on the sets of these data units. This will cause a major impact on algorithm design, because different algorithm settings may have the same computational complexity if their difference does not exceed the size of these data sets.</p><p>Here is an example: the PMADDWD instruction can be used to perform FIR filtering efficiently, just like what we did in Section 3.3. As each SSE register can store up to eight 16-bit integers, as long as the filter length does not exceed eight, we can use one SSE register to store the filter coefficients, and another one to store the data to be filtered. Then eight multiplications can be processed simultaneously and the program efficiency is greatly improved. Therefore, an FIR filter of length 4 and that of length 8 will have the same computational complexity since they are processed exactly the same way in this approach. However, the two filters may provide quite different effects because their lengths are different. (Normally, filter of longer length provides better results. As a filter of length 4 and a filter of length 8 have the same complexity, using the filter of length 8 should be a better choice, right?) Same rule applies when we have longer filters, where two or more SSE registers each will be used to store the coefficients and the data. For example filters of length 9-16 will have the same computational complexity.</p><p>As these newly developed processors become standardized, in order to obtain the best possible performance with given timing and cost constraints, algorithm designers must consider the new features in the processors and tailor algorithms accordingly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Data structure and memory operation</head><p>Data structures and alignments are critical for SIMD instructions. On Intel architecture, data units to be loaded must be 16-byte aligned or there will be penalties. Therefore, the programmer or system designer must be more careful while allocating memory spaces in order to avoid unaligned loads. While IntelÕs SSE3 technology introduces a new instruction, LDDQU, that significantly improves 128-bit unaligned memory accesses <ref type="bibr" target="#b11">[12]</ref>, it is generally not recommended unless we cannot avoid such unaligned memory accesses in the algorithm. In <ref type="bibr" target="#b10">[11]</ref>, it is shown that the performance of the block-matching motion estimation algorithm is heavily penalized because of its large number of unaligned memory accesses. Those unaligned memory accesses can hardly be avoided because of the nature of the algorithm. Because the new instruction in IntelÕs SSE3 technology can improve the performance of such unaligned memory access, the block-matching implementation with the new instruction is 1.37• faster than the implementation without it. However, it is noted in <ref type="bibr" target="#b11">[12]</ref> that there are situations where the new instruction may be slower than the existing instructions. That is, the instruction should be used with care. Hence, in general, we recommend transforming the algorithms to avoid unaligned memory accesses (for example, Section 3.3.1) first. If the algorithm cannot avoid such unaligned memory accesses, we use the new instruction.</p><p>As for video processing, normally image data are stored in large matrixes. Since video decoding will process the data in blocks with the size of multiples of four, if we align the first element of the matrix to a 16-byte aligned address, and store the whole matrix consecutively, a large portion of the operations on the matrix will benefit because their data accesses will already be properly aligned. Also if SIMD implementation is desired, the length of data units to be processed simultaneously must be identical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Data dependence and parallelism</head><p>Complicated data dependence makes it harder to parallelize the decoder/encoder. On one hand, because modern processors are supporting multiple threads simultaneously, one way to making the application run faster is to exploit the parallelism. On the other hand, the application may have complicated data dependence, which is required for higher quality. Either we have to trade off between parallelism and quality, or we have to design a much more complicated parallel scheme. For example, because breaking a frame into slices in H.264 degrades the compression efficiency substantially, the scheme in <ref type="bibr" target="#b3">[4]</ref> trades the quality for speed. For another instance, in Section 4.3, we proposed the macroblock-level decomposition, which provides good execution speedup without losing video quality. Nonetheless, our scheme needs 10-30• more synchronizations per second than the slice-based scheme. For future algorithm designs, we should consider potential parallelism available in the microprocessors and avoid introducing complicated data dependences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>While state-of-the-art codecs are getting more complicated and demand more computational capabilities than before, personal computers are getting faster. In this paper, we have studied and optimized the performance of H.264 encoder and decoder on Intel Pentium 4 processors. This work demonstrates that, after appropriate performance optimizations with SIMD instructions and with multi-threading technology, the encoder/decoder gained significant performance improvements. Thus, it is easy to implement high-performance multimedia applications on personal computers without installing any additional special hardware.</p><p>While we demonstrated the optimization strategies for H.264 encoder/decoder on Intel architecture, the methodology can be extended in two directions. First, the performance improvement techniques can also be applied to other video or multimedia processing applications. Second, many of the optimization strategies can also be applied to other platforms.</p><p>For best quality and performance, it is important to understand the implications from the underlying microprocessor architecture and modify the algorithm of the application accordingly. For example, we must exploit both data and program parallelism in the applications to get the best performance. Although an algorithm may require more computation (for example, matrix multiplication vs. multiplication free), the algorithm may run faster if it can be implemented in SIMD media instructions or in multiple threads (as shown in Table <ref type="table" target="#tab_2">1</ref>). At the same time, we should be very careful about any quality degradation when we want to increase the parallelism (as shown in Fig. <ref type="figure" target="#fig_6">12</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Time breakdown of H.264 reference decoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. FIR implementation of sub-pel interpolation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. PMADDWD instruction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Chrominance motion compensation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 . 4 •</head><label>64</label><figDesc>Fig. 6. 4 • 4 matrix multiplications.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Chain matrix multiplications.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 12 .</head><label>12</label><figDesc>Fig.<ref type="bibr" target="#b11">12</ref>. Speedup and bit rate vs. the number of slices in a frame.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Data dependence among frames.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Possible spatial data dependencies for a macroblock.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>3.1. (3) While Img0 is being encoded, reconstructed images should be prepared in advance for temporal predictions for Img1. If half of Img0 have been encoded, these encoded macroblocks are used to perform partial deblocking filtering, partial quarter-pel interpolation, and partial frame reconstruction. (4) When these preparations are finished, Img1 and Img0 can be concurrently encoded.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Speedup on different platforms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>• 16, 16 • 8, 8 • 16, 8 • 8, 8 • 4, 4 • 8, 4 • 4</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>Comparison of different implementation on inverse transform</figDesc><table><row><cell>Implementation method</cell><cell>Time used (seconds)</cell><cell>Speedup from original</cell><cell>Speedup from</cell></row><row><cell></cell><cell></cell><cell>matrix multiplications</cell><cell>multiplication-free</cell></row><row><cell>Original matrix multiplication</cell><cell>8.22</cell><cell>-</cell><cell>0.3•</cell></row><row><cell>Multiplication-free</cell><cell>2.41</cell><cell>3.4•</cell><cell>-</cell></row><row><cell>Matrix multiplication with SSE</cell><cell>0.56</cell><cell>14.7•</cell><cell>4.3•</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Y.-K. Chen et al. / J. Vis. Commun. Image R. 17 (2006) 509-532</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>There are a number of existing techniques for algorithmic optimization, e.g.<ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b25">26]</ref>. We implemented an 8-15• faster motion estimation algorithm, which is a hierarchical multi-hexagon motion search scheme with predictor selection and prediction mode reordering<ref type="bibr" target="#b14">[15]</ref>. Additionally, we implemented a 7-10• faster</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>• 4 mode decision algorithm, which utilizes the edge directional information of the video content to reduce the intra-prediction modes. Furthermore, in rate-distortion optimization criterion, we just calculate the SATD value to decide the best intra-prediction mode. Afterward, our SIMD-optimized and algorithmoptimized encoder is 2-4• faster than the SIMD-optimized encoder, and the degradation of video quality is $0.06 dB at the same bit rate.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Real-time MPEG encoding in shared-memory multiprocessors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Barbosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Kitajima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Meira</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Conf. Parallel Comput. Syst</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">MPEG-4 video decoder optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Casalino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Cagno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Luca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Conf. Multimedia Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="363" to="368" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<author>
			<persName><forename type="first">Y.-K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Holliman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Debes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zheltov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Knyazev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bratanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Belenov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Media applications on Hyper-Threading Technology</title>
		<imprint>
			<date type="published" when="2002-02">February. 2002</date>
			<biblScope unit="page" from="47" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Efficient multi-threading implementation of H.264 encoder on Intel Hyper-Threading Architectures, IEEE Pacific-Rim Conf. Multimedia (December)</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-K</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="469" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A split at the core</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Gibbs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Am</title>
		<imprint>
			<biblScope unit="page" from="96" to="101" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">MPEG decoding workload characterization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Holliman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-K</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Computer Architecture Evaluation using Commercial Workloads</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="23" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Information Technology-Coding of Audio-Visual Objects, Part10-Advanced Video Coding</title>
		<imprint>
			<biblScope unit="page" from="14496" to="14506" />
		</imprint>
		<respStmt>
			<orgName>International Standard Organization</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Information Technology-Coding of Audio-Visual Objects, Part2-Visual</title>
		<idno>ISO/IEC 14496-2</idno>
		<imprint/>
		<respStmt>
			<orgName>International Standard Organization</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">IntelÒ PentiumÒ 4 Optimization Reference Manual</title>
		<author>
			<persName><forename type="first">Intel</forename><surname>Corp</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">248966</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Intel</forename><surname>Corp</surname></persName>
		</author>
		<title level="m">IntelÒ IA-32 Intel Architecture Software DeveloperÕs Manual</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">245471</biblScope>
		</imprint>
	</monogr>
	<note>Instruction Set Reference</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Motion Estimation Algorithms Using Streaming SIMD Extensions 3</title>
		<author>
			<persName><forename type="first">Intel</forename><surname>Corp</surname></persName>
		</author>
		<ptr target="&lt;http://www.intel.com/cd/ids/developer/asmo-na/eng/newsletter/66775.htm&gt;" />
		<imprint>
			<date type="published" when="2003-12">December 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Next Generation IntelÒ Processor: Software Developers Guide</title>
		<imprint>
			<date type="published" when="2004-01">January 2004</date>
			<biblScope unit="page">252490</biblScope>
		</imprint>
		<respStmt>
			<orgName>Intel Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Iverson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcveigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Reese</surname></persName>
		</author>
		<title level="m">Real-time H.264/AVC codec on Intel architectures, Int. Conf. Image Process</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1541" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Implementation of H.264 encoder on general-purpose processors with Hyper-Threading Technology</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-K</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE Conf. Visual Commun. Image Process</title>
		<imprint>
			<date type="published" when="2004-01">January. 2004</date>
			<biblScope unit="volume">5308</biblScope>
			<biblScope unit="page" from="384" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast multi-frame motion estimation algorithm with adaptive search strategies in H</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">K</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Acoustics Speech Signal Process</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">264</biblScope>
			<biblScope unit="page" from="369" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Malvar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hallapuro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Karczewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kerofsky</surname></persName>
		</author>
		<title level="m">Low-complexity transform and quantization with 16-bit arithmetic for H.26L, Int. Conf. Image Process</title>
		<imprint>
			<date type="published" when="2002-10">October. 2002</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="489" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Performance analysis of Intel MMX technology for an H.263 Video Encoder</title>
		<author>
			<persName><forename type="first">V</forename><surname>Lappalainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Multimedia</title>
		<meeting>ACM Multimedia</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="309" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Ha ¨ma ¨la ¨inen, Complexity of optimized H.26L video decoder implementation</title>
		<author>
			<persName><forename type="first">V</forename><surname>Lappalainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hallapuro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="717" to="725" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Ha ¨ma ¨la ¨inen, Performance of H.26L video encoder on generalpurpose processor</title>
		<author>
			<persName><forename type="first">V</forename><surname>Lappalainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hallapuro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. VLSI Signal Proc. Syst. Signal Image Video Technol</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="239" to="249" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<author>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Binns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Koufaty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Upton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hyper-Threading Technology microarchitecture and performance</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Fast intra-prediction mode selection for 4 • 4 blocks in H</title>
		<author>
			<persName><forename type="first">B</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">C</forename><surname>Au</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Acoustics Speech Signal Process</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">264</biblScope>
			<biblScope unit="page" from="389" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A parallel implementation of an MPEG-1 encoder: faster than real-time</title>
		<author>
			<persName><forename type="first">K</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Delp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE Conf. Digital Video Compression: Algorithms Techn</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">An MPEG encoder implementation on the Princeton engine video supercomputer, Data Compression Conf</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="420" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Mapping of H.264 decoding on a multiprocessor architecture</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Van Der Tol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G T</forename><surname>Jaspers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Gelderblom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SPIE Conf. Image Video Commun. Process</title>
		<imprint>
			<biblScope unit="volume">5022</biblScope>
			<biblScope unit="page" from="707" to="718" />
			<date type="published" when="2003-01">January. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Implementation of H.264 decoder on general-purpose processors with media instructions</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-K</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE Conf. Image Video Commun</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">5022</biblScope>
			<biblScope unit="page" from="224" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A new diamond search algorithm for fast block matching</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">- K</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Systems Video Technol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="287" to="290" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
