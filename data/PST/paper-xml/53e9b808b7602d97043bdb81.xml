<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robust Head-shoulder Detection by PCA-Based Multilevel HOG-LBP Detector for People Counting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Chengbin</forename><surname>Zeng</surname></persName>
							<email>cbzeng@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia Beijing University of Posts and Telecommunications</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huadong</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia Beijing University of Posts and Telecommunications</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Robust Head-shoulder Detection by PCA-Based Multilevel HOG-LBP Detector for People Counting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5306540B75B45D419256A62863EB92FA</idno>
					<idno type="DOI">10.1109/ICPR.2010.509</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>head-shoulder detection</term>
					<term>multilevel HOG-LBP detector</term>
					<term>PCA</term>
					<term>people counting</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Robustly counting the number of people for surveillance systems has widespread applications. In this paper, we propose a robust and rapid head-shoulder detector for people counting. By combining the multilevel HOG (Histograms of Oriented Gradients) with the multilevel LBP (Local Binary Pattern) as the feature set, we can detect the head-shoulders of people robustly, even though there are partial occlusions occurred. To further improve the detection performance, Principal Components Analysis (PCA) is used to reduce the dimension of the multilevel HOG-LBP feature set. Our experiments show that the PCA based multilevel HOG-LBP descriptors are more discriminative, more robust than the state-of-the-art algorithms. For the application of the real-time people-flow estimation, we also incorporate our detector into the particle filter tracking and achieve convincing accuracy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Counting the number of people for surveillance systems has widespread applications in public places, such as museums, markets, and scenic spots. For example, the public museum can control the amount of entering people according to the real-time people flow information. Therefore, it is necessary to develop an automatic system of estimating the number of people accurately and rapidly.</p><p>The computer vision based methods are widely used to people counting. Kilambi et al <ref type="bibr" target="#b0">[1]</ref> proposed a blob-based system to estimate the number of people in a group in urban environments. However, the blob-based methods only can detect moving objects. Furthermore, when there are shadows of the people themselves, the count is affected greatly.</p><p>Li et al <ref type="bibr" target="#b1">[2]</ref> applied the Histograms of Oriented Gradients (HOG) feature <ref type="bibr" target="#b2">[3]</ref> to detect the head-shoulder. The merit of the head-shoulder detection is its effectiveness of reducing the partial occlusion. But the HOG feature is not discriminative enough for the head-shoulder detection <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4]</ref>.</p><p>Wang et al <ref type="bibr" target="#b3">[4]</ref> combined the HOG feature with the Local Binary Pattern (LBP) feature <ref type="bibr" target="#b4">[5]</ref> to detect the holistic body of human. They also reported that the HOG-LBP feature gains more than 20% improvement for upper body detection compared to the HOG feature. But the detection rate still Figure <ref type="figure">1</ref>. The performance of our head-shoulder detector in a complex scene. The image is scanned at 16 scales to search for head-shoulders of humans. We achieve minimal false alarms even though there are partial occlusion occurred (best visualized in green color). cannot satisfy the demands of the people counting system (74% detection rate with a false alarm of 10 -4 ).</p><p>In this paper, we propose a robust and rapid headshoulder detector for people counting. We first use the multilevel HOG-LBP feature to detect the head-shoulders of people, which can enhance the detection rate significantly. To further improve the detection accuracy, Principal Components Analysis (PCA) <ref type="bibr" target="#b5">[6]</ref> is used to reduce the dimension of the multilevel HOG-LBP feature set.</p><p>Our experiments show that the PCA-based multilevel HOG-LBP descriptors are more discriminative, more robust than state-of-the-art algorithms. Figure <ref type="figure">1</ref> shows the detection result by using our method. For the application of the realtime people-flow estimation, we also incorporate our detector into the particle filter tracking <ref type="bibr" target="#b6">[7]</ref> and increase the detection accuracy.</p><p>In the rest of the paper, we give a detailed description of our algorithm and experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. OUR HEAD-SHOULDER DETECTOR</head><p>We use the multilevel HOG-LBP feature to detect the head-shoulder of the human. This is inspired by <ref type="bibr" target="#b7">[8]</ref>, which uses multi-scale histogram of oriented edge energy feature to detect the holistic body of pedestrians. As in <ref type="bibr" target="#b8">[9]</ref> we use PCA to reduce the dimension of feature set. It is worth men-Figure <ref type="figure">2</ref>. The process of our head-shoulder detection tioning that Felzenszwalb et al. <ref type="bibr" target="#b9">[10]</ref> used PCA-HOG to detect deformable objects. Figure <ref type="figure">2</ref> shows the process of our head-shoulder detection algorithms based on the PCA-HOG-LBP detector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Multilevel HOG feature</head><p>HOG <ref type="bibr" target="#b2">[3]</ref> is an excellent descriptor for capturing the edge direction or the distribution of local intensity gradients of objects. It has been applied successfully to detect the holistic body of the human.</p><p>In order to improve the performance of HOG, we use multilevel HOG feature to describe the head-shoulder. Third, the histograms of the four cells in each block (Figure <ref type="figure" target="#fig_1">3(d)</ref>) are concatenated into a feature vector of the block. The L2-Hys normalization <ref type="bibr" target="#b2">[3]</ref> of the feature vector is used to reduce the influence of the local variation in illumination and foreground-background contrast. Then, the feature vectors of the blocks are concatenated into the feature vector of each level. Finally, three feature vectors corresponding to three levels are concatenated into the final 3024-D multilevel HOG feature vector (Figure <ref type="figure" target="#fig_0">3</ref>(e)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Multilevel LBP Feature</head><p>As we mentioned in Section 1, HOG, as an edge descriptor, is not discriminative enough for head-shoulder detection. The combination of the edge shape information and the texture information will enhance the detection performance significantly. Thus, as in <ref type="bibr" target="#b3">[4]</ref> we use LBP <ref type="bibr" target="#b4">[5]</ref> as the texture descriptors of the head-shoulder.</p><p>The LBP is an excellent texture descriptor for its invariance to gray-scale and rotation. We extend the work of <ref type="bibr" target="#b10">[11]</ref>, and use multilevel block structured LBP to describe the head-shoulders of people. The same as Figure <ref type="figure" target="#fig_0">3</ref>(c), we divide the gray image of the input image into blocks at three levels. Then, we calculate the histograms of the LBP patterns for each block. The LBP patterns we used is 2 8,1 LBP (Figure <ref type="figure">4</ref>), which denotes that 8 points with radius 1 are sampled for each pixel, and the number of 0-1 transitions is at most 2. A binary pattern is called uniform pattern if the binary pattern contains at most two 0-1 transitions.</p><p>For each block at one level, pixels in the block with different uniform patterns are voted into different bins and all of the nonuniform patterns are voted into one bin. We then use L2-Hys normalization scheme for the histograms of the blocks, which is better performance than L1-sqrt normalization scheme used in <ref type="bibr" target="#b3">[4]</ref> (by 5% with a false alarm of 10 -4 ). Finally, the three LBP feature vector corresponding to the three levels are concatenated into the final 4956-D multilevel LBP feature vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. PCA-based Multilevel HOG-LBP Detector</head><p>By combining the multilevel HOG and the multilevel LBP as the feature set, we can detect the upper bodies of people robustly even though there partial occlusions occurred. To further improve the detection rate, we use PCA <ref type="bibr" target="#b5">[6]</ref> to discover low dimensional feature of multilevel HOG-LBP.</p><p>PCA, as a standard technique for dimensionality reducti-   on, has been widely applied in the area of computer vision such as face recognition. We use PCA to reveal the hidden structures of multilevel HOG-LBP feature by computing a linear transformation that maps the feature set from a high dimensional space to a lower dimensional space. This transformation can accurately represent the high dimensional feature with a compact feature representation. More importantly, projecting the multilevel HOG-LBP feature onto the low-dimensional space can discard the redundant and noisy information. Thus the PCA-based multilevel HOG-LBP detector makes the detection of the head-shoulder more robust.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dataset</head><p>We created a head-shoulder dataset, which includes 2000 48×64 positive samples. Some of the positive samples are shown in Figure <ref type="figure" target="#fig_5">5</ref>. About half of the positive samples are cropped from the INRIA dataset <ref type="bibr" target="#b2">[3]</ref>, and the others are cropped from the Internet. The 5000 negative examples are randomly sampled from person-free images. We also add some lower body images to the negative set to reduce false alarm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Training</head><p>We use the linear SVM (c=1) to train and classify on the head-shoulder dataset. Hard examples (false positives) are necessarily added to the negative set to re-train and then obtain the final detector. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.</head><p>Performance Evaluation To quantify the detection performance, we use Detection Error Tradeoff (DET) curves <ref type="bibr" target="#b2">[3]</ref>, and plots of miss rate versus false positives per window (FPPW). Lower miss rate means better detection performance on the same FPPW.</p><p>We first evaluate the performance of the multilevel HOG-LBP detectors on different PCA subspaces. The PCA subspace with a dimensionality of 200 performs best (Figure <ref type="figure" target="#fig_4">6</ref>(a)). Therefore, we use the PCA-based multilevel HOG-LBP with a dimensionality of 200 as our final head-shoulder detector. Then, we evaluate the HOG detector and HOG-LBP detector respectively on our head-shoulder dataset and achieve similar results as <ref type="bibr" target="#b3">[4]</ref>. Finally, we test our PCAbased multilevel HOG-LBP detector and achieve 89% detection rate at 10 -4 FPPW as shown in Figure <ref type="figure" target="#fig_4">6(b)</ref>. Compared to the HOG detector (62% detection rate at 10 -4 FPPW) and the HOG-LBP detector (74% detection rate at 10 -4 FPPW), our detector improves the detection rate significantly.</p><p>We present the detection results in Figure <ref type="figure" target="#fig_6">7</ref> for some surveillance images. The detection speed is less than 0.2 seconds for a 320×240 image (2.5 GHz dual core CPU and 2GB RAM).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Counting the Pedestrian Flow</head><p>We apply our detector to the application of counting the pedestrian flow. We use the "detection and tracking" strategy by incorporating our detector into the particle filter tracking <ref type="bibr" target="#b6">[7]</ref>.</p><p>As illustrated in Figure <ref type="figure" target="#fig_7">8</ref>, the red rectangle denotes the detection region. The interval of detection is 10 frames to avoid the repetitive detection. The detected targets are labeled a number (Figure <ref type="figure" target="#fig_7">8(a)</ref>), and then be tracked by using particle filter with classifiers.</p><p>For the particle tracking, we use a 2-dimensional normal distribution to generate the initial particle set. As illustrated in Figure <ref type="figure" target="#fig_7">8</ref>(b), each green rectangle represents a particle. The number of particles of each object is twenty. Then, we calculate the likelihood of each particle according to its PCA-based multilevel HOG-LBP feature. The rest steps of tracking are described in <ref type="bibr" target="#b6">[7]</ref>.</p><p>Once the targets being tracked enter the blue region (Figure <ref type="figure" target="#fig_7">8</ref>), the amount of targets will be added to the counting system. Figure <ref type="figure">9</ref> illustrates the whole procedure of the people counting.</p><p>Our people counting system can run in real time (12 frames/second with 2.5 GHz dual core CPU and 2GB RAM) because the size of the detection region is only 64×180 pixels and the number of particles for each target are only twenty. Moreover, our system successfully detects and tracks 95% emerged targets.</p><p>IV. CONCLUSION   We propose a novel head-shoulder detector which uses multilevel HOG-LBP as the feature set and uses PCA to discard the redundant and noisy information of the feature set. Compared to the state-of-the art algorithms, our detector is more distinctive leading to significant improvements in detection accuracy. We also incorporate the detector into the particle filter tracking to count the pedestrian flow and achieve convincing accuracy.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3</head><label>3</label><figDesc>illustrates the procedure of the feature extraction. We first compute the gradient magnitude (Figure 3 (b)) of the input image using 1-D masks, i.e., [-1 0 1]. The size of the input image is 48×64 pixels with gamma normalization. Second, we divide the gradient magnitude of the image into blocks at three levels (Figure 3(c)). Each block at each level consists of four rectangle cells. The gradient magnitude of each pixel in the cell is voted into 9 bins according to the orientation of the pixel's gradient. The nine orientation bins are evenly spaced over 0 o -180 o .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. The procedure of the feature extraction of the multilevel HOG. (a) The input image. (b) The gradient magnitude of the input image. (c) The block division at three levels. (d) The histograms of each level. (e) The final multilevel HOG feature.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 . 8 , 1 LBP</head><label>481</label><figDesc>Figure 4. An illustration of the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. (a) The performance comparison of the multilevel HOG-LBP detectors with different dimensions projected by PCA . (b) The performance comparison between the proposed head-shoulder detectors and state-of-the-art detectors on our head-shoulder dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Some of the positive samples from our head-shoulder dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Some of the head-shoulder detection results.</figDesc><graphic coords="3,314.68,570.39,241.67,120.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. An illustration of our detection and tracking method. (a) Detect the head-shoulder of people in the region of red rectangle. (b) Tracking the detected targets. See text for details.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ACKNOWLEDGMENT This work reported in this paper is supported by the National Science Fund for Distinguished Young Scholars under Grant No.60925010, the National Natural Science Foundation of China under Grant No. 60833009, the 111 Project under Grant No.B08004, the National High Technology Research and Development Program of China under Grant No. 2009AA01Z305.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Estimating pedestrian counts in groups</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kilambi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ribnick</surname></persName>
		</author>
		<author>
			<persName><surname>Etc</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>CVIU</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Estimating the number of people in crowded scenes by MID based foreground segmentation and head-shoulder detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An HOG-LBP human detector with partial occlusion handling</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multiresolut-ion gray scale and rotation invariant texture analysis w-ith local binary patterns</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mäenpää</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PAMI</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">T</forename><surname>Joliffe</surname></persName>
		</author>
		<title level="m">Principal Component Analysis</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Real-Time tracking with Classifiers</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chateau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gay-Belille</surname></persName>
		</author>
		<author>
			<persName><surname>Etc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Classification Using Intersection Kernel Support Vector Machines is efficient</title>
		<author>
			<persName><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">PCA-SIFT: A more distincti-ve representation for local image descriptors</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Object detection with discriminatively trained part based models</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Grishick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcallister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PAMI</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Face descript-ion with local binary patterns: application to face recog-nition</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ahonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hadid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PAMI, 2006. Figure 9. An illustration of our people counting system</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
