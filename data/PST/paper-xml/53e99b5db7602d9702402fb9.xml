<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Specularity Removal in Images and Videos: A PDE Approach</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Satya</forename><forename type="middle">P</forename><surname>Mallick</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">University of California at San Diego</orgName>
								<address>
									<postCode>92093</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Todd</forename><surname>Zickler</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Engineering and Applied Sciences</orgName>
								<orgName type="institution">Harvard University</orgName>
								<address>
									<postCode>02138</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Columbia University</orgName>
								<address>
									<postCode>10027</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">University of California at San Diego</orgName>
								<address>
									<postCode>92093</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Specularity Removal in Images and Videos: A PDE Approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FB49C6E1914A623DE57B123D996B5574</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a unified framework for separating specular and diffuse reflection components in images and videos of textured scenes. This can be used for specularity removal and for independently processing, filtering, and recombining the two components. Beginning with a partial separation provided by an illumination-dependent color space, the challenge is to complete the separation using spatio-temporal information. This is accomplished by evolving a partial differential equation (PDE) that iteratively erodes the specular component at each pixel. A family of PDEs appropriate for differing image sources (still images vs. videos), differing prior information (e.g., highly vs. lightly textured scenes), or differing prior computations (e.g., optical flow) is introduced. In contrast to many other methods, explicit segmentation and/or manual intervention are not required. We present results on high-quality images and video acquired in the laboratory in addition to images taken from the Internet. Results on the latter demonstrate robustness to low dynamic range, JPEG artifacts, and lack of knowledge of illuminant color. Empirical comparison to physical removal of specularities using polarization is provided. Finally, an application termed dichromatic editing is presented in which the diffuse and the specular components are processed independently to produce a variety of visual effects.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The reflectance of a wide variety of materials (including plastics, plant leaves, cloth, wood and human skin) can be described as a linear combination of specular and diffuse components. When this description is accurate, there are benefits to decomposing an image in this way. The diffuse reflectance component is often well-described by the Lambertian model, and by isolating this component, powerful Lambertian-based tools for tracking, reconstruction and recognition can be applied more successfully to realworld, non-Lambertian scenes. There is also evidence that specular reflectance plays a role in human perception, and there is a set of computer vision algorithms that rely solely on this component (e.g., <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b10">11]</ref>). Finally, in addition to image-analysis applications, specular/diffuse separation is important in image-based 3-D modeling, where (specular-free) diffuse texture maps are often desired, and in photo-editing, where the two components can be independently processed and recombined.</p><p>This paper addresses the separation of reflection components in images of general, possibly textured, scenes. We restrict our attention to surfaces that are well-represented by Shafer's dichromatic reflectance model <ref type="bibr" target="#b14">[15]</ref>, in which the spectral distribution of the specular component is similar to that of the illuminant while that of the diffuse component depends heavily on the material properties of the surface. The dichromatic model suggests the possibility of decomposing an image into its specular and diffuse components based on color information. Beginning with a single three-channel RGB image, the objective is to recover an RGB "diffuse image" and a monochromatic specular layer. This is an ill-posed problem, even when the illuminant color is known, and most existing methods operate by aggregating color information spatially across the image plane. We can differentiate between methods that are global and local in nature <ref type="foot" target="#foot_0">4</ref> .</p><p>Klinker et al. <ref type="bibr" target="#b5">[6]</ref> show that when the diffuse color is the same at each point on an object's surface, the color histogram of its image forms a T-shaped distribution, with the diffuse and specular pixels forming linear clusters. They use this information to estimate a single "global" diffuse color, and in principle, this approach can be extended to cases in which an image is segmented into several regions of homogeneous diffuse color. Results can be improved by exploiting knowledge of the illuminant color through transformations of color space <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b17">18]</ref>, but these methods also require an explicit segmentation of the scene into large regions of constant diffuse color. In recent work, R. Tan and Ikeuchi <ref type="bibr" target="#b15">[16]</ref> avoid explicit segmentation by representing all of the diffuse colors in a scene by a global, low-dimensional, linear basis.</p><p>In addition to the global approaches mentioned above, there has been considerable interest in separating reflection components through purely local interactions. The advantage of this approach is that it admits highly textured scenes that do not contain piecewise constant diffuse colors. In most local methods, the illuminant color is assumed to be known a priori, which is not a severe restriction since it can often be estimated using established (global) methods (e.g., <ref type="bibr" target="#b6">[7]</ref>). R. Tan and Ikeuchi <ref type="bibr" target="#b16">[17]</ref> iteratively reduce the specular component of a pixel by considering one of its neighbors that putatively has a related diffuse component. P. Tan et al. <ref type="bibr" target="#b13">[14]</ref> allow a user to specify a closed curve surrounding a specular region and then minimize an objective function based on local variations in diffuse chromaticity and specular intensity. One of the earliest local methods is that of Nayar et al. <ref type="bibr" target="#b9">[10]</ref>, which uses polarization as an additional cue to enable the recovery a spatially-varying source color.</p><p>The goal of this paper is to formalize the notion of "local interactions" for specular/diffuse separation, and thereby develop a general framework for achieving separation through local interactions in both images and videos. Unlike previous approaches<ref type="foot" target="#foot_1">5</ref> , the method is developed in the continuous domain, with local interactions governed by partial differential equations (PDEs). This process selectively shares color information between nearby image points through multi-scale erosion <ref type="bibr" target="#b2">[3]</ref> with structuring sets that vary over the image plane. We derive a family of PDEs that are appropriate for differing conditions, including images of both textured and untextured surfaces. We also show how this framework extends naturally to videos, where motion information is available as an additional cue.</p><p>On the practical front, this paper presents results on high-quality images acquired in the laboratory (Fig. <ref type="figure" target="#fig_2">3a</ref>, 3b), and shows that they compare favorably to ground-truth determined using cross polarization (Fig. <ref type="figure" target="#fig_3">4</ref>). Results on 8-bit images downloaded from the Internet (Fig. <ref type="figure" target="#fig_2">3d</ref>, 3e) suggest robustness to artifacts caused by low dynamic range, JPEG compression, and lack of knowledge of the illuminant color. The paper also provides results on videos (Fig. <ref type="figure" target="#fig_4">5</ref>) for which explicit optical flow is not necessarily available. Finally, an application -dichromatic editing -is presented (Fig. <ref type="figure" target="#fig_5">6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Notation</head><p>The dichromatic model of reflectance is a common special case of the bidirectional reflectance distribution function (BRDF) model, and it was originally developed by Shafer <ref type="bibr" target="#b14">[15]</ref> for dielectrics. According to this model, the BRDF can be decomposed into two additive components: the interface (specular) reflectance and the body (diffuse) reflectance. The model assumes that each component can be factored into a univariate function of wavelength and a multivariate function of imaging geometry, and that the index of refraction of the surface is constant over the visible spectrum. These assumptions lead to the following expression for the BRDF of a dichromatic surface:</p><formula xml:id="formula_0">f (λ, Θ) = g d (λ)f d + f s (Θ),<label>(1)</label></formula><p>where λ is the wavelength of light and Θ = (θ i , φ i , θ r , φ r ) parameterizes the directions of incoming irradiance and outgoing radiance. The function g d is referred to as the spectral reflectance and is an intrinsic property of the material. The functions f d (constant for Lambertian surfaces) and f s are the diffuse and specular BRDFs, respectively. Taking into account the spectral power distribution of a light source L(λ) and a camera sensitivity function C k (λ), the image formation equation for a surface element with surface normal n, illuminated by a light source with direction l is written</p><formula xml:id="formula_1">I k = (D k f d + S k f s (Θ)) n • l,<label>(2)</label></formula><p>where</p><formula xml:id="formula_2">D k = C k (λ)L(λ)g d (λ)dλ and S k = C k (λ)L(λ)dλ.</formula><p>An RGB color vector I = [I 1 , I 2 , I 3 ] from a typical camera consists of three such measurements, each with a different sensitivity function with support in the visible spectrum. Note that S k represents the effective source strength as measured by the k th sensor channel and is independent of the surface being observed. Similarly, D k is the effective albedo in the k th channel. For notational simplicity, we define S = [S 1 , S 2 , S 3 ] (with a corresponding definition for D), and since scale can be absorbed by f d and f s , we assume D = S = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Illuminant-Dependent Color Spaces</head><p>In the last few years there has been a burst of activity in defining color space transformations that exploit knowledge of the illuminant color to provide more direct access to the diffuse information in an image. While motivated by different applications, the transformations discussed here all share the same idea of linearly combining the three color channels of an RGB image to obtain one or two "diffuse channels". R. Tan and Ikeuchi <ref type="bibr" target="#b16">[17]</ref> obtain a one-channel diffuse image through the transformation</p><formula xml:id="formula_3">I d = 3 max k (I k /S k ) -k (I k /S k ) 3 λ -1 ,<label>(3)</label></formula><p>where k ∈ {1, 2, 3}, and the bounded quantity 1/3 &lt; λ ≤ 1 is chosen arbitrarily. This transformation yields a positive monochromatic diffuse image, which can be seen by expanding Eq. 3 using Eq. 2 and assuming (for argument's sake) that I 1 /S 1 &gt; I 2 /S 2 , I 3 /S 3 . In this case,</p><formula xml:id="formula_4">I d = 2I 1 /S 1 -I 2 /S 2 -I 3 /S 3 3 λ -1 = (2D 1 /S 1 -D 2 /S 2 -D 3 /S 3 ) f d n • l 3 λ -1 .<label>(4)</label></formula><p>Since this expression is independent of f s and is directly related to n • l, the positive image I d is specular-free and depends directly on diffuse shading information. An alternative transformation is proposed by Park <ref type="bibr" target="#b11">[12]</ref>, who isolates two predominantly diffuse channels while retaining a similarity to HSI color space. The transformation is composed of a linear transformation L p and rotation R p , and is written</p><formula xml:id="formula_5">I p = R p L p I, with R p L p S = [ 0 0 2 ] .<label>(5)</label></formula><p>The matrices R p and L p are chosen such that the third color axis is aligned with the illumination color. As a result, that channel contains the majority of the specular component, leaving the other two channels to be predominantly diffuse.</p><p>A third transformation, proposed by Mallick et al. <ref type="bibr" target="#b7">[8]</ref>, defines a color space referred to as SUV color space. The transformation is written</p><formula xml:id="formula_6">I SU V = RI, with RS = [ 1 0 0 ] .<label>(6)</label></formula><p>Similar to Park's transformation, one of the transformed axes in SUV space is aligned with the illuminant color. Unlike Park's transformation, however, this channel includes the complete specular component, leaving the remaining two channels to be purely diffuse. To see this, we expand the expression for I SU V using Eqs. 2 and 6 to obtain</p><formula xml:id="formula_7">I SU V = Df d + Sf s (Θ) n • l,<label>(7)</label></formula><p>where D = RD and S = RS = [1, 0, 0] . Letting r i denote the i th row of R, the diffuse U V channels are which depend only on diffuse-shading and are specular-free. The S-channel is given by</p><formula xml:id="formula_8">I U = r 2 Df d n • l, I V = r 3 Df d n • l,<label>(8)</label></formula><formula xml:id="formula_9">I S I SUV φ d ρ φ θ S V U (a) (b) (c) (d)</formula><formula xml:id="formula_10">I S = r 1 Df d n • l + f s (Θ)n • l.<label>(9)</label></formula><p>It contains all of the specular component in addition to an unknown diffuse component. Each of the three transformations described in this section exploits knowledge of the illuminant to provide a partial dichromatic separation, which is an important step toward our stated goal. Of the three, the SUV color space defined in Eq. 6 is the best-suited for our purpose. Unlike Eq. 3, it is a linear transformation that yields two "diffuse" channels, and unlike Eq. 5, these two "diffuse" channels are in fact completely free of specularity. As described in the next section, these properties lead to a generalized notion of hue that can be used as a guide for local interactions, enabling the computation of a complete specular/diffuse separation even in cases of significant diffuse texture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Specularity Removal and Differential Morphology</head><p>This section derives a family of non-linear PDEs for completing the partial specular/diffuse separation provided by a transformation to SUV color space. Intuitively, these PDEs define a series of local interactions in which color information is shared along curves (or surfaces) of constant "hue."</p><p>We begin by re-parameterizing SUV color space using a combination of cylindrical and spherical coordinates. As depicted in Fig. <ref type="figure" target="#fig_0">1</ref>, suppressing the spatial dependence for notational simplicity, we define</p><formula xml:id="formula_11">ρ = I 2 U + I 2 V , θ = tan -1 I U I V , φ = tan -1 I S ρ . (<label>10</label></formula><formula xml:id="formula_12">)</formula><p>This parameterization has the following properties:</p><p>1. Since they depend only on the diffuse U V channels, both ρ and θ are independent of the specular reflectance component. 2. Since the illuminant color is aligned with the S-axis, the angle θ parameterizes the pencil of dichromatic planes in an image. We refer to θ as generalized hue, since it reduces to the standard definition of hue in the special case of a white illuminant. It depends on the direction of the diffuse color vector but not the magnitude of the diffuse component. 3. ρ represents diffuse shading, since it is directly related to n • l, and therefore, the magnitude of the diffuse component. 4. φ is a linear combination of specular and diffuse components, and we can write φ = φ s + φ d , where φ s and φ d are the specular and diffuse contributions to φ.</p><p>According to these properties, the problem of computing a specular/diffuse separation is reduced to one of estimating φ d (x, y), the diffuse contribution to φ at each image point. Once the scalar function φ d (x, y) is known, the RGB diffuse component follow directly from inverting the transformations in Eqs. 10 and 6, with φ replaced by φ d .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Multi-scale Erosion</head><p>Our goal is to compute a specular/diffuse separation through estimation of the scalar function φ d (x, y) through purely local interactions. This section describes how this can be accomplished by evolving a PDE that iteratively "erodes" the specular contribution to φ and converges to an estimate of φ d at each point. The erosion process is guided locally by the diffuse color information provided by ρ and θ, and is formulated in the continuous domain using one of a family of non-linear PDEs that define multi-scale erosion <ref type="bibr" target="#b2">[3]</ref>. The theory presented in this section is related to the formulation of multiscale erosion presented by Brockett and Maragos <ref type="bibr" target="#b2">[3]</ref>.</p><p>The multi-scale erosion ε(x, t) of a bivariate function f : R 2 →R by structuring set B ⊆ R 2 at scale t is defined as</p><formula xml:id="formula_13">ε(x, t) = (f tB)(x) = inf{f (x + ∆x) : ∆x ∈ tB} ,</formula><p>where the set B is compact, and tB {tb : b ∈ B}. Intuitively, ε(x, t) evaluated at a particular value of t corresponds to an erosion of the function f (x), where the function value at x = (x, y) is replaced by the minimum of all function values in the "neighborhood" tB, which is a scaled replica of structuring set B. A multi-scale erosion is computed by considering the PDE</p><formula xml:id="formula_14">∂ε ∂t (x, t) = lim ∆t→0 ε(x, t + ∆t) -ε(x, t) ∆t . (<label>11</label></formula><formula xml:id="formula_15">)</formula><p>When the structuring set is both compact and convex, the multi-scale erosion has a semigroup structure, allowing one to write <ref type="bibr" target="#b2">[3]</ref>   where ∇ε is the two-dimensional spatial gradient of ε evaluated at t. Finally, as shown in <ref type="bibr" target="#b2">[3]</ref>, in the special case where B is disk-shaped, Eq. 12 becomes</p><formula xml:id="formula_16">∂ε ∂t (x, t) = lim ∆t→0 inf{∇ε ∆x : ∆x ∈ ∆tB} ∆t ,<label>(12)</label></formula><formula xml:id="formula_17">M I2×2 I2×2 -∇ θ ∇ θ AA I3×3 -∇ θ∇ θ FF / F 2</formula><formula xml:id="formula_18">ε t = -∇ε .<label>(13)</label></formula><p>Eq. 13 is an example of a PDE that can be used for specular/diffuse separation, albeit in the special case when the scene consists of a texture-less surface with uniform diffuse color. To see this, suppose we are given an input image with corresponding functions ρ(x), θ(x) and φ(x), and suppose we define ε(x, 0) = φ(x). The solution to Eq. 13 evaluated at scale t corresponds to the erosion of φ by a disk-shaped structuring set, meaning that the value of φ at each image point is replaced by the minimum value within a disk-shaped neighborhood of radius t. Since φ d (x) ≤ φ(x), it follows that when the image contains at least one image point that is purely diffuse (that is, for which φ s = 0) then ε(x, t) evaluated at t will converge to φ d (x) as t is made sufficiently large. In the next three sub-sections, we develop more sophisticated PDEs for cases of multiple regions of uniform diffuse color, complex diffuse texture, and video. In all of these, the basic idea is the same: the value of φ d at each image point is estimated by eroding the initial function φ. By changing the structuring set, however, the process can be controlled so that region boundaries and diffuse texture are preserved during the process. In particular, we show that the PDE governing the evolution of φ for three different cases -texture-less images, textured images, and video -can all be written as</p><formula xml:id="formula_19">ε t = -g(ρ, ∇ρ) ∇ε M∇ε 1/2 , (<label>14</label></formula><formula xml:id="formula_20">)</formula><p>where M is a different matrix for each case. g(ρ, ∇ρ) is called the stopping function and is defined in the following section. Fig. <ref type="figure" target="#fig_1">2</ref> summarizes the cases we consider.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Texture-less Surfaces: Isotropic Erosion</head><p>Eq. 13 describes a process in which the specular component of φ is eroded equally in all directions. This is desirable in cases of homogeneous diffuse color, but if regions of distinct color exist, there is a possibility that "color bleeding" may occur. To prevent this, we introduce a "stopping function" analogous to that used in anisotropic diffusion <ref type="bibr" target="#b12">[13]</ref>.</p><p>A stopping function is useful for attenuating the erosion process in two different cases 1. If a region of the surface is "white" (i.e., it reflects all wavelengths equally) or if the surface is the same color as the light source, the diffuse component of color cannot be isolated. Since ρ = 0 in this case, no diffuse color information is available, and erosion should be arrested. 2. Information about φ should not be shared across boundaries between regions of distinct color. Since these boundaries often coincide with large values of ∇ρ , erosion should be attenuated when ∇ρ is large.</p><p>One possible stopping function that meets these guidelines is</p><formula xml:id="formula_21">g(ρ, ∇ρ) = 1 -e -ρ 1 + e -ρ e -( ∇ρ -τ ) 1 + e -( ∇ρ -τ ) , (<label>15</label></formula><formula xml:id="formula_22">)</formula><p>where τ is a threshold on ∇ρ , above which erosion is heavily attenuated. Incorporating this into Eq. 13 yields</p><formula xml:id="formula_23">ε t = -g(ρ, ∇ρ) = -g(ρ, ∇ρ) ∇ε I 2×2 ∇ε 1/2 . (<label>16</label></formula><formula xml:id="formula_24">)</formula><p>The erosion process defined by this equation can be used for the specular/diffuse separation of images containing large regions of uniform diffuse color.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Textured Surfaces: Anisotropic Erosion</head><p>An example of a scene that does not contain regions of uniform diffuse color is shown in Fig. <ref type="figure" target="#fig_0">1 (b</ref>). In this case, eroding the function φ isotropically would blur the diffuse texture. Instead, we need to erode φ anisotropically, only sharing information between neighboring image points for which φ d is likely to be equal. Of course, we have no information about the diffuse color a priori, so it is impossible to know the correct neighborhood (if it even exists) with certainty. As depicted in Fig. <ref type="figure" target="#fig_0">1 (c,</ref><ref type="figure">d</ref>), since θ is independent of both specularity and shading information, the directions tangent to the iso-contours of θ(x) provide a good choice. In the absence of any additional information, they provide a good local predictor for the direction in which φ d is constant. We define</p><formula xml:id="formula_25">∇ θ = ∇θ/ ∇θ ∇θ &gt; 0 0 ∇θ = 0,<label>(17)</label></formula><p>where ∇(•) refers to the spatial gradient, and we denote the direction orthogonal to ∇θ by V. <ref type="foot" target="#foot_2">6</ref> The multi-scale erosion of φ with the spatially-varying, linear structuring sets V(x) is derived analogous to the isotropic (disk-shaped) case discussed previously.</p><formula xml:id="formula_26">ε t = lim ∆t→0 inf{∇ε ∆x : ∆x ∈ ∆tV} ∆t = lim ∆t→0 -∆t|∇ε V| ∆t = -|∇ε V| . (<label>18</label></formula><formula xml:id="formula_27">)</formula><p>Using the fact that V = [ θyθx ] (or [ θyθx ] ), and including the stopping function, we obtain</p><formula xml:id="formula_28">ε t = -g(ρ, ∇ρ) ∇ε I 2×2 -∇ θ∇ θ ∇ε 1/2 . (<label>19</label></formula><formula xml:id="formula_29">)</formula><p>Using similar arguments to that in the isotropic case, it can be shown that ε(x, t) evaluated at sufficiently large t will be equal to φ d (x) (and will yield a correct specular/diffuse separation) if the iso-contour of θ passing through each point x: 1) contains only points for which φ d is constant; and 2) contains at least one point at which a purely diffuse observation (φ s = 0) is available. Note that in regions where the diffuse color is constant (i.e., ∇ θ = [ 0 0 ] ), this equation reduces to Eq. 16, and the erosion becomes isotropic as desired.</p><p>In practice, the transition from linear to disk-shaped structuring sets in Eq. 19 is controlled by a threshold on ∇θ . This discontinuous transition can be avoided by employing an elliptical structuring set with a minor axis aligned with the direction of ∇θ and with an eccentricity that varies smoothly with ∇θ . To derive a PDE for the corresponding multi-scale erosion, we let E denote an elliptical structuring set, and we describe this set by the lengths of its major and minor axes (λ 1 , λ 2 ) and the angle between its major axis and the x-axis (ψ). Points x on the boundary of E satisfy</p><formula xml:id="formula_30">x Qx = 1 where Q = R(-ψ)Λ -2 R(ψ) , Λ = diag(λ 1 , λ 2 )</formula><p>and R(ψ) is a clockwise rotation of the plane. As before, the multi-scale erosion defined by this set satisfies</p><formula xml:id="formula_31">ε t = lim ∆t→0 inf{∇ε ∆x : ∆x ∈ ∆tE} ∆t .<label>(20)</label></formula><p>To simplify the right-hand side of this equation, we define the transformation x = Ax , with A = R(-ψ)ΛR(ψ) . The spatial gradient of ε with respect to x is then given by the chain rule: ∇ε = A ∇ε. The transformation A maps the set E to the unit disk (since x Qx = x A QAx = x x = 1), and as a result, we can write inf{∇ε ∆x : ∆x ∈ ∆tE} = inf{∇ε ∆x : ∆x ∈ ∆tB}. Substituting this into Eq. 20 and comparing with Eq. 13, we obtain</p><formula xml:id="formula_32">ε t = -∇ε = -∇ε AA ∇ε 1/2</formula><p>. Finally, the addition of the stopping function yields</p><formula xml:id="formula_33">ε t = -g(ρ, ∇ρ) ∇ε AA ∇ε 1/2 . (<label>21</label></formula><formula xml:id="formula_34">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Videos: Anisotropic Erosion in Three Dimensions</head><p>Thus far, we have dealt exclusively with still images, but the framework extends naturally to video, which can be treated as a 3D volume I(x, y, z) in which time is the third dimension (z). As in the case of textured images, the direction of ∇θ is assumed to be a good local predictor for the direction (in 3D space-time) of maximum diffuse color change. We would like to preserve the component of ∇φ along this direction during the erosion process, which is accomplished by restricting the erosion of φ to the iso-surfaces of θ. In the absence of additional information, there is no preferred direction within an iso-surface of θ, so a natural choice of structuring set is a circular disk contained within its tangent plane.</p><p>To compute the multi-scale erosion equation, we note that the structuring set described above consists of a disk (denoted C) whose surface normal is aligned with ∇θ. Thus, the maximum projection of ∇φ onto the plane that contains this disk is given by ∇φ 2 -∇ θ ∇φ 2 1/2 , and the evolution equation can be simply written as</p><formula xml:id="formula_35">ε t = lim ∆t→0 inf{∇ε ∆x : ∆x ∈ ∆tC} ∆t = lim ∆t→0 -∆t ∇ε 2 -∇ θ ∇ε 2 1/2 ∆t = -∇ε 2 -∇ θ ∇ε 2 1/2 , where ∇ε = [ ε x ε y ε z ] .</formula><p>After some algebraic manipulations, and incorporating the stopping function, we obtain</p><formula xml:id="formula_36">ε t = -g(ρ, ∇ρ) ∇ε (I 3×3 -∇ θ∇ θ )∇ε 1/2 . (<label>22</label></formula><formula xml:id="formula_37">)</formula><p>Note that the erosion equation for textured and texture-less surfaces are special cases of the erosion equation for videos.</p><p>As mentioned earlier, if some a priori information is known, better structuring sets can be designed. An interesting example is when optical flow estimates are available at each location in a video. We let [ u(x, y, z) v(x, y, z) ] represent the estimated optical flow at location (x, y, z) in the video, so that space-time points (x, y, z) and (x + u, y + v, z + 1) correspond to projections of the same surface element. It follows that φ d can be estimated by eroding φ along the direction F = [u v 1] . Using the expression for erosion by a linear set derived in Eq. 19 we obtain</p><formula xml:id="formula_38">ε t = -g(ρ, ∇ρ) F F ∇ε = -g(ρ, ∇ρ) ∇ε FF F 2 ∇ε 1/2 . (<label>23</label></formula><formula xml:id="formula_39">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>The methods were evaluated using images and videos acquired in the laboratory as well as those downloaded from the Internet. Using a known (or approximately known) illuminant color, each image is transformed into SUV space, and the functions ρ, θ and φ are computed. Specular/diffuse separation is achieved by numerically evolving the appropriate multi-scale erosion PDE with initial condition ε(x, 0) = φ(x). The process is complete when the maximum change in ε is below a selected threshold, and this yields an estimate of φ d (x), which completely defines the specular and diffuse components.</p><p>It is important to note that the non-linear PDEs governing erosion are defined at points where the partial derivatives exist. Even if this is satisfied by the initial data, however, at finite scales a multi-scale erosion generally develops discontinuities referred to as shocks. Shocks can be dealt with (as we do here) by replacing standard derivatives by morphological derivatives <ref type="bibr" target="#b2">[3]</ref>. They can also be handled using viscosity solutions <ref type="bibr" target="#b3">[4]</ref>.</p><p>Fig. <ref type="figure" target="#fig_2">3</ref> (a, b) shows two 12-bit images 7 acquired in a controlled setting (with known illuminant color) along with the recovered specular and diffuse components. Both re-sults were obtained using the anisotropic erosion defined in Eq. 19. The method correctly handles both regions of uniform color (e.g., the orange pepper Fig. <ref type="figure" target="#fig_2">3 (a)</ref>) and regions with significant texture (e.g., the pear in Fig. <ref type="figure" target="#fig_2">3 (b)</ref>). Looking closely at the pear, we notice that diffuse texture that is barely visible in the input image is revealed when the specularity is removed. Figure <ref type="figure" target="#fig_2">3</ref> (c) shows a 12-bit image of a human face in which the illuminant color was unknown and was assumed to be white. Again, diffuse texture is preserved, while the specular component is reduced. Pixels on the forehead between the eyebrows are saturated, and therefore violate the dichromatic model. The stopping function (Eq. 15) ensures that these pixels are implicitly identified and treated as outliers during the erosion process. While left here for illustrative purposes, these artifacts can be reduced by inpainting the diffuse and/or specular components in a post-process. (This is done, for example, by P. Tan et al. <ref type="bibr" target="#b13">[14]</ref>.)</p><p>Figure <ref type="figure" target="#fig_3">4</ref> compares the result of our algorithm with the ground truth obtained using polarization filters on the light source and camera. The polarizer in front of the light source is fixed while the polarizer in front of the camera is rotated to an orientation that produces an image with minimum specularity. The result of our algorithm is very close to the ground truth on both the textured surfaces (i.e., the vase and pear) and the untextured surfaces (i.e., the sphere).</p><p>Additional still-image results are shown in Fig. <ref type="figure" target="#fig_2">3 (d,</ref><ref type="figure">e</ref>). These images were downloaded from the Internet, so they exhibit low dynamic range (8-bit) and are corrupted by JPEG compression. Since illuminant color was not known, it was assumed to be white, and the gamma was assumed to be 2.2. Despite these sources of noise, the multi-scale erosion defined in Eq. 19 still succeeds in separating the diffuse and specular components. An animation of the erosion process accompanies this paper.</p><p>In addition to still images, we also evaluated the method on video sequences, some frames of which are shown in Fig. <ref type="figure" target="#fig_4">5</ref>. In both cases, erosion is performed along isosurfaces of θ using Eq. 22, and in both cases, texture is preserved while the specularity is removed. Complete videos accompany this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dichromatic Editing</head><p>To further demonstrate the efficacy of our approach, we use it as a means for dichromatic editing -the simulation of visual effects by the independent processing of reflection components. Some examples are shown in Fig. <ref type="figure" target="#fig_5">6</ref>, where: 1) the specular and diffuse components are recovered using Eq. 19, 2) each component is processed individually, and 3) they are recombined. Since the diffuse and specular components often form two distinct components of visual perception, dichromatic editing can achieve a variety of visual effects, including the effects of make-up, surface roughening, and wetness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper presents a framework for specular/diffuse separation in images and video that is based on local spatial (and spatio-temporal) interactions. Separation is framed in terms of differential morphology, which leads to a family of non-linear PDEs. By evolving these PDEs, we effectively erode the specular component at each image point. This erosion is guided by local color and shading information, so that diffuse texture is preserved without requiring an explicit segmentation of the image. By developing the problem in terms of morphological PDEs, we can benefit from existing robust numerical algorithms to solve them <ref type="bibr" target="#b8">[9]</ref>, which is an important advantage over purely discrete formulations. In addition, videos are naturally considered in this formulation, with the erosion equation for videos including the still-image equations as a special case.</p><p>The approach described in this paper relies purely on local color information, and is therefore limited to dichromatic surfaces for which the diffuse and specular colors are distinct. It requires the illuminant color to be known (at least approximately) a priori. In the future, we plan to overcome these limitations by exploiting additional cues, such as local shape, in addition to color. In (c), the illuminant color was not known and was assumed to be white. 8-bit JPEG images (d, e) were downloaded from the Internet, the illuminant was assumed to be white, and the gamma was assumed to be 2.2. Despite these sources of noise, diffuse and specular components are successfully recovered.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) A color in the SUV color space is parameterized by (ρ, θ, φ). ρ and θ are independent of specularity, and θ generalizes the notion of "hue" for arbitrarily colored illuminants. The problem of removing specularity is reduced to finding φ d , the diffuse part of φ. (b) A rendered RGB image of a textured sphere. (c) The value of θ at each pixel of the image. Notice that θ is constant in regions of constant diffuse color and is independent of specularity as well as shading. (d) Blownup view of the iso-contours of θ in the rectangular region indicated in (b) and (c). White indicates regions of constant θ. In textured images, erosion of the specular component occurs along isocontours of θ, which ensures that diffuse texture is preserved while the specularity is removed.</figDesc><graphic coords="5,221.83,115.87,79.50,79.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Summary of five cases from left to right: (1) image with uniform diffuse color, (2-3) textured image, (4) video, and (5) video with known optical flow. Rows depict: the structuring set used, the direction/surface of erosion, and the matrix M in the multi-scale erosion equation (Eq. 14.) In×n is the identity matrix, and ∇ θ, A and F are as defined in Sec. 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Separation results for images. Top row: Input images. Middle row: Diffuse Component. Bottom row: Specular component. Equation19is used in all cases, since it naturally handles both textured and untextured surfaces. The 12-bit input images in (a, b) were acquired in the laboratory under known illuminant color. In (c), the illuminant color was not known and was assumed to be white. 8-bit JPEG images (d, e) were downloaded from the Internet, the illuminant was assumed to be white, and the gamma was assumed to be 2.2. Despite these sources of noise, diffuse and specular components are successfully recovered.</figDesc><graphic coords="13,145.01,403.98,86.89,69.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Comparison to ground truth. Left: input image. Center: ground truth diffuse component obtained using linear polarizers. Right: diffuse component recovered using anisotropic multiscale erosion.</figDesc><graphic coords="14,264.24,130.65,62.20,52.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Separation results for (12-bit) video. Top row: Frames from input sequences. Bottom row: Diffuse component recovered using Eq. 22. (Complete videos accompany this paper.) '</figDesc><graphic coords="14,136.99,203.14,185.12,93.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Dichromatic editing examples. In each case a visual effect is simulated by independent processing of the recovered specular and diffuse components. (a) Input image. (b) Wetness effect by sharpening the specular component. (c) Skin color change by varying the intensity of the diffuse component. (d) Effect of make-up by smoothing the diffuse component and removing the specular component. (e) Input image. (f) Sharpened specular lobe, as would occur if the surface was more smooth. This is achieved by eroding the specular component using a diskshaped structuring element and amplifying it. (g) Effect of an additional light source obtained by exploiting the object symmetry and reflecting the specular component about the vertical axis. (h) Avocado-like appearance by modulating the specular component.</figDesc><graphic coords="14,156.11,446.73,69.10,90.13" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>In addition to the color-based methods discussed here, there are a number of other methods that rely on multiple images and/or additional cues, such as variable lighting, variable polarization, and parametric reflectance. Readers are referred to<ref type="bibr" target="#b16">[17]</ref> for a description of these methods.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1"><p>A notable exception is the work of P. Tan et al.<ref type="bibr" target="#b13">[14]</ref>, who use a variational PDE to separate manually-segmented highlight regions. Our work differs in that it uses morphological PDEs enabling separation without the need for manual segmentation.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2"><p>Since θ is periodic, a definition of distance is necessary for its gradient to be correctly computed. We define the distance between two angles θ1 and θ2 as min(|θ1 -θ2|, 2π -|θ1 -θ2|).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3"><p>All images in this section should be viewed on a monitor or high-quality color print. The images can be viewed at a higher resolution by zooming into the PDF document.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgment</head><p>The authors would like to thank Roger Brockett for helpful comments regarding the theoretical development in Sec. 4. This work was supported in part by the National Science Foundation. S. Mallick and D. Kriegman were funded under IIS-03-08185 and EIA-02-24431, T. Zickler was funded under IIS-05-41173, and P. Belhumeur was funded under IIS-03-08185, EIA-02-24431, and ITR-00-85864.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Detection of diffuse and specular interface reflections and inter-reflections by color image segmentation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bajcsy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="241" to="272" />
			<date type="published" when="1996-03">March 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Geometry from specularities</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Brelstaff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="394" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Evolution equations for continuous scale morphology</title>
		<author>
			<persName><forename type="first">R</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maragos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE trans. on Sig. Proc</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="3377" to="3386" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">User&apos;s Guide to Viscosity Solutions of Second Order Partial Differential Equations</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Lions</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992-07">July 1992</date>
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Local shape from specularity</title>
		<author>
			<persName><forename type="first">G</forename><surname>Healey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Binford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVGIP</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="62" to="86" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The measurement of highlights in color images</title>
		<author>
			<persName><forename type="first">G</forename><surname>Klinker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shafer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="32" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Method for computing the scene-illuminant chromaticity from specular highlights</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JOSAA</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1694" to="1699" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Beyond Lambert: Reconstructing specular surfaces using color</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mallick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zickler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">II</biblScope>
			<biblScope unit="page" from="619" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Curve evolution and differential morphology</title>
		<author>
			<persName><forename type="first">P</forename><surname>Maragos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Butt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fundamenta Informaticae</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="91" to="129" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Separation of reflection components using color and polarization. Int</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nayar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Boult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="163" to="186" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Using specularities for recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Osadchy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="1512" to="1519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Efficient color representation for image segmentation under nonwhite illumination</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">5267</biblScope>
			<biblScope unit="page" from="163" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Scale-space and edge detection using anisotropic diffusion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="629" to="639" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Highlight removal by illumination-constrained inpainting</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<meeting><address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="164" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Using color to separate reflection components</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shafer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">COLOR research and applications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="210" to="218" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Reflection components decomposition of textured surfaces using linear basis functions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ikeuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="125" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Separating reflection components of textured surfaces using a single image</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ikeuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="178" to="193" />
			<date type="published" when="2005-02">February 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Separating reflection components based on chromaticity and noise analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nishino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ikeuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1373" to="1381" />
			<date type="published" when="2004-10">October 2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
