<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The development of a multi-objective Tabu Search algorithm for continuous optimisation problems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2006-10-25">25 October 2006</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Jaeggi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Engineering Design Centre</orgName>
								<orgName type="department" key="dep2">Department of Engineering</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<addrLine>Trumpington Street</addrLine>
									<postCode>CB2 1PZ</postCode>
									<settlement>Cambridge</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Parks</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Engineering Design Centre</orgName>
								<orgName type="department" key="dep2">Department of Engineering</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<addrLine>Trumpington Street</addrLine>
									<postCode>CB2 1PZ</postCode>
									<settlement>Cambridge</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">T</forename><surname>Kipouros</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Engineering Design Centre</orgName>
								<orgName type="department" key="dep2">Department of Engineering</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<addrLine>Trumpington Street</addrLine>
									<postCode>CB2 1PZ</postCode>
									<settlement>Cambridge</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Clarkson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Engineering Design Centre</orgName>
								<orgName type="department" key="dep2">Department of Engineering</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<addrLine>Trumpington Street</addrLine>
									<postCode>CB2 1PZ</postCode>
									<settlement>Cambridge</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The development of a multi-objective Tabu Search algorithm for continuous optimisation problems</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2006-10-25">25 October 2006</date>
						</imprint>
					</monogr>
					<idno type="MD5">5C516E6E902DF0FF6F1AF718942DBD43</idno>
					<idno type="DOI">10.1016/j.ejor.2006.06.048</idno>
					<note type="submission">Received 1 July 2005; accepted 1 June 2006</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Tabu Search</term>
					<term>Global optimisation</term>
					<term>Genetic algorithms</term>
					<term>Multiple criteria analysis</term>
					<term>Meta-heuristics</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>While there have been many adaptations of some of the more popular meta-heuristics for continuous multi-objective optimisation problems, Tabu Search has received relatively little attention, despite its suitability and effectiveness on a number of real-world design optimisation problems. In this paper we present an adaptation of a single-objective Tabu Search algorithm for multiple objectives. Further, inspired by path relinking strategies common in discrete optimisation problems, we enhance our algorithm to allow it to handle problems with large numbers of design variables. This is achieved by a novel parameter selection strategy that, unlike a full parametric analysis, avoids the use of objective function evaluations, thus keeping the overall computational cost of the procedure to a minimum. We assess the performance of our two Tabu Search variants on a range of standard test functions and compare it to a leading multi-objective Genetic Algorithm, NSGA-II. The path relinking-inspired parameter selection scheme gives a clear performance improvement over the basic multi-objective Tabu Search adaptation and both variants perform comparably with the NSGA-II.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Meta-heuristic optimisation techniques have proved effective in solving complex, real-world optimisation problems with many local minima, problems to which traditional, gradient-based methods are ill suited. Some significant methods to have emerged in recent years are Simulated Annealing (SA), Genetic Algorithms (GA), Evolution Strategies (ES) and Tabu Search (TS).</p><p>With the realisation that most real-world design problems involve compromises between conflicting objectives, efforts have been directed towards developing multi-objective optimisation algorithms. The first multi-objective GA was developed in 1985 and research in this field has been very active <ref type="bibr" target="#b7">[8]</ref>. Similarly, multi-objective SA <ref type="bibr" target="#b29">[30]</ref> and ES <ref type="bibr" target="#b25">[26]</ref> algorithms have also been developed . However, very little work has been done on multi-objective TS algorithms. Jones et al. <ref type="bibr" target="#b21">[22]</ref> surveyed 115 articles concerned with multi-objective meta-heuristics for both discrete and continuous problems. They found 70% of the articles used GA or ES as the primary meta-heuristic, 24% SA and 6% TS.</p><p>In this paper we present two multi-objective TS algorithms. The first, previously presented algorithm is a straightforward adaptation of a singleobjective TS algorithm for continuous problems. The second algorithm contains significant enhancements, including a novel design variable selection scheme (to improve local search efficiency) based on path relinking strategies common in discrete optimisation algorithms.</p><p>The motivation for these developments in the TS algorithm is our interest in aerodynamic shape optimisation problems. Such problems have high computational demands, are highly constrained, and cannot be solved by gradient-based methods due to the lack of gradient information and the large number of local minima. Previous research on a single-objective aerodynamic problem has found TS to be a particularly effective optimisation algorithm for this application domain <ref type="bibr" target="#b16">[17]</ref> and we believe that this will carry over into multi-objective problems in the same domain and also in any domain where the design space is highly constrained <ref type="bibr" target="#b19">[20]</ref>. Similar research in other fields has also suggested TS as a suitable optimisation algorithm for these kinds of problems <ref type="bibr" target="#b4">[5]</ref>.</p><p>The development of the design variable selection scheme was motivated by the authors' belief that real-world optimisation problems will increasingly have larger numbers of design variables. Good parameterisation schemes for aerodynamic shape optimisation problems -as shown by Harvey <ref type="bibr" target="#b16">[17]</ref>, Kellar <ref type="bibr" target="#b22">[23]</ref>, Duvigneau and Visonneau <ref type="bibr" target="#b9">[10]</ref> and Gaiddon et al. <ref type="bibr" target="#b12">[13]</ref> -tend to produce optimisation landscapes with many variables.</p><p>Of particular interest is the parameterisation scheme -Kellar's observation that, given a perfect optimisation algorithm and a zero cost objective function evaluation, the effectiveness of an optimisation algorithm is solely dependent on the range of possible designs it can generate is particularly pertinent. Kellar showed that a good and highly flexible parameterisation scheme for the shape optimisation of a Formula 1 racing car front wing could have of the order of 1000 design variables <ref type="bibr" target="#b22">[23]</ref>. The shape optimisation of a Boeing 747 wing performed by Jameson <ref type="bibr" target="#b20">[21]</ref> required 90 design variables.</p><p>Of course, the effectiveness of optimisation in a real-world situation will depend on the interplay between all three components -the optimisation algorithm, the parameterisation scheme and the underlying simulation generating the objective function values -but it is clear that optimisation algorithms in the future will have to cope with greater numbers of design variables.</p><p>Furthermore, in the same work Kellar performed a parametric study on a number of optimisation problems and showed that the sensitivity of an objective function to each design variable was not consistent across the design space. Specifically, for each design variable, there were regions in the design space where that variable had little effect on the objective function and regions where it had a great effect. Thus, he showed that optimising on a dynamically changing subset of design variables, rather than the entire set of variables, led to a great optimiser performance improvement. However, it is important to note that this is only possible using a local search method (such as TS) as the design variable sensitivities are local themselves.</p><p>Ideally, one could devise an optimisation scheme that employed a full parametric sensitivity analysis as part of the ongoing search. This, however, would be unfeasibly expensive when one considers the number of function evaluations required. Kellar circumvented this problem by performing cheap geometric comparisons with a dynamic reference set of known good solutions. This is analogous to path relinking <ref type="bibr" target="#b14">[15]</ref> employed in discrete optimisation strategies. Inspired by Kellar's work, we modified his strategy so that it could be applied to any continuous optimisation problem and incorporated it into our multi-objective TS algorithm.</p><p>In the remainder of this paper, we will describe these developments in more detail and present results of a comparison between our two TS variants and a leading multi-objective Genetic Algorithm, NSGA-II <ref type="bibr" target="#b8">[9]</ref>. Although comparisons between one of these TS algorithms and NSGA-II have been previously published <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>, this paper describes the significant enhancements made in the new TS variant and provides a far more rigourous performance assessment of all three algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Multi-objective optimisation</head><p>The goal of single-objective optimisation is to find a vector x such that f ð xÞ attains its minimal value, its optimum. The vector x is called a vector of design variables and the function f ð xÞ is called an objective function. A point x 1 in design space can be considered ''better'' than another point</p><formula xml:id="formula_0">x 2 if f ð x 1 Þ &lt; f ð x 2 Þ</formula><p>. Thus, single-objective optimisation has only one optimal solution cost (although there is the possibility that this may be realised by multiple design vectors).</p><p>In multi-objective optimisation, we are tasked with minimising not just one objective function, but n objective functions f 1 ð xÞ; . . . ; f n ð xÞ, where n P 2. The solution to this problem is more complex than the single-objective case, and the idea of Pareto-dominance must be introduced to be able to visualise it. Consider first an objective function vector F ð xÞ, where F ð xÞ ¼ ff 1 ð xÞ; . . . ; f n ð xÞg. A point x 1 , with an objective function vector F 1 , is said to dominate point x 2 , with an objective function vector F 2 , if no component of F 1 is greater than its corresponding component in F 2 , and at least one component is smaller. Similarly, x 1 can be said to be Pareto-equivalent to x 2 if some components of F 1 are greater than F 2 and some are smaller. Pareto-equivalent points represent a trade-off between the objective functions, and it is impossible to say that one point is ''better'' than another Paretoequivalent point without introducing preferences or relative weighting of the objectives.</p><p>Thus, the solution to a multi-objective optimisation problem is a set of design vectors which are not dominated by any other vector, and which are Pareto-equivalent to each other. This set is known as the Pareto-optimal set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Existing multi-objective Tabu Search algorithms</head><p>There are two commonly used approaches to solving a multi-objective optimisation problem <ref type="bibr" target="#b29">[30]</ref>. The first reduces the multiple objectives to a single objective by generating a composite objective function, usually from a weighted sum of the objectives. This composite objective function can be optimised using existing single-objective optimisers. However, the weights must be pre-set, and the solution to this problem will be a single vector of design variables rather than the entire Pareto-optimal set. This can have undesirable consequences: setting the weights implicitly introduces the designer's preconceptions about the relative trade-off between objectives. Real-world problems can produce surprising Pareto-optimal sets which may profoundly affect design decisions, and the potential to generate novel designs is a key benefit of optimisation <ref type="bibr" target="#b29">[30]</ref>. The TS algorithms reviewed by Jones et al. <ref type="bibr" target="#b21">[22]</ref> use this approach to solve the multi-objective problem.</p><p>The second approach to solving the multi-objective problem is to search directly for the entire Pareto-optimal set. This can be achieved in a number of ways and requires modification to existing single-objective algorithms.</p><p>The authors know of only two other attempts to produce a multi-objective TS algorithm which finds multiple Pareto-optimal solutions to a continuous optimisation problem in a single run. Hansen's algorithm <ref type="bibr" target="#b15">[16]</ref> is an extension of the composite objective approach: his algorithm performs a number of composite objective Tabu searches in parallel. Each search has a different and dynamically updated set of weights, and in this way the search can be driven to explore the entire Pareto front. This algorithm, although a good implementation of TS, suffers the problems common to all weighted-sum approaches: for problems with concave Pareto fronts, there may be regions of the front that are not defined by a combination of weights, and conversely certain combinations of weights represent two points on the front. Thus, this algorithm may not adequately locate the entire Pareto-optimal set. Baykasoglu et al. <ref type="bibr" target="#b1">[2]</ref> developed a TS algorithm combining a downhill local search with an intensification memory (IM) to store non-dominated points that were not selected in the search. When the search fails to find a downhill move, a point from the IM is selected instead. When the IM is empty and all search paths exhausted, the algorithm stops. This cannot be considered a true TS algorithm: in restricting the search to only downhill moves its originators reject one of the basic tenets of TS, that ''a bad strategic choice can yield more information than a good random choice'' <ref type="bibr" target="#b14">[15]</ref>. Also, the lack of any diversification strategy renders the algorithm incomplete and merely an elaborate local search algorithm.</p><p>For combinatorial optimisation problems, Caballero et al. <ref type="bibr" target="#b3">[4]</ref> developed a novel TS based algorithm with a 2-phase approach: the first phase consisted of a local Tabu Search algorithm to generate a list of locally Pareto-equivalent solutions (those solutions which are non-dominated with respect to their immediate neighbours); the second phase involved an intensification procedure using these solutions, which employed a path-relinking strategy. While the structure of their algorithm is quite different, with elements being tailored to combinatorial optimisation problems, it is a good implementation and it contains some interesting ideas.</p><p>Jaeggi et al. developed the first multi-objective TS variant presented in this paper and executed a performance comparison on a set of unconstrained test functions <ref type="bibr" target="#b18">[19]</ref>. The constraint handling approach and the performance of the algorithm on constrained optimisation problems was also presented in <ref type="bibr" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Path relinking</head><p>Path relinking strategies are quite common in the discrete optimisation field. They were developed for use in TS <ref type="bibr" target="#b14">[15]</ref> and Scatter Search <ref type="bibr" target="#b13">[14]</ref> algorithms, and have also been used in Greedy Randomised Adaptive Search Procedures <ref type="bibr" target="#b0">[1]</ref>.</p><p>The underlying principle is that knowledge of the path (or direction) in design space can be used to guide the search along that path, given that it may be a better search direction than a random one, in the hope that it will yield further good points.</p><p>A path can be determined by considering an initial point and a guiding (or reference) point. The reference point is a known good solution in the search. In essence, considering the points as vectors of design variables, the path between the points is a linear combination of their design variables and, as such, retains information about the reference point, leading ideally to further good points <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Multi-objective Tabu Search adaptation</head><p>In this paper, we present two multi-objective TS algorithms. The first, previously presented algorithm <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref> we call MOTS (Multi-Objective Tabu Search). The second algorithm, which contains the newly developed design variable selection scheme, we call PRMOTS (Path Relinking Multi-Objective Tabu Search). The fundamental basis for both algorithms is the same and is presented in this section. The two algorithms differ in their local search pattern, a key component of TS and an area in which significant performance enhancements can be made, and this will be described in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Algorithm overview</head><p>The single-objective TS implementation of Connor and Tilley <ref type="bibr" target="#b5">[6]</ref> is used as a starting point for our multi-objective variants. This uses a Hooke and Jeeves (H&amp;J) local search algorithm (designed for continuous optimisation problems) <ref type="bibr" target="#b17">[18]</ref> coupled with short, medium and long term memories to implement search intensification and diversification as prescribed by Glover and Laguna <ref type="bibr" target="#b14">[15]</ref>.</p><p>TS operates in a sequential, iterative manner: the search starts at a given point and the algorithm selects a new point in the search space to be the next current point. The basic search pattern in Connor and Tilley's implementation is the H&amp;J search.</p><p>Recently visited points are stored in the short term memory (STM) and are Tabu -the search is not allowed to revisit these points. Optimal or near-optimal points are stored in the medium term memory (MTM) and are used for intensification, focusing the search on areas of the search space with known good objective function values. The long term memory (LTM) records the regions of the search space which have been explored, and is used on diversification, directing the search to regions which are under-explored. This is achieved by dividing each design variable into n_regions regions and counting the number of solutions evaluated in those regions. A local iteration counter i_local is used and reset upon a successful addition to the MTM. When i_local reaches user-specified values, the algorithm will diversify or intensify the search, or reduce the search step size and restart the search from the best solution found.</p><p>Thus, TS combines a systematic local search with a stochastic element and an intelligent coverage of the entire search space. Our multi-objective TS implementation of Connor and Tilley's algorithm <ref type="bibr" target="#b5">[6]</ref> is modified in the following areas: search point comparison; the H&amp;J move; optimal point archiving and the MTM; search intensification and restart strategy. These modifications are described below, along with some further improvements. A flow diagram of this algorithm is shown in Fig. <ref type="figure">1</ref>.</p><p>A pseudocode listing for the main TS procedure is presented in Algorithm 1, along with subroutines presented in Algorithms 2-11. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Search point comparison</head><p>In a single-objective optimisation problem, points may be compared using the operators ==, &gt; and &lt; acting on the objective function values for those points. Similarly, points in a multi-objective problem can be compared in the same way (thus preserving the logic of the single-objective algorithm) by using the concepts of Pareto-equivalence (==) and dominance (&gt; and &lt;), described in Section 2.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">The Hooke and Jeeves move</head><p>At each iteration, a H&amp;J move is made. 2n_var new points are generated by incrementing and decrementing each of the n_var design variables by a given step around the current point. The objective functions for each new point are evaluated and, as long as the point is neither Tabu (i.e., not a member of the STM) nor violates any constraints, it is considered as a candidate for the next point in the search.</p><p>In the single-objective TS algorithm, these candidates are sorted and the point with the lowest objective is chosen as the next point. A similar logic can be applied to the multi-objective case: however, the possibility of multiple points being Pareto-equivalent and optimal must be allowed for. This is achieved by classifying each candidate point according to its domination or Pareto-equivalence to the current point. If there is a single dominating point, it is automatically accepted as the next point. If there are multiple dominating points, the dominated points within that group are removed and one is selected at random from those remaining. The other points become candidates for intensification (discussed below). If there are no dominating points, the same procedure is applied to those candidate points which are Pareto-equivalent to the current point. If there are no Pareto-equivalent points, a dominated point is selected in the same fashion. Thus, our strategy accepts both downhill and uphill moves -the next point is simply the ''best'' allowed point (or one of the Pareto-equivalent best points) selected from the candidate solutions.</p><p>In addition, a pattern move strategy is implemented in the same way as Connor and Tilley. Before every second H&amp;J move, the previous move is repeated. This new point is compared to the current point, and, if it dominates it, is accepted as the next point; if not, the standard H&amp;J move is made. In this way, the search may be accelerated along known downhill directions. The basic search pattern is shown in Fig. <ref type="figure" target="#fig_0">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Optimal point archiving and the medium term memory</head><p>In Connor and Tilley's single-objective TS, the MTM is a bounded, sorted list of near-optimal solutions. As the concept of a single optimal point does not exist in multi-objective optimisation (see Section 2.1), we replace the MTM in our multi-objective TS variant by an unbounded set of non-dominated solutions produced by the search. As new points are evaluated, they become candidates for addition to this set. Thus, the MTM represents the Paretooptimal set for the problem at that stage in the search.</p><p>An unbounded MTM was chosen for two main reasons. First, for continuous problems the ideal Pareto set is infinite and an unbounded set is a logical discretisation of this concept. While there are legitimate concerns regarding the presentation of a large number of Pareto-optimal solutions to a designer as the result of an optimisation run, we feel it would be better to deal with these issues at the post-processing stage. It is worth pointing out that some GAs use bounded archives of optimal points because this is consistent with the use of fixed size populations in those algorithms.</p><p>Our second justification for the use of an unbounded set is entirely pragmatic: typically the number of solutions stored in the MTM is low. For example, for the problems presented in this paper, the MTM size rarely exceeded 150 -one would expect real-world problems run with a lower number of function evaluations to have smaller MTMs. For an MTM of this kind of size, the memory and run-time overhead is low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Intensification and restart strategy</head><p>The original single-objective TS produced intensification points by using the MTM to generate points in the neighbourhood of good solutions. Although the replacement of the MTM by a Pareto-optimal set of solutions allows us to use a variant of this strategy, a feature of multi-objective optimisation suggests an alternative strategy, similar to that used by Baykasoglu et al. <ref type="bibr" target="#b1">[2]</ref>.</p><p>A multi-objective H&amp;J iteration may produce multiple Pareto-optimal points (see Fig. <ref type="figure" target="#fig_0">2</ref>). As only one point may be selected as the next point, it seems wasteful to discard the other points. Therefore, we incorporate an intensification memory into our algorithm. This is a set of Pareto-equivalent points; at each H&amp;J step, points which dominate the current solution, but are not selected as the next point (of which there can be only one), are considered as candidates for addition to the set. At search intensi- fication, a point is chosen randomly from the IM. The IM is continuously updated and points which become dominated by the addition of a new point are removed. Thus, the IM should always contain points which are on, or near to, the current Pareto-optimal front (stored in the MTM). Fig. <ref type="figure" target="#fig_0">2</ref> shows the relationship between the various TS memories.</p><p>The single-objective TS restart strategy returns the search to the current best point in the MTM. As the MTM is now a set of Pareto-optimal points, we simply select one point at random from the set. More intelligent restart strategies are possible <ref type="bibr" target="#b29">[30]</ref> and are under investigation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Constraint handling</head><p>We employ a very simple constraint handling strategy: any point which violates any constraint is deemed to be Tabu and the search is not allowed to visit that point. Thus, accepted solutions are limited to feasible space. We refer to this as a binary constraint -solutions are either feasible or not and there is no need to quantify the extent of constraint violation.</p><p>A common constraint handling approach is that using penalty functions <ref type="bibr" target="#b8">[9]</ref>. Here, the extent of constraint violation must be quantified and this value is used as a surrogate objective to drive the search into feasible regions.</p><p>Our algorithm has the flexibility to use both kinds of constraint handling as the introduction of penalty functions or modified dominance relations <ref type="bibr" target="#b8">[9]</ref> is trivial. We believe that this approach gives our algorithm significant power in tackling realworld problems, particularly where complex simulations are being used to evaluate objective functions. Here, there is a possibility that a simulation may not converge and thus a solution may not be feasible, with no further information. Indeed, it is the authors' experience that the attainment of a fully converged CFD solution for novel geometries is a non-trivial task and there are frequent simulation failures. These failures tend not to be an issue of software quality, rather they reflect the overstepping of boundaries in the physical model being used. These issues are also reported by researchers in other fields <ref type="bibr" target="#b4">[5]</ref>. A further benefit to running our algorithm on highly constrained problems is the local search pattern at the heart of TS, which reduces the likelihood of generating infeasible solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">Parallelisation strategy</head><p>Any optimisation procedure that forms part of a real-world design cycle must be able to complete in a reasonable time frame. Parallel processing offers a large potential speed-up; an optimisation algorithm should ideally be designed with this in mind. Our multi-objective TS algorithm is parallelised by means of functional decomposition. At each H&amp;J move, the required objective function evaluations are computed in parallel. This gives the potential for near-linear speed-up on parallel computers with up to 2n_var processors (this being the maximum number of required function evaluations at each iteration, determined by the H&amp;J search).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Local search efficiency improvements</head><p>The H&amp;J local search strategy requires roughly 2n_var solution evaluations (allowing for points that are Tabu or violate constraints) at each step. This is the most computationally expensive part of the optimisation procedure -assuming that objective function evaluations are expensive compared to the optimisation algorithm logic, a reasonable assumption for most real-world problems -and there is considerable scope for efficiency savings at this step.</p><p>Our two TS variants are distinguished by the way in which they attempt to improve the search efficiency at this step. The original MOTS algorithm incorporates an element of random sampling with the aim of finding a ''downhill'' move (defined by Pareto-dominance) in fewer objective function evaluations. The PRMOTS algorithm restricts the dimensionality of the local search space by only using a set of design variables that are estimated to have the greatest impact on the objective function values. These two approaches are described in detail below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Improved local search space sampling -MOTS</head><p>Following the H&amp;J search pattern procedure, we generate the 2n_var new points, remove those that are Tabu, but only evaluate n_sample 6 2n_var points from those that remain, selecting randomly to avoid introducing any directional bias. If one of these points dominates the current point, it is automatically accepted as the next point. If more than one point dominates the current point, a nondominated point from these is randomly selected. If no points dominate the current point, a further n_sample points (or less, depending on the number of points remaining) are sampled randomly and the comparison is repeated. If all the feasible, non-Tabu points have been sampled without finding a point that dominates the current solution, the standard selection procedure is employed, as described in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Design variable selection scheme -PRMOTS</head><p>The search space sampling in MOTS reduces the number of potential evaluations at each H&amp;J step by introducing random sampling. PRMOTS attempts to reduce the number of evaluations in a more systematic way; PRMOTS allows some design variables to be ''dormant'' and others to be ''active'' in the search, based on their estimated likely impact on the objective function values. Thus, the dimensionality of the problem is temporarily reduced.</p><p>Ideally, one would perform a full parametric analysis to determine the full sensitivities of the objective functions to the design variables, and select the active variables according to these sensitivities. However, for a problem with a large number of design variables and expensive objective functions, this procedure would be prohibitively costly. Instead, our scheme uses the concept of a path in design space as a surrogate for the likely impact on the objective functions, allowing quasisensitivities to be calculated at near-zero cost.</p><p>After every select_interval TS iterations, variable selection takes place as follows. Based on the H&amp;J search pattern, we generate the 2n_var new points. However, we now keep all the points without removing those that are Tabu and without making any function evaluations. We then assess the potential for improvement in the objective functions for each design variable in the following way. Each design variable has two new points associated with it, for which the H&amp;J step has incremented or decremented that variable. Taking the current set of Pareto-optimal points (stored in the MTM) as the reference set, the Euclidean distance in design space between these two points and every point in the reference set is calculated. The smallest of these distances is saved, and the design variables are ranked according to this distance. The design variables with the n_selected smallest distances are set to be active for the next select_interval iterations, while the other variables are dormant and are kept fixed at their current values, until the procedure is repeated again. The calculation of the distances used to rank the design variables is shown graphically in Fig. <ref type="figure">3</ref>.</p><p>In essence, this selection scheme is only allowing the optimiser to vary those variables that will progress the search from current point to the reference set in the fastest possible way. This assessment is based solely on a measure of the Euclidean distance in design space, which is used as a surrogate mea-Fig. <ref type="figure">3</ref>. Graphical representation of the parameter selection scheme -calculation of the minimum Euclidean distance associated with variable x 1 to the reference set.</p><p>sure of the scale of potential improvement -it does not involve any evaluation of the objective functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Testing procedure</head><p>In order to assess the effectiveness of our two TS algorithms, we undertook a rigorous testing procedure on a set of benchmark test problems. There were two aims to this exercise: to assess the performance benefit of the design variable selection scheme; to compare the performance of both TS variants to a leading multi-objective optimisation algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Test functions</head><p>The test functions used in this study are from the ZDT family of problems <ref type="bibr" target="#b7">[8]</ref> and are described in detail in Table <ref type="table" target="#tab_1">1</ref>. They have 10 6 n_var 6 30 and the number of objectives n_obj = 2, and they are designed to have Pareto-optimal sets which are difficult to locate accurately by means of an optimisation algorithm. They have some shortcomings, namely that the locations of the Pareto-optimal sets in design space form continuous regions <ref type="bibr" target="#b27">[28]</ref>, and their relevance and applicability to real-world problems is debatable. However, they are easy to imple-ment, well studied, fast to compute and provide a useful basis for assessing optimiser performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Benchmark algorithm</head><p>The algorithm chosen for comparison was NSGA-II <ref type="bibr" target="#b8">[9]</ref> which has been shown to be one of the better multi-objective Genetic Algorithms and has a number of high-quality, open-source software implementations freely available. Although various studies have been published which show competitive algorithms outperforming it on the family of ZDT problems <ref type="bibr" target="#b26">[27]</ref>, there are two main reasons for the choice of NSGA-II as the benchmark algorithm. First, the algorithm is very well known, due both to its inclusion in a number of free and commercial software packages and to its featuring in a range of published studies. Second, our ultimate goal in developing our TS algorithms is not absolute performance on a set of benchmark problems. Rather, our development is motivated by the requirements of real-world optimisation problems, for which we believe our TS algorithms to be well suited. Performance assessment on a set of well known problems against a well known algorithm then serves as validation of our approach and provides us with suggestions for algorithmic improvement. </p><formula xml:id="formula_1">q gð xÞ ¼ 1 þ 9 P n var i¼2 xi ðn varÀ1Þ ZDT2 30 f 1 ð xÞ ¼ x 1 x 2 ½0:0; 1:0 f 2 ð xÞ ¼ gð xÞ 1 À ð x1 gð xÞ Þ 2 h i gð xÞ ¼ 1 þ 9 P n var i¼2 xi ðn varÀ1Þ ZDT3 30 f 1 ð xÞ ¼ x 1 x 2 ½0:0; 1:0 f 2 ð xÞ ¼ gð xÞ 1 À ffiffiffiffiffiffi x1 gð xÞ q À x1 gð xÞ sinð10px 1 Þ gð xÞ ¼ 1 þ 9 P n var i¼2 xi ðn varÀ1Þ ZDT4 10 f 1 ð xÞ ¼ x 1 x 1 2 [0.0,1.0] f 2 ð xÞ ¼ gð xÞ 1 À ffiffiffiffiffiffi x1 gð xÞ q x i 2 [À5.0,5.0] gð xÞ ¼ 1 þ 10ðn var À 1Þ þ sð sÞ i = 2, . . . ,n_var sð xÞ ¼ P n var i¼2 ½x 2 i À 10 cosð4px i Þ ZDT6 10 f 1 ð xÞ ¼ 1 À expðÀ4x 1 Þ sin 6 ð6px 1 Þ x 2 ½0:0; 1:0 f 2 ð xÞ ¼ gð xÞ 1 À ð f1ð xÞ gð xÞ Þ 2 h i gð xÞ ¼ 1 þ 9 P n var i¼2 xi ðn<label>varÀ1Þ</label></formula><p>0:25</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Performance analysis</head><p>The performance assessment of multi-objective optimisation algorithms is more involved than the single-objective case. In single-objective optimisation, the output of an optimisation run is a single best objective function value obtained -thus performance can be directly compared on the basis of these values. In multi-objective optimisation, the output is set of solutions approximating the Pareto-optimal set, which we call an approximation set. The key to performing a performance assessment of a multi-objective optimisation algorithm is the ability to assign a measure of quality to an approximation set -in essence, reducing it to a single value -which then may be directly compared to other runs. There are a number of such performance indicators available, each indicator having different properties and measuring different aspects of quality of the approximation set. However, certain indicators are inconsistent with concepts of Pareto-dominance and, as such, are poor choices. Zitzler et al. <ref type="bibr" target="#b31">[32]</ref> give a detailed discussion of the performance assessment of multi-objective optimisers. Following their advice, and that also given by Fonseca et al. <ref type="bibr" target="#b11">[12]</ref>, we use two performance indicators in this study: the unary epsilon indicator and the hypervolume indicator (both described below).</p><p>In this study, we have chosen not to include performance indicators that attempt to measure the degree to which solutions are evenly spread along the Pareto front. As discussed by Zitzler et al. <ref type="bibr" target="#b31">[32]</ref>, it is difficult to draw any meaningful conclusions from such indicators, except in cases where two sets of results are (or are very nearly) non-dominated by each other. Similarly, we have not included an indicator measuring distances of some kind to an ideal set. For certain problems, an ideal set cannot be calculated analytically. In addition, this kind of indicator does not offer any further insight into the relative performance of two algorithms than that provided by either the hypervolume or epsilon indicator. It only allows us to gauge absolute performance -as previously discussed, the nature of this study is largely comparative.</p><p>Further, as the optimisation algorithms under evaluation are not deterministic, the results from multiple runs must be collated and assessed. A suitable statistical test for determining whether certain algorithms tend to produce better approximation sets (using the performance indicators described) is the Kruskal-Wallis test <ref type="bibr" target="#b6">[7]</ref>. This technique will also be described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1.">Unary epsilon indicator</head><p>The unary epsilon indicator was proposed by Zitzler et al. <ref type="bibr" target="#b31">[32]</ref> and makes direct use of the principle of Pareto-dominance, making it very intuitive. Consider two approximation sets A and B where A dominates B. The epsilon indicator is a measure of the smallest distance one would need to translate every point in B so that it dominates A. If set A is chosen to be a reference set, such that it dominates sets B and C, then B and C can be directly compared on the basis of the epsilon indicator with respect to the reference set. Thus, for a given reference set, the indicator is unary in nature. See Fig. <ref type="figure" target="#fig_1">4</ref> for a graphical representation of this performance indicator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2.">Hypervolume indicator</head><p>The hypervolume indicator was proposed by Zitzler and Thiele <ref type="bibr" target="#b30">[31]</ref> and its properties are discussed in depth in <ref type="bibr" target="#b31">[32]</ref>. The two-dimensional case can be easily visualised and understood -each point in the approximation set forms a rectangle of given area with respect to a reference point that lies beyond the bounds of the approximation set. The hypervolume indicator is the area of the union of all these rectangles. This concept can easily be extended to higher dimensions. In effect, the hypervolume indicator measures the hyperspace enclosed by the approximation set. Fig. <ref type="figure" target="#fig_1">4</ref> also shows a graphical representation of this performance indicator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3.">Kruskal-Wallis test</head><p>The Kruskal-Wallis test is an extension of the Mann-Whitney test for two independent samples, allowing it to incorporate k independent samples, for k P 2. Using random samples of a quantity taken from k different populations, it is designed to determine whether certain populations tend to produce greater observed values of that quantity. Like the Mann-Whitney test, the Kruskal-Wallis test is a rank-based method -that is, all observations from the k populations are ranked together, and the ranks of individuals in a population are used to calculate the test statistic. Full details of this test (and the Mann-Whitney test) can be found in <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Experimental details</head><p>Each algorithm was run 45 times on each test function and the non-dominated sets obtained after 1000, 5000 and 10,000 function evaluations were archived and used to generate the performance measures. The random number generator for each of the 45 runs was initialised with a different seed, the seeds being constant across test functions and algorithms.</p><p>While previous studies <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b18">19]</ref> have assessed algorithm performance at up to 25,000 function evaluations, we felt a lower number of evaluations would yield results more applicable to real-world applications -Kipouros et al. performed aerodynamic shape optimisation with up to 3000 evaluations <ref type="bibr" target="#b23">[24]</ref>, while Knowles <ref type="bibr" target="#b24">[25]</ref> has developed an optimiser to perform well on a maximum of 250 evaluations, in response to a real-world requirement.</p><p>The two TS algorithms were implemented in a C++ program and the parameter settings used are shown in Table <ref type="table" target="#tab_2">2</ref>. The TS algorithms were both initialised with a randomly selected point from the search space, selected differently according to the random number generator seed. The NSGA-II algorithm implementation used was that available in the PISA toolkit <ref type="bibr" target="#b2">[3]</ref> using real-coded variables and simulated binary crossover (SBX) <ref type="bibr" target="#b8">[9]</ref>, and the parameter settings used are shown in Table <ref type="table" target="#tab_3">3</ref>.</p><p>The generation of the reference sets used for calculating the performance indicators and the calculation of the performance indicators themselves were also performed using software provided in the PISA toolkit. The Kruskal-Wallis tests and the generation of additional statistics were performed using the R statistical software environment <ref type="bibr" target="#b28">[29]</ref>.</p><p>The results were normalised such that all objective function values fell in the range 1.0-2.0. Thus, a reference point could be chosen as the nadir point of the entire set of results for a particular problem and evaluation count. This reference point was used in the hypervolume calculation. A reference set was chosen as the 50% attainment surface of a random search and the indicator values were calculated relative to this reference set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1.">Run-time performance</head><p>Given the differences in complexity between MOTS/PRMOTS and NSGA-II, it is worth making a comment on the run-times of the algorithms under comparison. Detailed run-time figures were not calculated as the authors felt this was not worthwhile for two reasons. First, the execution time for all three algorithms under test was in the order of 30 seconds. For a real-world optimisation problem, it is not uncommon for the evaluation of a singleobjective function value to take this amount of time; in many cases, objective function evaluations may take in the order of minutes or hours. Thus the proportion of the total computational cost attributable to the optimisation algorithm itself for most realworld applications is negligible.</p><p>Second, the performance of any code is highly implementation-specific. The implementation of NSGA-II used in this study was that provided by the PISA toolkit, which is written in C and makes heavy use of files as a means of inter-process communication. Our implementations of the TS algorithms were written in C++ and inter-process communication is achieved using the MPI protocol. There are clearly significant performance overheads associated with code-specific design choices, and this makes run-time comparison almost worthless.</p><p>A specific feature of our TS algorithms is the use of multiple memories, some of which are unbounded. The insertion of a point into the memories is, at worst, an n 2 operation and readers may rightly question the impact of this on performance. It is worth noting our comments above and our observations that the run-times of our TS algorithms were consistently smaller that those of the NSGA-II algorithm. The other potential perfor-mance impact of the use of memories in TS is the computer's RAM usage. Again, this is an implementation-specific detail. Through use of pointers, it is possible to minimise this RAM usage. Assume storage of 25,000 solutions comprising of 30 design variables and two objective functions: a total of 800,000 floating point numbers must be stored in the computer. Consider further, as a worst case scenario, that each of those 25,000 solutions is referenced by pointers in four separate memories: a further 100,000 pointer memory locations must be stored. A floating point number requires 4 bytes, as does a memory pointer. Thus, a total of (800,000 + 100,000) • 4 bytes are required, or 3.6MB. This memory requirement, while making it unsuitable for embedded applications, is very low for modern desktop or server computer systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results and discussion</head><p>The means and standard deviations of both performance indicators for all test conditions are shown in Table <ref type="table" target="#tab_4">4</ref>, and the results of the Kruskal-Wallis test are shown in Table <ref type="table" target="#tab_5">5</ref>. A lower number for both indicators signifies a ''better'' approximation set. As previously mentioned, the results for a particular problem and evaluation count were normalised and indicator values calculated relative to a reference set. This means that the results are relative and it is not possible to infer trends over different numbers of evaluations. For example, for problem ZDT3, both indicators have a greater value at 10,000 evaluations than at 5000 evaluations for all three algorithms -if the indicators were absolute this would suggest worse approximation sets at 10,000 evaluations than at 5000 evaluations, which is clearly wrong.</p><p>For the Kruskal-Wallis test, the null-hypothesis H0 was that no significant differences could be found in the distribution of results for the performance indicators at a confidence level a = 0.05. The p-values shown in Table <ref type="table" target="#tab_5">5</ref> (e.g., p(A &gt; B)) are the probabilities that an algorithm A exhibits better performance than algorithm B.</p><p>The testing procedure gave rise to 30 possible scenarios (5 test functions, 3 function evaluation levels and 2 performance indicators). In these 30 scenarios, the null-hypothesis was accepted in three instances -that is, it was not possible to discern any meaningful difference between the performance of the three algorithms in 10% of the scenarios.</p><p>The results in Table <ref type="table" target="#tab_5">5</ref> allow us to compare the performance of the two TS variants, as well as that of the two variants plus NSGA-II. Considering solely the two TS variants, PRMOTS was the better algorithm in 18 (60%) of the scenarios whereas MOTS was the better algorithm in just 9 (30%) of the scenarios.</p><p>Considering all three algorithms, we find that NSGA-II was the better algorithm in 14 (47%) of the scenarios, whereas both MOTS and PRMOTS were better in 13 (43%) of the scenarios.</p><p>It is interesting to note that the indicators sometimes give contradictory results. For example, in Table <ref type="table" target="#tab_5">5</ref> for problem ZDT4 at 10,000 evaluations, PRMOTS is found to be better than MOTS considering the hypervolume indicator, while the converse is true if the epsilon indicator is considered. While the indicators may be consistent with regard to the Pareto-dominance concept (as discussed in <ref type="bibr" target="#b31">[32]</ref>), this does not necessarily mean that they are consistent among themselves. This highlights the problem of relying on just one indicator to assess an optimisation algorithm's performance.</p><p>Box-plots of the epsilon indicator on all five test functions after 10,000 evaluations are given in Figs. <ref type="figure" target="#fig_2">5</ref><ref type="figure" target="#fig_3">6</ref><ref type="figure" target="#fig_4">7</ref><ref type="figure" target="#fig_5">8</ref><ref type="figure">9</ref>. The median, upper and lower quartiles and the extreme points for the 45 runs are shown in the boxplots. The results for the hypervolume indicator, and the results after 1000 and 5000 evaluations are similar.</p><p>It is clear from the plots (and from Table <ref type="table" target="#tab_4">4</ref>) that NSGA-II in general exhibits less variation in performance than either TS variant, with the exception of its performance on ZDT4. This behaviour may be desirable in certain situations (e.g. <ref type="bibr" target="#b24">[25]</ref>). Interestingly, results presented in <ref type="bibr" target="#b18">[19]</ref> showed that NSGA-II outperformed MOTS on ZDT4 on optimisation runs of 25,000 evaluations, because MOTS becomes trapped in a local optimum. This suggests that NSGA-II has a greater ability to locate other areas of the design space; GAs in general have a larger stochastic element to them, whereas TS methods have at their core a local search, so this is to be expected.</p><p>Similarly (from Figs. 5-9 and Table <ref type="table" target="#tab_4">4</ref>), PRMOTS in general exhibits less performance variation than MOTS, although the distribution in results is broadly comparable, as one might expect given that the same basic algorithm is common to both variants.</p><p>There is only test function on which MOTS comprehensively outperforms PRMOTS is ZDT3, and it is instructive to analyse this closer. An attainment surface plot for this problem is shown in Fig. <ref type="figure">10</ref>. An attainment surface plot is a way of visualising the output of n runs of an optimiser and shows the minimum surface in objective space achieved by m &lt; n of those runs. The technique is described in detail in <ref type="bibr" target="#b10">[11]</ref> and software included with the PISA toolkit <ref type="bibr" target="#b2">[3]</ref> was used to generate the plot. Fig. <ref type="figure">10</ref> shows the 18th or 60% attainment surface for both MOTS and PRMOTS on ZDT3 after 10,000 evaluations -this attainment surface is presented because it clearly illustrates a difficulty that PRMOTS has on this problem. This test function has a disjointed Pareto front and therefore presents problems for optimisation algorithms.</p><p>It is immediately apparent from Fig. <ref type="figure">10</ref> that the reason that PRMOTS has performed poorly relative to MOTS on this problem is that it has failed to adequately resolve two sections of the Pareto front,  corresponding to f 1 &gt; 0.4. Given that, on this problem, x 1 = f 1 , it appears that PRMOTS has not fully explored the entire range of design variable x 1 . One possible reason for this is that the variable selection scheme has ''locked-in'' x 1 to the lower end of its range; the optimisation algorithm may have quickly located the other two sections of the Pareto-front, thus the reference set used in the variable selection  scheme may not have shown enough diversity in x 1 to prevent x 1 from remaining dormant for much of the search. One possible, and simple, fix for this problem would be to introduce a stochastic element into the variable selection scheme, perhaps by means of roulette wheel selection of active design variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>In this paper, we have presented two TS algorithms for use on continuous multi-objective optimisation problems. Both algorithms feature mechanisms to improve the efficiency of the local search component of TS. The first algorithm, MOTS, uses an element of random sampling to reduce the computational cost. A more advanced version of this algorithm, PRMOTS, uses a novel design variable selection scheme inspired by path relinking strategies common in discrete optimisation problems. This scheme effectively performs a sensitivity analysis of the design variables, while avoiding the computational cost of a full parametric analysis. This allows the dimensionality of the problem to be temporarily reduced, leading to greater local-search efficiency.</p><p>These two algorithms were tested on a set of five standard test functions and the results were compared with those from a leading multi-objective GA, NSGA-II. The results showed that the variable selection scheme gave a clear improvement in performance over the basic MOTS algorithm. Additionally, both algorithms performed comparably with NSGA-II. Overall, both TS algorithms exhibited greater performance variability than NSGA-II, but this was compensated by a greater likely improvement in the objective functions.</p><p>Based on these findings, it appears that our PRMOTS algorithm is competitive with NSGA-II and both could be expected to perform well on other multi-objective optimisation problems. NSGA-II may be a better choice where low performance variability is desired. However, as we have argued in this paper and as reported by other researchers <ref type="bibr" target="#b4">[5]</ref>, the local-search component and the constraint handling flexibility of TS makes it particularly attractive for problems which may be highly constrained, and we believe that PRMOTS is a good choice for these types of problems. A major shortcoming in the assessment of optimisation algorithms for use on real-world problems is the lack of a suitable set of benchmark problems, which accurately capture the main features of the problems of interest. Until such a set is developed, true performance comparison between algorithms is difficult and one must rely on inference from a less suitable set of benchmark problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Future work</head><p>There are a number of further algorithmic developments suggested by these results. The introduction of a random element in the parameter selection scheme would potentially alleviate some of the problems encountered by PRMOTS on ZDT3. Further, although the introduction of the parameter selection scheme is an improvement on the basic Hooke &amp; Jeeves local search algorithm, there is still considerable scope for further enhancements in this area. For example, other than simple caching of solutions, the local search does not make use of the search memories (already present in the TS algorithm) in any intelligent manner: surrogate modelling, similar to that employed by the ParEGO algorithm <ref type="bibr" target="#b24">[25]</ref> would offer such an opportunity. Finally, the parallelisation strategy employed places rather hard limits on the scalability of the algorithm across many processors, especially for problems with a low number of design variables. An algorithm employing multiple local searches with shared global memories -a multi-threaded TS -would be far more flexible in this regard, and may also offer raw algorithmic performance improvements over and above the parallel computational speed-up.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Point selection for the Hooke &amp; Jeeves move and Tabu Search memories.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Graphical representation of epsilon and hypervolume indicators.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Box-plot of epsilon indicator results for ZDT1 at 10,000 evaluations.</figDesc><graphic coords="17,97.88,67.32,354.60,243.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Box-plot of epsilon indicator results for ZDT2 at 10,000 evaluations.</figDesc><graphic coords="17,97.88,356.60,354.60,243.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Box-plot of epsilon indicator results for ZDT3 at 10,000 evaluations.</figDesc><graphic coords="18,93.54,67.32,354.60,243.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Box-plot of epsilon indicator results for ZDT4 at 10,000 evaluations.</figDesc><graphic coords="18,93.54,350.86,354.60,242.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 .Fig. 10 .</head><label>910</label><figDesc>Fig. 9. Box-plot of epsilon indicator results for ZDT6 at 10,000 evaluations.</figDesc><graphic coords="19,97.88,67.32,354.60,241.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>Test functions</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Name</cell><cell>n_var</cell><cell>Objective functions</cell><cell></cell><cell>Variable bounds</cell></row><row><cell>ZDT1</cell><cell>30</cell><cell>f 1 ð xÞ ¼ x 1 f 2 ð xÞ ¼ gð xÞ 1 À</cell><cell>ffiffiffiffiffiffi x1 gð xÞ</cell><cell>x 2 ½0:0; 1:0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 Tabu</head><label>2</label><figDesc></figDesc><table><row><cell cols="2">Search parameter settings</cell></row><row><cell>Parameter</cell><cell>Description</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>NSGA-II parameter settings</cell><cell></cell></row><row><cell>Parameter</cell><cell>Description</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc>Means and standard deviations of the hypervolume and epsilon performance indicators</figDesc><table><row><cell>Functions</cell><cell>Evaluations</cell><cell>Indicator</cell><cell>MOTS</cell><cell></cell><cell>PRMOTS</cell><cell></cell><cell>NSGA-II</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Mean</cell><cell>SD</cell><cell>Mean</cell><cell>SD</cell><cell>Mean</cell><cell>SD</cell></row><row><cell>ZDT1</cell><cell>1000</cell><cell>hyp</cell><cell>0.2341</cell><cell>0.1623</cell><cell>0.1778</cell><cell>0.1396</cell><cell>0.1774</cell><cell>0.0201</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.2277</cell><cell>0.1748</cell><cell>0.1765</cell><cell>0.1524</cell><cell>0.1709</cell><cell>0.0190</cell></row><row><cell></cell><cell>5000</cell><cell>hyp</cell><cell>0.0694</cell><cell>0.02170</cell><cell>0.0676</cell><cell>0.0490</cell><cell>0.0008</cell><cell>0.0002</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.0555</cell><cell>0.0162</cell><cell>0.0633</cell><cell>0.0467</cell><cell>0.0021</cell><cell>0.0003</cell></row><row><cell></cell><cell>10,000</cell><cell>hyp</cell><cell>0.0425</cell><cell>0.0196</cell><cell>0.0331</cell><cell>0.0110</cell><cell>0.0002</cell><cell>0.0</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.0407</cell><cell>0.0170</cell><cell>0.0362</cell><cell>0.0113</cell><cell>0.0006</cell><cell>0.0</cell></row><row><cell>ZDT2</cell><cell>1000</cell><cell>hyp</cell><cell>0.1845</cell><cell>0.1413</cell><cell>0.1618</cell><cell>0.1151</cell><cell>0.2752</cell><cell>0.0362</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.1788</cell><cell>0.1492</cell><cell>0.1613</cell><cell>0.1305</cell><cell>0.3115</cell><cell>0.0371</cell></row><row><cell></cell><cell>5000</cell><cell>hyp</cell><cell>0.0894</cell><cell>0.0344</cell><cell>0.0790</cell><cell>0.0185</cell><cell>0.0559</cell><cell>0.0315</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.1056</cell><cell>0.0372</cell><cell>0.0997</cell><cell>0.0312</cell><cell>0.1293</cell><cell>0.0724</cell></row><row><cell></cell><cell>10,000</cell><cell>hyp</cell><cell>0.0500</cell><cell>0.0171</cell><cell>0.0461</cell><cell>0.0127</cell><cell>0.0559</cell><cell>0.0302</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.0725</cell><cell>0.0341</cell><cell>0.0795</cell><cell>0.0351</cell><cell>0.1294</cell><cell>0.0740</cell></row><row><cell>ZDT3</cell><cell>1000</cell><cell>hyp</cell><cell>0.1284</cell><cell>0.0590</cell><cell>0.1083</cell><cell>0.0250</cell><cell>0.3583</cell><cell>0.0172</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.1352</cell><cell>0.0637</cell><cell>0.1398</cell><cell>0.0396</cell><cell>0.3253</cell><cell>0.0282</cell></row><row><cell></cell><cell>5000</cell><cell>hyp</cell><cell>0.0659</cell><cell>0.0283</cell><cell>0.0705</cell><cell>0.0275</cell><cell>0.1761</cell><cell>0.0012</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.1198</cell><cell>0.0537</cell><cell>0.1375</cell><cell>0.0537</cell><cell>0.1625</cell><cell>0.0016</cell></row><row><cell></cell><cell>10,000</cell><cell>hyp</cell><cell>0.0834</cell><cell>0.0480</cell><cell>0.1018</cell><cell>0.0497</cell><cell>0.2995</cell><cell>0.0002</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.1938</cell><cell>0.0922</cell><cell>0.2302</cell><cell>0.0946</cell><cell>0.2701</cell><cell>0.0004</cell></row><row><cell>ZDT4</cell><cell>1000</cell><cell>hyp</cell><cell>0.4081</cell><cell>0.1006</cell><cell>0.4102</cell><cell>0.1025</cell><cell>0.0340</cell><cell>0.0155</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.3407</cell><cell>0.0830</cell><cell>0.3394</cell><cell>0.0958</cell><cell>0.0363</cell><cell>0.0127</cell></row><row><cell></cell><cell>5000</cell><cell>hyp</cell><cell>0.1078</cell><cell>0.0862</cell><cell>0.0945</cell><cell>0.0881</cell><cell>0.0192</cell><cell>0.0100</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.1115</cell><cell>0.0795</cell><cell>0.0952</cell><cell>0.0834</cell><cell>0.0188</cell><cell>0.0087</cell></row><row><cell></cell><cell>10,000</cell><cell>hyp</cell><cell>0.0104</cell><cell>0.0042</cell><cell>0.0103</cell><cell>0.0055</cell><cell>0.0269</cell><cell>0.0140</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.0113</cell><cell>0.0035</cell><cell>0.0121</cell><cell>0.0072</cell><cell>0.0277</cell><cell>0.0126</cell></row><row><cell>ZDT6</cell><cell>1000</cell><cell>hyp</cell><cell>0.4247</cell><cell>0.1289</cell><cell>0.3511</cell><cell>0.1410</cell><cell>0.2715</cell><cell>0.0723</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.2989</cell><cell>0.1235</cell><cell>0.2506</cell><cell>0.1272</cell><cell>0.2885</cell><cell>0.0702</cell></row><row><cell></cell><cell>5000</cell><cell>hyp</cell><cell>0.3748</cell><cell>0.0756</cell><cell>0.3526</cell><cell>0.0757</cell><cell>0.0126</cell><cell>0.0064</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.2791</cell><cell>0.0725</cell><cell>0.2599</cell><cell>0.0815</cell><cell>0.0199</cell><cell>0.0065</cell></row><row><cell></cell><cell>10,000</cell><cell>hyp</cell><cell>0.3176</cell><cell>0.0461</cell><cell>0.3201</cell><cell>0.0494</cell><cell>0.0008</cell><cell>0.0002</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.2319</cell><cell>0.0678</cell><cell>0.2379</cell><cell>0.0736</cell><cell>0.0020</cell><cell>0.0003</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc>Kruskal-Wallis p-values</figDesc><table><row><cell>Functions</cell><cell>Evaluations</cell><cell>Indicator</cell><cell>p(A &gt; B)</cell><cell>p(A &gt; C)</cell><cell>p(C &gt; B)</cell><cell>Indicated best</cell><cell>Indicated best</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>TS algorithm</cell><cell>overall</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>algorithm</cell></row><row><cell>ZDT1</cell><cell>1000</cell><cell>hyp</cell><cell cols="2">H0 hypothesis satisfied</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell cols="2">H0 hypothesis satisfied</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>5000</cell><cell>hyp</cell><cell>0.0</cell><cell>0.0006</cell><cell>0.0</cell><cell>PRMOTS</cell><cell>NSGA-II</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.0</cell><cell>0.1167</cell><cell>0.0</cell><cell>PRMOTS</cell><cell>NSGA-II</cell></row><row><cell></cell><cell>10,000</cell><cell>hyp</cell><cell>0.0</cell><cell>0.00078</cell><cell>0.0</cell><cell>PRMOTS</cell><cell>NSGA-II</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.0</cell><cell>0.1486</cell><cell>0.0</cell><cell>PRMOTS</cell><cell>NSGA-II</cell></row><row><cell>ZDT2</cell><cell>1000</cell><cell>hyp</cell><cell>1.0</cell><cell>0.1667</cell><cell>1.0</cell><cell>PRMOTS</cell><cell>PRMOTS</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>1.0</cell><cell>0.2009</cell><cell>1.0</cell><cell>PRMOTS</cell><cell>PRMOTS</cell></row><row><cell></cell><cell>5000</cell><cell>hyp</cell><cell>0.0</cell><cell>0.0161</cell><cell>0.0065</cell><cell>PRMOTS</cell><cell>NSGA-II</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.9997</cell><cell>0.2502</cell><cell>0.9999</cell><cell>PRMOTS</cell><cell>PRMOTS</cell></row><row><cell></cell><cell>10,000</cell><cell>hyp</cell><cell>0.9980</cell><cell>0.1838</cell><cell>0.9999</cell><cell>PRMOTS</cell><cell>PRMOTS</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.9999</cell><cell>0.7529</cell><cell>0.9998</cell><cell>MOTS</cell><cell>MOTS</cell></row><row><cell>ZDT3</cell><cell>1000</cell><cell>hyp</cell><cell>1.0</cell><cell>0.0123</cell><cell>1.0</cell><cell>PRMOTS</cell><cell>PRMOTS</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>1.0</cell><cell>0.7119</cell><cell>1.0</cell><cell>MOTS</cell><cell>MOTS</cell></row><row><cell></cell><cell>5000</cell><cell>hyp</cell><cell>1.0</cell><cell>0.8557</cell><cell>1.0</cell><cell>MOTS</cell><cell>MOTS</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.9998</cell><cell>0.9689</cell><cell>0.9665</cell><cell>MOTS</cell><cell>MOTS</cell></row><row><cell></cell><cell>10,000</cell><cell>hyp</cell><cell>1.0</cell><cell>0.9496</cell><cell>1.0</cell><cell>MOTS</cell><cell>MOTS</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell cols="2">H0 hypothesis satisfied</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ZDT4</cell><cell>1000</cell><cell>hyp</cell><cell>0.0</cell><cell>0.6287</cell><cell>0.0</cell><cell>MOTS</cell><cell>NSGA-II</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.0</cell><cell>0.5018</cell><cell>0.0</cell><cell>MOTS</cell><cell>NSGA-II</cell></row><row><cell></cell><cell>5000</cell><cell>hyp</cell><cell>0.0</cell><cell>0.2197</cell><cell>0.0</cell><cell>PRMOTS</cell><cell>NSGA-II</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.0</cell><cell>0.0527</cell><cell>0.0</cell><cell>PRMOTS</cell><cell>NSGA-II</cell></row><row><cell></cell><cell>10,000</cell><cell>hyp</cell><cell>1.0</cell><cell>0.3739</cell><cell>1.0</cell><cell>PRMOTS</cell><cell>PRMOTS</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>1.0</cell><cell>0.6400</cell><cell>1.0</cell><cell>MOTS</cell><cell>MOTS</cell></row><row><cell>ZDT6</cell><cell>1000</cell><cell>hyp</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0012</cell><cell>PRMOTS</cell><cell>NSGA-II</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.6985</cell><cell>0.0015</cell><cell>0.9997</cell><cell>PRMOTS</cell><cell>PRMOTS</cell></row><row><cell></cell><cell>5000</cell><cell>hyp</cell><cell>0.0</cell><cell>0.0003</cell><cell>0.0</cell><cell>PRMOTS</cell><cell>NSGA-II</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.0</cell><cell>0.0002</cell><cell>0.0</cell><cell>PRMOTS</cell><cell>NSGA-II</cell></row><row><cell></cell><cell>10,000</cell><cell>hyp</cell><cell>0.0</cell><cell>0.3609</cell><cell>0.0</cell><cell>PRMOTS</cell><cell>NSGA-II</cell></row><row><cell></cell><cell></cell><cell>eps</cell><cell>0.0</cell><cell>0.6460</cell><cell>0.0</cell><cell>MOTS</cell><cell>NSGA-II</cell></row></table><note><p>Algorithm A = MOTS, B = NSGA-II, C = PRMOTS.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>D.M. Jaeggi et al. / European Journal of Operational Research 185 (2008) 1192-1212</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research is supported by the UK Engineering and Physical Sciences Research Council (EPSRC) under grant number GR/R64100/01. The authors would also like to thank Prof. Bill Dawes for his support and encouragement, and the anonymous reviewers for their helpful comments on the first version of this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Parallel GRASP with path-relinking for job shop scheduling</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Aiex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Binato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G C</forename><surname>Resende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Parallel Computing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="393" to="430" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A taboo search based approach to find the Pareto optimal set in multiple objective optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Baykasoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Owen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gindy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering Optimization</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="731" to="748" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">PISA -a platform and programming language independent interface for search algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bleuler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laumanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Multi-Criterion Optimization (EMO 2003)</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Fonseca</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Fleming</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003. 2003</date>
			<biblScope unit="volume">2632</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">MOAMP -a generic multi-objective metaheuristic using an adaptive memory</title>
		<author>
			<persName><forename type="first">R</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gandibleux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Molina</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>University of Valenciennes</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multiobjective process design in multi-purpose batch plants using a Tabu Search optimization algorithm</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cavin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hungerbuehler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and Chemical Engineering</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="393" to="430" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Tabu Search method for the optimisation of fluid power circuits</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Tilley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IMechE Journal of Systems and Control</title>
		<imprint>
			<biblScope unit="volume">212</biblScope>
			<biblScope unit="page" from="373" to="381" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Conover</surname></persName>
		</author>
		<title level="m">Practical Nonparametric Statistics</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>third ed.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Multi-Objective Optimization using Evolutionary Algorithms</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>John Wiley</publisher>
			<pubPlace>Chichester</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A fast and elitist multiobjective genetic algorithm: NSGA-II</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Meyarivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="182" to="197" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hybrid genetic algorithms and artificial neural networks for complex design optimization in CFD</title>
		<author>
			<persName><forename type="first">R</forename><surname>Duvigneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Visonneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal for Numerical Methods in Fluids</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="1257" to="1278" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On the performance assessment and comparison of stochastic multiobjective optimizers</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Problem Solving from Nature -PPSN IV</title>
		<editor>
			<persName><forename type="first">H.-M</forename><surname>Voigt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Ebeling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Rechenberg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H.-P</forename><surname>Schwefel</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1996">1996. 1996</date>
			<biblScope unit="volume">1141</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A tutorial on the performance assessment of stochastic multiobjective optimizers, An invited talk presented by J. Knowles at EMO</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
			<pubPlace>Guanajuato, Mexico</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Automated optimization of supersonic missile performance taking into account design uncertainties</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gaiddon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Greard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Knight</surname></persName>
		</author>
		<idno>AIAA- 2003-3879</idno>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>AIAA</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</author>
		<title level="m">Scatter search and path relinking</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Corne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>New Ideas in Optimization</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laguna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tabu</forename><surname>Search</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Hansen</surname></persName>
		</author>
		<title level="m">Tabu search for multiobjective optimization: MOTS, in: MCDM</title>
		<meeting><address><addrLine>Cape Town, South Africa</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The design optimisation of turbomachinery blade rows</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Harvey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
		<respStmt>
			<orgName>Cambridge University, Engineering Department</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Direct search solution of numerical and statistical problems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hooke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Jeeves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="212" to="229" />
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multi-objective parallel Tabu Search</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Jaeggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Asselin-Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Parks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kipouros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Clarkson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Problem Solving from Nature -PPSN VIII</title>
		<editor>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Burke</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-A</forename><surname>Lozano</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Smith</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Merelo-Guervos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Bullinaria</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Rowe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Tino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Kaban</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H-P</forename><surname>Schwefel</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="volume">3242</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A multi-objective tabu search algorithm for constrained optimisation problems</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Jaeggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Parks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kipouros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Clarkson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Multi-Criterion Optimization (EMO 2005)</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Coello Coello</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Herna ´ndez Aguirre</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="volume">3410</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A perspective on computational algorithms for aerodynamic analysis and design</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jameson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Progress in Aerospace Sciences</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="197" to="243" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multi-objective meta-heuristics: An overview of the current state-of-theart</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Mirrazavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tamiz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Kellar</surname></persName>
		</author>
		<title level="m">Geometry modelling in computational fluid dynamics and design optimisation</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
		<respStmt>
			<orgName>Cambridge University, Engineering Department</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multi-objective optimisation of turbomachinery blades using tabu search</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kipouros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Jaeggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">N</forename><surname>Dawes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Parks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Savill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Multi-Criterion Optimization (EMO 2005)</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Coello Coello</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Herna ´ndez Aguirre</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="volume">3410</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A hybrid algorithm with on-line landscape approximation for expensive multi-objective optimization problems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><surname>Parego</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="66" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Approximating the nondominated front using the Pareto archived evolution strategy</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Corne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">New ideas in applying scatter search to multiobjective optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Nebro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Luna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Multi-Criterion Optimization (EMO 2005)</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Coello Coello</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Herna ´ndez Aguirre</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="volume">3410</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On test functions for evolutionary multi-objective optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Okabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Olhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sendhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-A</forename><surname>Lozano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Merelo-Guervos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bullinaria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kaban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Problem Solving from Nature -PPSN VIII</title>
		<editor>
			<persName><forename type="first">H-P</forename><surname>Schwefel</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="volume">3242</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">R: A language and environment for statistical computing</title>
		<author>
			<orgName type="collaboration">R Development Core Team</orgName>
		</author>
	</analytic>
	<monogr>
		<title level="m">R Foundation for Statistical Computing</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A simulated annealing algorithm for multiobjective optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Suppapitnarm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Seffen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Parks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Clarkson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering Optimization</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="59" to="85" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multiobjective optimization using evolutionary algorithms -a comparative case study</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Problem Solving from Nature -PPSN V</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Ebeling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Rechenberg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H.-P</forename><surname>Schwefel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H.-M</forename><surname>Voigt</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1998">1998. 1998</date>
			<biblScope unit="volume">2632</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Performance assessment of multiobjective optimizers: An analysis and review</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laumanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Grunert Da Fonseca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="117" to="132" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
