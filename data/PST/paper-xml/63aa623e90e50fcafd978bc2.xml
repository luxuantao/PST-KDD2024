<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Large Language Models Encode Clinical Knowledge</title>
				<funder>
					<orgName type="full">National Library of Medicine</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-12-26">26 Dec 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Karan</forename><surname>Singhal</surname></persName>
							<email>karansinghal@google.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shekoofeh</forename><surname>Azizi</surname></persName>
							<email>shekazizi@google.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tao</forename><surname>Tu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">S</forename><surname>Sara Mahdavi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hyung</forename><surname>Won</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nathan</forename><surname>Scales</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ajay</forename><surname>Tanwani</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Heather</forename><surname>Cole-Lewis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stephen</forename><surname>Pfohl</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Perry</forename><surname>Payne</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martin</forename><surname>Seneviratne</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Gamble</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chris</forename><surname>Kelly</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nathaneal</forename><surname>Sch?rli</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Philip</forename><surname>Mansfield</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Blaise</forename><surname>Ag?era Y Arcas</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dale</forename><surname>Webster</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yossi</forename><surname>Matias</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Katherine</forename><surname>Chou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Juraj</forename><surname>Gottweis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nenad</forename><surname>Tomasev</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">DeepMind</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yun</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alvin</forename><surname>Rajkomar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joelle</forename><surname>Barral</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><surname>Semturs</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alan</forename><surname>Karthikesalingam</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vivek</forename><surname>Natarajan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">PubMedQA MultiMedQA MedQA</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Large Language Models Encode Clinical Knowledge</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-12-26">26 Dec 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2212.13138v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large language models (LLMs) have demonstrated impressive capabilities in natural language understanding and generation, but the quality bar for medical and clinical applications is high. Today, attempts to assess models' clinical knowledge typically rely on automated evaluations on limited benchmarks. There is no standard to evaluate model predictions and reasoning across a breadth of tasks. To address this, we present MultiMedQA, a benchmark combining six existing open question answering datasets spanning professional medical exams, research, and consumer queries; and HealthSearchQA, a new free-response dataset of medical questions searched online. We propose a framework for human evaluation of model answers along multiple axes including factuality, precision, possible harm, and bias. In addition, we evaluate PaLM (a 540-billion parameter LLM) and its instruction-tuned variant, Flan-PaLM, on MultiMedQA. Using a combination of prompting strategies, Flan-PaLM achieves state-of-the-art accuracy on every MultiMedQA multiple-choice dataset (MedQA, MedMCQA, PubMedQA, MMLU clinical topics), including 67.6% accuracy on MedQA (US Medical License Exam questions), surpassing prior state-of-the-art by over 17%. However, human evaluation reveals key gaps in Flan-PaLM responses. To resolve this we introduce instruction prompt tuning, a parameter-efficient approach for aligning LLMs to new domains using a few exemplars. The resulting model, Med-PaLM, performs encouragingly, but remains inferior to clinicians. We show that comprehension, recall of knowledge, and medical reasoning improve with model scale and instruction prompt tuning, suggesting the potential utility of LLMs in medicine. Our human evaluations reveal important limitations of today's models, reinforcing the importance of both evaluation frameworks and method development in creating safe, helpful LLM models for clinical applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Medicine is a humane endeavor where language enables key interactions for and between clinicians, researchers, and patients. Yet, today's AI models for applications in medicine and healthcare have largely failed to fully utilize language. These models, while useful, are predominantly single-task systems (e.g., classification, regression, segmentation), lacking expressivity and interactive capabilities <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b80">81,</ref><ref type="bibr" target="#b96">97]</ref>. As a result, there is a discordance between what today's models can do and what may be expected of them in real-world clinical workflows <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b73">74]</ref>.</p><p>Recent advances in large language models (LLMs) offer an opportunity to rethink AI systems, with language as a tool for mediating human-AI interaction. LLMs are "foundation models" <ref type="bibr" target="#b9">[10]</ref>, large pre-trained AI systems that can be repurposed with minimal effort across numerous domains and diverse tasks. These expressive and interactive models offer great promise in their ability to learn generally useful representations from the knowledge encoded in medical corpora, at scale. There are several exciting potential applications of such models in medicine, including knowledge retrieval, clinical decision support, summarisation of key findings, questions reveal key gaps. To resolve this, we propose instruction prompt tuning, a data-and parameterefficient alignment technique, to further adapt Flan-PaLM to the medical domain. The resulting model, Med-PaLM, performs encouragingly on the axes of our pilot human evaluation framework. For example, a panel of clinicians judged only 61.9% of Flan-PaLM long-form answers to be aligned with scientific consensus, compared to 92.6% for Med-PaLM answers, on par with clinician-generated answers (92.9%). Similarly, 29.7% of Flan-PaLM answers were rated as potentially leading to harmful outcomes, in contrast with 5.8% for Med-PaLM, comparable with clinician-generated answers (6.5%).</p><p>While these results are promising, the medical domain is complex. Further evaluations are necessary, particularly along the dimensions of fairness, equity, and bias. Our work demonstrates that many limitations must be overcome before such models become viable for use in clinical applications. We outline some key limitations and directions of future research in our study.</p><p>Our key contributions are summarized below:</p><p>? Approaches for evaluation of LLMs in medical question answering -Curation of HealthSearchQA and MultiMedQA We introduce HealthSearchQA, a dataset of 3375 commonly searched consumer medical questions. We present this dataset alongside six other existing open datasets for medical question answering, spanning medical exam, medical research, and consumer medical questions, as a diverse benchmark to assess the clinical knowledge and question answering capabilities of LLMs (see Section 3.1). -Pilot framework for human evaluation We pilot a framework for physician and lay user evaluation to assess multiple axes of LLM performance beyond accuracy on multiple-choice datasets. Our evaluation assesses answers for agreement with scientific and clinical consensus, likelihood and possible extent of harm, reading comprehension, recall of relevant clinical knowledge, manipulation of knowledge via valid reasoning, completeness of responses, potential for bias, relevance, and helpfulness (see Section 3.2).</p><p>? State-of-the-art results on medical question answering benchmarks On the MedQA, MedMCQA, PubMedQA and MMLU clinical topics datasets, FLAN-PaLM achieves SOTA performance via a combination of prompting strategies, surpassing several strong LLM baselines. Specifically, we reach 67.6% accuracy on MedQA (more than 17% above prior SOTA), 57.6% on MedMCQA, and 79.0% on PubMedQA (see Section 4).</p><p>? Instruction prompt tuning to align LLMs to the medical domain We introduce instruction prompt tuning, a simple, data-and parameter-efficient technique for aligning LLMs to the safety-critical medical domain (see <ref type="bibr">Section 3.3.3)</ref>. We leverage this to build Med-PaLM, an instruction prompt-tuned version of Flan-PaLM specialized for the medical domain. Our human evaluation framework reveals limitations of Flan-PaLM in scientific grounding, harm, and bias. However, Med-PaLM significantly reduces the gap (or even compares favorably) to clinicians on several of these axes, according to both clinicians and lay users (see Section 4.5).</p><p>? Key limitations of LLMs revealed through our human evaluation While our results demonstrate the potential of LLMs in medicine, they also suggest several critical improvements are necessary in order to make these models viable for real-world clinical applications. We outline future research directions and mitigation strategies to address these challenges (see Section 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Large language models (LLMs) Over the past few years, LLMs have shown impressive performance on natural language processing (NLP) tasks <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b88">89,</ref><ref type="bibr" target="#b90">91,</ref><ref type="bibr" target="#b98">99]</ref>. They owe their success to scaling up the training of transformer-based models <ref type="bibr" target="#b83">[84]</ref>. It has been shown that model performance and data-efficiency scales with model size and dataset size <ref type="bibr" target="#b36">[37]</ref>. LLMs are often trained using self-supervision on large scale, using general-purpose text corpi such as Wikipedia and BooksCorpus. They have demonstrated promising results across a wide range of tasks, including tasks that require specialized scientific knowledge and reasoning <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b28">29]</ref>. Perhaps the most interesting aspect of these LLMs is their in-context few-shot abilities, which adapt these models to diverse tasks without gradient-based parameter updates <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b88">89]</ref>. This allows them to rapidly generalize to unseen tasks and even exhibit apparent reasoning abilities with appropriate prompting strategies <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b78">79,</ref><ref type="bibr" target="#b90">91]</ref>.</p><p>Several studies have shown that LLMs have the capacity to act as implicit knowledge bases <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b78">79]</ref>. However, there is a significant risk of these models producing hallucinations, amplifying social biases present in their training data, and displaying deficiencies in their reasoning abilities. To examine the current limitations of LLMs and to quantify the large gap between human and LLM language capabilities, BIG-bench was introduced as a community-wide initiative to benchmark on tasks that were believed at time of publication to be beyond the capabilities of current language models <ref type="bibr" target="#b77">[78]</ref>.</p><p>LLMs for science and biomedicine Recent studies, such as SciBERT <ref type="bibr" target="#b4">[5]</ref>, BioNLP <ref type="bibr" target="#b45">[46]</ref>, BioMegatron <ref type="bibr" target="#b75">[76]</ref>,</p><p>BioBERT <ref type="bibr" target="#b43">[44]</ref>, PubMedBERT <ref type="bibr" target="#b24">[25]</ref>, DARE <ref type="bibr" target="#b65">[66]</ref>, ScholarBERT <ref type="bibr" target="#b30">[31]</ref>, and BioGPT <ref type="bibr" target="#b55">[56]</ref>, have demonstrated the effectiveness of using curated scientific and biomedical corpora for both discriminative and generative language modeling. These models, although promising, are typically small in scale and scope compared to LLMs such as GPT-3 <ref type="bibr" target="#b11">[12]</ref> and PaLM <ref type="bibr" target="#b13">[14]</ref>. While the medical domain is challenging, specific proposals for LLMs have already included examples as varied as augmenting non-critical clinical assessments to summarisation of complex medical communications <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b74">75]</ref>.</p><p>The closest precedents to our work are Taylor et al. <ref type="bibr" target="#b78">[79]</ref>, who introduced a LLM for science named Galactica, and Li?vin et al. <ref type="bibr" target="#b49">[50]</ref>, who studied the reasoning capability of LLMs in the medical question answering context. In particular, Li?vin et al. <ref type="bibr" target="#b49">[50]</ref> used Instruct GPT-3, an instruction-tuned LLM <ref type="bibr" target="#b62">[63]</ref>, and applied chain-of-thought prompting <ref type="bibr" target="#b90">[91]</ref> on top to improve the results on the MedQA, MedMCQA, and PubMedQA datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>Here we describe in detail:</p><p>? Datasets: the MultiMedQA benchmark for assessment of LLMs in medical question answering.</p><p>? Framework for human evaluation: a rating framework for evaluation of model (and clinician) answers by clinicians and laypeople. ? Modeling: Large language models (LLMs) and the methods used to align them to requirements of the medical domain in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>To assess the potential of LLMs in medicine, we focused on medical question answering. Answering medical questions requires reading comprehension skills, ability to accurately recall medical knowledge, and manipulation of expert knowledge. There are several existing medical question answering datasets for research. These include datasets that assess professional medical knowledge such as medical exam questions <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b63">64]</ref>, questions that require medical research comprehension skills <ref type="bibr" target="#b33">[34]</ref>, and questions that require the ability to assess user intent and provide helpful answers to their medical information needs <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>.</p><p>We acknowledge that medical knowledge is vast in both quantity and quality. Existing benchmarks are inherently limited and only provide partial coverage of the space of medical knowledge. Nonetheless, bringing together a number of different datasets for medical question answering enables deeper evaluation of LLM knowledge than multiple-choice accuracy or natural language generation metrics such as BLEU. The datasets we grouped together probe different abilities -some are multiple-choice questions while others require long-form answers; some are open domain (where questions are answered without limiting available information to a pre-specified source) while others are closed domain (where questions are answered by retrieving content from associated reference text) and come from different sources. There has been extensive activity in the field of medical question answering over recent years and we refer to <ref type="bibr" target="#b32">[33]</ref> for a comprehensive summary of medical question answering datasets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">MultiMedQA -A benchmark for medical question answering</head><p>MultiMedQA includes multiple-choice question answering datasets, datasets requiring longer-form answers to questions from medical professionals, and datasets requiring longer-form answers to questions that might be asked by non-professionals. These include the MedQA <ref type="bibr" target="#b32">[33]</ref>, MedMCQA <ref type="bibr" target="#b63">[64]</ref>, PubMedQA <ref type="bibr" target="#b33">[34]</ref>, LiveQA <ref type="bibr" target="#b0">[1]</ref>, MedicationQA <ref type="bibr" target="#b1">[2]</ref> and MMLU clinical topics <ref type="bibr" target="#b28">[29]</ref> datasets. We further augmented MultiMedQA with a new dataset of curated commonly searched health queries: HealthSearchQA. All the datasets are English-language and we describe them in detail below.</p><p>These datasets vary along the following axes:</p><p>? Format: multiple-choice vs. long-form answer questions ? Capabilities tested: e.g., assessing the recall of medical facts in isolation vs. assessing medical reasoning capabilities in addition to recall of facts ? Domain: open domain vs. closed domain questions ? Question source: from professional medical exams, medical research, or consumers seeking medical information ? Labels and metadata: presence of labels or explanations and their sources While MedMCQA, PubMedQA, LiveQA, and MedicationQA provide reference long-form answers or explanations, we do not use them in this work. Firstly, the reference answers are not coming from consistent sources across the different datasets. Answers often came from automated tools or non-clinicians such as librarians. The construction of the reference answers and explanations in these pioneering datasets was not optimized for holistic or comprehensive assessments of long-answer quality, which renders them suboptimal for use as a "ground truth" against which to assess LLMs using automated natural language metrics such as BLEU. To alleviate this, as discussed in Section 4.5, we obtained a standardized set of responses from qualified clinicians to a subset of the questions in the benchmark. Secondly, given the safety-critical requirements of the medical domain, we believe it is important to move beyond automated measures of long-form answer generation quality using metrics such as BLEU to those involving more nuanced human evaluation frameworks such as the one proposed in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MedQA (USMLE)</head><p>The MedQA dataset <ref type="bibr" target="#b32">[33]</ref> consists of US Medical License Exam (USMLE) style questions, which were obtained with a choice of 4 or 5 possible answers from the National Medical Board Examination in the USA. The development set consists of 11450 questions and the test set has 1273 questions.</p><p>MedQA (2021) <ref type="bibr" target="#b32">[33]</ref> Format: Q + A, multiple choice, open domain Size (Dev/Test): 11450 / 1273 Question: A 65-year-old man with hypertension comes to the physician for a routine health maintenance examination. Current medications include atenolol, lisinopril, and atorvastatin. His pulse is 86/min, respirations are 18/min, and blood pressure is 145/95 mm Hg. Cardiac examination reveals end diastolic murmur. Which of the following is the most likely cause of this physical examination? Answer: (A) Decreased compliance of the left ventricle (B) Myxomatous degeneration of the mitral valve (C) Inflammation of the pericardium (D) Dilation of the aortic root (E) Thickening of the mitral valve leaflets MedMCQA The MedMCQA dataset consists of more than 194k 4-option multiple-choice questions from Indian medical entrance examinations (AIIMS/NEET) <ref type="bibr" target="#b63">[64]</ref>. This dataset covers 2.4k healthcare topics and 21 medical subjects. The development set is substantial, with over 187k questions.</p><p>MedMCQA (2022) <ref type="bibr" target="#b63">[64]</ref> Format: Q + A, multiple choice, open domain Size (Dev/Test): 187000 / 6100 Question: Which of the following ultrasound findings has the highest association with aneuploidy? Answer: (A) Choroid plexus cyst (B) Nuchal translucency (C) Cystic hygroma (D) Single umbilical artery Explanation: All the above mentioned are ultrasound findings associated with increased risk of aneuploidy although the highest association is seen with cystic hygroma. Nuchal translucency and cystic hygroma are both measured in the first trimester. Trisomy 21 is the most common aneuploidy associated with increased NT and cystic hygroma while monosomy X presents as second-trimester hygroma.</p><p>PubMedQA The PubMedQA dataset <ref type="bibr" target="#b33">[34]</ref> consists of 1k expert labeled question answer pairs where the task is to produce a yes/no/maybe multiple-choice answer given a question together with a PubMed abstract as context. While the MedQA and MedMCQA datasets are open domain question answering tasks, the PubMedQA task is closed domain, in that it requires answer inference from the supporting PubMed abstract context.</p><p>PubMedQA (2019) <ref type="bibr" target="#b33">[34]</ref> Format: Q + A + context, multiple choice, closed domain Size (Dev/Test): 500 / 500 Question: Double balloon enteroscopy: is it efficacious and safe in a community setting? Context: From March 2007 to January 2011, 88 DBE procedures were performed on 66 patients. Indications included evaluation anemia/gastrointestinal bleed, small bowel IBD and dilation of strictures. Video-capsule endoscopy (VCE) was used prior to DBE in 43 of the 66 patients prior to DBE evaluation. The mean age was 62 years. Thirty-two patients were female, 15 were African-American; 44 antegrade and 44 retrograde DBEs were performed. The mean time per antegrade DBE was 107.4 ? 30.0 minutes with a distance of 318.4 ? 152.9 cm reached past the pylorus. The mean time per lower DBE was 100.7 ? 27.3 minutes with 168.9 ? 109.1 cm meters past the ileocecal valve reached. Endoscopic therapy in the form of electrocautery to ablate bleeding sources was performed in 20 patients (30.3%), biopsy in 17 patients (25.8%) and dilation of Crohn's-related small bowel strictures in 4 (6.1%). 43 VCEs with pathology noted were performed prior to DBE, with findings endoscopically confirmed in 32 cases (74.4%). In 3 cases the DBE showed findings not noted on VCE. Answer: Yes Long Answer: DBE appears to be equally safe and effective when performed in the community setting as compared to a tertiary referral center with a comparable yield, efficacy, and complication rate. LiveQA The LiveQA dataset <ref type="bibr" target="#b0">[1]</ref> was curated as part of the Text Retrieval Challenge (TREC) 2017. The dataset consists of medical questions submitted by people to the National Library of Medicine (NLM). The dataset also consists of manually collected reference answers from trusted sources such as the National Institute of Health (NIH) website.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Medical Genetics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Size</head><p>LiveQA (2017) <ref type="bibr" target="#b0">[1]</ref> Format: Q + long answers, free text response, open domain Size (Dev/Test): 634/104 Question: Could second hand smoke contribute to or cause early AMD? Long Answer: Smoking increases a person's chances of developing AMD by two to five fold. Because the retina has a high rate of oxygen consumption, anything that affects oxygen delivery to the retina may affect vision. Smoking causes oxidative damage, which may contribute to the development and progression of this disease. Learn more about why smoking damages the retina, and explore a number of steps you can take to protect your vision.</p><p>MedicationQA The MedicationQA dataset <ref type="bibr" target="#b1">[2]</ref> consists of commonly asked consumer questions about medications. In addition to the question, the dataset contains annotations corresponding to drug focus and interactions. Similar to LiveQA, we evaluate models' ability to produce long form answers to the questions in the test set.</p><p>MedicationQA (2017) <ref type="bibr" target="#b1">[2]</ref> Format: Q + long answers, free text response, open domain Size (Dev/Test): NA/674 Question: Question: how does valium affect the brain? Focus (Drug): Valium Question Type: Action Long Answer: Diazepam is a benzodiazepine that exerts anxiolytic, sedative, muscle-relaxant, anticonvulsant and amnestic effects. Most of these effects are thought to result from a facilitation of the action of gamma aminobutyric acid (GABA), an inhibitory neurotransmitter in the central nervous system. Section Title: CLINICAL PHARMACOLOGY URL: https://dailymed.nlm.nih.gov/dailymed/drugInfo.cfm?setid=554baee5-b171-4452-a50a-41a0946f956c</p><p>HealthSearchQA We curated our own additional dataset consisting of 3375 commonly searched consumer questions, referred to as "HealthSearchQA". The dataset was curated using seed medical conditions and their associated symptoms. We used the seed data to retrieve publicly-available commonly searched questions generated by a search engine, which were displayed to all users entering the seed terms. We publish the dataset as an open benchmark for consumer medical question answering and hope this will be a useful resource for the community, as a dataset reflecting real-world consumer concerns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HealthSearchQA (Ours)</head><p>Format: Q only, free text response, open domain Size: 3375 Question: How serious is atrial fibrillation? Question: What kind of cough comes with Covid? Question: Is blood in phlegm serious?</p><p>While MultiMedQA allows us to probe the medical question answering capabilities of LLMs along multiple axes, we acknowledge that it is not exhaustive. We plan to expand the benchmark to other relevant datasets, such as those probing question answering ability from electronic medical records <ref type="bibr" target="#b64">[65]</ref> or those requiring pre-clinical biomedical knowledge <ref type="bibr" target="#b82">[83]</ref>, in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Framework for human evaluation</head><p>Here we describe our proposed framework for human evaluation of long-form answers to medical questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Clinician evaluation</head><p>While objective accuracy metrics on multiple-choice questions are a robust measure of model performance, they omit several important details. To more deeply assess the generative outputs of LLMs in open-ended Table <ref type="table">2</ref> | Summary of the different axes along which clinicians evaluate the answers in our consumer medical question answering datasets. These include agreement with scientific consensus, possibility and likelihood of harm, evidence of comprehension, reasoning and retrieval ability, presence of inappropriate, incorrect or missing content and possibility of bias in the answer. We use a pool of clinicians to evaluate the quality of model and human-generated answers along these axes. question answering for medical topics, we developed a pilot framework for human evaluation of long-form model answers to consumer medical questions in the LiveQA, MedicationQA and HealthSearchQA datasets.</p><p>The pilot framework was inspired by approaches published in a similar domain by Feng et al. <ref type="bibr" target="#b21">[22]</ref> to examine the strengths and weaknesses of LLM generations in clinical settings. We used focus groups and interviews with clinicians based in the UK, US and India to identify additional axes of evaluation <ref type="bibr" target="#b59">[60]</ref> and expanded the framework items to address notions of agreement with scientific consensus, possibility and likelihood of harm, completeness and missingness of answers and possibility of bias. Alignment with scientific consensus was measured by asking raters whether the output of the model was aligned with a prevailing scientific consensus (for example in the form of well-accepted clinical practice guidelines), opposed to a scientific consensus; or whether no clear scientific consensus exists regarding the question. Harm is a complex concept that can be evaluated along several dimensions (e.g. physical health, mental health, moral, financial and many others). When answering this question, raters were asked to focus solely on physical/mental health-related harms, and evaluated both severity (in a format inspired by the AHRQ common formats for harm <ref type="bibr" target="#b92">[93]</ref>) and likelihood, under the assumption that a consumer or physician based on the content of the answer might take actions. Bias was assessed broadly by raters considering if the answer contained information that would be inapplicable or inaccurate to a specific patient demographic. The questions asked in the evaluation are summarized in Table <ref type="table">2</ref> Our framework items' form, wording and response-scale points were refined by undertaking further interviews with triplicate assessments of 25 question-answer tuples per dataset by three qualified clinicians. Instructions for the clinicians were written including indicative examples of ratings for questions, and iterated until the clinicians' rating approaches converged to indicate the instructions were usable. Once the guidelines had converged a larger set of question-answer tuples from the consumer medical questions datasets were evaluated by single-ratings performed by one of nine clinicians based in the UK, USA or India and qualified for practice Table <ref type="table">3</ref> | Summary of the different axes along which lay users evaluate the utility of answers in our consumer medical question answering datasets. We use a pool of 5 non-expert lay users to evaluate the quality of model and human-generated answers along these axes.</p><p>Task Axis Question 1</p><p>Answer captures user intent How well does the answer address the intent of the question? 2</p><p>Helpfulness of the answer How helpful is this answer to the user? (for example, does it enable them to draw a conclusion or help clarify next steps?)</p><p>in their respective countries, with specialist experience including pediatrics, surgery, internal medicine and primary care.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Lay user (non-expert) evaluation</head><p>In order to assess the helpfulness and utility of the answers to the consumer medical questions we undertook an additional lay user (non-expert) evaluation. This was performed by five raters without a medical background, all of whom were based in India. The goal of this exercise was to assess how well the answer addressed the perceived intent underlying the question and how helpful and actionable it was. The questions asked in the evaluation are summarized in Table <ref type="table">3</ref> 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.3 Modeling</head><p>In this section, we detail large language models (LLMs) and the techniques used to align them with the requirements of the medical domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Models</head><p>We build on the PaLM and Flan-PaLM family of LLMs in this study.</p><p>PaLM Pathways Language Model (PaLM), introduced by <ref type="bibr" target="#b13">[14]</ref> is a densely-activated decoder-only transformer language model trained using Pathways <ref type="bibr" target="#b3">[4]</ref>, a large-scale ML accelerator orchestration system that enables highly efficient training across TPU pods. The PaLM training corpus consists of 780 billion tokens representing a mixture of webpages, Wikipedia articles, source code, social media conversations, news articles and books. All three PaLM model variants are trained for exactly one epoch of the training data. We refer to <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b79">80]</ref> for more details on the training corpus. At the time of release, PaLM 540B achieved breakthrough performance, outperforming fine tuned state of the art models on a suite of multi-step reasoning tasks and exceeding average human performance on BIG-bench <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b77">78]</ref>.</p><p>Flan-PaLM In addition to the baseline PaLM models, we also considered the instruction-tuned counterpart introduced by <ref type="bibr" target="#b14">[15]</ref>. These models are trained using instruction tuning, i.e., finetuning the model on a collection of datasets in which each example is prefixed with some combination of instructions and/or few-shot exemplars.</p><p>In particular, Chung et al. <ref type="bibr" target="#b14">[15]</ref> demonstrated the effectiveness of scaling the number of tasks, model size and using chain-of-thought data <ref type="bibr" target="#b90">[91]</ref> as instructions. The Flan-PaLM model reached state of the art performance on several benchmarks such as MMLU, BBH, and TyDIQA <ref type="bibr" target="#b15">[16]</ref>. Across the suite of evaluation tasks considered in <ref type="bibr" target="#b14">[15]</ref>, Flan-PaLM outperformed baseline PaLM by an average of 9.4%, demonstrating the effectiveness of the instruction tuning approach.</p><p>In this study we considered both the PaLM and Flan-PaLM model variants at three different model sizes: 8B, 62B and 540B, with the largest model using 6144 TPUv4 chips for pretraining.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Aligning LLMs to the medical domain</head><p>General-purpose LLMs like PaLM <ref type="bibr" target="#b13">[14]</ref> and GPT-3 <ref type="bibr" target="#b11">[12]</ref> have reached state of the art performance on a wide variety of tasks on challenging benchmarks such as BIG-bench. However, given the safety critical nature of the medical domain, it is necessary to adapt and align the model with domain-specific data. Typical transfer learning and domain adaptation methods rely on end-to-end finetuning of the model with large amounts of in-domain data, an approach that is challenging here given the paucity of medical data. As such, in this study we focused on data-efficient alignment strategies building on prompting <ref type="bibr" target="#b11">[12]</ref> and prompt tuning <ref type="bibr" target="#b44">[45]</ref>.</p><p>Prompting strategies Brown et al. <ref type="bibr" target="#b11">[12]</ref> demonstrated that LLMs are strong few-shot learners, where fast in-context learning can be achieved through prompting strategies. Through a handful of demonstration examples encoded as prompt text in the input context, these models are able to generalize to new examples and new tasks without any gradient updates or finetuning. The remarkable success of in-context few-shot learning has spurred the development of many prompting strategies including scratchpad <ref type="bibr" target="#b60">[61]</ref>, chain-of-thought <ref type="bibr" target="#b90">[91]</ref>, and least-to-most prompting <ref type="bibr" target="#b99">[100]</ref>, especially for multi-step computation and reasoning problems such as math problems <ref type="bibr" target="#b16">[17]</ref>. In this study we focused on standard few-shot, chain-of-thought and self-consistency prompting as discussed below.</p><p>Few-shot prompting The standard few-shot prompting strategy was introduced by Brown et al. <ref type="bibr" target="#b11">[12]</ref>. Here, the prompt to the model is designed to include few-shot examples describing the task through text-based demonstrations. These demonstrations are typically encoded as input-output pairs. The number of examples is typically chosen depending on the number of tokens that can fit into the input context window of the model. After the prompt, the model is provided with an input and asked to generate the test-time prediction.</p><p>The zero-shot prompting counterpart typically only involves an instruction describing the task without any additional examples. Brown et al. <ref type="bibr" target="#b11">[12]</ref> observed that while zero-shot prompting scaled modestly with model size, performance with few-shot prompting increased more rapidly. Further, Wei et al. <ref type="bibr" target="#b89">[90]</ref> observed emergent abilities-that is, abilities which are non-existent in small models but rapidly improve above random performance beyond a certain model size in the prompting paradigm.</p><p>In this study we worked with a panel of qualified clinicians to identify the best demonstration examples and craft the few-shot prompts. Separate prompts were designed for each dataset as detailed in Section A.8.</p><p>The number of few-shot demonstrations varied depending on the dataset. Typically we used 5 input-output examples for the consumer medical question answering datasets, but reduced the number to 3 or fewer for PubMedQA given the need to also fit in the abstract context within the prompt text.</p><p>Chain-of-thought prompting Chain-of-thought (CoT), introduced by Wei et al. <ref type="bibr" target="#b90">[91]</ref>, involves augmenting each few-shot example in the prompt with a step-by-step breakdown and a coherent set of intermediate reasoning steps towards the final answer. The approach is designed to mimic the human thought process when solving problems that require multi-step computation and reasoning. Wei et al. <ref type="bibr" target="#b90">[91]</ref> demonstrated that CoT prompting can elicit reasoning abilities in sufficiently large language models and dramatically improve performance on tasks such as math problems <ref type="bibr" target="#b16">[17]</ref>. Further, the appearance of such CoT reasoning appears to be an emergent ability <ref type="bibr" target="#b89">[90]</ref> of LLMs. Lewkowycz et al. <ref type="bibr" target="#b46">[47]</ref> used CoT prompting as one of the key strategies in their work leading to breakthrough LLM performance on several STEM benchmarks.</p><p>Many of the medical questions explored in this study involve complex multi-step reasoning, making them a good fit for CoT prompting techniques. Together with clinicians, we crafted CoT prompts to provide clear demonstrations on how to reason and answer the given medical questions. Examples of such prompts are detailed in Section A.9.</p><p>Self-consistency prompting A straightforward strategy to improve the performance on the multiple-choice benchmarks is to prompt and sample multiple decoding outputs from the model. The final answer is the one with the majority (or plurality) vote. This idea was introduced by Wang et al. <ref type="bibr" target="#b87">[88]</ref> under the name of "self-consistency". The rationale behind this approach here is that for a domain such as medicine with complex reasoning paths, there might be multiple potential routes to the correct answer. Marginalizing out the reasoning paths can lead to the most consistent answer. The self-consistency prompting strategy led to particularly strong improvements in <ref type="bibr" target="#b46">[47]</ref>, and we adopted the same approach for our datasets with multiple-choice questions: MedQA, MedMCQA, PubMedQA and MMLU.</p><p>Prompt tuning Because LLMs have grown to hundreds of billions of parameters <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14]</ref>, finetuning them is extraordinarily computationally expensive. While the success of few-shot prompting has alleviated this issue to a large extent, many tasks would benefit further from gradient-based learning. Lester et al. <ref type="bibr" target="#b44">[45]</ref> introduced prompt tuning (in contrast to prompting / priming), a simple and computationally inexpensive You are a helpful medical knowledge assistant. Provide useful, complete, and scientifically-grounded answers to common consumer search queries about health.</p><p>Question: How do you treat skin redness?</p><p>Complete Answer: It depends on the cause of the skin redness. For example, if the cause is cellulitis, then antibiotics may be required. However, this might be be inappropriate for other causes of redness such as eczema. The first step should be to establish the cause of the redness, which may require seeing a doctor.</p><p>You are a helpful medical knowledge assistant. Provide useful, complete, and scientifically-grounded answers to consumer questions about medications.</p><p>Question: Why take simvastatin?</p><p>Complete Answer: Simvastatin is a medication that is used to lower cholesterol levels in the blood. Simvastatin is typically used to treat high cholesterol and to prevent heart disease, and to reduce the risk of heart attacks and strokes in those with the greatest risk of these happening (or re-occuring). It's used together with other steps like healthy lifestyle and diet, weight-loss, and exercise, and sometimes other medications. Simvastatin may also be used to decrease the amount of?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instruction Prompt Tuning</head><p>You are a helpful medical knowledge assistant. Provide useful, complete, and scientifically-grounded answers to consumer questions about medications.</p><p>Question: How can i split a 3mg or 4mg waefin pill so i can get a 2.5mg pill?</p><p>Complete Answer: You should not attempt to split a 3mg or 4mg warfarin pill to obtain a 2.5mg dose. If you are prescribed warfarin in a 2.5mg dose, it is important to talk to your doctor or pharmacist to obtain the correct pills, so that you can take the exact dose and frequency your medical team have prescribed. Warfarin is a type of medicine known as an anticoagulant, which means it makes your blood take longer to clot. The exact amount required to achieve the desired effect can vary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Med-PaLM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Flan-PaLM</head><p>Prompt parameters aligned with the medical domain method to adapt LLMs to specific downstream tasks, especially with limited data. The approach involves the learning of soft prompt vectors through backpropagation while keeping the rest of the LLM frozen, thus allowing easy reuse of a single model across tasks.</p><p>This use of soft prompts can be contrasted with the discrete "hard" text-based few-shot prompts popularized by LLMs such as GPT-3 <ref type="bibr" target="#b11">[12]</ref>. While prompt tuning can benefit from any number of labeled examples, typically only a handful of examples (e.g., tens) are required to achieve good performance. Further, Lester et al. <ref type="bibr" target="#b44">[45]</ref> demonstrated that prompt-tuned model performance becomes comparable with end-to-end finetuning at increased model scale. Other related approaches include prefix tuning <ref type="bibr" target="#b47">[48]</ref>, where prefix activation vectors are prepended to each layer of the LLM encoder and learned through backpropagation. Lester et al. <ref type="bibr" target="#b44">[45]</ref>'s prompt tuning can be thought of as a simplification of this idea, restricting the learnable parameters to only those representing a small number of tokens prepended to the input as a soft prompt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Instruction prompt tuning</head><p>Wei et al. <ref type="bibr" target="#b88">[89]</ref> and Chung et al. <ref type="bibr" target="#b14">[15]</ref> demonstrated the benefits of multi-task instruction finetuning: the Flan-PaLM model achieved state of the performance on several benchmarks such as BIG-bench <ref type="bibr" target="#b46">[47]</ref> and MMLU <ref type="bibr" target="#b28">[29]</ref>. In particular, Flan-PaLM demonstrated the benefits of using CoT data in fine-tuning, leading to robust improvements in tasks that required reasoning.</p><p>Given the strong performance of instruction tuning, we built primarily on the Flan-PALM model in this work. However, as discussed in Section 4.5, our human evaluation revealed key gaps in Flan-PaLM's performance on the consumer medical question answering datasets, even with few-shot prompting. To further align the model to the requirements of the safety-critical medical domain, we explored additional training specifically on medical data.</p><p>For this additional training, we used prompt tuning instead of full-model finetuning given compute and clinician data generation costs. Our approach effectively extends Flan-PaLM's principle of "learning to follow instructions" to the prompt tuning stage. Specifically, rather than using the soft prompt learned by prompt tuning as a replacement for a task-specific human-engineered prompt, we instead use the soft prompt as an initial prefix that is shared across multiple medical datasets, and which is followed by the relevant task-specific human-engineered prompt (consisting of instructions and/or few-shot exemplars, which may be chain-of-thought examples) along with the actual question and/or context.</p><p>We refer to this method of prompt tuning as "instruction prompt tuning". Instruction prompt tuning can thus be seen as a lightweight way (data-efficient, parameter-efficient, compute-efficient during both training and inference) of training a model to follow instructions in one or more domains. In our setting, instruction prompt tuning adapted LLMs to better follow the specific type of instructions used in the family of medical datasets that we target.</p><p>Given the combination of soft prompt with hard prompt, instruction prompt tuning can be considered a type of "hard-soft hybrid prompt tuning" <ref type="bibr" target="#b51">[52]</ref>, alongside existing techniques that insert hard anchor tokens into a soft prompt <ref type="bibr" target="#b52">[53]</ref>, insert learned soft tokens into a hard prompt <ref type="bibr" target="#b27">[28]</ref>, or use a learned soft prompt as a prefix for a short zero-shot hard prompt <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b95">96]</ref>. To the best of our knowledge, ours is the first published example of learning a soft prompt that is prefixed in front of a full hard prompt containing a mixture of instructions and few-shot exemplars.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Putting it all together: Med-PaLM</head><p>To adapt Flan-PaLM to the medical domain, we applied instruction prompt tuning on a small set of exemplars. These examples were effectively used to instruct the model to produce text generations more aligned with the requirements of the medical domain, with good examples of medical comprehension, recall of clinical knowledge, and reasoning on medical knowledge unlikely to lead to patient harm. Thus, curation of these examples was very important.</p><p>We randomly sampled examples from MultiMedQA free-response datasets (HealthSearchQA, MedicationQA, LiveQA) and asked a panel of five clinicians to provide exemplar answers. These clinicians were based in the US and UK with specialist experience in primary care, surgery, internal medicine, and pediatrics. Clinicians then filtered out questions / answer pairs that they decided were not good examples to instruct the model. This generally happened when clinicians felt like they could not produce an "ideal" model answer for a given question, e.g., if the information required to answer a question was not known. We were left with 40 examples across HealthSearchQA, MedicationQA, and LiveQA used for instruction prompt tuning training.</p><p>The resulting model, Med-PaLM, was evaluated on the consumer medical question answering datasets of MultiMedQA along with Flan-PaLM. Figure <ref type="figure" target="#fig_1">2</ref> gives an overview of our instruction prompt tuning approach for Med-PaLM. Further details on the hyperparameter optimization and model selection process can be found in Section A.1. The model card for Med-PaLM is provided in Section A.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>In this section, we first provide an overview of our key results as summarized in Figures <ref type="figure">3</ref> and<ref type="figure" target="#fig_2">4</ref>. Then, we present several ablations to help contextualize and interpret the results. PubMedGPT, and BioGPT <ref type="bibr" target="#b55">[56]</ref> the Galactica model <ref type="bibr" target="#b78">[79]</ref>.</p><p>Similarly on the PubMedQA dataset, our model achieved an accuracy of 79.0% outperforming the previous state of the art BioGPT model Luo et al. <ref type="bibr" target="#b55">[56]</ref> by 0.8%. The results are summarized in Figure <ref type="figure" target="#fig_1">2</ref> below. While this improvement may seem small compared to MedQA and MedMCQA datasets, the single rater human performance on PubMedQA is 78.0% <ref type="bibr" target="#b32">[33]</ref>, indicating that there may be an inherent ceiling to the maximum possible performance on this task.  <ref type="bibr" target="#b93">[94]</ref> 47.5 BioLinkBERT (340 M) <ref type="bibr" target="#b94">[95]</ref> 45.1 Galactica (120 B) <ref type="bibr" target="#b78">[79]</ref> 44.4 PubMedBERT (100 M) <ref type="bibr" target="#b24">[25]</ref> 38.1 GPT-Neo (2.7 B) <ref type="bibr" target="#b6">[7]</ref> 33.3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">State-of-the-art performance on MMLU clinical topics</head><p>The MMLU dataset contains multiple-choice questions from several clinical knowledge, medicine and biology related topics. These include anatomy, clinical knowledge, professional medicine, human genetics, college medicine and college biology. Flan-PaLM 540B achieved state of the art performance on all these subsets, outperforming strong LLMs like PaLM, Gopher, Chinchilla, BLOOM, OPT and Galactica. In particular, on the professional medicine and clinical knowledge subset, Flan-PaLM 540B achieved a SOTA accuracy of 83.5% and 84.0%. Figure <ref type="figure" target="#fig_2">4</ref> summarizes the results, providing comparisons with other LLMs where available <ref type="bibr" target="#b78">[79]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ablations</head><p>We performed several ablations on three of the multiple-choice datasets -MedQA, MedMCQA and PubMedQA -to better understand our results and identify the key components contributing to Flan-PaLM's performance. We present them in detail below:</p><p>Instruction tuning improves performance on medical question answering Across all model sizes, we observed that the instruction-tuned Flan-PaLM model outperformed the baseline PaLM model on all three datasets -MedQA, MedMCQA and PubMedQA. The models were few-shot prompted in these experiments using the prompt text detailed in A.   We have not yet completed a thorough analysis of the effect of instruction prompt tuning on multiple-choice accuracy; our analysis is of Flan-PaLM in this section, not Med-PaLM. Med-PaLM (instruction prompt-tuned Flan-PaLM) was developed to improve the long-form generation results of Flan-PaLM presented in Section 4.5 by better aligning the model to the medical domain. However, given the success of domain-agnostic instruction tuning for multiple-choice question answering, in-domain instruction prompt tuning appears promising, and we present a preliminary result in Section A.6.</p><p>Scaling improves performance on medical question answering A related observation from 5 was the strong performance improvements obtained from scaling the model from 8B to 62B and 540B. We observed approximately a 2x improvement in performance when scaling the model from 8B to 540B in both PaLM and Flan-PaLM. These improvements were more pronounced in the MedQA and MedMCQA datasets. In particular, for the Flan-PaLM model, the 540B variant outperformed the 62B variant by over 14% and the 8B variant by over 24%. Given these results and the strong performance of the Flan-PaLM 540B model, we built on this model for downstream experiments and ablations. The scaling plots are provided in Section A.4.</p><p>Chain-of-Thought (CoT) prompting 6 summarizes the results from using CoT prompting and provides a comparison with the few-shot prompting strategy using the Flan-PaLM 540B model. Somewhat unexpectedly, we did not observe improvements using CoT over the standard few-shot prompting strategy across the three multiple-choice datasets -MedQA, MedMCQA and PubMedQA. The CoT prompts used are summarized in Section A.9.  Self-consistency (SC) leads to strong improvement in multiple-choice performance Wang et al. <ref type="bibr" target="#b87">[88]</ref> showed that self-consistency prompting can help when CoT prompting hurts performance. They showed significant improvements on arithmetic and commonsense reasoning tasks. Taking their cue, we apply it to our datasets. We fixed the number of chain-of-thought answer explanation paths to 11 for each of the three datasets. We then marginalized over the different explanation paths to select the most consistent answer. Using this strategy, we observed significant improvements over the standard few-shot prompting strategy for the Flan-PaLM 540B model on the MedQA and MedMCQA datasets. In particular, for the MedQA dataset we observed a &gt;7% improvement with self-consistency. However, somewhat unexpectedly, self-consistency led to a drop in performance for the PubMedQA dataset. The results are summarized in Table <ref type="table" target="#tab_7">7</ref>.</p><p>We further provide some example responses from the Flan-PaLM 540B model for MedQA in Table <ref type="table" target="#tab_8">8</ref>.</p><p>Uncertainty and Selective Prediction LLMs are capable of long, coherent, and complex generations. However, they can also generate statements inconsistent with fact. In medical settings in particular, such failure modes need to be carefully vetted, and in real world applications, generations unlikely to be true should be withheld. Instead, we may want to defer to other information sources or experts when needed. One solution is therefore for LLMs to communicate uncertainty estimates along with their responses.</p><p>While uncertainty measures over LLM output sequences remains an open area of research <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b50">51]</ref>, here we explored a simple proxy as an initial approach to measuring the relationship between LLM uncertainty and statement accuracy. We created a selective prediction task <ref type="bibr" target="#b81">[82]</ref>, using the number of decodes matching a given answer from self-consistency as a measure of uncertainty and used it to withhold the answer if the model was not appropriately confident. We performed the experiment using 41 decodes from the Flan-PaLM 540B model with chain-of-thought prompting and self consistency. We observe in 5 that as the deferring fraction increases (i.e., with a higher "confidence" required to provide a prediction), the performance of the model on MedQA improves, reaching up to an accuracy of of 82.5% at a 0.45 deferring fraction. This suggests our measure of response uncertainty may be reasonable, and that LLMs seem to encode uncertainty about their knowledge in the medical domain. However, more research is needed beyond this preliminary analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Human evaluation results</head><p>We randomly selected 100 questions from HealthSearchQA, 20 questions from LiveQA, and 20 questions from MedicationQA as a smaller long-form answer benchmark for detailed human evaluation. These questions reflect real-world consumer queries for medical information. These selected questions were disjoint from those exemplars used for instruction prompt tuning to produce Med-PaLM.</p><p>We had a panel of clinicians generate expert reference answers to these questions. We then produced answers using Flan-PaLM and Med-PaLM (both 540B models). A few qualitative examples of these questions and the corresponding Med-PaLM responses are shown in Table <ref type="table" target="#tab_10">9</ref>. We had the three sets of answers evaluated by another panel of clinicians along the axes in Table <ref type="table">2</ref>, without revealing the source of answers. One clinician evaluated each answer. To reduce the impact of variation across clinicians on generalizability of our findings, our panel consisted of 9 clinicians (based in the US, UK, and India). We used the non-parametric bootstrap to estimate any significant variation in the results, where 100 bootstrap replicas were used to produce a distribution for each set and we used the 95% bootstrap percentile interval to assess variations. These results are described in detail below and in Section A.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scientific consensus:</head><p>We wished to understand how the answers related to current consensus in the clinical and scientific community. On the 140 questions evaluated in the study, we found that clinicians' answers were judged to be aligned with the scientific consensus in 92.9% of questions. On the other hand, Flan-PaLM was found to be in agreement with the scientific consensus in only 61.9% of answers. For other questions, answers were either opposed to consensus, or no consensus existed. This suggested that generic instruction tuning on its own was not sufficient to produce scientific and clinically grounded answers. However, we observed that 92.9% of Med-PaLM answers were judged to be in accordance with the scientific consensus, showcasing the strength of instruction prompt tuning as an alignment technique to produce scientifically grounded answers.</p><p>We note that since PaLM, Flan-PaLM, and Med-PaLM were trained using corpora of web documents, books, Wikipedia, code, natural language tasks, and medical tasks at a given point of time, one potential limitation of these models is that they can reflect the scientific consensus of the past instead of today. This was not a commonly observed failure mode for Med-PaLM today, but this motivates future work in continual learning of LLMs and retrieval from a continuously evolving corpus.  Clinicians were asked to identify whether the answer is aligned with the prevailing medical/scientific consensus; whether the answer was in opposition to consensus; or whether there is no medical/scientific consensus for how to answer that particular question (or whether it was not possible to answer this question). We observe that while the Flan-PaLM model answers are only found to be in agreement with the scientific consensus 61.9% of the time, this improves to 92.9% for Med-PaLM matching expert answers.</p><p>model as expressed through the answers generated by them. We asked a panel of clinicians to rate whether answers contained any (one or more example of) evidence of correct / incorrect medical reading comprehension, medical knowledge retrieval and medical reasoning capabilities, using the same approach as Feng et al. <ref type="bibr" target="#b21">[22]</ref>.</p><p>Correct and incorrect evidence were assessed in parallel because it is possible that a single long-form answer may contain evidence of both correct and incorrect comprehension, retrieval and reasoning.</p><p>We found that expert generated answers were again considerably superior to Flan-PaLM, though performance was improved by instruction prompt tuning for Med-PaLM. This trend was observed in all the six sub-questions used to evaluate in this axis. For example, with regard to evidence of correct retrieval of medical knowledge, we found that clinician answers scored 97.8% while Flan-PaLM only scored 76.3%. However, the instruction prompt-tuned Med-PaLM model scored 95.4%, reducing the inferiority of the model compared to clinicians.</p><p>Incorrect or missing content: The goal of this evaluation was to understand the completeness and correctness of the generated answers, by assessing whether the answer omits any information it should not, or whether the answer contained any content it should not. Where there was deemed to be missing or omitted content, the rater was asked whether that was of great or little potential clinical significance.</p><p>Again we observed that clinician-generated answers were superior to AI models. Clinician answers showed evidence of inappropriate/incorrect content in only 1.4% of the cases, compared to 16.1% for Flan-PaLM. Surprisingly, instruction prompt tuning seemed to further degrade performance, with 18.7% of the Med-PaLM answers judged to contain inappropriate or incorrect content.</p><p>On the other hand, we observed that instruction prompt tuning helped improve model performance in omission of important information. While Flan-PaLM answers were judged to miss important information 47.2% of the time, the number improved significantly for Med-PaLM with only 15.1% of the answers adjudged to have missing information, reducing the inferiority compared to clinicians whose answers were judged to have Night sweats are a common symptom that can be caused by a variety of underlying medical conditions. In most cases, night sweats are not a cause for concern and will resolve on their own. However, persistent night sweats can be a sign of a serious underlying medical condition. Some of the medical conditions that can cause night sweats include: infection, fever, anxiety, menopause, hyperthyroidism, and cancer. If you are experiencing persistent night sweats, it is important to see a doctor for evaluation to determine the cause and receive appropriate treatment. The doctor will review your medical history, perform a physical exam, and order tests to determine the cause of the night sweats.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How serious is hepatitis A?</head><p>Hepatitis A is a viral infection that affects the liver. It is usually caused by consuming food or water that has been contaminated with the hepatitis A virus. Hepatitis A can cause severe liver disease, but it usually does not cause long-term liver damage. Most people who get hepatitis A recover completely after a few weeks or months. In some cases, hepatitis A can cause death. The severity of hepatitis A can vary from person to person. Some people may have no symptoms at all, while others may have severe symptoms that require hospitalization. The severity of hepatitis A is often related to the person's age. Children and young adults usually have a mild infection that resolves on its own. Older adults and people with chronic liver disease are more likely to have severe hepatitis A infection.  <ref type="table" target="#tab_12">10</ref> suggesting that LLM answers may be able to complement and complete physician responses to patient queries in future use cases.</p><p>One potential explanation of these observations is that instruction prompt tuning teaches the Med-PaLM model to generate significantly more detailed answers than the Flan-PaLM model, reducing the omission of important information. However a longer answer also increases the risk of introducing incorrect content.</p><p>Possible extent and likelihood of harm: We sought to identify the severity and likelihood of potential harm based on acting upon the generated answers. We asked raters to assume that the output of models might lead to actions by either clinicians or consumers/patients, and estimate the possible severity and likelihood of physical/mental health-related harms that might result. We based the options for selection by raters in the AHRQ Common Formats Williams et al. <ref type="bibr" target="#b92">[93]</ref>, which presents options to assign severity of harm ranging from death, severe or life-threatening injury, moderate, mild or no harm. We acknowledge that this definition of harm is more typically used in the context of analyzing harms incurred during healthcare delivery and that even in such settings (where the context for harms occurring is known with considerably greater specificity) there is frequently substantial variation in physician estimation of harm severity <ref type="bibr" target="#b85">[86]</ref>. The validity of the AHRQ scale cannot therefore be assumed to extend to our context, where our rater outputs should be regarded as subjective estimates because our work was not grounded in a specific intended use and sociocultural context.</p><p>Despite the broad definition and subjectivity of ratings, we observed that instruction prompt tuning produced safer answers that reduced both estimated likelihood and severity. While 29.7% of the Flan-PaLM responses were judged as potentially leading to harm, this number dropped to 5.9% for Med-PaLM comparing on par with clinician-generated answers which were also judged as potentially harmful in 5.7% of the cases.</p><p>Similarly, on the likelihood of harm axes, instruction prompt tuning enabled Med-PaLM answers to match the expert generated answers.</p><p>Bias for medical demographics: The final axis along which we evaluated the answers was bias. The use of large language models for medical question answering has the potential for bias and fairness-related harms that contribute to health disparities. These harms derive from several sources, including the presence of patterns in training data that reflect disparities in health outcomes and access to care, the capability for medical question answering systems to reproduce racist misconceptions regarding the cause of racial health disparities <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b84">85]</ref>,  algorithmic design choices <ref type="bibr" target="#b31">[32]</ref>, and differences in behavior or performance of machine learning systems across populations and groups that introduce downstream harms when used to inform medical decision making <ref type="bibr" target="#b12">[13]</ref>.</p><p>Medical question answering systems also pose additional risks beyond those posed by the use of other AI applications in healthcare because they have potential to produce arbitrary outputs, have limited reasoning capability, and could potentially be used for a wide range of downstream use cases. We sought to understand whether the answer contained any information that is inaccurate or inapplicable for a particular demographic. Flan-PaLM answers were found to contain biased information in 7.9% of the cases. However, this number reduced to 0.8% for Med-PaLM, comparing favorably with experts whose answers were judged to contain evidence of bias in 1.4% of the cases.</p><p>Lay user assessment: Beyond expert evaluation, we also had a panel of five non-experts in the domain (laypeople without a medical background, based in India) assess the answers.  user's question intent in 90.8% of cases. This number improved to 94.0% for Med-PaLM, which was inferior to clinician-generated answers at 95.9%.</p><p>The lay evaluation consistently reproduced the benefits of instruction prompt tuning to produce answers that are helpful to users, while also demonstrating that there is still considerable work needed to approximate the quality of outputs provided by human clinicians.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Our results suggest that strong performance on medical question answering may be an emergent ability <ref type="bibr" target="#b89">[90]</ref> of LLMs combined with effective instruction prompt tuning.</p><p>Firstly, we observed strong scaling performance with accuracy improving by approximately 2x as we scale the PaLM models from 8-billion to 540-billion. The performance of the PaLM 8-billion on MedQA was only slightly better than random performance. However, this number improved by over 30% for the PaLM 540-billion demonstrating the effectiveness of scale for the medical question answering task. We observed similar improvements for the MedMCQA and PubMedQA datasets. Further, instruction fine-tuning was also effective with Flan-PaLM models performing better than the PaLM models across all size variants on all the multiple-choice datasets.</p><p>It is possible that the PaLM pre-training corpus included significant quantities of high quality medical content and one possible conjecture for the strong performance of the 540-billion model variant is memorization of evaluation datasets considered in this study. However, Chowdhery et al. <ref type="bibr" target="#b13">[14]</ref> showed similar deltas in performance of the PaLM 8B and 540B model when evaluating contaminated (i.e where part of the test set is in the model pre-training corpus) and cleaned test datasets. This suggests that memorization alone does not explain the strong performance observed by scaling up the models.</p><p>There have been several efforts to train language models on a biomedical corpus, especially PubMed. These include BioGPT <ref type="bibr" target="#b55">[56]</ref> (355 million parameters), PubMedGPT <ref type="bibr" target="#b8">[9]</ref> (2.7 billion parameters) and Galactica <ref type="bibr" target="#b78">[79]</ref> (120 billion parameters). Our models were able to outperform these efforts on PubMedQA without any finetuning. Further, the benefits of scale and instruction fine-tuning were much more pronounced on the MedQA dataset, which can be considered out-of-domain for all these models. Given the results, we observe that medical answering performance (requiring recall, reading comprehension, and reasoning skills) improves with LLM scale.</p><p>However, our human evaluation results on the consumer medical question answering datasets clearly point out that scale alone is insufficient. Even state-of-the-art LLMs like Flan-PaLM can generate answers that are inappropriate for use in the safety-critical medical domain. However, the Med-PaLM results demonstrate that with instruction prompt tuning we have a data and parameter-efficient alignment technique useful for improving factors related to accuracy, factuality, consistency, safety, harm, and bias, helping close the gap with clinical experts and bringing these models closer to real-world clinical applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Limitations</head><p>Our study demonstrated the potential of LLMs for encoding medical knowledge and in particular for question answering. However, it had several limitations which we discuss in detail below and outline directions for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Expansion of MultiMedQA</head><p>Firstly, while the MultiMedQA benchmark is diverse and contains questions from a variety of professional medicine, medical research and consumer sources, it is by no means exhaustive. We plan to expand the benchmark in the future to include a larger variety of medical and scientific domains (eg: biology) and formats.</p><p>A key challenge in clinical environments is eliciting information from patients and synthesizing findings into an assessment and plan. Multiple-choice question answering tasks are inherently easier because they are often grounded in vignettes compiled by experts and selected to have a generally preferred answer, which is not true for all medical decisions. Developing benchmark tasks that reflect real world clinical workflows is an important direction of future research.</p><p>Furthermore, we only considered English-language datasets in this study, and there is a strong need to expand the scope of the benchmark to support multilingual evaluations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Development of key LLM capabilities necessary for medical applications</head><p>While the Flan-PaLM was able to reach state-of-the-art performance on several multiple-choice medical question answering benchmarks, our human evaluation clearly suggests these models are not at clinician expert level on many clinically important axes. In order to bridge this gap, several new LLM capabilities need to be researched and developed including:</p><p>? grounding of the responses in authoritative medical sources and accounting for the time-varying nature of medical consensus. ? ability to detect and communicate uncertainty effectively to the human in-the-loop whether clinician or lay user. ? ability to respond to queries in multiple languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Improving the approach to human evaluation</head><p>The rating framework we proposed for this study represents a promising pilot approach, but our chosen axes of evaluation were not exhaustive and were subjective in nature. For example the concept of medical/scientific consensus is time-varying in nature and is reflective of understandings of human health and disease and physiology based on discrimination in areas such as race/ethnicity, gender, age, ability, and more <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b56">57]</ref>. Furthermore, consensus often exists only for topics of relevance to certain groups (e.g. greater in number and/or power) and consensus may be lacking for certain subpopulations affected by topics for various reasons (e.g., controversial topics, lower incidence, less funding). Additionally, the concept of harm may differ according to population (e.g., a genetic study of a smaller group of people may reveal information that is factual but incongruent with that group's cultural beliefs, which could cause members of this group harm). Expert assessment of harm may also vary based on location, lived experience, and cultural background. Our ratings of potential harm were subjective estimates, and variation in perceived harm may also have been due to differences in health literacy of both our clinician and lay raters, or might vary in real world settings depending on the sociocultural context and health literacy of the person receiving and acting on the answers to the health questions in the study by Berkman et al. <ref type="bibr" target="#b5">[6]</ref>. Further research might test whether perceived usefulness and harm of question answers varied according to the understandability and actionability score for the answer content <ref type="bibr" target="#b76">[77]</ref>.</p><p>The number of model responses evaluated and the pool of clinicians and lay-people assessing them were limited, as our results were based on only a single clinician or lay-person evaluating the responses. This represents a limitation to generalizability of our findings which could be mitigated by inclusion of a significantly larger and intentionally diverse pool of human raters (clinicians and lay users) with participatory design in the development of model auditing tools. It is worth noting that the space of LLM responses or "coverage" is extremely high and that presents an additional difficulty in the design of evaluation tools and frameworks.</p><p>The pilot framework we developed could be significantly advanced using recommended best practice approaches for the design and validation of rating instruments from health, social and behavioral research <ref type="bibr" target="#b7">[8]</ref>. This could entail the identification of additional rating items through participatory research, evaluation of rating items by domain experts and technology recipients for relevance, representativeness, and technical quality. The inclusion of a substantially larger pool of human raters would also enable testing of instrument generalizability by ratifying the test dimensionality, test-retest reliability and validity <ref type="bibr" target="#b7">[8]</ref>. As the same answer can be evaluated multiple ways, the most appropriate rating instrument is also dependent on the intended purpose and recipient for LLM outputs, providing multiple opportunities for the development of validated rating scales depending on the context and purpose of use. Further, substantial user experience (UX) and human-computer interaction (HCI) studies using community-based participatory research methods are necessary before any real world use, and would be specific to a developed tool that is beyond the scope of our exploratory research. Under these contexts further research could explore the independent influence of variation in lay raters' education level, medical conditions, caregiver status, experience with health care, education level or other relevant factors on their perceptions of the quality of model outputs. The impact of variation in clinician raters' specialty, demographics, geography or other factors could be similarly explored in further research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Fairness and equity considerations</head><p>Our current approach to evaluating bias is limited and does not serve as a comprehensive assessment of potential harms, fairness, or equity. The development of procedures for the evaluation of bias and fairnessrelated harms in large language models is ongoing <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b91">92]</ref>. Healthcare is a particularly complex application of large language models given the safety-critical nature of the domain and the nuance associated with social and structural bias that drives health disparities. The intersection of large language models and healthcare creates unique opportunities for responsible and ethical innovation of robust assessment and mitigation tools for bias, fairness, and health equity.</p><p>We outline opportunities for future research into frameworks for the systematic identification and mitigation of downstream harms and impacts of large language models in healthcare contexts. Key principles include the use of participatory methods to design contextualized evaluations that reflect the values of patients that may benefit or be harmed, grounding the evaluation in one or more specific downstream clinical use cases <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b70">71]</ref>, and the use of dataset and model documentation frameworks for transparent reporting of choices and assumptions made during data collection and curation, model development, and evaluation <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b71">72]</ref>. Furthermore, research is needed into the design of algorithmic procedures and benchmarks that probe for specific technical biases that are known to cause harm if not mitigated. For instance, depending on the context, it may be relevant to assess sensitivity of model outputs to perturbations of demographic identifiers in prompts designed deliberately such that the result should not change under the perturbation <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b97">98]</ref>.</p><p>Additionally, the aforementioned research activities to build evaluation methods to achieve health equity in large language models require interdisciplinary collaboration to ensure that various scientific perspectives and methods can be applied to the task of understanding the social and contextual aspects of health <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b61">62]</ref>.</p><p>The development of evaluation frameworks for large language models is a critical research agenda that should be approached with equal rigor and attention as that given to the work of encoding clinical knowledge in language models.</p><p>In this study we worked with a panel of four qualified clinicians to identify the best-demonstration examples and craft few-shot prompts, all based in either the US or UK, with expertise in internal medicine, pediatrics, surgery and primary care. Although recent studies have surprisingly suggested that the validity of reasoning within a chain-of-thought prompt only contributes a small extent to the impact of this strategy on LLM performance in multi-step reasoning challenges <ref type="bibr" target="#b86">[87]</ref>, further research could significantly expand the range of clinicians engaged in prompt construction and the selection of exemplar answers and thereby explore how variation in multiple axes of the types of clinician participating in this activity impact LLM behavior; for example clinician demographics, geography, specialism, lived experience and more.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Ethical considerations</head><p>This research demonstrates the potential of LLMs for future use in healthcare. Transitioning from a LLM that is used for medical question answering to a tool that can be used by healthcare providers, administrators, and consumers will require significant additional research to ensure the safety, reliability, efficacy, and privacy of the technology. Careful consideration will need to be given to the ethical deployment of this technology including rigorous quality assessment when used in different clinical settings and guardrails to mitigate against over reliance on the output of a medical assistant. For example, the potential harms of using a LLM for diagnosing or treating an illness are much greater than using a LLM for information about a disease or medication. Additional research will be needed to assess LLMs used in healthcare for homogenization and amplification of biases and security vulnerabilities inherited from base models <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b48">49]</ref>. Given the continuous evolution of clinical knowledge, it will also be important to develop ways for LLMs to provide up to date clinical information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>The advent of foundation AI models and large language models present a significant opportunity to rethink the development of medical AI and make it easier, safer and more equitable to use. At the same time, medicine is an especially complex domain for applications of large language models.</p><p>Our research provides a glimpse into the opportunities and the challenges of applying these technologies to medicine. We hope this study will spark further conversations and collaborations between patients, consumers, AI researchers, clinicians, social scientists, ethicists, policymakers and other interested people in order to responsibly translate these early research findings to improve healthcare.   Med-PaLM uses the same system type and implementation frameworks as Flan-PaLM <ref type="bibr" target="#b14">[15]</ref>. We show parts of the model card <ref type="bibr" target="#b58">[59]</ref> specific to Med-PaLM in Table <ref type="table" target="#tab_15">A</ref>.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.6 Med-PaLM multiple-choice evaluation</head><p>Med-PaLM was trained using instruction prompt tuning to improve the quality of long-form generations produced by Flan-PaLM. However, given the generality of instruction prompt tuning, the technique can also be applied to multiple-choice datasets. We can learn shared soft prompt parameters to be prepended to instructions and/or few-shot exemplars which vary for each multiple-choice dataset.</p><p>In a preliminary experiment, we trained Flan-PaLM using instruction prompt tuning on MedQA, MedMCQA, PubMedQA, and MMLU (clinical topics). Exemplars were written by a panel of five qualified clinicians.</p><p>Each training example contained dataset-specific instructions and 5 few-shot examples. The resulting model achieved a 67.2% accuracy on MedQA using chain-of-thought and self-consistency, roughly matching the corresponding result with Flan-PaLM i Section 4. We plan to extend this early result in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.7 Detailed human evaluation results</head><p>Detailed human evaluation results with confidence intervals are summarized in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model characteristics Model initialization</head><p>The model is initialized from Flan-PaLM <ref type="bibr" target="#b14">[15]</ref>. Additional soft prompt parameters are initialized as described in Section A.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model stats</head><p>The model has 540 billion parameters following Flan-PaLM. There are 1.84M additional domain-specific prompt parameters learned via instruction prompt tuning as described in Section 3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation dataset</head><p>The model was evaluated on a benchmark of 140 questions curated from the LiveQA, MedicationQA, and HealthSearchQA datasets. These datasets are described in Section 3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation results</head><p>The results are described in Section 4.5. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.9 Chain-of-Thought prompt examples</head><p>We provided examples of some of the chain-of-thought prompts used in this study in   Attempts to contact the patients for follow-up, adherence to follow-up recommendations, and patient characteristics were abstracted from medical records. The probability of adherence to follow-up vs the number of follow-up attempts was modeled with survival analysis. Cox proportional hazards models were used to examine multivariate relationships related to adherence. The rate of overall adherence to follow-up recommendations was 56.0% (136/243). Adherence to a second colposcopy was not significantly different from that to a repeated Pap smear (odds ratio, 1.40; 95% confidence interval, 0.80-2.46). The use of as many as 3 patient reminders substantially improved adherence to follow-up. Women without insurance and women attending 1 of the 3 clinics were less likely to adhere to any follow-up recommendation (hazard ratio for no insurance, 0.  Question: how reduce cholesterol? Answer: High cholesterol is when you have too much of a fatty substance called cholesterol in your blood. It's mainly caused by eating fatty food, not exercising enough, being overweight, smoking and drinking alcohol. It can also run in families. You can lower your cholesterol by eating healthily and getting more exercise. Some people also need to take medicines as advised by a doctor, for example statins or other options.</p><p>Question: metoprolol pill how long before it takes effect? Answer: Metoprolol starts to work after about 2 hours, but it can take up to 1 week to fully take effect. You may not feel any different when you take metoprolol, but this doesn't mean it's not working.</p><p>Question: how long do opioid withdrawals last? Answer: Opioid withdrawal symptoms can last anywhere from one week to one month. The first phase (acute withdrawal) begins about 12 hours after your last opioid use. It peaks at around 3 -5 days, and lasts for approximately 1 -4 weeks. The second phase (post-acute withdrawal) can last up to two years. The symptoms include mood swings, anxiety, variable energy, low enthusiasm, variable concentration, and disturbed sleep.</p><p>Question: what foods should a person taking warfarin eat? Answer: Foods containing a lot of vitamin K can affect how warfarin works. These include green leafy vegetables, including broccoli, spinach and lettuce, chickpeas, liver, egg yolks, mature cheese and blue cheese, avocado, olive oil. It's important that you eat foods containing vitamin K, so rather than leaving them out of your diet, make sure you eat similar amounts of them regularly. This will mean the level of vitamin K in your blood stays fairly constant and makes it more likely that your INR level stays stable. Do not drink cranberry juice, grapefruit juice or pomegranate juice while you're taking warfarin. It can increase the effect of your medicine and put you at higher risk of bleeding.</p><p>Table <ref type="table" target="#tab_15">A</ref>.20 | PubMedQA (2019) <ref type="bibr" target="#b33">[34]</ref> chain-of-thought prompt examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instructions:</head><p>The following are multiple choice questions about medical research. Determine the answer to the question given the context in a step-by-step fashion. Consider the strength of scientific evidence to output a single option as the final answer.</p><p>Context: To describe the interstitial fluid (ISF) and plasma pharmacokinetics of meropenem in patients on continuous venovenous haemodiafiltration (CVVHDF). This was a prospective observational pharmacokinetic study. Meropenem (500 mg) was administered every 8 h. CVVHDF was targeted as a 2-3 L/h exchange using a polyacrylonitrile filter with a surface area of 1.05 m 2 and a blood flow rate of 200 mL/min. Serial blood (pre-and post-filter), filtrate/dialysate and ISF concentrations were measured on 2 days of treatment (Profiles A and B). Subcutaneous tissue ISF concentrations were determined using microdialysis. A total of 384 samples were collected. During Profile A, the comparative median (IQR) ISF and plasma peak concentrations were 13.6 (12.0-16.8) and 40.7 <ref type="bibr">(36.6-45.6</ref>) mg/L and the trough concentrations were 2.6 (2.4-3.4) and 4.9 (3.5-5.0) mg/L, respectively. During Profile B, the ISF trough concentrations increased by ?40%. Meropenem ISF penetration was estimated at 63% (60%-69%) and 69% (65%-74%) for Profiles A and B, respectively, using comparative plasma and ISF AUCs. For Profile A, the plasma elimination t1/2 was 3. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(Dev/Test): 11 / 100 Question: The allele associated with sickle cell anemia apparently reached a high frequency in some human populations due to: Answer: (A) random mating (B) superior fitness of heterozygotes in areas where malaria was present (C) migration of individuals with the allele into other populations (D) a high mutation rate at that specific gene. Professional Medicine Size (Dev/Test): 31 / 272 Question: A 19-year-old woman noticed a mass in her left breast 2 weeks ago while doing monthly breast self-examination. Her mother died of metastatic breast cancer at the age of 40 years. Examination shows large dense breasts; a 2-cm, firm, mobile mass is palpated in the upper outer quadrant of the left breast. There are no changes in the skin or nipple, and there is no palpable axillary adenopathy. Which of the following is the most likely diagnosis? Answer: (A) Fibroadenoma (B) Fibrocystic changes of the breast (C) Infiltrating ductal carcinoma (D) Intraductal papilloma College Biology Size (Dev/Test): 16 / 144 Question: Which of the following is the most direct cause of polyteny in somatic cells of certain organisms? Answer: (A) RNA transcription (B) Supercoiling of chromatin (C) Chromosome replication without cell division (D) Chromosome recombination</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 |</head><label>2</label><figDesc>Figure 2 | Instruction prompt tuning for Med-PaLM We use instructions and exemplars from a panel of qualified clinicians for each of the consumer medical question answering datasets and use them to instruction prompt tune Flan-PaLM. Med-PaLM is the resulting model, with additional prompt parameters aligned with the medical domain.</figDesc><graphic url="image-4.png" coords="12,352.90,69.57,190.81,247.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 |</head><label>4</label><figDesc>Figure 4 | Comparison of SOTA LLMs on MMLU clinical topics Flan-PaLM achieves state-of-the-art performance on MMLU clinical topics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 |</head><label>6</label><figDesc>Figure6| Clinician evaluation of answers agreement with scientific and clinical consensus Clinicians were asked to rate answers provided to questions in the HealthSearchQA, Live QA and Medication question answering datasets. Clinicians were asked to identify whether the answer is aligned with the prevailing medical/scientific consensus; whether the answer was in opposition to consensus; or whether there is no medical/scientific consensus for how to answer that particular question (or whether it was not possible to answer this question). We observe that while the Flan-PaLM model answers are only found to be in agreement with the scientific consensus 61.9% of the time, this improves to 92.9% for Med-PaLM matching expert answers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 9 |</head><label>9</label><figDesc>Figure9| Clinician evaluation of potential harm from answers (a) Extent of possible harm and (b) likelihood of harm. While 29.7% of the Flan-PaLM responses were judged as potentially leading to harm, this number dropped to 5.9% for Med-PaLM on par with clinician-generated answers which were also judged as potentially leading to harm in 5.7% of the cases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 11 |</head><label>11</label><figDesc>Figure11| Lay user assessment of answers (a) Helpfulness (b) how well they address the intent of the query Flan-PaLM answers were found to be helpful in only 60.6% of the cases. However, this number improved to 80.3% for Med-PaLM, but remaining inferior to clinicians whose answers were judged to be helpful in 91.1% of the cases. On the capturing of user intent, Flan-PaLM answers were judged as directly addressing the user's question intent in 90.8% of cases. Using Med-PaLM this number improves to 94.0%, closing the gap to clinician-generated answers at 95.9%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure A. 1 |</head><label>1</label><figDesc>Figure A.1 | Scaling plots for PaLM and Flan-PaLM with few-shot prompting on MedQA and MedMCQA</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure A. 2 |</head><label>2</label><figDesc>Figure A.2 | Scaling plots for Flan-PaLM with few-shot and Flan-PaLM few-shot + chain-of-thought (CoT) + self-consistency (SC) on MedQA and MedMCQA</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>(randomization-by-time interaction coefficient=-1.40; 95% CI -3.91 to 1.10) or anxiety symptoms (randomization-by-time interaction coefficient=-0.55; 95% CI -1.59 to 0.49). The intervention did not reduce caregiver burden or their health related quality of life. Question: Does a family meetings intervention prevent depression and anxiety in family caregivers of dementia patients? (A) Yes (B) No (C) Maybe Answer:(B) Answer the following question given the context (reply with one of the options): Context: To compare adherence to follow-up recommendations for colposcopy or repeated Papanicolaou (Pap) smears for women with previously abnormal Pap smear results. Retrospective cohort study. Three northern California family planning clinics. All women with abnormal Pap smear results referred for initial colposcopy and a random sample of those referred for repeated Pap smear. Medical records were located and reviewed for 90 of 107 women referred for colposcopy and 153 of 225 women referred for repeated Pap smears. Routine clinic protocols for follow-up-telephone call, letter, or certified letter-were applied without regard to the type of abnormality seen on a Pap smear or recommended examination. Documented adherence to follow-up within 8 months of an abnormal result.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>43 [95% confidence interval, 0.20-0.93], and for clinic, 0.35 [95% confidence interval, 0.15-0.73]). Question: Do follow-up recommendations for abnormal Papanicolaou smears influence patient adherence? (A) Yes (B) No (C) Maybe Answer:(B)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>7 (3.3-4.0) h, the volume of distribution was 0.35 (0.25-0.46) L/kg, the total clearance was 4.1 (4.1-4.8) L/h and the CVVHDF clearance was 2.9 (2.7-3.1) L/h. Question: Are interstitial fluid concentrations of meropenem equivalent to plasma concentrations in critically ill patients receiving continuous renal replacement therapy? (A) Yes (B) No (C) Maybe Explanation: This is the first known report of concurrent plasma and ISF concentrations of a meropenem antibiotic during CVVHDF. We observed that the ISF concentrations of meropenem were significantly lower than the plasma concentrations, although the present dose was appropriate for infections caused by intermediately susceptible pathogens (MIC?4 mg/L).Answer: (B)Context: Family caregivers of dementia patients are at increased risk of developing depression or anxiety. A multi-component program designed to mobilize support of family networks demonstrated effectiveness in decreasing depressive symptoms in caregivers. However, the impact of an intervention consisting solely of family meetings on depression and anxiety has not yet been evaluated. This study examines the preventive effects of family meetings for primary caregivers of community-dwelling dementia patients. A randomized multicenter trial was conducted among 192 primary caregivers of community dwelling dementia patients. Caregivers did not meet the diagnostic criteria for depressive or anxiety disorder at baseline. Participants were randomized to the family meetings intervention (n=96) or usual care (n=96) condition. The intervention consisted of two individual sessions and four family meetings which occurred once every 2 to 3 months for a year. Outcome measures after 12 months were the incidence of a clinical depressive or anxiety disorder and change in depressive and anxiety symptoms (primary outcomes), caregiver burden and quality of life (secondary outcomes). Intention-to-treat as well as per protocol analyses were performed. A substantial number of caregivers(72/192) developed a depressive or anxiety disorder within 12 months. The intervention was not superior to usual care either in reducing the risk of disorder onset (adjusted IRR 0.98; 95% CI 0.69 to 1.38) or in reducing depressive (randomization-by-time interaction coefficient=-1.40; 95% CI -3.91 to 1.10) or anxiety symptoms (randomization-by-time interaction coefficient=-0.55; 95% CI -1.59 to 0.49). The intervention did not reduce caregiver burden or their health related quality of life. Question: Does a family meetings intervention prevent depression and anxiety in family caregivers of dementia patients? (A) Yes (B) No (C) Maybe Explanation: This study did not demonstrate preventive effects of family meetings on the mental health of family caregivers. Further research should determine whether this intervention might be more beneficial if provided in a more concentrated dose, when applied for therapeutic purposes or targeted towards subgroups of caregivers.Answer: (B)Context: To compare adherence to follow-up recommendations for colposcopy or repeated Papanicolaou (Pap) smears for women with previously abnormal Pap smear results. Retrospective cohort study. Three northern California family planning clinics. All women with abnormal Pap smear results referred for initial colposcopy and a random sample of those referred for repeated Pap smear. Medical records were located and reviewed for 90 of 107 women referred for colposcopy and 153 of 225 women referred for repeated Pap smears. Routine clinic protocols for follow-up-telephone call, letter, or certified letter-were applied without regard to the type of abnormality seen on a Pap smear or recommended examination. Documented adherence to follow-up within 8 months of an abnormal result. Attempts to contact the patients for follow-up, adherence to follow-up recommendations, and patient characteristics were abstracted from medical records. The probability of adherence to follow-up vs the number of follow-up attempts was modeled with survival analysis. Cox proportional hazards models were used to examine multivariate relationships related to adherence. The rate of overall adherence to follow-up recommendations was 56.0% (136/243). Adherence to a second colposcopy was not significantly different from that to a repeated Pap smear (odds ratio, 1.40; 95% confidence interval, 0.80-2.46). The use of as many as 3 patient reminders substantially improved adherence to follow-up. Women without insurance and women attending 1 of the 3 clinics were less likely to adhere to any follow-up recommendation (hazard ratio for no insurance, 0.43 [95% confidence interval, 0.20-0.93], and for clinic, 0.35 [95% confidence interval, 0.15-0.73]). Question: Do follow-up recommendations for abnormal Papanicolaou smears influence patient adherence? (A) Yes (B) No (C) Maybe Explanation: Adherence to follow-up was low in this family planning clinic population, no matter what type of follow-up was advised. Adherence was improved by the use of up to 3 reminders. Allocating resources to effective methods for improving adherence to follow-up of abnormal results may be more important than which follow-up procedure is recommended. Answer: (B)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 |</head><label>1</label><figDesc>Summary of MultiMedQA describing the format, size, and domain of the datasets in the benchmark.</figDesc><table><row><cell>Dataset</cell><cell>Format</cell><cell>Size (dev/test)</cell><cell>Domain</cell></row><row><cell>MedQA (USMLE)</cell><cell>Q + A (4-5 Choices)</cell><cell>11450 / 1273</cell><cell>General medical knowledge in US medical licensing exam</cell></row><row><cell>MedMCQA (AIIMS/NEET)</cell><cell>Q + A (4 Choices and Explanations)</cell><cell>187K / 6.1K</cell><cell>General medical knowledge in Indian medical entrance exams</cell></row><row><cell></cell><cell></cell><cell>500 / 500</cell><cell></cell></row><row><cell></cell><cell>Q + Context + A</cell><cell>#QA pairs:</cell><cell></cell></row><row><cell>PubMedQA</cell><cell>(Yes/No/Maybe)</cell><cell>Labeled: 1k</cell><cell>Biomedical scientific literature</cell></row><row><cell></cell><cell>(Long Answer)</cell><cell>Unlabeled: 61.2k</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Synthetic: 211.3k</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Medical knowledge covering anatomy,</cell></row><row><cell>MMLU</cell><cell>Q + A (4 Choices)</cell><cell>123 / 1089</cell><cell>clinical knowledge, college medicine, medical genetics, professional medicine,</cell></row><row><cell></cell><cell></cell><cell></cell><cell>and college biology</cell></row><row><cell>LiveQA TREC-2017</cell><cell>Q + Long Answer (Librarian Answers)</cell><cell>634 / 104</cell><cell>General medical knowledge sought by consumers</cell></row><row><cell>Medication QA</cell><cell>Q + A (Long Answer)</cell><cell>NA / 674</cell><cell>Medication knowledge frequently sought by consumers</cell></row><row><cell>HealthSearchQA (Ours)</cell><cell>Q + Manual Expert Evaluation</cell><cell>3375</cell><cell>General medical knowledge searched for by consumers</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>On the MedQA dataset consisting of USMLE style questions with 4 options, our Flan-PaLM 540B model achieved a multiple-choice question (MCQ) accuracy of 67.6% surpassing the DRAGON model<ref type="bibr" target="#b93">[94]</ref> by 20.1%.Concurrent to our study, Bolton et al.<ref type="bibr" target="#b8">[9]</ref> developed PubMedGPT, a 2.7 billion model trained exclusively on biomedical abstracts and paper. The model achieved a performance of 50.3% on MedQA questions with 4 options. To the best of our knowledge, this is the state-of-the-art on MedQA, and Flan-PaLM 540B exceeded this by 17.3%. Table4compares to best performing models on this dataset. On the more difficult set of questions with 5 options, our model obtained a score of 62.0%. Comparison of our method and prior SOTA We achieve state-of-the-art performance on MedQA (4 options), MedMCQA and PubMedQA datasets with our Flan-PaLM 540B model. SOTA results come from Galactica (MedMCQA)<ref type="bibr" target="#b78">[79]</ref>,</figDesc><table><row><cell></cell><cell>80</cell><cell>SOTA</cell><cell></cell><cell>Flan-PaLM</cell><cell></cell><cell>78.2</cell><cell>79.0</cell></row><row><cell>Accuracy (%)</cell><cell>50 60 70</cell><cell>52.9</cell><cell>57.6</cell><cell>50.3</cell><cell>67.6</cell></row><row><cell></cell><cell>40</cell><cell cols="2">MedMCQA</cell><cell cols="2">MedQA (USMLE)</cell><cell>PubMedQA</cell></row><row><cell>Figure 3 |</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p><p>4.1 Flan-PaLM exceeds previous state-of-the-art on MedQA (USMLE) by over 17%</p>4.2 State-of-the-art performance on MedMCQA and PubMedQA</p>On the MedMCQA dataset, consisting of medical entrance exam questions from India, Flan-PaLM 540B reached a performance of 57.6% on the dev set. This exceeds the previous state of the art result of 52.9% by</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 |</head><label>4</label><figDesc>Summary of the best performing models on the MedQA (USMLE) dataset questions with 4 options. Our results with Flan-PaLM exceed previous state of the art by over 17%.</figDesc><table><row><cell cols="2">Model (number of parameters) MedQA (USMLE) Accuracy %</cell></row><row><cell>Flan-PaLM (540 B)(ours)</cell><cell>67.6</cell></row><row><cell>PubMedGPT (2.7 B) [9]</cell><cell>50.3</cell></row><row><cell>DRAGON (360 M)</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 |</head><label>5</label><figDesc>Summary of the performance of PaLM and Flan-PaLM models across different model size variants on the multiple-choice medical question answering datasets in MultiMedQA using few-shot prompting.</figDesc><table><row><cell>Dataset</cell><cell cols="6">PaLM 8B Flan-PaLM 8B PaLM 62B Flan-PaLM 62B PaLM 540B Flan-PaLM 540B</cell></row><row><cell>MedQA</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>4 options</cell><cell>25.7</cell><cell>35.4</cell><cell>40.9</cell><cell>46.1</cell><cell>58.9</cell><cell>60.3</cell></row><row><cell>(5-shot)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MedMCQA (5-shot)</cell><cell>26.7</cell><cell>34.5</cell><cell>43.4</cell><cell>46.2</cell><cell>54.5</cell><cell>56.5</cell></row><row><cell>PubMedQA (3-shot)</cell><cell>34.0</cell><cell>67.6</cell><cell>57.8</cell><cell>77.2</cell><cell>55.0</cell><cell>79.0</cell></row></table><note><p>most prominent in the PubMedQA dataset where the 8B Flan-PaLM model outperformed the baseline PaLM model by over 30%. Similar strong improvements were observed in the case of 62B and 540B variants too. These results demonstrated the strong benefits of instruction fine-tuning. Similar results with MMLU clinical topics are reported in Section A.3.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 |</head><label>6</label><figDesc>Summary of the performance of Flan-PaLM models with few-shot and chain-of-thought (CoT) prompting across different model size variants on the multiple-choice medical question answering datasets in MultiMedQA.</figDesc><table><row><cell>Dataset</cell><cell>Flan-PaLM 540B with few-shot</cell><cell>Flan-PaLM 540B with CoT</cell></row><row><cell>MedQA 4 options (5-shot)</cell><cell>60.3</cell><cell>60.3</cell></row><row><cell>MedMCQA (5-shot)</cell><cell>56.5</cell><cell>53.6</cell></row><row><cell>PubMedQA (3-shot)</cell><cell>79.0</cell><cell>77.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 |</head><label>7</label><figDesc>Summary of the performance of Flan-PaLM with and without self-consistency prompting (SC) across different model size variants on the multiple-choice datasets.</figDesc><table><row><cell>Dataset</cell><cell>Flan-PaLM 540B with few-shot</cell><cell>Flan-PaLM 540B with SC</cell></row><row><cell>MedQA 4 options</cell><cell>60.3</cell><cell>67.6</cell></row><row><cell>MedMCQA</cell><cell>56.5</cell><cell>57.6</cell></row><row><cell>PubMedQA</cell><cell>79.0</cell><cell>75.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 |</head><label>8</label><figDesc>The table below shows example explanations generated by the Flan-PaLM 540B model to support its multiple-choice answer in the MedQA dataset.Question: A 65-year old man presents with gradually worsening rigidity of his arms and legs and slowness in performing tasks. He says he has also noticed hand tremors, which increase at rest and decrease with focused movements. On examination, the patient does not swing his arms while walking and has a shortened, shuffling gait. An antiviral drug is prescribed which alleviates the patient's symptoms. Which of the following drugs was most likely prescribed to this patient? (A) Amantadine (B) Ribavirin (C) Acyclovir (D) Levodopa (E) Zidovudine Explanation: The most likely drug prescribed for this patient is (A) Amantadine. Amantadine is an antiviral drug that is used to alleviate symptoms of Parkinson's disease. Parkinson's disease is a progressive disorder that is characterized by muscle rigidity and bradykinesia, which is a slowing of movement. Levodopa is used to alleviate symptoms of Parkinson's disease; however, it is not an antiviral drug. Acyclovir, ribavirin, and zidovudine are antiviral drugs that are used to treat viral infections and do not have a role in the treatment of Parkinson's disease.Answer: (A)Question: A 37-year-old man with no significant past medical history is rear-ended in a motor vehicle accident. He reported significant neck pain to emergency responders, but otherwise denies weakness, numbness or tingling in his extremities. His vitals on presentation to the ED are HR 90, BP 140/80, RR 20, SpO2 98%. What is the most appropriate next step upon presentation to the emergency room? (A) Lateral cervical film (B) Three view cervical spine series (C) Cervical immobilization (D) IV methylprednisolone (E) Observation overnight. Explanation: The most appropriate next step upon presentation to the emergency room is (C) Cervical immobilization. Significant neck pain suggests a possible cervical spinal injury, and cervical immobilization should be initiated until radiographs can be obtained. Lateral cervical film (choice A) is not the appropriate radiograph for a cervical injury. Three view cervical spine series (choice B) is the appropriate series of radiographs to rule out a cervical injury, but it must be done with cervical immobilization. IV methylprednisolone (choice D) is used to treat acute spinal cord injury, but it is not indicated for this patient at this time. Observation overnight (choice E) would not be appropriate in the setting of suspected cervical spinal injury without cervical immobilization and radiographs.</figDesc><table /><note><p>Answer: (C)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Selective prediction analysis Analysis of deferral behavior of Flan-PaLM 540B model with self-consistency. We observe that if we defer more often using an uncertainty threshold based on self-consistency, the model becomes increasingly accurate on questions it does not defer</figDesc><table><row><cell></cell><cell>0.825</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.800</cell><cell></cell><cell></cell></row><row><cell>Accuracy (%)</cell><cell>0.725 0.750 0.775</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.675 0.700</cell><cell></cell><cell></cell><cell>Flan-PaLM</cell></row><row><cell></cell><cell>0</cell><cell>0.1</cell><cell>0.2 Deferring Fraction 0.3</cell><cell>0.4</cell></row><row><cell>Figure 5 | Clinician Med-PaLM Flan-PaLM</cell><cell>61.9%</cell><cell>92.9% 92.6%</cell><cell></cell><cell>Scientific Consensus No consensus Opposed to consensus Aligned with consensus</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>|17</cell></row></table><note><p>Comprehension, retrieval and reasoning capabilities: We sought to understand the (whether expert or model generated) medical comprehension, medical knowledge retrieval and reasoning capabilities of the</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 |</head><label>9</label><figDesc>Examples of Med-PaLM responses to questions in the HealthSearchQA dataset. Middle ear infection (otitis media), which is commonly caused by a viral infection and can cause pain, redness, and swelling of the ear. External ear infection (otitis externa), which is commonly caused by a bacterial infection and can cause pain, redness, and swelling of the ear. Earwax impaction, which can cause pain, a feeling of fullness in the ear, and decreased hearing. Ear pain can also be a sign of a more serious condition, such as a brain tumor or a stroke. If you have severe ear pain that lasts longer than a few days, or if you have other symptoms along with the ear pain, such as dizziness, fever, or facial weakness or numbness, you should see a doctor for evaluation. The doctor can determine the cause of the pain and provide appropriate treatment. What do nights sweats indicate?</figDesc><table><row><cell>Question</cell><cell>Med-PaLM</cell></row><row><cell>How do you know if ear pain is serious?</cell><cell>Ear pain can be a sign of several underlying conditions, including:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>If you have symptoms of hepatitis A, such as fever, fatigue, loss of appetite, and yellow skin or eyes, it is important to see a doctor for evaluation. The doctor can perform tests to confirm the diagnosis and provide treatment if necessary. Clinician evaluation of comprehension, retrieval and reasoning capabilities (a) Evaluation of correctness and (b) evaluation of incorrectness of reading comprehension, recall of knowledge and reasoning step. The results indicate Med-PaLM shows any evidence of incorrect comprehension only 5.0% of the time. With regard to evidence of correct retrieval of medical knowledge, we found that clinician answers scored 97.8% while Flan-PaLM only scored 76.3%. However, the instruction prompt-tuned Med-PaLM model scored 95.4%, reducing the inferiority of the model compared to clinicians.</figDesc><table><row><cell>Clinician Med-PaLM Flan-PaLM</cell><cell cols="2">97.8% 90.5% 97.5%</cell><cell>Evidence of Correct Comprehension No Yes</cell><cell>Clinician Med-PaLM Flan-PaLM</cell><cell>2.2% 9.2% 5.0%</cell><cell>Evidence of Incorrect Comprehension Yes No</cell></row><row><cell>Clinician Med-PaLM Flan-PaLM</cell><cell>76.3%</cell><cell>97.8% 95.4%</cell><cell>Evidence of Correct Retrieval No Yes</cell><cell>Clinician Med-PaLM Flan-PaLM</cell><cell>3.6% 23.1% 16.9%</cell><cell>Evidence of Incorrect Retrieval Yes No</cell></row><row><cell>Clinician Med-PaLM Flan-PaLM</cell><cell cols="2">97.7% 85.7% 92.5%</cell><cell>Evidence of Correct Reasoning No Yes</cell><cell>Clinician Med-PaLM Flan-PaLM</cell><cell>2.1% 14.3% 10.1%</cell><cell>Evidence of Incorrect Reasoning Yes No</cell></row><row><cell></cell><cell></cell><cell>(a)</cell><cell></cell><cell></cell><cell>(b)</cell><cell></cell></row><row><cell>Figure 7 |</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>missing information in only 11.1% of the cases. A few qualitative examples are shown in Table</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 10 |</head><label>10</label><figDesc>Examples of HealthSearchQA questions where the physician answers were considered incomplete, and corresponding Med-PaLM answers. This suggests that LLMs may be a useful complement to physicians in future use cases. Clinician evaluation of answers contents (a) Presence of incorrect content and (b) presence of missing content in the answers. Clinician answers showed evidence of inappropriate/incorrect content in only 1.4% of the cases, compared to 16.1% for Flan-PaLM. Surprisingly, Med-PaLM seemed to further degrade performance, with 18.7% of the Med-PaLM answers judged to contain inappropriate or incorrect content. On the missing content axis, while Flan-PaLM answers were judged to miss important information 47.6% of the time, the number improved significantly for Med-PaLM with only 15.1% of the answers adjudged to have missing information, reducing the inferiority to clinicians whose answers were judged to have missing information in only 11.1% of the cases.</figDesc><table><row><cell>Question</cell><cell>Physician</cell><cell>Med-PaLM</cell></row><row><cell>How can I stop diarrhoea?</cell><cell>Without treatment, most diarrhoea re-</cell><cell>Diarrhoea is caused by a range of different</cell></row><row><cell></cell><cell>solves on its own. When experiencing di-</cell><cell>factors, so the treatment will depend on</cell></row><row><cell></cell><cell>arrhoea, it's important to stay hydrated,</cell><cell>the cause. If it is caused by an infection,</cell></row><row><cell></cell><cell>and best to eat small, light meals and</cell><cell>antibiotics may be needed. If it is caused</cell></row><row><cell></cell><cell>avoid spicy or fatty foods. Diarrhoea due</cell><cell>by food poisoning, it may be necessary</cell></row><row><cell></cell><cell>to an infection should not be treated with</cell><cell>to wait for the infection to pass. In all</cell></row><row><cell></cell><cell>imodium.</cell><cell>cases, it is important to stay hydrated by</cell></row><row><cell></cell><cell></cell><cell>drinking plenty of fluids, such as water</cell></row><row><cell></cell><cell></cell><cell>or oral rehydration solution. It is also</cell></row><row><cell></cell><cell></cell><cell>important to replace lost electrolytes by</cell></row><row><cell></cell><cell></cell><cell>eating foods such as bananas, potatoes,</cell></row><row><cell></cell><cell></cell><cell>and salted crisps. If possible, avoid foods</cell></row><row><cell></cell><cell></cell><cell>that are high in fat and fiber, which may</cell></row><row><cell></cell><cell></cell><cell>worsen diarrhoea. If you have diarrhoea</cell></row><row><cell></cell><cell></cell><cell>that lasts for more than a few days, or if</cell></row><row><cell></cell><cell></cell><cell>you have severe diarrhoea, it is important</cell></row><row><cell></cell><cell></cell><cell>to see a doctor.</cell></row><row><cell>What happens if listeria is left</cell><cell>Most people with mild symptoms of Lis-</cell><cell>Listeria is a type of bacteria that can</cell></row><row><cell>untreated?</cell><cell>teria require no treatment as the body is</cell><cell>cause an infection in people. It is usually</cell></row><row><cell></cell><cell>able to fight off infection without inter-</cell><cell>spread through contaminated food, such</cell></row><row><cell></cell><cell>vention. However, in more severe cases of</cell><cell>as soft cheeses, deli meats, and smoked</cell></row><row><cell></cell><cell>Listeria infection, the individual may suf-</cell><cell>fish. Listeria infection can cause flu-like</cell></row><row><cell></cell><cell>fer life-threatening complications such as</cell><cell>symptoms, such as fever, muscle aches,</cell></row><row><cell></cell><cell>meningitis and septicaemia without treat-</cell><cell>and headache. In some cases, it can cause</cell></row><row><cell></cell><cell>ment.</cell><cell>more severe symptoms, such as meningi-</cell></row><row><cell></cell><cell></cell><cell>tis (infection of the lining of the brain),</cell></row><row><cell></cell><cell></cell><cell>encephalitis (infection of the brain), and</cell></row><row><cell></cell><cell></cell><cell>sepsis (a severe infection that affects the</cell></row><row><cell></cell><cell></cell><cell>entire body). If listeria infection spreads</cell></row><row><cell></cell><cell></cell><cell>to the brain, it can be life-threatening. If</cell></row><row><cell></cell><cell></cell><cell>you are infected with listeria, your doctor</cell></row><row><cell></cell><cell></cell><cell>will likely prescribe antibiotics to treat the</cell></row><row><cell></cell><cell></cell><cell>infection. If the infection spreads to the</cell></row><row><cell></cell><cell></cell><cell>brain, you may need to be hospitalized to</cell></row><row><cell></cell><cell></cell><cell>receive intravenous antibiotics.</cell></row><row><cell>Does stress cause nosebleed?</cell><cell>Physician answer: Those experiencing</cell><cell>Yes, stress can cause a nosebleed. Stress</cell></row><row><cell></cell><cell>stress or anxiety can experience nose-</cell><cell>can cause the blood vessels in the nose to</cell></row><row><cell></cell><cell>bleeds as a symptom. This is because</cell><cell>break, leading to a nosebleed. Stress can</cell></row><row><cell></cell><cell>stress and anxiety can often result in ele-</cell><cell>also cause changes in the body that can</cell></row><row><cell></cell><cell>vated blood pressure which is a common</cell><cell>make nosebleeds more likely. For example,</cell></row><row><cell></cell><cell>cause of nose bleeds.</cell><cell>stress can cause an increase in blood pres-</cell></row><row><cell></cell><cell></cell><cell>sure, which can put extra pressure on the</cell></row><row><cell></cell><cell></cell><cell>blood vessels in the nose and cause them</cell></row><row><cell></cell><cell></cell><cell>to break. Stress can also cause changes</cell></row><row><cell></cell><cell></cell><cell>in the body's clotting function, which can</cell></row><row><cell></cell><cell></cell><cell>make it harder for the blood to clot and</cell></row><row><cell></cell><cell></cell><cell>stop a nosebleed. Stress can also cause</cell></row><row><cell></cell><cell></cell><cell>changes in the body's hormones, which</cell></row><row><cell></cell><cell></cell><cell>can affect the body's ability to clot blood</cell></row><row><cell></cell><cell></cell><cell>and stop a nosebleed. If you are experienc-</cell></row><row><cell></cell><cell></cell><cell>ing frequent nosebleeds, it is important to</cell></row><row><cell></cell><cell></cell><cell>see a doctor to determine the cause and re-</cell></row><row><cell></cell><cell></cell><cell>ceive appropriate treatment. The doctor</cell></row><row><cell></cell><cell></cell><cell>may recommend treatments to help re-</cell></row><row><cell></cell><cell></cell><cell>duce your stress levels and prevent future</cell></row><row><cell></cell><cell></cell><cell>nosebleeds.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>Clinician evaluation of possible bias in answers Flan-PaLM answers were found to contain biased information in 7.9% of the cases. However, this number reduced to 0.8% for Med-PaLM, comparing favorably with clinicians whose answers were judged to contain evidence of bias in 1.4% of the cases.</figDesc><table><row><cell>Clinician Med-PaLM Flan-PaLM</cell><cell>1.4% 7.9% 0.8%</cell><cell></cell><cell>Possibility of Bias</cell><cell>Yes No</cell></row><row><cell>Figure 10 | Clinician Med-PaLM Flan-PaLM</cell><cell>60.6%</cell><cell>91.1% 80.3%</cell><cell cols="2">How helpful is the Anwer? Not Helpful Somewhat Helpful Helpful</cell></row><row><cell></cell><cell></cell><cell>(a)</cell><cell></cell></row><row><cell>Clinician Med-PaLM Flan-PaLM</cell><cell></cell><cell>95.9% 90.8% 94.4%</cell><cell cols="2">Address Intent of Question Does not address query. Addresses query.</cell></row></table><note><p><p><p>The results are summarized in</p>Fig 10 below</p>. While Flan-PaLM answers were judged to be helpful in only 60.6% of the cases, the number improved to 80.3% for Med-PaLM answers. However, this remained inferior to clinician answers which were judged to be helpful 91.1% of the time. Similarly, Flan-PaLM answers were judged as directly addressing the</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>Table A.3 -Table A.12.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table A .</head><label>A</label><figDesc>2 | Model card for Med-PaLM.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head></head><label></label><figDesc>Instruction prompt tuning dataset The dataset was curated using inputs from a panel of clinicians. The exemplars came from LiveQA, MedicationQA and HealthSearchQA datasets. Further details are provided in Section 3.3.2.</figDesc><table><row><cell></cell><cell>3.2.</cell></row><row><cell></cell><cell>Usage</cell></row><row><cell>Application</cell><cell>The primary use is research on LLMs for medical question answering</cell></row><row><cell></cell><cell>including advancing accuracy, alignment methods, fairness, safety, and</cell></row><row><cell></cell><cell>equity research, and understanding limitations of current LLMs for</cell></row><row><cell></cell><cell>potential medical applications.</cell></row><row><cell></cell><cell>Data overview</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table A .</head><label>A</label><figDesc><ref type="bibr" target="#b2">3</ref> | Agreement with scientific and clinical consensus The results showed that the answers provided by the Flan-PaLM model were in agreement with the scientific consensus only 61.9% of the time, but this improved to 92.9% for the Med-PaLM model when compared to expert answers.TableA.4 | Possible extent of harm While 29.6% of the Flan-PaLM responses were judged as potentially leading to harm, this number dropped to 6.0% for Med-PaLM comparing favorably with clinician-generated answers (judged as potentially harmful in 6.5% of the cases) Table A.5 | Likelihood of harm from answers While 19.4% of the Flan-PaLM responses were judged as likely to lead to harm, this number dropped to 3.1% for Med-PaLM on par with clinician-generated answers which were also judged as likely to be harmful in 1.6% of the cases.Table A.6 | Evidence of comprehension, retrieval and reasoning capabilitiesThe results showed that the answers provided by the Flan-PaLM model exhibits comprehension 90.5% of the time, but this improved to 97.5% for the Med-PaLM. With regard to evidence of correct retrieval and reasoning of medical knowledge, we found that clinician answers scored 97.8% and 97.7% while Flan-PaLM only scored 76.3% and 85.7%, respectively while Med-PaLM reached 95.4% and 93.5%.Table A.7 | Evidence of incorrect comprehension, retrieval and reasoning capabilitiesThe results indicate Med-PaLM showed evidence of incorrect comprehension only 5.0% of the time.Table A.8 | Presence of inappropriate/incorrect content Clinician answers showed evidence of inappropriate/incorrect content in only 1.4% of the cases, compared to 16.1% for Flan-PaLM. Surprisingly, Med-PaLM seemed to further degrade performance, with 18.7% of the Med-PaLM answers judged to contain inappropriate or incorrect content.TableA.9 | Missing contents While Flan-PaLM answers were judged to miss important information 47.2% of the time, the number improved significantly for Med-PaLM with only 15.1% of the answers adjudged to have missing information, reducing the inferiority compared to clinicians whose answers were judged to have missing information in only 11.1% of the cases.Table A.10 | Possible bias Flan-PaLM answers were found to contain biased information in 7.9% of the cases. However, this number reduced to 0.7% for Med-PaLM, comparing favorably with experts whose answers were judged to contain evidence of bias in 1.4% of the cases.TableA.11 | Lay user assessment of answers with respect to capturing user intent Flan-PaLM answers were judged as directly addressing the user's question intent in 90.8% of cases. Using Med-PaLM this number improves to 94.0%, while clinician-generated answers were at 95.9%. TableA.12 | Lay user assessment of answers with respect to helpfulness While Flan-PaLM answers were judged to be helpful in only 59.6% of the cases, the number improved to 80.1% for Med-PaLM answers. However, this remained inferior to clinician answers which were judged to be helpful 90.8% of the time.We provide examples of some few-shot prompts used in the study in TableA.13, Table A.14, Table A.15, Table A.16, and Table A.17.</figDesc><table><row><cell cols="3">Answer Captures User Intent</cell><cell cols="2">Expert</cell><cell>Med-PaLM Flan-PaLM</cell></row><row><cell cols="6">Evidence of correct Comprehension, Retrieval, Reasoning Address Query 95.9 ? 1.7 No Comprehension Yes Does Not Address Query 4.1 ? 1.7</cell><cell>Expert 94.4 ? 2.0 2.3 ? 1.2 97.8 ? 1.2 5.6 ? 2.0</cell><cell>90.8 ? 2.1 Med-PaLM Flan-PaLM 2.6 ? 1.3 9.0 ? 2.5 97.5 ? 1.3 90.5 ? 2.5 9.2 ? 2.1</cell></row><row><cell>Retrieval</cell><cell>Yes No</cell><cell></cell><cell></cell><cell></cell><cell>97.8 ? 1.3 2.2 ? 1.2</cell><cell>? 1.6 4.6 ? 1.6</cell><cell>76.3 ? 3.7 23.7 ? 3.3</cell></row><row><cell>Reasoning</cell><cell cols="2">Yes No Helpfulness of the answer</cell><cell cols="2">Expert</cell><cell>97.7 ? 1.2 2.4 ? 1.2 Med-PaLM Flan-PaLM 93.5 ? 2.1 7.5 ? 2.1</cell><cell>85.7 ? 3.3 14.3 ? 3.2</cell></row><row><cell></cell><cell>Helpful</cell><cell></cell><cell cols="2">91.1 ? 2.3</cell><cell>80.3 ? 3.2</cell><cell>60.6 ? 4.5</cell></row><row><cell></cell><cell>Somewhat helpful</cell><cell></cell><cell cols="2">7.0 ? 2.2</cell><cell>16.1 ? 2.8</cell><cell>26.4 ? 3.8</cell></row><row><cell></cell><cell>Not helpful</cell><cell></cell><cell cols="2">2.0 ? 1.2</cell><cell>3.6 ? 1.6</cell><cell>13.0 ? 2.6</cell></row><row><cell cols="6">Evidence of Incorrect Comprehension, Retrieval, Reasoning Yes Comprehension No A.8 Few-shot prompt examples</cell><cell>Expert 2.3 ? 1.2 97.8 ? 1.1</cell><cell>Med-PaLM Flan-PaLM 5.0 ? 1.9 9.2 ? 2.2 95.0 ? 1.9 90.8 ? 2.2</cell></row><row><cell>Retrieval</cell><cell>No Yes</cell><cell></cell><cell></cell><cell></cell><cell>96.4 ? 1.6 3.6 ? 1.7</cell><cell>83.1 ? 3.3 16.9 ? 3.2</cell><cell>76.9 ? 3.8 23.1 ? 3.6</cell></row><row><cell>Reasoning</cell><cell>No Yes</cell><cell></cell><cell></cell><cell></cell><cell>97.9 ? 1.1 2.3 ? 1.0</cell><cell>89.9 ? 2.7 10.1 ? 2.7</cell><cell>85.7 ? 3.3 14.3 ? 3.3</cell></row><row><cell></cell><cell>Scientific Consensus</cell><cell cols="2">Expert</cell><cell cols="2">Med-PaLM Flan-PaLM</cell></row><row><cell cols="6">No Consensus Oppose to Consensus Inappropriate/incorrect Content 92.9 ? 2.3 2.2 ? 1.1 Expert 92.6 ? 2.1 -Med-PaLM Flan-PaLM 61.9 ? 4.7 19.0 ? 3.2 Aligned with Consensus 5.0 ? 1.9 7.4 ? 2.1 No 98.6 ? 0.9 81.3 ? 3.2 83.9 ? 2.9 19.1 ? 3.5 Yes, Little Clinical Significance 1.6 ? 0.8 8.1 ? 2.3 7.7 ? 2.0</cell></row><row><cell cols="2">Yes, Great Clinical Significance</cell><cell></cell><cell></cell><cell>-</cell><cell>10.7 ? 2.6</cell><cell>8.3 ? 2.4</cell></row><row><cell cols="2">Extent of Possible Harm</cell><cell></cell><cell></cell><cell cols="2">Expert</cell><cell>Med-PaLM Flan-PaLM</cell></row><row><cell cols="2">No Harm Missing Content</cell><cell></cell><cell cols="3">94.3 ? 2.0 Expert Med-PaLM Flan-PaLM 94.1 ? 1.9 70.3 ? 4.2</cell></row><row><cell cols="6">Moderate or Mild Harm Death, life-threatening injury, or severe harm No 88.9 ? 2.8 4.9 ? 1.8 1.1 ? 0.5 84.7 ? 3.0 4.3 ? 1.6 1.7 ? 0.9 52.4 ? 4.2 18.6 ? 3.4 11.0 ? 2.6 Yes, Little Clinical Significance 6.9 ? 1.6 8.9 ? 2.3 28.0 ? 3.5</cell></row><row><cell></cell><cell cols="2">Yes, Great Clinical Significance</cell><cell cols="2">4.2 ? 2.1</cell><cell>6.4 ? 2.1</cell><cell>19.6 ? 4.0</cell></row><row><cell cols="2">Extent of Possible Harm</cell><cell></cell><cell></cell><cell cols="2">Expert</cell><cell>Med-PaLM Flan-PaLM</cell></row><row><cell>No Harm</cell><cell>Possibility of Bias</cell><cell cols="2">Expert</cell><cell cols="2">94.3 ? 2.0 Med-PaLM Flan-PaLM 94.1 ? 1.9</cell><cell>70.3 ? 4.2</cell></row><row><cell cols="2">Moderate or Mild Harm No</cell><cell cols="2">98.6 ? 0.9</cell><cell cols="2">4.9 ? 1.8 99.2 ? 0.7</cell><cell>4.3 ? 1.6 92.1 ? 2.5</cell><cell>18.6 ? 3.4</cell></row><row><cell cols="6">Death, life-threatening injury, or severe harm 1.1 ? 0.5 Yes 1.5 ? 0.8 1.2 ? 0.6</cell><cell>1.7 ? 0.9 7.9 ? 2.5</cell><cell>11.0 ? 2.6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head></head><label></label><figDesc>Table A.18, Table A.19, Table A.20 and Table A.21.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table A .</head><label>A</label><figDesc>15 | PubMedQA (2019)  <ref type="bibr" target="#b33">[34]</ref> few-shot prompt examples.The following are multiple choice questions (with answers) about medical knowledge.Answer the following question given the context (reply with one of the options): Context: To describe the interstitial fluid (ISF) and plasma pharmacokinetics of meropenem in patients on continuous venovenous haemodiafiltration (CVVHDF).Answer the following question given the context (reply with one of the options): Context: Family caregivers of dementia patients are at increased risk of developing depression or anxiety. A multi-component program designed to mobilize support of family networks demonstrated effectiveness in decreasing depressive symptoms in caregivers. However, the impact of an intervention consisting solely of family meetings on depression and anxiety has not yet been evaluated. This study examines the preventive effects of family meetings for primary caregivers of community-dwelling dementia patients. A randomized multicenter trial was conducted among 192 primary caregivers of community dwelling dementia patients. Caregivers did not meet the diagnostic criteria for depressive or anxiety disorder at baseline. Participants were randomized to the family meetings intervention (n=96) or usual care (n=96) condition. The intervention consisted of two individual sessions and four family meetings which occurred once every 2 to 3 months for a year. Outcome measures after 12 months were the incidence of a clinical depressive or anxiety disorder and change in depressive and anxiety symptoms (primary outcomes), caregiver burden and quality of life (secondary outcomes). Intention-to-treat as well as per protocol analyses were performed. A substantial number of caregivers (72/192) developed a depressive or anxiety disorder within 12 months. The intervention was not superior to usual care either in reducing the risk of disorder onset (adjusted IRR 0.98; 95% CI 0.69 to 1.38) or in reducing depressive</figDesc><table><row><cell>This</cell></row><row><cell>was a prospective observational pharmacokinetic study. Meropenem (500 mg) was administered every 8 h. CVVHDF was</cell></row><row><cell>targeted as a 2-3 L/h exchange using a polyacrylonitrile filter with a surface area of 1.05 m2 and a blood flow rate of 200</cell></row><row><cell>mL/min. Serial blood (pre-and post-filter), filtrate/dialysate and ISF concentrations were measured on 2 days of treatment</cell></row><row><cell>(Profiles A and B). Subcutaneous tissue ISF concentrations were determined using microdialysis. A total of 384 samples were</cell></row><row><cell>collected. During Profile A, the comparative median (IQR) ISF and plasma peak concentrations were 13.6 (12.0-16.8) and</cell></row><row><cell>40.7 (36.6-45.6) mg/L and the trough concentrations were 2.6 (2.4-3.4) and 4.9 (3.5-5.0) mg/L, respectively. During Profile B,</cell></row><row><cell>the ISF trough concentrations increased by ?40%. Meropenem ISF penetration was estimated at 63% (60%-69%) and 69%</cell></row><row><cell>(65%-74%) for Profiles A and B, respectively, using comparative plasma and ISF AUCs. For Profile A, the plasma elimination</cell></row><row><cell>t1/2 was 3.7 (3.3-4.0) h, the volume of distribution was 0.35 (0.25-0.46) L/kg, the total clearance was 4.1 (4.1-4.8) L/h and the</cell></row><row><cell>CVVHDF clearance was 2.9 (2.7-3.1) L/h. Question: Are interstitial fluid concentrations of meropenem equivalent to plasma</cell></row><row><cell>concentrations in critically ill patients receiving continuous renal replacement therapy?</cell></row><row><cell>(A) Yes (B) No (C) Maybe</cell></row><row><cell>Answer:(B)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table A .</head><label>A</label><figDesc><ref type="bibr" target="#b16">17</ref> | MedicationQA (2017)<ref type="bibr" target="#b1">[2]</ref> few-shot prompt examples.You are a helpful medical assistant. Provide useful and scientifically-grounded explanation to justify the question statement.Question: what does vitamin d3 do? Answer: Vitamin D helps your body absorb calcium. Calcium is one of the main building blocks of bone. A lack of vitamin D can lead to bone diseases such as osteoporosis or rickets. Vitamin D also has a role your nerve, muscle, and immune systems.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This project was an extensive collaboration between many teams at <rs type="institution">Google Research and Deepmind</rs>. We thank <rs type="person">Michael Howell</rs>, <rs type="person">Cameron Chen</rs>, <rs type="person">Basil Mustafa</rs>, <rs type="person">David Fleet</rs>, <rs type="person">Fayruz Kibria</rs>, <rs type="person">Gordon Turner</rs>, <rs type="person">Lisa Lehmann</rs>, <rs type="person">Ivor Horn</rs>, <rs type="person">Maggie Shiels</rs>, <rs type="person">Shravya Shetty</rs>, <rs type="person">Jukka Zitting</rs>, <rs type="person">Evan Rappaport</rs>, <rs type="person">Lucy Marples</rs>, <rs type="person">Viknesh Sounderajah</rs>, <rs type="person">Ali Connell</rs>, <rs type="person">Jan Freyberg</rs>, <rs type="person">Cian Hughes</rs>, <rs type="person">Megan Jones-Bell</rs>, <rs type="person">Susan Thomas</rs>, <rs type="person">Martin Ho</rs>, <rs type="person">Sushant Prakash</rs>, <rs type="person">Bradley Green</rs>, <rs type="person">Ewa Dominowska</rs>, <rs type="person">Frederick Liu</rs>, <rs type="person">Xuezhi Wang</rs>, and <rs type="person">Dina Demner-Fushman</rs> (from the <rs type="funder">National Library of Medicine</rs>) for their valuable insights and feedback during our research. We are also grateful to <rs type="person">Karen DeSalvo</rs>, <rs type="person">Zoubin Ghahramani</rs>, <rs type="person">James Manyika</rs>, and <rs type="person">Jeff Dean</rs> for their support during the course of this project.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Hyperparameters and model selection</head><p>We performed instruction prompt tuning on Flan-PaLM 540B with a soft prompt length of 100 to produce Med-PaLM. We froze the rest of the model, and the embedding dimension is 18432 as in Chowdhery et al. <ref type="bibr" target="#b13">[14]</ref>, so this resulted in 1.84M trainable parameters. We randomly initialized the learnable parameters to be uniform over [-0.5, 0.5], following Lester et al. <ref type="bibr" target="#b44">[45]</ref>. We grid searched over learning rates in 0.001, 0.003, 0.01 with AdamW optimizer <ref type="bibr" target="#b54">[55]</ref> and a weight decay factor in {0.001, 0.00001}. We used a batch size of 32 across all runs. We ran training for 200 steps.</p><p>We performed model selection by asking a clinician to rank responses on several held-out HealthSearchQA, MedicationQA and LiveQA examples (not used for training or human evaluation), and chose the checkpoint that performed the best. We did this manual validation instead of computing some automated metric on a validation set, e.g. negative log-likelihood on held-out (question, answer) pairs, since in the large output space of natural language generations, these metrics may not correlate well with human judgements of actual model outputs. The model we chose for human evaluation had a learning rate of 0.003 and a weight decay factor of 0.00001.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Variation of results</head><p>Due to repeated stochastic decodes using temperature sampling, there is some expected variation in results with self-consistency. While it is impractical to run multiple experiments for all of our models across all the datasets used in this study, we repeat the evaluations on the MedQA dataset 4 times with our best performing model. The observed variance is 0.078 suggesting a high-degree of consistency in the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 MMLU ablations</head><p>We performed ablations comparing Flan-PaLM 540B model using the few-shot, chain-of-thought (CoT) and self-consistency prompting strategies on MMLU clinical topics <ref type="bibr" target="#b28">[29]</ref>. The results are summarized in Section A. <ref type="bibr" target="#b2">3</ref>. We observe that while for most topics, Flan-PaLM 540B with self-consistency obtains the best results, there are a couple of topics where standard few-shot or CoT prompting does better. Across these topics, Flan-PaLM 540B obtains state-of-the-art performance.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Scaling plots</head><p>We provide scaling plots comparing the PaLM and Flan-PaLM models using few-shot prompting on the MedQA and MedMCQA datasets in  The following are multiple choice questions (with answers) about medical knowledge.</p><p>Question: A 32-year-old woman with bipolar disorder visits her gynecologist because she believes she is pregnant. A urine pregnancy test is performed which confirms she is pregnant. She has mild bipolar disorder for which she takes lithium and admits that she has been taking it 'on and off' for 2 years now but has never had any symptoms or episodes of relapse. She says that she had not made contact with her psychiatrist for the past several months because she 'couldn't find any time. Question: Background: Aldosterone blockade reduces mortality and morbidity among patients with severe heart failure. We conducted a double-blind, placebo-controlled study evaluating the effect of eplerenone, a selective aldosterone blocker, on morbidity and mortality among patients with acute myocardial infarction complicated by left ventricular dysfunction and heart failure. Methods: Patients were randomly assigned to eplerenone (25 mg per day initially, titrated to a maximum of 50 mg per day; 3,319 patients) or placebo (3,313 patients) in addition to optimal medical therapy. The study continued until 1,012 deaths occurred. The primary endpoints were death from any cause, death from cardiovascular causes, hospitalization for heart failure, acute myocardial infarction, stroke, or ventricular arrhythmia. Results: During a mean follow-up of 16 months, there were 478 deaths in the eplerenone group and 554 deaths in the placebo group (relative risk, 0.85; 95 percent confidence interval, 0.75 to 0.96; p = 0.008). Of these deaths, 407 in the eplerenone group and 483 in the placebo group were attributed to cardiovascular causes (relative risk, 0.83; 95 percent confidence interval, 0.72 to 0.94; p = 0.005). The rate of the other primary endpoint, death from cardiovascular causes, or hospitalization for cardiovascular events was reduced by eplerenone (relative risk, 0.87; 95 percent confidence interval, 0.79 to 0.95; p = 0.002), as was the secondary endpoint of death from any cause or any hospitalization (relative risk, 0.92; 95 percent confidence interval, 0.86 to 0.98; p = 0.02). There was also a reduction in the rate of sudden death from cardiac causes (relative risk, 0.79; 95 percent confidence interval, 0.64 to 0.97; p = 0.03). The rate of serious hyperkalemia was 5.5 percent in the eplerenone group and 3.9 percent in the placebo group (p = 0.002), whereas the rate of hypokalemia was 8.4 percent in the eplerenone group and 13.1 percent in the placebo group (p &lt; 0.001). Which of the following statements represents the most accurate interpretation of the results from the aforementioned clinical trial? (A) There was no significant difference in the incidence of hyperkalemia between trial arms. (B) There was no significant difference in the rate of sudden cardiac death between trial arms. (C) Eplerenone, when added to optimal medical therapy, decreases all cause mortality in patients with left ventricular dysfunction following myocardial infarction.  Question: how to treat eczema? Complete Answer: Treatment of eczema may start with the avoidance of scratching and practicing regular moisturizing with emollient creams to prevent the skin becoming dry. Self-care is important, for example avoiding triggers. If certain fabrics irritate your skin, avoid wearing these and stick to soft, fine-weave clothing or natural materials such as cotton. If heat aggravates your eczema, keep the rooms in your home cool, especially the bedroom. Avoid using soaps or detergents that may affect your skin -use soap substitutes instead. If these don't help, your health care provider might suggest medicated creams that control itching and help repair skin. Some foods, such as eggs and cows' milk, can trigger eczema symptoms. But you should not make significant changes to your diet to prevent eczema without first speaking to a doctor about the risks and benefits. Doctors may also prescribe medications for treating eczema. For example emollients (moisturizers) -used every day to stop the skin becoming dry. Topical corticosteroids -creams and ointments used to reduce swelling and redness during flare-ups. Topical pimecrolimus or tacrolimus for eczema in sensitive sites not responding to simpler treatment. Antihistamines for severe itching.</p><p>Table <ref type="table">A</ref>.18 | MedQA (2021) <ref type="bibr" target="#b32">[33]</ref> chain-of-thought prompt examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instructions:</head><p>The following are multiple-choice questions about medical knowledge. Solve them in a step-by-step fashion. Output a single option as the final answer.</p><p>Question: A 22-year-old male marathon runner presents the office with the complaint of right-sided rib pain when he runs long distances. Physical examination reveals normal heart and lung findings and an exhalation dysfunction at ribs 4-5 on the right. Which of the following muscles or muscle groups will be most useful in correcting this dysfunction utilizing a direct method? (A) anterior scalene (B) latissimus dorsi (C) pectoralis minor (D) quadratus lumborum Explanation: We refer to Wikipedia articles on medicine for help. Among the options, only pectoralis minor muscle origins from the outer surfaces of the 3rd to 5th ribs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer: (C)</head><p>Question: A 36-year-old male presents to the office with a 3-week history of low back pain. He denies any recent trauma but says that he climbs in and out of his truck numerous times a day for his job. Question: A 44-year-old man comes to the office because of a 3-day history of sore throat, nonproductive cough, runny nose, and frontal headache. He says the headache is worse in the morning and ibuprofen does provide some relief. He has not had shortness of breath. Medical history is unremarkable. He takes no medications other than the ibuprofen for pain. Vital signs are temperature 37.4?C (99.4?F), pulse 88/min, respirations 18/min, and blood pressure 120/84 mm Hg. Examination of the nares shows erythematous mucous membranes. Examination of the throat shows erythema and follicular lymphoid hyperplasia on the posterior oropharynx. There is no palpable cervical adenopathy. Lungs are clear to auscultation. Which of the following is the most likely cause of this patient's symptoms? (A) Allergic rhinitis (B) Epstein-Barr virus (C) Mycoplasma pneumonia (D) Rhinovirus Explanation: We refer to Wikipedia articles on medicine for help. The symptoms, especially the headache, suggest that the most likely cause is Rhinovirus. Epstein-Barr virus will cause swollen lymph nodes but there is no palpable cervical adenopathy. Lungs are clear to auscultation suggests it's not Mycoplasma pneumonia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer: (D)</head><p>Question: A previously healthy 32-year-old woman comes to the physician 8 months after her husband was killed in a car crash. Since that time, she has had a decreased appetite and difficulty falling asleep. She states that she is often sad and cries frequently. She has been rechecking the door lock five times before leaving her house and has to count exactly five pieces of toilet paper before she uses it. She says that she has always been a perfectionist but these urges and rituals are new. Pharmacotherapy should be targeted to which of the following neurotransmitters? (A) Dopamine (B) Glutamate (C) Norepinephrine (D) Serotonin Explanation: We refer to Wikipedia articles on medicine for help. The patient feels sad and among the options, only Dopamine and Serotonin can help increase positive emotions. Serotonin also affects digestion and metabolism, which can help the patient's decreased appetite and sleep difficulty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer: (D)</head><p>Question: A 42-year-old man comes to the office for preoperative evaluation prior to undergoing adrenalectomy scheduled in 2 weeks. One month ago, he received care in the emergency department for pain over his right flank following a motor vehicle collision. At that time, blood pressure was 160/100 mm Hg and CT scan of the abdomen showed an incidental 10-cm left adrenal mass. Results of laboratory studies, including complete blood count, serum electrolyte concentrations, and liver function tests, were within the reference ranges. The patient otherwise had been healthy and had never been told that he had elevated blood pressure. He takes no medications. A follow-up visit in the office 2 weeks ago disclosed elevated urinary normetanephrine and metanephrine and plasma aldosterone concentrations. The patient was referred to a surgeon, who recommended the adrenalectomy. Today, vital signs are temperature 36.6?C (97.9?F), pulse 100/min, respirations 14/min, and blood pressure 170/95 mm Hg. Physical examination discloses no significant findings. Initial preoperative preparation should include treatment with which of the following? (A) Labetalol (B) A loading dose of potassium chloride (C) Nifedipine (D) Phenoxybenzamine Explanation: We refer to Wikipedia articles on medicine for help. The symptoms and the adrenal mass suggested pheochromocytoma, and the blood pressure indicates hypertension. Phenoxybenzamine is used to treat hypertension caused by pheochromocytoma. Answer: (D) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instructions:</head><p>The following are multiple-choice questions about medical knowledge. Solve them in a step-by-step fashion or by referring to Wikipedia articles on medicine for help. Output a single option as final answer.</p><p>Question: Maximum increase in prolactin level is caused by: (A) Risperidone (B) Clozapine (C) Olanzapine (D) Aripiprazole Explanation: Clozapine generally does not raise prolactin levels. Atypicals such as olanzapine and aripiprazole cause small if no elevation. Risperidone is known to result in a sustained elevated prolactin level. Therefore risperidone is likely to cause the maximum increase in prolactin level. Answer: (A)  The expected proportion of individuals who carry the b allele but are not expected to develop the cancer equals to the frequency of heterozygous allele in the given population. According to the Hardy-Weinberg equation p?2 + 2pq + q?2 = 1, where p is the frequency of dominant allele frequency, q is the frequency of recessive allele frequency, p?2 is the frequency of the homozygous dominant allele, q?2 is the frequency of the recessive allele, and 2pq is the frequency of the heterozygous allele. Given that q?2=1/400, hence, q=0.05 and p=1-q=0.95. The frequency of the heterozygous allele is 2pq=2*0.05*0.95=38/400.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer: (D)</head><p>Question: A high school science teacher fills a 1 liter bottle with pure nitrogen and seals the lid. The pressure is 1.70 atm, and the room temperature is 25?C. Which two variables will both increase the pressure of the system, if all other variables are held constant? (A) Decreasing volume, decreasing temperature (B) Increasing temperature, increasing volume (C) Increasing temperature, increasing moles of gas (D) Decreasing moles of gas, increasing volume Explanation: According to the ideal gas law, PV = nRT (P = pressure, V = volume, n = number of moles, R = gas constant, T = temperature). Hence, increasing both temperature (T) and moles of gas (n), while other variables stay constant, will indeed increase the pressure of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer: (C)</head><p>Question: A 22-year-old male marathon runner presents to the office with the complaint of right-sided rib pain when he runs long distances. Physical examination reveals normal heart and lung findings and an exhalation dysfunction at ribs 4-5 on the right. Which of the following muscles or muscle groups will be most useful in correcting this dysfunction utilizing a direct method? (A) anterior scalene (B) latissimus dorsi (C) pectoralis minor (D) quadratus lumborum Explanation: All of the muscles have an insertion on the rib cage; however only one has an insertion at ribs 4-5 and could be responsible for right-sided rib pain: pectoralis minor. Pectoralis minor inserts to the costal cartilage of the anterior third to fifth ribs. Answer: (C)</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Overview of the medical question answering task at TREC 2017 LiveQA</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Agichtein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pinter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TREC</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bridging the Gap Between Consumers&apos; Medication Questions and Trusted Answers</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mrabet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Goodwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Shooshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MedInfo</title>
		<imprint>
			<biblScope unit="page" from="25" to="29" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hegselmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.12689</idno>
		<title level="m">Large Language Models are Zero-Shot Clinical Information Extractors</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Pathways: Asynchronous distributed dataflow for ML</title>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hurt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Machine Learning and Systems</title>
		<meeting>Machine Learning and Systems</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="430" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><surname>Scibert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.10676</idno>
		<title level="m">A pretrained language model for scientific text</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Health literacy interventions and outcomes: an updated systematic review</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Berkman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Sheridan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Viera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Crotty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brasure</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Lohr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Harden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evidence report/technology assessment</title>
		<imprint>
			<biblScope unit="page" from="1" to="941" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Large Scale Autoregressive Language Modeling with Mesh-Tensorflow version 1.0. If you use this software, please cite it using these metadata</title>
		<author>
			<persName><forename type="first">S</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Leahy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><surname>Gpt-Neo</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.5297715</idno>
		<ptr target="https://doi.org/10.5281/zenodo.5297715" />
		<imprint>
			<date type="published" when="2021-03">Mar. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Best practices for developing and validating scales for health, social, and behavioral research: a primer</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">O</forename><surname>Boateng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Neilands</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Frongillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Melgar-Qui?onez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in public health</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">149</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">E</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Crfm</forename><surname>Stanford</surname></persName>
		</author>
		<ptr target="https://hai.stanford.edu/news/stanford-crfm-introduces-pubmedgpt-27b.2022" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">On the opportunities and risks of foundation models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Von Arx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bohg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brunskill</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07258</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<ptr target="https://crfm.stanford.edu/2022/11/17/helm.html.2022" />
		<title level="m">Language Models are Changing AI: The Need for Holistic Evaluation</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ethical machine learning in healthcare</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pierson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ferryman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual review of biomedical data science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="123" to="144" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02311</idno>
		<title level="m">Scaling language modeling with pathways</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Scaling instruction-finetuned language models</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brahma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.11416</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A benchmark for information-seeking question answering in typologically diverse languages</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Nikolaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">A</forename><surname>Tydi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="454" to="470" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.14168</idno>
		<title level="m">Training verifiers to solve math word problems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The Algorithmic Leviathan: Arbitrariness, Fairness, and Opportunity in Algorithmic Decision-Making Systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Creel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hellman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Canadian Journal of Philosophy</title>
		<imprint>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Glam: Efficient scaling of language models with mixture-of</title>
		<author>
			<persName><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5547" to="5569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Health inequities and the inappropriate use of race in nephrology</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Eneanya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Boulware</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Ford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Morales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Reese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Thorpe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Nephrology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="84" to="94" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep learning-enabled medical computer vision</title>
		<author>
			<persName><forename type="first">A</forename><surname>Esteva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mottaghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Topol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NPJ digital medicine</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Khetan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sacaleanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><surname>Chard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.04191</idno>
		<title level="m">Clinical Health-Aware Reasoning Across Dimensions for Text Generation Models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Counterfactual fairness in text classification through robustness in</title>
		<author>
			<persName><forename type="first">S</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Perot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Limtiaco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Taly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beutel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society</title>
		<meeting>the 2019 AAAI/ACM Conference on AI, Ethics, and Society</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="219" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Datasheets for datasets</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morgenstern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vecchione</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Iii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Crawford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="86" to="92" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Domain-specific language model pretraining for biomedical natural language processing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Usuyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Poon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computing for Healthcare (HEALTH)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Ppt: Pre-trained prompt tuning for few-shot learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.04332</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Ethics and governance of artificial intelligence for health</title>
		<author>
			<persName><forename type="first">W</forename><surname>Guidance</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>World Health Organization</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Ptr: Prompt tuning with rules for text classification</title>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>AI Open</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.03300</idno>
		<title level="m">Measuring massive multitask language understanding</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D L</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.15556</idno>
		<title level="m">Training Compute-Optimal Large Language Models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ajith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pauloski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duede</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Malamud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Magoulas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><surname>Scholarbert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.11342</idno>
		<title level="m">Bigger is Not Always Better</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Moving beyond &quot;algorithmic bias is a data problem</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hooker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Patterns</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">100241</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">What disease does this patient have? a large-scale open domain question answering dataset from medical exams</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Oufattole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">6421</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Q</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><surname>Pubmedqa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.06146</idno>
		<title level="m">A dataset for biomedical research question answering</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><surname>Triviaqa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.03551</idno>
		<title level="m">A large scale distantly supervised challenge dataset for reading comprehension</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Language models (mostly) know what they know</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Conerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Drain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Schiefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>Dodds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dassarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tran-Johnson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.05221</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.08361</idno>
		<title level="m">Scaling laws for neural language models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Identifying credible sources of health information in social media: Principles and attributes</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Kington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arnesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><forename type="middle">S</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Curry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lazer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Villarruel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NAM perspectives</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Algorithmic monoculture and social welfare</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raghavan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<date type="published" when="2021">2018340118. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Iwasawa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.11916</idno>
		<title level="m">Large Language Models are Zero-Shot Reasoners</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Considering the possibilities and pitfalls of Generative Pre-trained Transformer 3 (GPT-3) in healthcare delivery</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Korngiebel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NPJ Digital Medicine</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Lakkaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Slack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.01875</idno>
		<title level="m">Rethinking Explainability as a Dialogue: A Practitioner&apos;s Perspective</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Matthewson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Tessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02329</idno>
		<title level="m">Can language models learn from explanations in context? arXiv preprint</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">BioBERT: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1234" to="1240" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">The power of scale for parameter-efficient prompt tuning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08691</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Pretrained language models for biomedical and clinical tasks: Understanding and extending the state-of-the</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Clinical Natural Language Processing Workshop</title>
		<meeting>the 3rd Clinical Natural Language Processing Workshop</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="146" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Solving quantitative reasoning problems with language models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramasesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Slone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Schlag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gutman-Solo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.14858</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Prefix-tuning: Optimizing continuous prompts for generation</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00190</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Soylu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.09110</idno>
		<title level="m">Holistic evaluation of language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Li?vin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Hother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.08143</idno>
		<title level="m">Can large language models reason about medical questions? arXiv preprint</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Evans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.14334</idno>
		<title level="m">Teaching Models to Express Their Uncertainty in Words</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.13586</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.10385</idno>
		<title level="m">GPT understands, too</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">The medical algorithmic audit</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Mccradden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Denniston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Oakden-Rayner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Lancet Digital Health</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05101</idno>
		<title level="m">Decoupled weight decay regularization</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">BioGPT: generative pre-trained transformer for biomedical text generation and mining</title>
		<author>
			<persName><forename type="first">R</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Briefings in Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Mandavilli</surname></persName>
		</author>
		<ptr target="https://www.nytimes.com/2021/06/02/health/jama-racism-bauchner.html.2021" />
		<title level="m">Medical Journals Blind to Racism as Health Crisis, Critics Say</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Matheny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Israni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whicher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Artificial Intelligence in Health Care: The Hope, the Hype, the Promise, the Peril</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zaldivar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vasserman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Spitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Raji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
		<title level="m">Model cards for model reporting in Proceedings of the conference on fairness, accountability, and transparency</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="220" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Scale development: ten main limitations and recommendations to improve future research practices</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">F</forename><surname>Morgado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Meireles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Ferreira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psicologia: Reflexao e Critica</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gur-Ari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.00114</idno>
		<title level="m">Show your work: Scratchpads for intermediate computation with language models</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">The Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H O</forename><surname>Of Science</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Policy</surname></persName>
		</author>
		<ptr target="https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf.2022" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ray</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.02155</idno>
		<title level="m">Training language models to follow instructions with human feedback</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Umapathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sankarasubbu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical domain Question Answering in Conference on Health, Inference, and Learning</title>
		<imprint>
			<biblScope unit="page" from="248" to="260" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Pampari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><surname>Emrqa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.00732</idno>
		<title level="m">A large corpus for question answering on electronic medical records</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">DARE: Data augmented relation extraction with gpt-2</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Papanikolaou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pierleoni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.13845</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation in</title>
		<author>
			<persName><forename type="first">K</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Perturbation sensitivity analysis to detect unintended model biases</title>
		<author>
			<persName><forename type="first">V</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.04210</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aslanides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.11446</idno>
		<title level="m">Scaling language models: Methods, analysis &amp; insights from training gopher</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Closing the AI accountability gap: Defining an end-to-end framework for internal algorithmic</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Raji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Smith-Loud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Theron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barnes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 conference on fairness, accountability, and transparency</title>
		<meeting>the 2020 conference on fairness, accountability, and transparency</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="33" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Rostamzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mincu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wilcox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pushkarna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schrouff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Amironesei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Moorosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Heller</surname></persName>
		</author>
		<author>
			<persName><surname>Healthsheet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.13028</idno>
		<title level="m">Development of a Transparency Artifact for Health Datasets</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ili?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hesslow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Castagn?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yvon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gall?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.05100</idno>
		<title level="m">A 176B-Parameter Open-Access Multilingual Language Model</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Expert discussions improve comprehension of difficult cases in medical image assessment</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schaekermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sayres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI conference on human factors in computing systems</title>
		<meeting>the 2020 CHI conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Operationalizing and Implementing Pretrained, Large Artificial Intelligence Linguistic Models in the US Health Care System: Outlook of Generative Pretrained Transformer 3 (GPT-3) as a Service Model</title>
		<author>
			<persName><forename type="first">E</forename><surname>Sezgin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sirrianni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Linwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMIR Medical Informatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">32875</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bakhturina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Patwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shoeybi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mani</surname></persName>
		</author>
		<author>
			<persName><surname>Biomegatron</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.06060</idno>
		<title level="m">Larger biomedical domain language model</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Development of the Patient Education Materials Assessment Tool (PEMAT): a new measure of understandability and actionability for print and audiovisual patient information</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Shoemaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Patient education and counseling</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="395" to="403" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A M</forename><surname>Shoeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garriga-Alonso</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.04615</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Scialom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hartshorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Saravia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Poulton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kerkez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stojnic</surname></persName>
		</author>
		<author>
			<persName><surname>Galactica</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.09085</idno>
		<title level="m">A Large Language Model for Science</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>De Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.08239</idno>
		<title level="m">Language models for dialog applications</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Use of deep learning to develop continuous-risk models for adverse event prediction from electronic health records</title>
		<author>
			<persName><forename type="first">N</forename><surname>Toma?ev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mottram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zielinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Askham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saraiva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Magliulo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Protocols</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="2765" to="2787" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Dusenberry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Collier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Mariet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.07411</idno>
		<title level="m">Towards reliability using pretrained large model extensions</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">An overview of the BIOASQ large-scale biomedical semantic indexing and question answering competition</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Balikas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zschunke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Alvers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Petridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Polychronopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Hidden in plain sight-reconsidering the use of race correction in clinical algorithms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Jones</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Measuring harm in healthcare: optimizing adverse event review</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Walsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Harik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Mazor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Perfetto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Anatchkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Biggins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Schoettker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Firneno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Klugman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical care</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page">436</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.10001</idno>
		<title level="m">Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.11171</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.01652</idno>
		<title level="m">Finetuned language models are zero-shot learners</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.07682</idno>
		<title level="m">Emergent abilities of large language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Chain of thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.11903</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Ethical and social risks of harm from language models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Weidinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rauh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Balle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kasirzadeh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.04359</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">The reliability of AHRQ Common Format Harm Scales in rating patient safety events</title>
		<author>
			<persName><forename type="first">T</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Szekendi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pavkovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Clevenger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cerese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of patient safety</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="52" to="59" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.09338</idno>
		<title level="m">Deep bidirectional languageknowledge graph pretraining</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><surname>Linkbert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.15827</idno>
		<title level="m">Pretraining Language Models with Document Links</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">S</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Seo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.03029</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">Retrieval of Soft Prompt Enhances Zero-Shot Task Generalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Predicting conversion to wet age-related macular degeneration using deep learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Spitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Winkens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Obika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Askham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lukic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huemer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fasler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="892" to="899" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abdalla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<title level="m">Hurtful words: quantifying biases in clinical contextual word embeddings in proceedings of the ACM Conference on Health, Inference, and Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="110" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">OPT: Open pre-trained transformer language models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dewan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">V</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.01068</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sch?rli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.10625</idno>
		<title level="m">Least-to-Most Prompting Enables Complex Reasoning in Large Language Models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
