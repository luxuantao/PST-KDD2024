<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Techniques for Debugging Parallel with Flowback Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jong-Deok</forename><surname>Choi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Barton</forename><forename type="middle">P</forename><surname>Miller</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><forename type="middle">H B</forename><surname>Netzer</surname></persName>
						</author>
						<author>
							<persName><forename type="first">J.-D</forename><surname>Choi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arthur</forename><forename type="middle">Conan</forename><surname>Doyle</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">IBM Thomas J. Watson Research Center</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Wisconsin</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Techniques for Debugging Parallel with Flowback Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CA7B8C9538CDDD5247BAC8D28D4F09CA</idno>
					<note type="submission">Received August 1988; revised February 1990, October 1990, and February 1991; accepted March 1991</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Debugging</term>
					<term>flowback analysis</term>
					<term>incremental tracing</term>
					<term>parallel program</term>
					<term>program dependence graph</term>
					<term>semantic analysls</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In solving a problem of this sort, the grand thing is to be able to reason backward This is a very useful accomplishment, and a very easy one, but people do not practise it much In the everyday affairs of life it is more useful to reason forward, and so the other comes to be neglected. There are fifty who can reason synthetically for one who can reason analytically, "Let me see if I can make It clearer. Most people, if you describe a train of events to them, will tell you what the result would be, They can put those events together in their mmds, and argue from them that something will come to pass. There are few people, however, who, if told them a result, would be able to evolve from their own inner consciousness what the steps were which led up to that result. This power is what I mean when I talk of reasoning backward, or analytically. " Sherlock Holmes in "A Study rn Scarlet"</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Programs</head><p>Flowback analysis is a powerful technique for debugging programs. It allows the programmer to examine dynamic dependence in a program's execution history without having to reexecute the program. The goal is to present to the programmer a graphical view of the dynamic program dependence.</p><p>We are building a system, called PPD, that performs flowback analysis while keeping the execution time overhead low. We also extend the semantics of flowback analysis to parallel programs. This paper describes details of the graphs and algorithms needed to implement efficient flowback analysis for parallel programs. Execution-time overhead is kept low by recording only a small amount of trace during a program's execution. We use semantic analysis and a technique called incremental tracing to keep the time and space overhead low. As part of the semantic analysis, PPD uses a static program dependence graph structure that reduces the amount of work done at compile time and takes advantage of the dynamic information produced during execution time. Parallel programs have been accommodated in two ways. First, the flowback dependence can span process boundaries; that is, the most recent modification to a variable might be traced to a different process than that one that contains the current reference. The static dynamic program dependence graphs of the individual processes are tied together with synchronization and data dependence information to form complete graphs that represent the entire program.</p><p>Second, our algorithms will detect potential data-race conditions in the access to shared variables. The programmer can be directed to the cause of the race condition. PPD is currently being implemented for the C programming language on a Sequent Symmetry shared-memory multiprocessor. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preparatory Phase</head><p>Figure <ref type="figure">1</ref> shows the preparatory phase, during which the Compiler/Linker produces, along with the object code, the following:</p><p>( </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Execution Phase</head><p>The object code plays the major role in the execution phase.  </p><formula xml:id="formula_0">: a -(A[i] -b); S7: b -A[j]; s8: A[k] -B[l]+a+b; [u: IUSE IM: IMOD ~: data dependence edge ------------q : linking edge ru i A b j 1 B k L i 1 IM a b A Fig. 7</formula><p>. Data dependence graph with array and linking edges (control block Gin Figure <ref type="figure">4</ref>).</p><p>the control block. We also insert an entry if the first reference to the array in the control block is a definition of an element, in anticipation of a subsequent use of the array.</p><p>A read from an array element is handled identically except that a select node is created to represent the read. For example, the select node above node " S7 :B" in Figure <ref type="figure">7</ref> represents the array access "Aljl" on the right-hand side of statement s7. This select node has an incoming data dependence edge from the index node and an incoming linking edge from node "s6:A", the most recent modification of array "A" in the control block.   L@: ""k @ -b -----..  ------+-1 ; -. <ref type="figure">----t-+-;-7</ref> E-POINTERS Fig. <ref type="figure">14</ref>, LOG with a back pointer for each e-block type might be accessed by more than one e-block, the list of e-blocks that contain the variable in their IMOD sets. We call the list the e-block table. The e-block table in Figure <ref type="figure">14</ref> shows the list of e-blocks for three variables:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>~~-</head><p>"gI", "gZ", and "g3". Figure <ref type="figure">14</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Arrays and the Log</head><p>For an e-block with array accesses, it is not possible to compute IUSE and IMOD sets that contain only those array elements that are actually accessed in the e-block. One approach is to generate a log entry for the entire array even if only a few array elements are accessed. A second approach is simply to trace every array access. However, both approaches can potentially generate a large amount of traces during execution.</p><p>Our solution to this problem is as follows:</p><p>We distinguish two types of array accesses: systematic accesses and random accesses. We say there is a systematic access to an array if the array is accessed in a loop and the array index has a possibly transitive data dependence on the loop control variable.</p><p>With a systematic access, we regard the entire array as accessed and generate a log entry (as usual) for the entire array.</p><p>We regard all of the other types of accesses to arrays as random accesses and generate a special log entry for the array index and the accessed value (read or updated value) of the array element at the time the access is made.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">PARALLEL PROGRAMS AND FLOWBACK ANALYSIS</head><p>The discussion so far has described mechanisms to implement efficient flowback analysis for sequential programs.</p><p>In this section we discuss the mechanisms for extending flowback analysis to parallel programs.</p><p>For parallel pro~ams, data dependence may exist across process boundaries. Locating such data dependence involves constructing an abstraction of the dynamic graph that contains the events belonging to all processes and then ordering the events in this graph.</p><p>With additional logging of shared variables, the incremental tracing scheme described in Section 5 can then be used to establish dependence between processes. In addition, potential data races in the program execution can be detected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Parallel Dynamic Graph and Ordering Concurrent Events</head><p>To A synchronization edge from one node to another indicates that the first synchronization operation executed before the second. An internal edge abstracts out all events (belonging to the same process) that executed between the synchronization operations connected by the edge. For example,</p><p>in Figure <ref type="figure">15</ref> all of the events of process PI that executed before event nl, ~also executed before all those events of process Pz that executed after event nz, ~. The synchronization edge between nl, ~and nz, ~can be viewed as a generalized flow edge that spans the two processes.</p><p>We now describe how to construct synchronization edges for programs that use semaphores. Other synchronization primitives (such as messages, rendezvous, etc.) can also be handled <ref type="bibr">[10]</ref>. In general, we construct a synchronization edge between two nodes if we can identify the temporal ordering between them. We say that the source node of an edge is the node connected to the tail of the edge, and the sink node of an edge is the node connected to the head of the edge.</p><p>Semaphore operations, such as P and V, are used in controlling accesses to shared resources by either acquiring resources (through a P operation) or releasing resources (through a V operation). We construct a synchronization edge from the node representing each V operation to the node representing some P operation on the same semaphore. Each V operation, which releases resources, is paired with the P operation that acquires those released resources.</p><p>There are two cases to be considered. The first case is where the second process tries to acquire the resources before the first process releases them;</p><p>the second process thus blocks on the P operation until the V operation of the first process. The second case is where the first process releases the resources before the second process tries to acquire them; the second process does not block on the P operation in this case. In both cases, we define a source node for the V operation and a sink node for the corresponding P operation. many operations on the given semaphore have previously been issued. The semaphore operations can easily be paired and the synchronization edges constructed from these log entries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Ordering</head><p>Events.</p><p>In the parallel dynamic graph, each internal edge represents the set of events bounded by the surrounding synchronization operations.</p><p>The order in which two events executed can be determined if there is a path between the two internal edges that represent those events (if no such path exists, then the actual execution order cannot always be determined).</p><p>We partially order the nodes and edges of the parallel dynamic graph by defining the happened-before relation [27], + , as follows:</p><p>(1) For any two nodes nl and nz of the parallel dynamic graph, nl -nz is true if nz is reachable from nl by following any sequence of internal and synchronization edges.</p><p>(2) For two edges el and ez, el + ez is true if nl + nz is true where nl is the sink node of the edge el, and nz is the source node of the edge ez. This dependence is located by finding the event that assigned the value to "SV" that was read. This event is the one that wrote "SV" that is most recently ordered before the read by the happened-before relation.</p><p>To locate this write event, the latest edge in each process that happened before the edge containing the read is located. These edges give a boundary beyond which all events executed concurrently with or after the read event.</p><p>Each process in the parallel graph is then scanned backward from this boundary to find an edge that modified "SV".</p><p>The ordering of all such write events is examined to determine which one executed last. A data dependence can then be drawn from this last event to the read event. A unique write event is guaranteed to be found if no data races involving "SV" exist (unless, of course, "SV" was uninitialized). Figure <ref type="figure">16</ref> shows an example of a parallel graph in which a shared variable </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Fig. 1. Preparatory phase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 9 ,-</head><label>9</label><figDesc>Fig.9, Data dependence graphs for control blocks A and B of Figure4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>to the location of the bug. An easier way to locate a bug is to track the events backward from the error to the point at which the</figDesc><table><row><cell cols="2">placing detected</cell><cell cols="4">breakpoints error.</cell><cell cols="4">The problem</cell><cell>is that</cell><cell>there</cell><cell>is a no way</cell><cell>to know</cell><cell>what</cell><cell>errors</cell></row><row><cell>will</cell><cell cols="4">be detected</cell><cell></cell><cell cols="3">before</cell><cell>the execution</cell><cell>of the program;</cell><cell>either</cell><cell>the user has to</cell></row><row><cell cols="10">bug caused the error. generate a trace of every Flowback event</cell><cell>analysis so that</cell><cell>tracks events in such a way. The the traces will not lack anything</cell></row><row><cell cols="3">programmer important</cell><cell cols="6">sees, either when an error</cell><cell>forward is detected,</cell><cell>or backward, or the user has to reexecute how information</cell><cell>flowed a modified</cell></row><row><cell cols="2">through program</cell><cell cols="8">the program that generates to produce events of interest. the necessary traces</cell><cell>Using flo whack analysis, after an error is detected.</cell></row><row><cell cols="5">the programmer Tracing every</cell><cell></cell><cell cols="4">can more easily event is expensive</cell><cell>locate the bugs that led to the observed because of unacceptable overhead and is</cell></row><row><cell>errors. most</cell><cell cols="3">often</cell><cell cols="4">impractical</cell><cell></cell><cell>for parallel</cell><cell>programs</cell><cell>because</cell><cell>of the distortions</cell><cell>that</cell></row><row><cell cols="8">Parallel the debugger programming would</cell><cell cols="2">offers challenges introduce in the interaction beyond</cell><cell>sequential pattern</cell><cell>programming between processes.</cell></row><row><cell cols="4">that complicate Reexecution</cell><cell cols="6">the problem is impractical</cell><cell>of debugging. for programs</cell><cell>First, it is difficult that lack reproducibility,</cell><cell>to order events as is often</cell></row><row><cell cols="8">occurring the case with in parallel parallel</cell><cell cols="2">programs. programs.</cell><cell>The ordering</cell><cell>of the events during</cell><cell>program</cell></row><row><cell cols="10">execution we use incremental is crucial for seeing causal relationships tracing to reduce the above</cell><cell>between difficulties.</cell><cell>the events (and, The main idea</cell></row><row><cell cols="10">therefore, of incremental the cause of errors). tracing is to generate Second, parallel coarse-grained programs</cell><cell>are often nondeter -traces, called the log,</cell></row><row><cell>ministic. during</cell><cell></cell><cell cols="8">Such nondeterminism program execution.</cell><cell>Then,</cell><cell>often during</cell><cell>makes the interactive it difficult</cell><cell>to reexecut e the portion of the debug-</cell></row><row><cell>program ging</cell><cell cols="9">for debugging session, we use the coarse purposes.</cell><cell>Third, traces</cell><cell>interactions and other compiler-generated between</cell><cell>cooperating informa-</cell></row><row><cell cols="10">processes tion to produce in a multiprocessor incrementally</cell><cell>system the fine-grained are frequent, traces</cell><cell>and these accesses to needed to do flowback</cell></row><row><cell cols="5">shared variables analysis. This</cell><cell></cell><cell cols="4">can occur without method transfers</cell><cell>the proper synchronization. execution-time costs into</cell><cell>PPD not only compile time and</cell></row><row><cell cols="2">performs debug</cell><cell cols="8">efficient time. At compile flowback</cell><cell>analysis time we use semantic for sequential analyses, programs, such as int,erprocedu but also helps</cell><cell>-</cell></row><row><cell cols="10">address the problems ral analysis and data-flow of debugging analysis,</cell><cell>parallel to help reduce programs.</cell><cell>the amount</cell><cell>of information</cell></row><row><cell cols="10">Debugging In this paper we address the class of parallel is a major step in developing a program, programs that needs to be generated during program execution.</cell><cell>since it is rare that a that use explicit At debug time we</cell></row><row><cell cols="10">program synchronization amortize the cost of generating initially behaves the way the programmer primitives (such as semaphores, the fine traces over the interactive intends. monitors,</cell><cell>Whereas or Ada ren-most debugging</cell></row><row><cell cols="10">programmers dezvous) and explicit have experience (and dynamic) debugging process creation. sequential session. The traces are generated as the programmer</cell><cell>programs Although asks about</cell><cell>and have de-we are not dependence</cell></row><row><cell cols="8">veloped satisfactory addressing automatic in the program.</cell><cell cols="2">debugging parallelism,</cell><cell>strategies, many of our techniques debugging</cell><cell>parallel might be extended programs</cell><cell>has</cell></row><row><cell cols="9">proved more difficult. to such systems. Our we divide debugging</cell><cell>The Parallel current algorithms Program into three phases: preparatory Debugger assume</cell><cell>( PPD) [31] is a debug-that the underlying phase, execution phase,</cell></row><row><cell cols="10">ging system for parallel machine architecture has a sequentially programs running consistent on shared-memory memory and debugging phase. There are two major components in our debugging multiproces-system [28]</cell></row><row><cell cols="10">sors (hereafter, (as is the case on the Sequent called "multiprocessors"). Symmetry). system: the Compiler /Linker and the PPD Controller. PPD efficiently The techniques During implements in this paper a tech-the prepara-</cell></row><row><cell cols="10">nique called are described tory phase, the Compiler/Linker flowback analysis in terms of the C programming [7], which provides language information [23], but they on the data produces the object code and the files to be</cell></row><row><cell cols="10">and control flow between should generalize to other imperative events in a program's languages. used in the debugging phase. While the object execution. We address a large part PPD provides code is running in the this</cell></row><row><cell cols="10">information of the C language, while keeping including execution phase, it generates</cell><cell>both the execution-time primitives for synchronization. and debug-time We also discuss overhead a log to be used in the following debugging</cell></row><row><cell cols="10">low. By using a method a simple approach to pointer phase. When the program</cell><cell>called variables, incremental but this is a topic that needs further tracing, only a small amount halts, due to either an error or user intervention,</cell><cell>of</cell></row><row><cell cols="8">trace is generated investigation. the debugging phase</cell><cell cols="2">during begins.</cell><cell>execution The</cell><cell>and is supplemented PPD Controller oversees</cell><cell>during the</cell><cell>debugging debugging</cell></row><row><cell cols="10">by detailed This paper is organized information phase, responding to the programmer's obtained as follows:</cell><cell>by reexecuting Section 2 presents only selected parts of the an overview of the requests.</cell></row><row><cell cols="10">program. design of PPD. Sections 3 and 4 describe the graph structures PPD is also capable of performing flowback</cell><cell>analysis and tools used on parallel</cell></row><row><cell cols="10">programs by PPD to perform and detecting flowback</cell><cell>data races in the interactions analysis. Section 3 describes the static program between processes.</cell></row><row><cell cols="10">This paper describes dependence graph, built at compile the mechanisms time, which shows potential used by PPD to implement dependence efficient</cell></row><row><cell cols="10">flowback between events in the program's analysis for parallel</cell><cell>programs. execution.</cell><cell>These mechanisms Section 4 describes the dynamic include program</cell></row><row><cell cols="10">dependence program dependence graphs and semantic graph, built</cell><cell>analysis at debug time, techniques which</cell><cell>such as interprocedural shows the actual</cell></row><row><cell cols="3">analysis dependence</cell><cell cols="7">[2, 12] and data-flow between events in the execution. analysis [22].</cell><cell>Section 4 also describes</cell><cell>how</cell></row><row><cell cols="10">The goal of PPD is to aid debugging dynamic graphs are built by augmenting</cell><cell>by displaying the static graphs dynamic with</cell><cell>program traces</cell></row><row><cell cols="5">dependence. generated during</cell><cell cols="5">These dependence execution and debugging. should guide the programmer Section 5 presents</cell><cell>from manifes-the details of</cell></row><row><cell cols="3">tations incremental</cell><cell cols="7">of erroneous tracing. Section 6 describes how flowback program behavior (the failure) analysis to the corresponding is extended to</cell></row><row><cell cols="10">erroneous parallel programs program and how data races are detected. state (the error) to the cause of the problem Section 7 presents</cell><cell>(the bug). some</cell></row><row><cell cols="10">Debugging initial performance is a difficult overhead</cell><cell>job because the programmer results. We conclude with Section 8. has little</cell><cell>guidance</cell><cell>in</cell></row><row><cell cols="3">locating</cell><cell cols="7">bugs. To locate a bug that caused an error, the programmer</cell><cell>must</cell></row><row><cell cols="10">reason about the causal relationships 2. STRUCTURAL AND FUNCTIONAL OVERVIEW between</cell><cell>events in the program's</cell><cell>execu-</cell></row><row><cell>tion.</cell><cell></cell><cell cols="3">There</cell><cell cols="4">is usually</cell><cell>an interval</cell><cell>between</cell><cell>when</cell><cell>a bug first</cell><cell>affects</cell><cell>the</cell></row><row><cell cols="3">program Flowback</cell><cell cols="4">behavior analysis</cell><cell cols="3">and when the programmer would be straightforward if we were to trace every event notices an error caused by the</cell></row><row><cell cols="8">bug. This interval during the execution</cell><cell cols="2">makes it difficult of a program. However, to locate the bug precisely. doing so is expensive</cell><cell>The usual in time</cell></row><row><cell cols="10">method and space. The user needs traces for only those events that may lead to the for locating a bug is to execute the program repeatedly, each time</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="7">ACM l'ransactlom on Programming Languages and Systems,Vol 13 No. 4, Octobl~r1991.</cell></row></table><note><p>closer</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>2. Execution phase. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</figDesc><table><row><cell>. q .</cell><cell cols="2">J.-D. Choi et al. J.-D. Choi et al J.-D. Choi et al.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">program execution. debugging entries be read before output The phase include the next logging and a log that log is used, along contains with to generate fine traces prelogs, which record the values dynamic the emulation information package, about for the flowback analysis. of the variables point, and postlogs, which record the changes program during the The log that might in the program state since the last logging point. The log entries and tracing are described in more detail in Section 5. 2.3 Debugging Phase The goal of the debugging phase (see Figure 3) is to build a graph of the dynamic dependence in a program. The debugging phase assembles informa-tion from the previous phases: the static graph and program database ~gener -ated by the compiler during the preparation phase, and the log generated by the object code during the execution phase. This information is used together with the emulation package to generate the detailed traces needed to bluild a graph of the dynamic dependence. The PPD Controller oversees the debug-ging phase. It responds to requests from the programmer, locating the necessary data from the log and static graph, and then executing parts of the emulation package to generate the fine traces. 3. STATIC PROGRAM DEPENDENCE GRAPH The static program dependence graph (static graph) shows the potential :: :: ;: !: : ~--: ~~~: ; SOURCEFILES ; . . . . . . . . . . . . . . . . . . . . :: ,.. . PROGRAM ! DYNAMIC DATASASE [ PROGRAM DEPENDENCE r --------------J-------, : "--; SXATICPRCCRAM ~[ GRAPH ;: DEPENDENCE ; : : control flow USER : information flow o :syst em provided : generated during debugging phase .&gt; : generated during previous phases ( ~: compiler generated . . Fig. 3. Debugging phase. deperzclence.s (similar to control dependence [151). The static graph is also the basic building block of the dy~amic program dependence graph (dynamic graph). The static graph is a variation of the program dependence graph intro-duced by Kuck et al. [251. Since then, there have been numerous variations that can be categorized into two classes, according to their applications. First, the program dependence graph is used as an intermediate program represen-tation for the purpose of optimizing, vectorizing, and parallelizing transfor-mations of the program [15, 24-26, 361. The main concern in this class is to decide whether there exists any potential dependence between two sets of statements. Second, the program dependence graph is used to extract slices from a program. A slice of a program with respect to variable v and program point p is the set of all the statements that might affect the value of u at p [38]. Such slices can be used for integrating program variants [211 and for program debugging [15, 34, 37, 381. One common attribute of the two classes of applications is that they do not use the dynamic information obtained during program execution. However, in PPD, we augment the static graph with the dynamic information obtained during execution and debugging in building the dynamic graph. The dynamic graph in PPD can be viewed as a dynamic slice of the program at an execution point based on the actual dependence between statements. Accordingly, the static graph structure in PPD differs in several ways from previous systems. The structure of the static graph is motivated by the following observations: First, the static graph should contain enough infor-mation to build the dynamic graph with only a small amount of trace generated at execution time. A small amount of trace means low execution-time overhead. Second, compile-time efficiency should not be compromised to identify dependence that can be easily determined with dynamic informa-tion obtained at execution and debugging times. Since the dynamic trace information effectively unrolls all loops, computing data dependence direction vectors [39], which are approximate compile-time characterizations of depend-ence, is unnecessary to show execution-time dependence. Although co input -ing data dependence direction vectors is essential for automatic loop ]paral -lelization [3], it is unnecessary because we can reconstruct this information at execution time. Moreover, because we require the actual paths of controd flow taken at run time (obtained from the dynamic trace), we need not approxi-mate such information at compile time. We, therefore, do not construct precise static control flow graph. Finally, for each subroutine, identify the sets of variables that might be used or defined by the execution of that subroutine. Such identification allows us to decide whether to sh~ow or to skip the execution details of a subroutine when showing the depend~ences requested by the user. In this section we describe a static graph consisting of two layers. The outer layer, called the branch dependence graph, shows the branch depend-ence, and the inner layer, called the data dependence graph, shows the data dependence within the blocks of the branch dependence graph. We discuss the two layers in detail. Interprocedural analysis is used in building the data dependence graph. With separate compilation, interprocedural analysis also allows us to avoid rebuilding the entire static graph from scratch when one or more modules of the program are modified. The separate compilation issue is described in detail in Section 3.5, where we describe how we use interproce-dural analysis in building the static graphs. 3.1 Branch Dependence Graph The outer layer of the static graph is the branch dependence graph. This (static) branch dependence graph, which is always a tree, is developed from syntactic program analysis (i. e., at parse time). In Section 4.3 we compare this graph with the control dependence graph [15]. The static branch d~epen -dence graph consists of nodes called control blocks and branch dependence edges between these nodes. Figure 4 shows an example branch dependence graph. Such a graph is constructed for each subroutine in the program. A control block is identical to a basic block, except that labels (which are potential targets of branching statements such as goto) always delimit the start of a new control block. For example, to handle switch statements in C, we also treat a case statement as a label, since an implicit branch occurs when a case does not end with a break and is allowed to fall through to the following case. A leaf control block represents a block of statements in which the flow of control always enters at the beginning and exits at the end, and Slo: Sll: S12: S13: [ g2 = a; H gl -g2; SubX(a) ; g2 = g2 + g3; }: S14: I while (a &gt; 1) ( I S15: s16: B a=a-1; E g2 = g2 * a; 1; IUSE IMOD USE MOD POINTERTODATA DEPENDENCEGRAPH Fig.4 Sample static graph, that is devoid of conditional or loop control statements. For programs without labels that are potential targets of branching statements branch dependence graph is identical to the abstract syntax program, with the basic blocks being the leaf nodes of the tree. Thus, the branch dependence graphs can be built at compile time without Since we do not perform control-flow analysis of the program, assume at compile time that every label will be a target branching statement. This assumption sometimes results in overly grained basic blocks, such as blocks F, G, and H in Figure 4, However, benefit from not performing control-flow analysis easily additional overhead incurred by such pessimistic assumptions. statements, such as goto, can affect the structure of dynamic In Section 4.3 we describe how the simple structure of the branch depend-ence graphs, combined with run-time traces, can handle statements. We now use terminology from Banning [8]. block. The IUSE set of a block is the set of upward-exposed used variables of to identify the array elements that will actually be accessed. Our apprc)ach is these branching lIn previous papers [31] we used different terminology for these sets as follows: previously referred to as DEFINED, IUSE as USED, MOD as GDEFINED, and USE as GUSED. block, and the bottom of the block shows the variables in the IMOD set of the Array index values are usually unknown at compile time, so it is not possible exposed, a use of an array element always creates an entry in the IUSE set of IMC)D was The top of the control block shows the variables in the IUSE set of the 3.4 Arrays and Linking Edges which fails to prevent any uses reached by the definition from being upward-graphs. index is a variable. Linking edges are described in more detail in Section 3.4. Because a definition of an array element is a preserving definition [1], Branching IMOD, USE, and MOD sets) for a summarizing block are the unions of the example, deciding which array element is actually accessed when the array parameters of a called subroutine. the control block). offsets the small, ing blocks, one for each e-block in the subroutine. The four sets (the IIUSE, resolve the dependence that can only be determined at execution time, for in Figure 4 and shows how actual parameters are mapped to the formal being modified (since there were no previous modifications of array "A" in the The branch dependence graph for a subroutine can have several summariz-execution; it shows the control flow of the program. The linking edge helps a function return value). Figure 6 shows the static graph of control block C of the assignment, and a linking edge from the IUSE set entry for the array fine-interprocedural analysis. represented by n~immediately follows the event represented by n, during is labeled with "%" followed by the parameter position (%0 represents value, one data dependence edge for the variable used in the right-hand side of at least one. The USE and MOD sets are described in more detail in Section 3,5, on uses output of S1. ) A flow edge from n, to nJ is defined when the event node) for each actual parameter passed to a subroutine. Each parameter node 7 contains three incoming edges: one data dependence edge for the index we simply the USE and MOD sets can only be determined by interprocedural anallysis. 1 [4, 24]. (A statement Sz has a true dependence on another statement SI if S'z call during debugging, we create a parameter node (a variant of the singular each index node to the assignment node. For example, node " s6:A" in Figure analysis. sets are determined locally by inspecting the statements belonging to a block, and linking edges. The data dependence edge represents a true dependence To map between formal parameters and actual parameters of a subroutine position (similar to a parameter node). A data dependence edge is added from control-flow block in a subroutine called from this block (following the transitive cllosure of calls). The MOD set is similarly defined. Whereas the IUSE and IMOD an identifier or an expression. The data dependence graph has three edge types: data dependence, flow, created for each array index and is labeled with "70" followed by the index 3.3 Parameters to Subroutines array, and a linking edge is added from this entry. Finally, an index node is tree [1] of the variables that might be used before they are defined in this block or any the data dependence graph is labeled with the statement number and either debugging and are recorded in the dynamic graph (described in Section 4). array in the control block, then a special IUSE set entry is made for the such as goto, the The fourth type of nonleaf block is a dummy block. This block exista only as a descendant of a conditional block to group together the blocks (if there are more than one) dependent on the conditional. The dummy block satisfies the condition that only one of the descendants of a conditional block will be executed. All of the descendants of a dummy block will also be executed in left-to-right order. Control block D in Figure 4 is a dummy block with three descendants. Leaf blocks G and H are defined because of labels "L1" and "L2"; flow of control can potentially enter at these points. (We introduce these labels to show how labels affect the static graph, although there is no goto statement in the example program.) Associated with each control block (except dummy blocks) are four sets of variables-the IUSE, IMOD, USE, and MOD sets-and a data dependence graph. The IUSE set is the set of variables that might be referenced before they are defined by a statement in this block; it is the set of upward-exposed used variables [1] of this block. The IMOD set is the set of variables whose values might be defined by statements in this block. The USE set is the set of Section 5 discusses how these data structures work together incremental 3.2 Data Dependence Graph Each control block (except for summarizing and dummy blocks) has a data dependence graph that shows only the dependence between statements belonging to that block. Data dependence between different blocks resolved at debug time and appear in the dynamic graph. Figure sample control block and its data dependence ence graph has two node types: singular and subgraph node represents an assignment statement, a control predicate such as an if or a switch, or a branch statement constant used on the right-hand side of a statement, node, which is a subtype of the singular node. The subgraph the call site of a subroutine and is a way of encapsulating such subroutines. There is one static graph for each subroutine. Each node of recorded in the static graph. Interlock dependence are resolved array, to the assignment node. If there are no previous writes to the same during the inside details of different control blocks) are not resolved at compile time; they added, from the most recent node in the control block that writes the same are not node represents Interlock dependence (dependence between two statements belonging of the assignment. However, for array assignments, a linking edge is then to we create a constant explicitly show the flow edges in the figures edges from the nodes representing the variables used in the right-hand side in this section. such as goto or exit. For a in debugging parallel programs, which is described with assignments to scalar variables, this node contains data dependence in Section 6. We will not in a statement control block. Ordering events belonging to different created. Nodes " s6:A" and " s8:A" in Figure 7 are examples of such nodes. As processes is important nodes. The singular ing the nodes, so we can say that a node is after or before another To represent an assignment to an array element, a singular node is nodle in a graph. The (static) data depend-events represented by the nodes and is represented dependence quickly. by the flow edges connect-5 shows a control block are sequential. This total ordering shows the execution data dependence and are used during debugging to locate the actual order of are value of the variable represented by node N. A data dependence edge into the IMOD variable shows the last statement in the block that modifies the variable. of the nodes in a data dependence graph are totally ordered according corresponding statements in the control block, because statements nodes represent read-accesses of an array. Linking edges represent potential in a select nodes. Index nodes show the indexes used in array accesses, and select to the type, the linking edge, and two variants of the singular node, the index and All dependence can be quickly determined at debug time. We use a new edge entry for a to supply enough information in the static graph so that array reference has not been defined in this block before the statement tracing. node N shows a dangling data dependence in this block, meaning that the with the log and the block. A data dependence edge from the IUSE entry for a variable into a we want to S9: a = gl; construct an e-block out of the subroutine. for easy identification of which e-blocks might use or modify a given variable. Fig. 6. Data dependence graphs for parameter mapping (control block C in Figure 4) a extern int gl, c32, g3; extern int A[1OO], B[1O()]; wolf ( ) ( int i, j, k, 1, a, b: SI : r if (gl &gt; O) { S2: 7 a -Add2(gl, g2); C I , S3: S4: S5: s6: * S7: s8: } else { [ gl = o; F SubY ( ) ; a = gl; L1 : r a = (A[i] = b); G b= A[j]; A[k] -B[l]+a+b; L2 : D 0 wolf /. /\ \ /' \ There are four nonleaf block types needed for C programs. -The first type represents conditional statements, such as if or switch statements. 1n the absence of gotos (including implicit gotos, which occur when one case of a switch statement falls through to the following case), only one child of a conditional node in the static graph will execute. Block A in Figure 4 is of this type. During execution, either block C or block D will be executecl. The second nonleaf block type represents loop control statements such as while or for. Execution of the descendant blocks may be repeated zero or more times depending on the loop control statement. Block B in Figure 4 is of this second type. The third and fourth nonleaf block types do not correspond to any state-ment. The third type acts as a summarizing block for its descendant blocks and is used when its descendants constitute an e-block; an e-block is the unit of incremental tracing during debugging (described in Section 5.1). All of the descendants of a summarizing block execute in left-to-right order. Also, the root block of a static graph is a summarizing block, even if we do not same sets of all of the descendants' blocks that constitute the e-block. However, they do not contain variables that cannot be accessed outside the corresponding e-block, except for upward-exposed static variables. For exam-ple, those four sets for a subroutine do not contain variables local to the subroutine, although static variables are treated the same way as global variables. The program database [31] contains the scope information of each variable, telling whether a given variable is a global variable, a variable local to a subroutine, a static variable (in C), or a formal parameter of a subroutine. It also tells whether a given global variable of a parallel program is a shared variable. (Sequent C has two additional parallel programming [351: shared and private.) The variables in the IUSE and IMOD set of the summarizing block are the variables that will be written to the log (described in Section 5) at execution time. The structure of the branch dependence graph and the four sets of used and defined variables allows for easy identification of the sets of variables that might be used and defined during the execution of an e-block. They also allow o : singular node Fig. 5. Basic block and its data dependence graph -VU a g2 (control block E in Figure 4). I I : subgmph node E -8 s2: a O : singular node key words to support S15: a= a-l; S16: g2=g2 *a; IU : RJSE lM: IMOD _ : data dependence edge IU a gz -S2: a = Add2(gl, g2); III: RJSE lM: IMOD IU gl cj2 s2: Add2 %0 E %1 %2 s6</cell></row><row><cell>dependence</cell><cell>between</cell><cell>program</cell><cell>components,</cell><cell>such</cell><cell>as data dependence.s</cell><cell>[241</cell></row></table><note><p>-+ -.......... .......... and branch ,---. -...................... ,.......--. -. . ......................... : I</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table I .</head><label>I</label><figDesc>Test Program Execution Time Measurements (time in seconds) Table III shows the reexecution times and debug-time trace sizes of various e-blocks of the tested programs. The e-block from SORT consists of a singly nested loop that sorts the list of numbers once.</figDesc><table><row><cell></cell><cell></cell><cell cols="5">Debugging Parallel Programs with Flowback Analysis</cell><cell>.</cell><cell>525</cell></row><row><cell>partitioned Array irrelevant</cell><cell cols="6">PI units, which identify some interesting Trace Size Measurements to be easily into synchronization logging can also cause Table II. Execution-Time to debugging ignored. Flowback which shared variables P2 P3 performance anomalies. (sizes in bytes) analysis should,</cell></row><row><cell cols="7">to record and where in the program Notice that test program SH.PATH-2 Without PPD compiler shows a slight therefore, scale well to large parallel programs. Second, they should be logged. improvement PPD compiler With repeated execution in CPU of Sequent without log optimization with log optimization time (the sum of user and system time) with the code generated by the PPD log optimization log optimization the program is not required. The overhead associated with repeatedly reexe -el,o e 2,o e3,0 Definition 6.5. A synchronization unit consists of all the edges that are reachable from a given nonbranching node in the simplified static compiler (overhead in%) (overhead in%) compiler. The PPD compiler generates logging code immediately before the SORT 18,209 cuting long-running (and possibly nondeterministic) programs is avoided. 18,209 graph SORT 5.5 5.7 (3.6%) 5.7 (3.6%) loop that accesses a large array; the logging code accesses the entire array. MATRIX 40,120,221 120,217 Finally, data-race detection allows us to deal with one of the more difficult</cell></row><row><cell cols="5">without CPU This extra access seems to affect the paging passing through another nonbranching Elapsed 5.6 6.1 SH.PATH. 1 825,517 synchronization errors encountered in parallel</cell><cell cols="2">node. (8.9%) behavior programs.</cell><cell>6.1 @ossibly at the archi-(8.9%) 825,517</cell></row><row><cell cols="7">ez,l } {e., e,}, and {e,, e,, e,} in Figure SV=b ; The sets {el, e2, e3, e5, efj, 'a, eg , each constitute a synchronization unit. MATRIX 12.7 52.5 (313.4%) 13.4 (5.5%) CPU Elapsed 12.7 54.7 (330.7%) 13.7 (7.9%) tecture level) of the program, resulting in less execution time. We are 17 currently investigating this anomaly. sH_PATH.2 417,129 417,129 CLASS 104,508 The graphs and algorithms presented in this paper provide the foundation 104,892 for the construction of the system that will perform efficient flowback analy-</cell></row><row><cell cols="7">Fig. The object code generates 16. Dependence that span pro-an additional Program CLASS can also run as an interactive prelog sis for parallel programs. Several ideas make el,l cesses. synchronization unit for those shared variables SH.PATH.1 1.1 1.8 (63.6%) a 33 percent increase in CPU time and a 75 percent increase in elapsed time '? at the beginning of each program, Whereas there is efficient flowback analysis e2,2 that are potentially 1.8 (63.6%) possible. The use of semantic analysis allows us to identify at compile time read-accessed inside the synchronization unit. There is no corresponding postlog CPU Elapsed 1.3 2.2 (69.2%) 2.2 (69.2%) when CLASS ran using an input file, there was no noticeable difference in Table III. Reexecution Times and Trace Sizes (time in seconds) only those variables that are necessary to trace at execution time. The</cell></row><row><cell cols="7">I shared variables nl,z logs generated for the write-accessed as the regular at the beginning e2,3 e 2,4 at the end of a synchroniza-n2,3 e3,1 &gt; n 2,4 and end of the contain tion unit, generated e-block the values of both shared and nonshared variables. The additional prelog of the read-accessed shared variables is used to ensure repeatable reexecution of the events in the synchronization unit. As long as there were no data races during execution, the additional prelog will suffice sH_PATH_2 107.0 105.5 (-2.4%) 105.5 the response times when CLASS ran interactively. incremental generation of the detailed traces at debugging time further (-2,4%) CPU Elapsed 107.0 107.3 (2.8%) 107.3 (2.8%) CLASS 0.3 0.4 (33.3%) 0.4 CPU Elapsed 7.2 Execution-Time Original Reexecution Debug-time amortizes the cost of tracing over the interactive debugging session. The trace size Trace Size CPU CPU (Mbytes) fragmented static graph structure used in PPD is easily built and is tailored Elapsed (33.3%) 0.4 0.7 (75.0%) 0.7 (75.0%) Table II shows the sizes of execution-time traces (log) generated by the test programs. As described before, pro~am MATRIX has a substantial decrease in trace size from log optimization. Program e-block 1 (SORT) &lt;0.1 0.1 to be the building block of the dynamic graph. With the inclusion of synchro-1.7 e-block 2 (MATRIX) 8.6 160.5 0.37 57.76 nization dependence, these graph structures generalize nicely to parallel 165.5 CLASS has a slight increase in e-block 3 (SH_PATH_ 1) 0.1 3.8 4.8 programs. 1.24 el.2 for ensuring repeatable execution behavior during debugging. trace size from log optimization because of the reason described previously. e-block 4 (SH_PATH_2) 10.5 &gt;364.8 &gt;422.8 &gt;117,79 There are several issues that must be addressed in the PPD design. The</cell></row><row><cell cols="2">execution-time most immediate</cell><cell>overhead issue</cell><cell>of the tested is the handling</cell><cell cols="2">programs. of pointers</cell><cell>Execution-time and dynamic</cell><cell>overhead data struc-</cell></row><row><cell cols="7">7. PERFORMANCE ranges from O to 330 percent for object code that is not log-optimized MEASUREMENTS 7.3 Trade-off Between Run Time and Debug Time tures. The methods described in Section 3 form a starting point,</cell><cell>and from and we are</cell></row><row><cell cols="7">"SV" establish is read by process the data dependence p~and is modified edge for "SV", "SV" that occurred before the read must be located. by processes the most recent modification PI and Pz. TO of If events belonging to edges ez ~(the edge emanating from node n2, 1) and el, o (the topmost edge of process 'pl) are the only modifications of "SV", then a data dependence is established between the event ez, ~that modified "SV" that read "SV&gt;'. If, for example, there exists another "SV" in any of the edges el, ~, el, z, ez,2, e2, ~, or ez,A (i.e., edges simultaneous moments. Reexecution of this e-block may therefore perform a different the additional logging for shared variables, the simplified static graph is unduly burdening the other phases of program execution. Table I shows the techniques for succinctly summarizing tion of an e-block could be made dynamically at execution time. the programmer on the cause of the errors allows parts of the execution data accesses in arrays [6]. event that modified other processes may have changed the value of "SV&gt;' between these two 6.2.2 Synchronization Units and Additional Logging. To generate The goal of the PPD design is to minimize execution-time overhead without lar row (or other part) of the matrix that is actually accessed by employing decision whether to generate another prelog-postlog pair during allows dependence to be followed that span process boundaries. Focusing the execu-and the event in e3, 1 to ea, ~), then we cannot tell which event actually modified "SV" last, and a data race is reported to the user. 6.2 Incremental Tracing for Parallel Programs Our implementation of incremental tracing described in Section 5 relied on the reproducibility of the debugged program. We now discuss applying incre-mental tracing to shared-memory parallel programs that lack reproducibil-ity. Our solution uses a graph called the simplified static graph, which is a subset of the static graph that abstracts out everything except the synchro-nization operations between processes. From this graph we determine what additional logging is required to support incremental tracing. 6.2.1 Simplified Static Graph. To motivate the construction of the simpli-fied static graph, consider the example shovvn in Figure 17, which contains a subroutine that accesses a global variable named "SV". The subroutine also constitutes an e-block. The statement indicated by the arrow is the first statement that accesses the variable "SV'&gt; in this subroutine. In the case of a sequential program, we construct a prelog that saves the value of "SV" at the beginning of the subroutine. The value of "SV'&gt; will not be changed until it is first accessed in the statement indicated by the arrow. Hence, one prelog and one postlog are sufficient to obtain reproducible behavior when reexecuting parts of sequential programs during debugging. However, now consider the case of a parallel program. If "SV)' is a shared variable, we cannot guarantee that the value of "SV" saved in the prelog at the beginning of the subroutine will be the same as when "SV" is first read; gram state for read-accessed shared variables. The simplified static graph allows us to determine which shared variables must be recorded and where in the program they should be logged. In our examples we only consider semaphore operations; however, this approach can be generalized to other synchronization primitives. The simplified static graph is a subset of the static graph that contains only flow edges and nodes that represent either possible control transfers (such as if or case statements) or semaphore operations (Figure 17 also shows the simplified static graph for subroutine SubB). Any subgraph node representing a subroutine that may perform a semaphore operation This section presents measurements of the overhead caused by PPD on the execution time of application programs. We compare the execution O to 75 percent for object code that is log-optimized. MATRIX has the largest performance improvement from log optimization. The execution-time As described in Section 3, there is a trade-off between efficiency during currently working on this problem. The user-interface design is another area 7.4 Summary of Measurements over-execution and response time during debugging. If we construct an e-block in that must be investigated. A graphical representation of program depen-time of the object code generated by the PPD compiler with that generated head of MATRIX is reduced from 330.7 to 7.9 percent. MATRIX has a favor of the execution phase, debugging phase performance will suffer. On In this section we have provided performance measurements of the various dence can offer quick access to complex structures. But, as the body of by the Sequent Symmetry C Compiler. We also present measurements subroutine that is called one million (100 by 100 by 100) times by another the other hand, if we construct an e-block in favor of the debugging phase, parts of PPD. The measurements show that increases in the execution time displayed information increases, these displays can quickly overwhelm the of execution-time trace size. There is a trade-off between the amount subroutine. Without log optimization, each call to this subroutine generates a execution phase performance will suffer. vary significantly (O to 86 percent) among the test programs. However, larger viewer. A careful trade-off between graphical and textual information using of trace generated during execution time and the amount generated during debug time. prelog-postlog pair, resulting in a large execution-time overhead (due to the increases in the execution time come from test programs that access only part multiple views and supporting information will be necessary to provide an The trade-off is based on selecting the size and location of e-blocks. one million prelog-postlog pairs). However, this subroutine does not have a of arrays in loops. One possible way to reduce this overhead is to employ intuitive interface. Our current heuristics for making this selection are quite simple, loop or accesses to static variables; with log optimization, this subroutine The e-block of MATRIX is techniques for succinctly summarizing data accesses in arrays [6]. With a We believe that PPD can be a platform for more than interactive debug-so the performance numbers give only an initial indication becomes a non-eblock subroutine, and the caller becomes the parent e-block. made of a triply nested loop. By constructing a single e-block out of the triply more sophisticated dependence analysis for such complex objects, we expect a ging. Currently, the decision about which variable's dependence to examine of the cost of using PPD. We present measurement results of five test programs: The non-eblock subroutine does not generate log entries, yielding a much nested loop of MATRIX, we were able to reduce the execution phase over-reduction in the execution-time overhead. is made by the programmer. Flowback analysis could be integrated with a SORT, MATRIX, SH.PATH -1, SH-PATH-2, and CLASS. smaller execution time, Accordingly, log optimization also causes MATRIX to head, but with a large debug-time overhead: 166 seconds in reexecution time Execution-time trace sizes are generally small (less than 1 Mbyte in all more automated decision-making process. This might be a verification sys-SORT sorts a vector of 100 integers using an Insertion Sort algorithm, whose time complexity have a large reduction in the size of execution-time traces. and about 58 Mbytes of debug-time trace. For a comparison, the execution cases). However, the measurements show that we need more experiments tem based on formal specifications or an expert system based on debugging is 0( nz ). MATRIX multiplies two square matrices of integers into a third matrix. Log optimization might actually produce a higher execution-time overhead time of MATRIX itself is about 13 seconds, and execution-time trace size is and research to achieve a better balance between the trace size during knowledge. The size of each matrix, for our tests, is 100 by 100. MATRIX uses a subroutine if the non-eblock subroutine is never invoked due to conditional statements 0.12 Mbytes, with log optimization. The e-block of SH-PATH. 1 in Table III execution and the response time during debugging. Many of the design decisions and heuristics in PPD must be evaluated in in multiplying two scalar elements of the two matrices. The subroutine in the program; parent e-blocks of these non-eblock subroutines may generate is constructed out of a singly nested loop that computes the shortest paths The test programs used in the performance measurements of PPD are, in practice. A working prototype is under construction to test our decisions on does not contain a loop or accesses to a static variable, making that subroutine additional log information for the non-eblock subroutines that are never from a city to 99 other cities, while the e-block of SH-PATH-2 is constructed general, small in size. However, we think that the results obtained with real programs. These tests will allow us to evaluate overall effectiveness and a target of log optimization (see Section 5.3). SH.PATH. 1 computes invoked. However, we expect that such cases of losing by log optimization out of a doubly nested loop that computes the shortest paths from 100 cities these programs will scale up proportionally well with larger size programs. to tune the algorithms for such things as the selection of e-block sizes and the the shortest paths from a city to 99 other cities using an algorithm described should be rare. to all of the other cities. The e-block of SH-PATH -1 took about 5 seconds to In general, the performance measurements of PPD described in this section handling of large arrays. An initial implementation of PPD (including all of by Horowitz and Sahni [19]. SH-PATH-2 is the same as SH_PATH -1 except We also see that copying the contents of an entire array (for a log entry) at execute with 1.3 Mbytes of trace, while the e-block of SH-PATH-2 termi-have demonstrated the feasibility of the ideas and directions proposed in our the facilities described in this paper) is running, using the C programming during its execution (or during the execution of any subroutine tively called by it) is treated as a semaphore operation. The simplified static graph therefore contains only branching nodes, which represent control' transfers, and non branching nodes, which represent semaphore 7.1 Execution Time this overhead is to generate a smaller log entry containing only the particu-tion time (such as an e-block made out of a nested loop). In this case, the see causal relationships directly. In parallel programs, the ordering of events operations. expensive, as seen in test program SH-PATH-1. One possible way to reduce generate more than one prelog-postlog pair for an e-block with long execu-First, dependence can be followed backward, allowing the programmer to possible run as an interactive program. array elements are accessed in a loop, dumping out an entire array can be more than one e-block out of a nested loop. One alternative might be to Debugging parallel programs with flowback analysis has several advantages. possible cities. CLASS is a program that emulates course registration such as registering for courses and dropping from courses. CLASS also can is the case with program SH-PATH-2. However, if only a fraction of the These two results suggest that it might sometimes be better to construct 8. CONCLUSION for students, overhead if most of the array elements are actually accessed in the loop. Such PATH-2 lasted more than 7 minutes with more than 100 Mbytes of trace. that may be transi-that it computes the shortest paths from all of the 100 cities to all of the other the beginning or at the end of a loop is inexpensive in terms of execution-time nated because the file system was full. At that time, the e-block of SH_ approach for debugging parallel programs. language, on a Sequent Symmetry shared-memory multiprocessor.</cell></row><row><cell cols="7">ACM Transactions on Programming Languages and Systems,VO1 13 No. 4, October 1991 ACM Transactions on Programming Languages and Systems,Vol. 13 No 4, October 1991.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>ACM Transactionson Programming Languages and Systems, Vol 13 No 4, October 1991.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>ACM TransactIons on Programming Languages and Systems, Vol 13 No 4, October 1991</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>ACM Transactions on Programmmg Languages and Systems, Vol 13 No 4, October 1991</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>ACM Transactionson Programming Languages and Systems, Vol. 13 No, 4, October 1991.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>on Programming Languages and Systems, Vol 13 No. 4, October 1991.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p>on Programming Languages and Systems, Vol. 13 No. 4, October 1991</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_6"><p>on Programming Languages and Systems, Vol. 13 No. 4, October 1991.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_7"><p>ACM Transactionson Programming Languages and Systems, Vol. 13 No. 4, October 1991</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_8"><p>ACM Transactions on ProgrammingLanguages and Systems, Vol. 13 No. 4, October 1991.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_9"><p>ACM Transactionson Programming Languages and Systems, Vol. 13 No 4, October 1991.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_10"><p>ACM TransactIonson Programming Languages and Systems, Vol. 13 No, 4, October 1991</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_11"><p>ACM Transactions on ProgrammingLanguagesand Systems, Vol. 13 No. 4, October 1991,</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_12"><p>ACM Transactionson Programming Languages and Systems, Vol. 13 No. 4, October 1991.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_13"><p>ACM Transactionson Programming Languages and Systems, Vol. 13 No 4, October 1991</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_14"><p>ACM TransactIons on Programmmg Languages and Systems, Vol 13 No 4, October 1991.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_15"><p>ACM Transactions on Programming Languages and Systems, Vol. 13 No. 4, October 1991.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We wish to thank Ron Cytron for his valuable suggestions and perseverance through several drafts of this paper, and to thank the anonymous referees for their helpful comments and suggestions. We also wish to thank Fran Allen and Michael Burke for their support.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Aho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sethi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ullman</surname></persName>
		</author>
		<title level="m">Compilers: Principles, Techmques, and Tools</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><surname>Addison-Wesley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<pubPlace>Reading, Mass</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">F</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cytron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ferrante</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>An overview of the</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">K</forename><surname>Kennedy</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
