<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Speech Pause Detection for Noise Spectrum Estimation by Tracking Power Envelope Dynamics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mark</forename><surname>Marzinzik</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Medical Physics Department</orgName>
								<orgName type="institution">Carl von Ossi-etzky University Oldenburg</orgName>
								<address>
									<postCode>D-26111</postCode>
									<settlement>Oldenburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Birger</forename><surname>Kollmeier</surname></persName>
							<email>birger.kollmeier@uni-oldenburg.de</email>
							<affiliation key="aff0">
								<orgName type="department">Medical Physics Department</orgName>
								<orgName type="institution">Carl von Ossi-etzky University Oldenburg</orgName>
								<address>
									<postCode>D-26111</postCode>
									<settlement>Oldenburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Speech Pause Detection for Noise Spectrum Estimation by Tracking Power Envelope Dynamics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B1CCF3BBAAD19108FDDBA2956F1A187D</idno>
					<note type="submission">received May 15, 2001; revised September 24, 2001. This work was supported in part by a research grant from GN ReSound.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Envelope dynamics</term>
					<term>envelope minima</term>
					<term>noise estimation</term>
					<term>noise reduction</term>
					<term>speech pause detection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A speech pause detection algorithm is an important and sensitive part of most single-microphone noise reduction schemes for enhancement of speech signals corrupted by additive noise as an estimate of the background noise is usually determined when speech is absent. An algorithm is proposed which detects speech pauses by adaptively tracking minima in a noisy signal's power envelope both for the broadband signal and for the high-pass and low-pass filtered signal. In poor signal-to-noise ratios (SNRs), the proposed algorithm maintains a low false-alarm rate in the detection of speech pauses while the standardized algorithm of ITU G.729 shows an increasing false-alarm rate in unfavorable situations. These characteristics are found with different types of noise and indicate that the proposed algorithm is better suited to be used for noise estimation in noise reduction algorithms, as speech deteriorations may thus be kept at a low level. It is shown that in connection with the Ephraim-Malah noise reduction scheme [1], the speech pause detection performance can even be further increased by using the noise-reduced signal instead of the noisy signal as input for the speech pause decision unit.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>speech pause detection. Martin <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref> uses the minimum of the sub-band signal power within a time window of about 1 s as an estimate of the noisepower in the respective sub-band. This ideawas already formulated by Paul <ref type="bibr" target="#b3">[4]</ref>. Doblinger <ref type="bibr" target="#b4">[5]</ref> proposed a continuous noise estimation scheme similar to Martin's which is computationally more efficient. This scheme was, however, not systematically tested. Hirsch <ref type="bibr" target="#b5">[6]</ref> and Hirsch and Ehrlicher <ref type="bibr" target="#b6">[7]</ref> proposed an algorithmwhich is based on the observation that the most commonly occurring spectral magnitude value in clean speech is zero. Hence, having noisy speech their algorithm measures the distribution density function of the spectral magnitude and determines the maxima which are then used as an estimate of the respective noise magnitude. These kind of algorithms which avoid speech pause detection for noise estimation are supposed to cope better with nonstationary (i.e., fluctuating) noise, since they are generally faster in their adaptation to changing noise levels even during speech activity. On the other hand, the continuous update of the noise estimate (independently in the sub-bands) is susceptible to erroneously capture speech energy. This, however, leads inevitably to speech deterioration in a subsequent noise reduction process. Fischer and Stahl <ref type="bibr" target="#b7">[8]</ref> investigated a spectral subtraction noise reduction algorithm with a continuous noise spectrum updating scheme. They found that the corruption of the noise estimate by speech is too large to be further considered and conclude that voice activity detection plays an important role and cannot be fully omitted. Recently, Nemer et al. <ref type="bibr" target="#b8">[9]</ref> proposed to use the kurtosis (fourth-order statistics) of the noisy signal to continuously estimate speech and noise energies. The examples presented used noisy speech signals with positive signal-to-noise ratios (SNRs) and yield promising results, but further research is required to extend these results to negative SNRs and different classes of noise, respectively.</p><p>Most authors reporting on noise reduction refer to speech pause detection when dealing with the problem of noise estimation. As Hirsch <ref type="bibr" target="#b5">[6]</ref> pointed out, "this is a very difficult and ultimately unsolved problem for realistic situations with a varying noise level." A lot of studies thus evade the problem by using an ideal speech pause detection using the clean speech signal or by using only short test signals with an initial noise-only period for noise estimation without the need for updating the noise spectrum estimate. In some applications like audio restoration (e.g., restoration of old gramophone recordings) the noise estimation indeed can often be done "manually" off-line. However, other applications like noise reduction for mobile communication and for digital hearing aids require automatic updating of the noise spectrum estimate. Most authorsagreethatvoiceactivityorspeechpausedetectors,respectively,are a very sensitive and often limiting part of systems for the reduction of additive noise in speech <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>.</p><p>Various procedures for speech pause detection have been described in the literature so far. Kang and Fransen <ref type="bibr" target="#b11">[12]</ref> proposed a very simple scheme. Whenever the low-pass band energy (in the frequency range from 0 to 1 kHz) of a current signal frame is below a specific fraction of the low-pass band dynamic range as scanned in the past frames, the frame is used for updating the noise spectrum estimate. Obviously, this procedure has strong limitations. It will only work with higher SNRs and will fail in noises with prominently low frequencies. A more elaborate algorithm using adaptive energy thresholds was proposed by van Gerven and Xie <ref type="bibr" target="#b12">[13]</ref>. Elberling et al. <ref type="bibr" target="#b13">[14]</ref> used the so-called synchro method for spectral estimation of the background noise. This procedure makes use of the specific characteristic of voiced speech sounds, i.e., that the energy is confined to pitch-harmonic frequencies. Based on successive multiplication of the envelopes from neighboring pairs of band-pass signals, followed by a summation over all resulting signal-products, a global measure of energy synchronization is obtained which is then used to classify the time frames of the input signal into those dominated by speech (high synchronization) and those not dominated by speech (low synchronization). This patent application is reported to work successfully in SNRs ranging from 9 to 9 dB with various noises. However, an increase of wrong speech pause decisions with decreasing SNR is reported. Sheikhzadeh et al. <ref type="bibr" target="#b14">[15]</ref> proposed a pause detection algorithm based on an auto-correlation voicing detection which was performed on the enhanced signal (i.e., after the noise reduction rather than on the noisy signal). Although extensive testing is mentioned, no performance results are presented. However, the authors state that the algorithm is not supposed to work well below SNRs of 0 dB. Dendrinos and Bakamidis <ref type="bibr" target="#b9">[10]</ref> presented an algorithm for determining the starting and ending points of speech segments in colored-noise environments through singular value decomposition based on some thresholds which have been determined experimentally. Good performance was proved for SNRs higher than 0 dB. However, the complexity of the algorithm makes a real-time implementation difficult. Recently, El-Maleh and Kabal <ref type="bibr" target="#b15">[16]</ref> performed a comparative study of three voice activity detection (VAD) algorithms: a VAD used in the GSM cellular system <ref type="bibr" target="#b16">[17]</ref>, the VAD used in the enhanced variable rate codec (EVRC) of the North American CDMA-based PCS and cellular systems <ref type="bibr" target="#b17">[18]</ref>, and a third-order statistics based VAD <ref type="bibr" target="#b18">[19]</ref>. Unfortunately, the authors did not investigate false-alarm rates and hit rates systematically but present only some noisy waveforms with the respective VAD decisions. However, the EVRC VAD is reported to show consistent superiority over the other VADs. Davídek et al. <ref type="bibr" target="#b19">[20]</ref> implemented a speech activity detector using cepstral coefficients for use in a real-time noise cancellation system. However, a comprehensive evaluation of the detector itself is not given. Abdallah et al. <ref type="bibr" target="#b20">[21]</ref> introduced a local entropic criterion for speech signal detection. Very good performance down to SNRs of 20 dB is reported. However, only white noise was tested so far. McKinley and Whipple <ref type="bibr" target="#b21">[22]</ref> suggested a model based speech pause detection algorithm which is claimed to be robust for low SNRs. The speech pause detection problem is formulated into a decision theory framework. However, this algorithm requires extensive training of a Hidden Markov Model with the set of speech prototypes to be encountered. Itoh and Mizushima <ref type="bibr" target="#b22">[23]</ref> proposed a speech/nonspeech identification based on four different parameters. The first is the maximum value of the auto-correlation function of the LPC residual signal, which represents the degree of the periodicity of the signal waveform. Second is a spectral slope parameter, third is a reflection coefficient which itself is computed from some PARCOR coefficients, and fourth is the signal energy. For each of the parameters, Itoh and Mizushima used empirically determined thresholds for a speech/stationary noise/nonstationary noise decision. It seems, however, that the decision for nonstationary noise is made only on the basis of the spectral slope parameter. Unfortunately, the proposed algorithm was not tested in low SNR situations.</p><p>Irrespective of the actual kind of speech pause detector used, a comprehensive and fair evaluation should include its hit rate as well as its false-alarm rate using different noises with a large variety of SNRs. These measures reveal most of an algorithm's capabilities and deficiencies. For an application in noise reduction, the problem is that a speech pause detection algorithm with a high false-alarm rate results in remarkably deteriorated speech after the noise reduction. On the other hand, a speech pause detection algorithm that finds too few of the actual speech pauses results in worse reduction of the noise. Hence, noise estimation is a very sensitive stage in the noise reduction process.</p><p>The algorithm for speech pause detection that will be described in the next section dynamically tracks the dynamics of the signal's temporal power envelope as well as of its low-and high-pass frequency band power envelopes. After a number of threshold comparisons, a frame-by-frame decision is made on the presence of a speech pause. This approach was motivated by the work of Festen et al. <ref type="bibr" target="#b23">[24]</ref>, who used the minima in the signal envelope for estimating the noise level in a speech-plus-noise signal to control an AGC (automatic gain control) algorithm for hearing aids. The proposed algorithm can be regarded as an extension of the simple scheme proposed by Kang and Fransen <ref type="bibr" target="#b11">[12]</ref>. In order to assess its applicability to real-time noise reduction for practical applications (see above), both the hit rate and false-alarm rate are evaluated for a large range of SNRs and different types of noise and compared to a voice activity detector (VAD) algorithm recommended by the International Telecommunication Union <ref type="bibr" target="#b24">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. ALGORITHM</head><p>The speech pause detection algorithm calculates the signal's temporal power envelope by summing up the squares of the spectral components of the input signal in each short-time frame <ref type="bibr" target="#b0">(1)</ref> Here, denotes the spectral component of the noisy input signal at frequency at time frame . In addition, a low-pass band power envelope and a high-pass band power envelope are calculated:</p><formula xml:id="formula_0">(2) (3)</formula><p>where runs over all spectral components up to the cut-off frequency, and runs over the remaining spectral components. In ordertoslightlysmooththeenvelopes, , and are averaged over a few frames by a recursive low-pass filter of first order with a release time constant ; no smoothing is performed in case of an increase in energy (i.e., attack time zero) to avoid smearing over onsets. The algorithm tracks the minimum value and the maximum value of each envelope and uses these for the speech pause decision as described by the following scheme.</p><p>1) After an assumed 200 ms initial phase of noise only the minimum and maximum values are set as follows:</p><p>(4)</p><p>This guarantees that the minimum envelope values correspond roughly with the noise energy at the beginning.</p><p>2) The minimum and maximum values are updated for each of the three envelopes in the following manner.</p><p>• If the current envelope value is larger than the maximum value for the corresponding envelope, then the maximum value is set to the current value. Otherwise, the maximum value slowly decays. This is done by a recursive low-pass filter of first order with a release time constant , which takes as input the current envelope value.</p><p>• If the current envelope value is smaller than the minimum value for the corresponding envelope, then the minimum value is set to the current value. Otherwise, the minimum value is slowly raised. This is done by a recursive low-pass filter of first order with attack time constant , which takes as input the current envelope value.</p><p>3) The differences between the maximum and the minimum values are calculated for each envelope no LP Speech Pause). Now, if the difference between the current and of the low-pass band envelope is smaller than some fraction of (which means that the actual envelope is near its minimum), a closer look at the high-pass band is necessary to support a speech pause decision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case 1)</head><p>of the high-pass band is smaller than threshold .</p><p>In this case no additional information can be obtained from the high-pass band because of its small dynamic range. Now, if at least (the signal's envelope) lies in the lower half of its dynamic range [i.e., in the lower half between and ] the current frame can be assumed to be a speech pause because of the closeness of the low-pass band energy to its minimum value ( LP Speech Pause) otherwise, however, there is not enough support for a speech pause decision ( no LP Speech Pause). Case 2)</p><p>is bigger than two times the threshold .</p><p>In this case, there is enough dynamic range to pay attention to the high-pass band. Thus, it is demanded that the difference between the current and of the high-pass envelope is smaller than two times the fraction of to support the small envelope value in the low-pass band. Then a noise-only frame is assumed ( LP Speech Pause). This demand is not as strict as that for the low-pass band, to account for the case that the disturbing noise has a rather high-frequency characteristic. But if this condition is not fulfilled, speech may be present in the actual frame ( no LP Speech Pause). Case 3) is smaller than two times the threshold , but bigger than .</p><p>In this case, which is not as clear as Case 2, it is only demanded that (the high-pass envelope) lies in the lower half of its dynamic range to support the small envelope value in the low-pass band. Then it is assumed that target speech is absent ( LP Speech Pause). However, if this condition is not fulfilled, speech may be present in the actual frame ( no LP Speech Pause). c) Condition b) accounts for the case that the disturbing noise has a rather high-frequency characteristic, hence the speech pause decision should mainly be made upon the information in the low-pass band. To account also for the case that it has a rather low-frequency characteristic, the same conditions as under condition b) have to be checked but now with reverse roles of the low-pass and the high-pass bands to determine whether target speech is absent (HP Speech Pause). Fig. <ref type="figure" target="#fig_1">1</ref> gives a flowchart of the proposed speech pause detection algorithm. The flowchart is not fully symmetrical with respect to LP and HP speech pause detection since several redundant tests are omitted.</p><p>Due to its flexible design this novel approach for speech pause detection can easily be adjusted to obtain a rather low falsealarm rate by adapting the main parameters and . Generally, a low false-alarm rate is desirable to reduce speech distortions in the subsequent noise reduction process. However, this also results in a reduced hit rate.</p><p>During the development of the algorithm noisy signals generated from various different noise types and speech signals at several SNRs were used for performance verification. Finally, the following values were chosen for the free parameters: The input signal was digitized with a sampling frequency of 22 050 Hz and partitioned in Hann-windowed segments of length 8 ms with 4 ms overlap. These segments were padded with zeros and a 256-point FFT was performed. This framework is compatible with most single-microphone noise reduction algorithms which can thus easily be integrated. Such short segments are motivated by the fact that then the same signal analysis and synthesis as necessary for a real-time noise reduction environment can be used. Due to the longer signal delay, longer window lengths in real-time signal processing applications would cause problems with lip reading and would cause stuttering when speaking. The cut-off frequency between low-pass and high-pass band was set to 2 kHz, motivated by the fact that excluding speech frequencies above 1.9 kHz has a roughly similar effect on speech intelligibility as excluding those below this value <ref type="bibr" target="#b25">[26]</ref>. The time constant for the envelope smoothing was set to 32 ms. The time constants and were both set to 3 s. These constants were determined by examination of the envelopes from several speech samples. With these settings a good approximation to the actual dynamic range of the signal and of its "placement" in the level area under a variety of conditions was achieved. However, systematic variations of these parameters were not investigated. The threshold was set to 5 dB and the fraction was set to 0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXAMPLES</head><p>To illustrate the speech pause detection scheme, Figs. <ref type="figure" target="#fig_3">3</ref><ref type="figure" target="#fig_4">4</ref><ref type="figure" target="#fig_5">5</ref>show some detection examples using a target sentence of approximately 5 s length mixed with different noises (digitally added).</p><p>Fig. <ref type="figure" target="#fig_3">3</ref> shows an example with car noise. This type of noise was recorded in the cabin of a driving car and has dominant parts in the low frequency range. The bar at the bottom of the panels shows the real speech pauses which were determined manually.</p><p>[For comparison, the waveform of the clean sentence is displayed in Fig. <ref type="figure" target="#fig_2">2</ref> (upper panel); the lower panel shows the mixed signal with a SNR of 5 dB.] The speech pause decisions of the algorithm are displayed in the other bottom three bars. The distinct bars give additional information about the reason for the speech pause decision. The first bar shows a symbol whenever a speech pause is detected due to a small dynamic range of the signal in the low-pass band as well as in the high-pass band, and generally in the initial noise estimation phase (the first 200 ms). The second bar shows a symbol whenever a speech pause is detected on the basis of the low-pass band information. Finally, a symbol in the third bar means that the decision was based on the high-pass band information.</p><p>The car noise example shows that it is worthwhile to consider band-limited envelopes. In this case, the signal's low-pass band envelope (as well as its broadband envelope) are strongly disturbed by the noise. However, the high-pass envelope is "clean enough" for obtaining reliable speech pause decisions (Fig. <ref type="figure" target="#fig_3">3</ref>). Actually, the third bar in the figure panels shows that the decision is mainly based on the high-pass information. Fig. <ref type="figure" target="#fig_4">4</ref> shows an example, where the sentence is mixed with the noise of a drilling machine at 5 dB SNR. This noise makes it impossible to get reliable speech pause information from the high-pass channel, but in this case the low-pass band information can be used. Comparison with the lowest bar in the figures (the "true" speech pauses) shows that a good speech pause detection is obtained. Although the algorithm wrongly considers the time frames around 0.6 s ("p" from "played"), 1.2 s ("th" from "theater") and around 1.5 s ("f" from "festival") as noise, these speech parts actually sound very similar to equally short segments of the drill noise. Hence, these wrong decisions are assumed to have no adverse effects on the speech quality when used for noise estimation in a noise reduction algorithm.</p><p>Fig. <ref type="figure" target="#fig_5">5</ref> shows an example with restaurant noise, which is neither mainly low-frequency nor high-frequency in its characteristics. As can be seen at the second and third bar in the figures, the speech pause detection, indeed, is sometimes based on the low-pass band information and sometimes on the high-pass information. In combination, a good speech pause detection performance is obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. COMPARISON WITH G.729 VAD ALGORITHM</head><p>In 1996 the International Telecommunication Union (ITU) "standardized" a voice activity detector (VAD) algorithm for a speech coding scheme as its Recommendation G.729 Annex B <ref type="bibr" target="#b24">[25]</ref>. The VAD algorithm makes a voice activity decision every 10 ms based on differential parameters of the full-band energy, the low-pass band energy, the zero-crossing rate and a spectral distortion measure. These are obtained at each frame as differences between each parameter and its respective long-term average. The output of the VAD module is either 1 or 0, indicating the presence or absence of voice activity, respectively. Several publications compared their own algorithms with the G.729 VAD so far <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>.</p><p>Using the G.729 algorithm here as a competitor is motivated by the fact that it has proven being successful in a wide range of conditions and that it is available from the ITU. Comparing a novel algorithm with this "standard" makes it also comparable to other algorithms, if these are tested against this "standard." Of course, the G.729 algorithm was intended to be used in less noisy environments, originally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Procedure</head><p>A female reading of a short story (41 s length) from the German PhonDat database <ref type="bibr" target="#b28">[29]</ref> was used to test the performance of the proposed algorithm versus the G.729 algorithm. The speech signal was mixed with a car noise, a multi-talker babble noise, an aircraft engine noise, and a factory noise, respectively, which were taken from the NOISEX-92 database <ref type="bibr" target="#b29">[30]</ref>. SNRs from 10 dB to 20 dB were employed. Negative SNRs do often occur in real-life situations and especially hearing-impaired persons have enormous problems to have conversations in noisy environments. Of course, the frequency shape of a noise signal has a strong influence on its masking effect. While the speech reception threshold (i.e., SNR where 50% of the speech are intelligible) for some machinery noises can be very low (for drill noise it is about 20 dB; <ref type="bibr" target="#b30">[31]</ref>), for cafeteria noise, e.g., it may be much higher (about 4 dB; <ref type="bibr" target="#b30">[31]</ref>) but still negative. False-alarm rates (i.e., the fraction of all real speech frames that were erroneously detected as speech pauses) and hit rates (i.e., the fraction of all real speech pauses that were correctly detected as speech pauses) were determined in each noise condition for both the proposed algorithm and the G.729 algorithm. For the calculation of the false-alarm rate as well as the hit rate, the "real" speech frames and "real" speech pauses were determined using the G.729 VAD algorithm on the clean speech signal. Using the G.729 itself as reference takes into consideration that no simple rule exists even for determining pauses in clean speech. Since the G.729 algorithm is recommended by the ITU, it can be taken for granted that it works well for clean speech. Note, that in the comparative test with the proposed new algorithm this may give an advantage for the G.729 algorithm, as it defines the "clean" standard. Hand-labeling of the real speech pauses was not considered since an automatic procedure was much more economical for determination of even very short pauses.</p><p>Finally, both algorithms are compared in terms of receiver operating characteristics (ROC). <ref type="foot" target="#foot_0">1</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Results</head><p>The detection results are shown in Figs. <ref type="figure" target="#fig_6">6</ref> and<ref type="figure" target="#fig_7">7</ref>. The upper panels show the false-alarm rate, the lower panels present the hit rate of both algorithms.</p><p>The comparison with the G.729 Annex B algorithm shows that the proposed speech pause detection algorithm yields a clearly lower false-alarm rate in each of the four different noises over the entire range of SNRs that were tested (cf., Figs. <ref type="figure" target="#fig_6">6</ref> and<ref type="figure" target="#fig_7">7</ref>). On the other hand, fewer speech pauses are actually detected than with the G.729 algorithm.</p><p>The false-alarm rates are lowest in car noise, followed by the multi-talker babble noise, the factory noise, and the aircraft engine noise. However, a principal difference between the algorithms is observed: While the proposed algorithm keeps the false-alarm rate and the hit rate almost constant with changing SNR, the performance of the G.729 algorithm strongly depends on the SNR-the lower the SNR, the larger the false-alarm rate as well as the hit rate. It is striking that the performance of the G.729 algorithm in car noise is rather poor even at moderate noise levels of 20 dB.</p><p>In terms of receiver operating characteristics (ROC), the working point of the G.729 algorithm shifts up and to the right in ROC space with decreasing SNR, while the working point of the proposed algorithm stays nearly at the same place in ROC space. In general, the false-alarm rates can be decreased by changing threshold criteria in the algorithm's decision rules. This is, of course, connected with a decrease of the hit rates. Whether the proposed algorithm is generally "better" than the G.729 algorithm can be examined by comparing them in ROC space (in terms of discriminability, i.e., the area under the ROC curve). Figs. 8-10 show ROC curves of the proposed algorithm using car noise, babble noise, and aircraft noise, respectively. The upper panels were obtained at SNRs of 10 dB; for the lower panels SNRs of 10 dB were used. The curves were generated by varying the threshold in the decision rule of the proposed algorithm (cf., Section II) from 1 to 25 dB in 1-dB steps.</p><p>Since in all noise conditions the G.729 algorithm falls below the ROC curve of the proposed algorithm, it may be concluded that the discriminability is better with the proposed speech pause detection algorithm.</p><p>Additionally, in Fig. <ref type="figure" target="#fig_10">10</ref> (upper panel) the ROC curve was determined for the proposed algorithm using a noise-reduced signal as input for the speech pause detection (by employing the single-microphone noise reduction algorithm from Ephraim and Malah <ref type="bibr" target="#b0">[1]</ref>, on a frame-by-frame basis) instead of the noisy signal. The detected speech pauses are in turn used to adjust the noise spectrum estimate for the noise reduction. Although this leads to a recursive design of the signal flow, no stability This modified algorithm is denoted as "Proposed Algo NR." Actually, the discriminability of the speech pause detection algorithm is further increased by this modification as can be seen at the larger area under the ROC curve (cf., Fig. <ref type="figure" target="#fig_10">10</ref>, upper panel).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Discussion</head><p>In a noise estimation application for noise reduction algorithms it is generally proposed to operate the speech pause detection at rather low hit rates to keep the false-alarm rate low. Large false-alarm rates in the speech pause detection lead to wrong noise spectrum estimates which include significant speech parts and hence cause artifacts in a subsequent noise re- For comparison, the performance of the G.729 VAD algorithm is also indicated. duction process. In fact, the proposed speech pause detection algorithm maintains a low false-alarm rate over a wide range of SNRs while the hit rate decreases only slightly at poorer SNRs. Hence, the algorithm keeps a relatively fixed position in ROC space over a wide range of SNRs. In contrast to the proposed algorithm, the algorithm of the ITU Recommendation G.729 yields very large false-alarm rates (but also larger hit rates) at low SNRs.</p><p>Obviously, the G.729 was not designed to detect the true speech pauses in adverse noise conditions. In conditions where the speech is hardly noticeable, the G.729 VAD algorithm rather decides to classify this situation as speech-free (i.e., a kind of extended speech pause). Since this behavior is inherent in the algorithmic design of the G.729 scheme, it cannot be overcome by global changes of its threshold parameters. In a noise reduc- For comparison, the performance of the G.729 VAD algorithm is also indicated. tion application, this behavior probably makes it impossible for a noise reduction algorithm to "retrieve" the speech signal, if the whole signal is classified as noise. As the proposed algorithm detects speech pauses by tracking envelope minima, its behavior at very poor SNRs differs here. It still decides for speech pauses only when energy minima occur.</p><p>The threshold parameters in the proposed speech pause detection algorithm were determined empirically to obtain low false-alarm rates for a wide range of input signals and SNRs. By this, speech deteriorations due to wrong noise spectrum estimates (i.e., including speech energy) in any subsequent noise reduction processing are minimized. However, low false-alarm rates are connected with lower hit rates which could also lead to signal deteriorations for certain types of strongly fluctuating noises. If the noise is strongly fluctuating in its characteristics between speech pauses, a noise estimate determined only when speech is absent is not sufficient to ensure effective noise reduction. For such conditions, noise reduction schemes have to be employed which exploit other features (for example separation in space between noise and target source <ref type="bibr" target="#b32">[33]</ref>), or a running noise estimate has to be determined from the noisy signal and not only during speech pauses.</p><p>Apart from that, low hit rates in the proposed algorithm do not necessarily mean that some speech pause intervals are not detected at all, but rather that several frames during speech pauses are not detected as such (see for example Fig. <ref type="figure" target="#fig_3">3</ref>). For the adjustment of a noise spectrum estimate, the proposed algorithm can hence be employed at rather low hit rates to obtain low false-alarm rates and still detects at least some frames during most speech pauses. The proposed algorithm has successfully been employed in several experiments with single-microphone noise reduction algorithms <ref type="bibr" target="#b30">[31]</ref>.</p><p>It might seem strange that the false-alarm rates of the proposed algorithm increase slightly for better SNRs, but this is due to the fact that the G.729 defines the clean reference. Very soft consonant parts (with insignificant low energy) are classified as speech pause by the proposed algorithm. However, these parts are classified as speech by the G.729 algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS</head><p>The proposed speech pause detection algorithm maintains a low and approximately constant false-alarm rate over a wide range of SNRs. The hit rate decreases only slightly at poorer SNRs.</p><p>Since the proposed speech pause detection algorithm was shown to be superior to the G.729 VAD algorithm in terms of discriminability (area under the ROC curve) in speech with noise, it should be preferred in applications where noise disturbances may occur.</p><p>The performance can be further enhanced if the algorithm is combined with the single-microphone noise reduction algorithm proposed by Ephraim and Malah <ref type="bibr" target="#b0">[1]</ref> and the noise reduced signal is employed for the speech pause detection.</p><p>The relatively low complexity of the algorithm should allow an immediate application in, for example, digital hearing aids or cellular phones. The delay time due to the signal processing is below 10 ms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>( 5 ) 4 )</head><label>54</label><figDesc>Three different criteria are introduced of which only one has to be true for making the decision that target speech is not present in the actual frame: a) the speech pause decision can be made because of a low signal dynamics in both the low-pass and the high-pass band (Dyn Speech Pause); b) the decision can be based on the low-pass band information (LP Speech Pause); and c) it can be made upon the high-band information (HP Speech Pause). These decision criteria are derived as follows.a) If is smaller than some threshold and also then it is assumed that only noise is present due to the very small dynamic range of the signal ( Dyn Speech Pause). b) If a) is not true, it is checked whether is bigger than (otherwise the dynamic range in the low-pass band is very small and it should not receive too much attention</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Flowchart of the proposed speech pause detection algorithm operating on a single time frame. See text for details.</figDesc><graphic coords="4,39.60,62.28,252.00,466.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Upper panel: Waveform of the sentence "I played in a theater festival, honoring the German writer Heiner Müller." Lower panel: Sentence mixed with car noise at 05 dB SNR.</figDesc><graphic coords="5,38.22,62.28,250.80,342.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Low-pass band power envelope (upper panel) and high-pass band power envelope (lower panel) of the sentence displayed in Fig. 2 when mixed with car noise at 05 dB SNR (solid curves). The dashed curves displayEand E, respectively. The detected as well as the actual speech pauses are displayed in the additional bars (see text for details).</figDesc><graphic coords="5,320.04,62.28,213.36,338.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Low-pass band power envelope (upper panel) and high-pass band power envelope (lower panel) of the sentence displayed in Fig. 2 when mixed with drilling machine noise at +5 dB SNR (solid curves). The dashed curves display E and E, respectively. The detected as well as the actual speech pauses are displayed in the additional bars (see text for details).</figDesc><graphic coords="6,58.50,62.28,213.36,372.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Low-pass band power envelope (upper panel) and high-pass band power envelope (lower panel) of the sentence displayed in Fig. 2 when mixed with restaurant noise at +5 dB SNR (solid curves). The dashed curves displayEand E, respectively. The detected as well as the actual speech pauses are displayed in the additional bars. See text for details.</figDesc><graphic coords="6,321.54,62.28,213.36,352.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Speech pause detection performance of the proposed algorithm and the G.729 VAD algorithm in car noise and multi-talker babble noise with SNRs ranging from 010 to +20 dB. The upper panel shows the false-alarm rates and the lower panel shows the hit rates with the respective algorithms.</figDesc><graphic coords="7,57.00,62.28,213.36,383.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Speech pause detection performance of the proposed algorithm and the G.729 VAD algorithm in aircraft engine and factory noise with SNRs ranging from 010 to +20 dB. The upper panel shows the false-alarm rates and the lower panel shows the hit rates with the respective algorithms.</figDesc><graphic coords="7,320.04,62.28,213.36,385.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. ROC curve of the proposed algorithm using car noise at 010 dB SNR (upper panel) and +10 dB SNR (lower panel). The curve was generated by varying the threshold in the decision rule from 1 to 25 dB in 1-dB steps. For comparison, the performance of the G.729 VAD algorithm is also indicated.</figDesc><graphic coords="8,58.50,62.28,213.36,457.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. ROC curve of the proposed algorithm using babble noise at 010 dB SNR (upper panel) and +10 dB SNR (lower panel). The curve was generated by varying the threshold in the decision rule from 1 to 25 dB in 1-dB steps.</figDesc><graphic coords="8,321.90,62.28,212.64,451.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. ROC curve of the proposed algorithm using aircraft noise at 010 dB SNR (upper panel) and +10 dB SNR (lower panel). The curve was generated by varying the threshold in the decision rule from 1 to 25 dB in 1-dB steps.</figDesc><graphic coords="9,57.00,62.28,213.36,456.96" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>According to Egan<ref type="bibr" target="#b31">[32]</ref>, the receiver operating characteristic (ROC) is a function which summarizes the possible performances of an observer faced with the task of detecting a signal in noise. In general, the ROC is given as a plot of the hit rate versus the false-alarm rate which is obtained by modifying the decision criterion. In the present study, the signal to be detected is a "speech pause" occurring in a noisy speech signal.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors thank the anonymous reviewers for critical reading of the manuscript and for their helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Speech enhancement using a minimum mean-square error short-time spectral amplitude estimator</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ephraim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Malah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust., Speech, Signal Processing</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1109" to="1121" />
			<date type="published" when="1984-06">June 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An efficient algorithm to estimate the instantaneous SNR of speech signals</title>
		<author>
			<persName><forename type="first">R</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EUROSPEECH&apos;93</title>
		<meeting>EUROSPEECH&apos;93</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">in Signal Processing VII, Theories and Applications</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EUSIPCO-94</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">J J</forename><surname>Holt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">F N</forename><surname>Cowan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Grant</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Sandham</surname></persName>
		</editor>
		<meeting>EUSIPCO-94<address><addrLine>Lausanne, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>Spectral subtraction based on minimum statistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The spectral envelope estimation vocoder</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Paul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust., Speech, Signal Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="786" to="794" />
			<date type="published" when="1981-04">Apr. 1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Computationally efficient speech enhancement by spectral minima tracking in subbands</title>
		<author>
			<persName><forename type="first">G</forename><surname>Doblinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th Eur. Conf. Speech Communication Technology EUROSPEECH&apos;95</title>
		<meeting>4th Eur. Conf. Speech Communication Technology EUROSPEECH&apos;95<address><addrLine>Madrid, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-09">Sept. 1995</date>
			<biblScope unit="page" from="1513" to="1516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Estimation of noise spectrum and its application to SNRestimation and speech enhancement</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Hirsch</surname></persName>
		</author>
		<idno>TR-93-012</idno>
	</analytic>
	<monogr>
		<title level="j">Int. Comput. Sci. Inst</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<pubPlace>Berkeley, CA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Noise estimation techniques for robust speech recognition</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ehrlicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Acoustics, Speech, Signal Processing</title>
		<meeting>IEEE Int. Conf. Acoustics, Speech, Signal essing</meeting>
		<imprint>
			<date type="published" when="1995">1995. 1995</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="153" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On improvement measures for spectral subtraction applied to robust automatic speech recognition in car environ</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop Robust Methods Speech Recognition Adverse Conditions</title>
		<meeting>Workshop Robust Methods Speech Recognition Adverse Conditions<address><addrLine>Tampere, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-05">May 1999</date>
			<biblScope unit="page" from="75" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">SNR estimation of speech signals using subbands and fourth-order statistics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nemer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Goubran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahmoud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Lett</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="171" to="174" />
			<date type="published" when="1999-07">July 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Voice activity detection in colorednoise environment through singular value decomposition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dendrinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bakamidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th Int. Conf. Signal Processing Applications and Technology</title>
		<meeting>5th Int. Conf. Signal essing Applications and Technology<address><addrLine>Waltham, MA</addrLine></address></meeting>
		<imprint>
			<publisher>DSP Associates</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="137" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The study of speech/pause detectors for speech enhancement methods</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sovka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pollák</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th Eur. Conf. Speech Communication Technology EUROSPEECH&apos;95</title>
		<meeting>4th Eur. Conf. Speech Communication Technology EUROSPEECH&apos;95<address><addrLine>Madrid, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>ESCA</publisher>
			<date type="published" when="1995-09">September 1995</date>
			<biblScope unit="page" from="1575" to="1578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Quality improvement of LPC-processed noisy speech by using spectral subtraction</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Fransen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust., Speech, Signal Processing</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="930" to="942" />
			<date type="published" when="1989-06">June 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A comparative study of speech detection methods</title>
		<author>
			<persName><forename type="first">S</forename><surname>Van Gerven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th Eur. Conf. Speech Communication Technology, EUROSPEECH&apos;97</title>
		<meeting>5th Eur. Conf. Speech Communication Technology, EUROSPEECH&apos;97<address><addrLine>Rhodes, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The design and testing of a noise reduction algorithm based on spectral subtraction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Elberling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ludvigsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Keidser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scand. Audiol</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="39" to="49" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Real-time implementation of HMM-based MMSE algorithm for speech enhancement in hearing aid applications</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sheikhzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sameti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Acoustics, Speech, Signal Processing</title>
		<meeting>IEEE Int. Conf. Acoustics, Speech, Signal essing</meeting>
		<imprint>
			<date type="published" when="1995">1995. 1995</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="808" to="811" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Comparison of voice activity detection algorithms for wireless personal communications systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>El-Maleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CCECE&apos;97 Can. Conf. Electrical Computer Engineering</title>
		<meeting>CCECE&apos;97 Can. Conf. Electrical Computer Engineering</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="470" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Voice activity detection for cellular networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gersho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Speech Coding Workshop</title>
		<meeting>IEEE Speech Coding Workshop</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="85" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Enhanced variable rate codec, speech service option 3 for wideband spread spectrum digital systems</title>
		<author>
			<persName><surname>Tia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
	<note>Document PN-3292</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Higher order statistics based Gaussianity test applied to on-line speech processing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rangoussi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Carayannis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Asilomar Conf</title>
		<meeting>IEEE Asilomar Conf</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="303" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Noise cancellation system on TMS320C31</title>
		<author>
			<persName><forename type="first">V</forename><surname>Davídek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Šika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Štusák</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st Eur</title>
		<meeting>1st Eur<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="134" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Speech signal detection in noisy environment using a local entropic criterion</title>
		<author>
			<persName><forename type="first">I</forename><surname>Abdallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Montrésor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Baudry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th Eur. Conf. Speech Communication Technology, EUROSPEECH&apos;97</title>
		<meeting>5th Eur. Conf. Speech Communication Technology, EUROSPEECH&apos;97<address><addrLine>Rhodes, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Model based speech pause detection</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Whipple</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Acoustics, Speech, Signal Processing</title>
		<meeting>IEEE Int. Conf. Acoustics, Speech, Signal essing<address><addrLine>Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997. 1997</date>
			<biblScope unit="page" from="1179" to="1182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Environmental noise reduction based on speech/nonspeech identification for hearing aids</title>
		<author>
			<persName><forename type="first">K</forename><surname>Itoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mizushima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Acoustics, Speech, Signal Processing</title>
		<meeting>IEEE Int. Conf. Acoustics, Speech, Signal essing<address><addrLine>Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Comput. Soc. Press</publisher>
			<date type="published" when="1997">1997. 1997</date>
			<biblScope unit="page" from="419" to="422" />
		</imprint>
	</monogr>
	<note>Conference Proceedings</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The efficiacy of a multichannel hearing aid in which the gain is controlled by the minima in the temporal envelope</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Festen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Van Dijkhuizen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Plomp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scand. Audiol</title>
		<imprint>
			<biblScope unit="page" from="101" to="110" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
	<note>Suppl. 38</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">729-Annex B: A Silence Compression Scheme for G.729 Optimized for Terminals Conforming to Recommendation V</title>
		<author>
			<persName><forename type="first">G</forename><surname>Itu-T Recommendation</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">70</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Noise</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Stress and Fatigue in Human Performance, R. Hockey</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1983">1983, ch. 3</date>
			<biblScope unit="page" from="61" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Robust voice-activity detection based on the wavelet transform</title>
		<author>
			<persName><forename type="first">J</forename><surname>Stegmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schröder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1997 IEEE Workshop Speech Coding Telecommunications</title>
		<meeting>1997 IEEE Workshop Speech Coding Telecommunications<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="99" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A statistical model-based voice activity detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Lett</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="1999-01">Jan. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Introduction to the Verbmobil-PhonDat Database of spoken German</title>
		<author>
			<persName><forename type="first">C</forename><surname>Draxler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Int. Conf. Practical Application Prolog</title>
		<meeting>3rd Int. Conf. Practical Application Prolog<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="201" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Description of the RSG.10 noise database</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J M</forename><surname>Steeneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">W M</forename><surname>Geurtsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TNO Inst. Perception, Soesterberg, The Netherlands, Tech. Rep. IZF</title>
		<imprint>
			<date type="published" when="1988">1988-3, 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Noise reduction schemes for digital hearing aids and their use for the hearing impaired</title>
		<author>
			<persName><forename type="first">M</forename><surname>Marzinzik</surname></persName>
		</author>
		<ptr target="http://docserver.bis.uni-oldenburg.de/publikationen/disserta-tion/2001/marnoi00/marnoi00.html" />
		<imprint>
			<date type="published" when="2000">2000</date>
			<pubPlace>Oldenburg; Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Carl von Ossietzky Universität</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Signal Detection Theory and ROC Analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Egan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>Academic</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Two-channel noise reduction algorithms motivated by models of binaural interaction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wittkop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<pubPlace>Oldenburg, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Carl von Ossietzky Univ.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">He received the Ph.D. degree in physics (supervised by B. Kollmeier) in 2000 with a dissertation on &quot;Noise reduction schemes for digital hearing aids and their use for the hearing impaired</title>
		<imprint>
			<pubPlace>Oldenburg, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Universität Oldenburg</orgName>
		</respStmt>
	</monogr>
	<note>His studies focus on dynamic compression and noise reduction for digital hearing aids</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Since 1993, he has been Full Professor of physics and Head of the Medical Physics Department at the Universität Oldenburg, Germany. He has authored or co-authored more than 100 original papers and six books and has supervised 21 completed Ph</title>
	</analytic>
	<monogr>
		<title level="m">Birger Kollmeier was born in 1958. He received the Diplom degree in physics in 1982, the M.D. degree in 1986, the Ph.D. degree in physics (supervised by M. R. Schroeder) in 1986 and the Ph</title>
		<meeting><address><addrLine>St. Louis, MO</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1982">1982. 1983. 1991-1992</date>
		</imprint>
		<respStmt>
			<orgName>Physikalisches Institut, Universität Göttingen</orgName>
		</respStmt>
	</monogr>
	<note>D. degree in medicine in 1989, all from the Universität Göttingen, Germany. He received the Fulbright Scholarship and was with Washington University and Central Institute for the Deaf. D. dissertations. Dr. Kollmeier is vice president of the German Audiological Society and has received various prizes and honors</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
