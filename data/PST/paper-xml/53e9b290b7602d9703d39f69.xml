<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Time-Space Trade-O s for Predecessor Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2007-10-16">October 16, 2007</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mihai</forename><forename type="middle">P</forename><surname>Atra Scu</surname></persName>
						</author>
						<title level="a" type="main">Time-Space Trade-O s for Predecessor Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2007-10-16">October 16, 2007</date>
						</imprint>
					</monogr>
					<idno type="MD5">771807AB9F4E3E5CDB9CD02830DEF2DC</idno>
					<idno type="arXiv">arXiv:cs/0603043v1[cs.CC]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We develop a new technique for proving cell-probe lower bounds for static data structures. Previous lower bounds used a reduction to communication games, which was known not to be tight by counting arguments. We give the rst lower bound for an explicit problem which breaks this communication complexity barrier. In addition, our bounds give the rst separation between polynomial and near linear space. Such a separation is inherently impossible by communication complexity.</p><p>Using our lower bound technique and new upper bound constructions, we obtain tight bounds for searching predecessors among a static set of integers. Given a set Y of n integers of ' bits each, the goal is to e ciently nd predecessor(x) = max fy 2 Y j y xg. For this purpose, we represent Y on a RAM with word length w using S words of space. De ning a = lg S n + lg w, we show that the optimal search time is, up to constant factors: min</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In external memory (w &gt; '), it follows that the optimal strategy is to use either standard Btrees, or a RAM algorithm ignoring the larger block size. In the important case of w = ' = lg n, for &gt; 1 (i.e. polynomial universes), and near linear space (such as S = n lg O(1) n), the optimal search time is (lg '). Thus, our lower bound implies the surprising conclusion that van Emde Boas' classic data structure from [FOCS'75] is optimal in this case. Note that for space n 1+" , a running time of O(lg '= lg lg ') was given by Beame and Fich [STOC'99].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper we provide tight trade-o s between query time and space of representation for static predecessor search. This is one of the most basic data structures, and the trade-o gives the rst separation between linear and polynomial space for any data structure problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">The Complexity-Theoretic View</head><p>Yao's cell-probe model <ref type="bibr" target="#b20">[21]</ref> is typically the model of choice for proving lower bounds on data structures. The model assumes the memory is organized in w-bit cells (alternatively called words).</p><p>In the case of static data structures, one rst constructs a representation of the input in a table with a bounded number of cells S (the space complexity). Then, a query can be answered by probing certain cells. The time complexity T is de ned to be the number of cell probes. The model allows free nonuniform computation for both constructing the input representation, and for the query algorithm. Thus, the model is stronger than the word RAM or its variants, which are used for upper bounds, implementable in a programming language like C. In keeping with the standard assumptions on the upper bound side, we only consider w = (lg n).</p><p>Typically, lower bounds in this model are proved by considering a two-party communication game. Assume Bob holds the data structure's input, while Alice holds the query. By simulating the cell-probe solution, one can obtain a protocol with T rounds, in which Alice sends lg S bits and Bob replies with w bits per round. Thus, a lower bound on the number of rounds translates into a cell-probe lower bound.</p><p>Intuitively, we do not expect this relation between cell-probe and communication complexity to be tight. In the communication model, Bob can remember past communication, and answer new queries based on this. Needless to say, if Bob is just a table of cells, he cannot remember anything, and his responses must be a function of Alice's last message (i.e. the address of the cell probe). By counting arguments, it can be shown <ref type="bibr" target="#b11">[12]</ref> that the cell-probe complexity can be much higher than the communication complexity, for natural ranges of parameters. However, a separation for an explicit problem has only been obtained in a very restricted setting. G al and Miltersen <ref type="bibr" target="#b10">[11]</ref> showed such a separation when the space complexity is very close to minimum: given an input of n cells, the space used by the data structure is n + o(n).</p><p>Besides the reduction to communication complexity, and the approach of <ref type="bibr" target="#b10">[11]</ref> for very small space, there are no known techniques applicable to static cell-probe complexity with cells of (lg n) bits. In particular, we note that the large body of work initiated by Fredman and Saks <ref type="bibr" target="#b8">[9]</ref> only applies to dynamic problems, such as maintaining partial sums or connectivity. In the case of static complexity, there are a few other approaches developed speci cally for the bit-probe model (w = 1); see <ref type="bibr" target="#b13">[14]</ref>.</p><p>In conclusion, known lower bound techniques for cell-probe complexity cannot surpass the communication barrier. However, one could still hope that communication bounds are interesting enough for natural data structure problems. Unfortunately, this is often not the case. Notice that polynomial di erences in S only translate into constant factors in Alice's message size. In the communication game model, this can only change constant factors in the number of rounds, since Alice can break a longer message into a few separate messages. Unfortunately, this means that communication complexity cannot be used to separate, say, polynomial and linear space. For many natural data-structure problems, the most interesting behavior occurs close to linear space, so it is not surprising that our understanding of static data-structure problems is rather limited.</p><p>In this work, we develop a new lower-bound technique, the cell-probe elimination lemma, targeted speci cally at the cell-probe model. Using this lemma, we obtain a separation between space n 1+o (1) and space n 1+" for any " &gt; 0. This also represents a separation between communication complexity and cell-probe complexity with space n 1+o (1) . Our lower bounds hold for predecessor search, one of the most natural and well-studied problems.</p><p>Our lower bound result has a strong direct sum avor, which is interesting in its own right. Essentially, we show that for problems with a certain structure, a data structure solving k independent subproblems with space k cannot do better than k data structures solving each problem with space .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">The Data-Structural View</head><p>Using our lower bound technique and new upper bound constructions, we obtain tight bounds for predecessor search. The problem is to represent an ordered set Y , such that for any query x we can nd e ciently predecessor(x) = max fy 2 Y j y xg. This is one of the most fundamental and well-studied problems in data structures. For a comprehensive list of references, we refer to <ref type="bibr" target="#b3">[4]</ref>; here, we only describe brie y the best known bounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.1">The Upper-Bound Story</head><p>We focus on the static case, where Y is given in advance for preprocessing. For example, we can sort Y , and later nd the predecessor of x by binary search using O(lg n) comparisons, where n = jY j.</p><p>On computers, we are particularly interested in integer keys. Thereby we also handle, say, oating point numbers whose ordering is preserved if they are cast as integers. We can then use all the instructions on integers available in a standard programming language such as C, and we are no longer limited by the (lg n) comparison based lower bound for searching. A strong motivation for considering integer keys is that integer predecessor search is asymptotically equivalent to the IP look-up problem for forwarding packets on the Internet <ref type="bibr" target="#b6">[7]</ref>. This problem is extremely relevant from a practical perspective. The fastest deployed software solutions use non-comparison-based RAM tricks <ref type="bibr" target="#b5">[6]</ref>.</p><p>More formally, we will represent Y on a unit-cost word RAM with a given word length w. We assume each integers in Y has ' bits, and that lg n ' w. On the RAM, the most natural assumption is ' = w. The case w &gt; ' models the external memory model with B = b w ' b keys per page. In this case, the well-known (comparison-based) B-trees achieve a search time of O(log B n). For the rest of the discussion, assume w = '.</p><p>Using the classic data structure of van Emde Boas <ref type="bibr" target="#b18">[19]</ref> from 1975, we can represent our integers so that predecessors can be searched in O(lg ') time. The space is linear if we use hashing <ref type="bibr" target="#b19">[20]</ref>.</p><p>In the 1990, Fredman and Willard <ref type="bibr" target="#b9">[10]</ref> introduced fusion trees, which requires linear space and can answer queries in O(log ' n) time. Combining with van Emde Boas' data structure, they got a search time of O(min f lg n lg ' ; lg 'g), which is always O( p lg n). In 1999, Beame and Fich <ref type="bibr" target="#b3">[4]</ref> found an improvement to van Emde Boas' data structure bringing the search time down to O( lg ' lg lg ' ). Combined with fusion trees, this gave them a bound of O(min f lg n lg ' ; lg ' lg lg ' g), which is always O( q lg n lg lg n ). However, the new data structure of Beame and Fich uses quadratic space, and they asked if the space could be improved to linear or near-linear.</p><p>As a partially a rmative answer to this question, we show that their O( lg ' lg lg ' ) search time can be obtained with space n 1+1= exp(lg 1 " ') for any " &gt; 0. However, we also show, as our main result, that with closer to linear space, such as n lg O(1) n, one cannot in general improve the old van Emde Boas bound of O(lg ').</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.2">The Lower-Bound Story</head><p>Ajtai <ref type="bibr" target="#b0">[1]</ref> was the rst to prove a superconstant lower bound for our problem. His results, with a correction by Miltersen <ref type="bibr" target="#b12">[13]</ref>, can be interpreted as saying that there exists n as a function of ' such that the time complexity for polynomial space is ( p lg '), and likewise there exists ' a function of n making the time complexity ( 3 p lg n). Miltersen <ref type="bibr" target="#b12">[13]</ref> revisited Ajtai's work, showing that the lower bound holds in the communication game model, and for a simpler colored predecessor problem. In this problem, the elements of Y have an associated color (say, red or blue), and the query asks only for the color of the predecessor in Y . This distinction is important, as one can reduce other problems to this simpler problem, such as existential range queries in two dimensions <ref type="bibr" target="#b14">[15]</ref> or pre x problems in a certain class of monoids <ref type="bibr" target="#b12">[13]</ref>. Like previous lower bound proofs, ours also holds for the colored problem, making the lower bounds applicable to these problems.</p><p>Miltersen, Nisan, Safra and Wigderson <ref type="bibr" target="#b14">[15]</ref> once again revisited Ajtai's proof, extending it to randomized algorithms. More importantly, they captured the essence of the proof in an independent round elimination lemma, which forms a general tool for proving communication lower bounds. Our cell-probe elimination lemma is inspired, at a high level, by this result.</p><p>Beame and Fich <ref type="bibr" target="#b3">[4]</ref> improved the lower bounds to ( lg ' lg lg ' ) and ( q lg n lg lg n ) respectively. Sen and Venkatesh <ref type="bibr" target="#b15">[16]</ref> later gave an improved round elimination lemma, which can reprove the lower bounds of Beame and Fich, but also for randomized algorithms. Analyzing the time-space tradeo s obtained by these proofs, one obtains ( lg n lg w ; lg ' lg lg S ), where S is the space bound, and possibly w &gt; '.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">The Optimal Trade-O s</head><p>De ne lg x = dlog 2 (x + 2)e, so that lg x 1 even if x 2 [0; 1]. Assuming space S, and de ning a = lg S n + lg w, we show that the optimal search time is, up to constant factors:</p><formula xml:id="formula_0">min 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : log w n lg ' lg n a lg ' a lg a lg n lg ' a lg ' a lg lg ' a / lg lg n a<label>(1)</label></formula><p>The upper bounds are achieved by a deterministic query algorithm on a RAM. The data structure can be constructed in expected time O(S) by a randomized algorithm, starting from a sorted list of integers. The lower bounds hold for deterministic query algorithms answering the colored predecessor problem in the cell-probe model. When S n 1+" for some constant " &gt; 0, the lower bounds also hold in the stronger communication game model, even allowing randomization with two-sided error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.1">External Memory and Branch One</head><p>To understand the rst branch of the trade-o , rst consider the typical case on a RAM, when a word ts exactly one integer, i.e. w = '. In this case, the bound is log ' n, which describes the performance of fusion trees <ref type="bibr" target="#b9">[10]</ref>.</p><p>To understand the case w &gt; ', consider the external memory model with B words per page. This model has as a nonuniform counterpart the cell-probe model with cells of size w = B'. Observe that only the rst branch of our trade-o depends on w. This branch is log w n = lg n lg B+lg ' = (minflog ' n; log B ng). The rst term describes the performance of fusion trees on a RAM with 'bit words, as noted above. The second term matches the performance of the B-tree, the fundamental data structure in external memory.</p><p>Thus, we show that it is always optimal to either use a standard B-tree, or the best RAM algorithm which completely ignores the bene ts of external memory. The RAM algorithm uses '-bit words, and ignores the grouping of words into pages; this algorithm is the best of fusion trees and the algorithms from branches 2{4 of the trade-o . Thus, the standard comparison-based B-tree is the optimal use of external memory, even in a strong model of computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.2">Polynomial Universes: Branch Two</head><p>For the rest of the discussion, assume the rst branch (B-trees and fusion trees) does not give the minimum. Some of the most interesting consequences of our results can be seen in the very important special case when integers come from a polynomial universe, i.e. ' = O(lg n). In this case, the optimal complexity is (lg ' lg n a ), as given by the second branch of the trade-o . On the upper bound side, this is achieved by a simple elaboration of van Emde Boas' data structure. This data structure gives a way to reduce the key length from ' to '  2 in constant time, which immediately implies an upper bound of O(lg '). To improve that, rst note that when ' a, we can stop the recursion and use complete tabulation to nd the result. This means only O(lg ' a ) steps are needed. Another trivial idea, useful for near-linear universes, is to start with a table lookup based on the rst lg n bits of the key, which requires linear space. Then, continue to apply van Emde Boas for keys of w lg n bits inside each subproblem, giving a complexity of O(lg w lg n a ). Quite surprisingly, our lower bound shows that van Emde Boas' classic data structure, with these trivial tweaks, is optimal. In particular, when the space is not too far from linear (at most n 2 lg 1 " n ) and ' (1 + ") lg n, the standard van Emde Boas bound of (lg ') is optimal. It was often conjectured that this bound could be improved.</p><p>Note that with space n 1+" , the optimal complexity for polynomial universes is constant. However, with space n 1+o (1) , the bound is !(1), showing the claimed complexity-theoretic separations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.3">The Last Two Branches</head><p>The last two branches are relevant for superpolynomial universes, i.e. ' = !(lg n). Comparing the two branches, we see the third one is better than the last one (up to constants) when a = (lg n). On the other hand, the last branch can be asymptotically better when a = o(lg n). This bound has the advantage that in the logarithm in the denominator, the factor a lg n , which is subconstant for a = o(lg n), is replaced by 1= lg a lg n . The third branch is obtained by a careful application of the techniques of Beame and Fich <ref type="bibr" target="#b3">[4]</ref>, which can improve over van Emde Boas, but need large space. The last branch is also based on these techniques, combined with novel approaches tailored for small space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.4">Dynamic Updates</head><p>Lower bounds for near-linear space easily translate into interesting lower bounds for dynamic problems. If inserting an element takes time t u , we can obtain a static data structure using space O(n t u ) by simply simulating n inserts and storing the modi ed cells in a hash table. This transformation works even if updates are randomized, but, as before, we require that queries be deterministic. This model of randomized updates and deterministic queries is standard for hashing-based data structures. By the discussion above, as long as updates are reasonably fast, one cannot in general improve on the O(lg ') query time. It should be noted that van Emde Boas data structure can handle updates in the same time as queries, so this classic data structure is also optimal in the typical dynamic case, when one is concerned with the slowest operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Contributions</head><p>We now discuss our contributions in establishing the tight results of (1). Our main result is proving the tight lower bounds for a = o(lg n) (in particular, branches two and four of the trade-o ). As mentioned already, previous techniques were helpless, since none could even di erentiate a = 2 from a = lg n.</p><p>Interestingly, we also show improved lower bounds for the case a = (lg n), in the classic communication framework. These improvements are relevant to the third branch of the trade-o . Assuming for simplicity that a w<ref type="foot" target="#foot_0">1</ref> " , our bound is min f lg n lg w ; lg w lg lg w+lg(a= lg n) g, whereas the best previous lower bound was min f lg n lg w ; lg w lg a g. Our improved bound is based on a simple, yet interesting twist: instead of using the round elimination lemma alone, we show how to combine it with the message compression lemma of Chakrabarti and Regev <ref type="bibr" target="#b4">[5]</ref>. Message compression is a re nement of round elimination, introduced by <ref type="bibr" target="#b4">[5]</ref> to prove a lower bound for the approximate nearest neighbor problem. Sen and Venkatesh <ref type="bibr" target="#b15">[16]</ref> asked whether message compression is really needed, or one could just use standard round elimination. Our result sheds an interesting light on this issue, as it shows message compression is even useful for classic predecessor lower bounds.</p><p>On the upper bound side, we only need to show the last two branches of the trade-o . As mentioned already, we use techniques of Beame and Fich <ref type="bibr" target="#b3">[4]</ref>. The third bound was anticipated 1 by the second author in the concluding remarks of <ref type="bibr" target="#b17">[18]</ref>. The last branch of (1), tailored speci cally for small space, is based on novel ideas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5">Direct-Sum Interpretations</head><p>A very strong consequence of our proofs is the idea that sharing between subproblems does not help for predecessor search. Formally, the best cell-probe complexity achievable by a data structure representing k independent subproblems (with the same parameters) in space k is asymptotically equal to the best complexity achievable by a data structure for one subproblem, which uses space . The simplicity and strength of this statement make it interesting from both the data-structural and complexity-theoretic perspectives.</p><p>At a high level, it is precisely this sort of direct-sum property that enables us to beat communication complexity. Say we have k independent subproblems, and total space S. While in the communication game Alice sends lg S bits per round, our results intuitively state that lg S k bits are su cient. Then, by carefully controlling the increase in k and the decrease in key length (the query size), we can prevent Alice from communicating her entire input over a superconstant number of rounds.</p><p>A nice illustration of the strength of our result are the tight bounds for near linear universes, i.e. ' = lg n + , with = o(lg n). On the upper bound side, the algorithm can just start by a table lookup based on the rst lg n bits of the key, which requires linear space. Then, it continues to apply van Emde Boas for -bit keys inside each subproblem, which gives a complexity of O(lg a ). Obtaining a lower bound is just as easy, given our techniques. We rst consider n=2 independent subproblems, where each has 2 integers of 2 bits each. Then, we pre x the integers in each subproblem by the number of the subproblem (taking lg n bits), and pre x the query with a random subproblem number. Because the universe of each subproblem (2 2 ) is quadratically bigger than the number of keys, we can apply the usual proof showing the optimality of van Emde Boas' bound for polynomial universes. Thus, the complexity is (lg a ).</p><p>2 Lower Bounds for Small Space</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Cell-Probe Elimination Lemma</head><p>An abstract decision data structure problem is de ned by a function f : D Q ! f0; 1g. An input from D is given at preprocessing time, and the data structure must store a representation of it in some bounded space. An input from Q is given at query time, and the function of the two inputs must be computed through cell probes. We restrict the preprocessing and query algorithms to be deterministic. In general, we consider a problem in conjunction with a distribution D over D Q. Note that the distribution need not (and, in our case, will not) be a product distribution. We care about the probability the query algorithm is successful under the distribution D (for a notion of success to be de ned shortly).</p><p>As mentioned before, we work in the cell-probe model, and let w be the number of bits in a cell. We assume the query's input consists of at most w bits, and that the space bound is at most 2 w . For the sake of an inductive argument, we extend the cell-probe model by allowing the data structure to publish some bits at preprocessing time. These are bits depending on the data structure's input, which the query algorithm can inspect at no charge. Closely related to this concept is our model for a query being successful. We allow the query algorithm not to return the correct answer, but only in the following very limited way. After inspecting the query and the published bits, the algorithm can declare that it cannot answer the query (we say it rejects the query). Otherwise, the algorithm can make cell probes, and at the end it must answer the query correctly. Thus, we require an a priori admission of any \error". In contrast to models of silent error, it actually makes sense to talk about tiny (close to zero) probabilities of success, even for problems with boolean output.</p><p>For an arbitrary problem f and an integer k 2 w , we de ne a direct-sum problem L k f :</p><formula xml:id="formula_1">D k ([k] Q) ! f0; 1g as follows.</formula><p>The data structure receives a vector of inputs (d 1 ; : : : ; d k ). The representation depends arbitrarily on all of these inputs. The query is the index of a subproblem i 2 [k], and an element q 2 Q. The output of</p><formula xml:id="formula_2">L k f is f (q; d i ).</formula><p>We also de ne a distribution L k D for L k f , given a distribution D for f . Each d i is chosen independently at random from the marginal distribution on D induced by D. The subproblem i is chosen uniformly from [k], and q is chosen from the distribution on Q conditioned on d i .</p><p>Given an arbitrary problem f and an integer h w, we can de ne another problem f (h) as follows. The query is a vector (q 1 ; : : : ; q h ). The data structure receives a regular input d 2 D, and integer r 2 [h] and the pre x of the query q 1 ; : : : ; q r 1 . The output of f (h) is f (d; q r ). Note that we have shared information between the data structure and the querier (i.e. the pre x of the query), so f (h) is a partial function on the domain D S t 1 i=0 Q i Q. Now we de ne an input distribution D (h) for f (h) , given an input distribution D for f . The value r is chosen uniformly at random. Each query coordinate q i is chosen independently at random from the marginal distribution on Q induced by D. Now d is chosen from the distribution on D, conditioned on q r . We give the f (h) operator precedence over the direct sum operator, i.e.</p><formula xml:id="formula_3">L k f (h) means L k f (h) .</formula><p>Using this notation, we are ready to state our central cell-probe elimination lemma:</p><p>Lemma 1. There exists a universal constant C, such that for any problem f , distribution D, and positive integers h and k, the following holds. Assume there exists a solution to L k f (h) with success probability over L k D (h) , which uses at most k words of space, 1 C ( h ) 3 k published bits and T cell probes. Then, there exists a solution to L k f with success probability 4h over L k D, which uses the same space, k h p Cw 2 published bits and T 1 cell probes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Setup for the Predecessor Problem</head><p>Let P (n; ') be the colored predecessor problem on n integers of ' bits each. Remember that this is the decision version of predecessor search, where elements are colored red or blue, and a query just returns the color of the predecessor. We rst show how to identify the structure of P (n; ') (h) inside P (n; h'), making it possible to apply our cell-probe elimination lemma.</p><p>Lemma 2. For any integers n; '; h 1 and distribution D for P (n; '), there exists a distribution D (h) for P (n; h') such that the following holds. Given a solution to L k P (n; h') with success probability over L k D (h) , one can obtain a solution to L k P (n; ') (h) with success probability over L k D (h) , which has the same complexity in terms of space, published bits, and cell probes.</p><p>Proof. We give a reduction from P (n; ') (h) to P (n; h'), which naturally de nes the distribution D (h) in terms of D (h) . A query for P (n; ') (h) consists of x 1 ; : : : ; x h 2 f0; 1g ' . Concatenating these, we obtain a query for P (n; h'). In the case of P (n; ') (h) , the data structure receives i 2 [h], the query pre x x 1 ; : : : ; x i 1 and a set Y of '-bit integers. We prepend the query pre x to all integers in Y , and append zeros up to h' bits. Then, nding the predecessor of x i in Y is equivalent to nding the predecessor of the concatenation of x 1 ; : : : ; x h in this new set.</p><p>Observe that to apply the cell-probe elimination lemma, the number of published bits must be just a fraction of k, but applying the lemma increases the published bits signi cantly. We want to repeatedly eliminate cell probes, so we need to amplify the number of subproblems each time, making the new number of published bits insigni cant compared to the new k. Lemma 3. For any integers t; '; n 1 and distribution D for P (n; '), there exists a distribution D t for P (n t; ' + lg t) such that the following holds. Given a solution to L k P (n t; ' + lg t)</p><p>with success probability over L k D t , one can construct a solution to L kt P (n; ') with success probability over L kt D, which has the same complexity in terms of space, published bits, and cell probes.</p><p>Proof. We rst describe the distribution D t . We draw Y 1 ; : : : ; Y t independently from D, where Y i is a set of integers, representing the data structures input. Pre x all numbers in Y j by j using lg t bits, and take the union of all these sets to form the data structure's input for P (nt; ' + lg t). To obtain the query, pick j 2 f0; : : : ; t 1g uniformly at random, pick the query from D conditioned on Y j , and pre x this query by j. Now note that L kt D and L k D t are really the same distribution, except that the lower lg t bits of the problems index for L kt D are interpreted as a pre x in L k D t .</p><p>Thus, obtaining the new solution is simply a syntactic transformation.</p><p>Our goal is to eliminate all cell probes, and then reach a contradiction. For this, we need the following impossibility result for a solution making zero cell probes: Lemma 4. For any n 1 and ' log 2 (n + 1), there exists a distribution D for P (n; ') such that the following holds. For all (8)0 &lt; 1 and k 1, there does not exist a solution to</p><formula xml:id="formula_4">L k P (n; ')</formula><p>with success probability over L k D, which uses no cell probes and less than k published bits.</p><p>Proof. The distribution D is quite simple: the integers in the set are always 0 up to n 1, and the query is n. All that matters is the color of n 1, which is chosen uniformly at random among red and blue. Note that for L k P (n; ') there are only k possible queries, i.e. only the index of the subproblem matters.</p><p>Let p be the random variable denoting the published bits. Since there are no cell probes, the answers to the queries are a function of p alone. Let (p) be the fraction of subproblems that the query algorithm doesn't reject when seeing the published bits p. In our model, the answer must be correct for all these subproblems. Then, Pr[p = p] 2 (p)k , as only inputs which agree with the (p)k answers of the algorithm can lead to these published bits. Now observe that</p><formula xml:id="formula_5">= E p [ (p)] E p h 1 k log 2 1 Pr[p=p] i = 1 k H(p)</formula><p>, where H( ) denotes binary entropy. Since the entropy of the published bits is bounded by their number (less than k), we have a contradiction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Showing Predecessor Lower Bounds</head><p>Our proof starts assuming that we for any possible distribution have a solution to P (n; ') which uses n 2 a space, no published bits, and successfully answers all queries in T probes, where T is small. We will then try to apply T rounds of the cell-probe elimination from Lemma 1 and 2 followed by the problem ampli cation from Lemma 3. After T rounds, we will be left with a nontrivial problem but no cell probes, and then we will reach a contradiction with Lemma 4. Below, we rst run this strategy ignoring details about the distribution, but analyzing the parameters for each round. Later in Lemma 5, we will present a formal inductive proof using these parameters in reverse order, deriving di cult distributions for more and more cell probes.</p><p>We denote the problem parameters after i rounds by a subscript i. We have the key length ' i and the number of subproblems k i . The total number of keys remains n, so the have n=k i keys in each subproblem. Thus, the problem we deal with in round i + 1 is</p><formula xml:id="formula_6">L k i P ( n k i ; ' i )</formula><p>, and we will have some target success probability i . The number of cells per subproblem is i = n k i 2 a . We start the rst round with ' 0 = '; 0 = 1; k 0 = 1 and 0 = n 2 a . For the cell probe elimination in Lemma 1 and 2, our proof will use the same value of h 2 in all rounds. Then i+1 i 4h , so i (4h) i . To analyze the evolution of ' i and k i , we let t i be the factor by which we increase the number of subproblems in round i when applying the problem ampli cation from Lemma 3. We now have k i+1 = t i k i and ' i+1 = ' i h lg t i . When we start the rst round, we have no published bits, but when we apply Lemma 1 in round i + 1, it leaves us with up to k i h p i Cw 2 published bits for round i + 2. We have to choose t i large enough to guarantee that this number of published bits is small enough compared to the number of subproblems in round i + 2. To apply Lemma 1 in round i + 2, the number of published bits must be at most 1 3 . Assume for now that T = O(lg '). Using h ', and i (4h) T 2 O(lg 2 ') , we conclude it is enough to set: (8)i :</p><formula xml:id="formula_7">C ( i+1 h ) 3 k i+1 = 3 i t i 64Ch 6 k i . Hence we must set t i h p i 64C 2 w 2 h 6 ( 1 i )</formula><formula xml:id="formula_8">t i h r n k i 2 a=h w 2 2 (lg 2 ')<label>(2)</label></formula><p>Now we discuss the conclusion reached at the end of the T rounds. We intend to apply Lemma 4 to deduce that the algorithm after T stages cannot make zero cell probes, implying that the original algorithm had to make more than T probes. Above we made sure that we after T rounds had</p><formula xml:id="formula_9">1 C ( T h ) 3 k T &lt; T k T published</formula><p>bits, which are few enough compared to the number k T of subproblems. The remaining conditions of Lemma 4 are:</p><formula xml:id="formula_10">' T 1 and n k T 1 (3) Since ' i+1 ' i</formula><p>2 , this condition entails T = O(lg '), as assumed earlier.</p><p>Lemma 5. With the above parameters satisfying ( <ref type="formula" target="#formula_8">2</ref>) and ( <ref type="formula">3</ref>), for i = 0; : : : ; T , there is a distribution D i for P ( n k i ; ' i ) so that no solution for</p><formula xml:id="formula_11">L k i P ( n k i ; ' i ) can have success probability i over L k i D i using n 2 a space, 1 C ( i h ) 3 k i published bits, and T i cell probes.</formula><p>Proof. The proof is by induction over T i. A distribution that de es a good solution as in the lemma is called di cult. In the base case i = T , the space doesn't matter, and we get the di cult distribution directly from (3) and Lemma 4. Inductively, we use a di cult distribution D i to construct a di cult distribution D i 1 .</p><p>Recall that k i = k i 1 t i 1 . Given our di cult distribution D i , we use the problem ampli cation in Lemma 3, to construct a distribution D</p><formula xml:id="formula_12">t i 1 i for P ( n k i t i 1 ; ' i + lg t i 1 ) = P ( n k i 1 ; ' i + lg t i 1 ) so that no solution for L k i 1 P ( n k i 1 ; ' i + lg t i 1 ) can have success probability i over L k i 1 D t i 1 i using n 2 a space, 1 C ( i h ) 3 k i published bits, and T i cell probes. Recall that (2) implies k i 1 h p i 1 Cw 2 1 C ( i h ) 3 k i , hence that k i 1 h p i 1</formula><p>is less than the number of bits allowed published for our di cult distribution</p><formula xml:id="formula_13">D t i 1 i</formula><p>. Also, recall that j k j = n 2 a for all j. We can therefore use the cell probe elimination in Lemma 1, to construct a distribution</p><formula xml:id="formula_14">D t i 1 i (h) for P ( n k i 1 ; ' i + lg t i 1 ) (h) so that no solution for L k i 1 P ( n k i 1 ; ' i + lg t i 1 ) (h) can have success probability i 1 h i over L k i 1 D t i 1 i (h) using n 2 a space, 1 C ( i 1 h ) 3 k i 1 published</formula><p>bits, and T i + 1 cell probes. Finally, using Lemma 2, we use D</p><formula xml:id="formula_15">t i 1 i (h) to construct the desired di cult distribution D i 1 for P ( n k i 1 ; h(' i + lg t i 1 )) = P ( n k i 1 ; ' i 1 ).</formula><p>The predecessor lower bound then follows by applying Lemma 5 with i = 0 and the initial parameters ' 0 = '; 0 = 1; k 0 = 1. We conclude that there is a di cult distribution D 0 for P (n; ') with no solution getting success probability 1 using n 2 a space, 0 published bits, and T cell probes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Calculating the Trade-O s</head><p>In this section, we show how to choose h and t i in order to maximize the lower bound T , under the conditions of ( <ref type="formula" target="#formula_8">2</ref>) and (3). First, we show a simple bound on a recursion that shows up repeatedly in our analysis: Lemma 6. Consider the recursion x i+1</p><p>x i , for 1. As long as i log 1= (</p><formula xml:id="formula_16">x 0 1+ =(1 ) ), we have x i 1.</formula><p>Proof. Expanding the recursion, we have</p><formula xml:id="formula_17">x i x 0 i ( i 1 + +1) = x 0 i 1 i 1 . For x i 1, we must have x 0 i 1 + 1 i 1 , which is true if x 0 i 1 + 1 . This gives i log 1= ( x 0 1+ =(1 ) ).</formula><p>We now argue that the bound for low space that we are trying to prove can only be better than the communication complexity lower bound when lg ' = O((lg lg n) 2 ). This is relevant because our cell-probe elimination lemma is less than perfect in its technical details, and cannot always achieve the optimal bound. Fortunately, however, it does imply an optimal bound when ' is not too large, and in the remaining cases an optimal lower bound follows from communication complexity.</p><p>Remember that for space O(n 2 ), communication complexity implies an asymptotic lower bound of minf lg n lg w ; lg('= lg n) lg lg('= lg n) g. If lg ' = ((lg lg n) 2 ), this is (minf lg n lg w ; lg ' lg lg ' g). For a lg n, we are trying to prove an asymptotic lower bound of minf lg n lg w ;</p><formula xml:id="formula_18">lg('=a) lg(lg ' a = lg lg n a )</formula><p>g. If lg ' = ((lg lg n) 2 ), this becomes (minf lg n lg w ; lg ' lg lg ' g), which is identical to the communication bound.</p><p>Polynomial Universes. Assume that ' 3 lg n. We rst show a lower bound of (lg lg n a ), which matches van Emde Boas on polynomial universes. For this, it su ces to set h = 2 and Here we have used lg w = O((lg lg n) 2 ), which is the regime in which our bound for small space can be an improvement over the communication bound.</p><formula xml:id="formula_19">t i = ( n k i ) 3=4 . Then, n k i+1 = ( n k i ) 1=4 ,</formula><p>Handling Larger Universes. We now show how one can take advantage of a higher w to obtain larger lower bounds. We continue to assume w 3 lg n. Our strategy is to use the smallest t i possible according to <ref type="bibr" target="#b1">(2)</ref> and superconstant h. To analyze the recursion for ' i , we just bound t i n, so ' i+1 ' i h lg n. Using Lemma 6, we have ' T 1 for T (lg h ( w lg n )). We also have the recursion:</p><formula xml:id="formula_20">lg n k i+1 = lg n k i lg t i = 1 1 h lg n k i a h O(lg 2 w)</formula><p>Again by Lemma 6, we see that n k T 1 if:</p><formula xml:id="formula_21">T lg lg n h ( a h + lg 2 w) /lg 1 1 1 h ! = h lg lg n a + h lg 2 w = min h lg lg n a ; h lg lg n h lg 2 w</formula><p>As mentioned before, the condition ' T 1 in (3) implies T = O(lg w), so we can assume h = O(lg w). Remember that we are assuming lg w = O((lg lg n) 2 ), so the second term in the min is just (h lg lg n). Then, the entire expression simpli es to (h lg lg n a ). The lower bound we obtain is be the minimum of the bounds derived by considering ' i and k i . We then choose h to maximize this minimum, arriving at:</p><formula xml:id="formula_22">max h min lg(w= lg n) lg h ; h lg lg n a</formula><p>Clearly, the (lg lg n a ) bound derived previously still holds. Then, we can claim a lower bound that is the maximum of this and our new bound, or, equivalently up to constants, their sum: We choose h to balance the two terms, so h lg h = lg(w=a) lg(lg n=a) and lg h = (lg lg w a lg lg lg n a ). Then the bound is ( lg(w=a) lg lg(w=a) lg lg(lg n=a) ).</p><formula xml:id="formula_23">lg</formula><p>Handling Smaller Universes. Finally, we consider smaller universes, i.e. w &lt; 3 lg n. Let w = + lg n. We start by applying Lemma 3 once, with t = n=2 =2 . Now we are looking at the problem L t P (2 =2 ; 3 2 ). Observe that the subproblems have a universe which is cubic in the number of integers in the subproblem. Then, we can just apply our strategy for polynomial universes, starting with ' 0 = 3 2 and n 0 = 2 =2 . We obtain a lower bound of (lg a ) = (lg w lg n a ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proof of Cell-Probe Elimination</head><p>We assume a solution to L k f (h) , and use it to construct a solution to L k f . The new solution uses the query algorithm of the old solution, but skips the rst cell probe made by this algorithm.</p><p>A central component of our construction is a structural property about any query algorithm for L k f (h) with the input distribution L k D (h) . We now de ne and claim this property. Section 3.1 uses it to construct a solution for L k f , while Section 3.2 gives the proof.</p><p>We rst introduce some convenient notation. Remember that the data structure's input for L k f (h) consists of a vector (d 1 ; : : : ; d k ) 2 D k , a vector selecting the interesting segments (r 1 ; : : : ; r k ) 2</p><p>[h] k and the query pre xes Q i j for all j 2 [r i 1]. Denote by d; r and Q the random variables giving these three components of the input. Also let p be the random variable representing the bits published by the data structure. Note that p can also be understood as a function p(d; r; Q). The query consists of an index i selecting the interesting subproblem, and a vector (q 1 ; : : : ; q h ) with a query to that subproblem. Denote by i and q these random variables. Note that in our probability space L k f (h) , we have</p><formula xml:id="formula_24">q j = Q i j ; (8)j &lt; r i .</formula><p>Fix some instance p of the published bits and a subproblem index i 2 [k]. Consider a pre x (q 1 ; : : : ; q j ) for a query to this subproblem. Depending on q j+1 ; : : : ; q h , the query algorithm might begin by probing di erent cells, or might reject the query. Let i (p; q 1 ; : : : ; q j ) be the set of cells that could be inspected by the rst cell probe. Note that this set could be ?, if all queries are rejected. Now de ne:</p><formula xml:id="formula_25">" i (p) = ( 0 if i (p; Q i ) = ?</formula><p>Pr h j i (p; q 1 ; : : : ; q r i )j minf ;j i (p;Q i )jg</p><formula xml:id="formula_26">h p j i = i i otherwise<label>(4)</label></formula><p>The probability space is that de ned by L k D (h) when the query is to subproblem i. In particular, such a query will satisfy q j = Q i j ; (8)j &lt; r i , because the pre x is known to the data structure. Note that this de nition completely ignores the su x q r i +1 ; : : : ; q h of the query. The intuition behind this is that for any choice of the su x, the correct answer to the query is the same, so this su x can be \manufactured" at will. Indeed, an arbitrary choice of the su x is buried in the de nition of i .</p><p>With these observations, it is easier to understand (4). If the data structure knows that no query to subproblem i will be successful, " i = 0. Otherwise, we compare two sets of cells. The rst contains the cells that the querier might probe given what the data structure knows: i (p; Q i ) contains all cells that could be probed for various q i r i and various su xes. The second contains the cells that the querier could choose to probe considering its given input q i r i (the querier is only free to choose the su x). Obviously, the second set is a subset of the rst. The good case, whose probability is measured by " i , is when it is a rather large subset, or at least large compared to .</p><p>For convenience, we de ne</p><formula xml:id="formula_27">" (p) = E i [k] [" i (p)] = 1 k P i " i (p).</formula><p>Using standard notation from probability theory, we write " i (p j E), when we condition on some event E in the probability of (4). We also write " i (p j X) when we condition on some random variable X, i.e. " i (p j X) is a function x 7 ! " i (p j X = x). We are now ready to state our claim, to be proven in Section 3.2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Solution for L k f</head><p>As mentioned before, we use the solution for L k f (h) , and try to skip the rst cell probe. To use this strategy, we need to extend an instance of L k f to an instance of L k f (h) . This is done using the r and Q values whose existence is guaranteed by Lemma 7. The extended data structure's input consists of the vector (d 1 ; : : : ; d k ) given to L k f , and the vectors r and Q. A query's input for</p><formula xml:id="formula_28">L k f is a problem index i 2 [k]</formula><p>and a q 2 Q. We extend this to (q 1 ; : : : ; q h ) by letting q j = Q i j ; (8)j &lt; r i , and q r i = q, and manufacturing a su x q r i +1 ; : : : ; q h as described below.</p><p>First note that extending an input of L k f to an input of L k f (h) by this strategy preserves the desired answer to a query (in particular, the su x is irrelevant to the answer). Also, this transformation is well de ned because r and Q are \constants", de ned by the input distribution L k D (h) . Since our model is nonuniform, we only care about the existence of r and Q, and not about computational aspects.</p><p>To fully describe a solution to L k f , we must specify how to obtain the data structure's representation and the published bits, and how the query algorithm works. The data structure's representation is identical to the representation for L k f (h) , given the extended input. The published bits for L k f consist of the published bits for L k f (h) , plus a number of published cells from the data structure's representation. Which cells are published will be detailed below. We publish the cell address together with its contents, so that the query algorithm can tell whether a particular cell is available. The query algorithm is now simple to describe. Remember that q 1 ; : : : ; q r i 1 are prescribed by Q, and q r i = q is the original input of L k f . We now iterate through all possible query su xes. For each possibility, we simulate the extended query using the algorithm for L k f (h) . If this algorithm rejects the query, or the rst probed cell is not among the published cells, we continue trying su xes. Otherwise, we stop, obtain the value for the rst cell probe from the published cells and continue to simulate this query using actual cell probes. If we don't nd any good su x, we reject the query. It is essential that we can recognize success in the old algorithm by looking just at published bits. Then, searching for a su x that would not be rejected is free, as it does not involve any cell probes.</p><p>Publishing cells. It remains to describe which cells the data structure chooses to publish, in order to make the query algorithm successful with the desired probability. Let p be the bits published by the L k f (h) solution. Note that in order to make the query (i; q) successful, we must publish one cell from i (p; Q i ; q). Here, we slightly abuse notation by letting Q i ; q denote the r i entries of the pre x Q i , followed by q. We will be able to achieve this for all (i; q) satisfying:</p><formula xml:id="formula_29">i (p; Q i ) 6 = ? and j i (p; Q i ; q)j minf ; j i (p; Q i )jg h p<label>(5)</label></formula><p>Comparing to (4), this means the success probability is at least " (p j r = r; Q = Q; d = (d 1 ; : : : ; d k )). Then on average over possible inputs (d 1 ; : : : ; d k ) to L k f , the success probability will be at least 2h , as guaranteed by Lemma 7.</p><p>We will need the following standard result:</p><p>Lemma 8. Consider a universe U 6 = ? and a family of sets F such that (8)S 2 F we have S U and jSj jU j B . Then there exists a set T U; jT j B ln jFj such that (8)S 2 F; S \ T 6 = ?.</p><p>Proof. Choose B ln jFj elements of U with replacement. For a xed S 2 F, an element is outside S with probability at most 1 1 B . The probability all elements are outside S is at most (1 1 B ) B ln jF j &lt; e ln jF j &lt; 1 jF j . By the union bound, all sets in F are hit at least once with positive probability, so a good T exists.</p><p>We distinguish three types of subproblems, parallel to <ref type="bibr" target="#b4">(5)</ref>. If i (p; Q i ) = ?, we make no claim (the success probability can be zero). Otherwise, if j i (p; Q i )j &lt; , we handle subproblem i using a local strategy. Consider all q such that j i (p; Q i ; q)j j i (p;Q i )j h p . We now apply Lemma 8 with the universe i (p; Q i ) and the family i (p; Q i ; q), for all interesting q's. There are at most 2 w choices of q, bounding the size of the family. Then, the lemma guarantees that the data structure can publish a set of O( h p w) cells which contains at least one cell from each interesting set. This means that each interesting q can be handled successfully by the algorithm.</p><p>We handle the third type of subproblems, those with j i (p; Q i )j , in a global fashion. Consider all \interesting" pairs (i; q) with j i (p; Q i ; q)j 1 1=h . We now apply Lemma 8 with the universe consisting of all k cells, and the family being i (p; Q i ; q), for interesting (i; q). The cardinality of the family is at most 2 w , since i and q form a query, which takes at most one word.</p><p>Then by Lemma 8, the data structure can publish a set of O(k h p w) cells, which contains at least one cell from each interesting set. With these cells, the algorithm can handle successfully all interesting (i; q) queries.</p><p>The total number of cells that we publish is O(k h p w). Thus, we publish O(k h p w 2 ) new bits, plus O(k) bits from the assumed solution to L k f (h) . For big enough C, this is at most k h p Cw 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">An Analysis of</head><formula xml:id="formula_30">L k f (h) : Proof of Lemma 7</formula><p>Our analysis has two parts. First, we ignore the help given by the published bits, by assuming they are constantly set to some value p. As r i and Q i are chosen randomly, we show that the conditions of (4) are met with probability at least 1 h times the success probability for subproblem i. This is essentially a lower bound on " i , and hence on " .</p><p>Secondly, we show that the published bits do not really a ect this lower bound on " . The intuition is that there are two few published bits (much fewer than k) so for most subproblems they are providing no information at all. That is, the behavior for that subproblem is statistically close to when the published bits would not be used. Formally, this takes no more than a (subtle) application of Cherno bounds. The gist of the idea is to consider some setting p for the published bits, and all possible inputs (not just those leading to p being published). In this probability space, " i are independent for di erent i, so the average is close to " with overwhelmingly high probability. Now pessimistically assume all inputs where the average of " i is not close to " are possible inputs, i.e. input for which p would be the real help bits. However, the probability of this event is so small, that even after a union bound for all p, it is still negligible.</p><p>We now proceed to the rst part of the analysis. Let i (p) be the probability that the query algorithm is successful when receiving a random query for subproblem i. Formally, i (p) = Pr[ i (p; q) 6 = ? j i = i]. We de ne i (p j E); i (p j X) and ( ) similar to the functions associated to " i . Observe that the probability of correctness guaranteed by assumption is = E r;Q;d [ (p(r; Q; d) j r; Q; d)]. Lemma 9. For any i and p, we have " i (p) i (p) h . Proof. Let us rst recall the random experiment de ning " i (p). We select a uniformly random r 2 [h] and random q 1 ; : : : ; q r 1 . First we ask whether i (p; q 1 ; : : : ; q r 1 ) = ?. If not, we ask about the probability that a random q r is good, in the sense of (4). Now let us rephrase the probability space as follows: rst select q 1 ; : : : ; q h at random; then select r 2 [h] and use just q 1 ; : : : ; q r as above. The probability that the query (q 1 ; : : : ; q h ) is handled successfully is precisely i (p). Let's assume it doesn't. Then, for any r, i (p; q 1 ; : : : ; q r 1 ) 6 = ? because there is at least one su x which is handled successfully. We will now show that there is at least one choice of r such that q r is good when the pre x is q 1 ; : : : ; q r 1 . When averaged over q 1 ; : : : ; q r 1 , this gives a probability of at least</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i (p) h</head><p>To show one good r, let r = minfj i (p; q 1 ; : : : ; q r 1 )j; g. Now observe that 1 . By the pigeonhole principle, (9)r : r r+1 1=h . This implies j i (p; q 1 ; : : : ; q r )j minf ;j i (p;q 1 ;:::;q r 1 )j h p , as desired.</p><p>Note that if the algorithm uses zero published bits, we are done. Thus, for the rest of the analysis we may assume 1 C ( h ) 3 k 1. We now proceed to the second part of the analysis, showing that " is close to the lower bound of the previous lemma, even after a union bound over all possible published bits.</p><p>Lemma 10. With probability at least 1 8h over random r; Q and d: (8)p : " (p j r; Q; d)</p><formula xml:id="formula_31">(p) h 4h</formula><p>Proof. Fix p arbitrarily. By de nition, " (p j r; Q</p><formula xml:id="formula_32">; d) = 1 k P i " i (p j r; Q; d). By Lemma 9, E[" i (p j r; Q; d)] = " i (p) i (p) h , which implies " (p) (p)</formula><p>h . Thus, our condition can be rephrased as:</p><formula xml:id="formula_33">1 k X i " i (p j r; Q; d) E " 1 k X i " i (p j r; Q; d) # 4h</formula><p>Now note that " i (p j r; Q; d) only depends on r i ; Q i and d i , since we are looking at the behavior of a query to subproblem i for a xed value of the published bits; see the de nition of " i in (4). Since (r i ; Q i ; d i ) are independent for di erent i, it follows that " i (p j r; Q; d) are also independent. Then we can apply a Cherno bound to analyze the mean " (p j r; Q; d) of these independent random variables. We use an additive Cherno bound <ref type="bibr" target="#b1">[2]</ref>:</p><formula xml:id="formula_34">Pr r;Q;d " (p j r; Q; d) &lt; " (p) 4h &lt; e (k( h ) 2 )</formula><p>Now we take a union bound over all possible choices p for the published bits. The probability of the bad event becomes 2</p><formula xml:id="formula_35">1 C ( h ) 3 k e (( h ) 2 k)</formula><p>. For large enough C, this is exp( (( h ) 2 k)), for any and h. Now we use that 1 C ( h ) 3 k 1, from the condition that there is at lest one published bit, so this probability is at most e (Ch= ) . Given that h 1, this is at most 8h for large enough C.</p><p>Unfortunately, this lemma is not exactly what we would want, since it provides a lower bound in terms of (p). This probability of success is measured in the original probability space. As we condition on r; Q and d, the probability space can be quite di erent. However, we show next that in fact cannot change too much. As before, the intuition is that there are too few published bits, so for most subproblems they are not changing the query distribution signi cantly. Proof. The proof is very similar to that of Lemma 10. Fix p arbitrarily. By de nition, (p j r; Q; d) is the average of i (p j r; Q; d). Note that for xed p, i depends only on r i ; Q i and d i . Hence, the i values are independent for di erent i, and we can apply a Cherno bound to say the mean is close to its expectation. The rest of the calculation is parallel to that of Lemma 10.</p><p>We combine Lemmas 10 and 11 by a union bound. We conclude that with probability at least 1 4 over random r; Q and d, we have that (8)p:</p><formula xml:id="formula_36">" (p j r; Q; d) (p) h 4h (p j r; Q; d) (p) +<label>4</label></formula><p>)</p><formula xml:id="formula_37">) " (p j r; Q; d) (p j r; Q; d) h 2h<label>(6)</label></formula><p>Since this holds for all p, it also holds for p = p, i.e. the actual bits p(r; Q; d) published by the data structure given its input. Now we want to take the expectation over r; Q and d. Because " ( ); ( ) 2 [0; 1], we have " ( ) 1 h ( )</p><formula xml:id="formula_38">1</formula><p>h . We use this as a pessimistic estimate for the cases of r; Q and d where (6) does not hold. We obtain:</p><formula xml:id="formula_39">E " (p j r; Q; d) (p j r; Q; d) h 2h + 4 1 h = 3 4h ) E " (p j r; Q; d) 1 h E (p j r; Q; d) 3 4h = 1 h 3 4h = 4h</formula><p>4 Communication Lower Bounds</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Protocol Manipulations</head><p>To obtain our improved lower bounds for large space, we use two-party communication complexity.</p><p>In this section, we state the protocol manipulation tools that we will use in our proof. We allow protocols to make errors, and look at the error probability under appropriate input distributions. Thus, as opposed to our lower bounds for small space, we also obtain lower bounds for randomized algorithms with bounded error. We de ne an [A; m 1 ; m 2 ; m 3 ; : : : ]-protocol to be a protocol in which Alice speaks rst, sending m 1 bits, Bob then sends m 2 bits, Alice sends m 3 bits and so on. In a [B; m 1 ; m 2 ; : : : ]-protocol, Bob begins by sending m 1 bits. For a communication problem f : A B ! f0; 1g, de ne a new problem f A;(k) in which Alice receives x 1 ; : : : ; x k 2 A, Bob receives y 2 B; i 2 [k] and x 1 ; : : : ; x i 1 , and they wish to compute f (x i ; y). This is similar to our de nition for f (t) , except that we need to specify that Alice's input is being multiplied. We de ne f B;(k) symmetrically, with the roles of Alice and Bob reversed. Finally, given a distribution D for f , we de ne D A;(k) and D B;(k) following our old de nition for D (k) .</p><p>The rst tool we use is round elimination, which, as mentioned before, has traditionally been motivated by predecessor lower bounds. The following is a strong version of this result, due to <ref type="bibr" target="#b15">[16]</ref>:</p><p>Lemma 12 (round elimination <ref type="bibr" target="#b15">[16]</ref>). Suppose f (k);A has an [A; m 1 ; m 2 ; : : : ]-protocol with error probability at most " on D A; (k) . Then f has a [B; m 2 ; : : : ]-protocol with error probability at most " + O( p m 1 k ) on D. As opposed to previous proofs, we also bring message compression into play. The following is from <ref type="bibr" target="#b4">[5]</ref>, restated in terms of our f A;(k) problem: Lemma 13 (message compression <ref type="bibr" target="#b4">[5]</ref>). Suppose f (k);A has an [A; m 1 ; m 2 ; : : : ] protocol with error probability at most " on D A;(k) . Then for any &gt; 0, f has an [A; O( 1+(m 1 =k)</p><p>2 ); m 2 ; : : : ]protocol with error probability at most " + on D.</p><p>Since this lemma does not eliminate Alice's message, but merely reduces it, it is used in conjuction with the message switching technique <ref type="bibr" target="#b4">[5]</ref>. If Alice's rst message has a bits, we can eliminate it if Bob sends his reply to all possible messages from Alice (thus increasing his message by a factor of 2 a ), and then Alice includes her rst message along with the second one (increasing the second message size additively by a): Lemma 14 (message switching). Suppose f has an [A; m 1 ; m 2 ; m 3 ; m 4 ; : : : ]-protocol. Then it also has a [B; 2 m 1 m 2 ; m 1 + m 3 ; m 4 ; : : : ]-protocol with the same error complexity.</p><p>Message compression combined with message switching represent, in some sense, a generalization of the round elimination lemma, allowing us to trade a smaller k for a larger penalty in Bob's messages. However, the trade-o does yield round elimination as the end-point, because message compression cannot reduce Alice's message below ( 2 ) for any k. We combine these two lemmas to yield a smooth trade-o (with slightly worse error bounds), which is easier to work with: Lemma 15. Suppose f (k) has an [A; m 1 ; m 2 ; m 3 ; m 4 ; : : : ]-protocol with error " on D A;(k) . Then for any &gt; 0, f has a [B; 2 O(m 1 =(k 4 )) m 2 ; m 1 + m 3 ; m 4 ; : : : ]-protocol with error probability " + on D.</p><p>Proof. If m 1 k 2 , we can apply the round elimination lemma. Then, Alice's rst message is ommitted with an error increase of at most . None of the subsequent messages change. If m 1 k 2 , we apply the message compression lemma, which reduces Alice's rst message to O( 1+(m 1 =k) 2 ) bits, while increasing the error by . Since m 1 k 2 , the bound on Alice's message is at most O( m 1 k 4 ). Then, we can eliminate Alice's rst message by switching. Note our bound for the second message from Alice is loose, since it ignores the compression we have done.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Application to Predecessor Search</head><p>Theorem 16. Consider a solution to colored predecessor search in a set of n '-bit integers, which uses space n 2 a in the cell-probe model with cells of w bits. If a = (lg n) and the query algorithm has an error probability of at most 1  3 , the query time must satisfy:</p><formula xml:id="formula_40">T = min lg w n; lg('=a) lg lg('=a) + lg(a= lg n)</formula><p>Proof. We consider the communication game in which Alice receives the query and Bob receives the set of integers. Alice's messages will have lg(n 2 a ) = (a) bits, and Bob's w bits. The structure of our proof is similar to the application of the cell-probe elimination lemma in Section 2. By Lemma 2, we can identify the structure of P (n; ') A;(h) in P (n; h'). Then, we can will apply our Lemma 15 to eliminate Alice's messages. Now, we use Lemma 3 to identify the structure of P (n; ') B;(t) in P (n t; ' + lg t). Note that P (n; ') B;(t) is syntactically equivalent to our old L t P (n; '), except that Alice also receives a (useless) pre x of Bob's input. Now we apply the round elimination lemma to get rid of Bob's message. Thus, after eliminating a message from each player, we are left with another instance of the colored predecessor problem, with smaller n and ' parameters. This contrasts with our cell-probe proof, which couldn't work with just one subproblem, but needed to look at all of them to analyzing sharing. Our strategy is to increase the error by at most 1 9T in each round of the previous argument. Then, after T steps, we obtain an error of at most 1 3 + 1 9 &lt; 1 2 . Assuming we still have n 2 and ' 1, it is trivial to make the answer to the query be either red or blue with equal probability. Then, no protocol with zero communication can have error complexity below 1  2 , so the original cell-probe complexity had to be greater than T .</p><p>As explained in Section 2.3, the proof should be interpreted as an inductive argument in the reverse direction. Assuming we have a distribution on which no protocol with i rounds can have error less than ", our argument constructs a distribution on which no protocol with i + 1 rounds can have error less than " 1 9T . At the end, we obtain a distribution on which no protocol with T rounds can have error 1  3 , implying the cell-probe lower bound. It remains to de ne appropriate values h and t which maximize our lower bound T by the above discussion. After step i, Alice's message will have size (i + 1) (a + lg n) = O(aT ), because we have applied message switching i times (in the form of <ref type="bibr">Lemma 15)</ref>. Applying Lemma 15 one more time with = 1 18T , we increases Bob's next message to w 2 O(aT 5 =h) . We now apply round elimination to get rid of Bob's message. We want an error increase of at most 1 18T , adding up to at most 1 9T per round. Then, we set t according to:</p><formula xml:id="formula_41">O 0 @ s w 2 O(aT 5 =h) t 1 A 1 18T ) t = w O(T 2 ) 2 O(aT 5 =h)</formula><p>Let n i and ' i denote the problem parameters after i steps of our argument. Initially, n 0 = n; ' 0 = '. By the discussion above, we have the recursions: ' i+1 = ' i h lg t and lg n i+1 = lg n i t = lg n i lg t. We have lg t = O(lg w + lg T + aT 5 h ). Since we want ' T 1, we must have T lg ' lg w, so lg t simpli es to O(lg w + aT 5 h ). Now the condition n T 2 implies the following bound on T :</p><formula xml:id="formula_42">T &lt; lg n 1 (lg w + aT 5 h ) = min lg n lg w ; h lg n aT 5</formula><p>To analyze the condition ' T 1, we apply the recursion bound of Lemma 6, implying T &lt; lg h ( ' (lg t) ). This is satis ed if we upper bound lg t by O((a + lg w) (1 + T 5 h )), and set:</p><formula xml:id="formula_43">T &lt; lg( ' a+lg w ) lg( T 5 h ) lg h ! = lg( ' a+lg w ) lg h ! O(lg T ) ) T &lt; lg( ' a+lg w ) lg h</formula><p>! Thus, our lower bound is, up to constant factors, minf lg n lg w ; h lg n aT 5 ; lg('=(a+lg w)) lg h</p><p>g. First we argue that we can simplify a + lg w to just a in the last term. If a = (lg w), this is trivial. Otherwise, we have a = O(lg w), so lg n = O(lg w). But in this case the rst term of the min is O(1) anyway, so the other terms are irrelevant.</p><p>It now remains to choose h in order to maximize the lower bound. This is achieved when h lg n aT 5 = lg('=a) lg h , so we should set lg h = (lg lg ' a + lg a lg n + lg T ). The lg T term can be ignored because T = O(lg ' a ). With this choice of h, the lower bound becomes, up to constants, minf lg n lg w ; lg('=a) lg lg('=a)+lg(a= lg n) g.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Upper Bounds</head><p>We are working on the static predecessor problem where we are rst given a set Y of n keys. The predecessor of a query key x in Y is the largest key in Y that is smaller than or equal to x. If x is smaller than any key in Y , its predecessor is 1, representing a value smaller than any possible key. Below each key is assumed to be a non-negative '-bit integer. We are working on a RAM with word length w '. The results also apply in the stronger external memory model where w is the bit size of a block. The external memory model is stronger because it like the cell-probe model does not count computations.</p><p>For n s and lg n ' w, we will show represent n '-bit keys using O(s') bits of space where s n. With a = lg sw n , we will show how to search predecessors in time</p><formula xml:id="formula_44">O lg n lg w (7) O lg ' lg n a if ' = O(lg n)<label>(8)</label></formula><formula xml:id="formula_45">O 0 @ lg ' a lg a lg ' a (lg n) 1 A if a lg n and ' = !(lg n)<label>(9)</label></formula><formula xml:id="formula_46">O 0 B @ lg ' a lg lg ' a lg lg n a 1 C A if a lg n and ' = !(lg n)<label>(10)</label></formula><p>Contents Below, we rst obtain (7) using either B-trees or the fusion trees of Fredman and Willard <ref type="bibr" target="#b9">[10]</ref>. Next we use <ref type="bibr" target="#b6">(7)</ref> to increase the space by a factor w so that we have O(2 a ') bits of space available per key. Then we prove (8) by a slight tuning of van Emde Boas' data structure <ref type="bibr" target="#b18">[19]</ref>. This bound is tight when w = O(lg n). Next, elaborating on techniques of Beame and Fich <ref type="bibr" target="#b3">[4]</ref>, we will rst show <ref type="bibr" target="#b8">(9)</ref> and then <ref type="bibr" target="#b9">(10)</ref> in the case where w 2 lg n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Preliminaries</head><p>In our algorithms, we will assume that w, ', and a are powers of two. For the word length w, we note we that can simulate up to twice the word length implementing each extended word operation with a constant number of regular operations. Hence, internally, our algorithms can use a word length rounded up to the nearest power of two without a ecting the asymptotic search times. Concerning the parameters ' and a, we note that it does not a ect the asymptotics if they change by constant factors, so we can freely round ' up to the nearest factor of two and a down to the nearest factor of two, thus accepting a larger key length and lesser space for the computations.</p><p>The search times will be achieved via a series of reductions that often reduce the key length '. We will make sure that each reduction is by a power of two.</p><p>We will often allocate arrays with m entries, each of ' bits. These occupy m' consecutive bits in memory, possibly starting and ending in the middle of words. As long as ' w, using simple arithmetic and shifts, we can access or change an entry in constant time. In our case, the calculations are particularly simple because ' and w are powers of two.</p><p>We will use product notation for concatenation of bit strings. Hence xy or x y denotes the concatenation of bit strings x and y. As special notation, we de ne 1 x = x 1 = 1. Finally, we de ne log = log 2 . Note that this is di erent from lg which is the function used in our asymptotic bounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Fusion or B-trees</head><p>With Fredman and Willard's fusion trees <ref type="bibr" target="#b9">[10]</ref>, we immediately get a linear space predecessor search time of O lg n lg ' . If w ' 2 , this implies the O lg n lg w search time from <ref type="bibr" target="#b6">(7)</ref>. Otherwise, we use a B-tree of degree d = w='. We can pack the d keys in a singe word, and we can then search a B-tree node in constant time using some of the simpler bit manipulation from <ref type="bibr" target="#b9">[10]</ref>. This gives a search time of O lg n lg d which is O lg n lg w for w ' 2 . Thus we achieve the search time from (7) using only linear space, or O(n') bits.</p><p>We note that the B-tree solution is simpler in the external memory model where we do not worry about the actual computations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Inceasing the space</head><p>We will now use <ref type="bibr" target="#b6">(7)</ref> to increase the space per key by a factor w. We simply pick out a set Y 0 of n 0 = bn=wc equally spaced keys so that we have a segment of less than w keys between consecutive keys in Y 0 . We will rst do a predecessor search in Y 0 , and based on the result, do a predecessor search in the appropriate segment. Since the segment has less than w keys, by <ref type="bibr" target="#b6">(7)</ref>, it can be searched in constant time.</p><p>Thus we are left with the problem of doing a predecessor search in Y 0 . For this we have O(s') bits, which is O(s'=(n=w)) = O(sw'=n) = O(2 a ') bits per key. Moreover we note that replacing n by n 0 = bn=wc does not increase any of the bounds ( <ref type="formula" target="#formula_44">8</ref>)- <ref type="bibr" target="#b9">(10)</ref>. Hence it su ces to prove the these bounds ( <ref type="formula" target="#formula_44">8</ref>)-( <ref type="formula" target="#formula_46">10</ref>) assuming that we O(n2 a ') bits of space available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">A tuned van Emde Boas bound for polynomial universes</head><p>In this section, we develop a tuned version of van Emde Boas's data structure, representing n keys in O (n2 a ') bits of space providing the search time from (8) of O lg ' lg n a :</p><p>We shall only use this bound for polynomial universes, that is, when ' = O(lg n).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">Complete tabulation</head><p>The static predecessor problem is particularly easy when we have room for a complete tabulation of all possible query keys, that is, if we have O(2 ' ') bits of space. Then we can allocate a table pred Y that for each possible query key x stores the predecessor pred Y</p><formula xml:id="formula_47">[x] of x in Y . If x &lt; min Y , pred Y [x] = 1.</formula><p>For our bounds, we will use this as a base case if ' a.</p><p>Note that this simple base case is a prime example of what we can do when not restricted to comparisons on a pointer machine: we use the key as an addrees to a table entry and get the answer in constant time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Pre xes tabulation</head><p>If our keys are too long for a complete tabulation, but not too much longer, it may still be relevant to use tabulation based on the rst p bits of each key. Below it is understood that the pre x of a key is the rst p bits and the su x is the last ' p bits. Let Su Y [u] be the su xes in Y of keys with pre x u. Also let pred We now have the following pseudo-code for searching Y :</p><p>Pred(x; Y ) (x 0 ; x 1 ) = (pre x(x); su x(x))</p><formula xml:id="formula_48">y 1 = Pred(x 1 ; Su Y [x 0 ]) if y 1 = 1 then return pred 6 = Y [x 0 ]</formula><p>. return x 0 y 1 Note in the above pseudo-code that the produre termintes as soon as it executes return statement. Hence the last statement is only executed if y 1 6 = 1. Also, as a rule of thumb, we use square brackets around the argument of a function that we can compute in constant time.. We shall use this reduction with p lg n as the rst step of our predecessor search. More precisely, we choose p lg n such that the reduced length ' p is a power of two less than 2(' lg n). The reduction adds a constant to the search time. It uses O(2 p ') = O(n') bits of space on the tables over the pre xes. The su x of a key y appears in the subproblem Su Y [u]. Hence the subproblems have a total of n keys, each of length less than 2(' lg n).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.3">Van Emde Boas' reduction</head><p>The essential component of van Emde Boas' data structure is a reduction that halves the key length '. Trivially this preserves that key lengths are powers of two. To do this halving, we would like to use the reduction above with pre x length p = '=2. However, if ' is too large, we do not have O(2 p ') bits of space for tabulating all pre xes. As a limited start, we can use hashing to tabulate the above information for all pre xes of keys in Y . Let U be the set of these pre xes. For all u 2 U , as above, we store pred 6 = Y [u] and a recursive representation of Su Y [u]. We can then handle all queries x with a pre x in U . However, if the pre x x 0 of x is not in u, we need a way to compute</p><formula xml:id="formula_49">pred 6 = Y [x 0 ].</formula><p>To compute pred 6 = Y [x 0 ] for a pre x x 0 not in U , we use a recursive representation of U . Moreover, with each u 2 U , we store the maximal key max Y [u] in Y with pre x u. Moreover, we de ne max Y [ 1] = 1. We now rst compute the predecessor y 0 of x 0 in U , and then we return max Y [y 0 ].</p><p>The above reduction spends constant time on halving the key length but the number of keys may grow in that a key x = x 0 x 1 2 Y has x 0 in the subproblem U and x 1 in the subproblem Su Y [x 0 ]. A general solution is that instead of recursing directly on a subproblem Z, we remove the maximal key treating it separately, thus only recursing on Z = Z n fmax Zg.</p><p>In our concrete case, we will consider the reduced recursive subproblems Su Y [u]. We then have the following recursive pseudo-code for searching the predecessor of x:</p><formula xml:id="formula_50">Pred(x; Y ) (x 0 ; x 1 ) = (pre x(x); su x(x)) if x 0 6 2 U then return max Y [Pred(x 0 ; U )] if x max Y [x 0 ] then return max Y [x 0 ] y 1 = Pred(x 1 ; Su Y [x 0 ]) if y 1 = 1 then return pred 6 = Y [x 0 ] return x 0 y 1</formula><p>The key lengths have been halved to ' 0 = '=2. We have n jU j half keys in the su x subproblems Su Y [x 0 ], and jU j half keys in the pre x subproblem U , so the total number of keys is n.</p><p>As described above, the space used by the reduction is O(n') bits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.4">The nal combination</head><p>To solve the predecessor search problem in O(n2 a ') bits of space, we will rst tabulate a pre x of length p lg n as described in Section 5.4.2, thus reducing the key length to ' p 2(' lg n) whish is a power of two. Then we apply the van Emde Boas reduction recursively as described in Section 5.4.3, until we get down to a key length below a. This requires lg ' lg n a recursions. We do not recurse on empty subproblems. For these we know that the predecessor is always 0. Finally we use the complete tabulation on each subproblem as described in Section 5.4.1.</p><p>Since each reduction adds a constant to the search time, the search time of our solution is O(lg ' lg n a ). The rst reduction uses O(n') bits of space, and the last uses O(2 a ') bits of space per subproblem. Since the subproblems are non-empty, this is O(n2 a ') bits of space in total. Each van Emde Boas recursion uses O(n') bits of space where ' is the current key length. Since ' is halved each time, the space of the rst iteration with the original key length ' dominates. Thus we have proved:</p><p>Lemma 17. Using O(n2 a ') bits of space, we can represent n '-bit keys so to we can search predecessors in O(lg ' lg n a ) time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Reduction a la Beame and Fich</head><p>In this section, we will derive better bounds for larger universes using a reduction very similar to one used by Beame and Fich <ref type="bibr" target="#b3">[4]</ref>. Our version of the reduction is captured in the following proposition:</p><p>Proposition 18. Let be given an instance of the static predecessor search problem with n keys of length '. Choose integer parameters q 2 and h 2 where h divides '. We can now reduce into subproblems, each of which is easier in one of two ways:</p><p>length reduced The key length in the subproblem is reduced by a factor h to '=h, and the subproblem contains at most half the keys.</p><p>cardinality reduced The number of keys is reduced by a factor q to n=q.</p><p>The reduction costs a constant in the query time. For some number m determined by the reduction, the reduction uses O((q (2h) + m)') bits of space. The total number of keys in the cardinality reduced subproblems is at most n m, and the total number of keys in the length reduced subproblems is at most m.</p><p>The original reduction of Beame and Fich [4, Section 4.2] is specialized towards their overall quadratic space solution, and had an assumption that ' '=h. They satisfy this assumption by rst applying van Emde Boas' reduction lg h times. This works ne in their case, but here we consider solutions to the predecessor search problem where we get down to constant query time using large space, and then their assumption would be problematic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.1">Larger space</head><p>Recall that we are looking for a solution to the predecessor problem using O(n2 a ') bits of space. In our rst simple solution assumes a lg n and ' = !(lg n). With some h to be xed later we apply Proposition 18 recursively with q xed as 2 a=(2h) . Here a and h are assumed powers of two. Then the bit space used in each recursive step is O(2 a '). Since no subproblem has more than half the keys, the recursion tree has no degree 1 nodes. Hence we have at most n 1 recursive nodes, so the total space used in the recursive steps is O(n2 a ') bits.</p><p>As described in Section 5.4.1, we can stop recursing when we get down to key length a, so the number of length reductions in a branch is at most lg h w a . On the other hand, the number of cardinality reductions in a branch is at most lg  Except for the division of w by a in w a , the above bound is equivalent to one anticipated without any proof or construction in <ref type="bibr" target="#b17">[18]</ref>. we shall prove that this bound is tight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.2">Smaller space</head><p>We now consider the case where we start with a problem with lg n a=2 and ' = !(lg n). We are now going to appy Proposition 18 recursively with a xed value of h which is a power of two, but with a changing value of q, stopping when we get a subproblem with only one key, or where the key length is at most a. While lg n a=2, we use Proposition 18 recursively with q = bn 1=(4h) c. However, when we get down to n 2 a=2 keys, we use q = 2 a=(4h) . Proof. First we analyze the search time which is the recursion depth. Since we start with key length at most ' and nish if we get to a, the number of length reductions in a recursion branch is O(lg h ' a ). For the cardinality reductions, while n 2 a=2 , we note that it takes less than 4h reductions to get from n to p n keys. More precisely, in each of these reductions, we have q &gt; p n 1=(4h) , and then it takes less than</p><formula xml:id="formula_51">lg p n 1=(4h) n p n = lg p n lg n 1=(8h) = 4h</formula><p>cardinality reductions to get down to p n keys. Thus it takes 4h cardinality reductions to half log n, so to get from the original value and down to a=2, we need at most 4hdlg lg n a=2 e = O(h lg lg n a ) cardinality reductions. In the above argument, we have ignored that q is rounded down to the nearest integer. However, since h is a power of two, we can use the same argument to show that we can have at most 4h iterations while log n 2 [2 i ; 2 i+1 ).</p><p>Finally, starting from n 2 a=2 keys and using q = 2 a=(2h) , we use at most h cardinality reductions to get down to a single key. Thus, the total number of cardinality reducing reductions is O(h lg lg n a ). It follows that the total recursion depth is at most The bit space bound in each reductive step is O((q (2h) + m)'). We will add up each term separately over the whole recursion tree.</p><p>For the O(m') bound, we note that at least m keys get reduced to length '=h '=2. Thus, the total bit length of the keys is reduced by at least m'=2, so we use O(1) bits per key bit saved. Starting with n' key bits, the total space used is O(n').</p><p>Finally, concerning the O(q (2h) ') bound, we have to cases. When q = b2 (lg p n)=(4h) c, the bit space used is O( p n'). This is O('= p n) bits of space per key in the recursion. Following a key x down the branch, we know that the number of keys is halved in each step, and this means that the space assigned to x is increased by a factor p 2. Thus, the total space assigned to x is dominated by the last recursion, hence O(') bits. Thus, over all the keys, we get O(n') bits of space for this case.</p><p>Finally, when q = 2 a=(2h) , the bit space is O(2 a '), and then the at most n 1 recursive nodes give a bit space bound of O(n2 a '). Thus the whole thing adds up to O(n2 a ') bits of space, as desired.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.3">Proof of Proposition 18</head><p>In this section, we prove Proposition 18:</p><p>Let be given an instance of the static predecessor search problem with n keys of length '. Choose integer parameters q 2 dividing n and h 2 dividing '. We can now reduce into subproblems, each of which is easier in one of two ways: length reduced The key length in the subproblem is reduced by a factor h to '=h, and the subproblem contains at most half the keys.</p><p>cardinality reduced The number of keys is reduced by a factor q to n=q.</p><p>The reduction costs a constant in the query time. For some number m determined by the reduction, the reduction uses O((q (2h) + m)') bits of space. The total number of keys in the cardinality reduced subproblems is at most n m, and the total number of keys in the length reduced subproblems is at most m.</p><p>In the proof below we will ignore the requirement that a length reduced subproblem should contain at most half the keys. If one of these subproblems ends up with two many keys, we can just split it around the median, adding only a constant to the search time.</p><p>We will view each key x as a vector x 1 x h of h characters, each of c = '=h bits. We now provide an alternative to the parallel hashing in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr">Lemma 4.1]</ref>. The most signi cant di erence is that our lemma does not require a word length that is h times bigger than '. Besides, the statement is more directly tuned for our construction.</p><p>Lemma 20. Using O(q 2h ') bits of space, we can store a set Z = fz 1 ; :::; z q g of q h-character keys so that given a query key x, we can in constant time nd the number of whole characters in the longest common pre x between x and any key in Z.</p><p>Proof. Andersson et al. <ref type="bibr" target="#b2">[3,</ref><ref type="bibr">Section 3</ref>] have shown we in constant time can apply certain universal hash functions H 1 ; :::; H h in parallel to the characters in a word, provided that the hash values are no bigger than the characters hashed. Thus, for each i independently, and for any two di erent characters x 6 = y, if the hash values are in [m], then Pr[H i (x) = H i (y)] 1=m. Given x = x 1 x h , we return H 1 (x 1 ) H h (x h ) in constant time. However, the hashed key has the same length as the original key. More precisely, if the characters have c bits and the hashed characters are in [2 b ], then we have c b leading zeros in the representation of H i (x i ).</p><p>We will map each character to b = 2 lg q bits. We may here assume that b &lt; c, for otherwise, we can tabulate all possible keys in q 2h ' bits of space. For each character position i, we have q characters z j i , and for random H i these are all expected to hash to di erent values. In particular, we can choose an H i without collisions on fz j i g 1 j q . Now if x i = z j i we have H i (x i ) = H i (z j i ) and there is no z j 0 i 6 = z j i with H i (x i ) = H i (z j 0 i ). Next, consider the set A of values H 1 (x 1 ) H h (x h ) over all possible vectors x = x 1 x h . These vectors are ch long, but since only the b least signi cant bits are used for the hash values of each character, there are at most 2 bh di erent values in A. Using the linear space 2-level hashing of Fredman et al. <ref type="bibr" target="#b7">[8]</ref>, we construct a hash table H over A using O(2 bh ') bits of space. With the entry H(H 1 (x 1 ) H h (x h )), we store the key z j so that H 1 (z j 1 ) H h (z j h ) has the longest possible pre x with H 1 (x 1 ) H h (x h ). The key z j is found from x in constant time. We now claim that no key z j 0 can agree with x in more characters than z j 0 . Suppose for a contradiction that z j agrees with x in the rst r 1 characters but not in character r, and that z j 0 agrees in the rst r characters. Then H 1 (x 1 ) H r (x r ) = H 1 (z j 0 1 ) H r (z j 0 r ). However, since H r is 1-1 on fz j r g 1 j q , H r (z j r ) 6 = H r (z j 0 r ) = H r (x r ). All that remains is to compute the number of whole characters in the common pre x of x and z j . This can be done by clever use of multiplication as described in <ref type="bibr" target="#b9">[10]</ref>. A more practical solution based on converting integers and to oating point numbers and extracting the exponent is discussed in <ref type="bibr" target="#b16">[17]</ref>.</p><p>Using Lemma 20, we can compute in constant time the longest common pre x, comm pref Z [x], in whole characters, between x and any key in Z. Also, if x 6 2 Z, we can get the pre x comm pref + Z [x] that has one more character from x.</p><p>We are now return to the proof of Proposition 18 which is similar to the one in [4, <ref type="bibr">Section 4</ref>]. Out of our original set Y of n keys, we pick a subset Z = fz 1 ; :::; z q g of q keys so that there is a key from Z among any sequence of dn=qe consecutive keys from Y . We apply Lemma 20 to Z. Thereby we use O(q 2h ') bits of space. We are going to consider two types of subproblems. The total bit space used is O(q 2h ') for the implication of Lemma 20, O(jV j') for the cardinality reduction, and O((jU j + jV j)') for the length reduction. Here O(jU j) = O(hq) = O(q 2h ) and jV j &lt; m, so the total bit space is O((q 2h + m)'). This completes the proof of Proposition 18.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Lemma 7 .</head><label>7</label><figDesc>There exist r and Q, such that E d [" (p(r; Q; d) j r = r; Q = Q; d)] 2h .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Lemma 11 .</head><label>11</label><figDesc>With probability at least 1 8 over random r; Q and d: (8)p : (p j r; Q; d) (p) + 4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Lemma 19 .</head><label>19</label><figDesc>The above construction uses O(n2 a ') bits of space and the search time is</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>c</head><label></label><figDesc>= Pred Y (d; Next char Y [u]) if c = 1 then return pred 6 = Y [u] return max Y [uc]Final analysis This almost nishes the proof. Let m = jZj + jV j. Then we have at most n m keys in cardinality reduced subproblems and at most m keys in length reduced subproblems.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>so lg n k i = 4 i lg n and lg t i = 3 4 4 i lg n. By our recursion for ' i , we have ' i+1 = ' i</figDesc><table><row><cell>' i</cell><cell cols="13">2 3 4 i lg n. Indeed, ' i+1 3 4 4 i lg n. Given ' 0 = ' 3 4 i 1 2 lg n 3 4 4 i lg n 3 lg n, it can be seen by induction that 3 4 (i+1) lg n. By the above, (3) is</cell></row><row><cell cols="2">satis ed for T</cell><cell></cell><cell></cell><cell cols="10">(lg lg n). Finally, note that condition (2) is equivalent to:</cell></row><row><cell></cell><cell>lg t i</cell><cell>1 h</cell><cell>lg</cell><cell>n k i</cell><cell>+</cell><cell>a h</cell><cell cols="4">+ (lg w + lg 2 ') ,</cell><cell>3 4</cell><cell>4 i lg n</cell><cell>1 2</cell><cell>4 i lg n +</cell><cell>a 2</cell><cell>+ (lg w + lg 2 ')</cell></row><row><cell></cell><cell cols="2">, T</cell><cell></cell><cell></cell><cell></cell><cell cols="2">lg min</cell><cell>lg n a</cell><cell>;</cell><cell>lg n lg 2 w</cell><cell>=</cell><cell>min lg</cell><cell>lg n a</cell><cell>; lg lg n</cell><cell>=</cell><cell>lg</cell><cell>lg n a</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>6 = Y [u] to denote the strict predessor in Y of u su xed by zeroes. Here by strict predecessor, we mean an unequal predecessor. If no length p pre x in Y is smaller than u, pred 6 = Y [u] = 1. The representation of Y now consists of the table that with each pre x u associates pred 6 = Y [u] and a recursive representatation of Su Y [u]. Note that if Su Y [u] = ?, the recursive representation returns 1 on any predecessor query.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>As a remark in<ref type="bibr" target="#b17">[18,</ref> Section 7.5], it is stated that \it appears that we can get the following results. . . ", followed by bounds equivalent to the third branch of (1).</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Cardinality reduced problems First we have the cardinality reduced subproblems. These are of the following type: we take a key from Y n Z and consider the pre x v = comm pref + (y; Z). Let Agree Y <ref type="bibr">[v]</ref> denote the keys from Y that have pre x v. These keys are consecutive and they do not contain any key from Z, so jAgree Y [v]j &lt; q. We use 2-level hash table for the pre xes in </p><p>This above informatoin su ces to nd the predecessor of any query key x with comm pref + (x; Z) = v. The bit space used above is O(jV j'). Each cardinality reduced subproblem Agree Y [v]j has at most q 2 keys, and they add up to a total of n jZj jV j keys.</p><p>Length reduced subproblems For query keys x with comm pref + (x; Z) 6 2 V , we will consult length reduced subproblems de ned over the set U of pre xes of keys in Z. We will have a 2level hash table over U . For each u 2 U , let Next char Y [u] be the set of characters c such that uc is a pre x of a key in Y . We will have a length reduced subproblem over the characters in</p><p>Now, consider a query key x with comm pref + (x; Z) 6 2 V . Let u = comm pref(x; Z) and let d be the subsequent character in x, that is, ud = comm pref + (x; Z). Then There can be at most U cases where uc 2 U . Otherwise, we have uc = comm pref + (y; Z) 2 V . The total bit space of the length reduction is hence O((jU j + jV j)').</p><p>We will now prove that the total number of keys in the length reduced subproblems Next char Y [u] is at most jZj + jV j. Above we saw that if a character c 2 Next char Y [u] did not represented a pre x in U , it represented a pre x in V . Those representing pre xes in U can also be viewed as representing children in the trie over Z. The total number of such children is at most jZj plus the number of internal trie nodes, and since we for Next char Y [u] subtracted a node for each internal trie node u, we conclude that the total number of keys is the length reduced subproblems is bounded by jZj + jV j. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pseudo-code</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A lower bound for nding predecessors in Yao&apos;s cell probe model</title>
		<author>
			<persName><forename type="first">Ajtai</forename><surname>Mikl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Combinatorica</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="235" to="247" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The Probabilistic Method</title>
		<author>
			<persName><forename type="first">Noga</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Spencer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>John Wiley</publisher>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sorting in linear time</title>
		<author>
			<persName><forename type="first">Arne</forename><surname>Andersson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Torben</forename><surname>Hagerup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Raman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="74" to="93" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note>See also STOC&apos;95</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Optimal bounds for the predecessor problem and related problems</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Beame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faith</forename><forename type="middle">E</forename><surname>Fich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="38" to="72" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>See also STOC&apos;99</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An optimal randomised cell probe lower bound for approximate nearest neighbour searching</title>
		<author>
			<persName><forename type="first">Amit</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oded</forename><surname>Regev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 45th IEEE Symposium on Foundations of Computer Science (FOCS)</title>
		<meeting>45th IEEE Symposium on Foundations of Computer Science (FOCS)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="473" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Small forwarding tables for fast routing lookups</title>
		<author>
			<persName><forename type="first">Mikael</forename><surname>Degermark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrej</forename><surname>Brodnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Svante</forename><surname>Carlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Pink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="3" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tradeo s for packet classi cation</title>
		<author>
			<persName><forename type="first">Anja</forename><surname>Feldmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE INFOCOM</title>
		<meeting>IEEE INFOCOM</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1193" to="1202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Storing a sparse table with 0(1) worst case access time</title>
		<author>
			<persName><forename type="first">L</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Endre</forename><surname>Fredman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edi</forename><surname>Szemer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="538" to="544" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
	<note>See also FOCS&apos;82</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The cell probe complexity of dynamic data structures</title>
		<author>
			<persName><forename type="first">L</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">E</forename><surname>Fredman</surname></persName>
		</author>
		<author>
			<persName><surname>Saks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 21st ACM Symposium on Theory of Computing (STOC)</title>
		<meeting>21st ACM Symposium on Theory of Computing (STOC)</meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="345" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Surpassing the information theoretic bound with fusion trees</title>
		<author>
			<persName><forename type="first">L</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><forename type="middle">E</forename><surname>Fredman</surname></persName>
		</author>
		<author>
			<persName><surname>Willard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="424" to="436" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
	<note>See also STOC&apos;90</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The cell probe complexity of succinct data structures</title>
		<author>
			<persName><forename type="first">Anna</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bro Miltersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 30th International Colloquium on Automata, Languages and Programming (ICALP)</title>
		<meeting>30th International Colloquium on Automata, Languages and Programming (ICALP)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="332" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The bit probe complexity measure revisited</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miltersen</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th Symposium on Theoretical Aspects of Computer Science (STACS)</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="662" to="671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Lower bounds for Union-Split-Find related problems on random access machines</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miltersen</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">26th ACM Symposium on Theory of Computing (STOC)</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="625" to="634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cell probe complexity -a survey</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miltersen</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">19th Conference on the Foundations of Software Technology and Theoretical Computer Science (FSTTCS)</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>Advances in Data Structures Workshop</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On data structures and asymmetric communication complexity</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bro Miltersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Nisan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shmuel</forename><surname>Safra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avi</forename><surname>Wigderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="49" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note>See also STOC&apos;95</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Lower bounds for predecessor searching in the cell probe model</title>
		<author>
			<persName><forename type="first">Pranab</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:cs.CC/0309033</idno>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>See also ICALP&apos;01, CCC&apos;03</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On RAM priority queues</title>
		<author>
			<persName><forename type="first">Mikkel</forename><surname>Thorup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="86" to="109" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>See also SODA&apos;96</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Space e cient dynamic stabbing with fast queries</title>
		<author>
			<persName><forename type="first">Mikkel</forename><surname>Thorup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 35th ACM Symposium on Theory of Computing (STOC)</title>
		<meeting>35th ACM Symposium on Theory of Computing (STOC)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="649" to="658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Design and implementation of an e cient priority queue</title>
		<author>
			<persName><surname>Peter Van Emde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Boas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kaas</surname></persName>
		</author>
		<author>
			<persName><surname>Zijlstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Systems Theory</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="99" to="127" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
	<note>Announced by van Emde Boas alone at FOCS&apos;75</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Log-logarithmic worst-case range queries are possible in space (N )</title>
		<author>
			<persName><forename type="first">Dan</forename><forename type="middle">E</forename><surname>Willard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing Letters</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="81" to="84" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Should tables be sorted?</title>
		<author>
			<persName><forename type="first">Chi-Chih</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="615" to="628" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
	<note>See also FOCS&apos;78</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
