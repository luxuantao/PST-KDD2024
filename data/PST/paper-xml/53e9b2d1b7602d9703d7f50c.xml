<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Esterel Compiler for Large Control-Dominated Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Stephen</forename><forename type="middle">A</forename><surname>Edwards</surname></persName>
						</author>
						<title level="a" type="main">An Esterel Compiler for Large Control-Dominated Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7F7E9B8DD27245E41ABA0594203B6BED</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T10:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Code generation</term>
					<term>compilers</term>
					<term>concurrency</term>
					<term>embedded systems</term>
					<term>Esterel</term>
					<term>reactive</term>
					<term>real-time language</term>
					<term>synchronous</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Embedded hard real-time software systems often need fine-grained parallelism and precise control of timing, things typical real-time operating systems do not provide. The Esterel language has both, but compiling large Esterel programs has been challenging, producing either needlessly slow or large code. This paper presents the first Esterel compiler able to compile large Esterel programs into fast, small code. By choosing a concurrent control-flow graph (CCFG) as its intermediate representation, it preserves many of the control constructs to produce code that can be 100 times faster and half the size than code from other compilers with similar capacity. The primary contribution is an algorithm that generates efficient sequential code from a CCFG. While developed specifically for compiling Esterel, the algorithm could be used to compile other synchronous languages with fine-grained parallelism.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>M ANY applications in reactive real-time embedded systems are most naturally described as concurrent systems, yet many are implemented using sequential languages like C or assembly on sequential processors. A real-time operating system (RTOS) capable of scheduling the execution of multiple independent sequential processes is a common way of providing concurrency to such languages, but the behavior of such an RTOS can be unpredictable, making it difficult to guarantee precise system timing.</p><p>The synchronous approach <ref type="bibr" target="#b0">[1]</ref> provides precise timing control by operating a system in lockstep with a global periodic clock signal. Although timing within a particular clock cycle is essentially uncontrolled, a system has exact control over the clock cycle in which each event occurs.</p><p>The synchronous approach is natural in hardware, where global clocks often drive sequential elements, but is used less frequently in software. A few synchronous languages for software have been proposed (Esterel <ref type="bibr" target="#b1">[2]</ref> and Lustre <ref type="bibr" target="#b2">[3]</ref>), but they have proven challenging to compile.</p><p>Implementing a concurrent synchronous language such as Esterel using concurrency supplied by an operating system would be very inefficient because of the large number of threads in a typical Esterel program (thousands in large programs) and the need for synchronization within each cycle. Since each Manuscript received February 29, 2000; revised <ref type="bibr">May 23, 2001</ref>. This paper was recommended by Associate Editor R. Gupta.</p><p>The author was with Synopsys, Inc., Mountain View, CA USA. He is now with the Department of Computer Science, Columbia University, New York, NY 10027 USA (e-mail: sedwards@cs.columbia.edu).</p><p>Publisher Item Identifier S 0278-0070(02)01046-1. thread needs to run at least once every cycle, and possibly much more depending on communication, context switching cost could dominate a single-processor implementation. A multiple-processor implementation, such as the one proposed by Caspi et al. <ref type="bibr" target="#b3">[4]</ref>, trades some context switching overhead for communication and synchronization overhead. This paper describes EC, a new compiler for Esterel that can produce small, fast code for large programs, avoiding the shortcomings of earlier compilers, and making large synchronous specifications practical. An executable produced by EC can run 100 times faster than one from another compiler able to handle large programs and can be exponentially smaller than code from the compiler that produces the fastest known code (EC's code is about half as fast).</p><p>This paper is structured around the small Esterel program in Fig. <ref type="figure" target="#fig_0">1</ref>. In Section II, we introduce the Esterel language and explain the behavior of the example. Section III is a review of existing Esterel compilers. Section IV describes EC's input format-the intermediate representation IC-and the example's manifestation in it (Fig. <ref type="figure" target="#fig_2">3</ref>).</p><p>The bulk of the paper describes the new compiler. Section V begins with an overview of the three compilation steps: constructing a concurrent control-flow graph (CCFG) from Esterel, scheduling the CCFG, and finally synthesizing a sequential control-flow graph (SCFG) from the concurrent one. Section VI describes the recursive unrolling algorithm that translates an In-0278-0070/02$17.00 Â© 2002 IEEE termediate Code (IC) graph into an equivalent CCFG. The main issues here are adhering to IC's complicated semantics and correctly unrolling the graph when certain instructions may execute more than once in a cycle. Section VII describes how a SCFG is synthesized from the concurrent one using a simulation procedure. After scheduling the nodes in the graph, the procedure steps through each one, copying it to the sequential graph and inserting code that simulates the effects of a context switch when it encounters a node from a different thread. Finally, Section VIII shows how to generate attractive C code from the SCFG. Fig. <ref type="figure" target="#fig_11">17</ref> shows the C code EC generates for the example.</p><p>Section IX describes experiments that compare the quality of the code EC generates with that from other Esterel compilers. The paper concludes with suggestions about how to extend the work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. THE ESTEREL LANGUAGE</head><p>Intended for specifying reactive real-time systems, Esterel <ref type="bibr" target="#b1">[2]</ref> has the control constructs of an imperative language like C but includes concurrency, preemption, and a synchronous model of time like that used in synchronous digital circuits. In each clock cycle, the program resumes running its concurrent threads, reads its inputs, computes its reaction, and suspends until the next cycle.</p><p>An Esterel program communicates through signals that are either present or absent in each cycle. In each cycle, each signal is absent unless an emit statement for the signal runs. Conditional present statements test signals and perform different actions depending on the presence of a signal. The presence of an emitted signal is seen immediately in the cycle it was emitted and does not hold its value in later cycles.</p><p>In Esterel, a statement that tests the value of a signal in a clock cycle blocks until the presence or absence of the signal is established in that clock cycle. Put another way, any statement that emits a signal must run before any statement that reads it. This constrains the order in which statements running in concurrent threads may execute within a cycle and can lead to deadlock. For example, code that attempts to test a signal before emitting it is erroneous: the data dependency contradicts the control dependency.</p><p>EC uses a simpleminded structural check to detect deadlock conditions and reject programs that contain them, but this can reject useful programs. Unfortunately, the alternative, used in the V5 compiler described in Section III, requires exploring the state space of the program (currently only practical with symbolic methods that are still quite expensive) and resynthesizing the program. EC's greatest shortcoming is its inability to do this analysis and accept a larger class of programs; we discuss how this problem might be addressed at the end of the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. An Example</head><p>Fig. <ref type="figure" target="#fig_0">1</ref> shows a simple Esterel program with two concurrent threads. Meant to model an arbiter for a shared resource, the first thread passes requests from the environment to the second thread, which responds to requests. The first thread waits for an signal before holding the signal present until the signal arrives, at which point it emits the signal and terminates. The second thread emits in response to in alternate cycles. Fig. <ref type="figure" target="#fig_1">2</ref> illustrates this behavior with a depiction of the program's response for a particular input sequence.</p><p>The body of the first thread starts with an await statement that waits for the next cycle in which its signal is present. Await always waits one cycle before it can terminate, so this thread does nothing in the cycle when it first appears. Following the await is a weak abort. When this runs (i.e., in the cycle in which signal is present), it immediately starts its body (in this case, a sustain statement that makes signal present in every cycle until the statement is terminated) and watches for the signal. Because this is a weak abort, the sustain runs in the cycle when is present, but terminates. Moreover, since the predicate is "immediate ," the signal is checked in the first cycle the abort statement runs (abort normally starts checking the next cycle, just like await).</p><p>The second thread is an infinite loop. Each pause statement delays a cycle when control reaches it. This happens in the first and second cycle in which the loop runs. In the third, signal is checked, and its presence causes to be emitted. After this, the loop is immediately restarted and the first pause is executed again.</p><p>The two threads are enclosed in an every-do loop that can preempt the two threads. The body of the statement (the pair of threads) is restarted in the cycle in which the signal is present before the body has a chance to resume.</p><p>There is a subtle and often critical difference between the strong preemption of the every-do, which checks its predicate before its body resumes, and the weak preemption of weak abort-when, which checks its predicate after its body resumes. We used weak abortion to preempt sustain R because strong abortion would have caused a deadlock: emitting can cause to be emitted. Had this been strong preemption, the presence of would have prevented from being emitted-a contradiction. Strong preemption around the two threads does not cause deadlock. It makes the program ignore in cycles when is present.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. RELATED WORK</head><p>Three other techniques for compiling Esterel are based on automata, logic gates, and event graphs.</p><p>The earliest compilers, such as Berry et al.'s V3 <ref type="bibr" target="#b1">[2]</ref>, built a single automaton for an Esterel program through exhaustive simulation. Each state of this automaton corresponds to set of control points from which the Esterel program will resume in the next cycle. The code for each state is a tree containing actions (such as emitting signals), conditionals that test external signals, and leaves that set the next state.</p><p>Automata compilers produce very fast code, but it can be exponentially larger than the source program since they generate separate code for each possible state of the program. Two approaches have been proposed to reduce this code size. The Polis group's automata compiler <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref> uses a binary decision diagram to identify code that can be shared between states. Castelluccia et al. <ref type="bibr" target="#b6">[7]</ref> also share subtrees to reduce code size, but also attempt to improve code speed by inlining called functions, swapping then and else branches to improve branch prediction, moving away infrequently executed code to improve cache performance, and reordering tests to put the common cases first. While both techniques can significantly improve the quality of generated code, they are still limited to small programs where it is practical to enumerate the states.</p><p>EC-generated code is slower than automata code because it has more overhead (due to internal communication and context switches), but EC code can be exponentially smaller because code is duplicated far less. As a result, EC is superior for all but the smallest Esterel programs.</p><p>The second class of compilation technique, exemplified by Berry et al.'s V5 compiler, translates Esterel into a netlist of Boolean logic gates and then generates a levelized compiled-code simulator for it. Capacity is the main advantage of this approach. Unlike automata compilers, each Esterel source instruction is translated into a small group of instructions in the executable; nothing is duplicated. The disadvantage is slower code; because the generated code is forced to perform computation for idle portions of the program, it can run hundreds of times slower than an automaton implementation of the same program.</p><p>Compared to gate-based compilers, EC generates code that is slightly more compact, but because it does not need to do work for idle portions of the program, the code can run hundreds of times faster. The key advantage of gate-based compilers over EC is their ability to analyze and compile programs that appear to have cyclic dependencies. However, this is a costly procedure that requires symbolic state-space exploration and circuit resynthesis <ref type="bibr" target="#b7">[8]</ref>.</p><p>The third approach, pioneered by a group from France Telecom <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, treats Esterel as having discrete-event semantics and generates a compiled event-driven simulator. For each segment of code between a pause or signal test, their compiler generates a small C function dispatched by a hard-coded scheduler. Each such function typically produces side effects and may schedule other functions to execute later in the same cycle or in the next cycle.</p><p>While this approach avoids doing work for most idle sections of code (improving performance over gate-based compilation), its scheduler does not take advantage of mutual exclusion among parts of the program (e.g., between branches of a conditional). EC exploits this, instead using program counters affecting multiway branches. EC produces faster code as a result.</p><p>The overall flow of EC-building a concurrent intermediate representation, scheduling it, and generating sequential code-was inspired by Lin's compiler <ref type="bibr" target="#b10">[11]</ref>, which compiles a concurrent variant of C. Lin translates his language into Petri nets that work well for Lin's rendezvous-style communication, but are awkward for Esterel's synchronous style. Lin schedules and then simulates these Petri nets to generate very fast automata-style code. Unfortunately, this technique can cause an exponential explosion in code size, even with an optimal schedule.</p><p>Later, Zhu and Lin <ref type="bibr" target="#b11">[12]</ref> proposed an algorithm that avoids the exponential increase in code size by allowing each process to suspend and resume at interprocess communication points (i.e., where it might have to wait for another process to handshake). The result is a collection of processes implemented as coroutines invoked in round-robin order.</p><p>EC improves upon Lin's work by generating more compact code that is less affected by poor quality schedules. Lin's compiler would benefit from using EC's sequential code generator. EC also improves upon Zhu and Lin's work because Esterel's semantics allow EC to statically schedule the execution of concurrent processes: Zhu and Lin resort to a round-robin scheme that may waste time deciding what to execute next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. THE IC FORMAT</head><p>This section describes the input to EC, the IC format. EC reads this instead of Esterel source because it is a more convenient starting point; IC contains high-level information, yet it is easier to manipulate and can be assumed correct. We use the front end of Berry's group's compilers to translate Esterel source into IC.</p><p>IC consists of a fairly traditional control-flow graph dangling from a reconstruction tree (Fig. <ref type="figure" target="#fig_2">3</ref>). The reconstruction tree (dark nodes and arcs) coordinates exceptions, preemption, and concurrency by dictating how the program resumes ("reconstructs its state") in each cycle. Gonthier developed IC as part of his thesis <ref type="bibr" target="#b12">[13]</ref> and it has continued to evolve with the Esterel language.</p><p>In a cycle, an Esterel program executes in three phases. In the first phase, the program tries to resume where it paused in the last cycle after checking strong preemption conditions such as every S. After this, normal statements such as emit and present run until control reaches a statement such as pause. In the final phase, termination and exceptions are checked and handled. IC models these three phases by sending control down the reconstruction tree toward leaves that were reached at the end of the last cycle, through nodes in the control-flow graph, and finally back up the tree.</p><p>Before the first cycle, control flows from the start node to initialize the program. In the example, this immediately sends control to the halt associated with the every S statement [Fig. <ref type="figure" target="#fig_4">4(a)</ref>]. When control reaches a halt, it starts walking up the reconstruction tree toward the root, marking its path at each reconstruction instruction to prepare the program to resume where it halted. When control reaches the root, the program is finished for the cycle.</p><p>At the beginning of each cycle, control starts at the root node and walks down the reconstruction tree along the path taken up the tree at the end of the last cycle. When control reaches a watchdog statement it takes a detour, usually to check a preemption signal. For the example in the first cycle, control starts at the root then flows to the first watchdog and to the test for . If is absent, control is sent back to the watchdog, which sends control to the halt and back up the reconstruction tree [Fig. <ref type="figure" target="#fig_4">4(b)</ref>]. If is present, control flows to the fork [Fig. <ref type="figure" target="#fig_4">4(c)]</ref>.</p><p>When control reaches a watchdog from a sequential node [e.g., when is absent in Fig. <ref type="figure" target="#fig_4">4</ref>(b) and (d)], the watchdog sends control to the child along the path taken up the reconstruction tree at the end of the last cycle. So if control followed the path in Fig. <ref type="figure" target="#fig_4">4</ref>  the conditional, and to the fork [Fig. <ref type="figure" target="#fig_4">4(c)</ref>], thus implementing the every S do instruction. Control splits when it reaches the fork, starting two threads and sending control to two halts (one just after await I, the other after the first pause). If is absent in the next cycle, control flows to the parallel [Fig. <ref type="figure" target="#fig_4">4(d)</ref>] and splits toward both thread nodes, resuming the two threads.</p><p>In addition to restarting threads, a parallel node handles thread termination and exceptions by checking the exit levels of the threads beneath it when control is passed to it from below. When a thread is done for the cycle, it can terminate by running an exit at level 0, pause by reaching a halt, corresponding to level 1, and throw an exception by running an exit at level 2 or higher. An exit node sends control directly to the parallel for its thread; a halt sends control back up the reconstruction tree to the closest parallel. Once all of a parallel's threads have returned control to it, the parallel sends control either back up the reconstruction tree or to an exception handler, depending on the highest exit level of all its threads. Using the highest exit level means the parallel only terminates if all its threads have terminated, and exceptions take precedence over paused or terminated threads.</p><p>To illustrate exit level behavior, consider the case when the sustain R statement is terminated. The node that emits sends control to the halt immediately beneath it, indicating an exit at level 1 (i.e., halt), and control flows up to the second parallel. Meanwhile, this causes the test for to succeed and causes to be emitted, sending control to the second-to-last halt (an exit at level 1) and up the reconstruction tree to the first parallel. The presence of is noted and causes the exit at level 2 to be executed. The exit level of the threads at the second parallel is therefore 2, so the parallel sends control to the node that emits and exits at level 0. Both threads under the second parallel are now terminated because the right thread under the top parallel has terminated. The topmost parallel has an exit level of 1 since the other thread halted, so control flows back up the reconstruction tree to the root and the program is done for the cycle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. OVERVIEW OF THE NEW COMPILER</head><p>The EC compiler produces better code for sequential processors by choosing a more appropriate intermediate representation than other compilers. The representation-a CCFG-is semantically closer to the Esterel source and the final generated code than the automata, netlists, or event graphs used by other Esterel compilers. The result is code that looks more like a direct implementation of the Esterel program instead of a simulation of its behavior as a circuit or a discrete-event system.</p><p>EC interprets the control flow of the IC format much like the gate compilers, so the generated code is of comparable (usually linear) size and avoids the exponential increase of the automata compilers. However, unlike the gate compilers, EC is able to avoid wasting time performing computations in inactive portions of the program because it preserves control flow. The result is code about the same size as that from a gate-based compiler that can run as much as 100 times faster.</p><p>The CCFG EC uses as an intermediate representation can be translated into software almost as easily as the branching programs of the automata compilers and has concurrent semantics so it can be generated from IC using an algorithm almost exactly like that in the gate-based compiler. Removing concurrency is the one challenge. We present an efficient algorithm for this in Section VII.</p><p>EC translates the IC graph in Fig. <ref type="figure" target="#fig_2">3</ref> into the CCFG in Fig. <ref type="figure" target="#fig_5">5</ref> using the algorithm in Fig. <ref type="figure" target="#fig_7">7</ref>. This mainly transforms the reconstruction tree into semantically simpler conditional, fork, and join nodes, but also compiles away much of the walk up the reconstruction tree. Rather than storing information about the path taken up the reconstruction tree at each reconstruction node, this information is stored in one variable per thread ( 0, 1, 2, and 3) encoded using the algorithm described in Section VI-D. A CCFG has software-like semantics, but its concurrency must be removed. Removing concurrency is complicated mainly by Esterel's ability to communicate between threads in the same cycle. In a program such as Fig. <ref type="figure" target="#fig_0">1</ref>, the execution of the two threads must be interleaved, i.e., the second thread must run after the first thread runs emit R but before the first thread runs emit O. The dashed lines in Fig. <ref type="figure" target="#fig_5">5</ref> show these dependencies.</p><p>EC interleaves concurrently running threads by inserting code that simulates a context switch. Instead of using a costly operating-system-like mechanism to save and restore the processor's state, each thread simply writes its control state to a variable (a single constant) and resumes with a multiway branch. In effect, the C compiler becomes responsible for saving and restoring context (register contents and the program counter) and can do it more efficiently since it knows which variables are live. In Fig. <ref type="figure" target="#fig_6">6</ref> (the SCFG EC generated from the CCFG in Fig. <ref type="figure" target="#fig_5">5</ref>), EC has inserted three such context switches, which write and test variables 2 and 3.</p><p>EC can only handle programs where the instructions can run in the same order in all states, much like the acyclic circuits generated by the gate-based compilers. This is a fundamental limitation since EC is based on static scheduling. Although each instruction may or may not execute in each cycle, the statements appear in a particular order in the generated code and can only be executed in that order. Thus, EC is unable to compile all valid Esterel programs, but the class of programs it can compile is broad, interesting, and includes all the large Esterel programs we know of.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. TRANSLATING IC INTO A CONCURRENT CONTROL-FLOW GRAPH</head><p>EC starts by translating an Esterel program expressed as an IC graph (Fig. <ref type="figure" target="#fig_2">3</ref>) into a CCFG such as Fig. <ref type="figure" target="#fig_5">5</ref>. This replaces preemption conditions with simple conditionals, inserts multiway conditionals to resume threads at the beginning of each cycle, and replicates code that is executed twice or more in the same cycle (Section VI-B explains this "reincarnation" problem in detail). The result is a representation that is close to the natural representation of code on a sequential processor (i.e., a flowchart), but concurrent. Section VII explains how to remove concurrency.</p><p>A CCFG contains action, conditional, fork, and join nodes, each with an expression. When control reaches a node, the node's expression is evaluated and control flows along one or more arcs leaving the node. An action node has a single outgoing arc and its expression is usually an assignment. Control leaves a conditional node along the arc whose integer label matches the value of the expression. These become if or switch statements in C.</p><p>Fork and join nodes start and collect groups of parallel threads. Control flows out all arcs leaving a fork, starting a group of threads that will rendezvous at a matching join node before continuing. Fork and join nodes may nest, but control may not pass between threads. Specifically, all paths from a particular fork meet for the first time at the matching join. The CCFGs built by the translation algorithm described below always have this structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The Translation Algorithm</head><p>Fig. <ref type="figure" target="#fig_7">7</ref> presents the recursive algorithm for converting an IC graph into a CCFG, an adaptation of the algorithm Berry developed for synthesizing gates from Esterel. It consists of two recursive functions with side effects, seqNode and recNode, that visit IC nodes and build the CCFG on the way. The algorithm is split into two routines mainly to distinguish the two ways control can reach a watchdog node. The arguments to the two routines are , the IC node being copied, , the reincarnation level (explained in the next section), , the thread of node , and , the join node for the current group of threads.</p><p>The two functions perform a modified depth-first traversal of the IC graph, adding and copying nodes to the CCFG as they go. The seqNode function begins with a test to see whether the node has been visited before; recNode needs no such test since the reconstruction nodes form a tree.</p><p>Exit and halt nodes have no successors, so they terminate the recursion. Each becomes a pair of nodes, one that sets its thread's state (encoding these variables is described in Section VI-D) and one that sets the exit level for the parallel that spawned the threads. The last of these two nodes branches to the join for the current group of threads. The basic recursive step happens for conditional and emit nodes. These are simply copied to the CCFG and arcs added to copies of their successors.</p><p>There are two ways to reach a watchdog. From a sequential node such as a conditional or emit, a watchdog becomes a conditional that checks its thread's state and branches to one of its reconstruction children. This is the rule for a Watchdog node in seqNode. From a reconstruction node, a watchdog sends control to its single sequential successor. This is the rule in recNode.</p><p>Not surprisingly, fork and parallel nodes are the most complicated. In both cases, they synthesize new threads after adding fork and join nodes that reset and test the exit level associated with the parallel. (Exit and halt nodes set this level, as described above.) Fork is easier to understand: for each of its successors, it synthesizes the nodes in that thread, instructing them to connect to the just-created join node for the group. After this, it adds arcs from the join node to every reachable exception handling routine on the matching parallel.</p><p>The rule for the Parallel is slightly more complicated. For each of its threads, it generates a conditional that checks the state of the thread and either branches to one of the thread node's children or directly to the join if the state is zero (i.e., when the thread is no longer running but one of the other threads under the same parallel is).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Unrolling to Remove Reincarnation</head><p>A simple depth-first traversal of the IC graph can produce cyclic CCFGs even though Esterel prohibits single-cycle infinite loops. The sequentializing algorithm we present in Section VII requires an acyclic CCFG, so the CCFG synthesis algorithm must remove these cycles by duplicating nodes, visiting them more than once. Berry first developed this unrolling technique to remove cycles from the output of his gate-based compiler.</p><p>Even if an Esterel statement is enclosed in a loop, it generally cannot execute twice in a cycle because Esterel forbids loops whose bodies can execute entirely within one cycle. However, if a concurrently running thread throws an exception, the loop can be restarted in the same cycle and the first statement in the loop can run again.</p><p>Fig. <ref type="figure" target="#fig_8">8</ref> shows a program with reincarnation. Emit S runs three times because it is the first statement in a loop that is terminated and instantly restarted by exceptions. Emit S runs first when it is restarted through the reconstruction tree [Fig. <ref type="figure" target="#fig_8">8(a)</ref>]. Meanwhile, exit T3 runs and restarts the inner loop, sending control back to emit S through the arc labeled 0,3 [Fig. <ref type="figure" target="#fig_8">8(b)</ref>]. Similarly, exit T2 also runs, terminating and restarting the outermost loop and running emit S for a third and final time [Fig. <ref type="figure" target="#fig_8">8(c)</ref>]. This behavior is unambiguous because the effects of a trap are always felt after all parallel threads have finished for the cycle.</p><p>The CCFG synthesis procedure in Fig. <ref type="figure" target="#fig_7">7</ref> distinguishes the three invocations of emit S by maintaining the parallel nesting level . In general, all the nodes in a thread are at the same level. Nodes in a thread reached from a parallel are at one level greater, but nodes reached through a fork are at the same level.</p><p>In Fig. <ref type="figure" target="#fig_8">8</ref>, emit S can be reached at levels 0 [through the two forks, Fig. <ref type="figure" target="#fig_8">8(c)</ref>], 1 [through the top parallel and lower fork, Fig. <ref type="figure" target="#fig_8">8(b)</ref>], and 2 [through the two parallels, Fig. <ref type="figure" target="#fig_8">8(c)</ref>]. The CCFG synthesis algorithm considers these three separate visits and makes three copies of emit S, one per reincarnation, as shown in Fig. <ref type="figure" target="#fig_9">9</ref>.</p><p>The emit R in Fig. <ref type="figure" target="#fig_2">3</ref> can be reached at levels 1 (through the first parallel and the second fork) and 2 (through the two parallels). Since it cannot be reached at level 0 (there is no path to it that does not pass through at least one parallel), only two copies of emit R appear in Fig. <ref type="figure" target="#fig_5">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Computing Reachable Exit Levels</head><p>The rules for synthesizing fork and parallel nodes in Fig. <ref type="figure" target="#fig_7">7</ref> involve an iteration over all reachable exception successors of a parallel node. To avoid cycles in the CCFG, it is crucial to distinguish between the exceptions that can be taken by the code in a thread reachable from a parallel and that reachable through the fork. For example, in Fig. <ref type="figure" target="#fig_8">8</ref> only exit level 1 can be reached from the lower fork. This is important since if exit level 3 was erroneously considered reachable, the join node synthesized for the fork would branch back to the fork and create a loop. EC calculates the reachable exits from each fork and parallel using a conservative algorithm due to Berry that considers all paths from a conditional reachable. The information is used both to limit which exception handlers are synthesized from each join and for a variety of other optimizations.</p><p>The recursive algorithm for computing exit levels, shown in Fig. <ref type="figure" target="#fig_0">10</ref>, builds two sets for each thread, the set of exit levels that can be reached from the fork, i.e., when the is first started Fig. <ref type="figure" target="#fig_0">10</ref>. The algorithm for computing reachable exit levels in the IC graph. The two recursive functions seqlevels and reclevels return the exit levels reachable from a node when entered through a sequential arc and arc in the reconstruction tree, respectively. Parexits computes the exit levels reachable at a parallel. The implementation in EC of these functions memoizes two values of the functions, one for the levels visible from a fork, the other from a parallel. and the set that can be reached when the thread is restarted through the parallel.</p><p>The seqlevels and reclevels functions in Fig. <ref type="figure" target="#fig_0">10</ref> recursively compute the exit levels visible from a node reached through a sequential arc and the reconstruction tree, respectively. The rule for conditional considers both true and false branches and simply combines the two sets. The rule for watchdog combines the levels reachable from each of its children in the reconstruction tree.</p><p>Not surprisingly, the rules for parallel and fork are the most complicated. Both compute the exit levels that each of their threads can reach. They then pass this information to the parexits function, which looks at the exit levels of each thread to find the exit levels that can be taken by the parallel once the threads are finished for the cycle, and finally combines the levels that can arise from handling any of these exceptions.</p><p>The rules in parexit assume that any combination of the exit levels from each thread may appear. However, since the highest exit level always prevails at a thread, parexit first computes the minimum exit level of each thread and uses the highest such value to place a lower bound on the lowest exit level that will be considered. For example, if one thread can exit at levels 0, 2, and 3, and another can exit at levels 1 or 2, the pair can only exit at levels 1, 2, or 3, since if the first thread exits at level 0, the second always takes priority since it exits at levels 1 or 2. This situation occurs frequently since threads often contain infinite loops and thus never terminate at level 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. State Assignment</head><p>At the beginning of each cycle, control flows down the reconstruction tree along the path taken up the tree at the end of the last cycle. When control reaches it, each reconstruction node must decide to which of its children it should send control. The state assignment problem amounts to choosing a representation that makes these decisions easy.</p><p>The V3 compiler keeps a variable at each node that stores the index of the child that will receive control when the node is next executed. This makes the decisions very easy but tends to waste memory because most nodes have only a few children to distinguish. Furthermore, executing a halt instruction may require setting many variables.</p><p>This section presents an encoding that requires less memory and time. The key observation is that an Esterel program can be divided into threads, sections of the reconstruction tree through which at most one path is taken. These are blocks of code separated by statements and amount to areas where there is at most a single point of control. In the reconstruction tree, a thread is a subtree rooted at a thread node or the root whose leaves are halts or other parallels.</p><p>Instead of one variable per watchdog, EC represents the state of each thread using a single variable. This saves memory, since fewer variables are needed, and time, since a halt simply assigns one constant to one variable instead of walking up the reconstruction tree, but the code at a watchdog is slightly more complicated because it must shift and mask the state before testing it. Fig. <ref type="figure" target="#fig_0">11</ref> illustrates the technique. The code for a path is formed by concatenating the sequence of labels along the branches. The least significant bits are labels at the root. For example, the halt labeled 10110 in Fig. <ref type="figure" target="#fig_0">11</ref> takes its value by being along the path labeled 10, 01, and finally 1. Most branches are labeled 0, 1, 2, etc. encoded in binary using just enough bits to distinguish them. Branches from the root are slightly different; since the all-zero state is used to represent when the thread has terminated, the labels at the root of the thread start at 1.</p><p>Such an encoding allows the code at each watchdog to decide which branch to take by a shift and a mask (drawn to the right of the nodes in Fig. <ref type="figure" target="#fig_0">11</ref>). The shift is unnecessary at the first decision point within the thread, and the mask is unnecessary at the last. In practice, many threads contain very simple reconstruction subtrees and these optimizations often greatly simplify the code.</p><p>This encoding is very compact when the number of branches at each node in the reconstruction tree is a power of two. Codes are wasted, for example, when a node has nine branches beneath it, since this requires four bits and nearly half of the possible codes are unused.</p><p>A single thread with many levels of nested watchdogs could overflow the single integers used to represent the state of a single thread. Using more bytes to represent a thread's state is the obvious solution, but we did not implement this because none of Fig. <ref type="figure" target="#fig_0">11</ref>. Encoding states within a thread (a subtree of the reconstruction tree). The encoding of each state (written below each halt or parallel) is formed by concatenating the labels along the path from the top parallel. The expression evaluated at each node is written to its right. the benchmarks had this problem. In handwritten code, most state trees (e.g., Fig. <ref type="figure" target="#fig_0">11</ref>) are wide (i.e., contain many pauses), not tall (i.e., do not contain many sequences of nested preemption conditions). The state encoding is trivial for small examples such as Fig. <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. REMOVING CONCURRENCY</head><p>After EC translates the IC graph representation of an Esterel program into a CCFG using the algorithm in the last section, it generates a SCFG by statically analyzing the concurrent behavior of the program, interleaving the code for each thread and inserting code that simulates context switches. The result is a SCFG that can easily be translated into a C function using the algorithm in Section VIII. Code generated this way runs faster than V5's gate code because it is a better fit to a processor's natural control behavior. The code from V3 runs faster because it avoids the overhead of context switching and internal communication, which it exhaustively analyzes when the program is compiled. But this comes at the expense of extensive code duplication. In effect, the code generated by V3 uses a distinct value of the program counter for each possible combination of program counters and internal signal states in the Esterel program.</p><p>The sequentializing procedure operates in three steps. First, it adds data dependency arcs to represent the constraint that each write of a signal must precede each read (the dashed lines in Fig. <ref type="figure" target="#fig_5">5</ref>). Second, it schedules the nodes in the CCFG by placing them in a topological order that respects both the existing control dependencies and the newly added data dependencies. Finally, it copies each CCFG node in scheduled order to a SCFG, along the way inserting nodes that save and restore control state where the schedule implies a context switch. (For example, the nodes that write and test variables 2 and 3 in Fig. <ref type="figure" target="#fig_6">6</ref>.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Scheduling</head><p>A schedule is an order of all the instructions in the program such that each runs when its predecessors have run and its data is ready. EC uses a schedule to determine the order instructions in concurrent threads will run and when one thread must be suspended and another resumed, i.e., when to context switch.  Any topological order of the CCFG augmented with data arcs is a correct schedule, but certain orders are better than others because they require fewer context switches. For example, a better choice of schedule in Fig. <ref type="figure" target="#fig_6">6</ref> would have eliminated the assignments and test of 3; the nodes 3 and 3 2 appeared too early. Unfortunately, finding a schedule with a minimum number of context switches is NP-complete, but a bad schedule does not significantly slow or bloat the generated code. Theoretically, the slowdown or bloat may be quadratic, but in practice EC produces acceptable code using a simple depth-first scheduler. Table <ref type="table" target="#tab_1">II</ref> shows the sequentializing procedure fed with a simple scheduler increases the number of nodes at most 65% for the largest 16 500-node example.</p><p>The optimum scheduling problem is NP-complete because it could be used to solve the minimum feedback vertex set problem. To solve the minimum feedback vertex set problem for a particular directed graph, create a program with one is not part of a cycle, the code for the two threads can be grouped under a single conditional. (c) If code for the node must be split because of a cyclic path in the graph that passes through the node, the test for n1 must be duplicated. thread per node, each thread having a single conditional invoking two threads beneath it [an operation], such as in Fig. <ref type="figure" target="#fig_10">12(a)</ref>. The first of these threads depends on signals corresponding to incoming arcs in the given node; the second emits signals corresponding to outgoing arcs. Instructions corresponding to a node that does not participate in any cycle can be scheduled together to generate code such as in Fig. <ref type="figure" target="#fig_10">12</ref>(b), the code for at least one node in each cycle must be split as in Fig. <ref type="figure" target="#fig_10">12(c</ref>). This requires duplicating a test, so the code size grows with the number of splits. Splitting a node is analogous to removing it from the graph, so asking if there is a schedule that generates code under a certain size is equivalent to asking if the graph can be made acyclic by removing fewer than a certain number of nodes-the feedback vertex set problem.</p><p>EC assumes a static schedule exists, i.e., there is a unique order in which all statements can execute in every cycle. This is true for many programs, but Esterel programs can have data-dependent orders. These may appear when resources are shared and used in different orders in different cycles, or when the system is inherently cyclic, such as a cyclic-ring arbiter. EC is unable to compile such programs.</p><p>Automata compilers permit statements to execute in different orders in each state, since they generate separate code for each. Gate-based compilers have a harder time: they must completely explore the state space of the system before concluding that the program is valid. As a side-effect, they determine the function of the system in all of these states and resynthesize the cyclic portions of the netlist. This is the machinery developed by Shiple et al. <ref type="bibr" target="#b7">[8]</ref>. We discuss the possibility of using this technique in EC in Section X.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Building the Graph</head><p>Fig. <ref type="figure" target="#fig_2">13</ref> shows the algorithm for synthesizing a SCFG from a CCFG, the most important algorithm in EC and this paper's key contribution. The algorithm walks through the nodes in the CCFG in scheduled order, copying each (line 2) and attaching its incoming arcs at each step (line 24). Normally this just copies the graph, but additional nodes are inserted that save and restore control state when control must switch between concurrently running threads.</p><p>Fig. <ref type="figure" target="#fig_4">14</ref> depicts a few steps of the algorithm while it is building Fig. <ref type="figure" target="#fig_6">6</ref>. In effect, the algorithm sweeps a line through the concurrent graph, shifting each node across the frontier (the dotted line) and attaching its incoming arcs according to the arcs that cross the frontier. Maintaining these arcs-predecessors (indicated with dashed lines)-is the algorithm's main concern.</p><p>A node keeps track of two types of node that may eventually branch to it. The most common is a "normal predecessor," a copy of a CCFG node. Line 21 maintains these predecessors, indicated by dashed arrows in Fig. <ref type="figure" target="#fig_4">14(a)</ref>. The other type of predecessor is a "restart predecessor," a multiway branch created when a thread is resumed. Line 34 assigns these. Node 3 in Fig. <ref type="figure" target="#fig_4">14(e</ref>) is a restart predecessor, indicated by a dotted arrow.</p><p>The distinction between normal and restart predecessors comes when a thread is suspended, in line 44. Only normal predecessors are saved. Since a restart predecessor indicates the possibility of something restarting, it is wasteful to save something that never started.</p><p>The algorithm simply copies the CCFG when synthesizing a sequence of nodes in the same thread (where context switching is unnecessary). The main loop copies each node (line 2), connects arcs from its predecessors (line 24), and prepares to connect the arcs to its successors (line 21). The resume and suspend procedures do nothing.</p><p>Fig. <ref type="figure" target="#fig_4">14</ref>(a) and (b) illustrates this common case, showing how a node is synthesized when no context switch is needed. Fig. <ref type="figure" target="#fig_4">14(a</ref>) shows 1's single normal predecessor , created earlier in line 21 when node was copied. In Fig. <ref type="figure" target="#fig_4">14(b)</ref>, line 2 has copied 1 to the sequential graph (moved above the dotted line), line 24 has added an arc from 1's predecessor to the new copy of 1, and line 21 has added the new sequential node 1 as a normal predecessor of both 3 and 1 3.</p><p>Synthesizing context switches is more complicated. When one thread is running and a node from another thread must run (usually when the first thread communicates to the second), the control state of the running thread is saved and the control state of the suspended thread is recovered. The suspend and resume procedures accomplish this by adding nodes that save and restore control state. They are recursive because threads are often nested in Esterel.</p><p>Fig. <ref type="figure" target="#fig_4">14(c</ref>)-(e) shows how this works. In Fig. <ref type="figure" target="#fig_4">14(c</ref>), the two join nodes labeled 2 and an unlabeled join are in the thread to be suspended (line 20 placed them there when their predecessors were copied). In Fig. <ref type="figure" target="#fig_4">14(d)</ref>, the suspend procedure has run; line 43 has added nodes 2 3, 2 4, and 2 1 to save the state of the thread, line 44 has added arcs from the two nodes, 2 1, and 2 to the new state-saving nodes, and line 45 has added each of the save state nodes as normal predecessors Fig. <ref type="figure" target="#fig_2">13</ref>. How to convert a CCFG into a sequential one. The main loop steps through the CCFG in scheduled order, copying each node and calling connect() to attach arcs from nodes that could run it next. The suspend procedure suspends a running thread under a fork, and resume prepares it to continue running. Fig. <ref type="figure" target="#fig_4">14</ref>. Synthesizing SCFG nodes. The dotted line separates the SCFG (above) from the uncopied part of the CCFG. In (a) and (b), node s1 is synthesized. In (a), s1 has S as its sole predecessor (dashed arrow). In (b), s1 has been copied to the SCFG, an arc has been added from S to s1 in the SCFG, and nodes s3 and s1 = 3 now have the copy of s1 as their predecessors. (c), (d), and (e) depict the synthesis of a context switch. In (d), the three uncopied nodes in (c) have been run as nodes that save their thread's state and the fork has gained them as predecessors. In (e), the fork node has been run as a conditional that tests the state of the resumed thread, and nodes in that thread have gained it as a predecessor.</p><p>of the unlabeled fork that is the parent of this thread ( in the suspend procedure).</p><p>Fig. <ref type="figure" target="#fig_4">14</ref>(e) shows the state after the resume procedure has run. Line 32 has created node 3, which tests the state of the thread being resumed, line 33 has called connect, causing line 21 to connect arcs from 2 3, 2 4, and 2 5 to 3 (these nodes were the of the fork), and line 34 has added 3 as the restart predecessor of the node that tests and the unlabeled join; the two nodes that were about to run before the thread was suspended.</p><p>Currently, EC uses a trivial encoding for the state of threads suspended within a cycle (this is different from the careful encoding used to save state between cycles described in Section VI-D). Each CCFG node is encoded with the unique small-integer identifier assigned when the node is created. While this is hardly the most efficient encoding, it matters little. Most resume branches are two-way, which become comparisons to a constant. A more efficient encoding might consider the sequence of nodes that are suspended and resumed for a particular thread and try to reuse codes to make the encodings at each resume dense, perhaps using a graph-coloring algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. GENERATING WELL-STRUCTURED C CODE</head><p>This section describes how to generate attractive, human-readable C code from the SCFG produced by the algorithms in Section VII. Generating correct C code is easy (the SCFG representation was chosen to make this trivial), but making it easy-to-read is harder. We did this to aid users of the compiler when they wish to debug their programs, although it may also make it easier for the C compiler to optimize the result.</p><p>The SCFGs generated by the algorithm in the last section are simple. Each node has an expression that is evaluated when the node runs. If the node has more successors, the result of the expression is used to choose among them. A code generation algorithm could simply generate the code for each node and use goto statements to branch to the appropriate location. The Polis compiler <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref> does this and the results, while correct, are inscrutable, although this is partly due to the unstructured control graphs generated from BDD's.</p><p>Structuring control-flow graphs has been studied in a few contexts. Baker <ref type="bibr" target="#b13">[14]</ref> proposed an algorithm for finding high-level control constructs (e.g., if-then-else, while loops) in goto-riddled FORTRAN programs. Cifuentes <ref type="bibr" target="#b14">[15]</ref> used a similar procedure to reconstruct high-level information in control-flow graphs generated by decompiling executables. Since loops are the main concern in both works, and the SCFG our compiler generates have no loops, the algorithms are not a good fit for the problem here.</p><p>The algorithm in EC generates sequences of statements for sequences of action nodes in the control-flow graph and conditionals-if-then-else for two-way branches; switch statements for three or more-for nodes with more than one outgoing arc. The challenge is deciding which nodes to include in the body of a conditional and which to place outside.</p><p>We choose the immediate postdominator of a conditional node as the first node outside the scope of the body of the conditional. A node postdominates node if every path from to the exit of the control-flow graph passes through . The immediate postdominator is the unique such that no other node both postdominates and is postdominated by . This is a classical relationship in graph theory, and we use the standard fast algorithm by Lengauer and Tarjan to compute it <ref type="bibr" target="#b15">[16]</ref>.</p><p>Fig. <ref type="figure" target="#fig_5">15</ref> shows the immediate postdominators for the conditional nodes in Fig. <ref type="figure" target="#fig_6">6</ref>. As expected, they are choke-points in the control-flow graph and match what a programmer would probably choose.</p><p>Fig. <ref type="figure" target="#fig_6">16</ref> shows the recursive algorithm used to build an abstract syntax tree (i.e., that can be easily traversed to produce C source code) from a control-flow graph. The function takes three arguments-the node to be synthesized, the node that follows it, and a flag indicating whether a break statement is necessary to reach this nod--and returns an AST for the node.</p><p>Fig. <ref type="figure" target="#fig_6">16</ref> actually builds the program backward, constructing the nodes that will appear later in the program before those that will appear earlier. This is to ensure all goto statements are forward, which is expected when the control-flow graph contains no loops. This is why code for an else branch is computed before the then branch, and why code for each case of a switch statement is inserted at the beginning of its body rather than at the end. Fig. <ref type="figure" target="#fig_11">17</ref> shows the code Fig. <ref type="figure" target="#fig_6">16</ref> generates from the SCFG in Fig. <ref type="figure" target="#fig_6">6</ref>. Because the successors of a multiway switch statement are built in an undefined order, some arbitrary choices were Fig. <ref type="figure" target="#fig_5">15</ref>. Postdominators of the conditional nodes in Fig. <ref type="figure" target="#fig_6">6</ref>. The solid line from each conditional leads down to the first instruction outside the body of the conditional. The immediate postdominator of a node is the closest node through which all paths from the conditional pass. Fig. <ref type="figure" target="#fig_6">16</ref>. The algorithm for building an AST from a SCFG such as Fig. <ref type="figure" target="#fig_6">6</ref>. This recursive function builds later statements first (e.g., the else before the then branch) to ensure all goto statements branch forward. made. For example, the two cases in the second switch statement could have been reversed, but the code after 6 would still have appeared in the later case since Fig. <ref type="figure" target="#fig_6">16</ref> ensures all gotos are forward.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. EXPERIMENTAL RESULTS</head><p>We ran experiments to compare the quality of code generated by the new compiler to that from the V3 automata compiler, the V5 gate-based compiler, the output of V5 after being passed through logic synthesis, and the compiler by Bertin et al. <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>. To measure average cycle times, we ran the generated program for a second and counted the number of cycles it executed. We generated pseudorandom input patterns with an testbench generated by the algorithm of Yuan et al. <ref type="bibr" target="#b21">[22]</ref> to produce inputs that observed environmental constraints (e.g., mutually exclusive input signals) but did not weight the inputs. Measured times do not include time to run the testbench. We ran the testbench separately and subtracted out its effects, which was as high as 75% of the execution time for the small examples, and probably distorted their times, but was less than 1% for the large</p><p>The example programs, listed in Table <ref type="table" target="#tab_0">I</ref>, were all handwritten and range from toy examples (hundreds of lines) to industrial size (nearly 10 000 lines). Fig. <ref type="figure" target="#fig_12">18</ref> shows the average cycle times and executable sizes we measured for these examples on two machines: a 336-MHz UltraSPARC-II and a 233-MHz Intel Pentium. Compared to EC, the V5 compiler produces consistently slower, larger code, but running the output of V5 through an aggressive logic optimizer can eliminate the gap, albeit only after many minutes of work and only for the smaller examples. Logic optimization did not finish in an hour on the examples over 1000 lines; EC was able to compile the largest example in 10 s.</p><p>The V3 compiler, when it runs, generally produces faster code, but at the expense of very large executables. It did not complete in an hour for any example larger than 1000 lines, and failed on a 600-line example. More precisely, V3 appears not to be able to compile programs with more than about 300 states.</p><p>Bertin et al.'s compiler produces code about twice as big and twice as fast as that from EC. The missing data points for large examples were due to the source not being available for some and because of a bug in their compiler that incorrectly rejected some programs. In theory, their approach should scale as well as EC's.</p><p>Small programs run faster on the lower clock-rate Pentium, but larger examples run slower. We suspect this is due to different cache sizes on the two processors.</p><p>The speed of V5 without logic optimization very closely tracks the size of the program. This is expected since each source statement becomes a few gates, and each gate is executed once per cycle, thus the speed should be directly proportional to the source program size. The speed of the code from the other compilers appears to have little to do with the size of the source. This is expected, since the speed of the code from these compilers is related to the number of source instructions that must execute each cycle, which differs from the number of instructions in the program an varies among programs.</p><p>The wristwatch example (465 nodes) shows the least variance among the different compilers because it calls a substantial number of external routines. Much of its execution time is spent in these routines, so the quality of the generated code matters less.</p><p>Compilation time becomes noticeable for the larger examples, but the C compiler is the bottleneck. For example, V5 without logic optimization was able to produce C code for the largest example in 7 s, and EC was able to produce it in 10 s, but it took Sun's CC about 2 min to compile the output from EC, and 45 min to compile V5's output.</p><p>Compilation times for V3 can range from very short to unacceptably long (hours). Unfortunately, patience in running V3 is not rewarded since long runs produce impractically large executables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X. CONCLUSION AND FUTURE WORK</head><p>This paper has presented a new way to compile the synchronous language Esterel that preserves much of the program's original control structure for a code size and speed advantage. It translates Esterel's preemption and exception constructs into conditional branches and compiles away its concurrency by statically scheduling the instructions and inserting code that saves control state in variables and restores it with conditional branches. Ultimately, it produces mostly structured C code that contains some gotos.</p><p>Experiments show EC produces code that can be 100 times faster and half the size of code from other high-capacity compilers. EC is currently used to generate simulation code in CoCentric System Studio (described under an earlier name by Buck and Vaidyanathan <ref type="bibr" target="#b22">[23]</ref>), an environment that allows designers to specify systems using a mixture of dataflow graphs and hierarchical finite-state machines. To compile a simulation, System Studio translates control behavior into IC programs, EC compiles them into C, and the result is linked code generated by System Studio for the dataflow portion.</p><p>Other applications are possible, in addition to compiling Esterel, EC could easily be adapted to compile other synchronous, concurrent languages, such an Lavagno and Sentovich's ECL <ref type="bibr" target="#b23">[24]</ref>.</p><p>Many further optimizations are possible. The automata compilers can produce much better code for small examples. One possibility is to apply the automata compilation technique to small segments of a much larger program, such as those with frequent synchronizing communication. Such things usually have far fewer states than a simple product would suggest and are exactly those where automata code would be far better than that from EC.</p><p>Handling apparently cyclic programs is another challenge. One approach would be to resynthesize cyclic portions of the circuit as the V5 compiler does using the technique due to Shiple et al. <ref type="bibr" target="#b7">[8]</ref>. They generate an exact three-valued next-state function by unrolling the circuit according to the algorithm of Bourdoncle <ref type="bibr" target="#b24">[25]</ref> and try to use it to prove that no state with unknown outputs is reachable. If they succeed, they resynthesize the cyclic portion of the circuit by forcing the exact three-valued next state function to take two values. Specifically, if in some state an output of the three-valued function is unknown, they replace that output with a 1. This does not affect the behavior of the program because their technique proves that none of these states can be reached.</p><p>How to apply this Boolean technique to control-flow graphs is not obvious, but another approach (suggested to me by Berry) is possible. A cyclic network can always be evaluated by unrolling it and simulating it using three-valued logic (i.e., each signal is either present, absent, or unknown), but simulating three-valued signals is costly in software, especially when simulating the program counter. However, it is not necessary when the program being evaluated is monotonic and guaranteed to always have defined outputs. Esterel's constructive semantics <ref type="bibr" target="#b25">[26]</ref> guarantees programs are monotonic; a more defined input always produces an equal or more-defined output. Specifically, changing an input from unknown to known can only change an undefined output to known or leave the output unchanged. It follows that all unknown inputs can be set to arbitrary, known values without affecting the output provided the program is known never to produce undefined outputs.</p><p>Concretely, this technique would unroll each strongly connected component of the CCFG using either Bourdoncle's <ref type="bibr" target="#b24">[25]</ref> or our <ref type="bibr" target="#b26">[27]</ref> scheduling algorithm. The amount of unrolling necessary follows from the structure of the program and noting that each signal can be either undefined or defined. Signals in the SCC would be initialized to absent (the value does not matter) and constant propagation on the resulting code would then greatly simplify it. However, there is still the strong possibility of a quadratic blow-up in code size with this technique.</p><p>One of the reviewers noted that EC can be thought of as having factored the automata code from V3. In effect, EC shares code common to two or more states by predicating it with variables that represent control state and internal signals. This observation raises the possibility of a compiler that analyzes the state space of an Esterel program and generates distinct pieces of code not for single states, but for groups of states for which EC generates efficient code. The result should be faster but larger than normal EC output.</p><p>Most future work involves combining the ideas from all the existing compilers, each of which have certain strengths.We are confident that the result would be capable of producing fast, small code for virtually all programs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. A simple Esterel module modeling a shared resource. The first thread generates requests (R) in response to external requests (I), and the second thread responds to them (A) in alternate cycles. The S input resets both threads.</figDesc><graphic coords="1,319.56,158.88,214.32,208.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. A timing diagram for an execution of the Esterel program in Fig. 1. Inputs are listed on the left; the signals generated by the program in response are listed on the right. Each horizontal tick denotes a clock cycle.</figDesc><graphic coords="2,314.76,62.28,226.80,162.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The IC graph for the program in Fig. 1. Each node is drawn to the right of its instruction where possible. The thin lines and outlined nodes are a control-flow graph with concurrency. The thick lines and solid nodes form the reconstruction tree, responsible for restarting the program at the beginning of each cycle.</figDesc><graphic coords="4,39.60,62.28,252.00,327.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(b) in the last cycle, the path to the halt was marked and control will flow like Fig. 4(b) in the next cycle. If instead control reached nodes beneath the parallel in the last cycle, the path leading to the parallel would have been marked and control will follow the path in Fig. 4(d) in the next cycle. Fork and parallel nodes start and resume threads. If is present, control flows through the topmost watchdog, through</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Flow of control around IC nodes implementing the every S statement. (a) Initialization: control begins at the start node, flows to the halt and stops. (b) S is absent and the halt was active last cycle (i.e., the body of the every is not running): the watchdog sends control to the halt. (c) S is present: control flows to the fork. (d) S is absent and the parallel was active last cycle (i.e., the every is running): the watchdog sends control to the parallel.</figDesc><graphic coords="4,317.28,62.28,221.76,126.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The CCFG EC generates for the program in Fig. 1. Dashed lines represent data dependencies. Variables s0, s1, s2, and s3 store state between cycles; e2 holds the exit level of the group of threads. Initially, s0 = 2 and all other variables are uninitialized.</figDesc><graphic coords="5,301.14,62.28,252.00,388.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. The SCFG EC generates for the program in Fig. 1. Three context switches-tests and assignments of t2 and t3-were introduced to interleave the execution of the threads.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. How to translate an IC graph into a CCFG (after Berry). The recursive procedures seqNode and recNode visit and copy IC nodes by following sequential and reconstruction arcs, respectively. n: IC node being visited, l: reincarnation level (see Section VI-B), t: thread in which n resides, j: CCFG join node for the thread.</figDesc><graphic coords="6,314.76,62.28,226.80,452.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Reincarnation. Emit S executes three times: (a) once at the beginning of the cycle when the two parallels are restarted (level 2), (b) once when exit T3 terminates and restarts the inner loop (level 1), and (c) once when exit T2 executes and is executed and causes the outer loop to restart (level 0).</figDesc><graphic coords="7,301.14,62.28,252.00,261.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. The CCFG generated for the program with reincarnation in Fig. 8.</figDesc><graphic coords="7,38.10,62.28,252.00,192.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Construction to demonstrate the NP-completeness of the minimal scheduling problem. (a) For each node in a directed graph, construct a thread like this one for a node n1 with incoming arcs a1 and a2 and outgoing arcs a3, a4, and a5. The signal n1 is an input, n1a, and n1b are outputs. (b) If this node</figDesc><graphic coords="10,51.72,62.28,226.80,225.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. Code generated from Fig. 6 by the algorithm in Fig. 16. This behaves like the concurrent Esterel program in Fig. 1 and is the final output of the compiler.</figDesc><graphic coords="13,38.10,62.28,252.00,474.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 18 .</head><label>18</label><figDesc>Fig. 18. Average cycle times for random inputs and executable sizes as a function of source program size for the examples in Table I. The four compilers are the automata-based V3, the gate-based V5, the output of V5 run through logic optimization, the new compiler EC, and Bertin et al.'s compiler (SX). Missing data points indicate part of the compilation chain failed or the source code was not available. (a) Average per-cycle execution times as a function of the source program size for a 336-MHz Sun UltraSPARC-II with a 4-MB cache, (b) sizes of the executable (generated by Sun's "cc -O"), (c) average cycle times on a 233-MHz Pentium with a 512-kB cache, and (d) executable sizes for the Pentium (generated by egcs 2.91.66 -O).</figDesc><graphic coords="14,72.96,62.28,447.36,260.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="8,51.72,62.28,226.80,352.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="11,61.86,62.28,466.56,283.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="11,64.14,385.02,462.00,137.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="12,314.76,259.26,226.80,244.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I EXAMPLES</head><label>I</label><figDesc>USED IN EXPERIMENTS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II NUMBER</head><label>II</label><figDesc>OF IC, CCFG, AND SCFG NODES IN THE EXAMPLES</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The synchronous approach to reactive realtime systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Benveniste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Berry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1991-09">Sept. 1991</date>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="1270" to="1282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The Esterel synchronous programming language: Design, semantics, implementation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gonthier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Comput. Programming</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="87" to="152" />
			<date type="published" when="1992-11">Nov. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The synchronous data flow programming language LUSTRE</title>
		<author>
			<persName><forename type="first">N</forename><surname>Halbwachs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Caspi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pilaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1991-09">Sept. 1991</date>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="1305" to="1320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automatic distribution of reactive systems for asynchronous networks of processors</title>
		<author>
			<persName><forename type="first">P</forename><surname>Caspi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Girault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pilaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="416" to="427" />
			<date type="published" when="1999-05">May 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Synthesis of software programs for embedded control applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chiodo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Giusto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jurecska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lavagno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sentovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 32nd Design Automation Conf</title>
		<meeting>32nd Design Automation Conf<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-06">June 1995</date>
			<biblScope unit="page" from="587" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Synthesis of software programs for embedded control applications</title>
		<author>
			<persName><forename type="first">F</forename><surname>Balarin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chiodo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Giusto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jurecska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lavagno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Sentovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Suzuki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Computer-Aided Design</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="834" to="849" />
			<date type="published" when="1999-06">June 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Generating efficient protocol code from an abstract specification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Castelluccia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dabbous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>O'malley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Networking</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="514" to="524" />
			<date type="published" when="1997-08">Aug. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Constructive analysis of cyclic circuits</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Shiple</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Touati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Design and Test Conf</title>
		<meeting>European Design and Test Conf<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-03">Mar. 1996</date>
			<biblScope unit="page" from="328" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Une nouvelle mÃ©thode de compilation pour le language ESTEREL [A new method for compiling the Esterel language]</title>
		<author>
			<persName><forename type="first">V</forename><surname>Bertin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Poize</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pulou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GRAISyHM-AAA</title>
		<meeting>GRAISyHM-AAA<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-03">Mar. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficient compilation of Esterel for real-time embedded systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Weil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bertin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Closse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Poize</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Venier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pulou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Compilers, Architecture, and Synthesis for Embedded Systems (CASES)</title>
		<meeting>Int. Conf. Compilers, Architecture, and Synthesis for Embedded Systems (CASES)<address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-11">Nov. 2000</date>
			<biblScope unit="page" from="2" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Software synthesis of process-based concurrent programs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 35th Design Automation Conf</title>
		<meeting>35th Design Automation Conf<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-06">June 1998</date>
			<biblScope unit="page" from="502" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Compositional software synthesis of communicating processes</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Computer Design (ICCD)</title>
		<meeting>IEEE Int. Conf. Computer Design (ICCD)<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-10">Oct. 1999</date>
			<biblScope unit="page" from="646" to="651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Gonthier</surname></persName>
		</author>
		<title level="m">SÃ©mantiques et modÃ¨les d&apos;exÃ©cution des langages rÃ©actifs synchrones; application Ã  Esterel</title>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
		<respStmt>
			<orgName>UniversitÃ© d&apos;Orsay</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">ThÃ¨se d&apos;informatique</note>
	<note>Semantics and models of execution of the synchronous reactive languages: Application to Esterel</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An algorithm for structuring flowgraphs</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Assn. Computing Machinery</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="98" to="120" />
			<date type="published" when="1977-01">Jan. 1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Structuring decompiled graphs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cifuentes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Compiler Construction</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>Int. Conf. Compiler Construction<address><addrLine>Linkoping, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1996-04">Apr. 1996</date>
			<biblScope unit="volume">1060</biblScope>
			<biblScope unit="page" from="91" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A fast algorithm for finding dominators in a flowgraph</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lengauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Tarjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Programming Languages and Systems</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="121" to="141" />
			<date type="published" when="1979-07">July 1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Bernhard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Boussinot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gonthier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ressouche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Rigault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Tanzi</surname></persName>
		</author>
		<ptr target="http://www.esteret.org" />
		<title level="m">Programming a reflex game in Esterel V3</title>
		<imprint>
			<date type="published" when="1989-05">1989. May</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Programming a digital wristwatch in Esterel V3. Rapport de recherche 8</title>
		<author>
			<persName><forename type="first">G</forename><surname>Berry</surname></persName>
		</author>
		<ptr target="http://www.esterel.org" />
	</analytic>
	<monogr>
		<title level="s">Centre de Mathematiques Appliquees</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Ecole des Mines de Paris</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hardware/software co-design of an avionics communication protocol interface system: An industrial case study</title>
		<author>
			<persName><forename type="first">F</forename><surname>CloutÃ©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-N</forename><surname>Contensou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Esteve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pampagnin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Favard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th Int. Workshop Hardware/Software Codesign (CODES)</title>
		<meeting>7th Int. Workshop Hardware/Software Codesign (CODES)<address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-05">May 1999</date>
			<biblScope unit="page" from="48" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Esterel: A formal method applied to avionic software development</title>
		<author>
			<persName><forename type="first">G</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bouali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fornari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ledinot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nassor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">De</forename><surname>Simone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Comput. Programming</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="5" to="25" />
			<date type="published" when="2000-01">Jan. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A case study in computer-aided co-design of embedded controllers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chiodo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Engels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Giusto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jurecska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lavagno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Design Automation Embedded Syst</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="51" to="67" />
			<date type="published" when="1996-01">Jan. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Modeling design constraints and biasing in simulation using BDDs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shultz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pixley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aziz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/ACM Int. Conf. Computer-Aided Design (ICCAD)</title>
		<meeting>IEEE/ACM Int. Conf. Computer-Aided Design (ICCAD)<address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-11">Nov. 1999</date>
			<biblScope unit="page" from="584" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Heterogeneous modeling and simulation of embedded systems in El Greco</title>
		<author>
			<persName><forename type="first">J</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vaidyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th Int. Workshop Hardware/Software Codesign (CODES)</title>
		<meeting>8th Int. Workshop Hardware/Software Codesign (CODES)<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-05">May 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">ECL: A specification environment for system-level design</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lavagno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sentovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 36th Design Automation Conf., New Orleans</title>
		<meeting>36th Design Automation Conf., New Orleans</meeting>
		<imprint>
			<date type="published" when="1999-06">June 1999</date>
			<biblScope unit="page" from="511" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Efficient chaotic iteration strategies with widenings</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bourdoncle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Formal Methods in Programming and Their Applications: Int. Conf. Proc</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Novosibirsk, Russia</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1993-06">June 1993</date>
			<biblScope unit="volume">735</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">The constructive semantics of pure Esterel</title>
		<author>
			<persName><forename type="first">G</forename><surname>Berry</surname></persName>
		</author>
		<ptr target="http://www.esterel.org" />
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The specification and execution of heterogeneous synchronous reactive systems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Edwards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Available as UCB/ERL M97/31</title>
		<meeting><address><addrLine>Berkeley</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>Univ. California</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">He is currently an Assistant Professor in the Computer Science Department of Columbia University in New York, which he joined in 2001 after a three-year stint with Synopsys, Inc., in Mountain View, CA. His research interests include embedded system design, domain-specific languages, and compilers. He is the author of Languages for Digital Embedded Systems</title>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">A</forename><surname>Edwards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">M&apos;97) received the B.S. degree in electrical engineering from the California Institute of Technology, in 1992, and the M.S. and Ph.D. degrees, also in electrical engineering</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="1994">1994 and 1997. 2000</date>
		</imprint>
		<respStmt>
			<orgName>University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note>respectively</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
