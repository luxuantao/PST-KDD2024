<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Design and Construction of a Realistic Digital Brain Phantom</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Collins</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">A</forename><forename type="middle">P</forename><surname>Zijdenbos</surname></persName>
						</author>
						<author>
							<persName><forename type="first">V</forename><surname>Kollokian</surname></persName>
						</author>
						<author>
							<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Sled</surname></persName>
						</author>
						<author>
							<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Kabani</surname></persName>
						</author>
						<author>
							<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Holmes</surname></persName>
						</author>
						<author>
							<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Evans</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">McConnell Brain Imaging Centre</orgName>
								<orgName type="institution" key="instit1">Montréal Neurological Institute</orgName>
								<orgName type="institution" key="instit2">McGill Univer-sity</orgName>
								<address>
									<postCode>3801, H3A 2B4</postCode>
									<settlement>University, Montréal</settlement>
									<region>P.Q</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Montréal Neurological Institute</orgName>
								<orgName type="institution">McGill University</orgName>
								<address>
									<addrLine>McConnell Brain Imaging Centre</addrLine>
									<postCode>H3A 2B4</postCode>
									<settlement>Montréal</settlement>
									<region>P.Q</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Design and Construction of a Realistic Digital Brain Phantom</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3024575E651CBE4F6D34429378C55745</idno>
					<note type="submission">received October 3, 1997; revised June 16, 1998. The Associate Editor responsible for coordinating the review of this paper and recommending its publication was M. W. Vannier. Asterisk indicates corresponding author.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Brain phantom</term>
					<term>magnetic resonance imaging</term>
					<term>positron emission tomography</term>
					<term>simulation</term>
					<term>testing</term>
					<term>validation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>After conception and implementation of any new medical image processing algorithm, validation is an important step to ensure that the procedure fulfills all requirements set forth at the initial design stage. Although the algorithm must be evaluated on real data, a comprehensive validation requires the additional use of simulated data since it is impossible to establish ground truth with in vivo data. Experiments with simulated data permit controlled evaluation over a wide range of conditions (e.g., different levels of noise, contrast, intensity artefacts, or geometric distortion). Such considerations have become increasingly important with the rapid growth of neuroimaging, i.e., computational analysis of brain structure and function using brain scanning methods such as positron emission tomography and magnetic resonance imaging.</p><p>Since simple objects such as ellipsoids or parallelepipedes do not reflect the complexity of natural brain anatomy, we present the design and creation of a realistic, high-resolution, digital, volumetric phantom of the human brain. This three-dimensional digital brain phantom is made up of ten volumetric data sets that define the spatial distribution for different tissues (e.g., grey matter, white matter, muscle, skin, etc.), where voxel intensity is proportional to the fraction of tissue within the voxel. The digital brain phantom can be used to simulate tomographic images of the head. Since the contribution of each tissue type to each voxel in the brain phantom is known, it can be used as the gold standard to test analysis algorithms such as classification procedures which seek to identify the tissue "type" of each image voxel. Furthermore, since the same anatomical phantom may be used to drive simulators for different modalities, it is the ideal tool to test intermodality registration algorithms. The brain phantom and simulated MR images have been made publicly available on the Internet (http://www.bic.mni.mcgill.ca/brainweb).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>T HE work presented in this paper was motivated by the continuing need for a three-dimensional (3-D) standard data set to test, validate and measure the accuracy of different image analysis procedures. Validation using data acquired in vivo is difficult since there is no direct information available for the imaged object to corroborate various analyses. Manual labeling is often used to determine truth indirectly in such cases, however intra-and inter-rater variability makes it sub-optimal as a gold standard. Without perfectly known reference data, absolute quantitative validation is not possible.</p><p>The use of in vivo magnetic resonance (MR) or computed tomography (CT) data confirmed by post-mortem images of macro-or microtomed histological sections is also of limited use, since tissue prepared for such imaging procedures may suffer from cytolysis, shrinkage, tearing, and other gross deformations, making registration difficult and thus complicating direct comparison with the in vivo data. Using post-mortem data sets acquired soon after death is an option for validation (e.g., see <ref type="bibr" target="#b0">[1]</ref> for multimodality registration). However, the tissue's magnetic characteristics will be modified due to physical changes (such as decreasing temperature and oxygenation level) affecting the MR signal and consequently the tissue intensity contrasts on which post-processing procedures are dependent.</p><p>Physical phantoms have been used to address these problems since they allow control over the object shape and material properties. For example, geometrically simple phantoms for MR imaging made of agar gel with iron oxide particles have been used to test classification algorithms <ref type="bibr" target="#b1">[2]</ref>. More complex, anatomically realistic head phantoms such as the well-known Hoffman brain phantom <ref type="bibr" target="#b2">[3]</ref> have been used for anatomical simulation to create positron emission tomography (PET) images <ref type="bibr" target="#b2">[3]</ref>, assessment of reconstruction accuracy of PET images <ref type="bibr" target="#b3">[4]</ref>, evaluation of single photon emission computed tomography (SPECT) imaging components <ref type="bibr" target="#b4">[5]</ref>, testing registration of SPECT and PET images <ref type="bibr" target="#b5">[6]</ref>, and testing modified filtered backprojection algorithms to correct for head motion <ref type="bibr" target="#b6">[7]</ref>. While physical phantoms permit extensive testing in the real-world scanning environment, their strength is also their weakness in that their stability makes it difficult to change shape or material properties at will.</p><p>Digital phantoms have been proposed to address weaknesses associated with both post-mortem data and physical phantoms. The advantages of digital phantoms are many: they can be easily modified to model pathology or variations in normal anatomy. Simulating images from these phantoms allows complete control over factors that may affect an algorithm such as noise, contrast, slice thickness, pixel size, geometric distortion, and movement artefacts. By varying each of these possible sources of error, one can evaluate the procedure's robustness in a controlled fashion. Some uses of digital brain phantoms include evaluation of PET imaging characteristics <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, evaluation of partial volume effects (PVE's) in PET <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref> and validation of registration algorithms <ref type="bibr" target="#b11">[12]</ref>. The principal weaknesses of simulated data are usually 1) the oversimplicity of the phantom geometry, 2) the improper treatment of edge-0278-0062/98$10.00 © 1998 IEEE effects which leads to tissue mixing within imaged voxels, and 3) improper modeling of the data acquisition and image formation stages. In this paper, we address the first two issues when generating a general purpose neuro-anatomical phantom for use with any tomographic imaging modality. The third issue is modality-specific and we give examples of simulated PET and MR images. More detailed treatment of the simulations concerned are given in related publications, cited below. While testing with simulated data is necessary for algorithm validation, it is not sufficient. Additional testing with real data must also be completed to demonstrate that the algorithm actually works under real-world conditions where some unknown factors almost certainly remain. By definition, since they are unknown, algorithm behavior with respect to these factors will not have been simulated. While an in vivo study may be statistically weaker due to limited data and greater variability, results from such a study that behave in a manner consistent with and comparable to simulations make a strong argument for the validity of the method tested.</p><p>In this paper we describe the design, construction, and application of a high-resolution, volumetric, anthropomorphic, digital brain phantom that can be used to simulate medical image data. For example, realistic PET images can be generated using a simulator that accounts for acquisition geometry, attenuation, scatter, randoms, and Poisson noise <ref type="bibr" target="#b12">[13]</ref> as shown in Section III-A2. Similarly, MR images can be simulated from physical principals by solving the Bloch equations <ref type="bibr" target="#b13">[14]</ref> as described in Section III-A1. The important advantage of using this phantom are that the "answer" is known a priori, and the phantom can be used to compute an objective measure of performance for a given image processing algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Design</head><p>Our goal was to create a simple digital representation of the human brain suitable for tomographic image simulation. The model needed to have high resolution (e.g., high enough to simulate 1mm MRI data sets) and must contain properly model PVE's<ref type="foot" target="#foot_0">1</ref> so that classification algorithms can be tested. Furthermore, the model must be anatomically accurate and as realistic as possible to have greater value than more simplyshaped phantoms. Most importantly, in order to be realistic, the model should be completely 3-D.</p><p>A voxel representation was selected since smooth transitions can be more easily modeled than, for instance, polyhedral models. Other reasons include: the availability of 1) a highresolution low-noise data set <ref type="bibr" target="#b14">[15]</ref> that could be used as an anatomical guide; 2) automatic classification procedures to correctly label the majority of voxels; and 3) 3-D visualization/editing tools to facilitate manual correction during the voxel-labeling phase, i.e., attachment of an identifying tissue type to each image voxel. The following sections describe phantom construction in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Construction</head><p>Phantom construction was based on a high-resolution (1-mm isotropic voxels) low-noise data set that was created by registering 27 scans (T1-weighted gradient-echo acquisitions with TR/TE/FA 18 ms/10 ms/30 ) of the same individual in stereotaxic space where they were subsampled and intensity averaged<ref type="foot" target="#foot_1">2</ref>  <ref type="bibr" target="#b14">[15]</ref>. The volume contains 181 217 181 voxels and covers the brain completely, extending from the top of the scalp to the base of foramen magnum (see Fig. <ref type="figure" target="#fig_0">1</ref>). As a direct result of the high signal-to-noise ratio (SNR), this single subject average dataset, dubbed CJH27, exhibits fine anatomical details such as the claustrum, subthalamic nuclei, gray matter bridges between the caudate and putamen, and vessels passing through the lentiform nucleus; details normally obscured by noise in single images. The 3-D, highresolution, anatomically accurate human brain phantom was created by manually correcting an automatically classified and preprocessed version of the MRI volume. The following sections describe the process in more detail.</p><p>1) Preprocessing: Intensity nonuniformity in MR images is one of the main causes of error when using classification algorithms to automatically identify different tissue types since the intensity variations blur the true intensity distributions of individual tissue classes. This type of artefact was reduced by applying a 3-D nonuniformity reduction procedure based on the deconvolution of the nonuniformity blurring kernel from the intensity histogram of the image <ref type="bibr" target="#b17">[18]</ref>.</p><p>2) Classification: The goal of the classification step was to correctly label as many brain voxels as possible to minimize later manual intervention. A total of 4 000 training points were selected by a trained neuroanatomist (N. J. Kabani) for the following classes: 1) grey-matter (GM c ); 2) whitematter (WM c ); 3) cerebrospinal fluid (CSF c ); 4) fat (FAT c ); and 5) background (BKG c ). (The " " differentiates volumes output from the classifier from those finally used to build the phantom after manual correction.) These training points were used to drive four different automatic classification procedures <ref type="bibr" target="#b18">[19]</ref>: minimum-distance, nearest K-mean, fuzzy C-mean <ref type="bibr" target="#b19">[20]</ref>, and artificial neural network (ANN) <ref type="bibr" target="#b20">[21]</ref>. The minimum distance (also known as nearest mean) and ANN classifications were selected by the neuroanatomist as the best in that they yielded the best representation for basal ganglia, cortical grey matter, and white matter within the cerebellum, and they required the least number of corrections. Since these two classifiers gave essentially equivalent results due to the high SNR of the images which resulted in good class separability, we chose to base the creation of the phantom on the result of the simpler minimum-distance classifier.</p><p>Classification of CJH27 yielded the spatial distribution of different tissue types necessary to realistically represent the human brain. However, a discrete classification, with only one tissue label per voxel, did not allow PVE's to be modeled. In order to account for tissue mixing, it was necessary to compute and represent fractional amounts for each tissue type within each voxel. The latter was accomplished by using a volume with -dimensional vector-valued voxels, where was the number of tissue types represented in the phantom. The th component of a voxel represents the fraction of th tissue type within the voxel with the constraint and that was normalized, i.e., Practically, the phantom was represented by ten volumes, each one representing the amount of tissue (e.g., grey matter, white matter, CSF, muscle, etc.) found at each voxel location.</p><p>We changed the standard minimum-distance classifier to have a continuous output. Our "fuzzy" minimum-distance classifier yields tissue fractions for each voxel based on the distances computed by the classifier instead of giving only the standard discrete label output. If the voxel's intensity was equal to any class mean , then the th tissue fraction was set to 1.0 and all other tissue fractions were set to 0.0 Otherwise, for each class was estimated to be inversely proportional to the distance between the voxel's intensity and the class mean:</p><p>(1)</p><p>Second, these values were normalized and stored in the vector :</p><p>(</p><formula xml:id="formula_0">)<label>2</label></formula><p>This implied that all classes had some nonzero representation within each voxel. User intervention and a priori anatomical knowledge were used to zero tissue probabilities for voxels where certain tissues are known not to exist and to reassign incorrectly labeled voxels. Fig. <ref type="figure" target="#fig_1">2</ref> shows the continuous output of the fuzzy minimum-distance classifier before any corrections were made.</p><p>3) Manual Correction: The five volumes (GM c , WM c , CSF c , FAT c , and BKG c ) generated by the classifier (see Fig. air outside head and within sinuses ten volumes that define the brain phantom are shown in Fig. <ref type="figure" target="#fig_2">3</ref>. Table <ref type="table">I</ref> summarizes the correction steps that are described in detail below.</p><p>As it was necessary to separate brain from nonbrain structures, the first step in the correction phase was the creation of a discrete brain mask ( ) by manual voxel painting using software developed in house<ref type="foot" target="#foot_2">3</ref> that permits tri-plane (coronal, sagittal, and transverse) roaming through the volume with arbitrary pan and zoom. The brain mask, which only identified brain parenchyma and omitted all nonventricular CSF spaces, was dilated and further edited by hand to create a second mask containing all structures (e.g., brain parenchyma, arteries, dura, sub-dural CSF, and CSF-filled cisterns) within the skull cavity. The complement of each volume, and respectively, were also created to identify nonbrain structures.</p><p>The brain masks were used to separate each of the five volumes into brain and nonbrain volumes. In each of following steps, where masking and manual corrections were interleaved, the total proportion of each tissue class in each voxel was kept constant; those removed from one tissue class were reattributed to other volumes so that the sum of all tissue fractions at each voxel was normalized to 1.0.</p><p>The WM c voxels within the brain mask became the final WM phantom volume after manual editing [Fig. <ref type="figure" target="#fig_2">3(b)]</ref>, those outside the dilated brain mask form the other (OTH) class. The remaining WM c voxels (WM c WM OTH) were due to PVE's between grey matter tissue and CSF. Since these voxels had a maximum value of less than 0.07 (where pure tissue is 1.0), they were ignored and zeroed instead of reattributing them to the GM or CSF volumes.</p><p>The GM c voxels within the brain became the final GM class after manual editing [Fig. <ref type="figure" target="#fig_2">3(a)</ref>]. The remaining GM c voxels fell into two groups: 1) those within the brain that were manually removed were from the inner surface of the ventricles and were used to form the glial (GL) class; and 2) those outside the brain became muscle and skin (M S).</p><p>The FAT volume was created by editing FAT c , using semiautomated region growing and manual painting. The remaining voxels were zeroed. Similar tools were used to produce the skull (SKL) volume by editing BKG c to identify all voxels within the skull. All BKG c voxels within the brain mask were zeroed. The remaining voxels formed the air (AIR) class.</p><p>After manual editing, voxels from the CSF c within formed the final CSF volume containing both ventricular and subarachnoid CSF [Fig. <ref type="figure" target="#fig_2">3(c)</ref>]. The CSF c voxels left over within the brain mask were ignored (zeroed) since they were caused by partial-volume regions where grey and white matter tissue occupy the same voxel as well as partial-volume regions around the ventricles. (These voxels had maximum CSF c values of 0.02 and 0.03, respectively.) Those that were left over outside the brain mask were either manually added to the SKL volume or formed the skin (SKN) volume, depending on their proximity to these structures.</p><p>Since some voxels from the WM c CSF c , FAT c and BKG c were zeroed, the integral of all tissue components was not equal to 1.0 for all voxels within the phantom. These voxels were simply normalized on a voxel by voxel basis, by dividing their respective tissue components by their sum.</p><p>These ten "fuzzy" volumes, one for each class, define the digital phantom. Three of those that define the brain are shown in Fig. <ref type="figure" target="#fig_2">3</ref>. A discrete version of the phantom was also created by storing the label of the most probable class at each voxel location and is shown in Fig. <ref type="figure" target="#fig_2">3(d)</ref>. A total of 20-30 manhours were required for all manual intervention required to build the phantom. It is important to note that while there may remain residual errors in the classification of some voxels of the phantom even after the manual correction process, these do not dilute the purity of the phantom for validation studies. By definition, "truth" in the tissue labeling for any voxel is what is stored in the reference volumes. To illustrate, a perfect MRI tissue segmentation algorithm should be able to take a simulated MRI image based on the reference volumes and recover the class occupancy of every voxel in the reference volumes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. APPLICATIONS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Image Simulation 1) MR Simulator:</head><p>The MR simulator (MRISIM) <ref type="bibr" target="#b13">[14]</ref> predicts image contrast by computing nuclear magnetic resonance (NMR) signal intensities from a discrete-event simulation of pulse sequences based on the Bloch equations. In order to simulate realistic MRI images of the human brain using MRISIM, the phantom was used to map tissue intensities into images. The simulator accounts for the effects of various image acquisition parameters by incorporating partial-volume averaging, noise, and intensity nonuniformity [see Fig. <ref type="figure" target="#fig_3">4(a)</ref>].</p><p>2) PET Simulator: The simulation of PET images with PETSIMU <ref type="bibr" target="#b12">[13]</ref> requires attenuation and emission coefficients to be associated with each tissue class of the phantom. PET-SIMU produces images by generating line integrals through the phantom using the specific acquisition geometry and 3-D detector response function of a multislice tomographic imaging system. Physical effects such as attenuation, scatter, randoms, detector efficiency, and Poisson noise are also incorporated to generate realistic data [see Fig. <ref type="figure" target="#fig_3">4(b)</ref>]. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Example Uses 1) Registration Validation:</head><p>Since the same phantom is used to drive each of the simulators described above, it becomes an ideal tool to test same subject, intermodality registration. One begins by applying a rigid-body transformation to the phantom before image simulation. Each modality is then simulated using the full battery of options (noise, contrast, slice thickness, etc.) available from the simulators. Afterwards, the registration procedure is applied. Since the rigid-body transformation is known a priori, it can be used as a gold standard to test the output of the registration algorithm.</p><p>2) Classification Validation: Classification algorithms can be evaluated in a similar manner. For example, the phantom can be transformed before simulation to test the effect of slice thickness and orientation on the estimated volume of a particular tissue class or structure. The behavior of the classification algorithm can be evaluated with respect to all parameters available within the simulator. This evaluation method has been used to compare different classification algorithms by running them with the same set of simulated input MRI data sets and comparing their output against the phantom reference volumes <ref type="bibr" target="#b21">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. DISCUSSION AND CONCLUSION</head><p>The primary benefit of using digital phantoms and simulated images is that many aspects of the imaging process can be controlled, so that the behavior of an algorithm can be carefully evaluated while yielding the important advantage that the desired answer is known a priori in the validation experiment. Furthermore, unlike physical phantoms, modifications such as identifying particular structures, adding pathologies, and highlighting activations areas are easily performed.</p><p>The digital brain phantom described in this paper is based on a high-resolution, high-SNR MRI volume of a normal volunteer. In addition to the advantage of being anatomically realistic, it models PVE's between tissues, thus, avoiding significant errors associated with the use of a discrete model. The processes used to create the average MRI and the digital brain phantom are simple and can be repeated in other labs using publicly available software for registration and classification.</p><p>This phantom may serve as a gold standard to measure the performance of image processing algorithms, and has been used to generate realistic MR [Fig. <ref type="figure" target="#fig_3">4</ref>(a)], PET [Fig. <ref type="figure" target="#fig_3">4(b)</ref>] and CT (not shown) images that are suitable for validation studies. The availability of a standard digital brain phantom and the associated simulated images will make it possible to evaluate the quality or functionality of procedures developed in different laboratories, judge their applicability for a given purpose, and compare them to other existing methods.</p><p>The work presented here is the first phase in the creation of a complete digital brain model useful for validation. The next phase will be to incorporate blood vessels, increase the resolution of the phantom, and further subdivide the anatomical model. We also plan to model the intensity variations that correspond to fine tracts in the white matter (e.g., occipital tracts). Since our initial design was motivated by the requirements for comparison of classification algorithms, the phantom contains only tissue type information. For use in electroencephalogram simulations, we plan to introduce electrical properties. Moreover, we are currently sub-dividing the greymatter tissue type into specific functional regions so that the phantom can be used in brain-mapping experiments <ref type="bibr" target="#b22">[23]</ref>.</p><p>The phantom data described here is available from the Montréal Neurological Institute (MNI), McGill University, McConnell Brain Imaging Centre web site 4 along with a database of simulated MR images <ref type="bibr" target="#b23">[24]</ref> so that any newly developed algorithms can be evaluated with the same data, thus providing a tool for comparison between methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Input MRI volume. Coronal, sagittal, and transverse slices through CJH27, the (n = 27) average MRI volume used to build the phantom.</figDesc><graphic coords="2,114.00,54.98,373.00,124.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Output of fuzzy minimum-distance classifier. Transverse and coronal slices through the four of the five volumes output by the fuzzy classifier where image intensity is proportional to class membership. (a) GM c , (b) WM c , (c) CSF c , and (d) FAT c (BKG c not shown). Note that GM c , WM c , and CSF c volumes contain muscle and scalp. These voxels were manually relabeled to give the final results of Fig. 3.</figDesc><graphic coords="3,102.06,55.00,396.00,206.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Digital Brain Phantom. Transverse and coronal slices through the (a) GM, (b) WM, and (c) CSF tissue volumes of the digital brain phantom. (d) The discrete phantom is shown. Note that the discrete phantom is never used for image simulation. It is included here only to visualize the spatial relationships between the different tissue phantoms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Simulated images. Transverse slices through (a) a simulated MRI image (3-D T1-weighted gradient echo acquisition, TR/TE/FA = 18 ms/10 ms/30 ) based on the ten volume phantom and (b) a simulated blood flow PET image. To judge the quality of the phantom and the MR simulation, compare Fig. 4(a) with Fig. 1(c).</figDesc><graphic coords="5,313.92,59.57,236.00,146.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="4,102.06,55.00,396.00,206.18" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Partial volume effects (PVE's) occur when more than one tissue type occupies a single voxel element, e.g., at tissue boundaries.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Stereotaxic space is a brain-based coordinate space which allows any point in a brain volume to be referenced by three Cartesian coordinates. It is used widely for intrasubject and intersubject image alignment, comparison and quantitative analysis<ref type="bibr" target="#b15">[16]</ref>,<ref type="bibr" target="#b16">[17]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Documentation at http://www.bic.mni.mcgill.ca/system/mni/Display/ Display.html</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A quantitative comparison of residual error for three different multimodality registration techniques</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hemler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Van Den Elsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sumanaweera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Napel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Drace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Adler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Processing in Medical Imaging</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Bizais</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Barillot</surname></persName>
		</editor>
		<meeting><address><addrLine>Berder, France</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="251" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cerebral magnetic resonance image segmentation using data fusion</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Rajapakse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Decarli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mclaughlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Giedd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Krain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Hamburger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Rapoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Assist. Tomogr</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="206" to="218" />
			<date type="published" when="1996-04">Mar./Apr. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">3-D phantom to simulate cerebral blood flow and metabolic images for PET</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cutler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Digby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mazziotta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Nucl. Sci</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="616" to="620" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Assessment of accuracy of PET utilizing a 3-D phantom to simulate the activity distribution of FDG uptake in the human brain</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cutler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Guerrero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Digby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mazziotta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cereb. Blood Flow Metab</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Stimulating technetium-99 m cerebral perfusion studies with a three-dimensional Hoffmann</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Karp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Mozley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">O</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">F</forename><surname>Kung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alavi</surname></persName>
		</author>
		<ptr target="http://www.bic.mni.mcgill.ca/brainweb" />
	</analytic>
	<monogr>
		<title level="j">Ann. Nucl. Med</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="153" to="160" />
			<date type="published" when="1996-02">Feb. 1996</date>
		</imprint>
	</monogr>
	<note>Collimator and filter selection in SPECT neuroimaging</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automated interstudy image registration technique for SPECT and pet</title>
		<author>
			<persName><forename type="first">S</forename><surname>Eberl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kanno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Fulton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">F</forename><surname>Hutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Fulham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Nucl. Med</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="137" to="145" />
			<date type="published" when="1996-01">Jan. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A filtered backprojection algorithm for axial head motion correction in fan-beam SPECT</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Jaszczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Coleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phy. Med., Biol</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="2053" to="2063" />
			<date type="published" when="1995-12">Dec. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A realistic computer-simulated brain phantom for evaluation of PET characteristics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mahoney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mazziotta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Carson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Phelps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="250" to="257" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">3-D SPECT simulations of a complex 3-D mathematical brain model and measurements of the 3-D physical brain phantom</title>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zeeberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fahey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Reba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Nucl. Med</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1923" to="1930" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Evaluation of partial volume effect in quantitative measurement of regional cerebral blood flow using positron emission tomography</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Narita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Ardekani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hatazawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kanno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Uemura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Nucl. Med</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="163" to="172" />
			<date type="published" when="1995-02">Feb. 1995</date>
		</imprint>
	</monogr>
	<note>Kaku Igaku-Jpn</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Evaluation of partial volume effect in quantitative measurement of regional cerebral blood flow in single photon emission computed tomography-effects of limited spatial resolution and firstpass extraction fraction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Narita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Ardekani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hatazawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nakazawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kanno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Uemura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Kaku Igaku-Jpn. J. Nucl. Med</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="155" to="162" />
			<date type="published" when="1995-02">Feb. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automatic 3-D modelbased neuroanatomical segmentation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Brain Mapping</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="190" to="208" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">3-D simulation of PET brain images using segmented MRI data and positron tomograph characteristics</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kamber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computerized Med. Imag., Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="365" to="371" />
			<date type="published" when="1993-10">July/Oct. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An extensible MRI simulator for post-processing evaluation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Pike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th Int. Conf. Visualization in Biomedical Computing, VBC &apos;96</title>
		<meeting>4th Int. Conf. Visualization in Biomedical Computing, VBC &apos;96<address><addrLine>Hamburg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-09">Sept. 1996</date>
			<biblScope unit="page" from="135" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Enhancement of MR images using registration for signal averaging</title>
		<author>
			<persName><forename type="first">C</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hoge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Woods</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Toga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Assist. Tomogr</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="324" to="333" />
			<date type="published" when="1998-03">Mar. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Co-Planar Stereotactic Atlas of the Human Brain: 3-Dimensional Proportional System: An Approach to Cerebral Imaging</title>
		<author>
			<persName><forename type="first">J</forename><surname>Talairach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tournoux</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Georg Thieme Verlag</publisher>
			<pubPlace>Stuttgart, New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Automatic 3-D inter-subject registration of MR volumetric data in standardized Talairach space</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Neelin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Assist. Tomogr</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="192" to="205" />
			<date type="published" when="1994-04">Mar./Apr. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A nonparametric method for automatic correction of intensity nonuniformity in MRI data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Sled</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Zijdenbos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="1998-02">Feb. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hart</surname></persName>
		</author>
		<title level="m">Pattern Recognition And Scene Analysis</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Bezdek</surname></persName>
		</author>
		<title level="m">Pattern Recognition with Fuzzy Objective Function Algorithms</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Plenum</publisher>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Introduction to Artificial Neural Systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Zurada</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>West</publisher>
			<pubPlace>St. Paul, MN</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Performance analysis of automatic techniques for tissue classification in MRI of the human brain</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kollokian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996-11">Nov. 1996</date>
			<pubPlace>Montreal, P.Q., Canada</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Concordia Univ.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">MS thesis</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">fMRI simulation for quantitative evaluation of analysis methods</title>
		<author>
			<persName><forename type="first">R.-S</forename><surname>Kwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="1997-05">May 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Brainweb: Online interface to a 3-D MRI simulated brain database</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cocosco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kollokian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R.-S</forename><surname>Kwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="1997-05">May 1997</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
