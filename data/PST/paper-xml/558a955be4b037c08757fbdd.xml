<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Nonlinear Operator for Oriented Texture</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Peter</forename><surname>Kruizinga</surname></persName>
							<email>peterkr@cs.rug.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Mathematics and Computing Science</orgName>
								<orgName type="institution">University of Groningen</orgName>
								<address>
									<postCode>9700 AV</postCode>
									<settlement>Groningen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nikolay</forename><surname>Petkov</surname></persName>
							<email>petkov@cs.rug.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Mathematics and Computing Science</orgName>
								<orgName type="institution">University of Groningen</orgName>
								<address>
									<postCode>9700 AV</postCode>
									<settlement>Groningen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Nonlinear Operator for Oriented Texture</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DE6BE3B9A16F2F3EFAD210EE183DC164</idno>
					<note type="submission">received March 16, 1998; revised February 23, 1999.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Grating cells</term>
					<term>texture analysis</term>
					<term>texture features</term>
					<term>visual cortex</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Texture is an important part of the visual world of animals and humans and their visual systems successfully detect, discriminate, and segment texture. Relatively recently progress was made concerning structures in the brain that are presumably responsible for texture processing. Neurophysiologists reported on the discovery of a new type of orientation selective neuron in areas V1 and V2 of the visual cortex of monkeys which they called grating cells. Such cells respond vigorously to a grating of bars of appropriate orientation, position and periodicity. In contrast to other orientation selective cells, grating cells respond very weakly or not at all to single bars which do not make part of a grating. Elsewhere we proposed a nonlinear model of this type of cell and demonstrated the advantages of grating cells with respect to the separation of texture and form information. In this paper, we use grating cell operators to obtain features and compare these operators in texture analysis tasks with commonly used feature extracting operators such as Gabor-energy and co-occurrence matrix operators. For a quantitative comparison of the discrimination properties of the concerned operators a new method is proposed which is based on the Fisher linear discriminant and the Fisher criterion. The operators are also qualitatively compared with respect to their ability to separate texture from form information and their suitability for texture segmentation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr" target="#b5">[6]</ref><p>, and Mitchell <ref type="bibr" target="#b6">[7]</ref>, the fractal dimension approach <ref type="bibr" target="#b7">[8]</ref>, and a method based on general operator processor (GOP) operations <ref type="bibr" target="#b8">[9]</ref>. They used the boundary error in the segmentation result as a comparison measure. In <ref type="bibr" target="#b9">[10]</ref> Ohanian and Dubes discussed four types of texture features, by comparing the error rates in the segmentation result. They considered co-occurrence matrix features, Gabor features <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, Markov random field features <ref type="bibr" target="#b12">[13]</ref>, and fractal features. Other recent studies in which the classification result comparison method was used include <ref type="bibr" target="#b13">[14]</ref>- <ref type="bibr" target="#b15">[16]</ref>. The segmentation algorithms that were applied in these studies classify individual pixels using their associated feature vectors. In a recent study, Ojala et al. <ref type="bibr" target="#b16">[17]</ref> used a different segmentation algorithm that performs the pixel classification on the basis of the distribution of the feature vectors in the surrounding of the concerned pixel. They compared the following four texture features: gray level differences, Laws texture features, center-symmetric covariance features, and local binary patterns. A comparison between four segmentation algorithms was made by Wang et al. <ref type="bibr" target="#b17">[18]</ref> using co-occurrence matrix features. A more theoretical study was carried out by Conners and Harlow <ref type="bibr" target="#b0">[1]</ref>. They made a comparison of the texture features that were used by Weszka et al. <ref type="bibr" target="#b1">[2]</ref> and used the amount of texture-context information that is contained in the intermediate matrices as a quality measure of the texture features.</p><p>In this paper, we assess the properties of a new type of texture operator and compare it with existing texture operators. This new operator has been inspired by the function of a recently discovered type of an orientation-selective neuron in areas V1 and V2 of the visual cortex of monkeys, called the grating cell <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>. About 4% of the cells in V1 and 1.6% of the cells in V2 can be characterized as grating cells and it is estimated that about 4 million grating cells in V1 subserve the central 4 of vision <ref type="bibr" target="#b19">[20]</ref>. Similarly to other orientation selective neurons, such as simple, complex, and hyper-complex cells <ref type="bibr" target="#b20">[21]</ref>- <ref type="bibr" target="#b22">[23]</ref>, grating cells respond vigorously to a grating of bars of appropriate orientation, position, and periodicity. In contrast to other orientation selective cells, grating cells respond very weakly or do not respond at all to single bars, this means, bars which are isolated and do not make part of a grating. This behavior of grating cells cannot be explained by linear filtering followed by half-wave rectification as in the case of simple cells <ref type="bibr" target="#b23">[24]</ref>- <ref type="bibr" target="#b27">[28]</ref>, neither can it be explained by three-stage models of the type used for complex cells <ref type="bibr" target="#b28">[29]</ref>- <ref type="bibr" target="#b32">[33]</ref>. Most grating cells start to respond when a grating of a few bars (2-5) is presented. In most cases the response rises linearly with the number of bars in the grating up to a given number <ref type="bibr" target="#b3">(4)</ref><ref type="bibr" target="#b4">(5)</ref><ref type="bibr" target="#b5">(6)</ref><ref type="bibr" target="#b6">(7)</ref><ref type="bibr" target="#b7">(8)</ref><ref type="bibr" target="#b8">(9)</ref><ref type="bibr" target="#b9">(10)</ref><ref type="bibr" target="#b10">(11)</ref><ref type="bibr" target="#b11">(12)</ref><ref type="bibr" target="#b12">(13)</ref><ref type="bibr" target="#b13">(14)</ref> after which it quickly saturates and the addition of new bars to the grating causes the response to rise only slightly or not to rise at all and in some cases even to decline. Similarly, the response rises with the length of the bars up to a given length after which saturation and in some cases inhibition is observed. The responses to moving gratings are unmodulated and do not depend on the direction of movement. The dependence of the response on contrast shows a switching characteristic, in that turn-on and saturation contrast values lie pretty close: the most sensitive grating cells start to respond at a contrast of 1% and level off at 3%. In general, grating cells are more selective than simple cells, having half-response spatial frequency bandwidths in the range of 0.4 to 1.4 octaves, with median 1 octave, and half-response orientation bandwidths of about 20 . For comparison, simple cell spatial frequency bandwidths at half response vary in the range 0.4 to 2.6 octaves with median 1.4 octave; their median orientation bandwidth is about 40 <ref type="bibr" target="#b33">[34]</ref>.</p><p>The above properties suggest that the primary role of grating cells is to detect periodicity in oriented patterns. In previous work, we proposed a computational model of grating cells, which explains the results of the neurophysiological experiments <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>. In this paper we focus on the properties of the grating cell operator as a texture analysis operator. It is compared with other, commonly used texture operators. For a quantitative comparison, however, we do not use the classification result comparison method that is used in most previous studies because this method characterizes the joint performance of a feature operator and a subsequent classifier. We rather propose a new method which characterizes the feature operator only. This method is based on a statistical approach to evaluate the capability of a feature operator to discriminate two textures by quantifying the distance between the corresponding clusters of points in the feature space according to Fisher's criterion <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>.</p><p>The paper is organized as follows: in Section II we review the Gabor filter; the output of the Gabor filter is used as input to the grating cell operator. Gabor-energy features that are closely related to Gabor filters are introduced. The computational model of grating cells is given in Section III. In Section IV, the co-occurrence matrix features are described. The texture analysis properties of the grating cell operator, the Gaborenergy operator, and a co-occurrence matrix based operator are examined and compared in Section V in a series of computational experiments. In Section VI we summarize the results of the study and draw conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. GABOR FILTERS</head><p>Gabor filters are closely related to the function of simple cells in the primary visual cortex of primates <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>. Since simple cells play a substantial role in the following, we first briefly introduce a computational model of this type of cell. The response of a simple cell which is characterized by a receptive field function to a luminance distribution image , , is computed as follows ( denotes the visual field domain):</p><p>(1) where for , for . Later on below we extend this simple model with local contrast normalization.</p><p>We use the following family of two-dimensional (2-D) Gabor functions <ref type="bibr" target="#b40">[41]</ref> to model the spatial summation properties of simple cells: 1   (2)</p><p>where the arguments and specify the position of a light impulse in the visual field and , , , , , , and are parameters as follows.</p><p>The pair , which has the same domain as the pair , specifies the center of a receptive field in image coordinates. The standard deviation of the Gaussian factor determines the (linear) size of the receptive field. Its eccentricity and herewith the eccentricity of the receptive field ellipse is determined by the parameter , called the spatial aspect ratio. It has been found to vary in a limited range of <ref type="bibr" target="#b42">[43]</ref>. The value is used in our simulations and, since this value is constant, the parameter is not used to index a receptive field function.</p><p>The parameter , which is the wavelength of the cosine factor , determines the preferred spatialfrequency of the receptive field function . The ratio determines the spatial frequency bandwidth 2 of a linear filter based on the function .</p><p>De Valois et al. <ref type="bibr" target="#b33">[34]</ref> propose that the input to higher processing stages is provided by the more narrowly tuned simple cells with half-response spatial frequency bandwidth of approximately one octave. This value of the half-response spatial frequency bandwidth corresponds to the value 0.56 of the ratio , which is used in the simulations of this study. Since and are not independent ( ), only one of them is considered as a free parameter which is used to index a receptive field function. For ease of reference to the spatial frequency properties of the cells, we choose to be this free parameter.</p><p>The parameter specifies the orientation of the normal to the parallel excitatory and inhibitory stripe zones-this normal is the axis in (2)-which can be observed in the receptive fields of simple cells, Fig. <ref type="figure" target="#fig_1">1(a)</ref>. The value of the spatial aspect ratio and the spatial-frequency bandwidth determine the orientation bandwidth of a linear filter based on the function . For and octave (</p><p>) the half-response orientation bandwidth of a linear filter based on is approximately 19 . 1 Our modification of the parametrization used in <ref type="bibr" target="#b40">[41]</ref> takes into account the restrictions found in experimental data, see <ref type="bibr" target="#b41">[42]</ref> for further details.  Finally, the parameter , which is a phase offset in the argument of the harmonic factor , determines the symmetry of the function : for and it is symmetric with respect to the center ( ) of the receptive field; for and , the function is antisymmetric and all other cases are asymmetric mixtures of these two. In our simulations, we use for the following values: for symmetric receptive fields to which we refer as "center-on," for symmetric receptive fields to which we refer to as "center-off," and and for antisymmetric receptive fields with opposite polarities.</p><p>An intensity map of a receptive field function with a particular position, size, orientation, and symmetry is shown in Fig. <ref type="figure" target="#fig_1">1</ref> Using the above parametrization, one can compute the response of a simple cell modeled by a receptive field function to an input image with gray level distribution as follows. First, an integral <ref type="bibr" target="#b2">(3)</ref> is evaluated in the same way as if the receptive field function were the impulse response of a linear system. In order to normalize the simple cell response with respect to the local average luminance of the input image, is divided by the average gray level within the receptive field which is computed using the Gaussian factor of the function :</p><p>(4)</p><p>The ratio is proportional to the local contrast within the receptive field of a cell modeled by the function . In order to obtain a contrast response function similar to the ones measured on real neural cells, we use the hyperbolic ratio function to calculate the simple cell response from the ratio as follows:</p><formula xml:id="formula_0">if otherwise (<label>5</label></formula><formula xml:id="formula_1">)</formula><p>where and are the maximum response level and the semisaturation constant, respectively. For further details of this model of simple cells we refer to <ref type="bibr" target="#b35">[36]</ref>.</p><p>Gabor-Energy Features: A popular set of texture features is based on the use of Gabor-filters (3) <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b44">[45]</ref> according to a multichannel filtering scheme. For this purpose, an image is filtered with a set of Gabor-filters with different preferred orientations, spatial frequencies, and phases. The filter results of the phase pairs are combined, yielding the so-called Gabor-energy quantity <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b46">[47]</ref>: <ref type="bibr" target="#b5">(6)</ref> where and are the outputs of the symmetric and antisymmetric filters. The Gabor-energy quantity is related to a model of complex cells which combines the responses of a quadrature phase pair of simple cells.</p><p>In the experiments described in Section V, we use Gaborenergy filters with eight equidistant preferred orientations ( , , , ) and three preferred spatial frequencies ( , , and ; image size 256 pixels), resulting in 24-dimensional (24-D) feature vectors. The choice of three preferred spatial-frequencies and eight preferred orientations is aimed at an appropriate coverage of the spatial-frequency domain (Fig. <ref type="figure" target="#fig_3">2</ref>). If one takes a smaller number of orientations, e.g., six instead of eight, there will be orientations to which none of the channels of the filter bank will respond sufficiently and this will have a negative effect on the discrimination performance for textures that are dominated by the concerned orientations. This means that the discrimination performance will depend on the choice of oriented texture. Similar arguments apply to the spatialfrequency discrimination. Fig. <ref type="figure" target="#fig_4">3</ref> illustrates the application of the filterbank on an input image which contains texture. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. GRATING CELLS-A COMPUTATIONAL MODEL</head><p>Our model of grating cells consists of two stages <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>. In the first stage, the responses of so-called grating subunits are computed using as input the responses of center-on and center-off simple cells with symmetrical receptive fields. The model of a grating subunit is conceived in such a way that the unit is activated by a set of three bars with appropriate periodicity, orientation and position. In the next, second stage, the responses of grating subunits of a given preferred orientation and periodicity within a certain area are added together to compute the response of a grating cell. This model is next explained in more detail:</p><p>A quantity , called the activity of a grating subunit with position , preferred orientation and preferred grating periodicity , is computed as follows:</p><formula xml:id="formula_2">if if (<label>7</label></formula><formula xml:id="formula_3">)</formula><p>where and is a threshold parameter with a value smaller than but near one (e.g.,</p><p>) and the auxiliary quantities and are computed as follows:</p><formula xml:id="formula_4">(8)<label>(9)</label></formula><p>The quantities , , are related to the activities of simple cells with symmetric receptive fields along a line segment of length passing through point in orientation . This segment is divided in intervals of length and the maximum activity of one sort of simple cells, center-on or center-off, is determined in each interval.</p><p>, for instance, is the maximum activity of center-on simple cells in the corresponding interval of length ; is the maximum activity of center-off simple cells in the adjacent interval, etc. Center-on and center-off simple cell activities are alternately used in consecutive intervals.</p><p>is the maximum among the above interval maxima.</p><p>Roughly speaking, the concerned grating cell subunit will be activated if center-on and center-off cells of the same preferred orientation and spatial frequency are alternately activated in intervals of length along a line segment of length centered on point and passing in direction . This will, for instance, be the case if three parallel bars with spacing and orientation of the normal to them are encountered (Fig. <ref type="figure" target="#fig_5">4</ref>). In contrast, the condition is not fulfilled by the simple cell activity pattern caused by a single bar or two bars, only.</p><p>In the next, second stage of the model, the response of a grating cell whose receptive field is centered on point and which has a preferred orientation of the normal to the grating and periodicity The weighted summation is a provision made to model the spatial summation properties of grating cells with respect to the number of bars and their length as well as their unmodulated responses with respect to the exact position (phase) of a grating. The parameter determines the size of the area over which effective summation takes place. A value of results in a good approximation of the spatial summation properties of grating cells. For further details of the grating cell operator we refer to <ref type="bibr" target="#b35">[36]</ref>. The choice of the values of model parameters in <ref type="bibr" target="#b6">(7)</ref> and in <ref type="bibr" target="#b9">(10)</ref> results in grating cell operators with a spatial-frequency bandwidth of about one octave and an orientation bandwidth of slightly more than 20 , which are similar to the respective bandwidth values for the Gabor operators which provide input to the grating cell operators.</p><p>1) Grating Cell Features: The texture features proposed here, are based on the grating cell operator ( <ref type="formula" target="#formula_2">7</ref>)- <ref type="bibr" target="#b9">(10)</ref>. A set of grating cell operators with eight different preferred orientations and three preferred periodicities is applied to an image, yielding a 24-D feature vector in each image point. The same sets of values of ( , , , ) and ( , , and ) are used for the Gabor-energy and the grating cell operator filterbanks. Fig. <ref type="figure" target="#fig_6">5</ref> shows the results of the application of such a set of 24 grating cell operators to an input image (top-right). Note that the output is sparser than the output of the Gabor filterbank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CO-OCCURRENCE MATRIX FEATURES</head><p>A classic method for obtaining features useful for texture segmentation is based on the gray level co-occurrence matrices <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b48">[49]</ref>. This approach is briefly reviewed in the following. In each point of a texture image, a set of gray level cooccurrence matrices is calculated for different orientations and inter-pixel distances. From these matrices features are extracted which characterize the neighborhood of the concerned pixel. The gray level co-occurrence matrix is defined for a neighborhood of a pixel, as follows:</p><p>card card <ref type="bibr" target="#b10">(11)</ref> where is the gray level in point and and are gray levels. The elements of represent the frequencies of occurrence of different gray level combinations at a distance . A large variety of texture features have been proposed by several authors, which are all based on the gray level cooccurrence matrices. In this study we use the following three features that are most commonly used:</p><formula xml:id="formula_5">Energy (<label>12</label></formula><formula xml:id="formula_6">)</formula><p>Inertia ( <ref type="formula">13</ref>)</p><formula xml:id="formula_7">Entropy (<label>14</label></formula><formula xml:id="formula_8">)</formula><p>where is the number of gray levels. In our experiments we used eight vectors (four orientations and two lengths) resulting in eight gray level co-occurrence matrices in each point. The neighborhood around each point in which the co-occurrence matrices were calculated was set to <ref type="bibr" target="#b11">12</ref> 12. Since three types of features (energy, inertia, and entropy) were extracted from each matrix the procedure resulted in a 24-D feature vector in each image point. Fig. <ref type="figure" target="#fig_7">6</ref> illustrates the effect of the application of this filter bank on an input image (top-right) which contains texture. The bottom-right image is the maximum-value superposition of all channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. TEXTURE ANALYSIS PROPERTIES OF THE OPERATORS</head><p>An often used approach to measure the performance of texture operators is to apply a segmentation algorithm to the set of feature vectors obtained by a given operator and to evaluate the segmentation performance qualitatively, based on perception, or quantitatively, based on the number of misclassified pixels. The latter method is sometimes referred to as the classification result comparison <ref type="bibr" target="#b0">[1]</ref> and is commonly used for comparing different texture operators. In Section V-C below, we employ this qualitative method to compare the operators considered above. Before that, two further criteria are used to compare the performance of the operators.</p><p>First, the abilities of the operators to detect texture and to separate texture and form are compared, Section V-A. The general requirement for a good texture operator in this respect is that the feature vectors assigned to points, which make part of texture or in the surroundings of which there is texture, are substantially larger than the feature vectors assigned to points where there is no texture.</p><p>Second, the ability of the operators to discriminate different textures is assessed in Section V-B. The general requirements in this respect are as follows: the feature vectors assigned to the image points which lie in areas covered by the same texture should be similar (in the ideal case, they must be identical). In multivariate statistical terms, this means that these vectors form a cluster in the feature space: a contiguous region with, in comparison to the space outside the cluster, a relatively high density of feature vectors <ref type="bibr" target="#b49">[50]</ref>. At the same time, the feature vectors assigned to image points which belong to regions of different textures, should be different. Again in terms of clustering: the clusters of feature vectors derived from different textures should be distinct.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Detection of Texture and Separation of Texture and Form</head><p>We will first look at the ability of the considered operators: i) to detect texture and ii) to separate form and texture.</p><p>1) Method-Use of Norm Features: Since the components of the vector-valued operators presented above are not isotropic and also depend on a scale parameter, no single component can be used for texture of arbitrary preferred orientation or periodicity. Therefore, we use a new scalar feature that cumulatively reflects the properties of all components of a vector operator. We choose this cumulative feature to be the length of the feature vector. For ease of computation we take the norm according to which the length of a vector is equal to the absolute value of the largest (by absolute value) component: <ref type="bibr" target="#b14">(15)</ref> The bottom-right images in Figs. <ref type="figure" target="#fig_4">3,</ref><ref type="figure" target="#fig_6">5</ref>, and 6 are computed according to (15) as a maximum-value superposition of the feature images output by the different channels of the corresponding filterbanks.</p><p>2) Results: Fig. <ref type="figure" target="#fig_9">7</ref> shows an input image [Fig. <ref type="figure" target="#fig_9">7</ref> Fig. <ref type="figure" target="#fig_10">8</ref> illustrates the difference between Gabor-energy and co-occurrence matrix operators, on one hand, and grating cell operators, on the other hand, when these operators are applied to input images that contain contours but do not contain texture. In this case the co-occurrence matrix operator and the Gabor-energy operator will give misleading results, if used as texture detecting operators, because they respond not only to texture, but to other image features such as edges, lines, and contours, as well. In contrast, grating cell operators detect no features such as isolated lines and edges. In this way grating cell operators fulfill a very important requirement imposed on texture processing operators in that, next to successfully detecting (oriented) texture, they do not react to other image attributes such as object contours.</p><p>The difference between Gabor-energy and co-occurrence matrix operators, on one hand, and grating cell operators, on the other hand, is especially well illustrated when these operators are applied to images which contain both oriented texture and form information, as shown in Fig. <ref type="figure" target="#fig_11">9</ref>. While the Gabor-energy operator [Fig. <ref type="figure" target="#fig_11">9(b)</ref>] and the co-occurrence matrix operator [Fig. <ref type="figure" target="#fig_11">9(c)</ref>] detect both contours and texture and are, in this way, not capable of discriminating between these two different types of image features, grating cell operators detect exclusively (oriented) texture. We conclude that grating cell operators are more effective than Gabor-energy and co-occurrence matrix operators in the detection and processing of texture in that they are capable not only of detecting texture, but also of separating it from other image features, such as edges and contours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Texture Discrimination</head><p>The clustering in the multidimensional feature space of feature vectors that originate from the same texture and the discrimination of feature vectors resulting from different textures are closely related: the compactness of a cluster of feature vectors that belong to the same texture can only be expressed in relation to the distance to other clusters.</p><p>In the following, we review a method of expressing both the intercluster distance and the compactness of the clusters in one quantity. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Method-Fisher Linear Discriminant Function and Fisher Criterion:</head><p>In order to determine the mutual relation between two clusters and to measure their intercluster distance, it is sufficient to look at the projection of the -dimensional feature space ( is the number of features) onto a onedimensional (1-D) space, under the assumption that this projection is chosen in such a way that it maximizes the separability of the clusters in the 1-D space.</p><p>The linear transformation that realizes such a projection is called the linear discriminant function and was first introduced by Fisher <ref type="bibr">[</ref> , then the means of the clusters and the pooled covariance matrix are also changed: and . Therefore, , so that . Fig. <ref type="figure" target="#fig_12">10</ref> shows a sample histogram with two projected clusters with a Gaussian distribution. The separability of the two clusters is high, as can be seen from the large distance between their means and in comparison to the sum of the standard deviations and . The projection of the feature vectors onto the linear discriminant maximizes the so-called Fisher criterion (see, e.g., <ref type="bibr" target="#b36">[37]</ref> and <ref type="bibr" target="#b37">[38]</ref>): <ref type="bibr" target="#b16">(17)</ref> where and are the variances of the distributions of the projected feature vectors of the respective clusters and and are the projected means and of the clusters:</p><formula xml:id="formula_9">(18)<label>(19)</label></formula><p>The Fisher criterion expresses the distance between two clusters relative to their compactness in one single quantity. For this reason, the Fisher criterion is a good measure of the separability of two clusters. In contrast to the Euclidean distance metric, for example, it can be used to compare intercluster distances of clusters in different feature spaces, which enables us to qualitatively compare different texture operators. The projection of two clusters is illustrated by Fig. <ref type="figure" target="#fig_13">11</ref>. From all possible projection lines, the Fisher linear discriminant is the one on which the Fisher criterion is maximal. Although the distance between the means of the projected feature vector distributions is larger in case of projection on , the optimal discriminant is , since on that line the distance between the means of the distributions is largest relative to the sum of their variances.</p><p>2) Results: The discrimination properties of the texture operators considered in the previous sections are now compared using a set of nine test images, each containing a single type of oriented texture (Fig. <ref type="figure" target="#fig_14">12</ref>). For each pair of these textures, the separability is measured, using the Fisher criterion, in the following way: a 24-D vector operator of a given type is applied to the nine test textures. In this way a 24-D feature vector is assigned to each image point of the texture images. The pooled covariance matrix is calculated for each pair of textures using 1000 sample feature vectors taken from each  texture at random positions. Then the feature vectors are projected on a line using the Fisher linear discriminant function. In the projection space, the Fisher criterion is evaluated. Fig. <ref type="figure" target="#fig_15">13</ref> shows the distributions of the projected grating cell operator feature vectors of two test images (T4 and T5) along the discriminant. As can be seen from this figure, the distributions do not overlap, meaning that the clusters of feature vectors are linear separable in the feature space.</p><p>Table <ref type="table" target="#tab_0">I</ref> shows the values of the Fisher criterion for each pair of test texture images, based on the grating cell operator features. The minimum value listed is 5.44 (for the pair of textures T3 and T7), which means that for the corresponding image pair, the projected feature vector distributions will at most overlap for no more than 0.02%. For the other texture pairs the overlap is even (much) smaller. Therefore, all clusters of feature vectors can be separated linearly. Note that the  feature vectors of a cluster are taken from an image that contains merely one texture. This means that it is a priori known to which cluster the feature vector samples belong to, resulting in a good estimate of the covariance matrix.</p><p>The values of the Fisher criterion obtained with the grating cell operator for any pair of the used test images are so high that a linear separation of the clusters is always possible. Therefore the conclusion is justified the grating cell operator has excellent discrimination properties.</p><p>Table <ref type="table" target="#tab_1">II</ref> shows the values of the Fisher criterion for pairs of clusters of feature vectors, derived from the nine different textures, using the Gabor-energy texture features. The values listed in Table II are all smaller than the corresponding values obtained with the grating cell operator (Table <ref type="table" target="#tab_0">I</ref>). On average, the Fisher criterion for the Gabor-energy features is more than two times smaller than the one for the grating cell operator. However, the Fisher criterion is still sufficiently large so that the clusters are distinguishable. The Gabor-energy features are therefore also suitable for oriented texture discrimination. For the segmentation of a texture image into regions containing the same texture, i.e., for the classification of individual pixels, the intercluster distance is not sufficient.</p><p>The Fisher criterion was also calculated using the cooccurrence matrix features. The results are shown in Table <ref type="table" target="#tab_2">III</ref>. The average intercluster distance is even smaller than in the  case of the Gabor-energy features. On average it is three times smaller compared to the values obtained with the grating cell operator features. The intercluster distances are, however, still large enough to separate the clusters as a whole.</p><p>The conclusion which can be drawn from these experiments is that the grating cell operator shows the best discrimination properties, at least as far as oriented textures are concerned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Automatic Texture Segmentation</head><p>We carried out a number of texture segmentation experiments in which a general purpose clustering algorithm was applied to the feature vectors obtained with the operators discussed above.</p><p>1) Method-Segmentation Using the -Means Clustering Algorithm: The -means clustering algorithm <ref type="bibr" target="#b51">[52]</ref> was used for segmentation. It is based on the following cluster criterion: if <ref type="bibr" target="#b19">(20)</ref> where and are clusters, and are the respective mean feature vectors, and is the distance between two feature vectors and . In our experiments we used the Euclidean distance. The -means clustering procedure is as follows:</p><p>1) Initially, cluster mean vectors are chosen randomly. 2) Next, all feature vectors are assigned to one of the clusters using the above criterion. 3) Each cluster mean is updated by computing it as the mean of all feature vectors that were assigned to the concerned cluster. 4) Steps 2 and 3 are repeated until a certain convergence criterion is fulfilled. 2) Results: In order compare the texture segmentation performance of the grating cell operator with the two other texture operators, we applied the operators to three test images to obtain feature vector fields to which the -means segmentation algorithm was applied. The results are shown in Fig. <ref type="figure" target="#fig_16">14</ref>. The leftmost column shows the input images with two, five, and nine different textures, respectively. The perfect segmentations (ground truth) of these images are shown in the second column. The other three columns show the segmentation results based on the three vector operators considered above.</p><p>It is clear that the results obtained with the grating cell features are considerably better than the results obtained with the other two types of features. The only misclassified pixels are located near the texture borders. This is due to the fact that two or more different textures fall in the receptive field of the grating cell operator, causing an inaccurate estimate of the feature vector. Because of the large distance between the clusters of feature vectors, such inaccurate estimates do not immediately result in misclassification.</p><p>The segmentation based on the Gabor-energy operator features (Fig. <ref type="figure" target="#fig_16">14</ref>, second column from the right) is clearly worse than the one based on the grating cell operator. Even the segmentation of two textures is poor. When more different textures are added, segmentation performance decreases rapidly. Pixels are classified incorrectly not only at the texture border but also inside a texture region. The rightmost column of Fig. <ref type="figure" target="#fig_16">14</ref> shows the segmentation results obtained with the co-occurrence matrix operator. The same effect is observed as with the Gabor-energy operator. The segmentation of the image which contains just two texture images is correct, but for more than two textures, the segmentation results get worse very quickly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. SUMMARY AND CONCLUSIONS</head><p>In this paper, we compared two well-known texture operators, the co-occurrence matrix operator and the Gabor-energy operator, with a new biologically motivated nonlinear texture operator, the grating cell operator, which was proposed elsewhere by the authors.</p><p>First, we evaluated the ability of the operators to detect texture and to separate texture and form information. By applying the operators to an image that does not contain texture and an image that contains both texture and form, we showed that the co-occurrence matrix operator and the Gabor-energy operator fail to distinguish between form and texture information. The energy feature channels of the cooccurrence matrix operator respond to regions of uniform gray level and both the co-occurrence matrix operator and the Gabor-energy operator respond to contours and edges. In contrast, the grating cell operator responds to oriented texture only. Elsewhere, we proposed a complementary operator that responds only to contours and edges, but does not respond to texture <ref type="bibr" target="#b35">[36]</ref>.</p><p>Second, we studied the discrimination properties of the concerned texture operators using a new quantitative comparison method based on the Fisher criterion. We investigated whether the feature vectors extracted from a single texture form a cluster in the feature space and whether feature vector clusters that originate from different textures can be distinguished. The Fisher linear discriminant function was applied to project the feature vectors on a 1-D feature space (line). The distance between the projected cluster means, relative to the sum of the variances of the projected cluster distributions, which is called the Fisher criterion, was used as a measure of the separability of the feature vector clusters. This method was applied to measure the intercluster distances for each pair of nine images containing oriented texture. On average the relative distance between the feature vector clusters obtained with the grating cell operator was twice as large as the relative distance between the clusters obtained with the Gabor-energy operator and about three times as large as the distance between the clusters resulting from the co-occurrence matrix operator.</p><p>Third, a number of texture segmentation experiments was performed in which a general purpose clustering algorithm was employed to cluster the feature vectors within the feature vector fields resulting from the application of the three concerned texture operators. The standard -means algorithm was used to cluster the feature vectors which were extracted from an input image containing two or more different textures. The outcome of the experiments confirmed the superiority of the grating cell operator, especially when a larger number of textures was to be segmented.</p><p>A final remark is due on the purpose of this study. Our aim was not to propose just another texture operator and to demonstrate its advantages in comparison to (a limited number of) other texture operators when applied to certain image material. The main purpose was to present to the image processing and computer vision research community a texture operator that closely models the texture processing properties of the visual system of monkeys and, most probably, of humans. In this respect, the grating cell operator cannot be considered as just another texture operator. The comparison with other operators was not done in order to prove superiority (or inferiority). This comparison was done, rather, to satisfy our curiosity (and, hopefully, the curiosity of other researchers) about how an operator that is employed by natural vision systems performs in comparison to artificial operators that are devised by man. Neither was image material selected in order to prove a specific point. The image material was arbitrarily chosen with the only restrictions being that the concerned textures be oriented and look natural. The first restriction is justified by the proposed biological role of grating cells and by the insights in its function. The second one is due to the understanding that natural vision mechanisms are optimally fitted to a natural environment. In this context and under the mentioned restrictions, the results of the study can be considered satisfactory.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>2</head><label></label><figDesc>The half-response spatial frequency bandwidth b (in octaves) of a linear filter with an impulse response according to (2) is the following function of the ratio =:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Two-dimensional Gabor function in (a) space and (b) spatial frequency domain.</figDesc><graphic coords="3,66.96,59.60,203.24,95.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a).Fig. 1(b) shows the corresponding spatial frequency response.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Spatial-frequency domain coverage by the Gabor-energy filterbank used.</figDesc><graphic coords="3,359.04,59.58,145.20,145.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Gabor-energy operator channels. The input image is shown in the top-right position. The images arranged in an 8 2 3 matrix correspond to the outputs of the different channels of the filterbank. The rows correspond to different preferred orientations, and the columns to different preferred wavelengths. The image shown in the bottom-right position is computed as a pixel-wise maximum superposition (L 1 norm) of all channel outputs.</figDesc><graphic coords="4,48.48,59.56,240.22,556.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Luminance distribution along a normal to a set of (a) three square bars, and the distribution of the computed responses of (b) center-on and (c) center-off cells along this line.</figDesc><graphic coords="5,47.52,59.58,242.16,134.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Grating cell operator channels. The input image is shown in the top-right position. The images in the 8 2 3 matrix correspond to the outputs of the different channels of the filterbank. The rows correspond to different preferred orientations, and the columns to different preferred wavelengths. The image shown in the bottom-right position is computed as a pixel-wise maximum superposition (L 1 norm) of all channel outputs.</figDesc><graphic coords="5,311.46,59.56,240.22,556.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Co-occurrence matrix operator channels. The three filterbank columns correspond to the co-occurrence matrix based quantities inertia, energy, and entropy. The rows correspond to different choices of the displacement vector d.</figDesc><graphic coords="6,311.46,59.56,240.22,556.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(a)] and the superposition ( -norm) outputs of Gabor-energy [Fig. 7(b)], co-occurrence matrix [Fig. 7(c)], and grating cell [Fig. 7(d)] operators. All three operators give strong response in the texture area of the image and little or no response in the surrounding background of uniform gray level. We conclude that all three operators give satisfactory results for detecting oriented texture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Oriented texture in (a) the input image is detected by (b) Gabor energy, (c) co-occurrence matrix, and (d) grating cell operators.</figDesc><graphic coords="7,385.44,411.11,92.29,92.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. While the (b) Gabor-energy operator and (c) co-occurrence matrix operator detect features, such as edges, in an input image (a) which contains no (oriented) texture, the grating cell operator (d) does not respond to nontexture image attributes.</figDesc><graphic coords="8,122.40,411.11,92.29,92.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. While the (b) Gabor-energy operator and (c) the co-occurrence matrix operator detect both texture and contours in the input image (a), the grating cell operator (d) detects only texture and does not respond to other image attributes, such as contours.</figDesc><graphic coords="8,385.44,411.11,92.29,92.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Two distributions of projected feature vector clusters (the horizontal axis corresponds to the position on the projection line; the vertical axis to the number of points in the image whose corresponding feature vector is projected on the same point of the projection line).</figDesc><graphic coords="9,61.38,59.58,214.32,174.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. In order to analyze the separability of the two clusters, the feature vectors are projected on a line. The line on which the clusters are optimally separable, in this case 2 1 , is called the Fisher linear discriminant.</figDesc><graphic coords="9,321.48,59.55,220.25,165.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Nine test images, to be denoted T1 to T9, left to right and top to bottom.</figDesc><graphic coords="9,308.04,271.09,247.09,246.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Projected versions of two clusters of feature vectors derived from different textures. Since the distributions of projected feature vectors do not overlap, the original clusters of feature vectors are linearly separable.</figDesc><graphic coords="10,77.70,59.58,181.68,163.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Results of segmentation experiments using the K-means clustering algorithm. The left-most column shows three input images containing two, five, and nine textures. The second column shows the exact segmentation of the input images (i.e., the so-called ground truth). The three right-most columns show the segmentation results (using K = 2, K = 5, and K = 9 for the respective rows) based on the grating cell operator (middle column), the Gabor-energy operator (second column from the right), and the co-occurrence matrix operator (right-most column).</figDesc><graphic coords="11,42.84,54.97,514.47,310.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I VALUES</head><label>I</label><figDesc>OF THE FISHER CRITERION f OBTAINED WITH THE GRATING CELL OPERATOR</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II VALUES</head><label>II</label><figDesc>OF THE FISHER CRITERION FISHER CRITERION OBTAINED WITH THE GABOR-ENERGY OPERATOR</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III VALUES</head><label>III</label><figDesc>OF THE FISHER CRITERION OBTAINED WITH THE CO-OCCURRENCE MATRIX OPERATOR</figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The work of P. Kruizinga was supported by a grant from the Massively Parallel Computing Programme of the Dutch Organization for Scientific Research (NWO) and by a grant by Foundation National Computing Facilities of NWO. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Robert J. Schalkoff.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Peter Kruizinga received the M.S. degree in computer science from the University of Groningen, The Netherlands, in 1993. Since 1993, he has been pursuing the Ph.D. degree at the Department of Computing Science, University of Groningen.</p><p>His main interests are texture analysis and computer models of visual neurons for texture processing.</p><p>Nikolay Petkov received the M.S. degree in physics from the University of Sofia, Bulgaria, in 1980, and the Dr.sc.techn. degree in computer engineering from Dresden University of Technology, Germany, in 1987.</p><p>Currently, he holds a chair of Parallel Computing at the University of Groningen, The Netherlands. He is the author of two books and more than 60 scientific publications. His current research interests are in the area of computer simulations of the visual system.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A theoretical comparison of texture algorithms</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Conners</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Harlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="204" to="222" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A comparative study of texture measures for terrain classification</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Weszka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="269" to="285" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Texture feature performance for image segmentation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M H</forename><surname>Du Buf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kardan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Spann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="291" to="309" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Textural features for image classification</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Dinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="610" to="621" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Local linear transforms for texture measurements</title>
		<author>
			<persName><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="61" to="79" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Textured image segmentation</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">I</forename><surname>Laws</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Process. Inst., Univ. South. Calif</title>
		<imprint>
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep. USCIPI 940</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A max-min measure for image texture analysis</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">R</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Boyne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="408" to="414" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multiple resolution texture analysis and classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Naor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Avnir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="514" to="523" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Texture analysis using twodimensional quadrature filters</title>
		<author>
			<persName><forename type="first">H</forename><surname>Knutsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Granlund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop CAPAIDM</title>
		<meeting>IEEE Workshop CAPAIDM<address><addrLine>Pasadena, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Performance evaluation for four classes of textural features</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Ohanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Dubes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="819" to="833" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Texture discrimination by Gabor functions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybern</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="71" to="82" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Gabor filters as texture discriminator</title>
		<author>
			<persName><forename type="first">I</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybern</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="103" to="113" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Markov random field texture models</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Cross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="25" to="39" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A comparison of bilinear space spatialfrequency representations for texture discrimination</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Goutte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1057" to="1068" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A comparison of texture feature extraction using adaptive gabor filtering, pyramidal and tree structured wavelet transforms</title>
		<author>
			<persName><forename type="first">O</forename><surname>Pichler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Teuner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Hosticka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="733" to="742" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Statistical methods to compare the texture features of machined surfaces</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Ramana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ramamoorthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1447" to="1460" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A comparative study of texture measures with classification based on feature distributions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="51" to="59" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Comparison of several approaches for the segmentation of texture images</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guerriero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Desario</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="509" to="521" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Grating cells in monkey visual cortex: Coding texture?</title>
		<author>
			<persName><forename type="first">R</forename><surname>Der Heydt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Peterhans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Dürsteler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Channels in the Visual Nervous System: Neurophysiology, Psychophysics and Models</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Blum</surname></persName>
		</editor>
		<meeting><address><addrLine>London, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Freund</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="53" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Periodic-pattern-selective cells in monkey visual cortex</title>
	</analytic>
	<monogr>
		<title level="j">J. Neuroscience</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1416" to="1434" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Receptive fields, binocular interaction and functional architecture in the cat&apos;s visual cortex</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Hubel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Wiesel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Physiol</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="page" from="106" to="154" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Sequence regularity and geometry of orientation columns in the monkey striate cortex</title>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Neurol</title>
		<imprint>
			<biblScope unit="volume">158</biblScope>
			<biblScope unit="page" from="267" to="293" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Exploration of the primary visual cortex, 1955-78</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Hubel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">299</biblScope>
			<biblScope unit="page" from="515" to="524" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Relationship between spatial frequency selectivity and receptive field profile of simple cells</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Pollen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Physiol</title>
		<imprint>
			<biblScope unit="volume">287</biblScope>
			<biblScope unit="page" from="163" to="176" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Linear and nonlinear properties of simple and complex receptive fields in area 17 of the cat visual cortex</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">D</forename><surname>Glezer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Tsherbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">E</forename><surname>Gauselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Bondarko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybern</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="195" to="208" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fourier analysis and spatial representation in the visual cortex</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Kulikowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Experientia</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="160" to="163" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Responses of visual cortical cells to periodic and nonperiodic stimuli</title>
		<author>
			<persName><forename type="first">L</forename><surname>Maffei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Morrone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pirchio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Physiol</title>
		<imprint>
			<biblScope unit="volume">296</biblScope>
			<biblScope unit="page" from="27" to="47" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Spatial summation in the receptive fields of simple cells in the cat&apos;s striate cortex</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Movshon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Tolhurst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Physiol</title>
		<imprint>
			<biblScope unit="volume">283</biblScope>
			<biblScope unit="page" from="53" to="77" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Feature detection in human vision: Aphase-dependent energy model</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Morrone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Burr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. R. Soc. Lond. B</title>
		<imprint>
			<biblScope unit="volume">235</biblScope>
			<biblScope unit="page" from="221" to="245" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Receptive field organization of complex cells in the cat&apos;s striate cortex</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Movshon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Tolhurst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Physiol</title>
		<imprint>
			<biblScope unit="volume">283</biblScope>
			<biblScope unit="page" from="79" to="99" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">in Visual Perception: The Neurophysiological Foundations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shapley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Caelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Rentschler</surname></persName>
		</author>
		<editor>L. Spillmann and J. S. Werner</editor>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Academic</publisher>
			<biblScope unit="page" from="417" to="448" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Computational theories of visual perception</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A complex-cell receptive-field model</title>
		<author>
			<persName><forename type="first">H</forename><surname>Spitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hochstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="1266" to="1286" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The two-dimensional spatial structure of nonlinear subunits in the receptive fields of complex cells</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Szulborski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="249" to="254" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Spatial frequency selectivity of cells in macaque visual cortex</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Devalois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Albrecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Thorell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="545" to="559" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A computational model of periodicpattern-selective cells</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kruizinga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Petkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IWANN&apos;95</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Mira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Sandoval</surname></persName>
		</editor>
		<meeting>IWANN&apos;95<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">930</biblScope>
			<biblScope unit="page" from="90" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Computational models of visual neurons specialised in the detection of periodic and aperiodic oriented visual stimuli: Bar and grating cells</title>
		<author>
			<persName><forename type="first">N</forename><surname>Petkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kruizinga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybern</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="83" to="96" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Fukunaga</surname></persName>
		</author>
		<title level="m">Introduction to Statistical Pattern Recognition</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic</publisher>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Schalkoff</surname></persName>
		</author>
		<title level="m">Pattern Recognition: Statistical, Structural and Neural Approaches</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Two-dimensional spectral analysis of cortical receptive field profiles</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Daugman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="847" to="856" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Mathematical description of the response of simple cortical cells</title>
		<author>
			<persName><forename type="first">S</forename><surname>Marcelja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Opt. Soc. Amer</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1297" to="1300" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Uncertainty relation for resolution in space, spatial frequency, and orientation optimized by two-dimensional visual cortical filters</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Daugman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Opt. Soc. Amer. A</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1160" to="1169" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Biologically motivated computationally intensive approaches to image pattern recognition</title>
		<author>
			<persName><forename type="first">N</forename><surname>Petkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="451" to="465" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">An evaluation of the two-dimensional Gabor filter model of simple receptive fields in cat striate cortex</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurophys</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="1233" to="1258" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Unsupervised texture segmentation using Gabor filters</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Farrokhnia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1167" to="1186" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Texture segmentation by clustering of Gabor feature vector</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Clar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Joint Conf. Neural Networks</title>
		<meeting>Int. Joint Conf. Neural Networks</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="683" to="688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Computational modeling of visual texture segregation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Bergen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Landy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Models of Visual Processing</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Landy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Movshon</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="253" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Texture edge detection by modeling visual cortical channels</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1283" to="1298" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Texture classification and segmentation based on neural network methods</title>
		<author>
			<persName><forename type="first">A</forename><surname>Visa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<pubPlace>Finland</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Helsinki Univ. Technol.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">An improved method for computing gray-level cooccurrence matrix based texture measures</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Peckingpaugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis., Graph., Image Process.: Graph. Models and Image Process</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="574" to="580" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Everitt</surname></persName>
		</author>
		<title level="m">Cluster Analysis</title>
		<meeting><address><addrLine>London, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Heinemann Educational Books</publisher>
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">The Mathematical Theory of Probabilities</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fisher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1923">1923</date>
			<publisher>Macmillan</publisher>
			<biblScope unit="volume">1</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Some methods for classification and analysis of multivariate observations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Macqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th Berkeley Symp. Mathematical Statistics and Probability</title>
		<meeting>5th Berkeley Symp. Mathematical Statistics and Probability<address><addrLine>Berkeley</addrLine></address></meeting>
		<imprint>
			<publisher>Univ. Calif. Press</publisher>
			<date type="published" when="1967">1967</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="281" to="297" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
