<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A novel approach for edge detection based on the theory of universal gravity</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Genyun</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">State Key Laboratory of Remote Sensing Science</orgName>
								<orgName type="department" key="dep2">Institute of Remote Sensing Applications</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100101</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qinhuo</forename><surname>Liu</surname></persName>
							<email>qhliu@irsa.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">State Key Laboratory of Remote Sensing Science</orgName>
								<orgName type="department" key="dep2">Institute of Remote Sensing Applications</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100101</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qiang</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Changyuan</forename><surname>Ji</surname></persName>
							<email>cyji@up.edu.ph</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">State Key Laboratory of Remote Sensing Science</orgName>
								<orgName type="department" key="dep2">Institute of Remote Sensing Applications</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100101</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">College of Engineering</orgName>
								<orgName type="institution">University of Philippines Diliman</orgName>
								<address>
									<settlement>Manila</settlement>
									<country key="PH">Philippines</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaowen</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">State Key Laboratory of Remote Sensing Science</orgName>
								<orgName type="department" key="dep2">Institute of Remote Sensing Applications</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100101</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A novel approach for edge detection based on the theory of universal gravity</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E1219C2EBF4A316634B9B8EB91D23B83</idno>
					<idno type="DOI">10.1016/j.patcog.2007.01.006</idno>
					<note type="submission">Received 1 December 2005; received in revised form 28 November 2006; accepted 3 January 2007</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Edge detection</term>
					<term>Image processing</term>
					<term>The law of universal gravity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents a new, simple and effective low-level processing edge detection algorithm based on the law of universal gravity. The algorithm assumes that each image pixel is a celestial body with a mass represented by its grayscale intensity. Accordingly, each celestial body exerts forces onto its neighboring pixels and in return receives forces from the neighboring pixels. These forces can be calculated by the law of universal gravity. The vector sums of all gravitational forces along, respectively, the horizontal and the vertical directions are used to compute the magnitude and the direction of signal variations. Edges are characterized by high magnitude of gravitational forces along a particular direction and can therefore be detected. The proposed algorithm was tested and compared with conventional methods such as Sobel, LOG, and Canny using several standard images, with and without the contamination of Gaussian white noise and salt &amp; pepper noise. Results show that the proposed edge detector is more robust under noisy conditions. Furthermore, the edge detector can be tuned to work at any desired scale.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Edges correspond to sharp variations of image intensity and convey vitally important information in an image. Detection of edges is therefore a key issue in image processing, computer vision, and pattern recognition. A variety of algorithms exist for edge characterization and detection such as the statistical methods <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>, the difference methods <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>, and curve fitting <ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref>.</p><p>As the complexity of image edge detection, every algorithm has its advantages and disadvantages. For example, Smith and Brady <ref type="bibr" target="#b13">[14]</ref> proposed a new approach for low-level feature extraction-SUSAN operator. It works on the principle of "Univalue Segments" and tries to provide robust signatures for each edge point. However, the characteristics (e.g., size) of this "Smallest Univalue Segment Assimilating Nucleus" are strongly influenced by the presence of edges and corners. On the other hand, noise contamination is always a problem and edge detection in noisy environment can be treated as an optimal linear filter design problem <ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref>. Canny <ref type="bibr" target="#b15">[16]</ref> described what has since become one of the most widely used edge finding algorithms. The first step taken is the definition of criteria which an edge detector must satisfy. Based on these Canny defined an optimal filter, which can be efficiently approximated by the first derivative of Gaussian function in the 1-D case. Canny's filter was further extended to recursive filters <ref type="bibr" target="#b19">[20]</ref>, which provide a more efficient way for image noise filtering and edge detection.</p><p>In the last decade, there have been renewed interests in the wavelet theory, and applications in filtering, classification, and compression <ref type="bibr" target="#b20">[21]</ref>. Wavelet and its associated multi-resolution analysis have also been applied for the characterization of image intensity variations. Mallat et al. <ref type="bibr" target="#b21">[22]</ref> presented their wavelet domain multi-scale edge detection approaches. In their researches, the edges are classified as the singularity points that can be detected as the local maxima of gradient moduli or the zero-crossings of wavelet coefficients. In Ref. <ref type="bibr" target="#b22">[23]</ref>, the zero-crossings of M-band wavelet coefficients are located and viewed as the edges. These multi-scale edge detection approaches have made a significant improvement for the image edge detection. More recently, a new approach based on the discrete singular convolution (DSC) edge detection algorithm has been proposed <ref type="bibr" target="#b23">[24]</ref>. However, up to now, it is still a challenge issue to develop robust edge detection algorithm. In this paper, a new edge detection algorithm is presented.</p><p>The method is based on the law of universal gravity. Every image point may be assumed as a celestial body, which has relationships with other neighboring image points. The proposed edge detector algorithm includes three steps. At first, the gravitational forces of a pixel exert on every other pixels around it are computed using the law of universal gravity. Secondly, the vector sum of all gravitational forces is calculated. At last, the magnitude and direction of the vector are used to detect image edges. Experiments indicate that the new approach is effective for edge detection especially under noisy conditions.</p><p>The rest of the paper is organized as the following: the law of universal gravity is briefly reviewed in Section 2. Then, the algorithm of the proposed edge detector is presented in Section 3. Furthermore, applications of the presented algorithm are given in Section 4. The performance is illustrated using a number of real images. Both noise free and noisy contaminated images are used for the experiments. Finally, conclusions are presented in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background on the law of universal gravity</head><p>Between any two objects that have mass, there exist attractive gravitational forces acting on each object separately. The two forces have the same magnitude with opposite directions as illustrated in Fig. <ref type="figure">1</ref>.</p><p>According to Newton's law of universal gravitation <ref type="bibr" target="#b24">[25]</ref>, every object in the Universe attracts every other object with a force directed along the line of centers for the two objects that is proportional to the product of their masses and inversely proportional to the square of the separation between the two objects. Newton's law of universal gravitation can be written as a vector equation to account for the direction of the gravitational force as well as its magnitude. As illustrated in Fig. <ref type="figure">1</ref>, the formulation states:</p><formula xml:id="formula_0">f 1,2 = Gm 1 m 2 r2,1 r 2,1 2 = Gm 1 m 2 r 2,1 r 2,1 3 ,<label>(1)</label></formula><p>where f 1,2 is the force on object 1 due to object 2, G is the gravitational constant, m 1 and m 2 are the masses of the objects 1 and 2, respectively, r 1 and r 2 are the vector positions of the two objects, respectively, r 2,1 = r 2r 1 is the distance between objects 1 and 2, r2,1 = r 2r 1 / r 2r 1 is the unit vector from object 2 to 1. Likewise, the vector gravitational force exerted by object 1 on object 2 takes the form</p><formula xml:id="formula_1">f 2,1 = -f 1,2 .</formula><p>(2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Gravity edge detector</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Illustration of the method</head><p>To construct an edge detector, we assume that every image point is a celestial body, which has some relationship with other image points within its neighborhood through gravitational forces. For points beyond a pre-specified range, we assume all gravitational forces are zero. For each image point, the magnitude and the direction of the vector sum of all gravitational forces the point exerts on its neighborhood conveys the vitally important information about an edge structure including the magnitude and the direction. The idea is inspired by USAN <ref type="bibr" target="#b13">[14]</ref> concept which was introduced by Smith and Brady for feature extraction.</p><p>There are a number of definitions of an edge, each being applicable in various specific circumstances. One of the most common and most general definitions is the ideal step edge <ref type="bibr" target="#b25">[26]</ref>. For notational simplicity we only describe the detection algorithm for vertically orientated edges under ideal step edge condition. The algorithm can be easily extended to horizontal and diagonal orientations. Edge structures in 90 • directions are depicted in Fig. <ref type="figure" target="#fig_1">2</ref>. Here we assume that the gray value of white pixels is I 1 , and that of black pixels I 2 , I 2 &gt; I 1 . F 1 represents the gravitational force between two white pixels per unit distance, F 2 between a white and a black, and F 3 between black and black, F 3 &gt; F 2 &gt; F 1 according to Eq. (1). The magnitude of the gravitational force of the center pixel exerts on each other pixel within its neighborhood is illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>, the arrow indicates the gravitational force direction, here a = 1 2 , for simplification, we only consider 3 × 3 neighborhood of four points, of which points 1 and 4 are latent edge points whereas points 2 and 3 are non-edge points.</p><formula xml:id="formula_2">F 1 aF 1 F 1 aF 1 aF 1 F 1 F 1 F 1 F 1 F 1 F 2 aF 1 aF 1 aF 2 aF 2 aF 1 aF 2 aF 2 F 2 F 3 F 3 aF 3 aF 3 F 3 aF 3 aF 3 aF 3 aF 3 F 3 F 3 F 3</formula><p>As can be seen from Fig. <ref type="figure" target="#fig_1">2</ref>, all image points have four double gravitational forces. For point 1, we first compute the magnitude sum of gravitational forces in both x and y directions, respectively,</p><formula xml:id="formula_3">F x = aF 2 * √ 2 2 + F 1 + aF 1 * √ 2 2 -aF 2 * √ 2 2 + F 1 + aF 1 * √ 2 2</formula><p>= 0,</p><formula xml:id="formula_4">F y = aF 2 * √ 2 2 + F 2 + aF 2 * √ 2 2 -aF 1 * √ 2 2 + F 1 + aF 1 * √ 2 2 = √ 2 2 + 1 * (F 2 -F 1 ).</formula><p>Then we calculate the magnitude and the direction of the vector sum of point 1 exerts on its neighborhood:</p><formula xml:id="formula_5">F 1 = (F x ) 2 + (F y ) 2 = √ 2 2 + 1 (F 2 -F 1 ), 1 = arctan(F x /F y ) = 0.</formula><p>Using exactly the same method, we obtain the response of points 2-4:</p><formula xml:id="formula_6">F 2 = F 3 = 0, 2 = 3 = arctan(F x /F y ) = 2 , F 4 = ( √ 2 2 + 1)(F 3 -F 2 ), 4 = arctan(F x /F y ) = 0.</formula><p>According to the above, the response F is 0 for non-edge points such as points 2 and 3, but for latent edge points such as points 1 and 4, F is greater than 0. In general, F 1 = F 4 , we assume F 4 &gt; F 1 &gt; 0 = F 2 = F 3 . Theoretically, we can set an appropriate threshold, for example F, and let F 4 &gt; F &gt; F 1 . A pixel location is declared an edge location if the value of response exceeds the threshold, here point 4 is labeled as edge point. Performing the same steps at each image point an edge map is then created (e.g., line 4 is labeled as edge). The edgedirection information is given by .</p><p>When using the Sobel or Prewitt operators in Fig. <ref type="figure" target="#fig_1">2</ref>, the pixels of Column 3 with point 1 and Column 4 with point 4 have the same response and are both labeled as edge. Therefore, our method is superior to Sobel and Prewitt operators according to the criteria "only one response to a single edge" which was described by Canny <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Generation of the edge operator</head><p>The entire algorithm of edge detection can be implemented as follows:</p><p>(1) For each image point g(i, j ), we consider a m × n neighborhood with pixels x k,l ∈ &amp; (k, l) = (i, j ). For each point, the gravitational force of the point exerts on its neighboring pixels is computed using Eq. ( <ref type="formula" target="#formula_0">1</ref>):</p><formula xml:id="formula_7">f i,j ;k,l = Gm i,j m k,l r r 3 ,<label>(3)</label></formula><p>where f i,j ;k,l is the gravity g(k, l) exerts on g(i, j ), m i,j , m k,l are the gray values of the pixel g(i, j ) and g(k, l), r is the vector from g(k, l) to g(i, j ), and</p><formula xml:id="formula_8">r = (k -i) 2 + (l -j) 2 . (<label>4</label></formula><formula xml:id="formula_9">)</formula><p>(2) Considering an image as 2D signals, in practical computing, we compute the gravitational forces in both x and y directions:</p><formula xml:id="formula_10">f x i,j ;k,l = f i,j ;k,l sin = Gm i,j m k,l r r 3 k -i r = Gm i,j m k,l (k -i) r 3 , f y i,j ;k,l = f i,j ;k,l cos = Gm i,j m k,l r r 3 l -j r = Gm i,j m k,l (l -j) r 3 . (<label>5</label></formula><formula xml:id="formula_11">)</formula><p>And the vector f i,j ;k,l can be calculated using the following formula:</p><formula xml:id="formula_12">f i,j ;k,l = f x i,j ;k,l x + f y i,j ;k,l ŷ.<label>(6)</label></formula><p>The vector sum of all gravitational forces which the neighborhoods exert on g(i, j ) is expressed as</p><formula xml:id="formula_13">F i,j = f i,j ;k,l = F x x + F y ŷ (k, l) ∈ &amp; (k, l) = (i, j ),<label>(7)</label></formula><p>where</p><formula xml:id="formula_14">F x = f x i,j ;k,l (k, l) ∈ &amp; (k, l) = (i, j ), F y = f y i,j ;k,l (k, l) ∈ &amp; (k, l) = (i, j ). (<label>8</label></formula><formula xml:id="formula_15">)</formula><p>(3) The edge strength response of point g(i, j ) is produced by the magnitude of the vector F i,j , its edge direction is given by the direction of F i,j :</p><formula xml:id="formula_16">F = (F x ) 2 + (F y ) 2 , = arctan(F x /F y ), (<label>9</label></formula><formula xml:id="formula_17">)</formula><p>where F is the magnitude of the vector sum F i,j , is the direction of the vector sum F i,j . ( <ref type="formula" target="#formula_8">4</ref>) Set an appropriate threshold to produce an edge map.</p><p>In fact, the effect of the algorithm is equal to a convolution mask to approximate the first derivative of the image brightness function. To illustrate this, substituting Eqs. ( <ref type="formula" target="#formula_8">4</ref>) and (5) in Eq. ( <ref type="formula" target="#formula_14">8</ref>) yields</p><formula xml:id="formula_18">F x = f x i,j ;k,l = Gm i,j m k,l (k -i) (i -k) 2 + (j -l) 2 3 (k, l) ∈ &amp; (k, l) = (i, j ), F y = f y i,j ;k,l = Gm i,j m k,l (l -j) (i -k) 2 + (j -l) 2 3 (k, l) ∈ &amp; (k, l) = (i, j ),<label>(10)</label></formula><p>Eq. ( <ref type="formula" target="#formula_18">10</ref>) is a local computation, set the location g(i, j ) as the original of the coordinate system, so</p><formula xml:id="formula_19">(i, j ) = (0, 0) and k = - m 2 , . . . , . . . m 2 ; l = - n 2 , . . . 0, . . . n 2 .</formula><p>For convenience we replace Gm i,j with a constant C since it is constant in the convolving process. Eq. ( <ref type="formula" target="#formula_18">10</ref>) can be simplified to</p><formula xml:id="formula_20">F x = f x i,j ;k,l = C m k,l k ( √ k 2 + l 2 ) 3 (k, l) ∈ &amp; (k, l) = (0, 0), F y = f y i,j ;k,l = C m k,l l ( √ k 2 + l 2 ) 3 (k, l) ∈ &amp; (k, l) = (0, 0).<label>(11)</label></formula><p>Eq. ( <ref type="formula" target="#formula_20">11</ref>) equals to a convolving procedure.</p><p>Conventional operators, such as Prewitt and Sobel operators, are sensitivity to noise and tend to generate spurious edges. The effect caused by noise may be filtered out if more neighboring points are considered by the operator. Experimental results demonstrate that for noisy images an edge operator with a larger mask may provide a better edge result.</p><p>In practice, the C can be set to other value to act at some special circumstances instead of only being defined as the gray level of the center pixel of the mask. The parameters, m and n, can take different values. In this paper, we say mask = x. means m = n = x. For example, let C = 1, taking the mask size equal to 3, we obtain two 3 × 3 masks for calculating the first derivatives in the x and y directions, respectively:</p><formula xml:id="formula_21">⎡ ⎢ ⎣ -1 2 √ 2 -1 1 √ 1 -1 2 √ 2 0 0 0 1 2 √ 2 1 1 √ 1 1 2 √ 2 ⎤ ⎥ ⎦ and ⎡ ⎢ ⎢ ⎣ -1 2 √ 2 0 1 2 √ 2 -1 1 √ 1 0 1 1 √ 1 -1 2 √ 2 0 -1 2 √ 2 ⎤ ⎥ ⎥ ⎦ .</formula><p>The parameter C can also take other values to achieve more effective results. We have found that C can convey the regional information around g(i, j ) and makes the algorithm more efficient under salt &amp; pepper noise conditions when C = sig(g(i, j )). Here sig(g(i, j )) is a sigmoid function which is inspired by Etienne <ref type="bibr" target="#b26">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental results</head><p>To demonstrate the efficiency of the proposed approach, we carried out computer experiments on gray-level images. We selected a few standard images which are either natural or human-made (Fig. <ref type="figure">3</ref>). The Lena and the Couple images are both figure image. The Singapore airport image is a natural and non-textured image and the square is a synthetic image. The settings of these images vary from in-door scenes to out-door views. The resolution of all images is 8-bit per pixel. The square image is of the size of 256 × 256 pixels, the Singapore airport is of 719 × 905, the rest two images are of 512 × 512.</p><p>Most edge detection techniques utilize a post processing thresholding immediately after feature extraction to thin and extend edge contours. There are many well-established thresholding methods <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref> and edge thinning techniques. In the present work, the edge detection consists of two steps: edge magnitude calculation and threshold. For magnitude result, we first get the contrast stretched image with brightness ranging from 0 to 255 by linear stretch method, then utilizes Otsu <ref type="bibr" target="#b29">[30]</ref> method to generate a threshold. The procedure described here is also applied for the implementation of other standard edge detectors, which are used for comparison in the present study.</p><p>In the rest of this section, we conduct two groups of computer experiments to test the proposed approach. Group one is designed to investigate the performance of the present algorithm on the edge detection of real images, including clean and noise images. Group two is designed to objectively compare the performances of different edge detectors by using a Fig. <ref type="figure">3</ref>. A collection of sample images, where the square is of the size of 256 × 256, the Singapore airport is of 719 × 905, the rest are of 512 × 512.  computer generated image. They are, respectively, described in the following three subsections. A brief discussion is given in the last subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Edge detection of clean images</head><p>It is well-known that both the Sobel and LOG detectors are the most commonly used edge operators as first and second order detection, respectively. For Lena image two edge maps obtained by the two detectors are shown in Fig. <ref type="figure" target="#fig_2">4(b)</ref> and<ref type="figure">(c</ref>). An edge map obtained by the new detector is shown in Fig. <ref type="figure" target="#fig_2">4(a)</ref> with parameters mask = 3, and C = 1. Apparently, the standard Sobel detector and gravity detector yield similar results. This is due to the fact that the Gravity detector uses the similar convolution mask as the Sobel to approximate the first derivative of the image brightness function. The edge map of LOG is slightly thinner, but it produces undesirable noise.</p><p>It is noted that none of the above-mentioned three edge detectors resolves some structures of the Lena image such as the nose feature. To illustrate the potential of the Gravity detector, we also conduct two tests by using Gravity with different parameters. The Gravity parameters are chosen as mask = 3, C = sig(g(i, j )). sig(g(i, j )) is the sigmoid function which has the form sig(g(i, j )) = 1 1 + e (g(i,j )-ḡ(i,j )) , <ref type="bibr" target="#b11">(12)</ref> where ḡ(i, j ) is the average intensity in the considered neighborhood at point g(i, j ) and is the standard deviation in the neighborhood at the same point.</p><p>These results are depicted in Fig. <ref type="figure" target="#fig_3">5</ref>, along with those obtained by Sobel and Canny detectors. Overall, the Canny detector produces smoother and thinner edges. However, it is clear that most of the edge structures are well preserved by the new detector. Although the edges by the present detector are slightly thicker than those of the Canny detector, its performance is still competitive with it, considering the Canny detector has a thinning stage of additional edge. In contrast, it is noted that the Gravity method detects more edge features (as the white ellipse indicated) than the Sobel operator. Furthermore, the edges detected by gravity operator are thinner than those of Sobel. Therefore, the gravity detector is more efficient than the Sobel detector for edge detection of these images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Noisy images</head><p>To investigate the performance of the new algorithm under noisy environment, we consider a number of low grade images. We first compare the proposed detector with the Sobel and Canny detector for salt &amp; pepper noise. The noise intensity is 0.1, which denotes significant degradation of image quality as show in Fig. <ref type="figure" target="#fig_5">6</ref>.</p><p>For noisy Lena image, three edge maps obtained by these detectors are shown in Fig. <ref type="figure" target="#fig_6">7: (a</ref>    of the present detector in the presence of severe noise is also perceivable compared with Fig. <ref type="figure" target="#fig_6">7</ref>(b), with much of the noise pulses removed and the edge map is more clear. Now we expand the mask size to 5. The compared detectors are Prewitt and LOG detectors with the same mask size. Fig. <ref type="figure" target="#fig_7">8</ref> illustrates the vertical mask of expanded Prewitt detector <ref type="bibr" target="#b30">[31]</ref>. Four edge maps of Couple image are show in Fig. <ref type="figure" target="#fig_8">9</ref>. (a) and (b) are obtained using the present detector with parameters (a) mask = 5, C = 1; (b) mask = 5, C = sig(g(i, j )); (c) and (d) are obtained using the Prewitt and LOG detector with mask = 5, respectively. The better performance of the present detector in the presence of salt &amp; pepper noise is clearly perceivable, compared to Fig. <ref type="figure" target="#fig_8">9(c</ref>), much of the noise pulses is removed and edge map is more lucid in Fig. <ref type="figure" target="#fig_8">9(a)</ref>. This example also illustrates the effects of adjusting the parameters on the resultant edge map. Some of the fine edge structures are missing and the edges are slightly thicker in Fig. <ref type="figure" target="#fig_8">9(c)</ref>. Comparatively, the edges in Fig. <ref type="figure" target="#fig_8">9</ref>(b) are thinner and most of the fine edges with relatively lower contrast are detected. Compared with Fig. <ref type="figure" target="#fig_8">9(d)</ref>, the edge map of Fig. <ref type="figure" target="#fig_8">9(b</ref>) is also clearer. Hence, increasing mask size has a significant effect on the reduction of noise influence, and the parameter of C =sig(g(i, j )) results in thinner edges under salt &amp; pepper noise conditions.</p><p>Results on the Singapore airport image corrupted with Gaussian noise (mean =0, intensity=0.1) and random noise is show in Fig. <ref type="figure">10</ref>. Fig. <ref type="figure" target="#fig_0">11</ref> shows the resulting edge images detected from noisy environment, obtained by the present detector (Row 1), the expanded Prewitt detector (Row 2), the LOG detector (Row 3), and the Canny detector (Row 4). For all detectors, the mask size of Column 1 is 5 and the Column 2 is 7, respectively.</p><p>As can be seen from these edge maps, the impact of noise on these detectors is clearly visible: the LOG detector is ineffective under such noise conditions. In contrast, sharp edge images are successfully attained by using the proposed detector. There is a little visual difference between those obtained by the present detector and the expanded Prewitt detector, but with the mask expanding, the proposed algorithm detects more edges efficiently: when the mask size is expanded to 7, the proposed detector can detect more edges, including some fine structural edges (for instance the right bottom corner).</p><p>As mentioned in the introduction, the Canny detector <ref type="bibr" target="#b15">[16]</ref> was formulated as an optimization problem for being used under noise environment. It is demonstrated in Refs. <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref> that a smooth parameter = 1.5 is nearly optimal in association with a 5 × 5 mask. The resulting edge images are included in Row 4 of Fig. <ref type="figure" target="#fig_0">11</ref> for comparison. Understandably, with the mask expanding, the Canny operator can detect narrower edges. On the contrary, the proposed detector (Row 1) can detect wider edges therefore fine edges may be detected. It is demonstrated that the new detector with a larger mask may provide a wider edge map under such condition compared with others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Edge detection of a synthetic image</head><p>To validate the Gravity detector further, we present an alternative evaluation in this subsection. Edge detection systems could be compared in many ways. For example, image gradients may be compared visually <ref type="bibr" target="#b32">[33]</ref>, where an edge image is evaluated by a group of people and the average score may serve as an index of quality. For synthetic images, where the exact location of edges is known, Abdou and Pratt <ref type="bibr" target="#b33">[34]</ref> proposed a figure of merit to objectively evaluate the performance of edge detectors. Their figure of merit is defined as</p><formula xml:id="formula_22">F = 1 max(N l , N D ) N D i=1 1 1 + d 2 i ,<label>(13)</label></formula><p>where d i is the distance between a pixel declared as edge point and the nearest ideal edge pixel, is a scaling constant set to 1   9   as in Pratt's work. N l and N D are the numbers of ideal and detected edge pixels, respectively. It is common practice to evaluate the performance of an edge detector for synthetic images by introducing noise in the images. F is an index to measure the accuracy of edge localizations. A larger value corresponds to better performance, with 1 being a perfect result. Performance comparison is based on a synthetic square image as shown in Fig. <ref type="figure">3</ref>. The figure of merit F for each of the methods studied is calculated with respect to different power of the added Gaussian white noise, and the results are shown in Table <ref type="table" target="#tab_0">1</ref>. Here Gravity.1 with mask = 3, C = 1; Gravity.2 with mask = 5, C = sig(g(i, j )); Sobel with mask = 3; LOG and Canny are both with mask = 5, as Section 4.2. When the noise level is 0, the F values are close to 1 and the performances of all the tested detectors are very satisfactory. With the increase of the noise level, the F values decrease. In contrast, the proposed detectors achieve large F values over the domain of interest, suggesting their superiority over the other three detectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussions</head><p>In the presence of noise, the direct application of the differentiation operation in edge detection will encounter difficulties, as illustrated by the preceding experiments. The differentiation operation is sensitive to noise and the problem is mathematically ill-posed. To offset the effect of noise, a direct approach is to remove noise before the differentiation, usually by convolving the raw input image with a Gaussian function, which leads to the well-known LOG detector <ref type="bibr" target="#b7">[8]</ref>. This problem can also be solved by using regularization techniques developed for dealing with mathematically ill-posed problems <ref type="bibr" target="#b34">[35]</ref>. Poggio et al. <ref type="bibr" target="#b35">[36]</ref> proved that the varying formulation of Tikhonov regularization leads to a Gaussian-like convolution filter. In the present work, the impact caused by noise would be reduced by using a larger mask. What's more, with the mask expanding, larger edges can be detected.</p><p>On the other hand, the algorithm has an extra parameter C, which can be tuned to act at certain special circumstances. Experiments in Section 4.1 indicated that when C = sig(g(i, i)), more detailed edges can be detected under salt &amp; pepper noise condition. Considering the combined use of mask scale and C, the Gravity algorithm is a potential method for more complicated tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>A new algorithm which is efficient for edge detection based on the law of universal gravity is proposed. The performance of the proposed algorithm is compared with many other existing methods, including the Sobel, LOG, and Canny detectors. Experiments on a variety of images have shown that the algorithm is consistent and reliable even when image quality is significantly degraded by noise, especially salt &amp; pepper noise. The algorithm requires two parameters. A series of edge operators with various sizes of masks are obtained from m, n. By considering a larger neighborhood, the effect of noise on edges is reduced. With the same size mask, the proposed detector is more effective than others. The combined use of the parameter C makes the present algorithm efficient for edge detection in a variety of practical situations, especially in salt &amp; pepper noise conditions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 Fig. 1 .</head><label>11</label><figDesc>Fig. 1. Newton's law of universal gravitation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. Basic edge structures oriented in 90 • directions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Edge maps of the Lena image: (a) the present detector with mask = 3, C = 1 (b) the Sobel detector, and (c) the LOG detector.</figDesc><graphic coords="5,128.57,71.49,328.32,120.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Edge maps of the Lena image: (a) the present detector with mask = 3, C = sig(g(i, j )), (b) the Sobel detector, and (c) the Canny detector.</figDesc><graphic coords="5,124.07,235.07,336.96,120.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>) the present detector with mask = 3, C = 1; (b) the Sobel detector; (c) the Canny detector. Obviously, the contrast of the Canny edge image is poor and contains much small and spurious contour. For comparison, much sharper edge images are successfully attained by the new detector as shown in Fig. 7(a). The better performance</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. A noisy Lena and Couple image corrupted with salt &amp; pepper noise with intensity = 0.1.</figDesc><graphic coords="6,148.62,70.82,308.52,156.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Edge maps of the Lena image corrupted with additive salt &amp; pepper noise (intensity = 0.1): (a) is obtained using the present detector with parameters mask = 3, C = 1; (b) and (c) are obtained using the Sobel and Canny detector, respectively.</figDesc><graphic coords="6,111.12,270.00,383.40,147.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. The vertical mask of expanded Prewitt detector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Edge maps of the Couple image corrupted with additive salt &amp; pepper noise (intensity = 0.1): (a) and (b) are obtained using the present detector with parameters (a) C = 1, mask = 5 and (b), mask = 5; C = sig(g(i, j )); (c) and (d) are obtained using the expanded Prewitt and LOG detector, respectively, with mask = 5.</figDesc><graphic coords="7,129.57,71.06,326.16,354.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Edge maps of the Singapore airport corrupted with Gaussian noise (mean = 0, intensity = 0.1) and random noise: (Row 1) the present detector; (Row 2) the expanded Prewitt detector; (Row 3) the LOG detector, and (Row 4) the Canny detector. The mask size of Column 1 is 5 and Column 2 is 7.</figDesc><graphic coords="8,150.62,71.73,304.20,486.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="4,319.61,501.95,235.44,218.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>The statistic of the merit F for different edge detectors</figDesc><table><row><cell>Power of</cell><cell>Detector</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>noise</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Gravity.1</cell><cell>Gravity.2</cell><cell>Sobel</cell><cell>LOG</cell><cell>Canny</cell></row><row><cell>0</cell><cell>0.8375</cell><cell>0.9054</cell><cell>0.8342</cell><cell>0.9054</cell><cell>0.9341</cell></row><row><cell>0.05</cell><cell>0.8412</cell><cell>0.9366</cell><cell>0.8301</cell><cell>0.1776</cell><cell>0.2778</cell></row><row><cell>0.1</cell><cell>0.8101</cell><cell>0.8608</cell><cell>0.7059</cell><cell>0.1774</cell><cell>0.2219</cell></row><row><cell>0.15</cell><cell>0.6006</cell><cell>0.6438</cell><cell>0.3947</cell><cell>0.1768</cell><cell>0.3194</cell></row><row><cell>0.2</cell><cell>0.3987</cell><cell>0.4710</cell><cell>0.2706</cell><cell>0.1763</cell><cell>0.2945</cell></row><row><cell>0.25</cell><cell>0.288</cell><cell>0.3810</cell><cell>0.2341</cell><cell>0.1753</cell><cell>0.2940</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This study was supported by the Knowledge Innovation Program of Chinese Academy of Sciences (KZCX3-SW-338) and Chinese Natural Science Foundation Project (40371087, 40401042).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Edge detection in correlated noise using Latin squares models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kurz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="119" to="129" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Line detection in noisy and structured background using Graco-Latin squares, CVGIP: Graphical Models Image Process</title>
		<author>
			<persName><forename type="first">J</forename><surname>Haberstroh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kurz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="161" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Bayesian recursive image estimation</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>Nahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Assefi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="734" to="738" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Image segmentation using simple Markov field models</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Elliot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graphics Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="101" to="132" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Statistical theory of edge detection, Comput. Vision Graphics Image Process</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Tseng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="337" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Object enhancement and extraction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M S</forename><surname>Prewitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Picture Processing and Psychopictorics</title>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Lipkin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1970">1970</date>
			<biblScope unit="page" from="75" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Computer determination of the constituent structure of biological images</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kirsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Biomed. Res</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="314" to="328" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Theory of edge detection</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hidreth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. R. Soc. London B</title>
		<imprint>
			<biblScope unit="volume">207</biblScope>
			<biblScope unit="page" from="187" to="217" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Digital step edges from zero crossing second directional derivatives</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. PAMI</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="58" to="68" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An operator which locates edges in digitized pictures</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Huechel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Assoc. Comput. Mach</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="113" to="125" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A facet model for image data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graphics Image Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="113" to="129" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On detecting edges</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nalwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Binford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. PAMI</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="699" to="714" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficient facet edge detection and quantitative performance evaluation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="689" to="700" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">SUSAN-a new approach to low level image processing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="78" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On edge detection</title>
		<author>
			<persName><forename type="first">V</forename><surname>Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. PAMI</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="147" to="163" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A computational approach to edge detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. PAMI</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="679" to="698" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Optimal unsupervised learning in a single-layer feedforward neural network</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Sanger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="459" to="473" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A unified approach to boundary perception: edges, textures and illusory contours</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Manjunath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="96" to="108" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On optimal infinite impulse response edge detection filters</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Boyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. PAMI</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1154" to="1171" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Optimal edge detection using recursive filtering</title>
		<author>
			<persName><forename type="first">R</forename><surname>Deriche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Conference on Computer Vision</title>
		<meeting>the First International Conference on Computer Vision<address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="501" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Characterization of signals from multiscale edges</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="710" to="732" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Zero-crossings of a wavelet transform</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory. IT</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1019" to="1033" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multidirectional and multiscale edge detection via M-band wavelet transform</title>
		<author>
			<persName><forename type="first">T</forename><surname>Aydin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yemez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Anarim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sankur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1370" to="1377" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A new approach to edge detection</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1559" to="1570" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Olenick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Apostol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Goodstein</surname></persName>
		</author>
		<title level="m">The Mechanical Universe: Introduction to Mechanics and Heat</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Algorithms for Image Processing and Computer Vision</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Parker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Willey, Computer Publishing, USA</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Detecting and matching feature points</title>
		<author>
			<persName><forename type="first">É</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Laganiere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vis. Commun. Image Representation</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="38" to="54" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A study of edge detection algorithms</title>
		<author>
			<persName><forename type="first">T</forename><surname>Peli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Malah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graphics Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Multilevel thresholding using edge matching, Comput. Vision Graphics Image Process</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Schafer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="279" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A threshold selection method from gray-level histograms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Otsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="62" to="66" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName><surname>Pratt</surname></persName>
		</author>
		<title level="m">Digital Image Processing</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Edge detection using a neural network</title>
		<author>
			<persName><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1653" to="1662" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A Robust visual method for assessing the relative performance of edge detection algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sanocki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analy. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1338" to="1359" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Quantitative design and evaluation of enhancement/thresholding edge detectors</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">E</forename><surname>Abdou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Pratt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="753" to="763" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On edge detection</title>
		<author>
			<persName><forename type="first">V</forename><surname>Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. PAMI</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="147" to="163" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A regularized solution to edge detection</title>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Complexity</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="106" to="123" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">About the Author-QINHUO LIU Professor, State Key Laboratory of Remote Sensing Science, Institute of Remote Sensing Applications, Chinese Academy of Sciences. His research interests include radiation transfer mechanism for remote sensing, quantitative remote sensing inversion and remote sensing image processing</title>
	</analytic>
	<monogr>
		<title level="m">He got bachelor degree in 1988, major in Hydrogeology and Engineering Geology</title>
		<title level="s">State Key Laboratory of Remote Sensing Science, Institute of Remote Sensing Applications, Chinese Academy of Sciences</title>
		<meeting><address><addrLine>Peking University</addrLine></address></meeting>
		<imprint>
			<publisher>About the Author-GENYUN SUN Ph.D. Candidate, major in Cartography and GIS</publisher>
			<date type="published" when="1994">1994</date>
		</imprint>
		<respStmt>
			<orgName>Wuhan University ; Department of Aerial Surveying and Engineering Geology, Southwest Jiaotong University ; Cartography and Remote Sensing, Institute of Remote Sensing and GIS, Peking University</orgName>
		</respStmt>
	</monogr>
	<note>His research interests include digital image processing and quantitative remote sensing applications. He got bachelor degree in 2003, major in Photogrammetry and Remote Sensing, School of Remote Sensing and Information Engineering. and Ph.D. degree in 1997 major in Atmospheric Physics, Department of Geophysics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
