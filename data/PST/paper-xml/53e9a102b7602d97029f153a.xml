<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Computers and Mathematics with Applications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">R</forename><surname>Oftadeh</surname></persName>
							<email>roftadeh@me.ut.ac.ir</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Mechatronics and Automation</orgName>
								<orgName type="department" key="dep2">School of Mechanical Engineering</orgName>
								<orgName type="institution">University of Tehran</orgName>
								<address>
									<settlement>Tehran</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mahjoob</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Mechatronics and Automation</orgName>
								<orgName type="department" key="dep2">School of Mechanical Engineering</orgName>
								<orgName type="institution">University of Tehran</orgName>
								<address>
									<settlement>Tehran</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">M</forename><surname>Shariatpanahi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Mechatronics and Automation</orgName>
								<orgName type="department" key="dep2">School of Mechanical Engineering</orgName>
								<orgName type="institution">University of Tehran</orgName>
								<address>
									<settlement>Tehran</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Computers and Mathematics with Applications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7CE615B12B310D820684A56E8EAEB4F7</idno>
					<idno type="DOI">10.1016/j.camwa.2010.07.049</idno>
					<note type="submission">Received 17 September 2009 Received in revised form 23 June 2010 Accepted 27 July 2010</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Meta-heuristic algorithm Continuous optimization problems Group hunting</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A novel optimization algorithm is presented, inspired by group hunting of animals such as lions, wolves, and dolphins. Although these hunters have differences in the way of hunting, they are common in that all of them look for a prey in a group. The hunters encircle the prey and gradually tighten the ring of siege until they catch the prey. In addition, each member of the group corrects its position based on its own position and the position of other members. If the prey escapes from the ring, hunters reorganize the group to siege the prey again. Several benchmark numerical optimization problems, constrained and unconstrained, are presented here to demonstrate the effectiveness and robustness of the proposed Hunting Search (HuS) algorithm. The results indicate that the proposed method is a powerful search and optimization technique. It yields better solutions compared to those obtained by some current algorithms when applied to continuous problems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Classical methods often face great difficulties in solving optimization problems that abound in the real world. In order to overcome the shortcomings of traditional mathematical techniques, nature-inspired soft computing algorithms have been introduced.</p><p>Several evolutionary or meta-heuristic algorithms have since been developed which combine rules and randomness mimicking natural phenomena. These phenomena include biological evolutionary processes (e.g., the evolutionary algorithm proposed by Fogel et al. <ref type="bibr" target="#b0">[1]</ref>, De Jong <ref type="bibr" target="#b1">[2]</ref>, and Koza <ref type="bibr" target="#b2">[3]</ref> and the genetic algorithm (GA) proposed by Holland <ref type="bibr" target="#b3">[4]</ref> and Goldberg <ref type="bibr" target="#b4">[5]</ref>), animal behavior (e.g., the tabu search proposed by Glover <ref type="bibr" target="#b5">[6]</ref>), the physical annealing process (e.g., simulated annealing proposed by Kirkpatrick et al. <ref type="bibr" target="#b6">[7]</ref>) and the musical process of searching for a perfect state of harmony (proposed by Geem et al. <ref type="bibr" target="#b7">[8]</ref>, Lee and Geem <ref type="bibr" target="#b8">[9]</ref> and Geem <ref type="bibr" target="#b9">[10]</ref> and proceeded with other researchers <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>).</p><p>Many researchers have recently studied these meta-heuristic algorithms, especially GA-based methods, to solve various optimization problems. However, new heuristic algorithms are needed to solve difficult and complicated real-world problems.</p><p>The method introduced in this paper is a meta-heuristic algorithm which simulates the behavior of animals hunting in a group (lions, wolves, etc.). Group hunters have certain strategies to encircle the prey and catch it. Wolves, for instance, rely on this kind of hunt very much, so they can hunt animals bigger or faster than themselves. They choose one prey and the group gradually moves toward it. They do not stand in the wind such that the prey senses their smell. We employ this idea in constrained problems to avoid forbidden areas. In our algorithm, each of the hunters indicates one solution for a particular problem. Like real animals which hunt in a group, artificial hunters cooperate to find and catch the prey; i.e., the optimum point in our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Hunting search meta-heuristic algorithm</head><p>Meta-heuristic algorithms imitate natural phenomena, e.g. physical annealing in simulated annealing, human memory in a tabu search, and evolution in evolutionary algorithms. A new Hunting Search (HuS) meta-heuristic algorithm is conceptualized here using the hunt process in catching a prey in the group hunting. Cooperation of the members of the group called hunters leads to encircling a prey and catching it (the group's food), similar to the optimization process which results in finding a global solution (a perfect state) as determined by an objective function. The position of each hunter compared to the prey determines its chance of catching the prey. Similarly, the objective function value is determined by the set of values assigned to each decision variable. The new HuS meta-heuristic algorithm is derived based on a model of group hunting of animals when searching for food such as the way in which wolves hunt.</p><p>In continuous optimization problems, the estimation of a solution is carried out by putting values of decision variables into the objective function or fitness function. This evaluates the function value, which includes cost, efficiency, and/or error. Therefore, a model for a continuous optimization problem may be formally defined as follows.</p><p>Definition 2.1. A model of a continuous optimization problem, generally shown as Q = (S, , f ), has the following features.</p><p>• A search space defined over a finite set of continuous decision variables (S).</p><p>• A set of constraints among the variables ( ).</p><p>• An objective function to be minimized (f</p><formula xml:id="formula_0">: S → R + 0 ).</formula><p>The search space (S) is defined as a set of N continuous variables ( Compared to group hunting, in a continuous optimization problem each 'hunter' is replaced with a 'solution' of the problem (or as we call it an 'artificial hunter'). Note that group hunting of animals and our meta-heuristic algorithm have a primary difference. In group hunting of animals (our emphasis is on animals that hunt on land such as wolves and lions), hunters can see the prey or when they hunt at night at least they can sense the smell of the prey and determine its position. In contrast, in optimization problems we have no indication of the optimum solution/point. In group hunting of animals, however, the solution (prey) is dynamic and the hunters (based on the current position of the prey) must correct their position. In optimization problems instead, the optimum solution is static and does not change its position during the search process. In fact, both real and artificial group hunting have their own difficulties. To resemble this dynamics of the hunting process in our algorithm, artificial hunters move towards the leader. The leader is the hunter which has the best position at the current stage (the optimum solution among current solutions at hand). In fact, we assume that the leader has found the optimum point and other members move towards it. If any of them finds a point better than the current leader, it becomes leader in the next stage.</p><formula xml:id="formula_1">x i , i = 1, . . . , N with values v i ∈ D i ⊆ R),</formula><p>Real animals not only gradually move toward the prey but also (based on the position of other hunters and the position of the prey) correct their position. Therefore, in this algorithm, after moving toward the previous leader, the hunters correct their position based on the position of other members. This is accomplished by introducing the 'hunting group consideration rate' (HGCR), which is defined later.</p><p>In addition in the group hunting of real animals, if the prey escapes out of the ring, the hunters organize themselves to encircle the prey again. In the HuS algorithm, the ability will be given to hunters, so they can search out of the ring of siege.</p><p>In the algorithm, if the positions of the hunters/solutions are too close to each other, the group is reorganized to find the optimum point in the next effort.</p><p>Fig. <ref type="figure" target="#fig_0">1</ref> displays the procedure of the Hunting Search algorithm, which consists of the following steps.</p><p>Step 1. Specify the optimization problem and parameters of the algorithm.</p><p>Step 2. Initialize the hunting group (HG).</p><p>Step 3. Move toward the leader.</p><p>Step 4. Correct the positions (cooperation between members).</p><p>Step 5. Reorganize the hunting group.</p><p>Step 6. Repeat Steps 3, 4 and 5 until the termination criterion is satisfied.</p><p>The details follow.</p><p>Step 1. Initialize the optimization problem and algorithm parameters.</p><p>The problem is defined as the model that is presented in Definition 2.1. The HuS algorithm parameters that are required to solve the optimization problem are also specified in this step: hunting group size (number of solution vectors in hunting group HGS), maximum movement toward the leader (MML), and hunting group consideration rate (HGCR), which varies between 0 and 1. The parameters MML and HGCR are parameters that are used to improvise the hunter position (solution vector) that are defined in Steps 3 and 4. Step 2. Initialize the hunting group (HG).</p><p>Based on the number of hunters (HGS), the hunting group matrix is filled with feasible randomly generated solution vectors. The values of objective function are computed and the leader is defined based on the values of objective functions of the hunters.</p><p>Step 3. Moving toward the leader.</p><p>The new hunters' positions (new solution vectors) x = (x 1 , x 2 , . . . , x N ) are generated by moving toward the leader (the hunter that has the best position in the group) as follows:</p><formula xml:id="formula_2">x i = x i + rand × MML × (x L i -x i ).</formula><p>(</p><formula xml:id="formula_3">)<label>1</label></formula><p>The MML is the maximum movement toward the leader, rand is a uniform random number which varies between 0 and 1, and x L i is the position value of the leader for the ith variable. For each hunter, if the movement toward the leader is successful, the hunter stays in its new position. However, if the movement is not successful (its previous position is better than its new position) it comes back to the previous position. With this, we achieve some advantages. First, we do not compare the hunter with the worst hunter in the group, so we allow the weak members to search for other solutions; they may find better solutions (as in a genetic algorithm). Secondly, for prevention from rapid convergence of the group the hunter compares its current position with its previous position; therefore, good positions will not be eliminated.</p><p>The value of parameter MML varies for different problems. It depends on the number of iterations in each epoch, which will be defined in Step 5. The range between 0.05 (for epochs with large number of iterations) and 0.4 (for epochs with small number of iterations) gives the best results, as is shown in the next examples.</p><p>Step 4. Position correction-cooperation between members. In this step, the cooperation between hunters is modeled in order to conduct the 'hunt' more efficiently. After moving toward the leader, hunters (based on other hunter positions and some random factors) choose another position to find better solutions. Hunters do the position correction in two ways: (1) real value correction (2) digital value correction.</p><p>In real value correction, the new hunter's position x = (x 1 , x 2 , . . . , x N ) is generated from HG, based on hunting group considerations or position corrections. For instance, the value of the first design variable for the jth hunter (x j 1 ) for the new vector (new hunter position) can be picked from any value (i.e. real number) in the specified HG (x 1 i , x 2 i , . . . , x HGS i ) or corrected using the HGCR parameter (chosen between 0 and 1). Updating the variable value is thus carried out as follows:</p><formula xml:id="formula_4">x j i ← x j i ∈ {x 1 i , x 2 i , . . . , x HGS i } with probability HGCR x j i = x j i ± Ra with probability (1 -HGCR) i = 1, . . . , N, j = 1, . . . , HGS.<label>(2)</label></formula><p>The parameter HGCR is the probability of choosing one value from the hunting group stored in the HG, and (1 -HGCR) is the probability of doing a position correction. For example, an HGCR of 0.3 indicates that the HuS algorithm will choose the design variable value from hunting group values in the HG with a 30% probability, and doing a position correction with a 70% probability. An HGCR in the range between 0.1 and 0.4 gives better results, as is shown in the examples.</p><p>Ra is an arbitrary distance radius for the continuous design variable, and rand is a uniform number which varies between 0 and 1. Ra can be fixed or reduced during optimization process. Many functions can be chosen for reducing Ra. Some useful functions are plotted in Fig. <ref type="figure" target="#fig_1">2</ref>. The first function uses a fixed decremental amount, which is subtracted from the search Ra after each iteration. This results in a constant rate of Ra reduction. The second function uses a fixed Ra reduction factor (some value less than 1), by which the Ra is multiplied after each generation. This option allows hunters to narrow down their search more rapidly initially, and to spend longer in detailed local solution exploration. The third function uses a similar approach, but instead is more biased towards global exploration. This approach leaves the hunters with more time to investigate the properties of the entire search space, and undergoes rapid convergence on solutions towards the end of the algorithm's life. In the fourth function, the Ra only begins to contract after a certain number of iterations.</p><p>In this paper, an exponential function is used for Ra reduction as follows:</p><formula xml:id="formula_5">Ra(it) = Ra min (max(x i ) -min(x i )) exp   Ln Ra min Ra max × it itm   ,<label>(3)</label></formula><p>where it is the iteration number, max(x i ) and min(x i ) are the maximum or minimum possible value of variable x i , respectively, Ra max and Ra min are the maximum and minimum of relative search radius of the hunter, respectively, and itm is the maximum number of iterations in the optimization process.</p><p>In digital value correction, instead of using real values of each variable, the hunters communicate with each other by the digits of each solution variable. For example, the solution variable with the value of 23.4356 has six meaningful digits. For this solution variable, the hunter chooses a value for the first digit (i.e. 2) based on hunting group considerations or position correction. For HGCR = 0.3, it chooses a digit from the hunting group with a 30% probability and does a position correction with 70% probability. The values for other digits in this solution variable and other variables can be selected in the same manner. Therefore, the kth digit of the ith solution variable is chosen as follows:</p><formula xml:id="formula_6">d j ik ← d j ik ∈ {d 1 ik , d 2 ik , . . . , d HGS ik } with probability HGCR d j ik = d j ik ± a with probability (1 -HGCR) i = 1, . . . , N, j = 1, . . . , HGS, k = 1, . . . , M (number of digits in each variable).<label>(4)</label></formula><p>The value of a can be any number between 1 and 9 or a random variable that generates numbers between 1 and 9. In the numerical examples we set the value of a to 1.</p><p>There are some points that should be considered in digital position correction. In the group consideration, there is a chance that a digit chooses another digit that is invalid (or void) and makes the value of solution variable inadmissible. For example, if the second digit of 423.3423 chooses the similar digit in 2.5678 that is void, this makes the value of solution variable inadmissible. Also, in the position correction, if the kth digit of solution variable is 9 or 0 and then added to or decreased by 1, this makes the value of the solution variable inadmissible (10 or -1). In such cases, the digit simply restores its original value.</p><p>Note that in digital position correction the algorithm must restore a certain number of digits for each solution variable. In the present study, for all numerical examples, the algorithm restores up to eight decimal figures.</p><p>The algorithm can use real value correction, digital value correction or both for cooperation between members. We have used both here. The presented numerical examples showed the effectiveness of this choice.</p><p>After the quality of the new hunter position is determined by evaluating the objective function, the hunter moves to this new position; otherwise it keeps its previous position (similar to the previous step).</p><p>Step 5. Reorganizing the hunting group.</p><p>As the search process continues, there is a chance for the hunters to be trapped in a local minimum (or a local maximum once our goal is to find the maximum). If this happens, the hunters must reorganize themselves to get another opportunity to find the optimum point. The algorithm does this in two independent conditions. If the difference between the values of the objective function for the leader and the worst hunter in the group becomes smaller than a preset constant ( 1 ) and the termination criterion is not satisfied, then the algorithm reorganizes the hunting group for each hunter. Alternatively, after a certain number of searches the hunters reorganize themselves. We have used the second condition in the examples for reorganization. The sequence of searches that end with trapping the group in a local minimum or the certain number of searches is called one epoch. They reorganize as follows. The leader keeps its position and the other hunters randomly choose their positions in the design space by</p><formula xml:id="formula_7">x i = x L i ± rand × (max(x i ) -min(x i )) × α exp(-β × EN),<label>(5)</label></formula><p>where x L i is the position value of the leader for the ith variable. rand is a uniform random number which varies between 0 and 1. max(x i ) and min(x i ) are the maximum and minimum possible values of variable x i , respectively. EN counts the number of times that the group has been trapped until this step (i.e. number of epochs until this step). As the algorithm goes on, the solution gradually converges to the optimum point. Parameters α and β are positive real values. They determine the global convergence rate of the algorithm. Large values of α and small values of β cause the algorithm to converge slowly. This is recommended for large optimization problems or for problems with several local optimums. In contrast, setting small values of α and large values of β makes the algorithm converge more rapidly. This is recommended for small optimization problems with a small number of design variables. By this practice, hunters benefits in four ways. First, they give themselves another opportunity to search the design space. Second, because the leader saves its position, other hunters have a direction to better areas after reorganizing and they do not have to search the whole design space blindly. Third, because the leader saves its position after each epoch, hunters do not miss the best solution they have found during search process. Fourth, and most importantly, as EN increases during search process, the hunters search the design space more locally to find the optimum point.</p><p>As the algorithm proceeds, the solution gradually converges into the optimum point.</p><p>Step 6. Repeat Steps 3-5 until the termination criterion is satisfied.</p><p>In Step 6, the computations are terminated when the termination criterion is satisfied. If not, Steps 3-5 are then repeated. The termination criterion can be defined as the maximum number of searches. Alternatively, if after reorganizing the function for the leader and the worst hunter in the group remains smaller than a preset constant ( 1 ), the search process ends.</p><p>To further elaborate on the HuS meta-heuristic algorithm, consider the following constrained minimization problem:</p><formula xml:id="formula_8">f (x) = (x 2 1 + x 2 -11) 2 + (x 1 + x 2 2 -7) 2 subject to g 1 (x) = 4.84 -(x 1 -0.05) -(x 2 -2.5) 2 ≥ 0 g 2 (x) = x 2 1 + (x 2 -2.5) 2 -4.84 ≥ 0 0 ≤ x 1 ≤ 6, 0 ≤ x 2 ≤ 6.<label>(6)</label></formula><p>This problem, introduced by Deb <ref type="bibr" target="#b12">[13]</ref>, is a minimization problem with two design variables and two inequality constraints, as shown in Fig. <ref type="figure">3</ref>. The unconstrained objective function f (x) has a minimum solution at (3, 2) with a corresponding function value equal to 0. The constrained minimum solution is located in a narrow crescent-shaped region. The HuS parameter values used in this problem are summarized in Table <ref type="table" target="#tab_1">1</ref> (step 1).</p><p>The HG was initially structured with randomly generated solution vectors within the bounds prescribed for this example (i.e., 0 to 6.0) and the leader is defined (Step 2). Next, based on Eq. ( <ref type="formula" target="#formula_3">1</ref>), the hunters move toward the leader, and if their new positions are better than the previous positions, they stay there. Otherwise, they come back to their previous positions (Step 3).</p><p>Then the hunters cooperate with each other to find better positions based on group considerations with a 30% probability and position corrections with a 70% probability (Step 4). After 30 iterations based on Eq. ( <ref type="formula" target="#formula_8">6</ref>), the hunters reorganize themselves (Step 5). In this example, the group can find the minimum point in two epochs. After 60 iterations (1800 function evaluations), the HuS algorithm improvised an optimal solution vector x = (2.246826212191825 2.381870437963585), which has a function value of 13.590841693489994, as shown in Fig. <ref type="figure">4</ref>. Fig. <ref type="figure">4</ref> shows the minimum value convergence history for this constrained function. The HuS best solution was compared to the previous solutions reported in the literature in Table <ref type="table">2</ref>. The optimal design obtained using the HuS algorithm showed a very good agreement with the previous solutions reported in the literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2</head><p>Optimal results of the constrained function represented by Eq. ( <ref type="formula" target="#formula_7">5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods Optimal design variables (x) Constraints</head><p>Objective function value f (x)  The HuS algorithm includes the structure of present meta-heuristic optimization algorithms. It preserves the history of past vectors (HG) similar to the tabu search and the harmony search, and is able to vary the adaptation rate (HGCR) from the beginning to the end of the computations, which resembles simulated annealing. It also considers several vectors simultaneously in a manner similar to the harmony search. However, the difference between the harmony search and the developed HuS algorithm is that in the latter hunters compare their positions only with their previous positions; therefore weak hunters have a chance to find better locations in subsequent iterations, while the harmony search compares each generated solution with all existing solutions and removes the worst solution from harmony memory. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 3</head><p>HuS parameter values for the Griewank function Eq. ( <ref type="formula" target="#formula_9">7</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Examples</head><p>The computational procedures described above have been implemented in a MATLAB computer program on a Pentium4 2.4 GHz computer. In this study, different unconstrained and constrained standard benchmark examples from the literature are presented to demonstrate the efficiency and robustness of the proposed HuS meta-heuristic algorithm. Unconstrained optimization problems are presented in two sets. In these sets, the performance of HuS is compared with five famous evolutionary algorithms through minimization of a high-dimensional Griewank function and other standard benchmark problems available in the literature. Three constrained optimization problems are also included to test the efficiency of the presented algorithm in the optimization of this type of problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Unconstrained function minimization examples-set one</head><p>In this section, the performance of HuS is compared with that of four famous evolutionary algorithms. Genetic Algorithms (GAs) are inspired by biological system's improved fitness through evolution <ref type="bibr" target="#b3">[4]</ref>. Memetic Algorithms (MAs) are inspired by Dawkins' notion of a meme <ref type="bibr" target="#b13">[14]</ref>. Particle Swarm Optimization (PSO) is inspired by the social behavior of a flock of migrating birds trying to reach an unknown destination <ref type="bibr" target="#b14">[15]</ref>. The Shuffled Frog Leaping (SFL) algorithm is inspired by a frog population searching for food and passing their ideas through a shuffling process <ref type="bibr" target="#b15">[16]</ref>. The results are compared with those reported in <ref type="bibr" target="#b16">[17]</ref>.</p><p>To have a reasonable comparison between HuS and the mentioned optimization algorithms, the simulations are performed for a high-dimension Griewank function (d = 10, 20, 50, and 100). The function is represented by</p><formula xml:id="formula_9">f GR ( x) = d i=1 x 2 i 4000 - n i=1 cos x i √ i + 1 -511 ≤ x i ≤ 512 (d = 10, 20, 50, 100).<label>(7)</label></formula><p>A schematic of a two-dimensional Griewank function is given in Fig. <ref type="figure" target="#fig_3">5</ref>. As can be observed, this function has many widespread local minima but it has only one global minimum at x i = 0, i = 1 : n with f (x) = 0. The HuS parameter values used in this problem are summarized in Table <ref type="table">3</ref>.</p><p>As in <ref type="bibr" target="#b16">[17]</ref>, 20 trial runs were performed for each dimension with the two (following) stopping criteria: (1) the value of the best objective function found by HuS reached a target value of 0.05 or less; (2) the objective function value did not improve in ten consecutive iterations. Fig. <ref type="figure">6</ref> shows the best and the worst history convergence for each dimension. Surprisingly, the HuS can found the optimum point for d = 20 in a lower number of iterations than for d = 10. Table <ref type="table" target="#tab_3">4</ref> presents results obtained by HuS and other compared algorithms. Reported is the percentage of success (% Success), mean solution (Mean S), mean number of function evaluations (Mean NF) and Processing time to reach the optimum (Time). Note that, for the compared algorithms, the mean number of function evaluation values are not available.</p><p>Obviously, HuS outperforms the other compared algorithms in terms of percentage of success and mean solution. The comparison of processing time may not be a fair comparison because the processor/hardware used in this study is different from that used in <ref type="bibr" target="#b16">[17]</ref>. Unfortunately, the authors in <ref type="bibr" target="#b16">[17]</ref> did not mention the number of function evaluations for further comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Unconstrained function minimization examples-set two</head><p>The list of test functions on which we ran HuS, together with the number of dimensions used and the initialization interval, is presented in Table <ref type="table">5</ref>. Figures of the test functions used can be found in <ref type="bibr" target="#b17">[18]</ref>.</p><p>Following the test set-up described in the literature, we performed 100 independent runs, with the following stopping criterion (as used by the other algorithms in this comparison):</p><formula xml:id="formula_10">|f -f * | &lt; 1 f + 2 , (<label>8</label></formula><formula xml:id="formula_11">)</formula><p>where f is the value of the best solution found by HuS, f * is the optimal value for the given test problem, and 1 and 2 are respectively the relative and absolute errors. For all the test simulations we have used 1 = 2 = 10 -4 following the values reported in the literature.</p><p>In this section, we compare our method with four other meta-heuristic optimization algorithms. These methods have some kind of cooperation between members similar to our method. They are optimization algorithms inspired by the foraging behavior of ants: ACO extended to continuous domains (ACO R ) <ref type="bibr" target="#b18">[19]</ref>, continuous ACO (CACO) <ref type="bibr" target="#b19">[20]</ref>, the API algorithm <ref type="bibr" target="#b20">[21]</ref>, and Continuous Interacting Ant Colony (CIAC) <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5</head><p>Test functions used for comparing HuS to other mentioned algorithms Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Function</head><p>Formula</p><formula xml:id="formula_12">B 2 x ∈ [-100, 100] d , n = d f B2 ( x) = x 2 1 + 2x 2 2 -3 10 cos(3π x 1 ) -2 5 cos(4π x 2 ) + 7 10</formula><p>Goldstein and Price (GP</p><formula xml:id="formula_13">) x ∈ [-2, 2] d , d = 2 f GP ( x) = (1 + (x 1 + x 2 + 1) 2 (19 -14x 1 + 13x 2 1 -14x 2 + 6x 1 x 2 + 3x 2 2 )) • (30 + (2x 1 -3x 2 ) 2 (18 - 32x 1 + 12x 2 1 -48x 2 -36x 1 x 2 + 27x 2 2 )) Martin and Gaddy (MG) x ∈ [-20, 20] d , d = 2 f MG ( x) = (x 1 -x 2 ) 2 + x 1 +x 2 -10 3 2 Rosenbrock (R n ) x ∈ [-5, 10] d , d = 2 f Rn ( x) = d-1 i=1 100(x 2 i -x i+1 ) + (x i -1) 2</formula><p>Griewangk (GR d ) x ∈ [-5.12, 5.12] d , d = 10</p><formula xml:id="formula_14">f GR d ( x) = 1 10 + d i=1 x 2 i 4000 -n i=1 cos x i √ i + 1 -1</formula><p>Sphere model (SM) x ∈ [-5.12,  Table <ref type="table" target="#tab_4">6</ref> summarizes the HuS parameter values used in this problem. Table <ref type="table" target="#tab_5">7</ref> presents the results obtained by HuS and other compared algorithms. Reported is the percentage of success (% Success) and mean number of function evaluations (Mean NF).</p><p>When compared with other algorithms, HuS is the winner in almost all cases in respect of percentage of success and mean number of function evaluations. In fact, HuS has proved to be more effective. Only for the Rosenbrock function does ACO R perform better in respect of mean number of function evaluations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Constrained function minimization examples</head><p>In this section, three constrained optimization problems from the literature are presented to show the efficiency of the HuS in handling this type of problem. Table <ref type="table" target="#tab_6">8</ref> summarizes the HuS parameter values used in this section. </p><formula xml:id="formula_15">= (x 1 -2) 2 + (x 2 -1) 2</formula><p>subject to,</p><formula xml:id="formula_16">g 1 (x) = x 1 -2x 2 + 1 = 0 g 2 (x) = -x 2 1 /4 -x 2 2 + 1 ≥ 0 -10 ≤ x 1 ≤ 10 -10 ≤ x 2 ≤ 10.<label>(9)</label></formula><p>This problem was originally introduced by Braken and McCormick <ref type="bibr" target="#b21">[22]</ref>. The optimum solution using the HuS algorithm is obtained at x * = (0.82288, 0.91144) with an objective function value equal to f * (x) = 1.3935. Homaifar et al. <ref type="bibr" target="#b22">[23]</ref> solved the problem using GA. Fogel <ref type="bibr" target="#b23">[24]</ref> also solved it using evolutionary programming. Lee and Geem <ref type="bibr" target="#b8">[9]</ref> used the harmony search algorithm to find the optimum point. After 3750 searches (5 epoch and 125 movement toward the leader), the HuS algorithm found the optimum vector. Table <ref type="table">9</ref> shows the best solution vector from the HuS algorithm and also the results obtained from the compared algorithms. The best vector found using the HuS meta-heuristic algorithm was x = (0.8228 0.9114), and the corresponding objective function value was 1.3935. As can be observed, the HuS algorithm has reached a better solution compared to the other three in terms of the objective function values and the constraint accuracy. subject to,</p><formula xml:id="formula_17">g 1 (x) = 127 -2x 2 1 -3x 4 2 -x 3 -4x 2 4 -5x 5 ≥ 0 g 2 (x) = 282 -7x 1 -3x 2 -10x 2 3 -x 4 + x 5 ≥ 0 g 3 (x) = 196 -23x 1 -x 2 2 -6x 2 6 + 8x 7 ≥ 0 g 4 (x) = -4x 2 1 -x 2 2 + 3x 1 x 2 -2x 2 3 -5x 6 + 11x 7 ≥ 0 -10 ≤ x i ≤ 10 (i = 1 -7). (<label>10</label></formula><formula xml:id="formula_18">)</formula><p>This constrained problem has seven design variables, and four constraint functions. After 8 epochs (approximately 22 000 searches) the optimal solution was obtained at x * = (2.330875, 1.951370, -0.474593, 4.365553, -0.037936, 1.594065) with the objective function value equal to f (x * ) = 680.6300771. For this problem, no constraints were violated. Table <ref type="table" target="#tab_1">10</ref> presents the results obtained by HuS and other compared algorithms. The solution obtained by the HuS algorithm is comparable with the previous solution reported in the literature and it take a smaller number of function evaluations to find the optimum point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3.">Constrained function</head><formula xml:id="formula_19">3 f (x) = x 1 + x 2 + x 3 subject to, g 1 (x) = 1 -0.0025(x 4 + x 6 ) ≥ 0 g 2 (x) = 1 -0.0025(x 5 + x 7 -x 4 ) ≥ 0 g 3 (x) = 1 -0.01(x 8 -x 5 ) ≥ 0 g 4 (x) = x 1 x 6 -833.33252x 4 -100x 1 + 83333.333 ≥ 0 g 5 (x) = x 2 x 7 -1250x 5 -x 2 x 4 + 1250x 4 ≥ 0 g 6 (x) = x 3 x 8 -x 3 x 5 -2500x 5 -11250000 ≥ 0 100 ≤ x 1 ≤ 10000, 1000 ≤ x 2 x 3 ≤ 10000, 10 ≤ x i ≤ 1000 (i = 4 -8).<label>(11)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 9</head><p>Optimal results for constrained function 1 Eq. ( <ref type="formula" target="#formula_16">9</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimal design variables (x) Constraints</head><p>Objective function value f (x) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 11</head><p>Optimal results for constrained function 3 Eq. ( <ref type="formula" target="#formula_19">11</ref>).</p><p>Optimal design variables x, f (x * ) and number of searches Michalewicz <ref type="bibr" target="#b24">[25]</ref> Deb <ref type="bibr" target="#b12">[13]</ref> Lee and Geem <ref type="bibr" target="#b8">[9]</ref> HuS (present study) In this problem there are eight design variables, six nonlinear constraints and 14 boundary conditions. The optimal solution is obtained at x * = (522.806838, 1380.644472, 5147.870997, 177.101116, 294.085207, 222.898280, 283.015889, 394.085207), with corresponding objective function value equal to f (x * ) = 7051.322306 after approximately 52 000 function evaluations (12 epochs). Table <ref type="table" target="#tab_1">11</ref> compares the best solution of constrained function 3 obtained using the HuS algorithm with the previous best solution reported in the literature. It can be seen from Table <ref type="table" target="#tab_1">11</ref> that the result obtained using the HuS algorithm is better than feasible solutions previously reported with respect to the objective function value and the number of function evaluations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>A new meta-heuristic algorithm has been developed. The Hunting Search (HuS) meta-heuristic optimization algorithm was conceptualized using the strategy of group hunters in catching their prey. Compared to gradient-based mathematical optimization algorithms, the HuS algorithm imposes fewer mathematical requirements and does not require initial value settings of the decision variables. In addition, the HuS algorithm uses stochastic searches; therefore, derivative information is unnecessary.</p><p>Selected benchmark optimization problems were solved to demonstrate the effectiveness and robustness of the new algorithm compared to other optimization methods. The test cases showed that the HuS algorithm is a global search algorithm that can be easily applied to various optimization problems. The results obtained using the HuS algorithm would yield better solutions than those obtained using other algorithms. In addition, in constrained optimization problems, hunters have power of orientation in the design space (movement toward leader); therefore, they can escape from forbidden areas and find feasible areas quickly, as real hunters do.</p><p>Further work is still needed to solve more complex and real optimization problems such as engineering problems. The algorithm can also be generalized for solving discrete and combinatorial optimization problems such as the traveling salesman problem and timetabling.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Optimization procedure of the Hunting Search algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Ra reduction: (a) constant reduction; (b), (c) exponential decay; (d) Ra begins to reduce after a certain number of searches.</figDesc><graphic coords="4,96.03,59.91,366.54,81.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .Fig. 4 .</head><label>34</label><figDesc>Fig. 3. Constrained function represented by Eq. (5). Green circles indicate hunters' initial positions. Blue circles indicate hunters' positions after epoch 1. The leader in each of these stages is represented by a triangle. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</figDesc><graphic coords="6,161.46,163.30,225.36,222.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Schematic of a Griewank function with different resolutions represented by Eq. (7). Left: the full definition range of the function. Right: range around the optimum point.</figDesc><graphic coords="7,68.90,53.09,411.54,130.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Parameter Value Problem dimension (d) 10, 20, 50, 100 Number of epochs (NE) 3 (d = 10, 20), 5 (d = 50), 10 (d = 100) Iteration per epoch (IE) 50 Hunting group size (HGS) 10 Maximum movement toward leader (MML) 0.3 Hunting group consideration rate (HGCR) 0.3 Ra max , Ra min 10 -2 , 5 × 10 -6 Reorganization parameters -α, β 0.05, -0.5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>where N is the number of design variables. A solution s ∈ S which satisfies all the constraints in the set is a feasible solution. Q is called an unconstrained problem if the set is empty; otherwise, it is called a constrained problem. A solution s</figDesc><table /><note><p>* ∈ S is called a global minimum if and only if f (s * ) ≤ f (s) ∀s ∈ S. Solving a continuous optimization problem requires at least one global minimum.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>HuS parameter values for constrained minimization problem Eq. (6).</figDesc><table><row><cell>Parameter</cell><cell>Value</cell></row><row><cell>Number of epochs (NE)</cell><cell>2</cell></row><row><cell>Iteration per epoch (IE)</cell><cell>30</cell></row><row><cell>Hunting group size (HGS)</cell><cell>10</cell></row><row><cell>Maximum movement toward leader (MML)</cell><cell>0.3</cell></row><row><cell>Hunting group consideration rate (HGCR)</cell><cell>0.3</cell></row><row><cell>Ra max , Ra min</cell><cell>1e-2, 1e-7</cell></row><row><cell>Reorganization parameters -α, β</cell><cell>0.1, -1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc>Comparative results of a high-dimensional Griewank function Eq. (7).</figDesc><table><row><cell>Algorithm</cell><cell>d = 10</cell><cell></cell><cell></cell><cell></cell><cell>d = 20</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>% Success</cell><cell>Mean S</cell><cell>Mean NF</cell><cell>Time (s)</cell><cell>% Success</cell><cell>Mean S</cell><cell>Mean NF</cell><cell>Time (s)</cell></row><row><cell>HuS</cell><cell>100</cell><cell>0.0471</cell><cell>3166</cell><cell>0.8</cell><cell>100</cell><cell>0.0486</cell><cell>2959</cell><cell>1.3</cell></row><row><cell>GAs (Evolver) [17]</cell><cell>50</cell><cell>0.06</cell><cell>-</cell><cell>312</cell><cell>30</cell><cell>0.097</cell><cell>-</cell><cell>∼1000</cell></row><row><cell>MAs [17]</cell><cell>90</cell><cell>0.014</cell><cell>-</cell><cell>∼40</cell><cell>100</cell><cell>0.013</cell><cell>-</cell><cell>∼100</cell></row><row><cell>PSO [17]</cell><cell>30</cell><cell>0.093</cell><cell>-</cell><cell>∼11</cell><cell>80</cell><cell>0.081</cell><cell>-</cell><cell>∼20</cell></row><row><cell>SFL [17]</cell><cell>50</cell><cell>0.08</cell><cell>-</cell><cell>∼3</cell><cell>70</cell><cell>0.063</cell><cell>-</cell><cell>∼11</cell></row><row><cell>Algorithm</cell><cell>d = 50</cell><cell></cell><cell></cell><cell></cell><cell>d = 100</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>% Success</cell><cell>Mean S</cell><cell>Mean NF</cell><cell>Time (s)</cell><cell>% Success</cell><cell>Mean S</cell><cell>Mean NF</cell><cell>Time (s)</cell></row><row><cell>HuS</cell><cell>100</cell><cell>0.0480</cell><cell>5515</cell><cell>3.7</cell><cell>100</cell><cell>0.0481</cell><cell>10 029</cell><cell>11.5</cell></row><row><cell>GAs (Evolver) [17]</cell><cell>10</cell><cell>0.161</cell><cell>-</cell><cell>∼2100</cell><cell>0</cell><cell>0.432</cell><cell>-</cell><cell>2427</cell></row><row><cell>MAs [17]</cell><cell>100</cell><cell>0.011</cell><cell>-</cell><cell>∼180</cell><cell>100</cell><cell>0.009</cell><cell>-</cell><cell>428</cell></row><row><cell>PSO [17]</cell><cell>100</cell><cell>0.011</cell><cell>-</cell><cell>∼40</cell><cell>100</cell><cell>0.011</cell><cell>-</cell><cell>∼300</cell></row><row><cell>SFL [17]</cell><cell>90</cell><cell>0.049</cell><cell>-</cell><cell>∼30</cell><cell>100</cell><cell>0.019</cell><cell>-</cell><cell></cell></row></table><note><p>∼70 Fig. 6. Best/worst convergence history of a high-dimensional Griewank function (d = 10, 20, 50, 100).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6</head><label>6</label><figDesc><ref type="bibr" target="#b4">5</ref>.12] d , d = 6 f SM ( x) = d HuS parameter values for unconstrained problems of Section 3.2.</figDesc><table><row><cell>i=1 x 2 i</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7</head><label>7</label><figDesc>Simulation results of the unconstrained problems of Section 3.2.</figDesc><table><row><cell>Algorithm</cell><cell>Rosenbrock (R 2 )</cell><cell></cell><cell>Griewangk (GR 10 )</cell><cell></cell><cell>Goldstein and Price</cell><cell></cell></row><row><cell></cell><cell>% Success</cell><cell>Mean NF</cell><cell>% Success</cell><cell>Mean NF</cell><cell>% Success</cell><cell>Mean NF</cell></row><row><cell>HuS</cell><cell>100</cell><cell>1 423</cell><cell>84</cell><cell>1 328</cell><cell>100</cell><cell>368</cell></row><row><cell>ACO R [19]</cell><cell>100</cell><cell>820</cell><cell>61</cell><cell>1 390</cell><cell>100</cell><cell>384</cell></row><row><cell>CIAC [18]</cell><cell>100</cell><cell>11 480</cell><cell>52</cell><cell>50 000</cell><cell>56</cell><cell>23 420</cell></row><row><cell>API [21]</cell><cell>100</cell><cell>9 840</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>CACO [20]</cell><cell>100</cell><cell>6 800</cell><cell>100</cell><cell>50 000</cell><cell>100</cell><cell>5 370</cell></row><row><cell>Algorithm</cell><cell>Martin and Gaddy</cell><cell></cell><cell>B 2</cell><cell></cell><cell>Sphere</cell><cell></cell></row><row><cell></cell><cell>% Success</cell><cell>Mean NF</cell><cell>% Success</cell><cell>Mean NF</cell><cell>% Success</cell><cell>Mean NF</cell></row><row><cell>HuS</cell><cell>100</cell><cell>315</cell><cell>100</cell><cell>327</cell><cell>100</cell><cell>323</cell></row><row><cell>ACO R [19]</cell><cell>100</cell><cell>345</cell><cell>100</cell><cell>544</cell><cell>100</cell><cell>781</cell></row><row><cell>CIAC [18]</cell><cell>20</cell><cell>11 730</cell><cell>100</cell><cell>11 960</cell><cell>100</cell><cell>50 000</cell></row><row><cell>API [21]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>100</cell><cell>10 150</cell></row><row><cell>CACO [20]</cell><cell>100</cell><cell>1 725</cell><cell>-</cell><cell>-</cell><cell>100</cell><cell>21 860</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8</head><label>8</label><figDesc>HuS parameter values for constrained problems of Section 3.3.</figDesc><table><row><cell>Parameter</cell><cell>Value</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Constrained function 1</cell><cell>Constrained function 2</cell><cell>Constrained function 3</cell></row><row><cell>Number of epochs (NE)</cell><cell>5</cell><cell>8</cell><cell>12</cell></row><row><cell>Iteration per epoch (IE)</cell><cell>25</cell><cell>100</cell><cell>150</cell></row><row><cell>Hunting group size (HGS)</cell><cell>10</cell><cell>10</cell><cell>10</cell></row><row><cell>Maximum movement toward leader (MML)</cell><cell>0.3</cell><cell>0.3</cell><cell>0.2</cell></row><row><cell>Hunting group consideration rate (HGCR)</cell><cell>0.3</cell><cell>0.3</cell><cell>0.3</cell></row><row><cell>Ra max , Ra min</cell><cell>10 -2 , 10 -4</cell><cell>10 -2 , 10 -5</cell><cell>10 -2 , 10 -4</cell></row><row><cell>Reorganization parameters -α, β</cell><cell>0.01, -1</cell><cell>0.01, -0.5</cell><cell>0.05, -0.05</cell></row><row><cell>3.3.1. Constrained function 1</cell><cell></cell><cell></cell><cell></cell></row><row><cell>fx</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Walsh</surname></persName>
		</author>
		<title level="m">Artificial Intelligence through Simulated Evolution</title>
		<meeting><address><addrLine>Chichester, UK</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley</publisher>
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Analysis of the behavior of a class of genetic adaptive systems</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">De</forename><surname>Jong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<pubPlace>Ann Arbor, MI</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Michigan</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Genetic programming: a paradigm for genetically breeding populations of computer programs to solve problems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Koza</surname></persName>
		</author>
		<idno>Rep. No. STAN-CS-90-1314</idno>
		<imprint>
			<date type="published" when="1990">1990</date>
			<pubPlace>Stanford University, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Adaptation in Natural and Artificial Systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Holland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>University of Michigan Press</publisher>
			<pubPlace>Ann Arbor, MI</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<title level="m">Genetic Algorithms in Search, Optimization and Machine Learning</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison Wesley</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Heuristic for integer programming using surrogate constraints</title>
		<author>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decis. Sci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="156" to="166" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Optimization by simulated annealing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gelatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vecchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="issue">4598</biblScope>
			<biblScope unit="page" from="671" to="680" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A new heuristic optimization algorithm: harmony search</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">W</forename><surname>Geem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">V</forename><surname>Loganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Simulation</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="60" to="68" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A new meta-heuristic algorithm for continues engineering optimization: harmony search theory and practice</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">W</forename><surname>Geem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Appl. Mech. Engrg</title>
		<imprint>
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page" from="3902" to="3933" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Novel derivative of harmony search algorithm for discrete design variables</title>
		<author>
			<persName><forename type="first">Zong</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geem</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">199</biblScope>
			<biblScope unit="page" from="223" to="230" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An improved harmony search algorithm for solving optimization problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mahdavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fesanghary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Damangir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">188</biblScope>
			<biblScope unit="page" from="1567" to="1579" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Global-best harmony search</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Mahamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehrdad</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName><surname>Mahdavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">198</biblScope>
			<biblScope unit="page" from="643" to="656" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An efficient constraint handling method for genetic algorithms</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Appl. Mech. Engrg</title>
		<imprint>
			<biblScope unit="volume">186</biblScope>
			<biblScope unit="page" from="311" to="338" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">The Selfish Gene</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dawkins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976">1976</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Neural Networks</title>
		<meeting>the IEEE International Conference on Neural Networks<address><addrLine>Perth, Australia, IEEE Service Center, Piscataway, NJ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Optimal design of water distribution network using shuffled complex evolution</title>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Liong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md</forename><surname>Atiquzzaman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Inst. Eng. Singap</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="93" to="107" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Comparison among five evolutionary-based optimization algorithms</title>
		<author>
			<persName><forename type="first">Emad</forename><surname>Elbeltagia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tarek</forename><surname>Hegazyb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Griersonb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Eng. Inf</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="43" to="53" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Continuous interacting ant colony algorithm based on dense hierarchy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dréo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Siarry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Gener. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="841" to="856" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Ant colony optimization for continuous domains</title>
		<author>
			<persName><forename type="first">Krzysztof</forename><surname>Socha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Dorigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European J. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page" from="1155" to="1173" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The ant colony metaphor for searching continuous design spaces</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bilchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">C</forename><surname>Parmee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AISB Workshop on Evolutionary Computation</title>
		<title level="s">Lecture Notes in Comput. Sci.</title>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Fogarty</surname></persName>
		</editor>
		<meeting>the AISB Workshop on Evolutionary Computation<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">993</biblScope>
			<biblScope unit="page" from="25" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On how pachycondyla apicalis ants suggest a new search algorithm</title>
		<author>
			<persName><forename type="first">N</forename><surname>Monmarché</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Venturini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Slimane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Gener. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="937" to="946" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Bracken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Mccormick</surname></persName>
		</author>
		<title level="m">Selected Applications of Nonlinear Programming</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Constrained optimization via genetic algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Homaifar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-V</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Simulation</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="242" to="254" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A comparison of evolutionary programming and genetic algorithms on selected constrained optimization problems</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Fogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Simulation</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="399" to="406" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Genetic algorithms, numerical optimization, and constraints</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Conference on Genetic Algorithms</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Esheman</surname></persName>
		</editor>
		<meeting>the Sixth International Conference on Genetic Algorithms<address><addrLine>San Mateo</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kauffman</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="151" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Hybridizing harmony search algorithm with sequential quadratic programming for engineering optimization problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fesanghary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mahdavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Minary-Jolandan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Alizadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Appl. Mech. Engrg</title>
		<imprint>
			<biblScope unit="volume">197</biblScope>
			<biblScope unit="page" from="3080" to="3091" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
