<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PinnerFormer: Sequence Modeling for User Representation at Pinterest</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-05-09">9 May 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nikil</forename><surname>Pancha</surname></persName>
							<email>npancha@pinterest.com</email>
							<affiliation key="aff0">
								<address>
									<settlement>San Francisco</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Zhai</surname></persName>
							<email>andrew@pinterest.com</email>
							<affiliation key="aff1">
								<address>
									<settlement>San Francisco</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Stanford University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Charles</forename><surname>Rosenberg</surname></persName>
							<email>crosenberg@pinterest.com</email>
							<affiliation key="aff3">
								<address>
									<settlement>San Francisco</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">PinnerFormer: Sequence Modeling for User Representation at Pinterest</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-05-09">9 May 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2205.04507v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS</term>
					<term>Information systems ? Recommender systems; Personalization Representation Learning</term>
					<term>Multi-Task Learning</term>
					<term>Personalization</term>
					<term>Recommender Systems</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Sequential models have become increasingly popular in powering personalized recommendation systems over the past several years. These approaches traditionally model a user's actions on a website as a sequence to predict the user's next action. While theoretically simplistic, these models are quite challenging to deploy in production, commonly requiring streaming infrastructure to reflect the latest user activity and potentially managing mutable data for encoding a user's hidden state. Here we introduce PinnerFormer, a user representation trained to predict a user's future long-term engagement using a sequential model of a user's recent actions. Unlike prior approaches, we adapt our modeling to a batch infrastructure via our new dense all-action loss, modeling long-term future actions instead of next action prediction. We show that by doing so, we significantly close the gap between batch user embeddings that are generated once a day and realtime user embeddings generated whenever a user takes an action. We describe our design decisions via extensive offline experimentation and ablations and validate the efficacy of our approach in A/B experiments showing substantial improvements in Pinterest's user retention and engagement when comparing PinnerFormer against our previous user representation. PinnerFormer is deployed in production as of Fall 2021.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Over 400M users use Pinterest each month to discover ideas and inspiration from our content corpus of billions of Pins. A Pin starts with an image and often includes text, a web link, and a board that connects the individual Pin to a user curated collection of pins. Inspiration is the key to Pinterest and facilitated mainly through our search and recommendation systems, allowing users to find content through (a) Homefeed, our personalized recommendation product, (b) Related Pins, recommendations contextual to a query Pin, and (c) Search, recommendations relevant to a user text query. Users give feedback through interactions such as saving Pins to boards (Repin), clicking through to the underlying link, zooming in on one Pin (close-up), hiding irrelevant content, and more. To achieve our mission of bringing everyone the inspiration to create a life they love, we need to personalize our content with our user's interests and context, taking into consideration feedback a user has given on their Pinterest journey; i.e., we need a strong representation of our users.</p><p>Learning user embeddings (representations) has become an increasingly popular method of improving recommendations. Such embeddings have been adopted to power ranking and candidate generation in industry, and are used to power personalized recommendations across YouTube <ref type="bibr" target="#b5">[6]</ref>, Google Play <ref type="bibr" target="#b25">[26]</ref>, Airbnb search <ref type="bibr" target="#b7">[8]</ref>, JD.com search <ref type="bibr" target="#b29">[30]</ref>, Alibaba <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b17">18]</ref>, and more. In addition to work on learning personalized embeddings, there is a body of work focused on directly building ranking models using sequential information <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b30">31]</ref>, enabling personalization of recommendations based on a user's recent engagement.</p><p>User behavior on websites tends to be sequential in nature; actions can be ordered by the time at which they are taken, which naturally leads to sequential modeling methods. Various methods have been proposed to predict future engagement based on users' sequences of historical interactions <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref>. More recent works have applied various deep learning models, including recurrent neural networks (RNNs) and transformers for such sequential recommendations and obtained promising results <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b28">29]</ref>. Sequential models traditionally focus on a realtime setting, aiming to predict a user's next action or engagement from all actions leading up to that point.</p><p>In practice, there are two key challenges in deploying existing sequence modeling approaches to large web-scale applications: (a) cost of computation, and (b) infrastructure complexity. Existing sequence modeling approaches broadly fall into two categories: stateless models, and stateful models. Stateless models may have high computational cost, as an embedding must be computed from scratch after every action a user takes, while stateful models require robust reliable streaming infrastructure to handle potential errors or data corruption in the model's state for a given user <ref type="bibr" target="#b17">[18]</ref>.</p><p>Here we present PinnerFormer, an end-to-end learned user representation that has been deployed in production at Pinterest. Similar to prior work on sequential user modeling, Pinner-Former directly learns a representation based on a user's past pin engagement. We propose a dense all action loss, which allows our embedding to capture a user's longer-term interests, rather than only predicting the next action. This allows our embedding to be computed in an offline, batch setting, and simplifies infrastructure considerably.</p><p>We also address the infrastructure complexity challenge that at Pinterest manifests in the following way: there are tens of ranking models that could benefit from personalization, but developing a custom solution for each one is not scalable. Rather than producing one user embedding for each model (which would increase complexity), we choose to invest in developing a single high quality user embedding that can be used for many downstream tasks. Although performance on a specific task may be sacrificed in some cases, the complexity tradeoff makes a shared embedding favorable for the majority of use cases.</p><p>We evaluate PinnerFormer in offline as well as online A/B experiments. In offline experiments, we show that this training objective nearly halves the gap in performance between a model inferred daily and a model inferred in realtime, and reflects a user's longerterm interests better than other approaches. Then, we demonstrate the utility of PinnerFormer as a feature, demonstrating that it enables significant online gains when used as a feature in multiple ranking models across different domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">DESIGN CHOICES</head><p>We begin by discussing key design choices in PinnerFormer.</p><p>Design Choice 1: Single vs. multiple embeddings for a single user. Most approaches to generating user representations produce a single embedding <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b28">29]</ref>, but some focus on learning a fixed or variable number of user embeddings <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b23">24]</ref>. In our previous user representation, PinnerSage, we made the decision to allow for a variable, potentially large number of embeddings, allowing the model to explicitly represent a user's varied interests <ref type="bibr" target="#b16">[17]</ref>.</p><p>Although using multiple embeddings allows for a model to more explicitly capture user interests and works well for retrieval, this can lead to issues when used in downstream models: storing 20+ 256d float16 embeddings in training data does not scale well, especially when datasets may contain billions of rows, as they do for ranking models. Separately, this also increases cost of model training and inference; processing 5000+ floating point numbers can introduce nontrivial latency, especially if they are transformed before aggregation. At training time, large examples can also increase the time taken to load data. To avoid these issues, when using PinnerSage in ranking models we would typically use a weighted aggregation of a user's embeddings as the final user representation. Because we wish for PinnerFormer to be easily usable as a feature, we produce a single embedding that captures a user's interests, allowing for painless use in downstream models. In offline evaluations, we show that our single embedding is able to reflect a user's longer-term interests better than PinnerSage, while requiring a fraction of the storage.</p><p>Design Choice 2: Real-time vs. Offline inference. Most prior work on sequential user modeling focuses on models that operate in realtime or near realtime. In practice, this leads to at least one of the following:</p><p>? High computational cost: for every action the user takes, the system must fetch all events in a user's history and frequently infer a potentially complex model ? High infrastructure complexity: a user's hidden state or embedding can be incrementally updated, but this requires a robust system to recover and warm up the model's state in the case of any data corruption <ref type="bibr" target="#b17">[18]</ref> On Pinterest, a user may take tens or hundreds of actions in a day, so a model that updates a user's embedding at most once each day only requires a small fraction of the computational resources of a comparably-sized realtime model. In offline evaluations, we demonstrate that our loss formulation substantially decreases the gap between realtime and daily-inferred models, and in A/B experiments, we show PinnerFormer greatly improves performance of downstream ranking models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OUR APPROACH: PINNERFORMER</head><p>In this section, we present PinnerFormer, which has been used in production at Pinterest since Fall 2021, describing both our model (depicted in Figure <ref type="figure" target="#fig_1">1</ref>) and how it is deployed.</p><p>We begin with a corpus of Pins P = {? 1 , ? 2 , . . . , ? ? }, where ? is large, on the order of billions, and a set of users U = {? 1 , ? 2 , . . .}, where |U| &gt; 500M. For each Pin in the corpus, we have a Pin-Sage <ref type="bibr" target="#b27">[28]</ref> embedding ? ? ? R 256 , which is an aggregation of visual, text, and engagement information for a Pin ? ? . For each user, we have a sequence of actions a user has taken on the site, A ? = {? 1 , ? 2 , . . . , ? ? }, ordered ascending by timestamp. In this work, we limit this sequence of actions to users' engagements with Pins, including Pin saves, clicks, reactions, and comments over the past year. Based on this assumption, an action can then be represented by a PinSage embedding, as well as some metadata about the action. In practice, ? may be very large for a given user, on the order of thousands or tens of thousands for some users, so we compute a user's embedding using their ? most recent actions.</p><p>Given these definitions, we aim to learn a user representation ? : U ? ? R ? , that is compatible with some Pin representation ? : P ? ? R ? under cosine similarity. We learn ? and ? jointly, using the sequence of actions A ? as the only input features to the model, and restricting to only the latest ?.</p><p>In a user's complete action sequence, there may be many types of actions, some of which are good (e.g. a long click), and and some of which are neutral or negative (e.g. a hide or short click). In this work, we focus learning representations to predict positive engagement, which we define as a Pin save ("Repin"), a Pin close-up lasting over 10s ("Closeup"), or a long clickthrough (&gt;10s) to the link underlying a Pin ("Click"). We only treat engagement on Homefeed as positive; on surfaces such as Search or Related Pins, the query provides substantial context, while on Homefeed, the user provides the primary context.</p><p>Our primary objective is to learn a model that is able to predict a user's positive future engagement over a 14 day time window after the generation of their embedding, rather than a traditional sequence modeling task, where the embedding would only predict the next action taken. In other words, our goal is to learn embeddings ? ? and ? ? such that if ? (? ? , ? ? ) &lt; ? (? ? , ? ? ), then ? ? is more likely to be positively engaged with by the user represented by ? ?   than ? ? over the 14 days after ? ? is generated. We choose this range of 14 days for tractability, and assume that actions a user takes over the course of two weeks sufficiently are representative of a user's longer-term interests. Figure <ref type="figure" target="#fig_1">1</ref> illustrates the PinnerFormer architecture, and below we expand on each component in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Feature Encoding</head><p>For each action in a user's sequence, we have a PinSage embedding (256-dimensional) <ref type="bibr" target="#b27">[28]</ref> and metadata features: action type, surface, timestamp, and action duration. We use small, learnable embedding tables to encode action type and surface, our two categorical features, and drop sequence elements with out of vocabulary terms for either of these two features. We encode action duration with a single scalar value, log(????????).</p><p>To represent the time an action occurred, we use 2 derived values in addition to the raw absolute timestamp: the time since the latest action a user has taken, and the time gap between actions. For each of these time features, we follow the common practice of encoding time using sine and cosine transformations with various periods in a manner similar to Time2vec <ref type="bibr" target="#b10">[11]</ref>, but with ? fixed periods, rather than learned periods, and a logarithmic transformation of time, rather than a linear one. This produces 2? + 1 features (2? from periodic transofmrations of the timestamp). 1  All features are concatenated into a single vector, resulting in an input vector of dimension ? in . The representation corresponding to action ? ? is denoted as ? ? ? R ? in .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model Architecture</head><p>In PinnerFormer, we model the sequence of user actions using a transformer model architecture <ref type="bibr" target="#b21">[22]</ref>. We choose to use PreNorm residual connections, applying Layer Normalization before each 1 Details are described in Section A.1 of the reproducibility material block, as this approach has been shown to improve stability of training <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b22">23]</ref>. We first construct the input matrix</p><formula xml:id="formula_0">? = ? ? ? ? ? ? ? -?+1 ? ?</formula><p>R ??? in using the ? actions leading up to action ? ? +1 as the user's sequence. Then, we project these to the transformer's hidden dimension, add a fully learnable positional encoding, and apply a standard transformer consisting of alternating feedforward network (FFN) and multi-head self attention (MHSA) blocks. The output of the transformer at every position is passed through a small MLP and ? 2 normalized, resulting in a set of embeddings</p><formula xml:id="formula_1">? = ? 1 ? ? ? ? ? ? ? R ??? ,</formula><p>where ? is the final embedding dimension. 2  To represent Pins, we learn an MLP that takes only PinSage as an input, and ? 2 normalize the output embeddings. We found that using ? 2 normalized embeddings to represent both users and Pins leads to the most stable training, and does not sacrifice offline performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Metric Learning</head><p>To train our representation, we need pairs {(? 1 , ? 1 ), . . . , (? ? , ? ? )} consisting of user embeddings and target Pin embeddings, where both users and Pins may be repeated. We choose to not use explicit negative examples in this work (i.e. we do not have loss terms for negative engagement, such as hides). In designing our model, there are several considerations: (a) How do we choose these pairs? (b) For a given (? ? , ? ? ) pair, how do we select negative examples? (c) Given a (? ? , ? ? ) pair and a set of negative examples, how do we compute the loss?</p><p>We first describe (b) and (c), then in Section 3.4 elaborate on (a).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Negative Selection.</head><p>We consider two sources of negative examples: in-batch negatives and random negatives. When selecting in-batch negatives for a given user, we choose all positive examples within the batch as negatives, masking pins that have positive engagement for that user. This approach is efficient and simple, but can lead to demotion of popular Pins if implemented naively, as engaging Pins are more likely to appear as negatives than less engaging ones. Another downside to in-batch negatives is that the distribution of negative examples is different from the true underlying distribution of Pins used for retrieval, leading to a discrepancy between training and serving. The second source of negatives are those uniformly sampled from the corpus of all Pins we might surface to Homefeed, but using these alone can lead to model collapse, as the negatives may be too easy. A third option we consider is combining both random and in-batch negatives to take advantage of the unique characteristics of both by merging the in-batch and random negative pools into a single one, which contains a combination of in-batch and random negatives <ref type="bibr" target="#b25">[26]</ref>.</p><p>In practice, a larger negative pool can increase the quality of the learned embeddings, so we gather negative examples from across all GPUs used in training, choosing the largest possible pool that can comfortably fit in GPU memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Loss Function.</head><p>After choosing the source of negative examples, we can produce a set of negative embeddings {? 1 , . . . , ? ? } for a given pair of user and positive embeddings (? ? , ? ? ). We compute a loss for each pair, and then compute a weighted average such that each user in the batch on a given GPU is given equal weight.</p><p>The loss function we have found to work best is sampled softmax with a logQ correction <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b26">27]</ref>, where we apply a correction to each logit based on the probability that a given negative appears in the batch. We also learn a temperature ? ? [0.01, ?), constraining the lower bound for stability. If we let ? (?, ?) = ??, ??/?, a sampled softmax loss without sample probability correction would be defined as follows:</p><formula xml:id="formula_2">L (? ? , ? ? ) = -log ? ? (? ? ,? ? ) ? ? (? ? ,? ? ) + ? ?=1 ? ? (? ? ,? ? )<label>(1)</label></formula><p>When negatives are not uniformly distributed, A correction term ? ? (?) = ? (Pin ? in batch | User ? ? in batch) should be applied to correct for sampling bias, where ? may be a positive or negative example. The softmax loss with sample probability correction for a single pair is then defined as follows:</p><formula xml:id="formula_3">L (? ? , ? ? ) = -log ? ? (? ? ,? ? )-log(? ? (? ? ))</formula><p>? ? (? ? ,? ? )-log(? ? (? ? )) + ? ?=1 ? ? (? ? ,? ? )-log(? ? (? ? ))</p><p>(2) For simplicity, we approximate ? using a count-min sketch <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Training Objective</head><p>Given our loss function, we address the question of how to select pairs (? ? , ? ? ). There are three forms of positive engagement our model should able to predict: Repins, Closeups, and Clicks. Each of these actions has value, but rather than learning task-specific heads as is common in multi-task learning literature <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b13">14]</ref>, we choose to train a single embedding in a multi-task manner, directly learning an embedding that can effectively retrieve different types of positive engagement. We do not explicitly weight different engagement differently in our loss computation function. given the user sequence {? ? , ? ? -1 , . . . , ? ? -?+1 } (if ? ? +1 is a positive engagement). This objective is intuitive for a realtime sequence model because, in the online setting, ? ? will always be the most recent action a user has taken. SASRec <ref type="bibr" target="#b9">[10]</ref> extends this simple training objective by aiming to predict the next action at every step in the model, rather than only predicting the most recent positive action. We slightly modify this in our experiments, only allowing positive actions to contribute to the model's loss. Unlike these traditional objectives, we do not aim to predict a user's next immediate action; instead, we infer our user embeddings daily and aim to capture longer-term interests of a user. To do so we introduce two alternate training objectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">All Action Prediction.</head><p>Based on the observation that we don't solely wish to predict the next action a user will take, we construct a na?ve training objective that predicts all actions a user will take over the next ? days using ? 1 , the final user embedding. <ref type="foot" target="#foot_0">3</ref> Assuming a user has positive engagement in actions ? + 3, ? + 8, and ? + 12, all of which fall within a ? day window of ? , we aim to predict all 3 actions: ? ? +3 , ? ? +8 , ? ? +12 from the user sequence {? ? , ? ? -1 , . . . , ? ? -?+1 }. This objective forces the model to learn longer-term interests, rather than focusing solely on the next action a user will take, which should decrease the effect of staleness that comes from daily offline inference. For computational tractability, we randomly sample up to 32 actions per user in this ? day time window.  To further improve the signal provided by each batch, we draw inspiration from SASRec <ref type="bibr" target="#b9">[10]</ref> to modify the all action prediction objective. Rather than predicting actions over a ? day window using only ? 1 , the most recent user embedding, we instead select a set of random indices, {? ? }, and for each ? ? ? , aim to predict a randomly selected positive action from the set of all positive actions over the next ? days. To ensure this approach learns from the ordering of the data, we apply causal masking to the transformer's self-attention block, so each action may only attend to past or present actions, but not future actions. We observe this masking substantially improves model performance on this task. To decrease memory usage, we do not aim to predict all positive actions, and instead only aim to predict one positive action for each ? ? ? . 4   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Dataset Design</head><p>We make use of a compressed format to store training sequences. One observation we make is that given a single user's timeline, many separate user sequences and positive examples can be constructed. Given an entire user sequence A ? = {? 1 , . . . , ? ? }, and some maximum sequence length ?, we can construct up to ? -? -1 training examples of length exactly equal to ? (assuming all actions are positive). For example, the sequence {? 5 , . . . , ? 5+?-1 } with positive engagements {? 5+? , ? 7+? } can be extracted from the complete timeline A ? . One potential way to store this data would be to materialize all relevant sequences of length ? (or less) ahead of time, along with a corresponding set of future positive 4 Observe that without any subsampling, assuming a batch size of 128, and 32 sampled positives, and maximum sequence length ? = 256, this could generate up to 128 ? 256 ? 32 = 1048576 pairs for softmax computation per GPU. engagements for each sequence. This runs into issues when experimenting with different sampling strategies, as tuning parameters would require regeneration of training data -a slow process. To increase productivity, we instead store each user's sequence as a single row in our dataset, and sample examples on the fly during training. This has a clear benefit of allowing for customized sampling during training, at the cost of decreasing shuffling of training data.</p><p>Specifically, there are several parameters we have tuned using this strategy, all of which can significantly impact the model's overall performance:</p><p>? Maximum sequence length ? The fraction of possible user sequences that are sampled from a user's timeline ? Maximum number of sequences to sample per user ? Maximum number of positive examples to sample as labels for each sequence</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Model Serving</head><p>As we focus on inference in an offline, batch setting for Pinner-Former, we infer the model in a daily, incremental workflow, shown in Figure <ref type="figure" target="#fig_2">3</ref>. This workflow generates new embeddings for users who have engaged with any Pin in the past day, merges them with the previous day's embeddings, then uploads them to a key-value feature store for online serving. Because we only generate new embeddings for users who have engaged in the last day and run inference offline (with no latency constraints), we are able to use larger models than would otherwise be possible, which increases the information our embedding can capture. In the case of any corruption in input features (for example, due to logging errors), we can easily run inference for all users whose embeddings have been updated since corruption and the next day's data will be correct, assuming the upstream data has been fixed. Pin embeddings are inexpensive to compute, only requiring a small MLP transformation of an existing feature, so we generate them from scratch daily, then compile a HNSW <ref type="bibr" target="#b14">[15]</ref> graph that can be queried online using the user embeddings saved in a feature store.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS AND RESULTS</head><p>Here, first we compare PinnerFormer with baselines, conduct ablations, and explore the gap in performance between realtime and daily inference through offline experiments. Then, we show considerable improvements over PinnerSage in A/B experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Offline Evaluation Metrics</head><p>The primary metric we use for evaluation is Recall@10. We select a 2 week period after training ends for evaluation, and evaluate on a disjoint set of users from those used for training. Assuming the training dataset ends at time ?, we compute embeddings at time ? for all users in the evaluation set, and then measure how well the embedding at time ? retrieves all Pins a user will engage with from time ? to ? + 14? from an index of 1M random Pins. Assuming we have a set of users, U, a set of positively engaged Pins P ? for each user ? , and a random corpus of 1M Pins N , we compute Recall@k </p><formula xml:id="formula_4">Recall@k(? ) = 1 |P ? | ?? ? ? P ? 1 {|{? ? N | d(? , ?) ? d(? , ? )}| &lt; ? } Recall@k = 1 |U| ?? ? ?U Recall@k(? )</formula><p>Here, distance between a user and pin is defined by the Euclidean distance between the user's embedding and the pin's embedding.</p><p>We also observe two measures of diversity: (a) the entropy of the distribution of Interests (about 350 unique topics of Pins) associated with the top 50 retrieved results from an index of 1M Pins ("Interest Entropy@50"), and (b) what fraction of the index of 1M Pins accounts for 90% of the top 10 retrieved results over a set of users ("P90 Coverage@10"). The former measures the diversity of the results retrieved for a specific user, whereas the latter represents the global diversity of retrieved results across all users. Both are useful to observe; a simple baseline which memorizes popularity independent of user could have good performance by metric (a), but (b) will show a value very close to 0.0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Offline Results</head><p>In this section we first compare PinnerFormer with baselines, then investigate what aspects of the model lead to good performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Comparison with Baselines.</head><p>In our offline evaluation, we compare to the baseline of PinnerSage <ref type="bibr" target="#b16">[17]</ref>, our previous, multiembedding user representation, measuring recall based on an oracle evaluation to obtain an upper bound. Specifically, given a fixed cutoff ?, and a given positive, we choose the user's representation as the closest embedding to the positive among the top ? PinnerSage embeddings. We believe this establishes an approximate upper bound on the ability of those ? embeddings to predict engagement. To compute diversity metrics, we do not adopt the oracle approach, and instead order results with round-robin blending: given some set of user embeddings (ordered by weight), each with some retrieved results, we take the first result from the first user embedding, the second from the second, and so on, returning to the first embedding after each has retrieved one result.</p><p>In Table <ref type="table" target="#tab_3">1</ref>, we show comparisons between PinnerFormer and PinnerSage, evaluated as described above. Even when evaluating PinnerSage with an oracle over the top 5 or 20 clusters, we see that the single PinnerFormer embedding outperforms PinnerSage in terms of retrieving content users are likely to engage with over a 14 day period. Increasing the number of clusters used to retrieve results leads to more diversity in the results retrieved for a given user, which is an area PinnerSage outperforms PinnerFormer when using a sufficiently large number of clusters. We also see that PinnerSage retrieves more unique candidates from the index, but certain variants of PinnerFormer achieve comparable levels of unique candidates while keeping engagement evaluation metrics higher, as seen in Table <ref type="table" target="#tab_6">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Daily vs Realtime Inference.</head><p>To quantify the drop in performance as inference frequency decreases, we compare two models that only vary in their training objective:</p><p>? A model trained using the SASRec training objective, which directly predicts the next action a user will take <ref type="bibr" target="#b9">[10]</ref>. We replace binary cross-entropy with our sampled softmax loss, and separately weight the loss on ? 1 equal to the loss on other positions, as we find this improves performance. <ref type="foot" target="#foot_2">5</ref>? PinnerFormer, trained using the dense all action prediction objective with a 28d window</p><p>We then evaluate these at three different frequencies over the evaluation window (?, ? + 14?]:</p><p>? Once: We use the single embedding predicted for a user at time ? to predict all of a user's positive actions over the 14 day window (?, ? + 14?]. ? Daily: We update a user's embeddings every day, predicting their actions in the interval (?, ? + 1?] based on the embedding computed at ? -1?, where ? ? {?, ? + 1?, . . . , ? + 13? }. This one day gap accounts for the delay between when an action is available in offline logs, and when it is uploaded to the feature store ? Realtime: We update embeddings after every action; i.e. we use the sequence of a user's ? actions preceding positive action to predict that positive action (for all positive actions in (?, ? + 14?]).</p><p>Note the daily and realtime settings are different from our primary evaluation. Here, given a user's embedding at a point in time, we measure our ability to predict the specific action a user will take, while our primary evaluation measures the ability of the embedding to capture a user's longer-term interests. A realtime model is not practical to serve in production, as it would substantially increase inference cost over a batch model: some users may take tens or hundreds of actions per day, which translates to many times the cost of an offline model, even if using a shorter sequence. We expect this realtime baseline to perform better than an offline, daily-computed model, but it helps quantify the opportunity cost of avoiding the realtime setting.</p><p>In Table <ref type="table" target="#tab_4">2</ref>, we also notice that the performance of PinnerFormer increases as the inference frequency increases, once at start of eval, to once daily, to realtime. Surprisingly, even in realtime Pin-nerFormer outperforms a model trained to predict only the next engaged item.</p><p>This experiment also provides evidence that the dense all action prediction objective has the desired effect of decreasing the model's sensitivity to short-term variations, and instead learns more stable interests of a user: when moving from realtime to daily inference, and daily inference to inference only once, there is a smaller loss in performance when the model is trained on the dense all action objective (-8.3%) than a next action prediction task (-13.9%).</p><p>There is still a nontrivial gap between realtime performance and daily inference performance, but given improvements over our baseline of PinnerSage, and the high cost and infra complexity of inferring PinnerFormer in realtime, we view this as an acceptable tradeoff.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Training Objective Selection.</head><p>In Table <ref type="table" target="#tab_5">3</ref>, we observe that only training to predict the next action in training leads to lower Recall@10, but higher retrieved index coverage. The lower Recall@10 can be explained because all action prediction tasks align better with the evaluation objective than next action prediction. We believe we observe the higher index coverage for next action prediction because prediction of actions over a longer time frame is a harder task than only predicting the next action taken, so the Pin embedding learned may bias more towards retrieving more generally engaging content than retrieving content directly relevant to recent actions. We have also observed that training on a 28 day future window for all action prediction yields better results than a 14 day window, even when the evaluation is fixed to a 14 day window. We believe this can be explained as a consequence of having more labels for each user sequence, which can increase training efficiency.</p><p>The dense all action loss outperforms all action prediction on Recall@10 and global diversity. The key difference between these two losses is that in the all action loss, gradients from all positive examples for a user will be backpropagated through the same user embedding, resulting in a larger averaging effect, as compared to We also tried summing losses computed based on different training objectives together, but such configurations did not outperform any single-objective model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Sampled Softmax.</head><p>In Table <ref type="table" target="#tab_6">4</ref>, we compare performance of different settings for our softmax loss. In all cases, we see that the presence of in-batch negatives increases diversity of retrieved results, but results in lower Recall@10 than mixed negatives. When we train a model using random negatives, the model seems to collapse to retrieving very similar results for all users; when retrieving 10 out of 1M Pins for 100000 users, only 1000 Pins can account for 90% of the retrieved results. This seems to indicate the model is failing to learn fine details regarding a user's interests, as it is retrieving very similar content for most users.</p><p>Overall, we see that sample probability correction does not increase Recall@10 on random negatives, which is expected: the probability that all negatives are in the batch should be equal in this case, as sampling is unbiased. When including in-batch negatives (either alone, or in combination with random negatives), enabling sample probability correction increases recall while decreasing global diversity. Given the large difference between in-batch and mixed negatives in terms of Recall@10, we choose to use mixed negatives with sample probability correction as our loss function, even though mixed negatives introduce slightly more complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.5">Multi-task</head><p>Learning. Here, we measure the difference in performance between single task and multi-task learning. For each  of the 3 positive action types, we train a model to predict a single action type (10s Closeup, 10s Click, Repin), and then train a model to predict any of these 3 action types. In Table <ref type="table" target="#tab_7">5</ref> we see the results: when we train on a specific action type, we maximize Recall@10 when treating only that action type as a positive label.</p><p>When training on all 3 action types together, we maximize the overall Recall@10, but perform slightly worse on each individual task than in a single-task setting. For each task-specific eval, the multitask performance is second to best, so we choose the multi-task training objective as a tradeoff between each objective, ensuring the final embedding does not strongly bias towards a specific task.</p><p>4.2.6 Feature Ablations. In Table <ref type="table" target="#tab_8">6</ref>, we see the impact of each feature on the final model performance. The two features that contribute noticeably to the final embedding are timestamp and the PinSage embedding. Without PinSage, the model has no way of understanding content behind a user's action, and this is reflected both by low Recall@10, and very low global diversity, indicating that we retrieve a similar set of highly results for all users. We see negative impact from removing each feature, so we choose to include all features in PinnerFormer.</p><p>4.2.7 Sequence Length. Figure <ref type="figure" target="#fig_3">4</ref> shows the effect of sequence length on the model's performance. We see approximately constant increases in both Recall@10 and global diversity when doubling sequence length up to around 32, but as sequence length increases we see diminishing returns. In this work, we do not examine sequences longer than length 256, as such models require sacrifices either in terms of batch size or training resources. A smaller batch size makes a comparison with shorter sequence models impossible, as the negative pool used for learning the embedding changes, and will require longer to train. Using more machines (16 GPUs/2 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ranking A/B Experiments</head><p>We run several A/B experiments using it as a feature in ranking models to better understand how PinnerFormer performs online. Both the control and enabled ranking models are trained on the same date range of data for fair comparisons. Table <ref type="table" target="#tab_9">7</ref> shows key results from this experiment. PinnerFormer significantly improved engagement on Homefeed, and led to an increase in daily active users (DAUs) and weekly active users (WAUs). We saw no regression in improvements over the course of several months after shipping the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Ads.</head><p>To verify that this embedding is useful as a feature beyond use cases that it is explicitly trained on, we also run an A/B experiment adding PinnerFormer to Ads ranking models (without replacing PinnerSage). Each primary surface (Homefeed, Related Pins, and Search) has a separate model dedicated to determining the order in which we show advertisements to users, so we experiment with each of them independently. Overall, we see significant gains in engagement with ads on each sufrace, in terms of clickthrough rate (CTR) and long clickthrough rate (gCTR), which are shown in Table <ref type="table" target="#tab_10">8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this work, we presented PinnerFormer, a single, end-to-end learned embedding designed to be inferred in an offline setting, and to capture a user's interests over a multi-day time horizon.</p><p>In contrast to other work focused on modeling users based on their past actions, we do not focus directly on predicting a user's next engagement, but apply a novel loss function to capture a user's interests over a horizon of several days. We show this training objective decreases the gap in performance between a model inferred in realtime and a model inferred once a day. We also present detailed experiments to show the contribution of each component of our model to overall performance, demonstrating the effectiveness of multi-task learning and sampled softmax.</p><p>In the future, we plan to more thoroughly investigate performance of PinnerFormer as a candidate generator, and include actions beyond Pin engagement as elements of the sequence of user actions, helping build an even more comprehensive representation of users.  tradeoff. We choose to use a 256d embedding because it offers good offline metrics, and is the same size as most existing embedding features used in Pinterest's ranking models; the negligible increase in performance from increasing the embedding to 1024d is not worth quadrupling storage cost for most downstream use cases.</p><p>A.4.3 Transformer Architecture. In Table <ref type="table" target="#tab_11">9</ref>, we show the effect of model capacity on final performance. Larger models improve recall, both in terms of number of layers, and hidden size. We do not see substantial changes when varying the number of heads used for multi-head self attention, so we hold this constant at 8 heads.</p><p>A.4.4 Modification of SASRec. In the original paper, SASRec <ref type="bibr" target="#b9">[10]</ref> model is trained based on a binary cross-entropy task, without any sample probability correction. We make two modifications: (a) we give equal weight to the loss on ? 1 , the latest user embedding, and (b) we replace binary cross-entropy with sampled softmax. In Table <ref type="table" target="#tab_12">10</ref>, we show our modifications substantially improve recall.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>e</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of PinnerFormer architecture. Features are passed through a transformer with causal masking, and embeddings are returned at every time step. Note that the training window (28d above) exceeds our future evaluation objective window (14d)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: PinnerFormer is inferred incrementally. We only compute embeddings for users who have engaged on Pinterest in the past day, then merge the new embeddings with the previous set of embeddings, falling back to the old ones if the new ones are missing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Max Sequence length vs Recall and Coverage. Longer sequences lead to better performance, but with diminishing returns.</figDesc><graphic url="image-7.png" coords="8,53.80,217.00,240.24,99.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>4. 3 . 1</head><label>31</label><figDesc>Homefeed. Our first comparison is in Pinterest's Homefeed ranking model, which helps determine the order in which content is shown to a user on Homefeed. Previously this model used a weighted average of a user's top ? PinnerSage embeddings as a feature. In the experiment's enabled group, we replace this aggregation of PinnerSage with the single PinnerFormer embedding.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Recall and diversity vs embedding dimension. Smaller embeddings perform worse and are more likely to retrieve the same results for many users.</figDesc><graphic url="image-8.png" coords="11,53.80,83.68,240.24,147.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>The four training</figDesc><table><row><cell>Next Action</cell><cell></cell><cell></cell></row><row><cell></cell><cell>User Sequence</cell><cell>K Day Future window</cell></row><row><cell>SASRec</cell><cell></cell><cell></cell></row><row><cell></cell><cell>User Sequence</cell><cell>K Day Future window</cell></row><row><cell>All Action</cell><cell></cell><cell></cell></row><row><cell></cell><cell>User Sequence</cell><cell>K Day Future window</cell></row><row><cell>Dense All</cell><cell></cell><cell></cell></row><row><cell>Action</cell><cell>User Sequence</cell><cell>K Day Future window</cell></row><row><cell></cell><cell>Non-positive engagement</cell><cell>Positive engagement</cell></row><row><cell cols="3">Figure 2: Four explored training objectives. Blue circles rep-</cell></row><row><cell cols="3">resent embeddings corresponding to actions considered pos-</cell></row><row><cell cols="3">itive, while red circles represent embeddings corresponding</cell></row><row><cell cols="3">to actions considered non-positive (but not necessarily ex-</cell></row></table><note><p><p><p><p><p>plicitly negative). The exact pairings in the dense all action loss are sampled, so this is simply one potential materialization. Note we do not attempt to predict non-positive examples objectives we consider are described below, and are depicted in Figure</p>2</p>.</p>3.4.1 Next Action Prediction.</p>The naive objective for a sequence modeling task is next action prediction, in which we predict ? ? +1</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>PinnerSage (PS) vs PinnerFormer. PinnerFormer outperforms PinnerSage on our engagement evaluation, even when PinnerSage is evaluated by setting the user embedding to the closest cluster to the true positive embedding. Higher interest entropy indicates more diverse results are retrieved per user, and higher coverage indicates that more unique results are retrieved over all users.</figDesc><table><row><cell>Model</cell><cell>R@10</cell><cell>Interest Entropy@50</cell><cell>P90 Coverage@10</cell></row><row><cell>PS (5 clusters)</cell><cell>0.026</cell><cell>1.69</cell><cell>0.130</cell></row><row><cell>PS (20 clusters)</cell><cell>0.046</cell><cell>2.10</cell><cell>0.133</cell></row><row><cell cols="2">PinnerFormer 0.229</cell><cell>1.97</cell><cell>0.042</cell></row><row><cell>(R@k) as follows:</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Real-time vs. offline batch inference. Moving from realtime to batch inference drops Recall@10 by 13.9% when training on SASRec objective, but only by 8.3% when using a dense all action objective (PinnerFormer)</figDesc><table><row><cell>Inference Frequency</cell><cell>Model</cell><cell cols="2">R@10 P90 Coverage@10</cell></row><row><cell>Once</cell><cell cols="2">SASRec PinnerFormer 0.229 0.198</cell><cell>0.048 0.042</cell></row><row><cell>Daily</cell><cell cols="2">SASRec PinnerFormer 0.243 0.216</cell><cell>0.052 0.043</cell></row><row><cell>Realtime</cell><cell cols="2">SASRec PinnerFormer 0.264 0.251</cell><cell>0.057 0.045</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Comparison of various training objectives. The dense all action objective maximizes Recall@10, and a 28 day future window performs significantly better than a 14d window.</figDesc><table><row><cell>Training Objective</cell><cell cols="2">Recall@10 P90 Coverage@10</cell></row><row><cell>Next Action</cell><cell>0.186</cell><cell>0.050</cell></row><row><cell>SASRec (Softmax)</cell><cell>0.198</cell><cell>0.048</cell></row><row><cell>All Action (28d)</cell><cell>0.224</cell><cell>0.028</cell></row><row><cell>Dense All Action (14d)</cell><cell>0.223</cell><cell>0.043</cell></row><row><cell>Dense All Action (28d)</cell><cell>0.229</cell><cell>0.042</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Effect of negative pool and sample probability correction (SPC). SPC significantly improves Recall@10, at the cost of decreased global result diversity.</figDesc><table><row><cell cols="4">SPC Negative Source P90 Coverage@10 Recall@10</cell></row><row><cell>N</cell><cell>random</cell><cell>0.002</cell><cell>0.136</cell></row><row><cell>N</cell><cell>in-batch</cell><cell>0.163</cell><cell>0.071</cell></row><row><cell>N</cell><cell>mixed</cell><cell>0.083</cell><cell>0.138</cell></row><row><cell>Y</cell><cell>random</cell><cell>0.001</cell><cell>0.139</cell></row><row><cell>Y</cell><cell>in-batch</cell><cell>0.119</cell><cell>0.167</cell></row><row><cell>Y</cell><cell>mixed</cell><cell>0.042</cell><cell>0.229</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Performance on different action types vs training objective action type. The best performing objective for each task is bold, second best is underlined. Although multi-task does not perform as well as single-task learning, it performs better than any individual model on overall Recalll@10, and second best on all other tasks.</figDesc><table><row><cell>Evaluation Task</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Feature ablations, including all but one feature at a time. Removing any feature results in a drop in Recall@10.</figDesc><table><row><cell>Omitted Feature</cell><cell cols="2">P90 Coverage@10 Recall@10</cell></row><row><cell>PinSage</cell><cell>0.0005</cell><cell>0.142</cell></row><row><cell>Timestamp</cell><cell>0.050</cell><cell>0.210</cell></row><row><cell>Surface</cell><cell>0.040</cell><cell>0.224</cell></row><row><cell>Action Type</cell><cell>0.042</cell><cell>0.226</cell></row><row><cell>Duration</cell><cell>0.042</cell><cell>0.226</cell></row><row><cell>Positional Encoding</cell><cell>0.041</cell><cell>0.228</cell></row><row><cell>None</cell><cell>0.042</cell><cell>0.229</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>Online A/B experiment results replacing Pinner-Sage with PinnerFormer as a feature in our Homefeed ranking model. We see improvements in sitewide metrics.</figDesc><table><row><cell>Metric</cell><cell>Lift</cell><cell>Metric</cell><cell>Lift</cell></row><row><cell>Time Spent</cell><cell>+1%</cell><cell>Homefeed Repins</cell><cell>+7.5%</cell></row><row><cell>DAU</cell><cell>+0.4%</cell><cell>Homefeed Clickthroughs</cell><cell>+1%</cell></row><row><cell>WAU</cell><cell>+0.12%</cell><cell>Homefeed Close-ups</cell><cell>+6%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>Online A/B experiment results adding Pinner-Former as a feature to Ads ranking models. Each surface benefits signficantly from PinnerFormer</figDesc><table><row><cell cols="3">Metric Related Pins Search Homefeed</cell></row><row><cell>CTR</cell><cell>+7.1% +7.3%</cell><cell>+10.0%</cell></row><row><cell>gCTR</cell><cell>+6.9% +5.2%</cell><cell>+10.1%</cell></row></table><note><p>machines for 512 sequence length, 32 GPUs/4 machines for 1024) allows longer sequence models to train, but decreases the number of possible parallel training runs. With the ability to train fewer models in parallel, tuning modeling decisions become slower to make, so for PinnerFormer we choose a sequence length of 256 in the final model.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 :</head><label>9</label><figDesc>Recall vs Model Capacity. Larger models tend to perform better.</figDesc><table><row><cell>Num Layers</cell><cell>Hidden Dimension</cell><cell cols="2">P90 Coverage@10 Recall@10</cell></row><row><cell>2</cell><cell>256</cell><cell>0.0359</cell><cell>0.2189</cell></row><row><cell>2</cell><cell>512</cell><cell>0.0388</cell><cell>0.2241</cell></row><row><cell>2</cell><cell>768</cell><cell>0.0397</cell><cell>0.2246</cell></row><row><cell>4</cell><cell>256</cell><cell>0.0366</cell><cell>0.2236</cell></row><row><cell>4</cell><cell>512</cell><cell>0.0412</cell><cell>0.2240</cell></row><row><cell>4</cell><cell>768</cell><cell>0.0426</cell><cell>0.2272</cell></row><row><cell>6</cell><cell>256</cell><cell>0.0383</cell><cell>0.2233</cell></row><row><cell>6</cell><cell>512</cell><cell>0.0400</cell><cell>0.2264</cell></row><row><cell>6</cell><cell>768</cell><cell>0.0417</cell><cell>0.2293</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 10 :</head><label>10</label><figDesc>SASRec, Sampled Softmax vs Binary Cross Entropy loss. Sampled softmax performs significantly better than binary cross-entropy on our dataset.</figDesc><table><row><cell>SASRec Loss</cell><cell cols="2">Recall@10 P90 Coverage@10</cell></row><row><cell>Binary Cross-entropy</cell><cell>0.138</cell><cell>0.111</cell></row><row><cell>Sampled Softmax</cell><cell>0.181</cell><cell>0.056</cell></row><row><cell>Sampled Softmax + equal ? 1 loss weight</cell><cell>0.198</cell><cell>0.048</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>? may not equal 14: we fix our evaluation objective to a 14 day window, but training on the same window may not optimize performance, as shown in</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>4.2.3   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>See Section A.4.4 of reproducibility material for further justification of this change</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>The authors would like to thank <rs type="person">Jay Adams</rs>, <rs type="person">Dhruvil Badani</rs>, <rs type="person">Kofi Boakye</rs>, <rs type="person">Haoyu Chen</rs>, <rs type="person">Yi-ping Hsu</rs>, <rs type="person">Haomiao Li</rs>, <rs type="person">Yang Liu</rs>, <rs type="person">Cosmin Negruseri</rs>, <rs type="person">Yan Sun</rs> and <rs type="person">Jiajing Xu</rs> who contributed or supported us throughout this project.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A INFORMATION FOR REPRODUCIBILITY A.1 Timestamp Encoding</head><p>We use 2 derived values in addition to the raw timestamp to represent time: the difference between the latest timestamp in the sequence and an action's timestamp, and the time gap between each two consecutive actions in the sequence, setting the last one to zero. To encode timestamps, we modify Time2vec to use fixed periods, and apply a log transform of the raw time values Specifically, given a timestamp ?, and ? periods, {? 1 , ? 2 , . . . ? ? }, we obtain 2? + 1 features ? 1 , . . . , ? 2? +1 by</p><p>where ? is a learned vector. We select the periods manually, choosing to use ? abs periods of real-life importance and fractions thereof: 0.25h, 0.5h, 0.75h, 1h, 2h, 4h, 8h, 16h, 1d, 7d, 28d, and 365d. We encode relative time difference features using ? rel = 32 evenly spaced periods on a log scale, ranging from one second to four weeks. This assumes that it is more important for the model to be able to distinguish between short durations, such as ten seconds vs one minute, as compared to long durations, such as 10 days vs 11 days.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Model Architecture</head><p>Here we describe in more detail the transformer architecture we use. We first construct the input matrix</p><p>R ??? in using the vector representations of the ? actions leading up to action ? ? +1 as the sequence. We first project this to the model's hidden dimension ? using a learnable matrix ? ? R ? in ?? , then add a positional encoding PE ? R ??? . This generates an input ? (0) = ?? + PE ? R ??? for the transformer. Following this, we apply a standard transformer model, consisting of alternating 2-layer feedforward network (FFN) blocks and multi-head self attention (MHSA) blocks, where the hidden dimension of the feedforward network is four times the transformer hidden dimension. In each MHSA block, we apply masking so a given output may only attend to current or previous elements of the sequence.</p><p>The model architecture can be described as follows:</p><p>After transforming inputs as described in Equation 3, we pass the final hidden state ? (?) ? R ??? through a two-layer MLP, then ? 2 normalize the output. The output MLP after the transformer is defined by</p><p>where  This results in a set of embeddings</p><p>R ??? , where ? is the final embedding dimension. We use ? 1 , the first row of ? and the most recent output, as the final user embedding. In the case that a user does not have ? engagements, input sequences can be padded to length ?, and positions that are padded can be masked in attention and loss computation, similarly to how they are treated in language modeling tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Mixed Negative Sampling Masking</head><p>In Figure <ref type="figure">5</ref> we depict mixed negative sampling with masking. There are two user embeddings for user ? 1 (potentially at different times) on GPU 1, and an embedding for ? 2 and ? 3 on GPU 2. ? 1 engaged with ? 1 and ? 2 , ? 2 engaged with ? 3 , and ? 3 engaged with ? 4 . ? 1 and ? 2 are random negatives. When computing the loss, we treat each positive as a separate row, but mask ? 2 in the first row and ? 1 in the second, as they are both positive examples for ? 1 . All four positives appear in both processes, as they are synchronized across GPUs before loss computation. Each user per GPU gets equal weight in the final loss computation, so in this case user ? 1 will be assigned twice the weight of ? 2 or ? 3 . In practice, a batch will contain many users, so weighting will be nearly uniform across all GPUs, even if it is not perfectly uniform.</p><p>In our experiments, we cap the number of in-batch negatives at 5000, and fix the number of random negatives to 8192.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Architecture Ablations</head><p>Here, we show the impact of varying model hyperparameters:</p><p>A.4.1 Sequence Selection. We have thoroughly explored removing weaker engagement from a user's history to generate a better embedding for users who engage often on Pinterest, but have seen no significantly positive results from sparsifying user sequences.</p><p>A.4.2 Embedding Dimension. In Figure <ref type="figure">6</ref>, we show the effect of varying the size of our final embedding on overall performance. We see diminishing improvements in Recall@10 as embedding dimension increases, especially beyond a 128d embedding. We also see that at smaller dimensions, the embedding tends towards retrieving similar results for most users, likely implying a level of memorization of popularity. As a consequence, there can be more diversity in each user's retrieved results at small dimensionalities, but because significant Recall@10 is sacrificed, this isn't a good</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Sean</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sami</forename><surname>Alsheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yina</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Pizzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Henning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karun</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omkar</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fedor</forename><surname>Borisyuk</surname></persName>
		</author>
		<title level="m">GrokNet: Unified Computer Vision Model Trunk and Embeddings For Commerce</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Adaptive importance sampling to accelerate training of a neural probabilistic language model</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-S?bastien</forename><surname>Sen?cal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">Minmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francois</forename><surname>Belletti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.02353[cs.LG]</idno>
		<title level="m">Top-K Off-Policy Correction for a REINFORCE Recommender System</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Behavior sequence transformer for e-commerce recommendation in alibaba</title>
		<author>
			<persName><forename type="first">Qiwei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pipei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Ou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Workshop on Deep Learning Practice for High-Dimensional Sparse Data</title>
		<meeting>the 1st International Workshop on Deep Learning Practice for High-Dimensional Sparse Data</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An improved data stream summary: the count-min sketch and its applications</title>
		<author>
			<persName><forename type="first">Graham</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shan</forename><surname>Muthukrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Algorithms</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep Neural Networks for YouTube Recommendations</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emre</forename><surname>Sargin</surname></persName>
		</author>
		<idno type="DOI">10.1145/2959100.2959190</idno>
		<ptr target="https://doi.org/10.1145/2959100.2959190" />
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Recommender Systems (RecSys &apos;16)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sequential User-Based Recurrent Neural Network Recommendations</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Donkers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benedikt</forename><surname>Loepp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J?rgen</forename><surname>Ziegler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM Conference on Recommender Systems (RecSys &apos;17)</title>
		<meeting>the Eleventh ACM Conference on Recommender Systems (RecSys &apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Real-Time Personalization Using Embeddings for Search Ranking at Airbnb</title>
		<author>
			<persName><forename type="first">Mihajlo</forename><surname>Grbovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibin</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD &apos;18)</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD &apos;18)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Recurrent Neural Networks with Top-k Gains for Session-based Recommendations</title>
		<author>
			<persName><forename type="first">Bal?zs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Self-attentive sequential recommendation</title>
		<author>
			<persName><forename type="first">Wang-Cheng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Data Mining (ICDM)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Rishab</forename><surname>Seyed Mehran Kazemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sepehr</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janahan</forename><surname>Eghbali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaspreet</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Sahota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cathal</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Smyth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><surname>Poupart</surname></persName>
		</author>
		<author>
			<persName><surname>Brubaker</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.05321</idno>
		<title level="m">Learning a vector representation of time</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multi-Interest Network with Dynamic Routing for Recommendation at Tmall</title>
		<author>
			<persName><forename type="first">Chao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengmeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pipei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiwei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dik</forename><surname>Lun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management (CIKM &apos;19)</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management (CIKM &apos;19)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Is a Single Vector Enough? Exploring Node Polysemy for Network Embedding</title>
		<author>
			<persName><forename type="first">Ninghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaoyu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuening</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Representation learning using multi-task deep neural networks for semantic classification and information retrieval</title>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye-Yi</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><forename type="middle">A</forename><surname>Malkov</surname></persName>
		</author>
		<author>
			<persName><surname>Yashunin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Transformers without Tears: Improving the Normalization of Self-Attention</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Toan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><surname>Salazar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.05895</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chantat</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yitong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Practice on long sequential user behavior modeling for click-through rate prediction</title>
		<author>
			<persName><forename type="first">Qi</forename><surname>Pi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijie</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guorui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqiang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Gai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Search-based User Interest Modeling with Lifelong Sequential Behavior Data for Click-Through Rate Prediction</title>
		<author>
			<persName><forename type="first">Qi</forename><surname>Pi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqiang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guorui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lejian</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Gai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.05639</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Factorizing Personalized Markov Chains for Next-Basket Recommendation</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on World Wide Web (WWW &apos;10)</title>
		<meeting>the 19th International Conference on World Wide Web (WWW &apos;10)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changhua</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management (CIKM &apos;19)</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management (CIKM &apos;19)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingbo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><forename type="middle">F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lidia</forename><forename type="middle">S</forename><surname>Chao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.01787[cs.CL]</idno>
		<title level="m">Learning Deep Transformer Models for Machine Translation</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Nonlinear Latent Factorization by Embedding Multiple User Interests</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ron</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hector</forename><surname>Yee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Recommender Systems (RecSys)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Recurrent Recommender Networks</title>
		<author>
			<persName><surname>Chao-Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amr</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">How</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><surname>Jing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth ACM International Conference on Web Search and Data Mining (WSDM &apos;17)</title>
		<meeting>the Tenth ACM International Conference on Web Search and Data Mining (WSDM &apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Mixed negative sampling for learning two-tower neural networks in recommendations</title>
		<author>
			<persName><forename type="first">Ji</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyang</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><forename type="middle">Zhiyuan</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichan</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><forename type="middle">Xiaoming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taibai</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of the Web Conference</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">Xinyang</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichan</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><forename type="middle">Zhiyuan</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Heldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditee</forename><surname>Ajit Kumthekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<title level="m">Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations</title>
		<editor>
			<persName><forename type="first">Li</forename><surname>Wei</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Graph convolutional neural networks for web-scale recommender systems</title>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pong</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining</title>
		<meeting>the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Simple Convolutional Generative Network for Next Item Recommendation</title>
		<author>
			<persName><forename type="first">Fajie</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Arapakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joemon</forename><forename type="middle">M</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining (WSDM &apos;19)</title>
		<meeting>the Twelfth ACM International Conference on Web Search and Data Mining (WSDM &apos;19)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Towards Personalized and Semantic Retrieval: An End-to-End Solution for E-Commerce Search via Embedding Learning</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songlin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiling</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunjiang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weipeng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Yun</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep interest evolution network for click-through rate prediction</title>
		<author>
			<persName><forename type="first">Guorui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Na</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Pi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijie</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqiang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Gai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
