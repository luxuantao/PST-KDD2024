<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-12-29">29 Dec 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yuqing</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yun</forename><surname>Zhao</surname></persName>
							<email>yunzhao20@meta.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Meta Platforms, Inc</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-12-29">29 Dec 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2312.17661v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The burgeoning interest in Multimodal Large Language Models (MLLMs), such as OpenAI's GPT-4V(ision), has significantly impacted both academic and industrial realms. These models enhance Large Language Models (LLMs) with advanced visual understanding capabilities, facilitating their application in a variety of multimodal tasks. Recently, Google introduced Gemini, a cutting-edge MLLM designed specifically for multimodal integration. Despite its advancements, preliminary benchmarks indicate that Gemini lags behind GPT models in commonsense reasoning tasks. However, this assessment, based on a limited dataset (i.e., Hel-laSWAG), does not fully capture Gemini's authentic commonsense reasoning potential. To address this gap, our study undertakes a thorough evaluation of Gemini's performance in complex reasoning tasks that necessitate the integration of commonsense knowledge across modalities. We carry out a comprehensive analysis of 12 commonsense reasoning datasets, ranging from general to domain-specific tasks. This includes 11 datasets focused solely on language, as well as one that incorporates multimodal elements. Our experiments across four LLMs and two MLLMs demonstrate Gemini's competitive commonsense reasoning capabilities. Additionally, we identify common challenges faced by current LLMs and MLLMs in addressing commonsense problems, underscoring the need for further advancements in enhancing the commonsense reasoning abilities of these models. Our data and results are available at: https://github.com/EternityYW/ Gemini-Commonsense-Evaluation/.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Commonsense reasoning, integral to human cognition, plays a crucial role in navigating the intricacies of everyday life. Consider a scenario where someone decides what to wear based on the weather. This decision extends beyond the mere selection of attire; it involves understanding weather patterns, the suitability of clothing for different temperatures, and the social context of the occasion. It's about synthesizing diverse pieces of knowledge: a forecast predicting rain, the practical necessity for a raincoat, and the societal expectation of dressing appropriately for an event. This reasoning goes beyond simply processing information; it entails integrating varied pieces of knowledge that humans often take for granted. A major challenge in Natural Language Processing (NLP) research is the ambiguity and under-specification of human language. Individuals rely heavily on their commonsense knowledge and reasoning abilities to decipher these ambiguities and infer missing information. Commonsense reasoning has consistently posed unique challenges in NLP research <ref type="bibr">(Li et al., 2021;</ref><ref type="bibr" target="#b3">Bian et al., 2023)</ref>, encompassing spatial, physical, social, temporal, and psychological aspects, along with an understanding of social norms, beliefs, values, and the nuances of predicting and interpreting human behavior <ref type="bibr" target="#b20">(Liu and Singh, 2004)</ref>. Models often lack this innate commonsense, hindering their ability to contextualize data coherently, in stark contrast to the human capacity for effortlessly understanding everyday situations <ref type="bibr" target="#b27">(Shwartz and Choi, 2020;</ref><ref type="bibr" target="#b2">Bhargava and Ng, 2022)</ref>.</p><p>Recent advances in Large Language Models (LLMs) have sparked unprecedented enthusiasm in the NLP community and beyond, significantly enhancing a wide array of applications <ref type="bibr" target="#b23">(Min et al., 2021;</ref><ref type="bibr">Zhao et al., 2023;</ref><ref type="bibr">Wang et al., 2023;</ref><ref type="bibr" target="#b11">Kasneci et al., 2023;</ref><ref type="bibr" target="#b7">He et al., 2023)</ref>. Building on these achievements, Multimodal Large Language Models (MLLMs) have emerged as a pivotal focus in the next wave of AI <ref type="bibr">(Wu et al., 2023b)</ref>, speculated to advance towards Artificial General Intelligence (AGI), which aims to develop AI systems smarter than humans and beneficial for all of humanity <ref type="bibr">(Rayhan et al., 2023)</ref>. The rise of MLLMs, particularly OpenAI's GPT-4V(ision) <ref type="bibr" target="#b43">(Yang et al., 2023</ref>) and Google's Gem-ini <ref type="bibr" target="#b31">(Team et al., 2023)</ref>, marks significant progress in this area. Among these developments, Gemini emerges as a formidable challenger to the stateof-the-art MLLM, GPT-4V, specially engineered for multimodal integration. Its release has ignited constructive discussions about the current level of AGI achievement. In widely used academic benchmarks, Gemini has attained new state-of-the-art status in the majority of tasks. However, preliminary evaluations of Gemini, especially when compared to models like the GPT series, have indicated potential shortcomings in its commonsense reasoning capabilities, a fundamental aspect of human cognition. Yet, it's important to consider that basing the assessment of Gemini's commonsense reasoning abilities solely on the HellaSWAG dataset <ref type="bibr">(Zellers et al., 2019b)</ref> may not comprehensively reflect Gemini's full scope in this critical domain.</p><p>To address the gap in the comprehensive evaluation of Gemini's real-world performance in commonsense reasoning tasks, our study conducts extensive experiments across 12 commonsense reasoning datasets, covering a broad spectrum of domains such as general, physical, social, and temporal reasoning. We experiment with four popular LLMs for the language dataset evaluation, including Llama2-70b <ref type="bibr" target="#b32">(Touvron et al., 2023)</ref>, Gemini Pro <ref type="bibr" target="#b31">(Team et al., 2023)</ref>, <ref type="bibr">GPT-3.5 Turbo, and GPT-4 Turbo (OpenAI, 2023)</ref>. For the multimodal dataset, we assess both Gemini Pro Vision and GPT-4V. Our key findings are summarized as follows: (1) Overall, Gemini Pro's performance is comparable to that of GPT-3.5 Turbo, demonstrating marginally better average results across 11 language datasets (1.4% higher accuracy), though it lags behind GPT-4 Turbo by an average of 8.2% in accuracy. Moreover, Gemini Pro Vision exhibits lower performance than GPT-4V on the multimodal dataset, except for temporal-related questions. (2) Approximately 65.8% of Gemini Pro's reasoning processes are evaluated as logically sound and contextually relevant, indicating its potential for effective application in various domains. (3) Gemini Pro encounters significant challenges in temporal and social commonsense reasoning, indicating key areas for further development. (4) Our manual error analysis reveals that Gemini Pro often misunderstands provided contextual information, accounting for 30.2% of its total errors. Furthermore, Gemini Pro Vision struggles particularly with identifying emotional stimuli in images, especially those in-volving human entities, which constitutes 32.6% of its total errors. In summary, our contributions are threefold:</p><p>(1) We provide the first thorough evaluation of Gemini Pro's efficacy in commonsense reasoning tasks, employing 12 diverse datasets that span both language-based and multimodal scenarios.</p><p>(2) Our study reveals that Gemini Pro exhibits performance comparable to GPT-3.5 Turbo in language-only commonsense reasoning tasks, demonstrating logical and contextual reasoning processes. However, it lags behind GPT-4 Turbo in accuracy and encounters challenges in temporal and social reasoning, as well as in emotion recognition in images.</p><p>(3) Our findings lay a valuable foundation for future research in the field of commonsense reasoning within LLMs and MLLMs, highlighting the necessity to enhance specialized domains in these models and the nuanced recognition of mental states and emotions in multimodal contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Commonsense Overview</head><p>Commonsense reasoning, a fundamental aspect of human intelligence, facilitates an intuitive understanding and interpretation of the world through basic and often implicit knowledge and beliefs. For instance, it involves understanding that a person carrying an umbrella on a cloudy day likely anticipates rain, or inferring that a closed door in a library signifies a need for quiet. In MLLMs, commonsense reasoning plays a vital role, enabling these models to interact with and interpret human language and visual cues in a manner that mirrors human understanding. In our study, we explore a variety of commonsense reasoning tasks. Definitions for each domain are provided as follows.</p><p>General Commonsense. This domain entails an understanding of basic, everyday knowledge about the world, such as recognizing that birds typically fly and fish live in water. 3 Experimental Setup</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>We experiment with 12 datasets related to different types of commonsense reasoning, which include 11 language-based datasets and one multimodal dataset. The language-based datasets encompass three main categories of commonsense reasoning problems: General and Contextual Reasoning: (1) CommonsenseQA <ref type="bibr" target="#b29">(Talmor et al., 2019)</ref>, focusing on general commonsense knowledge;</p><p>(2) Cosmos QA <ref type="bibr" target="#b9">(Huang et al., 2019)</ref>, emphasizing contextual understanding narratives, (3) ?NLI <ref type="bibr" target="#b1">(Bhagavatula et al., 2019)</ref>, introducing ab-ductive reasoning, which involves inferring the most plausible explanation; and (4) HellaSWAG, centering around reasoning with contextual event sequences. Specialized and Knowledge Reasoning: (1) TRAM <ref type="bibr">(Wang and Zhao, 2023b)</ref>, testing reasoning about time;</p><p>(2) NumerSense <ref type="bibr" target="#b17">(Lin et al., 2020)</ref>, focusing on numerical understanding; (3) PIQA <ref type="bibr" target="#b4">(Bisk et al., 2020)</ref>, assessing physical interaction knowledge; (4) QASC <ref type="bibr" target="#b13">(Khot et al., 2020)</ref>, dealing with science-related reasoning; and (5) Rid-dleSense <ref type="bibr" target="#b18">(Lin et al., 2021)</ref>, challenging creative thinking through riddles. Social and Ethical Reasoning:</p><p>(1) Social IQa <ref type="bibr" target="#b25">(Sap et al., 2019)</ref>, testing the understanding of social interactions; and (2) ETHICS <ref type="bibr" target="#b8">(Hendrycks et al., 2020)</ref>, evaluating moral and ethical reasoning. For the multimodal dataset (vision and language), we select VCR <ref type="bibr">(Zellers et al., 2019a)</ref>, a large-scale dataset for cognition-level visual understanding. For datasets like TRAM and ETHICS, which include multiple tasks, we extract the commonsense reasoning part for experiments. We employ accuracy as the performance metric for all datasets. Table <ref type="table" target="#tab_1">1</ref> provides an overview of the datasets, as well as example questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Models</head><p>We consider four popular LLMs for languagebased dataset evaluation, including the opensource model Llama-2-70b-chat <ref type="bibr" target="#b32">(Touvron et al., 2023)</ref> as well as the closed-source models Gemini Pro <ref type="bibr" target="#b31">(Team et al., 2023)</ref>, <ref type="bibr">GPT-3.5 Turbo, and GPT-4 Turbo (OpenAI, 2023)</ref>. Each of these models is accessed using its corresponding API key. Specifically, we query Gemini through Google Vertex AI, the GPT models through the OpenAI API, and Llama2 through DeepInfra. For the multimodal dataset, we consider GPT-4V (gpt-4-vision-preview in API) and Gemini Pro Vision (gemini-pro-vision in API) in our experiments. Given the constraints of API costs and rate limitations, we randomly select 200 examples from the validation set for each language-based dataset following <ref type="bibr">(Wang and Zhao, 2023b)</ref> and 50 examples from the validation set for the VCR dataset following <ref type="bibr" target="#b21">(Liu and Chen, 2023)</ref>. For all evaluations, we employ greedy decoding (i.e., temperature = 0) during model response generation. Notably, there are instances where the models decline to respond to certain queries, particularly those involving potentially illegal or unethical content. Sometimes, models provide answers that are outside the scope of the options. In these cases, we categorize these unanswered questions as incorrect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Prompts</head><p>In the evaluation of language-based datasets, we employ two prompting settings: (1) zero-shot standard prompting (SP) <ref type="bibr" target="#b14">(Kojima et al., 2022)</ref>, which aims to gauge the models' inherent commonsense capabilities in linguistic contexts, and (2) few-shot chain-of-thought (CoT) prompting <ref type="bibr" target="#b39">(Wei et al., 2022)</ref>, implemented to observe potential enhancements in the models' performance. For the multimodal dataset, we utilize zero-shot standard prompting to assess the authentic end-to-end visual commonsense reasoning abilities of MLLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Overall Performance Comparison</head><p>Table <ref type="table">2</ref> demonstrates the accuracy comparison of four LLMs under zero-shot SP and few-shot CoT settings on 11 language-based commonsense reasoning datasets. There are several key takeaways.</p><p>First, from the model perspective, GPT-4 Turbo outperforms the other models across the majority of datasets on average. Under the zero-shot learning paradigm, it surpasses Gemini Pro, the second-best performing model, by 7.3%, and shows an even greater lead of 9.0% under the few-shot learning paradigm. Gemini Pro exhibits marginally higher average accuracy than GPT-3.5 Turbo, with an increase of 1.3% under zero-shot SP and 1.5% in the few-shot CoT scenario. It also demonstrates substantially better performance than Llama-2-70b. Regarding prompting methods, the CoT approach consistently enhances performance across all datasets, with pronounced gains observed in datasets such as CommonsenseQA, TRAM, and Social IQa. Lastly, from a dataset standpoint, it is apparent that while these models exhibit commendable performance across a broad spectrum of commonsense domains, they encounter challenges in specific areas, particularly those involving temporal (TRAM) and social (Social IQa) dimensions of commonsense reasoning.</p><p>For the multimodal VCR dataset, we report the performance of GPT-4V and Gemini Pro Vision in Table <ref type="table">3</ref>. The VCR consists of three subtasks: (1) Q ? A, which involves generating an answer to a question based on the visual context; (2) QA ? R, which requires the model to produce a rationale for a given answer; and (3) Q ? AR, which challenges the model to both answer the question and justify the response with appropriate rationales. In all subtasks, GPT-4V demonstrates superior performance compared to Gemini Pro Vision, indicating a more robust capacity for integrating visual and textual information to provide coherent responses. In Q ? AR, the relatively lower performance of both models, compared to the other two subtasks, suggests that there is considerable room for improvement in understanding the interplay between visual cues and commonsense reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Effects of Commonsense Domain</head><p>Referring to Section 3.1, we have categorized 11 language-based datasets into three groups and presented the performance for each setting within each group in Figure <ref type="figure" target="#fig_1">1</ref>. Our findings indicate that GPT-4 Turbo consistently leads in performance across all categories. The Llama-2-70b model demonstrates marginally lower accuracy in comparison to the other models. Gemini Pro and GPT-3.5 Turbo display comparable performances; however, Gemini Pro slightly outperforms GPT-3.5 Turbo in two of the three categories. Notably, its performance dip in the Social and Ethical Reasoning group may stem from its tendency to refuse to answer questions that could potentially involve unethical content, which we have counted as incorrect in our evaluation. Based on our experiments, among the 200 samples, Gemini Pro refuses to answer 3.0% of the problems (6 in total) in the Social IQa dataset and 6.5% of the problems (13 in total) in the ETHICS dataset. Overall, all models exhibit robust capabilities in handling Social and Ethical Reasoning datasets, suggesting a relatively advanced grasp of moral and social norms. However, there is a notable disparity in their performance on General and Contextual Reasoning tasks, indicating a potential gap in their understanding of broader commonsense principles and their application in varied contexts. The Specialized and Knowledge Reasoning category, particularly in the realms of temporal and riddle-based challenges, highlights specific deficiencies in the models' abilities to process complex temporal sequences and to engage in the abstract and creative thought required to decipher riddles.</p><p>Regarding the multimodal dataset, Figure <ref type="figure">2</ref> details the comparative performance between GPT-4V and Gemini Pro Vision across different question types, in alignment with the guidelines of the VCR dataset <ref type="bibr">(Zellers et al., 2019a)</ref>. We concen- Table <ref type="table">2</ref>: Performance comparison of four LLMs across 11 language-based commonsense reasoning datasets. For the k-shot CoT setting, k is set to 5 for the majority of datasets, except HellaSWAG (k=10) and PIQA (k=1). The best results for the k-shot setting are boldfaced, and for the 0-shot setting, underlined. GPT-4 Turbo outperforms other models across the majority of datasets under both settings by a large margin. Gemini Pro and GPT-3.5 Turbo exhibit comparably matched performance overall, with Gemini Pro demonstrating marginally superior commonsense reasoning capabilities compared to GPT-3.5 Turbo on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset Method</head><p>Llama-2-70b Llama-2-70b Gemini Pro Gemini Pro GPT-3.5 Turbo GPT-3.5 Turbo GPT-4 Turbo GPT-4 Turbo (0-shot, SP) Table <ref type="table">3</ref>: Performance comparison between GPT-4V and Gemini Pro Vision on the VCR dataset. "Q ? A" evaluates question-answering accuracy, "QA ? R" assesses answer justification, and "Q ? AR" measures the performance of both correctly answering questions and selecting rationales. GPT-4V outperforms Gemini Pro Vision across all subtasks. trate on the "Q ? A" subtask as it most directly assesses the models' visual commonsense capabilities. Considering the data sample for each type, Gemini Pro Vision's performance either matches or is slightly lower than GPT-4V's, except in temporaltype questions, where it surpasses GPT-4V. This suggests its enhanced capability not only in recognizing but also in contextualizing time-related elements within visual scenarios.</p><formula xml:id="formula_0">(k-shot, CoT) (0-shot, SP) (k-shot, CoT) (0-shot, SP) (k-shot, CoT) (0-shot, SP) (k-shot,</formula><formula xml:id="formula_1">Method Q ? A QA ? R Q ? AR GPT-4V<label>80</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Reasoning Justification within MLLMs</head><p>To assess the reasoning capabilities of MLLMs, particularly their ability to provide not only correct answers but also sound and contextually grounded reasoning in matters of commonsense, we adopted a systematic sampling approach. For each of the 11 language-based datasets evaluated with four LLMs, we randomly selected 30 questions that were correctly answered and 30 questions that were incorrectly answered by each LLM following <ref type="bibr" target="#b3">(Bian et al., 2023)</ref>. In cases where a dataset presented fewer than 30 incorrect answers, we included all available incorrect responses to ensure comprehensive analysis. After selecting these questions, we prompted each model to explain "What is the rationale behind the answer to the question?" The reasoning processes provided by the models were then manually reviewed and classified as either True or False, based on their logical soundness and relevance to the question. Figure <ref type="figure">3</ref> illustrates a comprehensive view of the average reasoning correctness across the 11 datasets, in terms of the sampled correct and incorrect questions. In fact, not every model had 30 incorrect questions for each dataset.</p><p>In such scenarios, we scaled the available data up to 30 questions to ensure standardized computation. Figure <ref type="figure">3</ref> shows that GPT-4 Turbo's leading performance in both correct and incorrect answers highlights its advanced reasoning mechanisms and its ability to maintain coherent logic, even when the final answers are not accurate. Additionally, Gemini Pro has emerged as a notably proficient model, generally demonstrating commendable reasoning abilities and offering a well-rounded approach to commonsense reasoning. GPT-3.5, while trailing slightly behind Gemini Pro, still demonstrates competitive reasoning abilities. Figure <ref type="figure" target="#fig_3">4</ref> presents two real examples from Gemini Pro and GPT-3.5, illustrating the cases of a correct answer with a correct rationale and an incorrect answer with an incorrect rationale, respectively. Moving to the multimodal perspective, our analysis of GPT-4V and Gemini Pro Vision on the VCR dataset reveals notable patterns in reasoning correctness. With GPT-4V at 24% and Gemini Pro Vision at 26%, approximately one-quarter of the cases showed both models correctly identifying the answers but failing to provide appropriate rationale. This discrepancy suggests that while the models can often determine the correct outcomes, their ability to understand or explain the underlying reasoning behind these answers is not consistently aligned. Furthermore, in the instances of incorrect answers, GPT-4V and Gemini Pro Vision showed correct rationales 16% and 22% of the time, respectively. This indicates that, despite arriving at incorrect conclusions, the models demonstrate a capacity for effective reasoning or logical processing. However, this does not consistently translate into accurate outcomes, implying that while some aspects of the required knowledge are captured, other crucial elements are likely missed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Case Study: Gemini Pro in Commonsense</head><p>Given our focus on evaluating the commonsense reasoning capabilities of the Gemini Pro model, we conduct a qualitative analysis to assess its per-formance across representative examples in four major categories (three language-based and one multimodal), as described in Section 3.1. To ensure an authentic end-to-end capability evaluation, we present examples under the zero-shot learning setting, employing standard prompting techniques.</p><p>General (CommonsenseQA). In the general commonsense evaluation (General and Contextual Reasoning category) using the CommonsenseQA dataset, consider the example question: "People are what when you're a stranger? (A) train (B) strange (C) human (D) stupid (E) dangerous." Gemini Pro correctly chose (B) "strange," and its reasoning process is notable. It recognized that while all options relate to the concept of a "stranger", only "strange" accurately encapsulates the neutral and open-ended nature of the question. The model effectively ruled out other options: (A) "train", for being too specific and unrelated; (C) "human", as accurate but not capturing the question's essence; (D) "stupid", for being judgmental and offensive; and (E) "dangerous", due to its negative connotation. This selection of "strange" demonstrates an understanding of the unfamiliar nature associated with strangers, highlighting Gemini Pro's capability in interpreting and applying general commonsense knowledge appro-</p><formula xml:id="formula_2">DFWLYLW\ H[SODQDWLRQ K\SRWKHWLFDO PHQWDO UROH VFHQH WHPSRUDO 4XHVWLRQ7\SH $FFXUDF\ *379 *HPLQL3UR9LVLRQ</formula><p>Figure <ref type="figure">2</ref>: Performance comparison between GPT-4V and Gemini Pro Vision on the VCR dataset, categorized by question type, with a focus on the "Q ? A" subtask. Within our sample of 50 questions, the distribution across each type is as follows: activity (12), explanation ( <ref type="formula">16</ref>), hypothetical (3), mental (4), role (5), scene (4), and temporal (6). GPT-4V matches or surpasses Gemini Pro Vision in performance across these question types, with the exception of the temporal category.</p><formula xml:id="formula_3">/ODPDE *HPLQL3UR *377XUER *377XUER $YHUDJH5HDVRQLQJ&amp;RUUHFWQHVV4XHVWLRQV &amp;RUUHFW4XHVWLRQV ,QFRUUHFW4XHVWLRQV</formula><p>Figure <ref type="figure">3</ref>: Average reasoning correctness across 11 language datasets. The comparison among four LLMs is based on a random sample of 30 correct and 30 incorrect questions per dataset. In cases where a dataset contained fewer than 30 incorrect questions, the data were scaled up to maintain consistency in the sample size.</p><p>priately. Temporal (TRAM). In the temporal commonsense evaluation (Specialized and Knowledge Reasoning category) using the TRAM dataset, consider the example question: "He also promises to 'come to' him. How long does it take for him to 'come to' him? (A) 100 years (B) in a minute's time (C) a few hours." Lacking sufficient context, especially regarding the identities involved and the meaning of 'come to', Gemini Pro was unable to provide a definitive answer. Gemini Pro's response highlights a significant aspect of its temporal reasoning capabilities. It illustrates the model's reliance on specific contextual information to make accurate temporal judgments. While this cautious approach is prudent to avoid incorrect assumptions, it also signifies a limitation in addressing ambiguous or incomplete information -a frequent challenge in real-world communications. This example underlines the difficulties LLMs encounter in temporal reasoning tasks, especially when faced with scenarios that offer limited or unclear context. Social (Social IQa). In assessing Gemini Pro's performance in social commonsense reasoning using the Social IQa dataset (Social and Ethical Reasoning category), an interesting scenario was presented: "The people bullied Sasha all her life. But Sasha got revenge on the people. What will the people want to do next? (A) Do whatever Sasha says (B) Get even (C) Flee from Sasha." The correct answer is (C), but Gemini Pro's response is insightful. It chose (B) "Get even" as the most likely option, reasoning that the desire for revenge is a strong motivator and Sasha's actions likely ignited  a similar desire in them. Gemini Pro considered (A) as a less likely option, depending on whether Sasha's revenge instilled deep fear and assumed complete submission. The least likely option, according to Gemini Pro, was (C), which it associated with physical harm or an ongoing threat. This response demonstrates Gemini Pro's nuanced understanding of social dynamics and emotional motivations. However, it also highlights a limitation in accurately human reactions in complex social scenarios, where emotional responses might not always follow a logical pattern. This instance reveals the challenges LLMs face in accurately interpreting and responding to intricate social situations, an area that remains challenging for AI systems. Visual (VCR). In the visual commonsense evaluation using the VCR dataset, we analyzed Gemini Pro Vision's response to a scenario involving physical safety and potential danger, as shown in Figure <ref type="figure" target="#fig_4">5</ref>. Presented with an image of individuals on the edge of a cliff, the model was questioned: "What would happen if person 4 pushed person 3 at this moment?" In this context, Gemini Pro Vision's response mirrored the logical inference that if the second person from the left (person 4) pushed the third person from the left (person 3), the result would be person 3 falling off the cliff, leading to a fatal outcome. This example from the VCR dataset underscores Gemini Pro Vision's ability to analyze visual scenes and make predictions about the potential consequences of actions within those scenes, a crucial aspect of visual commonsense reasoning. It demonstrates the model's grasp of spatial relations and physical consequences, providing evidence of its capacity to process and reason about complex visual information akin to human cognition.</p><p>Overall, the cases presented underscore the advanced reasoning capabilities of Gemini Pro and Gemini Pro Vision, while also identifying challenges in achieving human-like inference. These insights point to potential avenues for the continued enhancement of LLMs and MLLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Error Analysis</head><p>To gain a deeper understanding of the mistakes made by models, we manually analyzed instances where a model made incorrect choices or provided inappropriate answers. We conducted a thorough examination of common error types encountered in commonsense reasoning tasks, with the results averaged across four LLMs. Our focus was on assessing these models in two distinct settings: zeroshot SP and few-shot CoT. Table <ref type="table" target="#tab_3">4</ref> presents the proportions of five common error types observed in each setting, with the data averaged over the four LLMs.</p><p>Context misinterpretation emerged as the most frequent error, occurring more often in the zeroshot SP setting (28.6%) compared to the few-shot CoT (23.4%). This trend suggests that the additional context in few-shot CoT helps models better understand scenarios, thereby reducing errors related to contextual misunderstanding. Logical errors were the second most common, accounting for 23.9% in zero-shot SP and slightly less in fewshot CoT (20.1%), indicating that extra examples in the latter setting aid in more consistent logical reasoning. Ambiguity errors, at 16.2% in zeroshot SP, were reduced to 11.6% in few-shot CoT, demonstrating the effectiveness of added context in resolving language ambiguities. In contrast, Overgeneralization errors showed an increase in fewshot CoT (15.6%) from zero-shot SP (11.8%), possibly due to models' overextending patterns learned from the additional examples. Notably, knowledge errors, where models misapplied correct and necessary commonsense knowledge, saw a significant increase in few-shot CoT (29.3%) compared to zero-shot SP (19.5%). This finding suggests that while extra context can be beneficial, it can also lead to inaccuracies, particularly in complex or nuanced scenarios. In our analysis of the VCR dataset, we focused on instances where either GPT-4V or Gemini Pro Vision chose incorrect answers in the Q ? A subtask. The four common error types for each model are summarized in Table <ref type="table" target="#tab_4">5</ref>. Emotion recognition errors were the most common, with GPT-4V encountering these errors in 30.1% of cases and Gemini Pro Vision slightly more at 31.3%. This high incidence suggests that both models find interpreting emotional cues in visual content particularly challenging, underscoring the complexity of deciphering human emotions from visual stimuli. Spatial perception errors were also significant, constituting 22.5% of errors for GPT-4V and 25.2% for Gemini Pro Vision. These figures indicate the models' difficulties in accurately understanding spatial relationships and the arrangement of elements in images. Logical errors were another major error type, more pronounced in GPT-4V (27.7%) than in Gemini Pro Vision (24.9%), pointing to challenges in logical reasoning within visual contexts. Context misinterpretation, although less frequent, was still a notable issue, with GPT-4V at 19.7% and Gemini Pro Vision at 18.6%. These errors demonstrate the models' struggles with grasping the overarching context or narrative depicted in the visual content.</p><p>Overall, error analysis sheds light on the specific challenges LLMs and MLLMs face in commonsense reasoning, providing valuable insights for future improvements for future model refinement.  <ref type="bibr" target="#b28">(Storks et al., 2019;</ref><ref type="bibr" target="#b30">Tamborrino et al., 2020;</ref><ref type="bibr" target="#b2">Bhargava and Ng, 2022)</ref>. This concern is echoed in various stud-ies that focus on evaluating the commonsense reasoning capabilities of LLMs <ref type="bibr" target="#b3">(Bian et al., 2023;</ref><ref type="bibr" target="#b40">Weng et al., 2023;</ref><ref type="bibr" target="#b26">Shen and Kejriwal, 2023)</ref>. Concurrently, researchers have been exploring diverse strategies to enhance the commonsense reasoning capabilities of NLP systems. These strategies range from leveraging large-scale knowledge graphs to employing methods of commonsense knowledge transfer, aiming to endow NLP systems with a deeper and more nuanced understanding of commonsense concepts <ref type="bibr" target="#b10">(Huang et al., 2023;</ref><ref type="bibr" target="#b45">Ye et al., 2023;</ref><ref type="bibr" target="#b50">Zhou et al., 2023)</ref>. Prior to delving into methodological refinements, a comprehensive evaluation is essential to understand the authentic commonsense reasoning capabilities of LLMs. In our study, we endeavor to advance this line of inquiry by examining how LLMs, particularly focusing on the Gemini model, navigate and implement commonsense reasoning in various NLP contexts.</p><p>Training Paradigms in LLMs. In NLP research, pretraining language models on large-scale varied textual datasets has become essential. This approach endows models with a comprehensive knowledge base across numerous fields. Initially, leveraging this knowledge often involved finetuning models with task-specific data. BERTbased models like BERT (Kenton and Toutanova, 2019) and RoBERTa <ref type="bibr" target="#b22">(Liu et al., 2019)</ref> exemplify this, being applied to tasks ranging from disease prediction <ref type="bibr" target="#b49">(Zhao et al., 2021)</ref> to text classification <ref type="bibr">(Wang et al., 2022b)</ref> and time series analysis <ref type="bibr">(Wang et al., 2022c)</ref>. The debut of GPT-3 <ref type="bibr" target="#b5">(Brown et al., 2020)</ref> shifted this focus towards more flexible learning methods like zero-shot and fewshot learning, showcasing models' adaptability to new tasks with minimal data <ref type="bibr" target="#b5">(Brown et al., 2020)</ref>. This shift has spurred the development of novel prompting techniques to enhance LLMs' reasoning and understanding capabilities, including chainof-thought (CoT) prompting <ref type="bibr" target="#b39">(Wei et al., 2022)</ref>, self-consistency with CoT <ref type="bibr">(Wang et al., 2022a)</ref>, tree-of-thought prompting <ref type="bibr" target="#b44">(Yao et al., 2023)</ref>, and metacognitive prompting <ref type="bibr">(Wang and Zhao, 2023a)</ref>.</p><p>In this work, we establish evaluations by considering four popular LLMs for language-based tasks under zero-shot and few-shot settings, and two MLLMs for multimodal tasks under the zero-shot learning paradigm. Our goal is to provide an indepth understanding of their strengths and limitations in diverse commonsense reasoning tasks.</p><p>Evaluations on MLLMs. Since the release of the state-of-the-art MLLM, GPT-4V, several evaluations have been conducted across diverse tasks, including medical imaging <ref type="bibr">(Wu et al., 2023a)</ref>, visual question answering <ref type="bibr" target="#b16">(Li et al., 2023;</ref><ref type="bibr" target="#b43">Yang et al., 2023)</ref>, and video understanding <ref type="bibr" target="#b19">(Lin et al., 2023)</ref>. These evaluations typically focus either on case-by-case qualitative analyses through example demonstrations or on quantitative assessments by analyzing the model's performance across diverse tasks. The recent release of Google's Gemini has garnered considerable attention, and early experiments have been conducted to evaluate its capabilities in both language understanding <ref type="bibr">(Akter et al., 2023)</ref> and the multimodal domain <ref type="bibr" target="#b21">(Liu and Chen, 2023;</ref><ref type="bibr" target="#b6">Fu et al., 2023)</ref>. However, a significant gap remains in fully comprehending the commonsense reasoning capabilities of Gemini, a known potential shortcoming since its introduction. In our work, we conduct a comprehensive analysis of Gemini's capabilities in this area, along with comparisons to other leading MLLMs, thereby highlighting both the potential and areas for further improvement in future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>In this study, we conducted a comprehensive evaluation of state-of-the-art LLMs and MLLMs, focusing particularly on Gemini Pro and Gemini Pro Vision, across 12 diverse commonsense reasoning datasets. Our findings indicate that while these models mark a significant advancement in various domains, demonstrating impressive performance in commonsense reasoning tasks, they still exhibit limitations, particularly in tasks requiring deep contextual understanding or abstract reasoning, such as those involving temporal dynamics, riddles, or intricate social scenarios.</p><p>Looking ahead, addressing these challenges is crucial to enhance the overall effectiveness of LLMs and MLLMs in commonsense reasoning. Future research should aim to refine the models' capabilities in interpreting and reasoning within complex contexts and abstract scenarios. Additionally, there is an emerging need for more holistic evaluation metrics and methodologies capable of accurately assessing the nuances of commonsense reasoning in AI systems. These metrics should evaluate not only the correctness of responses but also their logical coherence and context relevance.</p><p>In conclusion, our study underscores that perfecting commonsense reasoning in LLMs and MLLMs remains an ongoing endeavor. The observed performance discrepancies among these models reveal intriguing areas for further research and improvement. Although significant progress has been made, achieving AGI still represents a substantial goal on the horizon. Our work lays the groundwork for future exploration in this field, highlighting both the achievements and the areas in need of enhancement in the realm of commonsense reasoning within LLMs and MLLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Limitations</head><p>While this study offers valuable insights into the role of LLMs and MLLMs in commonsense reasoning, there are some limitations to our work. Firstly, our evaluation is heavily dependent on the selected questions and datasets used for analysis. Despite their diversity, these datasets may not cover all facets of commonsense reasoning. As a result, the performance and capabilities of Gemini Pro and other models could vary in real-world scenarios or with alternative datasets. Additionally, our analysis is confined to English language datasets, limiting the generalizability of our findings to other languages or multilingual contexts, where cultural nuances and linguistic differences are crucial in commonsense reasoning. Finally, our study represents a specific moment in the rapidly evolving landscape of AI, focusing on API-based systems that are subject to change. The introduction of newer models or updates to existing ones might lead to different performance outcomes, highlighting the need for ongoing evaluation and analysis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: Average model performance across three major commonsense reasoning categories over 11 languagebased datasets, including General and Contextual Reasoning (CommonsenseQA, Cosmos QA, ?NLI, HellaSWAG), Specialized and Knowledge Reasoning (TRAM, NumerSense, PIQA, QASC, RiddleSense), and Social and Ethical Reasoning (Social IQa, ETHICS). GPT-4 Turbo consistently exhibits superior performance in all commonsense reasoning categories. Gemini Pro marginally surpasses GPT-3.5 Turbo in the first two categories, except for Social and Ethical Reasoning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a) Example of a correct response and rationale explanation from Gemini Pro.(b) Example of an incorrect response and rationale explanation from GPT-3.5 Pro.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Model reasoning correctness justification examples. The sample questions are from the QASC dataset, with the correct answers highlighted in bold red. In example (a), Gemini Pro exhibits methodical reasoning by exclusion, carefully considering all options to reach the most logical conclusion. Conversely, example (b) illustrates GPT-3.5 Turbo's tendency towards unconventional logic, which can result in imaginative yet atypical answers. These instances emphasize the diverse strategies different models apply to commonsense reasoning tasks, revealing their distinct capabilities and limitations in such contexts.</figDesc><graphic url="image-3.png" coords="9,71.15,347.67,217.70,264.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Example image from the VCR dataset.</figDesc><graphic url="image-4.png" coords="10,70.87,70.87,226.77,96.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Overview of commonsense datasets used in our experiments. "K-Way MC" signifies a multiple-choice response format with K options. Bold text in the "Example Questions" column represents the correct answers. It wasn't time for my book to be released... I have received about five rejection letters." What may be the reason for your book getting rejected? (A). None of the above choices; (B). I never...; (C). I felt...; (D). It wasn't finished.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Domain Answer Type</cell><cell>Example Questions</cell></row><row><cell></cell><cell></cell><cell></cell><cell>General and Contextual Reasoning</cell></row><row><cell>CommonsenseQA</cell><cell>general</cell><cell>5-Way MC</cell><cell>Where is a doormat likely to be in front of? (A). facade; (B). front door; (C). doorway; (D). entrance porch; (E). hallway.</cell></row><row><cell cols="4">Cosmos QA Given the context "?NLI contextual 4-Way MC abductive 2-Way MC Given the beginning of the story: Four Outlaws camped in Blood Gulch,</cell></row><row><cell>HellaSWAG</cell><cell>event</cell><cell>4-Way MC</cell><cell></cell></row></table><note><p><p><p><p><p><p>and the end of the story: He arrested them, what is the more plausible hypothesis: (A). They found where the sheriff was; (B). The sheriff found where they were.</p>Given the context "A boy in an orange shirt is playing a video game. the scene" and the activity label "Washing face", which of the following endings is the most appropriate continuation of the scenario? (A). changes to safety features; (B). changes to the game itself; (C). switches to show...; (D). cuts to the boys...</p>Specialized and Knowledge Reasoning</p>TRAM temporal 3-Way MC Then the green ball told the orange ball that blue ball was stupid. How long was the green ball talking to the orange ball? (A). 5 weeks; (B). 24 hours; (C). 15 seconds.</p>NumerSense</p>numerical Number Complete the sentence by filling in &lt;mask&gt; with the most appropriate number. A classical guitar has &lt;mask&gt; strings. ? six PIQA physical 2-Way MC To reach the physical goal: trees, choose the more sensible solution: (A). provide homes for people; (B). provide homes for animals. QASC science 8-Way MC Crabs scavanage and uses dead snail shells for what? (A). RNA; (B). homes; (C). making holes; (D). damage; (E). a hosta; (F). Protein; (G). matter; (H). building a nest. RiddleSense riddle 5-Way MC Something very helpful if you want to go gently down a stream. (A). raft; (B). roll down hill; (C). rowboat; (D). water; (E). roll over. Social and Ethical Reasoning Social IQa social 3-Way MC Kai observed and improved Jan's work. What will Kai want to do next? (A). be effective; (B). get praise; (C). get incredible. ETHICS moral 2-way MC After I got the flu virus I called my friends to tell them that I had the virus. Is this acceptable? (A). acceptable; (B). unacceptable.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Proportion of common error types in commonsense reasoning in LLM evaluation. Misinterpret. represents misinterpretation.</figDesc><table><row><cell>Error Type</cell><cell cols="2">Zero-shot SP Few-shot CoT</cell></row><row><cell>Context Misinterpret.</cell><cell>28.6%</cell><cell>23.4%</cell></row><row><cell>Logical Errors</cell><cell>23.9%</cell><cell>20.1%</cell></row><row><cell>Text Ambiguity</cell><cell>16.2%</cell><cell>11.6%</cell></row><row><cell>Overgeneralization</cell><cell>11.8%</cell><cell>15.6%</cell></row><row><cell>Knowledge Errors</cell><cell>19.5%</cell><cell>29.3%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Proportion of commmon error types in visual commonsense reasoning in MLLM evaluation (GPT-4V and Gemini Pro Vision). Misinterpret.: and E. represent misinterpretation and errors, respectively.</figDesc><table><row><cell>Error Type</cell><cell cols="2">GPT-4V Gemini Pro Vision</cell></row><row><cell>Context Misinterpret.</cell><cell>19.7%</cell><cell>18.6%</cell></row><row><cell>Spatial Perception E.</cell><cell>22.5%</cell><cell>25.2%</cell></row><row><cell>Emotion Recognition E.</cell><cell>30.1%</cell><cell>31.3%</cell></row><row><cell>Logical Errors</cell><cell>27.7%</cell><cell>24.9%</cell></row><row><cell>5 Related Work</cell><cell></cell><cell></cell></row><row><cell cols="3">Commonsense Reasoning in NLP. Commonsense</cell></row><row><cell cols="3">reasoning has gained renewed attention in recent</cell></row><row><cell cols="3">years, especially in the context of advancements in</cell></row><row><cell cols="3">LLMs that have significantly influenced numerous</cell></row><row><cell cols="3">applications in NLP. However, there is a growing</cell></row><row><cell cols="3">concern about their ability to understand and rea-</cell></row><row><cell cols="2">son about commonsense knowledge</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">?ngel Alexander Cabrera, Krish Dholakia, Chenyan Xiong, and Graham Neubig. 2023. An in-depth look at gemini&apos;s language abilities</title>
		<author>
			<persName><forename type="first">Zichun</forename><surname>Syeda Nahida Akter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aashiq</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyue</forename><surname>Muhamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><surname>B?uerle</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.11444</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Abductive commonsense reasoning</title>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Ronan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaitanya</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keisuke</forename><surname>Malaviya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Commonsense knowledge reasoning and generation with pretrained language models: A survey</title>
		<author>
			<persName><forename type="first">Prajjwal</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="12317" to="12325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Xianpei</forename><surname>Ning Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaojie</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.16421</idno>
		<title level="m">Chatgpt is a knowledgeable but inexperienced solver: An investigation of commonsense problem in large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Piqa: Reasoning about physical commonsense in natural language</title>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="7432" to="7439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Chaoyou</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renrui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haojia</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongdong</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yubo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengye</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Longtian</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaoxiang</forename><surname>Ye</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.12436</idno>
		<title level="m">A challenger to gpt-4v? early explorations of gemini in visual expertise</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Large language models as zero-shot conversational recommenders</title>
		<author>
			<persName><forename type="first">Zhankui</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhouhang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harald</forename><surname>Steck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yesu</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prasad</forename><surname>Bodhisattwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Kallus</surname></persName>
		</author>
		<author>
			<persName><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd ACM international conference on information and knowledge management</title>
		<meeting>the 32nd ACM international conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="720" to="730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Aligning ai with shared human values</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Collin</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Critch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Cosmos qa: Machine reading comprehension with contextual commonsense reasoning</title>
		<author>
			<persName><forename type="first">Lifu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Ronan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2391" to="2401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mvp-tuning: Multi-view knowledge retrieval with prompt tuning for commonsense reasoning</title>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruyi</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="13417" to="13432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Chatgpt for good? on opportunities and challenges of large language models for education</title>
		<author>
			<persName><forename type="first">Enkelejda</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathrin</forename><surname>Se?ler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>K?chemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Bannert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daryna</forename><surname>Dementieva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urs</forename><surname>Gasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Groh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>G?nnemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eyke</forename><surname>H?llermeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learning and individual differences</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page">102274</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename><surname>Kristina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toutanova</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of naacL-HLT</title>
		<meeting>naacL-HLT</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Qasc: A dataset for question answering via sentence composition</title>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michal</forename><surname>Guerquin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8082" to="8090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Large language models are zero-shot reasoners</title>
		<author>
			<persName><forename type="first">Takeshi</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shane</forename><surname>Shixiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Machel</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutaka</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusuke</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><surname>Iwasawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="22199" to="22213" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Lorraine</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adhiguna</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Kuncoro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.00607</idno>
		<title level="m">Cyprien de Masson d&apos;Autume, Phil Blunsom, and Aida Nematzadeh. 2021. Do language models learn commonsense knowledge? arXiv preprint</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Yunxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Longyue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baotian</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanqi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.07536</idno>
		<title level="m">A comprehensive evaluation of gpt-4v on knowledgeintensive visual question answering</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Birds have four legs?! numersense: Probing numerical commonsense knowledge of pretrained language models</title>
		<author>
			<persName><forename type="first">Seyeon</forename><surname>Bill Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6862" to="6868" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Riddlesense: Reasoning about riddle questions featuring linguistic creativity and commonsense knowledge</title>
		<author>
			<persName><forename type="first">Ziyi</forename><surname>Bill Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong-Ho</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1504" to="1515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chung-Ching</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehsan</forename><surname>Azarnasab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zicheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yumao</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.19773</idno>
		<title level="m">Mmvid: Advancing video understanding with gpt-4v (ision)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Conceptnet-a practical commonsense reasoning tool-kit</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Push</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BT technology journal</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="211" to="226" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">An evaluation of gpt-4v and gemini in online vqa</title>
		<author>
			<persName><forename type="first">Mengchen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chongyan</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.10637</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Recent advances in natural language processing via large pre-trained language models: A survey</title>
		<author>
			<persName><forename type="first">Bonan</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hayley</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elior</forename><surname>Sulem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Pouran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Veyseh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thien</forename><surname>Huu Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oscar</forename><surname>Sainz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilana</forename><surname>Heintz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>ACM Computing Surveys</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<title level="m">Gpt-4 technical report. Abu Rayhan, Rajan Rayhan, and Swajan Rayhan. 2023. Artificial general intelligence: Roadmap to achieving human-level capabilities</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Social iqa: Commonsense reasoning about social interactions</title>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Le Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4463" to="4473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An experimental study measuring the generalization of finetuned language representation models across commonsense reasoning benchmarks</title>
		<author>
			<persName><forename type="first">Ke</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mayank</forename><surname>Kejriwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems</title>
		<imprint>
			<biblScope unit="page">e13243</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Do neural language models overcome reporting bias?</title>
		<author>
			<persName><forename type="first">Vered</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
		<meeting>the 28th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6863" to="6870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Shane</forename><surname>Storks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaozi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joyce</forename><forename type="middle">Y</forename><surname>Chai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.01172</idno>
		<title level="m">Commonsense reasoning for natural language understanding: A survey of benchmarks, resources, and approaches</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="60" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Commonsenseqa: A question answering challenge targeting commonsense knowledge</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4149" to="4158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Pretraining is (almost) all you need: An application to commonsense reasoning</title>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Tamborrino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Pellican?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baptiste</forename><surname>Pannier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Voitot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louise</forename><surname>Naudin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3878" to="3887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Gemini</forename><surname>Team</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Baptiste</forename><surname>Alayrac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiahui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Schalkwyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anja</forename><surname>Hauth</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.11805</idno>
		<title level="m">Gemini: a family of highly capable multimodal models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amjad</forename><surname>Almahairi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasmine</forename><surname>Babaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Bashlykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumya</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prajjwal</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Bhosale</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.09288</idno>
	</analytic>
	<monogr>
		<title level="m">Open foundation and fine-tuned chat models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.11171</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">2023a. Metacognitive prompting improves understanding in large language models</title>
		<author>
			<persName><forename type="first">Yuqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.05342</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Yuqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.00835</idno>
		<title level="m">Tram: Benchmarking temporal reasoning for large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">2022b. Integrating physiological time series and clinical notes with transformer for early prediction of sepsis</title>
		<author>
			<persName><forename type="first">Yuqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachael</forename><surname>Callcut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><surname>Petzold</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.14469</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Enhancing transformer efficiency for multivariate time series classification</title>
		<author>
			<persName><forename type="first">Yuqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><surname>Petzold</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.14472</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Yuqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><surname>Petzold</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.05368</idno>
		<title level="m">Are large language models ready for healthcare? a comparative study on clinical language understanding</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Chain-of-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24824" to="24837" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Large language models are better reasoners with self-verification</title>
		<author>
			<persName><forename type="first">Yixuan</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minjun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengping</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2550" to="2575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">Chaoyi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiayu</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaoyu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weike</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weixiong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoman</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ya</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.09909</idno>
		<title level="m">Yanfeng Wang, et al. 2023a. Can gpt-4v (ision) serve medical applications? case studies on gpt-4v for multimodal medical diagnosis</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">Jiayang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wensheng</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zefeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shicheng</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.13165</idno>
		<title level="m">Multimodal large language models: A survey</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">Zhengyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chung-Ching</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zicheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lijuan</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.17421</idno>
		<title level="m">The dawn of lmms: Preliminary explorations with gpt-4v (ision)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Tree of thoughts: Deliberate problem solving with large language models</title>
		<author>
			<persName><forename type="first">Shunyu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Izhak</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.10601</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Improving commonsense in vision-language models via knowledge graph riddles</title>
		<author>
			<persName><forename type="first">Shuquan</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongdong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenguang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2634" to="2645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">From recognition to cognition: Visual commonsense reasoning</title>
		<author>
			<persName><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6720" to="6731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Hellaswag: Can a machine really finish your sentence?</title>
		<author>
			<persName><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4791" to="4800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">Kun</forename><surname>Wayne Xin Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yupeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingqian</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beichen</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zican</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Dong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.18223</idno>
		<title level="m">A survey of large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Empirical quantitative analysis of covid-19 forecasting models</title>
		<author>
			<persName><forename type="first">Yun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junfeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haotian</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenni</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinghang</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><surname>Petzold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 International Conference on Data Mining Workshops (ICDMW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="517" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Commonsense knowledge transfer for pre-trained language models</title>
		<author>
			<persName><forename type="first">Wangchunshu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Le Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.02388</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
