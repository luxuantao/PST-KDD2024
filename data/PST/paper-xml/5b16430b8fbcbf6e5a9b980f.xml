<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A C C E P T E D M A N U S C R I P T CE3: A three-way clustering method based on mathematical morphology</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Pingxin</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Science</orgName>
								<orgName type="institution">Jiangsu University of Science and Technology</orgName>
								<address>
									<postCode>212003</postCode>
									<settlement>Zhenjiang, Jiangsu</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Regina</orgName>
								<address>
									<postCode>S4S 0A2</postCode>
									<settlement>Regina, Saskatchewan</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">College of Mathematics and Information Science</orgName>
								<orgName type="institution">Hebei Normal University</orgName>
								<address>
									<postCode>050024</postCode>
									<settlement>Shijiazhuang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yiyu</forename><surname>Yao</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Regina</orgName>
								<address>
									<postCode>S4S 0A2</postCode>
									<settlement>Regina, Saskatchewan</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A C C E P T E D M A N U S C R I P T CE3: A three-way clustering method based on mathematical morphology</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B53178A344CD7B96403D4D834E3A9A16</idno>
					<idno type="DOI">10.1016/j.knosys.2018.04.029</idno>
					<note type="submission">Received date: 17 December 2017 Revised date: 23 April 2018 Accepted date: 24 April 2018</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T05:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Knowledge-Based Systems Three-way clustering</term>
					<term>Three-way decision</term>
					<term>Mathematics morphology</term>
					<term>Contraction</term>
					<term>Expansion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Many existing clustering methods produce clusters with clear and sharp boundaries, which does not truly reflect the fact that a cluster may not necessarily have a well-defined boundary in many real world situations. In this paper, by combining ideas of erosion and dilation from mathematical morphology and principles of three-way decision, we propose a framework of a contraction-andexpansion based three-way clustering called CE3. A three-way cluster is defined by a nested pair of sets called the core and the support of the cluster, respectively. A stronger relationship holds between objects in the core and a weaker relationship holds between objects in the support. Given a cluster obtained from a hard clustering method, CE3 uses a contraction operation to shrink the cluster into the core of a three-way cluster and uses an expansion operation to enlarge the cluster into the support. The difference between the support and the core is called the fringe region, representing an unsharp boundary of a cluster. Within the CE3 framework, we can define different types of contraction and expansion operations. We can apply the CE3 framework on the top of any existing clustering method. As examples for demonstration, we introduce a pair of neighbor-based contraction and expansion operations and apply the CE3 framework on the top of k-means and spectral clustering, respectively. We use one synthetic data set, five UCI data sets, and three USPS data sets to evaluate experimentally the performance of CE3. The results show that CE3 is in fact effective in revealing cluster structures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Granular computing is about thinking, problem solving, and information processing at multiple levels of granularity <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref>. One of the fundamental tasks of granular computing is to granulate a data set into granules, in order to build multilevel granular structures <ref type="bibr" target="#b3">[4]</ref>. Among the many approaches to information granulation <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>, cluster analysis is perhaps one of the widely and most used ones <ref type="bibr" target="#b8">[9]</ref>. Cluster analysis plays an important role in many areas such as image analysis, bioinformatics, network structure analysis and others <ref type="bibr" target="#b9">[10]</ref>.</p><p>Email addresses: pingxin_wang@hotmail.com (Pingxin Wang), yyao@cs.uregina.ca (Yiyu Yao)</p><p>Preprint submitted to Knowledge-Based Systems <ref type="bibr">April 24, 2018</ref> A C C E P T E D M A N U S C R I P T The purpose of clustering is to assign similar objects into the same cluster and dissimilar objects into different clusters. Many existing methods are based on the assumption that an object is either in or not in a specific cluster, which leads to the class of hard clustering methods. Hard clustering requires crisp boundaries between different clusters. On the other hand, in many applications clusters may not necessarily have clear and sharp boundaries. We can use a simple example to illustrate this point. In Fig. <ref type="figure">1</ref>, there are two highly concentrated areas and six discrete points x 1 , x 2 , • • • , x 6 . If a hard clustering technique is used, x 1 and x 2 need to be assigned to either the left or the right clusters. It seems unreasonable to add x 1 and x 2 into one cluster but the other because the distances between them and two clusters are almost the same. On the other hand, although there are no difficulties in choosing clusters for x 3 , x 4 and x 5 , x 6 , respectively, their inclusion in a cluster would weaken the structure of the cluster.</p><p>The example shows that hard clustering methods do not address satisfactorily the relationships between an element and a cluster. There may exist at least three types of relationships between an element and a cluster, namely, belong-to fully, belong-to partially (i.e., also not belong-to partially), and not belong-to fully. To represent the three types of relationship, it is necessary to introduce a notion of three-way clustering <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13]</ref>, as an alternative to conventional two-way clustering. In two-way clustering, a cluster is represented by a set that divides the space into two regions. Objects belong to the cluster if they are in the set, otherwise they do not. In three-way clustering, we represent a three-way cluster by pair of nested sets called the core and support of the cluster, respectively. The core, the difference between the support and core (i.e., the fringe region), and the complement of the support give rise to a trisection of the space. A trisection captures the three types of relationships between a cluster and an object. With this understanding of clusters, Yu et al. <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13</ref>] initiated studies on three-way clustering by drawing ideas from a theory of three-way decision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>Three-way decision, as a new field of study for complex problem solving, was proposed by Yao <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref>. It is an extension of the commonly used binary-decision models. Three-way decision divides a universe of objects into three regions for processing. In the context of threeway clustering, we may interpret the three regions as the core region (Co), the fringe region (Fr), and the trivial region <ref type="bibr">(Tr)</ref>. Since Tr can be expressed as the complement of the union of Co and Fr, we can represent a three-way cluster by a pair of the set of core objects and the set of boundary or fringe objects. The core region is an area where the elements are highly concentrated and fringe region is an area where the elements are loosely concentrated. There may be common elements in the fringe regions of different clusters. Equivalently, we can also represent a threeway cluster by a pair of core and support, where the core is Co and the support is the union of Co and Fr. Based on these representations, basic ideas of three-way clustering were also considered by Lingras and West <ref type="bibr" target="#b17">[18]</ref>, Lingras and Peters <ref type="bibr" target="#b18">[19]</ref>, and Yao et al. <ref type="bibr" target="#b19">[20]</ref> earlier under the names of rough clustering and interval-set clustering.</p><p>In this paper, we study a new type of three-way clustering methods by drawing inspiration from mathematical morphology. Matheron <ref type="bibr" target="#b20">[21]</ref> introduced mathematical morphology to study porous media by using set theory. It evolved rapidly to a general theory of shape transformations and has been applied in particular to image processing and pattern recognition <ref type="bibr" target="#b21">[22]</ref>. Erosion and dilation are two primary morphological operations used to shrink and to stretch an image according to the structuring elements. The two operations correspond to the notions of lower and upper approximation of a set in rough set theory <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25]</ref>. The lower approximation of a set is a subset of the set and the upper approximation is a superset of the set. The pair of lower and upper approximations forms an interval set. These observations suggest a possible link between mathematical morphology, rough clustering, and interval-set clustering. We can further explore such an important connection. More specifically, inspired by the ideas of erosion and dilation operations for image processing, we introduce a pair of operations called contraction and expansion to shrink and to stretch a cluster obtained from a hard clustering method. The contraction operation shrinks a cluster so that a stronger relationship holds between objects in the contacted cluster. The expansion operation enlarges a cluster so that a weaker relationship holds between objects in the expanded cluster. The contracted set is regarded as core region and the difference between the contracted and expanded clusters is regarded as the fringe region. Therefore, a three-way explanation of the cluster is naturally formed. This reconstruction of hard clusters is referred to as CE3 method. The two letters C and E indicate two operations and the number 3 indicates three-way clustering. A three-way refinement of a hard cluster may reveal a better cluster structure.</p><p>In Fig. <ref type="figure">2</ref>, suppose that C 1 and C 2 are two clusters obtained by a hard clustering technique on data given in Fig. <ref type="figure">1</ref>. An object is either in C 1 or not in C 1 ; The same is true about C 2 . If we apply the proposed CE3 on C 1 and C 2 , we obtain the results in Fig. <ref type="figure">3</ref>. We can see that core regions are more compact and the structure is better than the results in Fig. <ref type="figure">2</ref>.</p><p>The proposed CE3 method shares some similarity to existing three-way approaches to clustering and, at the same time, differs from them in several ways. On the one hand, the format of clustering used in CE3 is the same as the one used in other three-way approaches, such as interval-set clustering <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b19">20]</ref> and rough-set clustering <ref type="bibr" target="#b18">[19]</ref>. That is, we use three regions or, equivalently, a pair of sets to represent a cluster. Yu <ref type="bibr" target="#b10">[11]</ref> introduced the notion of three-way clusters and suggested a general framework of three-way clustering, which unifies existing studies on a common ground. All these studies construct three-way clusters directly. On the other hand, CE3 refines clusters from a hard clustering algorithm. It only uses the results from a two-way clustering algorithm. That is, one can easily add CE3 on the top of any two-way clustering al-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>gorithm without modifying the two-way algorithm. In contrast, the approaches proposed by Yu and associates <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13]</ref> and Lingras and associates <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref> modify existing two-way clustering algorithms into three-way clustering algorithms. For a different algorithm, it is necessary to consider a different modification or adaptation, which is normally more difficult. From this sense, CE3 is more flexible and can be easily combined with any two-way clustering algorithms. Although CE3 refines clusters from a hard clustering algorithm, the resulting clusters are in a very different format. Therefore, it is not simply an improvement of a hard clustering method. In summary, CE3 provides a different type of three-way clustering methods and, while using results from a two-way clustering algorithm, is different from two-way clustering methods.</p><p>The present paper is based on, but substantially expands, our preliminary study reported in a conference paper <ref type="bibr" target="#b25">[26]</ref>. The rest of the paper is organized as follows. In Section 2, we briefly introduce the background knowledge. In Section 3, we give a detailed description of CE3 and a neighbor-based CE3 that aims to transform hard clusters into three-way clusters. In Sections 4 and 5, we propose a neighbor-based CE3 k-means algorithm and a CE3 spectral clustering algorithm, respectively. in Section 6, we report the results of experimental evaluation CE3. In Section 7, we give the conclusions and point out some future research problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Two-way and three-way clusterings</head><p>In this section, we briefly introduce the background of the proposed method, which consists of two-way clustering, three-way decision, three-way clustering, and mathematical morphology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Extensions of two-way clustering</head><p>Two-way clustering methods are based on an assumption that there exist crisp boundaries between different clusters. However, this assumption is not necessarily true in many practical situations. In order to relax this assumption, many soft clustering methods have been proposed and studied.</p><p>By incorporating fuzzy sets into k-means, Bezdek <ref type="bibr" target="#b26">[27]</ref> proposed fuzzy k-means (FKM), which uses membership degrees of fuzzy sets to describe similarities between objects and each cluster and assigns all objects to k fuzzy clusters. Hoppner et al. <ref type="bibr" target="#b27">[28]</ref> studied fuzzy clustering that represents a cluster by using a fuzzy set with a gradually changing boundary. Lingras and West <ref type="bibr" target="#b17">[18]</ref> applied rough sets theory <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30]</ref> to clustering and proposed rough k-means (RKM), which uses a lower and an upper approximation to describe a cluster. Later, Lingras and Peters <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b30">31]</ref> extended rough k-means to rough clustering. In rough clustering, an object can belong to multiple clusters based on the concepts of lower and upper approximations of rough sets and every cluster might have a fringe region (boundary region). We need more information for objects in the fringe regions so that they can be assigned eventually to some clusters. By considering membership degrees, Mitra et al. <ref type="bibr" target="#b31">[32]</ref> proposed a rough-fuzzy k-means (RFKM), which incorporates membership into the RKM framework. As an alternating mechanism for handling uncertainty, shadowed sets <ref type="bibr" target="#b32">[33]</ref> have been successfully used for clustering analysis, resulting in shadowed c-means <ref type="bibr" target="#b33">[34]</ref>. Takaki et al. <ref type="bibr" target="#b34">[35]</ref> produced a soft clustering method and applied it to network structure analysis. Aydin et al. <ref type="bibr" target="#b35">[36]</ref> introduced an overlapping clustering method and applied it to mobile ad hoc networks. By integrating three-way decision and clustering, Yu et al. <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13]</ref> proposed a theory of three-way clustering which is a most recent proposal for modeling clusters with an unsharp boundary. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Three-way decision</head><p>Rough sets theory <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30]</ref> has played an important role in data analysis. Yao introduced Bayesian decision theory into rough sets and proposed a decision-theoretic rough set model, which has led to the concept of three-way decision <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref>. A basic idea of three-way decision is to divide a universal set into three pair-wise disjoint regions and to process the three regions accordingly <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b36">37]</ref>. This tri-partition methodology provides flexible ways for complex problem solving and information processing <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b37">38]</ref>.</p><p>The theory of three-way decision extends binary-decision in order to overcome some drawbacks of binary-decision. In fact, people often make decisions based on available evidence. However, a positive or negative decision may not be made if the evidence is insufficient or not strong. In this case, people can choose an alternative decision that is neither yes nor no, which is also called a deferment decision that requires further judgments. We can formally define three regions of three-way decision by making use of an evaluation function. Definition 1. <ref type="bibr" target="#b16">[17]</ref> Suppose (L, ) is a totally ordered set, that is, is a total order. For two elements α, β with β ≺ α, suppose that the set of designated values for acceptance is given by L + = {t ∈ L | t α} and the set of designated values for rejection is given by L -= {b ∈ L | b β}. For an evaluation function ν : U → L, its three regions are defined by:</p><formula xml:id="formula_0">POS (α,β) (ν) = {x ∈ U | ν(x) α}, NEG (α,β) (ν) = {x ∈ U | ν(x) β}, BND (α,β) (ν) = {x ∈ U | β ≺ ν(x) ≺ α}.</formula><p>Three-way decision investigates scientifically a common problem-solving and informationprocessing practice. The idea of three-way decision is consistent with human cognitions in solving real world problem <ref type="bibr" target="#b37">[38]</ref>. Many soft computing models, such as interval sets, rough sets, fuzzy sets and shadowed sets, have the tri-partitioning properties and can be reinvestigated within the framework of three-way decision <ref type="bibr" target="#b16">[17]</ref>. A trisecting-and-acting model is propose by Yao <ref type="bibr" target="#b37">[38]</ref>, which can be depicted by Fig. <ref type="figure" target="#fig_1">4</ref>. According to the model, there are two basic tasks in three-way decision. The first one is to divide a universal set into three parts and the second one is to develop different strategies for processing the three parts.</p><p>In the last few years, we have witnessed a fast growing development and applications of threeway approaches in many fields and disciplines, such as, investment decision <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b39">40]</ref>, information</p><formula xml:id="formula_1">A C C E P T E D M A N U S C R I P T</formula><p>filtering <ref type="bibr" target="#b40">[41]</ref>, text classification <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43]</ref>, risk decision <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b41">42]</ref>, government decision <ref type="bibr" target="#b43">[44]</ref>, webbased support systems <ref type="bibr" target="#b44">[45]</ref>, formal concept analysis <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50]</ref>, sequential three-way decision <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b51">52]</ref>, resilience analysis of critical infrastructures <ref type="bibr" target="#b7">[8]</ref>, and many more. Based on the ideas of three-way decision, Yu et al. <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13]</ref> presented a framework of three-way clustering which represents the clusters by a pair of sets called core region and fringe region. Recently, Afridi et al. <ref type="bibr" target="#b52">[53]</ref> presented a three-way clustering approach for handling missing data by using game-theoretic rough set model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Three-way clustering</head><p>In the existing studies, a cluster is usually represented by a single set. From the view of making decisions, the single set representation means that objects in the set belong to the cluster and objects not in the set do not belong to the cluster. This is a typical result of a two-way decision. For hard clustering, an object just belongs to one cluster; for soft clustering, an object might belong to more than one cluster.</p><p>There are three types of relationships between an object and a cluster, namely, belong-to definitely, not belong-to definitely, and uncertain. It is therefore more appropriate to use three regions to represent a cluster. Inspired by ideas from three-way decision, Yu <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref> proposed a framework of three-way clustering that prepresents a cluster by a pair of sets or three sets. In some earlier studies on three-way clustering, for example rough clustering <ref type="bibr" target="#b18">[19]</ref>, it is assumed that an object must belong to one lower approximation or intersection of two upper approximations. Although this requirement seems valid in the setting of rough set theory, it is not very realistic for three-way clustering in general. It seems more reasonable to assume that an object can belong to at most one core region or at least one fringe region.</p><p>We summarize the basic concepts of three-way clustering. Assume</p><formula xml:id="formula_2">C = {C 1 , • • • , C k } is a family clusters of universe V = {v 1 , • • • , v n }.</formula><p>A hard clustering requires that C i satisfies the following properties:</p><formula xml:id="formula_3">(i) C i φ, i = 1, • • • , k, (ii) k i=1 C i = V, (iii) C i C j = φ, i j.</formula><p>Property (i) states that each cluster cannot be empty. Properties (ii) and (iii) state that every v ∈ V belongs to only one cluster. In this case, C is a partition of the universe. In contrast to the single set representation of a cluster, three-way clustering represents a three-way cluster C i as a pair of sets:</p><formula xml:id="formula_4">C i = (Co(C i ), Fr(C i )),</formula><p>where</p><formula xml:id="formula_5">Co(C i ) ⊂ V and Fr(C i ) ⊂ V. Let Tr(C i ) = V -(Co(C i ) ∪ Fr(C i ))</formula><p>. The three sets, Co(C i ), Fr(C i ) and Tr(C i ) naturally form the Core Region, Fringe Region, and Trivial Region, respectively, of a cluster. That is: </p><formula xml:id="formula_6">CoreRegion(C i ) = Co(C i ), FringeRegion(C i ) = Fr(C i ), TrivialRegion(C i ) = V -(Co(C i ) ∪ Fr(C i )). A C C E P T E D M A N U S C R I P T + Set A Set B Erosion of A by B Dilation of A by B</formula><formula xml:id="formula_7">C i definitely; if x ∈ FringeRegion(C i ), the object x might belong to C i ; if x ∈ TrivialRegion(C i )</formula><p>, the object x does not belong to C i definitely. These subsets have the following properties.</p><formula xml:id="formula_8">Tr(C i ) ∪ Co(C i ) ∪ Fr(C i ) = V, Co(C i ) ∩ Fr(C i ) = φ, Co(C i ) ∩ Tr(C i ) = φ, Fr(C i ) ∩ Tr(C i ) = φ. If Fr(C i ) = φ, the representation of C i turns into C i = Co(C i ). It is a set and Tr(C i ) = U -Co(C i ).</formula><p>This is a representation of two-way decision. The representation of a cluster by a single set is a special case of three-way cluster in which the fringe regions are the empty set.</p><p>There are different requirements on Co(C i ) and Fr(C i ). In this paper, we adopt the following properties:</p><formula xml:id="formula_9">(I) Co(C i ) φ, i = 1, • • • , k, (II) k i=1 (Co(C i ) ∪ Fr(C i )) = V, (III) Co(C i ) ∩ Co(C j ) = φ, i j.</formula><p>Property (I) demands that each cluster cannot be empty. Property (II) states that any element in V must be in the core or the fringe region of at least one cluster. It is possible that an element v ∈ V belongs to more than one cluster. Property (III) requires that the core regions of clusters are pairwise disjoint. Base on the above discussion, we have the following family of clusters to represent the result of three-way clustering:</p><formula xml:id="formula_10">C = {(Co(C 1 ), Fr(C 1 )), (Co(C 2 ), Fr(C 2 )), • • • , (Co(C k ), Fr(C k ))}.</formula><p>Note that the properties of C can be obtained from properties (I)-(III).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Erosion and dilation in mathematical morphology</head><p>Mathematical morphology is a widely used theory in image processing. In mathematical morphology, an image can be viewed as a subset of the integer grid Z d . The basic purpose of mathematical morphology is to transform an image by using a pre-defined shape, which is called a structuring element. There are two basic morphological operations called erosion and dilation <ref type="bibr" target="#b21">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T Definition 2. <ref type="bibr" target="#b21">[22]</ref> Let E be Euclidean space R d or the integer grid Z d , A be a binary image in E, and B be a structuring element. The erosion of the binary image A by the structuring element B is defined by:</p><formula xml:id="formula_11">A B = {x ∈ E | B x ⊆ A},</formula><p>and the dilation of A by the structuring element B is defined by:</p><formula xml:id="formula_12">A ⊕ B = {x ∈ E | Bx ∩ A φ},</formula><p>where B x denotes the translation of the structuring element at a point x and B denotes the symmetrical of B with respect to the origin of the space.</p><p>The erosion and dilation of a binary image A in integer grid Z 2 by the structuring element B is illustrated in Fig. <ref type="figure" target="#fig_2">5</ref>. From Fig. <ref type="figure" target="#fig_2">5</ref>, we can see that erosion operation has the effect of shrinking the image and the dilation operation has the effect of enlarging the image if the origin, denoted by + in Fig. <ref type="figure" target="#fig_2">5</ref>, is in the structuring element B. The results of erosion and dilation depend on the choice of structuring element. Different structuring elements will produce different results of erosion and dilation. Choosing an appropriate size and shape of the structuring element is critical for erosion and dilation operations. Mathematical morphology may provide a sound basis for three-way approaches to clustering. We will present a framework of three-way clustering, which is called CE3, based on the idea of mathematical morphology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">A three-way clustering based on mathematical morphology</head><p>Three-way clustering uses core region and fringe region to represent a cluster rather than a single set. One of the main tasks in three-way clustering is to construct core region and fringe region. There are different strategies for different applications. In this section, a new three-way clustering method will be presented by reconstructing the results from a hard clustering method. The idea comes from erosion and dilation operations in mathematical morphology. Similar to erosion and dilation operations for image processing, we can shrink and stretch each cluster obtained from a hard clustering method based on a pair of operations. We use contraction to indicate the deletion of data points while expansion to indicate the addition of more data points with respect to a specific cluster. Through operations of contraction and expansion, each cluster may shrink to form the core of a three-way cluster and stretch to form the support. The difference between the support and the core is regarded as the fringe region.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">A framework of CE3</head><p>Suppose that a data set</p><formula xml:id="formula_13">V = {v 1 , • • • , v n } has been divided into k clusters C = {C 1 , • • • , C k }</formula><p>by a hard clustering method such as k-means, spectral clustering, and so on. We present a CE3 strategy to transform each cluster C i into (Co(C i ), Fr(C i )). Fig. <ref type="figure">6</ref> describes the framework of the proposed CE3 method. Basically, the process of CE3 consists of two main steps. The first step is to classify data set into k clusters by existing hard clustering method, which aims at obtaining a partition of V. The second step is to apply the contraction and expansion operations on each cluster, which aims at obtaining the core region and fringe region of each cluster, respectively.</p><p>As we have pointed out in Section 2, erosion operation has the effect of shrinking the image and the dilation operation has the effect of enlarging the image if the origin is in the structuring element. Motivated by the erosion and dilation of an image, we can shrink or stretch a cluster according to a defined strategy. In order to extend erosion and dilation operation to a set, we introduce the concept of a structure-generating function.</p><p>8 The idea of structure-generating function comes from structuring element in mathematical morphology. In fact, if we view an image E as a set, any structuring element B can give rise to a structure-generating function by the following relation,</p><formula xml:id="formula_14">A C C E P T E D M A N U S C</formula><formula xml:id="formula_15">S (x) = {y | y ∈ B x },</formula><p>where B x denotes the translation of the structuring element at point x. Therefore, structuregenerating function is a generalization of structuring element in mathematical morphology. Definition 4. Suppose U is a nonempty set equipped with a pair of reflexive structure-generating functions (S 1 , S 2 ) and A is a subset of U. The contraction of A by structure-generating function S 1 is defined by:</p><formula xml:id="formula_16">A S 1 = {x | S 1 (x) ⊆ A}.</formula><p>The expansion of A by structure-generating function S 2 is defined by:</p><formula xml:id="formula_17">A ⊕ S 2 = {x | S 2 (x) ∩ A φ}.</formula><p>We also use and ⊕ to indicate contraction operation and expansion operation, respectively. From Definition 4, we can see that contraction deletes the elements of A that do not satisfy condition S 1 (x) ⊆ A, and expansion adds those elements outside of A that satisfy condition S 2 (x) ∩ A φ. Through contraction and expansion, a set may shrink to a smaller one and stretch to a larger one. We therefore can transform a hard cluster into a three-way cluster through contraction and expansion operations by choosing a pair of appropriate structure-generating functions (S 1 , S 2 ).</p><formula xml:id="formula_18">Definition 5. Suppose C = {C 1 , • • • , C k } is a set of two-way clusters obtained from a hard clus- tering algorithm on a universal set V = {v 1 , • • • , v n } and (S 1 , S 2</formula><p>) are a pair of reflexive structuregenerating functions on V. We define the core region and fringe region C i as,</p><formula xml:id="formula_19">Co(C i ) = C i S 1 = {v | S 1 (v) ⊆ C i }, Fr(C i ) = C i ⊕ S 2 -Co(C i ), where C i ⊕ S 2 = {v | S 2 (v) ∩ C i φ}.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>There are many kinds of structure-generating function for the contraction and expansion operations and different structure-generating function will produce different results of contraction and expansion. All of these methods by contraction and expansion operations on the results of hard clustering are called CE3 methods. An essential issue of CE3 methods is to choose an appropriate pair of reflexive structure-generating functions (S 1 , S 2 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">A neighbor-based CE3 method</head><p>We present a concrete CE3 method based on the framework of CE3. We consider the following semantics to interpret the core region Co(C i ) and the fringe region Fr(C i ): the core region is the area of those elements that are very concentrated and the fringe region is the area of those elements that are relative loosely connected. There are many kinds of method to define the structure-generating function (S 1 , S 2 ) for contraction and expansion operations. We consider a nearest neighbor-based method.</p><p>In the following discussion, we use Neig q (v) to represent the q-nearest objects of v, where q is a given parameter. Before introducing the reflexive structure-generating functions for contraction and expansion operations, we investigate the characteristics of objects in V. Let us take Fig. <ref type="figure">1</ref> as an example. In fact, we can easily divide these data points of Fig. <ref type="figure">1</ref> into two clusters except the six points x 1 , x 2 , x 3 , x 4 , x 5 and x 6 . As for x 1 and x 2 , it is difficult to decide which cluster they belong to, i.e., the left cluster or the right cluster, because they are between the two clusters. As for x 3 and x 4 , although there is no difficulties in choosing a cluster, the distances between them and the center of the cluster are significantly greater than other point-to-center distance. The same case is true for x 5 and x 6 . According to the semantics of the core region and the fringe region, the Co(C 1 ) should be C 1 -{x 1 , x 5 , x 6 } and {x 1 , x 2 , x 5 , x 6 } should be assigned to Fr(C 1 ). This procedure can be explained by the contraction and expansion operation for set C 1 .</p><p>In order to extend the above discussion with Fig. <ref type="figure">1</ref> to a general situation, we examine the characteristics of points x 1 and x 5 . It is easy to see that the distinguished characteristic of x 1 is</p><formula xml:id="formula_20">Neig q (x 1 ) ∩ C 1 φ ∨ Neig q (x 1 ) ∩ C 2 φ.</formula><p>The distinguished characteristics of x 5 are Neig q (x 5 ) ⊂ C 1 and the mean distances between x 5 and Neig q (x 5 ) are much more than the mean distances between all objects of the same cluster and their q-nearest objects.</p><p>Extending the above discussion to set V, we can classify all the objects of V into three types based on the results of a hard clustering:</p><formula xml:id="formula_21">Type I = {v | ∃i j, Neig q (v) ∩ C i φ ∧ Neig q (v) ∩ C j φ}, Type II = {v | ∃i, Neig q (v) ⊂ C i ∧ d &gt; ρd i }, Type III = {v | ∃i, Neig q (v) ⊂ C i ∧ d &lt; ρd i },</formula><p>where ρ &gt; 1 is a parameter, d is the mean distance between v and Neig q (v) and d i is the mean value of d for all v ∈ C i . According to the semantics of core region and fringe region, we use the following strategy to reconstruct the clusters: the objects in Type I and Type II should be assigned to fringe region and the objects in Type III should be assigned to core region of the corresponding cluster. Based on the above strategy, we can define the following structuregenerating functions S 1 for contraction and S 2 for expansion on cluster C i if V has been divided</p><formula xml:id="formula_22">A C C E P T E D M A N U S C R I P T into k clusters C = {C 1 , • • • , C k }</formula><p>by a two-way clustering method:</p><formula xml:id="formula_23">S 1 (v) = V, d &gt; ρd i Neig q (v), d ≤ ρd i , S 2 (v) = Neig q (v),</formula><p>where v is any element of V, ρ &gt; 1 is a given parameter, d is the mean distance between v and Neig q (v), and d i is the mean value of d for all v ∈ C i . It can be easily seen that S 1 and S 2 are reflexive. Using the definitions of contraction and expansion, we express the core region and fringe region of cluster C i as,</p><formula xml:id="formula_24">Co(C i ) = C i S 1 = {v | S 1 (v) ⊆ C i }, Fr(C i ) = C i ⊕ S 2 -Co(C i ),</formula><p>where</p><formula xml:id="formula_25">C i ⊕ S 2 = {v | S 2 (v) ∩ C i φ}.</formula><p>Through contraction and expansion operations, cluster C i can be represented by a pair of set (Co (C i ) , Fr(C i )). The procedure of this reconstruction of clusters is referred as neighbor-based CE3. By using the proposed method, from the results of Fig. <ref type="figure">1</ref>, we can obtain three-way clusters as shown in Fig. <ref type="figure">3</ref>. Algorithm 1 is a procedure of neighbor-based CE3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1. Neighbor-based CE3 method</head><formula xml:id="formula_26">Input: A set of objects V = {v 1 , • • • , v n }, the number of clusters k, parameters q and ρ. Output: C = {(Co(C 1 ), Fr(C 1 )), (Co(C 2 ), Fr(C 2 )), • • • , (Co(C k ), Fr(C k ))}. 1. Divide V = {v 1 , • • • , v n } into k clusters C = {C 1 , • • • , C k } by a hard clustering method.</formula><p>2. For each object v, compute its q-nearest neighborhood Neig q (v).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Given a cluster</head><formula xml:id="formula_27">C i , for each object v C i , if Neig q (v) C i φ, then v ∈ Fr(C i ). 4. For each object v j ∈ C i , if Neig q (v j ) C i , then v ∈ Fr(C i ).</formula><p>Otherwise, compute the average distance d j between v j and its q-nearest neighborhood Neig q (v) and the mean</p><formula xml:id="formula_28">d i of all d j for v j ∈ C i . If d j &lt; ρd i , then v ∈ Co(C i ). If d j &gt; ρd i , then v j ∈ Fr(C i ). 5. Return {(Co(C 1 ), Fr(C 1 )), (Co(C 2 ), Fr(C 2 )), • • • , (Co(C k ), Fr(C k ))}.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CE3 k-means</head><p>The previous discussion gives a framework for reconstructing hard clusters into three-way clusters. In this section, we will apply CE3 strategy to the results of k-means clustering to obtain a CE3 k-means algorithm.</p><p>As one of the simplest unsupervised learning algorithms, k-means was first proposed by Macqueen <ref type="bibr" target="#b53">[54]</ref>. The main idea of k-means is to use centroids to represent a cluster. The process can be viewed as iteration of reassignments of objects to k clusters, that is, each object is assigned to the nearest centroid. K-means algorithm aims at minimizing the following objective function,</p><formula xml:id="formula_29">J = min k j=1 v i ∈C j ||v i -µ j || 2 , A C C E P T E D M A N U S C R I P T Algorithm 2. K-means clustering algorithm. Input: A set of objects V = {v 1 , • • • , v n } ∈ R l , number of clusters k. Output: Clusters C = {C 1 , C 2 , • • • , C k }.</formula><p>1. Randomly place k objects into the space represented by the objects that are being clustered.</p><p>These objects represent initial group centroids</p><formula xml:id="formula_30">µ 1 , µ 2 , • • • , µ k .</formula><p>2. Assign each object to the group that has the closest centroid</p><formula xml:id="formula_31">C i = {v j |d(v j , µ i ) ≤ d(v j , µ l ), (l i), j = 1, 2, • • • , n}.</formula><p>3. When all objects have been assigned, recalculate the positions of the k centroids µ i =</p><formula xml:id="formula_32">1 |C i | j∈C i V j , i = 1, 2, • • • , k.</formula><p>4. Repeat Steps 2 and 3 until the centroids no longer change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Return</head><formula xml:id="formula_33">C = {C 1 , C 2 , • • • , C k }.</formula><p>where ||v iµ j || is a chosen distance measure between a data point v i and the cluster centre µ j of j-th cluster.</p><p>A standard k-means clustering algorithm has four steps. We give the procedure of k-means clustering algorithm in Algorithm 2. Based on the clustering results of k-means algorithm, we introduce a CE3 k-means algorithm by using the proposed CE3 strategy. The procedure of the algorithm has two main steps. The first step is to execute k-means procedures with the data and the second step is to compute the core region and fringe region of each cluster. A CE3 k-means algorithm is given as Algorithm 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3. CE3 k-means algorithm</head><formula xml:id="formula_34">Input: A set of objects V = {v 1 , • • • , v n } ∈ R l , number of clusters k, parameters q and ρ. Output: {(Co(C 1 ), Fr(C 1 )), Co(C 2 ), Fr(C 2 )), • • • , Co(C k ), Fr(C k ))}.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Execute step 1-4 of Algorithm 2 and obtained k clusters</head><formula xml:id="formula_35">C = {C 1 , • • • , C k } by spectral clustering method.</formula><p>2. For each object v, compute its q-nearest neighborhood Neig q (v).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Given a cluster</head><formula xml:id="formula_36">C i , for each object v C i , if Neig q (v) C i φ, then v ∈ Fr(C i ). 4. For each object v j ∈ C i , if Neig q (v j ) C i , then v ∈ Fr(C i ).</formula><p>Otherwise, compute the average distance d j between v j and its q-nearest neighborhood Neig q (v) and the mean</p><formula xml:id="formula_37">d i of all d j for v j ∈ C i . If d j &lt; ρd i , then v ∈ Co(C i ). If d j &gt; ρd i , then v j ∈ Fr(C i ). 5. Return {(Co(C 1 ), Fr(C 1 )), (Co(C 2 ), Fr(C 2 )), • • • , (Co(C k ), Fr(C k ))}.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CE3 spectral clustering</head><p>In this section, we first review spectral clustering algorithm and then apply CE3 framework to spectral clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Review of spectral clustering algorithm</head><p>Spectral clustering <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b58">59</ref>] is a clustering method based on graph theory, which was first suggested by Donath and Hoffman <ref type="bibr" target="#b54">[55]</ref> to construct graph partitions based on eigenvectors of the adjacency matrix. The idea of spectral clustering is to view objects as vertices and similarities between objects as weighted edges. It turns a clustering problem into a graph segmentation problem. The aim of spectral clustering is to find a graph segmentation method that makes the weights of the edges connecting different clusters as low as possible and the weights of the edges within a cluster as high as possible. A comprehensive review of spectral clustering can be found in <ref type="bibr" target="#b56">[57]</ref>. We review some related concepts of spectral clustering and NJW algorithm presented by Ng, Jordan and Weiss <ref type="bibr" target="#b59">[60]</ref>.</p><p>Let G = (V, E) be an undirected weighted graph with vertex set</p><formula xml:id="formula_38">V = {v 1 , • • • , v n }.</formula><p>Each vertex v i in this graph represents an object and non-negative weight w i j represents the similarity of two vertices v i and v j . The weighted adjacency matrix of the graph is the matrix W = (w i j ), i, j = 1, • • • , n. As G is undirected grape, it means W is symmetric, i.e., w i j = w ji . Matrix W is a similarity matrix between data points and contains all the information needed for clustering. The basic idea of spectral clustering is to find a partition of the graph such that the edges between different groups have a low similarity and the edges within a group have a high similarity.</p><p>In graph theory, there are different objective functions to separate a graph, the most popular methods in spectral clustering are RatioCut, NCut and MinMaxCut. The objective functions of them are the following, respectively,</p><formula xml:id="formula_39">RatioCut(C 1 , C 2 , • • • , C k ) = k i=1 Cut(C i , Ci ) |C i | , NCut(C 1 , C 2 , • • • , C k ) = k i=1 Cut(C i , Ci ) Vol(C i ) , MinMaxCut(C 1 , C 2 , • • • , C k ) = k i=1 Cut(C i , Ci ) Cut(C i , C i ) ,</formula><p>where Ci is the complement of</p><formula xml:id="formula_40">C i , Cut(C i , Ci ) = u∈C i ,v∈ Ci w(u, v), Cut(C i , C i ) = u∈C i ,v∈C i w(u, v), |C i | is the number of vertices in C i and Vol(C i ) = i∈C i n j=1 w i j .</formula><p>The working of most spectral clustering algorithms can be explained in a three-step process. The first step is to construct the similarity matrix representing the data sets. The second step is to compute eigenvalues and eigenvectors of the Laplacian matrix and to map each point to a lowerdimensional representation based on one or more eigenvectors. The third step is to assign points to two or more classes, based on the new representation. Taking NJW algorithm for example, we give the procedure of spectral clustering in Algorithm 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">CE3 spectral clustering algorithm</head><p>The primary task of spectral clustering is to construct a similar matrix that represent the degrees of similarity between data points. There are many ways to calculate similarity. The</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T Algorithm 4. NJW algorithm</head><formula xml:id="formula_41">Input: A set of objects V = {v 1 , • • • , v n } ∈ R l , number of clusters k, parameter σ. Output: C = {C 1 , C 2 , • • • , C k }.</formula><p>1. Form the similarity matrix W defined by w i j = exp(-</p><formula xml:id="formula_42">d 2 (v i ,v j )</formula><p>2σ 2 ), i j, and w ii = 0. 2. Define D to be the diagonal matrix whose (i, i)-element is the sum of A s i-th row, and construct the matrix</p><formula xml:id="formula_43">L = D -1 2 WD 1 2</formula><p>3. Find the first k eigenvectors of L (chosen to be orthogonal to each other in the case of repeated eigenvalues), and form the matrix U by stacking the eigenvectors in columns</p><formula xml:id="formula_44">X = [x 1 , x 2 , • • • , x k ] ∈ R n×k .</formula><p>4. Form the matrix Y from X by normalizing each of X s rows to have unit length,</p><formula xml:id="formula_45">Y i j = X i j j X 2 i j . 5.</formula><p>Treat each row of Y as a point in R k and classify them into k classes via k-means algorithm.</p><p>6. Assign the original points v i to cluster j if and only if row i of the matrix Y was assigned to cluster j.</p><formula xml:id="formula_46">7. Return C = {C 1 , C 2 , • • • , C k }.</formula><p>Gaussian kernel function is a commonly used similarity function. The expression of Gaussian kernel function is given by</p><formula xml:id="formula_47">w i j = exp(- d 2 (v i , v j ) 2σ 2 )</formula><p>, where σ is a scale parameter and d(v i , v j ) is the Euclidean distance.</p><p>The procedure of CE3 spectral algorithm has two main steps. The first step is to construct two-way clusters by spectral clustering. The second step is to compute the core region and fringe region of each cluster. A CE3 spectral clustering algorithm based on Gaussian kernel is given by Algorithm 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experimental evaluation</head><p>In this section, we report the results of a series of experiments conducted to evaluate the effectiveness and efficiency of CE3 algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Evaluation measures</head><p>The evaluation of clusters, also referred to as cluster validity, is a crucial process to assess the performance of a clustering algorithm. A good measure of cluster quality enables us to compare several clustering methods. The following quantitative indices are often used to evaluate the performance of clustering algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T Algorithm 5. CE3 spectral clustering algorithm based on Gaussian kernel</head><formula xml:id="formula_48">Input: A set of objects V = {v 1 , • • • , v n } ∈ R l , number of clusters k, parameters σ, q and ρ. Output: {(Co(C 1 ), Fr(C 1 )), (Co(C 2 ), Fr(C 2 )), • • • , (Co(C k ), Fr(C k ))}. 1. Execute Step 1-7 of Algorithm 4 and obtained k clusters C = {C 1 , • • • , C k } by spectral clustering method.</formula><p>2. For each object v, compute its q-nearest neighborhood Neig q (v).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Given a cluster</head><formula xml:id="formula_49">C i , for each object v C i , if Neig q (v) C i φ, then v ∈ Fr(C i ). 4. For each object v j ∈ C i , if Neig q (v j ) C i , then v ∈ Fr(C i ).</formula><p>Otherwise, compute the average distance d j between v j and its q-nearest neighborhood Neig q (v) and the mean</p><formula xml:id="formula_50">d i of all d j for v j ∈ C i . If d j &lt; ρd i , then v ∈ Co(C i ). If d j &gt; ρd i , then v j ∈ Fr(C i ). 5. Return {(Co(C 1 ), Fr(C 1 )), (Co(C 2 ), Fr(C 2 )), • • • , (Co(C k ), Fr(C k ))}. DB = 1 c c i=1 max j i S (C i ) + S (C j ) d(x i , x j ) ,<label>(1)</label></formula><p>where S (C i ) and d(x i , x j ) are the intra-cluster distance and the inter-cluster separation, respectively, and S (C i ) is defined as follows:</p><formula xml:id="formula_51">S (C i ) = v∈C i v -x i | C i | .<label>(2)</label></formula><p>As a function of the ratio of the within cluster scatter to the between cluster separation, a lower value will mean that a clustering algorithm is better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Accuracy (ACC hereafter):</head><formula xml:id="formula_52">ACC = k c=1 n j c n ,<label>(3)</label></formula><p>where n j c is the number of common objects in the c-th cluster and its matched class j after obtaining a one-to-one match between clusters and classes. A higher the value indicates a better clustering result. The value equals to 1 only when the clustering result matches the classification.</p><p>The goal of clustering is to partition n objects into k desired clusters with high intra-class similarity and low inter-class similarity. In three-way clustering, a cluster is represented by core region and fringe region rather than a single set. The core region is an area where the elements are highly concentrated and the fringe region is an area where the elements are loosely concentrated. In order to identify the three-way clustering quality, we denote core region as lower bound and the union of core region and fringe region as upper bound (i.e., the support). We compute DB index and ACC by using lower bounds and upper bounds of three-way clustering, respectively. A better three-way clustering results should have a lower DB value on lower bounds sets and a higher ACC on upper bounds sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Efficiency of algorithms</head><p>To illustrate the effectiveness of CE3 algorithm, one synthetic data set, four UCI <ref type="bibr" target="#b62">[63]</ref> data sets and three USPS <ref type="bibr" target="#b63">[64]</ref> data sets are employed. All codes are run in Matlab R2013b with machine precision 10 -16 on a personal computer and the parameters of CE3 clustering are q = 15 and ρ = 1.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1.">Synthetic data set</head><p>One synthetic two dimensional data set with 1590 objects is tested to illustrate the method presented in the previous section. The results of spectral clustering and CE3 spectral clustering are depicted in Fig. <ref type="figure">7</ref> and Fig. <ref type="figure" target="#fig_3">8</ref>, respectively.  From Fig. <ref type="figure">7</ref>, we can see that these objects are clustered into two clusters and each object belongs to only one cluster by spectral clustering. Compared to the traditional spectral clustering, CE3 spectral clustering algorithm finds core region and fringe region of every cluster and the overlapping parts of two classes. There are 80 objects in the fringe region of clusters C 1 and 90 objects in the fringe region of clusters C 2 , where 17 objects are overlapping. In fact, it is more significant to find overlapping objects in some applications such as social network analysis <ref type="bibr" target="#b64">[65]</ref> and web mining <ref type="bibr" target="#b17">[18]</ref>. If we are forced to assign the overlapping points to one cluster, it will be reduce the effectiveness of classification in the learning of labeled data, which is verified in the following experiment on UCI data sets.</p><p>From the experiment result we can see that the proposed algorithm can not only find the overlapping part of the class but also analyze the compactness of objects in one cluster, which provides more information to facilitate the further analysis of the clustering results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2.">UCI data sets</head><p>To test the performance of our proposed algorithm, four data sets from UCI Machine Leaning repository <ref type="bibr" target="#b62">[63]</ref> are employed. The details of these data sets are shown in Table <ref type="table" target="#tab_2">1</ref>. The performances of CE3 k-means and CE3 spectral clustering are reported on four UCI data sets. In order to measure the CE3 re-clustering efficiency, we denote core region as the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T lower bound and the union of core region and fringe region as the upper bound. We use all the core regions to form a clustering result and denote DB index and ACC on it as DB l and ACC l . Similarly, we use all the upper bounds to form a clustering result and denote DB index and ACC on it as DB u and ACC u . For comparing the clustering effect, the performances of HCM <ref type="bibr" target="#b53">[54]</ref>, SC <ref type="bibr" target="#b59">[60]</ref>, FCM <ref type="bibr" target="#b26">[27]</ref>, RFCM <ref type="bibr" target="#b31">[32]</ref>, ECM <ref type="bibr" target="#b65">[66]</ref> and RECM <ref type="bibr" target="#b66">[67]</ref> are also presented on each data set. These experiments are repeated 100 times for each data set. The average values and the best values of the two indices in 100 times runs are used to compare the overall performance. The results are presented in Tables <ref type="table" target="#tab_3">2</ref><ref type="table">3</ref><ref type="table" target="#tab_4">4</ref><ref type="table" target="#tab_5">5</ref><ref type="table" target="#tab_6">6</ref><ref type="table" target="#tab_7">7</ref><ref type="table" target="#tab_8">8</ref><ref type="table" target="#tab_9">9</ref>.  also between ACC l and ACC u obtained by CE3 clustering methods. In fact, since the upper bounds are expansion of hard clusterw, the number of common objects in the i-th cluster and its matched class are obviously higher than hard clustering results. On the contrary, since the lower bounds are contraction of hard cluster,the number of common objects in the i-th cluster and its matched class are obviously smaller than hard clustering results.</p><p>Conclusions 1 to 3 show that the lower bounds of CE3 clustering are areas where the elements are highly concentrated and the elements between upper bounds and lower bounds reduced data concentration. Dividing a cluster into a core region and a fringe region shows that CE3 reveals better cluster structures than hard clustering methods do.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3.">USPS data sets</head><p>USPS ZIP code handwritten digits database <ref type="bibr" target="#b63">[64]</ref> consists of 16 × 16 gray scale images and each image is represented by a 256-dimensional vector. We use three USPS data sets: digits 4 and 9 (USPS-49), 0 and 8 (USPS-08) and digits 3, 5, 6 and 8 (USPS-3568) which are known difficult to differentiate. The characteristics of these three data sets are given in Table <ref type="table" target="#tab_10">10</ref>.</p><p>This experiment is repeated 100 times for each data set. The average values and the best values of the two indices in 100 runs are used to compare the overall performance. The results of CE3 k-means and CE3 spectral clustering on three USPS data sets are presented in Tables <ref type="table" target="#tab_11">11</ref><ref type="table" target="#tab_12">12</ref><ref type="table" target="#tab_13">13</ref><ref type="table" target="#tab_14">14</ref>. The performances of HCM <ref type="bibr" target="#b53">[54]</ref>, SC <ref type="bibr" target="#b59">[60]</ref>, DTRCM <ref type="bibr" target="#b67">[68]</ref>, and RECM <ref type="bibr" target="#b66">[67]</ref> on USPS data sets are included in Tables <ref type="table" target="#tab_15">15</ref><ref type="table" target="#tab_16">16</ref><ref type="table" target="#tab_17">17</ref><ref type="table" target="#tab_18">18</ref>. It can be seen that most of DB values and ACC values obtained by HCM, SC, DTRCM and RECM are between DB u and DB l obtained by CE3 clustering methods.</p><p>The three experiments confirm again that the lower bounds of CE3 clustering is an area where the elements are highly concentrated and the elements between upper bounds and lower bounds reduced data concentration. Dividing a cluster into a core region and a fringe region shows that CE3 clustering gives more details of cluster structures than two-way clustering methods do.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Concluding Remarks</head><p>In many applications such as social network analysis and web mining, an object may belong to more than one cluster and cluster boundaries may overlap. In this paper, we developed a general framework of CE3 for converting two-way clusters to three-way clusters. CE3 employs the ideas of corrosion and expansion from mathematical morphology. According to q-nearest neighborhoods of data points in a cluster obtained from a hard clustering method, it contracts and expands, respectively, the cluster to form the core and support of a three-way cluster. The fringe region of the resulting three-way cluster consists of both overlapping points and discrete points. By applying CE3 on the top of existing hard clustering methods, we investigated in particular a neighbor-based CE3 k-means algorithm and a CE3 spectral clustering algorithm. Experimental results on several datasets show that the new algorithms can significantly improve the structure of clustering results, in comparison with some traditional clustering algorithms.</p><p>The present study is a first step towards a new type of three-way clustering, that is, refining the results of a hard clustering algorithm into three-way clusters, rather than constructing threeway clusters from scratch as existing methods do. The following two topics will be studied as future research. First, parameters q and ρ and the number of clusters have a great impact on the clustering results. How to determine the parameter and the number of clusters is an interesting topic. Second, multi-granulation is a recent topic in granular computing and can be used for the constructing approximations with respect to multiple granulations. Our proposed algorithm is based on a single granulation. How to develop three-way clustering based on multigranulations needs further attention.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>6 Fig. 1 AFig. 3</head><label>613</label><figDesc>Fig. 1 A schematic diagram of data set</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 Trisecting-and-acting model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5</head><label>5</label><figDesc>Fig. 5 Erosion and dilation of set A by the structuring element B</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 8</head><label>8</label><figDesc>Fig. 8 C&amp;E spectral re-clustering result</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>18 A</head><label>18</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>R I P T</figDesc><table><row><cell></cell><cell></cell><cell>Cluster C 1</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Cluster C 2</cell><cell>Contraction</cell><cell>Obtain the core region</cell></row><row><cell>Dataset V ...</cell><cell>Hard clustering</cell><cell>Cluster C 3 ...</cell><cell>Expansion</cell><cell>Obtain the fringe region</cell></row><row><cell></cell><cell></cell><cell>Cluster C k</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">Fig. 6 The structural framework of CE3 method</cell><cell></cell></row></table><note><p>Definition 3. Suppose U is a nonempty set. A mapping S : U → 2 U is called a structuregenerating function and S (x) is called a structuring element of x ∈ U. A structure-generating function S is reflexive if x ∈ S (x) for any x ∈ U. A set U equipped with a structure-generating function S is denoted by a pair (U, S ).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>A description of UCI data sets used in the experiments</figDesc><table><row><cell>ID</cell><cell>Data sets</cell><cell>Samples</cell><cell>Attributes</cell><cell>Classes</cell></row><row><cell>1</cell><cell>IRIS</cell><cell>150</cell><cell>4</cell><cell>3</cell></row><row><cell>2</cell><cell>WINE</cell><cell>178</cell><cell>13</cell><cell>3</cell></row><row><cell>3</cell><cell>WDBC</cell><cell>569</cell><cell>30</cell><cell>2</cell></row><row><cell>4</cell><cell>GLASS</cell><cell>214</cell><cell>9</cell><cell>6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Average performances of CE3 kmeans on UCI data sets</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Table 3: Best performances of CE3 k-means</cell></row><row><cell></cell><cell></cell><cell cols="2">re-clustering on UCI data sets</cell></row><row><cell>Data set DB l</cell><cell>DB u ACC l ACC u</cell><cell>Data set DB l</cell><cell>DB u ACC l ACC u</cell></row><row><cell cols="2">IRIS 0.7179 1.2075 0.6499 0.8315</cell><cell cols="2">IRIS 0.6357 1.1529 0.7067 0.9067</cell></row><row><cell cols="2">WINE 1.1270 2.3742 0.8363 0.9735</cell><cell cols="2">WINE 1.1077 2.3486 0.8483 0.9831</cell></row><row><cell cols="2">WDBC 1.0168 1.8882 0.7680 0.9490</cell><cell cols="2">WDBC 1.0101 1.8880 0.7689 0.9501</cell></row><row><cell cols="2">GLASS 1.1857 2.8308 0.3934 0.5146</cell><cell cols="2">GlASS 0.7332 1.7217 0.4486 0.5841</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Average performances of CE3 spectral clustering on UCI data sets</figDesc><table><row><cell>Data set DB l</cell><cell>DB u ACC l ACC u</cell></row><row><cell cols="2">IRIS 0.7386 1.1829 0.6802 0.8688</cell></row><row><cell cols="2">WINE 1.1508 2.3303 0.8539 0.9831</cell></row><row><cell cols="2">WDBC 1.0817 1.8904 0.7645 0.9402</cell></row><row><cell cols="2">GLASS 1.2447 2.513 0.3712 0.4589</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Best performances of CE3 spectral clustering on UCI data sets</figDesc><table><row><cell>Data set DB l</cell><cell>DB u ACC l ACC u</cell></row><row><cell cols="2">IRIS 0.6249 1.1264 0.6933 0.8867</cell></row><row><cell cols="2">WINE 1.1127 2.2387 0.8713 0.9910</cell></row><row><cell cols="2">WDBC 1.0571 1.6847 0.7745 0.9511</cell></row><row><cell cols="2">GLASS 0.8761 1.9955 0.4065 0.5374</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Average DB values of different algorithm on UCI data sets</figDesc><table><row><cell cols="2">Algorithms IRIS WINE WDBC GLASS</cell></row><row><cell>HCM</cell><cell>0.7909 1.3161 1.1363 1.2005</cell></row><row><cell>SC</cell><cell>0.7672 1.3069 1.1754 1.2330</cell></row><row><cell>FCM</cell><cell>0.7969 1.5623 1.2577 1.8530</cell></row><row><cell cols="2">RFCM 0.7352 1.2288 1.0772 1.2219</cell></row><row><cell>ECM</cell><cell>0.6930 1.4536 1.1437 1.8812</cell></row><row><cell cols="2">RECM 0.7812 1.3237 1.1458 1.4924</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Best DB values of different algorithm on UCI data sets</figDesc><table><row><cell cols="2">Algorithms IRIS WINE WDBC GLASS</cell></row><row><cell>HCM</cell><cell>0.7610 1.3053 1.1363 0.9542</cell></row><row><cell>SC</cell><cell>0.6973 1.3069 1.1754 1.1372</cell></row><row><cell>FCM</cell><cell>0.7926 1.5620 1.2576 1.2104</cell></row><row><cell cols="2">RFCM 0.7212 1.0947 1.0764 0.9457</cell></row><row><cell>ECM</cell><cell>0.6813 1.4461 1.1418 1.6416</cell></row><row><cell cols="2">RECM 0.7700 1.3115 1.1432 1.1703</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>Average ACC values of different algorithm on UCI data sets</figDesc><table><row><cell cols="2">Algorithms IRIS WINE WDBC GLASS</cell></row><row><cell>HCM</cell><cell>0.8187 0.9407 0.9219 0.4655</cell></row><row><cell>SC</cell><cell>0.8555 0.9663 0.9262 0.4371</cell></row><row><cell>FCM</cell><cell>0.8453 0.9494 0.9279 0.3872</cell></row><row><cell cols="2">RFCM 0.7983 0.9561 0.9306 0.3983</cell></row><row><cell>ECM</cell><cell>0.8471 0.9401 0.9279 0.4012</cell></row><row><cell cols="2">RECM 0.8506 0.9343 0.9286 0.3880</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9 :</head><label>9</label><figDesc>Best ACC values of different algorithm on UCI data sets degree of separation on the lower bounds and improve the accuracy of classification on the upper bounds. 2. Most of DB values obtained by two-way clustering methods are between DB u and DB l obtained by CE3 clustering methods. This is because the lower bounds are contraction of hard clusters and separated from each other while upper bounds are expansion of hard clusters and may intersect each other. Compared to the existing two-way clustering methods, CE3 clustering methods have a lower intra-cluster distance and a higher inter-cluster separation. 3. Similar to DB values, most of ACC values obtained by two-way clustering methods are</figDesc><table><row><cell cols="2">Algorithms IRIS WINE WDBC GLASS</cell></row><row><cell>HCM</cell><cell>0.7610 1.3053 1.1363 0.9542</cell></row><row><cell>SC</cell><cell>0.6973 1.3069 1.1754 1.1372</cell></row><row><cell>FCM</cell><cell>0.7926 1.5620 1.2576 1.2104</cell></row><row><cell cols="2">RFCM 0.7212 1.0947 1.0764 0.9457</cell></row><row><cell>ECM</cell><cell>0.6813 1.4461 1.1418 1.6416</cell></row><row><cell cols="2">RECM 0.7700 1.3115 1.1432 1.1703</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 :</head><label>10</label><figDesc>A description of USPS data sets in the experiments</figDesc><table><row><cell>ID</cell><cell>Data sets</cell><cell>Samples</cell><cell>Attributes</cell><cell>Classes</cell></row><row><cell>1</cell><cell>USPS-08</cell><cell>1736</cell><cell>256</cell><cell>2</cell></row><row><cell>2</cell><cell>USPS-49</cell><cell>1296</cell><cell>256</cell><cell>2</cell></row><row><cell>3</cell><cell>USPS-3568</cell><cell>2420</cell><cell>256</cell><cell>4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 11 :</head><label>11</label><figDesc>Average performances of CE3 kmeans on USPS data sets Data set DB l DB u ACC l ACC u USPS-49 2.3499 4.1980 0.6431 0.7877 USPS-08 1.7603 2.9487 0.6993 0.8554 USPS-3568 2.6359 4.6693 0.6561 0.7515</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 12 :</head><label>12</label><figDesc>Best performances of CE3 k-means clustering on USPS data sets Data set DB l DB u ACC l ACC u USPS-49 2.3340 4.0481 0.6682 0.8094 USPS-08 1.7583 2.9361 0.7039 0.8594 USPS-3568 2.3493 4.2203 0.7822 0.9041</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 13 :</head><label>13</label><figDesc>Average performances of CE3 spectral clustering on USPS data sets Data set DB l DB u ACC l ACC u USPS-49 2.3795 3.9360 0.6455 0.7732 USPS-08 1.7487 2.8912 0.7212 0.8756 USPS-3568 2.5413 4.4832 0.5646 0.6518</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 14 :</head><label>14</label><figDesc>Best performances of CE3 spectral clustering on USPS data sets Data set DB l DB u ACC l ACC u USPS-49 2.3786 3.9294 0.6458 0.7739 USPS-08 1.7487 2.8912 0.7212 0.8756 USPS-3568 2.4400 4.3328 0.6694 0.7843</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 15 :</head><label>15</label><figDesc>Average DB values of different algorithm on USPS data sets</figDesc><table><row><cell cols="3">Algorithms USPS-49 USPS-08 USPS-3568</cell></row><row><cell>HCM</cell><cell>2.5548 1.9280</cell><cell>2.8101</cell></row><row><cell>SC</cell><cell>2.4979 1.9187</cell><cell>2.7106</cell></row><row><cell cols="2">DTHCM 2.5339 1.9082</cell><cell>2.7997</cell></row><row><cell>RECM</cell><cell>2.6360 2.0543</cell><cell>3.3169</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 16 :</head><label>16</label><figDesc>Best DB values of different algorithm on USPS data sets</figDesc><table><row><cell cols="3">Algorithms USPS-49 USPS-08 USPS-3568</cell></row><row><cell>HCM</cell><cell>2.5423 1.9262</cell><cell>2.5370</cell></row><row><cell>SC</cell><cell>2.4967 1.9187</cell><cell>2.5955</cell></row><row><cell cols="2">DTHCM 2.5233 1.9005</cell><cell>2.5370</cell></row><row><cell>RECM</cell><cell>2.4962 1.9292</cell><cell>2.8507</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 17 :</head><label>17</label><figDesc>Average ACC values of different algorithm on USPS data sets</figDesc><table><row><cell cols="3">Algorithms USPS-49 USPS-08 USPS-3568</cell></row><row><cell>HCM</cell><cell>0.7345 0.8367</cell><cell>0.7206</cell></row><row><cell>SC</cell><cell>0.7482 0.8612</cell><cell>0.6299</cell></row><row><cell cols="2">DTHCM 0.7673 0.8396</cell><cell>0.7204</cell></row><row><cell>RECM</cell><cell>0.7314 0.7829</cell><cell>0.6263</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 18 :</head><label>18</label><figDesc>Best ACC values of different algorithm on USPS data sets</figDesc><table><row><cell cols="3">Algorithms USPS-49 USPS-08 USPS-3568</cell></row><row><cell>HCM</cell><cell>0.7677 0.8410</cell><cell>0.8694</cell></row><row><cell>SC</cell><cell>0.7492 0.8612</cell><cell>0.7529</cell></row><row><cell cols="2">DTHCM 0.7714 0.8450</cell><cell>0.8694</cell></row><row><cell>RECM</cell><cell>0.8333 0.8773</cell><cell>0.7504</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Davies-Bouldin index<ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b61">62]</ref> (DB hereafter):</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors are grateful to anonymous reviewers for their valuable comments and suggestions. This work was supported in part by National Natural Science Foundation of China (Nos. 61503160 and 61572242), Natural Science Foundation of the Jiangsu Higher Education Institutions of China (No. 15KJB110004), and a Discovery Grant from NSERC, Canada.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Advances in three-way decisions and granular computing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Fujita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl.-Bsed Syst</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A triarchic theory of granular computing</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Granul. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="145" to="157" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Toward a theory of fuzzy information granulation and its centrality in human reasoning and fuzzy logic</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fuzzy Set Syst</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="111" to="127" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Human-centric information processing through granular modelling</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yao</surname></persName>
		</author>
		<editor>A. Bargiela and W. Pedrycz</editor>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="31" to="47" />
		</imprint>
	</monogr>
	<note>Integrative levels of granularity</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neighborhood rough set based heterogeneous feature subset selection</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">178</biblScope>
			<biblScope unit="page" from="3577" to="3594" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Some issues on rough sets</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Pawlak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions on Rough Sets I 3100</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Grouping granular structures in human granulation intelligence</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Dang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">382</biblScope>
			<biblScope unit="issue">383</biblScope>
			<biblScope unit="page" from="150" to="169" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Resilience analysis of critical infrastructures: a cognitive approach based on granular computing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Fujita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gaeta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Loia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Orciuoli</surname></persName>
		</author>
		<ptr target="http://ieeexplore.ieee.org/document/8327881/" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Granular computing analysis and design of intelligent systems</title>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>CRC Press</publisher>
			<pubPlace>Boca Raton</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Survey of clustering algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Wunsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="645" to="678" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A framework of three-way cluster analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Rough Sets</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="300" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Detecting and refining overlapping regions in complex networks with threeway decisions</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">373</biblScope>
			<biblScope unit="page" from="21" to="41" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A tree-based incremental overlapping clustering method using the three-way decision theory</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl.-Based Syst</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="189" to="203" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Three-way decision: an interpretation of rules in rough set theory</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RSKT&apos;09</title>
		<meeting>RSKT&apos;09</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5589</biblScope>
			<biblScope unit="page" from="642" to="649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Three-way decisions with probabilistic rough sets</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">180</biblScope>
			<biblScope unit="page" from="341" to="353" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The superiority of three-way decisions in probabilistic rough set models</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="page" from="1080" to="1096" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An outline of a theory of three-way decisions</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RSCTC&apos;12</title>
		<meeting>RSCTC&apos;12</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">7413</biblScope>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Interval set clustering of web users with rough k-means</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lingras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Intell. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="5" to="16" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Rough clustering</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lingras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">WIRES Data Min. Knowl</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="64" to="72" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Interval set cluster analysis: a re-formulation</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lingras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename><surname>Miao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RSFDGrC&apos;09</title>
		<meeting>RSFDGrC&apos;09</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5908</biblScope>
			<biblScope unit="page" from="398" to="405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Random sets and integral geometry</title>
		<author>
			<persName><forename type="first">G</forename><surname>Matheron</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Serra</surname></persName>
		</author>
		<title level="m">Image Analysis and Mathematical Morphology</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Some relationships between fuzzy sets, mathematical morphology, rough sets, ftransforms, and formal concept analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Atif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hudelot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Uncertain Fuzz</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">On links between mathematical morphology and rough sets, Pattern Recogn</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bloch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1487" to="1496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Relations in mathematical morphology with applications to graphs and rough sets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Stell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COSIT&apos;07</title>
		<meeting>COSIT&apos;07</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="438" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">C&amp; E re-clustering: Reconstruction of clustering results by three-way strategy</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ISMIS&apos;17</title>
		<meeting>ISMIS&apos;17</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10352</biblScope>
			<biblScope unit="page" from="540" to="549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Pattern recognition with fuzzy objective function algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bezdek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>Plenum Press</publisher>
			<pubPlace>NewYork</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Fuzzy cluster analysis: methods for classification, data analysis and image recognition</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hoppner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Klawonn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kruse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Runkler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Wiley</publisher>
			<pubPlace>Chichester</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Rough sets</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Pawlak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="314" to="356" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Rough sets: theoretical aspects of reasoning about data</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Pawlak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Boston</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Applying rough set concepts to clustering</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lingras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rough Sets: Selected Methods and Applications in Management and Engineering</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="23" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Rough-fuzzy collaborative clustering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Banka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern. B</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="795" to="805" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Shadowed sets: representing and processing fuzzy sets</title>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern. B</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="103" to="109" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Shadowed c-means: integrating fuzzy and rough clustering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Barman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="1282" to="1291" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A extraction method of overlapping cluster based on network structure analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Takaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Conferences on Web Intelligence and Intelligent Agent Technology</title>
		<imprint>
			<biblScope unit="page" from="212" to="217" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Overlapping clusters algorithm in ad hoc networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Aydin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Naït-Abdesselam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pryyma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Turgut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Global Telecommunications Conference</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Orthopairs and granular computing</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ciucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Granul. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Three-way decisions and cognitive computing</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognit. Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="543" to="554" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A novel risk decision-making based on decision-theoretic rough sets under hesitant fuzzy information</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Fuzzy Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="237" to="247" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Three-way investment decisions with decision-theoretic rough sets</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J. Comput. Inf. Sys</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="66" to="74" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Swan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">An information filtering model on the web and its application in jobagent</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="285" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Risk decision making based on decision-theoretic rough set: a three-way view decision model</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Z</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J. Comput. Inf. Sys</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Hierarchical rough decision theoretic framework for text classification</title>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Cognitive Informatics</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="484" to="489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Three-way government decision analysis with decision-theoretic rough sets</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Uncertain Fuzz</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="119" to="132" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Web-based medical decision support systems for three-way medical decision making with game-theoretic rough sets</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Azam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Fuzzy Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="3" to="15" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Three-way concept learning based on cognitive operators: An information fusion viewpoint</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Z</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Approx. Reason</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="218" to="242" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Concept lattice compression in incomplete contexts based on k-medoids clustering</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Mach. Learn. &amp; Cyber</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="539" to="552" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Three-way cognitive concept learning via multi-granularity</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Q</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">378</biblScope>
			<biblScope unit="page" from="244" to="263" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The connections between three-way and classical concept lattices</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl.-Based Syst</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="143" to="151" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Interval sets and three-way concept analysis in incomplete contexts</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Mach. Learn. &amp; Cyber</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="3" to="20" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A unified model of sequential three-way decisions and multilevel incremental processing</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fujita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl.-Based Syst</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="172" to="188" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Optimal scale selection in dynamic multi-scale decision tables based on sequential three-way decisions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C C</forename><surname>Tsang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">415</biblScope>
			<biblScope unit="page" from="213" to="232" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A three-way clustering approach for handling missing data using gtrs</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Afridi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Azam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alanazi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijar.2018.04.001</idno>
		<ptr target="https://doi.org/10.1016/j.ijar.2018.04.001" />
	</analytic>
	<monogr>
		<title level="j">Int. J. Approx. Reason</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Some methods for classification and analysis of multivariate observations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Macqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5-th Berkeley Symposium on Mathematical Statistics and Probability</title>
		<meeting>5-th Berkeley Symposium on Mathematical Statistics and Probability</meeting>
		<imprint>
			<publisher>University of California Press</publisher>
			<date type="published" when="1967">1967</date>
			<biblScope unit="page" from="281" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Lower bounds for the partitioning of graphs</title>
		<author>
			<persName><forename type="first">W</forename><surname>Donath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hoffman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM J. Res. Dev</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="420" to="425" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Algebraic connectivity of graphs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fiedler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Czech. Math. J</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="298" to="305" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Spectral partitioning works: planar graphs and finite element meshes, in: 37th Annual Symposium on Foundations of Computer Science</title>
		<author>
			<persName><forename type="first">D</forename><surname>Spielman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Teng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>IEEE Computer Socitey Press</publisher>
			<biblScope unit="page" from="96" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">An optimal graph theoretic approach to data clustering: theory and its application to image segmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Leahy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1101" to="1113" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">On spectral clustering: analysis and an algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIP&apos;02</title>
		<meeting>NIP&apos;02</meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="849" to="856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Some new indexes of cluster validity</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bezdek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern. B</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="301" to="315" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Performance evaluation of some clustering algorithms and validity indices</title>
		<author>
			<persName><forename type="first">U</forename><surname>Maulik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1650" to="1654" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Merz</surname></persName>
		</author>
		<ptr target="http://www.ics.uci.edu/mlearn/MLRepository.html" />
		<title level="m">UCI machine learning repository</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist/" />
		<title level="m">The mnist database of handwritten digits</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Autonomous knowledge-oriented clustering using decision-theoretic rough set theory</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fund. Inform</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="141" to="156" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Ecm: an evidential version of the fuzzy c-means algorithm, Pattern Recogn</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Masson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Denoeux</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1384" to="1397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Recm: relational evidential c-means algorithm</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Masson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Denoeux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn. Lett</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1015" to="1026" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">An extension to rough c -means clustering based on decision-theoretic rough sets model</title>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Approx. Reason</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="116" to="129" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
