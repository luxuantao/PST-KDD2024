<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Online Metric Learning and Fast Similarity Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Prateek</forename><surname>Jain</surname></persName>
							<email>pjain@cs.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Sciences</orgName>
								<orgName type="institution">University of Texas at Austin Austin</orgName>
								<address>
									<postCode>78712</postCode>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Brian</forename><surname>Kulis</surname></persName>
							<email>kulis@cs.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Sciences</orgName>
								<orgName type="institution">University of Texas at Austin Austin</orgName>
								<address>
									<postCode>78712</postCode>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Inderjit</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
							<email>inderjit@cs.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Sciences</orgName>
								<orgName type="institution">University of Texas at Austin Austin</orgName>
								<address>
									<postCode>78712</postCode>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kristen</forename><surname>Grauman</surname></persName>
							<email>grauman@cs.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Sciences</orgName>
								<orgName type="institution">University of Texas at Austin Austin</orgName>
								<address>
									<postCode>78712</postCode>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Online Metric Learning and Fast Similarity Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">140E8708129956D523E6F68F8A8F18F1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Metric learning algorithms can provide useful distance functions for a variety of domains, and recent work has shown good accuracy for problems where the learner can access all distance constraints at once. However, in many real applications, constraints are only available incrementally, thus necessitating methods that can perform online updates to the learned metric. Existing online algorithms offer bounds on worst-case performance, but typically do not perform well in practice as compared to their offline counterparts. We present a new online metric learning algorithm that updates a learned Mahalanobis metric based on LogDet regularization and gradient descent. We prove theoretical worst-case performance bounds, and empirically compare the proposed method against existing online metric learning algorithms. To further boost the practicality of our approach, we develop an online locality-sensitive hashing scheme which leads to efficient updates to data structures used for fast approximate similarity search. We demonstrate our algorithm on multiple datasets and show that it outperforms relevant baselines.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A number of recent techniques address the problem of metric learning, in which a distance function between data objects is learned based on given (or inferred) similarity constraints between examples <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b14">15]</ref>. Such algorithms have been applied to a variety of real-world learning tasks, ranging from object recognition and human body pose estimation <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b8">9]</ref>, to digit recognition <ref type="bibr" target="#b6">[7]</ref>, and software support <ref type="bibr" target="#b3">[4]</ref> applications. Most successful results have relied on having access to all constraints at the onset of the metric learning. However, in many real applications, the desired distance function may need to change gradually over time as additional information or constraints are received. For instance, in image search applications on the internet, online click-through data that is continually collected may impact the desired distance function. To address this need, recent work on online metric learning algorithms attempts to handle constraints that are received one at a time <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b3">4]</ref>. Unfortunately, current methods suffer from a number of drawbacks, including speed, bound quality, and empirical performance.</p><p>Further complicating this scenario is the fact that fast retrieval methods must be in place on top of the learned metrics for many applications dealing with large-scale databases. For example, in image search applications, relevant images within very large collections must be quickly returned to the user, and constraints and user queries may often be intermingled across time. Thus a good online metric learner must also be able to support fast similarity search routines. This is problematic since existing methods (e.g., locality-sensitive hashing <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b0">1]</ref> or kd-trees) assume a static distance function, and are expensive to update when the underlying distance function changes.</p><p>The goal of this work is to make metric learning practical for real-world learning tasks in which both constraints and queries must be handled efficiently in an online manner. To that end, we first develop an online metric learning algorithm that uses LogDet regularization and exact gradient descent. The new algorithm is inspired by the metric learning algorithm studied in <ref type="bibr" target="#b3">[4]</ref>; however, while the loss bounds for the latter method are dependent on the input data, our loss bounds are independent of the sequence of constraints given to the algorithm. Furthermore, unlike the Pseudo-metric Online Learning Algorithm (POLA) <ref type="bibr" target="#b12">[13]</ref>, another recent online technique, our algorithm requires no eigenvector computation, making it considerably faster in practice. We further show how our algorithm can be integrated with large-scale approximate similarity search. We devise a method to incrementally update locality-sensitive hash keys during the updates of the metric learner, making it possible to perform accurate sub-linear time nearest neighbor searches over the data in an online manner.</p><p>We compare our algorithm to related existing methods using a variety of standard data sets. We show that our method outperforms existing approaches, and even performs comparably to several offline metric learning algorithms. To evaluate our approach for indexing a large-scale database, we include experiments with a set of 300,000 image patches; our online algorithm effectively learns to compare patches, and our hashing construction allows accurate fast retrieval for online queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related Work</head><p>A number of recent techniques consider the metric learning problem <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref>. Most work deals with learning Mahalanobis distances in an offline manner, which often leads to expensive optimization algorithms. The POLA algorithm <ref type="bibr" target="#b12">[13]</ref>, on the other hand, is an approach for online learning of Mahalanobis metrics that optimizes a large-margin objective and has provable regret bounds, although eigenvector computation is required at each iteration to enforce positive definiteness, which can be slow in practice. The information-theoretic metric learning method of <ref type="bibr" target="#b3">[4]</ref> includes an online variant that avoids eigenvector decomposition. However, because of the particular form of the online update, positive-definiteness still must be carefully enforced, which impacts bound quality and empirical performance, making it undesirable for both theoretical and practical purposes. In contrast, our proposed algorithm has strong bounds, requires no extra work for enforcing positive definiteness, and can be implemented efficiently. There are a number of existing online algorithms for other machine learning problems outside of metric learning, e.g. <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b11">12]</ref>.</p><p>Fast search methods are becoming increasingly necessary for machine learning tasks that must cope with large databases. Locality-sensitive hashing <ref type="bibr" target="#b5">[6]</ref> is an effective technique that performs approximate nearest neighbor searches in time that is sub-linear in the size of the database. Most existing work has considered hash functions for L p norms <ref type="bibr" target="#b2">[3]</ref>, inner product similarity <ref type="bibr" target="#b0">[1]</ref>, and other standard distances. While recent work has shown how to generate hash functions for (offline) learned Mahalanobis metrics <ref type="bibr" target="#b8">[9]</ref>, we are not aware of any existing technique that allows incremental updates to locality-sensitive hash keys for online database maintenance, as we propose in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Online Metric Learning</head><p>In this section we introduce our model for online metric learning, develop an efficient algorithm to implement it, and prove regret bounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Formulation and Algorithm</head><p>As in several existing metric learning methods, we restrict ourselves to learning a Mahalanobis distance function over our input data, which is a distance function parameterized by a d × d positive definite matrix A. Given d-dimensional vectors u and v, the squared Mahalanobis distance between them is defined as</p><formula xml:id="formula_0">d A (u, v) = (u -v) T A(u -v).</formula><p>Positive definiteness of A assures that the distance function will return positive distances. We may equivalently view such distance functions as applying a linear transformation to the input data and computing the squared Euclidean distance in the transformed space; this may be seen by factorizing the matrix A = G T G, and distributing G into the (uv) terms.</p><p>In general, one learns a Mahalanobis distance by learning the appropriate positive definite matrix A based on constraints over the distance function. These constraints are typically distance or similarity constraints that arise from supervised information-for example, the distance between two points in the same class should be "small". In contrast to offline approaches, which assume all constraints are provided up front, online algorithms assume that constraints are received one at a time. That is, we assume that at time step t, there exists a current distance function parameterized by A t . A constraint is received, encoded by the triple (u t , v t , y t ), where y t is the target distance between u t and v t (we restrict ourselves to distance constraints, though other constraints are possible). Using A t , we first predict the distance ŷt = d At (u t , v t ) using our current distance function, and incur a loss ℓ(ŷ t , y t ). Then we update our matrix from A t to A t+1 . The goal is to minimize the sum of the losses over all time steps, i.e. L A = t ℓ(ŷ t , y t ). One common choice is the squared loss: ℓ(ŷ t , y t ) = 1 2 (ŷ t -y t ) 2 . We also consider a variant of the model where the input is a quadruple (u t , v t , y t , b t ), where b t = 1 if we require that the distance between u t and v t be less than or equal to y t , and b t = -1 if we require that the distance between u t and v t be greater than or equal to y t . In that case, the corresponding loss function is ℓ(ŷ t , y t , b t ) = max(0, 1 2 b t (ŷ t -y t )) 2 . A typical approach <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b12">13]</ref> for the above given online learning problem is to solve for A t+1 by minimizing a regularized loss at each step:</p><formula xml:id="formula_1">A t+1 = argmin A≻0 D(A, A t ) + ηℓ(d A (u t , v t ), y t ),<label>(2.1)</label></formula><p>where D(A, A t ) is a regularization function and η t &gt; 0 is the regularization parameter. As in <ref type="bibr" target="#b3">[4]</ref>, we use the LogDet divergence D ℓd (A, A t ) as the regularization function. It is defined over positive definite matrices and is given by</p><formula xml:id="formula_2">D ℓd (A, A t ) = tr(AA -1 t ) -log det(AA -1 t ) -d.</formula><p>This divergence has previously been shown to be useful in the context of metric learning <ref type="bibr" target="#b3">[4]</ref>. It has a number of desirable properties for metric learning, including scale-invariance, automatic enforcement of positive definiteness, and a maximum-likelihood interpretation.</p><p>Existing approaches solve for A t+1 by approximating the gradient of the loss function, i.e. <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b3">4]</ref>. While for some regularization functions (e.g. Frobenius divergence, von-Neumann divergence) such a scheme works out well, for LogDet regularization it can lead to non-definite matrices for which the regularization function is not even defined. This results in a scheme that has to adapt the regularization parameter in order to maintain positive definiteness <ref type="bibr" target="#b3">[4]</ref>.</p><formula xml:id="formula_3">ℓ ′ (d A (u t , v t ), y t ) is approximated by ℓ ′ (d At (u t , v t ), y t )</formula><p>In contrast, our algorithm proceeds by exactly solving for the updated parameters A t+1 that minimize (2.1). Since we use the exact gradient, our analysis will become more involved; however, the resulting algorithm will have several advantages over existing methods for online metric learning. Using straightforward algebra and the Sherman-Morrison inverse formula, we can show that the resulting solution to the minimization of (2.1) is:</p><formula xml:id="formula_4">A t+1 = A t - η(ȳ -y t )A t z t z T t A t 1 + η(ȳ -y t )z T t A t z t ,<label>(2.2)</label></formula><p>where</p><formula xml:id="formula_5">z t = u t -v t and ȳ = d At+1 (u t , v t ) = z T t A t+1 z t .</formula><p>The detailed derivation will appear in a longer version. It is not immediately clear that this update can be applied, since ȳ is a function of A t+1 . However, by multiplying the update in (2.2) on the left by z T t and on the right by z t and noting that ŷt = z T t A t z t , we obtain the following:</p><formula xml:id="formula_6">ȳ = ŷt - η(ȳ -y t )ŷ 2 t 1 + η(ȳ -y t )ŷ t</formula><p>, and so ȳ =</p><formula xml:id="formula_7">ηy t ŷt -1 + (ηy t ŷt -1) 2 + 4η ŷ2 t 2η ŷt . (2.3)</formula><p>We can solve directly for ȳ using this formula, and then plug this into the update (2.2). For the case when the input is a quadruple and the loss function is the squared hinge loss, we only perform the update (2.2) if the new constraint is violated.</p><p>It is possible to show that the resulting matrix A t+1 is positive definite; the proof appears in our longer version. The fact that this update maintains positive definiteness is a key advantage of our method over existing methods; POLA, for example, requires projection to the positive semidefinite cone via an eigendecomposition. The final loss bound in <ref type="bibr" target="#b3">[4]</ref> depends on the regularization parameter η t from each iteration and is in turn dependent on the sequence of constraints, an undesirable property for online algorithms. In contrast, by minimizing the function f t we designate above in (2.1), our algorithm's updates automatically maintain positive definiteness. This means that the regularization parameter η need not be changed according to the current constraint, and the resulting bounds (Section 2.2) and empirical performance are notably stronger.</p><p>We refer to our algorithm as LogDet Exact Gradient Online (LEGO), and use this name throughout to distinguish it from POLA <ref type="bibr" target="#b12">[13]</ref> (which uses a Frobenius regularization) and the Information Theoretic Metric Learning (ITML)-Online algorithm <ref type="bibr" target="#b3">[4]</ref> (which uses an approximation to the gradient).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Analysis</head><p>We now briefly analyze the regret bounds for our online metric learning algorithm. Due to space issues, we do not present the full proofs; please see the longer version for further details.</p><p>To evaluate the online learner's quality, we want to compare the loss of the online algorithm (which has access to one constraint at a time in sequence) to the loss of the best possible offline algorithm (which has access to all constraints at once). Let dt = d A * (u t , v t ) be the learned distance between points u t and v t with a fixed positive definite matrix A * , and let L A * = t ℓ( dt , y t ) be the loss suffered over all t time steps. Note that the loss L A * is with respect to a single matrix A * , whereas L A (Section 2.1) is with respect to a matrix that is being updated every time step. Let A * be the optimal offline solution, i.e. it minimizes total loss incurred (L A * ). The goal is to demonstrate that the loss of the online algorithm L A is competitive with the loss of any offline algorithm. To that end, we now show that</p><formula xml:id="formula_8">L A ≤ c 1 L A * + c 2 ,</formula><p>where c 1 and c 2 are constants.</p><p>In the result below, we assume that the length of the data points is bounded: u 2 2 ≤ R for all u. The following key lemma shows that we can bound the loss at each step of the algorithm:</p><formula xml:id="formula_9">Lemma 2.1. At each step t, 1 2 α t (ŷ t -y t ) 2 - 1 2 β t (d A * (u t , v t ) -y t ) 2 ≤ D ld (A * , A t ) -D ld (A * , A t+1 ), where 0 ≤ α t ≤ η 1+η R 2 + q R 2 4 + 1 η 2 , β t = η</formula><p>, and A * is the optimal offline solution.</p><p>Proof. See longer version.</p><p>Theorem 2.2.</p><formula xml:id="formula_10">L A ≤ 1 + η R 2 + R 2 4 + 1 η 2 L A * + 1 η + R 2 + R 2 4 + 1 η 2 D ld (A * , A 0 ),</formula><p>where L A = t ℓ(ŷ t , y t ) is the loss incurred by the series of matrices A t generated by Equation (2.3), A 0 ≻ 0 is the initial matrix, and A * is the optimal offline solution. Proof. The bound is obtained by summing the loss at each step using Lemma 2.1:</p><formula xml:id="formula_11">t 1 2 α t (ŷ t -y t ) 2 - 1 2 β t (d A * (u t , v t ) -y t ) 2 ≤ t D ld (A * , A t ) -D ld (A * , A t+1 ) .</formula><p>The result follows by plugging in the appropriate α t and β t , and observing that the right-hand side telescopes to</p><formula xml:id="formula_12">D ld (A * , A 0 ) -D ld (A * , A t+1 ) ≤ D ld (A * , A 0 ) since D ld (A * , A t+1 ) ≥ 0.</formula><p>For the squared hinge loss ℓ(ŷ t , y t , b t ) = max(0, b t (ŷ t -y t )) 2 , the corresponding algorithm has the same bound.</p><p>The regularization parameter affects the tradeoff between L A * and D ld (A * , A 0 ): as η gets larger, the coefficient of L A * grows while the coefficient of D ld (A * , A 0 ) shrinks. In most scenarios, R is small; for example, in the case when R = 2 and η = 1, then the bound is</p><formula xml:id="formula_13">L A ≤ (4 + √ 2)L A * + 2(4 + √ 2)D ld (A * , A 0 ).</formula><p>Furthermore, in the case when there exists an offline solution with zero error, i.e., L A * = 0, then with a sufficiently large regularization parameter, we know that L A ≤ 2R 2 D ld (A * , A 0 ). This bound is analogous to the bound proven in Theorem 1 of the POLA method <ref type="bibr" target="#b12">[13]</ref>. Note, however, that our bound is much more favorable to scaling of the optimal solution A * , since the bound of POLA has a A * 2 F term while our bound uses D ld (A * , A 0 ): if we scale the optimal solution by c, then the D ld (A * , A 0 ) term will scale by O(c), whereas A * 2 F will scale by O(c 2 ). Similarly, our bound is tighter than that provided by the ITML-Online algorithm since, in the ITML-Online algorithm, the regularization parameter η t for step t is dependent on the input data. An adversary can always provide an input (u t , v t , y t ) so that the regularization parameter has to be decreased arbitrarily; that is, the need to maintain positive defininteness for each update can prevent ITML-Online from making progress towards an optimal metric.</p><p>In summary, we have proven a regret bound for the proposed LEGO algorithm, an online metric learning algorithm based on LogDet regularization and gradient descent. Our algorithm automatically enforces positive definiteness every iteration and is simple to implement. The bound is comparable to POLA's bound but is more favorable to scaling, and is stronger than ITML-Online's bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Fast Online Similarity Searches</head><p>In many applications, metric learning is used in conjunction with nearest-neighbor searching, and data structures to facilitate such searches are essential. For online metric learning to be practical for large-scale retrieval applications, we must be able to efficiently index the data as updates to the metric are performed. This poses a problem for most fast similarity searching algorithms, since each update to the online algorithm would require a costly update to their data structures.</p><p>Our goal is to avoid expensive naive updates, where all database items are re-inserted into the search structure. We employ locality-sensitive hashing to enable fast queries; but rather than re-hash all database examples every time an online constraint alters the metric, we show how to incorporate a second level of hashing that determines which hash bits are changing during the metric learning updates. This allows us to avoid costly exhaustive updates to the hash keys, though occasional updating is required after substantial changes to the metric are accumulated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Background: Locality-Sensitive Hashing</head><p>Locality-sensitive hashing (LSH) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b0">1]</ref> produces a binary hash key</p><formula xml:id="formula_14">H(u) = [h 1 (u)h 2 (u)...h b (u)]</formula><p>for every data point. Each individual bit h i (u) is obtained by applying the locality sensitive hash function h i to input u. To allow sub-linear time approximate similarity search for a similarity function 'sim', a locality-sensitive hash function must satisfy the following property: P r[h i (u) = h i (v)] = sim(u, v), where 'sim' returns values between 0 and 1. This means that the more similar examples are, the more likely they are to collide in the hash table . 

A LSH function when 'sim' is the inner product was developed in <ref type="bibr" target="#b0">[1]</ref>, in which a hash bit is the sign of an input's inner product with a random hyperplane. For Mahalanobis distances, the similarity function of interest is sim(u, v) = u T Av. The hash function in <ref type="bibr" target="#b0">[1]</ref> was extended to accommodate a Mahalanobis similarity function in <ref type="bibr" target="#b8">[9]</ref>: A can be decomposed as G T G, and the similarity function is then equivalently ũT ṽ, where ũ = Gu and ṽ = Gv. Hence, a valid LSH function for u T Av is:</p><formula xml:id="formula_15">h r,A (u) = 1, if r T Gu ≥ 0 0, otherwise,<label>(3.1)</label></formula><p>where r is the normal to a random hyperplane. To perform sub-linear time nearest neighbor searches, a hash key is produced for all n data points in our database. Given a query, its hash key is formed and then, an appropriate data structure can be used to extract potential nearest neighbors (see <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b0">1]</ref> for details). Typically, the methods search only O(n 1/(1+ǫ) ) of the data points, where ǫ &gt; 0, to retrieve the (1 + ǫ)-nearest neighbors with high probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Online Hashing Updates</head><p>The approach described thus far is not immediately amenable to online updates. We can imagine producing a series of LSH functions h r1,A , ..., h r b ,A , and storing the corresponding hash keys for each data point in our database. However, the hash functions as given in (3.1) are dependent on the Mahalanobis distance; when we update our matrix A t to A t+1 , the corresponding hash functions, parameterized by G t , must also change. To update all hash keys in the database would require O(nd) time, which may be prohibitive. In the following we propose a more efficient approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall the update for</head><formula xml:id="formula_16">A: A t+1 = A t - η(ȳ-yt)Atztz T t At 1+η(ȳ-yt)ŷt</formula><p>, which we will write as</p><formula xml:id="formula_17">A t+1 = A t + β t A t z t z T t A t , where β t = -η(ȳ -y t )/(1 + η(ȳ -y t )ŷ t ). Let G T t G t = A t . Then A t+1 = G T t (I + β t G t z t z T t G T t )G t . The square-root of I + β t G t z t z T t G T t is I + α t G t z t z T t G T t , where α t = ( 1 + β t z T t A t z t -1)/(z T t A t z t ). As a result, G t+1 = G t +α t G t z t z T t A t .</formula><p>The corresponding update to (3.1) is to find the sign of</p><formula xml:id="formula_18">r T G t+1 x = r T G t u + α t r T G t z t z T t A t u. (3.2)</formula><p>Suppose that the hash functions have been updated in full at some time step t 1 in the past. Now at time t, we want to determine which hash bits have flipped since t 1 , or more precisely, which examples' product with some r T G t has changed from positive to negative, or vice versa. This amounts to determining all bits such that sign(r T G t1 u) = sign(r T G t u), or equivalently, (r T G t1 u)(r T G t u) ≤ 0. Expanding the update given in (3.2), we can write r T G t u as</p><formula xml:id="formula_19">r T G t1 u + t-1 ℓ=t1 α ℓ r T G ℓ z ℓ z T ℓ A ℓ u.</formula><p>Therefore, finding the bits that have changed sign is equivalent to finding all u such that (r</p><formula xml:id="formula_20">T G t1 u) 2 + (r T G t1 u) t-1 ℓ=t1 α ℓ r T G ℓ z ℓ z T ℓ A ℓ u ≤ 0.</formula><p>We can use a second level of locality-sensitive hashing to approximately find all such u. Define a vector ū = [(r T G t1 u) 2 ; (r T G t1 u)u] and a "query" q = [-1; -</p><formula xml:id="formula_21">t-1 ℓ=t1 α ℓ r T A ℓ z ℓ z T ℓ G ℓ ].</formula><p>Then the bits that have changed sign can be approximately identified by finding all examples ū such that qT ū ≥ 0. In other words, we look for all ū that have a large inner product with q, which translates the problem to a similarity search problem. This may be solved approximately using the localitysensitive hashing scheme given in <ref type="bibr" target="#b0">[1]</ref> for inner product similarity. Note that finding ū for each r can be computationally expensive, so we search ū for only a randomly selected subset of the vectors r.</p><p>In summary, when performing online metric learning updates, instead of updating all the hash keys at every step (which costs O(nd)), we delay updating the hash keys and instead determine approximately which bits have changed in the stored entries in the hash table since the last update. When we have a nearest-neighbor query, we can quickly determine which bits have changed, and then use this information to find a query's approximate nearest neighbors using the current metric. Once many of the bits have changed, we perform a full update to our hash functions.</p><p>Finally, we note that the above can be extended to the case where computations are done in kernel space. We omit details due to lack of space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>In this section we evaluate the proposed algorithm (LEGO) over a variety of data sets, and examine both its online metric learning accuracy as well as the quality of its online similarity search updates. As baselines, we consider the most relevant techniques from the literature: the online metric learners POLA <ref type="bibr" target="#b12">[13]</ref> and ITML-Online <ref type="bibr" target="#b3">[4]</ref>. We also evaluate a baseline offline metric learner associated with our method. For all metric learners, we gauge improvements relative to the original (non-learned) Euclidean distance, and our classification error is measured with the k-nearest neighbor algorithm.</p><p>First we consider the same collection of UCI data sets used in <ref type="bibr" target="#b3">[4]</ref>. For each data set, we provide the online algorithms with 10,000 randomly-selected constraints, and generate their target distances as in <ref type="bibr" target="#b3">[4]</ref>-for same-class pairs, the target distance is set to be equal to the 5th percentile of all distances in the data, while for different-class pairs, the 95th percentile is used. To tune the regularization parameter η for POLA and LEGO, we apply a pre-training phase using 1,000 constraints. (This is not required for ITML-Online, which automatically sets the regularization parameter at each iteration to guarantee positive definiteness). The final metric (A T ) obtained by each online algorithm is used for testing (T is the total number of time-steps). The left plot of Figure <ref type="figure" target="#fig_1">1</ref> shows the k-nn error rates for all five data sets. LEGO outperforms the Euclidean baseline as well as the other online learners, and even approaches the accuracy of the offline method (see <ref type="bibr" target="#b3">[4]</ref> for additional comparable offline learning results using <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b14">15]</ref>). LEGO and ITML-Online have comparable running times. However, our approach has a significant speed advantage over POLA on these data sets: on average, learning with LEGO is 16.6 times faster, most likely due to the extra projection step required by POLA.</p><p>Next we evaluate our approach on a handwritten digit classification task, reproducing the experiment used to test POLA in <ref type="bibr" target="#b12">[13]</ref>. We use the same settings given in that paper. Using the MNIST data set, we pose a binary classification problem between each pair of digits (45 problems in all). The training and test sets consist of 10,000 examples each. For each problem, 1,000 constraints are chosen and the final metric obtained is used for testing. The center plot of Figure <ref type="figure" target="#fig_1">1</ref> compares the test error between POLA and LEGO. Note that LEGO beats or matches POLA's test error in 33/45 (73.33%) of the classification problems. Based on the additional baselines provided in <ref type="bibr" target="#b12">[13]</ref>, this indicates that our approach also fares well compared to other offline metric learners on this data set.</p><p>We next consider a set of image patches from the Photo Tourism project <ref type="bibr" target="#b13">[14]</ref>, where user photos from Flickr are used to generate 3-d reconstructions of various tourist landmarks. Forming the reconstructions requires solving for the correspondence between local patches from multiple images of the same scene. We use the publicly available data set that contains about 300,000 total patches  from images of three landmarks <ref type="foot" target="#foot_0">1</ref> . Each patch has a dimensionality of 4096, so for efficiency we apply all algorithms in kernel space, and use a linear kernel. The goal is to learn a metric that measures the distance between image patches better than L 2 , so that patches of the same 3-d scene point will be matched together, and (ideally) others will not. Since the database is large, we can also use it to demonstrate our online hash table updates. Following <ref type="bibr" target="#b7">[8]</ref>, we add random jitter (scaling, rotations, shifts) to all patches, and generate 50,000 patch constraints (50% matching and 50% nonmatching patches) from a mix of the Trevi and Halfdome images. We test with 100,000 patch pairs from the Notre Dame portion of the data set, and measure accuracy with precision and recall.</p><p>The right plot of Figure <ref type="figure" target="#fig_1">1</ref> shows that LEGO and POLA are able to learn a distance function that significantly outperforms the baseline squared Euclidean distance. However, LEGO is more accurate than POLA, and again nearly matches the performance of the offline metric learning algorithm. On the other hand, the ITML-Online algorithm does not improve beyond the baseline. We attribute the poor accuracy of ITML-Online to its need to continually adjust the regularization parameter to maintain positive definiteness; in practice, this often leads to significant drops in the regularization parameter, which prevents the method from improving over the Euclidean baseline. In terms of training time, on this data LEGO is 1.42 times faster than POLA (on average over 10 runs).</p><p>Finally, we present results using our online metric learning algorithm together with our online hash table updates described in Section 3.2 for the Photo Tourism data. For our first experiment, we provide each method with 50,000 patch constraints, and then search for nearest neighbors for 10,000 test points sampled from the Notre Dame images. Figure <ref type="figure" target="#fig_2">2</ref> (left plot) shows the recall as a function of the number of patches retrieved for four variations: LEGO with a linear scan, LEGO with our LSH updates, the L 2 baseline with a linear scan, and L 2 with our LSH updates. The results show that the accuracy achieved by our LEGO+LSH algorithm is comparable to the LEGO+linear scan (and similarly, L 2 +LSH is comparable to L 2 +linear scan), thus validating the effectiveness of our online hashing scheme. Moreover, LEGO+LSH needs to search only 10% of the database, which translates to an approximate speedup factor of 4.7 over the linear scan for this data set.</p><p>Next we show that LEGO+LSH performs accurate and efficient retrievals in the case where constraints and queries are interleaved in any order. Such a scenario is useful in many applications: for example, an image retrieval system such as Flickr continually acquires new image tags from users (which could be mapped to similarity constraints), but must also continually support intermittent user queries. For the Photo Tourism setting, it would be useful in practice to allow new constraints indicating true-match patch pairs to stream in while users continually add photos that should participate in new 3-d reconstructions with the improved match distance functions. To experiment with this scenario, we randomly mix online additions of 50,000 constraints with 10,000 queries, and measure performance by the recall value for 300 retrieved nearest neighbor examples. We recompute the hash-bits for all database examples if we detect changes in more than 10% of the database examples. Figure <ref type="figure" target="#fig_2">2</ref> (right plot) compares the average recall value for various methods after each query. As expected, as more constraints are provided, the LEGO-based accuracies all improve (in contrast to the static L 2 baseline, as seen by the straight line in the plot). Our method achieves similar accuracy to both the linear scan method (LEGO Linear) as well as the naive LSH method where the hash table is fully recomputed after every constraint update (LEGO Naive LSH). The curves stack up  appropriately given the levels of approximation: LEGO Linear yields the upper bound in terms of accuracy, LEGO Naive LSH with its exhaustive updates is slightly behind that, followed by our LEGO LSH with its partial and dynamic updates. In reward for this minor accuracy loss, however, our method provides a speedup factor of 3.8 over the naive LSH update scheme. (In this case the naive LSH scheme is actually slower than a linear scan, as updating the hash tables after every update incurs a large overhead cost.) For larger data sets, we can expect even larger speed improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions:</head><p>We have developed an online metric learning algorithm together with a method to perform online updates to fast similarity search structures, and have demonstrated their applicability and advantages on a variety of data sets. We have proven regret bounds for our online learner that offer improved reliability over state-of-the-art methods in terms of regret bounds, and empirical performance. A disadvantage of our algorithm is that the LSH parameters, e.g. ǫ and the number of hash-bits, need to be selected manually, and may depend on the final application. For future work, we hope to tune the LSH parameters automatically using a deeper theoretical analysis of our hash key updates in conjunction with the relevant statistics of the online similarity search task at hand.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>PhotoTourism Dataset</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: Comparison with existing online metric learning methods. Left: On the UCI data sets, our method (LEGO) outperforms both the Euclidean distance baseline as well as existing metric learning methods, and even approaches the accuracy of the offline algorithm. Center: Comparison of errors for LEGO and POLA on 45 binary classification problems using the MNIST data; LEGO matches or outperforms POLA on 33 of the 45 total problems. Right: On the Photo Tourism data, our online algorithm significantly outperforms the L2 baseline and ITML-Online, does well relative to POLA, and nearly matches the accuracy of the offline method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Results with online hashing updates. The left plot shows the recall value for increasing numbers of nearest neighbors retrieved. 'LEGO LSH' denotes LEGO metric learning in conjunction with online searches using our LSH updates, 'LEGO Linear' denotes LEGO learning with linear scan searches. L2 denotes the baseline Euclidean distance. The right plot shows the average recall values for all methods at different time instances as more queries are made and more constraints are added. Our online similarity search updates make it possible to efficiently interleave online learning and querying. See text for details.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://phototour.cs.washington.edu/patches/default.htm</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments: This research was supported in part by NSF grant CCF-0431257, NSF-ITR award IIS-0325116, NSF grant IIS-0713142, NSF CAREER award 0747356, Microsoft Research, and the Henry Luce Foundation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Similarity Estimation Techniques from Rounding Algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Charikar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Implicit Online Learning with Kernels</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Caelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Locality-Sensitive Hashing Scheme Based on p-Stable Distributions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Immorlica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mirrokni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SOCG</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Information-Theoretic Metric Learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Dhillon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Image retrieval and classification using local distance functions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Frome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Similarity Search in High Dimensions via Hashing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gionis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Metric Learning by Collapsing Classes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Globerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roweis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Discriminant embedding for local image descriptors</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Winder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast Image Search for Learned Metrics</title>
		<author>
			<persName><forename type="first">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Exponentiated Gradient Versus Gradient Descent for Linear Predictors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kivinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Warmuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Comput</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="63" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning a Distance Metric from Relative Comparisons</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Online Learning meets Optimization in the Dual</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLT</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Online and Batch Learning of Pseudo-metrics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Photo Tourism: Exploring Photo Collections in 3D</title>
		<author>
			<persName><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH Conference Proceedings</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="835" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Distance Metric Learning for Large Margin Nearest Neighbor Classification</title>
		<author>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distance Metric Learning, with Application to Clustering with Side-Information</title>
		<author>
			<persName><forename type="first">E</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
