<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Harnessing Pairwise-Correlating Data Prefetching With Runahead Metadata</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Fatemeh</forename><surname>Golsh</surname></persName>
							<idno type="ORCID">0000-0003-4250-1623</idno>
						</author>
						<author>
							<persName><forename type="first">Mehran</forename><surname>Shakerina</surname></persName>
							<idno type="ORCID">0000-0003-3293-8274</idno>
						</author>
						<author>
							<persName><forename type="first">Ali</forename><surname>Ansari</surname></persName>
							<email>aansari@ce.sharif.edu</email>
							<idno type="ORCID">0000-0002-9798-6966</idno>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Pejman</forename><surname>Lotfi-Kamran</surname></persName>
							<idno type="ORCID">0000-0003-3293-8274</idno>
						</author>
						<author>
							<persName><forename type="first">Hamid</forename><surname>Sarbazi-Azad</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Fatemeh</forename><surname>Golshan</surname></persName>
							<email>fgolshan@ce.sharif.edu</email>
						</author>
						<author>
							<persName><forename type="first">Mehran</forename><surname>Shakerinava</surname></persName>
							<email>mshakerinava@ce.sharif.edu</email>
						</author>
						<author>
							<affiliation>
								<orgName>Department of Computer Engineering, Sharif University of Technology, </orgName>
								<address><addrLine>Tehran 11155-11365, Iran. Tehran 11155-11365, Iran Pittsburgh, PA 15213. Tehran 11155-11365, Iran. Tehran 11155-11365, Iran, Tehran 11155-11365, Iran.</addrLine></address>
							</affiliation>
						</author>
						<author>
							<affiliation>
								<orgName> Department of Computer Engineering, Sharif University of Technology, </orgName>
							</affiliation>
						</author>
						<author>
							<affiliation>
								<orgName> Carnegie Mellon University, </orgName>
							</affiliation>
						</author>
						<author>
							<affiliation>
								<orgName> School of Computer Science, Institute for Research in Fundamental Sciences (IPM), </orgName>
							</affiliation>
						</author>
						<author>
							<affiliation>
								<orgName> Department of Computer Engineering, Sharif University of Technology, </orgName>
							</affiliation>
						</author>
						<author>
							<affiliation>
								<orgName> School of Computer Science, Institute for Research in Fundamental Sciences (IPM),</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Harnessing Pairwise-Correlating Data Prefetching With Runahead Metadata</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/LCA.2020.3019343</idno>
					<note type="submission">received 7 July 2020; revised 31 July 2020; accepted 7 Aug. 2020. Date of publication 25 Aug. 2020; date of current version 15 Sept. 2020.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Cache memory</term>
					<term>performance</term>
					<term>data prefetching</term>
					<term>pairwise-correlating data prefetching</term>
					<term>overprediction</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent research revisits pairwise-correlating data prefetching due to its extremely low overhead. Pairwise-correlating data prefetching, however, cannot accurately detect where data streams end. As a result, pairwise-correlating data prefetchers either expose low accuracy or they lose timeliness when they are performing multi-degree prefetching. In this letter, we propose a novel technique to detect where data streams end and hence, control the multi-degree prefetching in the context of pairwise-correlated prefetchers. The key idea is to have a separate metadata table that operates one step ahead of the main metadata table. This way, the runahead metadata table harnesses the degree of prefetching by allowing/ disallowing the main metadata table to issue prefetch requests. We evaluate our proposal in the context of a four-core chip multiprocessor and show that it significantly reduces erroneous prefetches, providing up to 16.1 percent performance improvement on top of a state-of-the-art pairwise-correlating prefetcher.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>prefetchers has culminated in revisiting delta-based pairwise-correlating data prefetching.</p><p>In contrast to streaming prefetchers <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, that store the whole observed address streams next to each other in a FIFO buffer, or footprint-based prefetchers <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, that store bit-vectors for all observed accesses over large memory regions, pairwise-correlating prefetchers correlate every event with a single next prediction. The event can be some relevant information about the memory accesses, like the last observed address, the last observed delta, or even a combination of several pieces of information like the last three observed deltas. The next prediction, also, can be the next expected address, with address-based pairwise-correlating prefetchers <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref> or the next expected delta, with delta-based pairwise-correlating prefetchers <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>. Fig. <ref type="figure" target="#fig_1">1</ref> illustrates how prefetcher metadata is organized with different prefetching methods.</p><p>Pairwise-correlating prefetching, in fact, is not a new concept in data prefetching literature; it goes way back to the 90s when the simple, preliminary data prefetchers were initially proposed. However, the turnaround from large, high-overhead streaming and footprint-based prefetching <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref> to simple delta-based 1 pairwise-correlating prefetching <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> is a new trend motivated by the movement towards multi-and many-core systems, where architectural components from hardware optimizers like prefetchers to cores themselves need to be as simple and low-overhead as possible <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>.</p><p>Organizing metadata in a delta-based pairwise-correlated manner leads to significantly less storage requirement for the prefetcher to offer a considerable performance improvement. State-of-the-art streaming prefetchers <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b15">[16]</ref> require megabytes of metadata; state-of-the-art footprint-based prefetchers <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref> require tens of or over a hundred kilobytes of metadata; state-of-the-art delta-based pairwise-correlating prefetchers <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> require several hundreds of bytes or a few kilobytes of metadata. The main reason why deltabased pairwise-correlating prefetchers impose less storage overhead is the "desirable fusion" of metadata in these methods. I.e., an observed access pattern that would be otherwise captured in several correlation entries is captured in a single pairwise correlation entry. For example, consider the same sequence of accesses shown in Fig. <ref type="figure" target="#fig_1">1</ref>, taking that 'A' and 'B' each falls into a separate 4 KB memory page. Such an access pattern is likely to happen when the program loops over two objects of the same class, where each object is allocated in a different page <ref type="bibr" target="#b25">[26]</ref>. With a 48-bit physical address space and 64-byte cache blocks (6-bit cache block offset), for such an access pattern, a streaming prefetcher needs to store the all observed addresses, resulting in N ? 4 ? 42 ? N ? 4 ? 42 ? 336N bits storage requirement (excluding the overhead of indexing the history <ref type="bibr" target="#b13">[14]</ref>). With a footprint-based prefetcher, two large bit-vector (each 64-bits) plus the corresponding page tags (each 36-bits) are stored, resulting in 200 bits storage overhead. With a delta-based pairwise-correlating prefetcher, the prefetcher simply stores the correlation between three 16-bit delta pairs, resulting in only 48 bits of storage requirement. Thanks to this extremely-low storage overhead, delta-based pairwise-correlating prefetchers gain increasingly more attention in the literature <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>.</p><p>While fusing metadata results in less storage overhead, it causes loss of useful information on the other hand. An important item of information that gets lost with pairwise-correlating is lookahead information. Unlike streaming prefetchers <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref> that prefetch multiple data addresses that follow the correlated address in 1. All the discussions and techniques we propose in this paper are applicable to all pairwise-correlating prefetchers regardless of being address-based or deltabased. However, in this paper, in line with all recent state-of-the-art work, we narrow down our focus to delta-based pairwise-correlating prefetchers because they are extremely low-overhead and hence, more suitable for modern multiand many-core systems.</p><p>the FIFO history buffer, or footprint-based prefetchers <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref> that prefetch multiple data addresses whose corresponding bit in the bit-vector is set, pairwise-correlating prefetchers have the information of only one next expected address or delta per correlation entry. With this lookahead limitation, pairwise-correlating prefetching could face timeliness as a major problem, in that, issuing merely a single prefetch request every time may not result in prefetch requests that cover the whole latency of cache misses. Therefore, pairwise-correlating prefetchers struggle to issue multiple prefetch requests at once (i.e., multi-degree prefetching); nevertheless, the lack of sufficient lookahead information makes this task particularly challenging.</p><p>Initial work <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref> suggested storing several next predictions (e.g., three next addresses that are expected to follow the current address) in order to perform multi-degree prefetching. However, the inefficiency of these methods was shown by later research <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b28">[29]</ref>. The main reason why storing a certain number of next predictions is not efficient is that the length of different correlated address/delta streams is quite dissimilar, ranging from a couple to hundreds of thousands <ref type="bibr" target="#b28">[29]</ref>. Hence, storing a certain number of predictions, say, N, would either result in storage-inefficiency or limited miss coverage. In detail, if the length of a stream is smaller than N, say M, the N ? M entries stored in the metadata storage is useless, resulting in storage-inefficiency; otherwise, if the length of a stream is greater than N, say K, the K ? N addresses in the stream would not be captured.</p><p>What is typically employed in state-of-the-art pairwise-correlating data prefetchers as the de facto mechanism, including deltabased <ref type="bibr" target="#b8">[9]</ref> and address-based <ref type="bibr" target="#b24">[25]</ref> ones, and even similar instruction prefetchers <ref type="bibr" target="#b29">[30]</ref>, is using the prediction as input to the metadata tables to make more predictions: whenever a prediction is made, the prefetcher assumes it a correct prediction, and repeatedly indexes the metadata table with the prediction to make more predictions. While this approach has no storage overhead, it offers poor accuracy, as explicitly shown by recent work <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b29">[30]</ref>. The problem is that the prefetcher has no information about how many times it should repeat this process. In other words, the mechanism is not able to detect when a data stream ends and cease the prefetching for the stream accordingly. In fact, this emanates again from dissimilar stream lengths: if we repeat this process N times, for streams whose length is smaller than N, say M, we overprefetch N ? M addresses, resulting in inaccuracy; for streams longer than N, we may lose timeliness.</p><p>Prior approaches that perform multi-degree prefetching in such a way, typically choose the degree of prefetching empirically based on a set of studied workloads. For example, Shevgoor et al. <ref type="bibr" target="#b8">[9]</ref> set the degree to four; Bakhshalipour et al. <ref type="bibr" target="#b24">[25]</ref> set it to three. These numbers are chosen completely experimentally for a specific configuration and by examining a limited number of workloads, with which, the chosen number provides a reasonable trade-off between accuracy and timeliness. Obviously, limiting the degree to a certain predefined number neither is a solution that scales to various configurations and workloads, nor is optimal (w.r.t accuracy and timeliness) for the examined very configuration/workloads because the length of streams, not only across applications but also across different address streams of the same application, conspicuously varies <ref type="bibr" target="#b28">[29]</ref>; that is why prior work <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b29">[30]</ref> observes severe inaccuracy for these prefetching methods.</p><p>Recently, Kim et al. <ref type="bibr" target="#b7">[8]</ref> proposed a method, named SPP, to harness multi-degree prefetching in the context of delta-based pairwise-correlating prefetching. SPP predicts prefetching confidence and throttles the prefetcher if the prediction is smaller than a constant predefined threshold (chosen empirically). While such a mechanism might be useful for harnessing the prefetcher, it causes the performance of the prefetcher to become increasingly dependent on the accuracy of throttling decisions <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>. That is, when the confidence prediction is not accurate, the prefetcher either loses accuracy due to overprefetching or loses miss coverage (and timeliness) because of inopportunely stopping prefetching. Moreover, enforcing constant predefined thresholds, that are chosen empirically based on evaluating a limited set of configurations and workloads, reduces the flexibility of this at scaling beyond its evaluated scope.</p><p>In this work, we propose a novel solution to harness the multidegree prefetching in the context of pairwise-correlating prefetchers. The key idea is to have separate metadata information for predicting the next but one expected event (e.g., the delta following the next delta; two deltas away from now). This way, in fact, we employ two separate metadata tables: one predicts the next event (DISTANCE1; D1), the other predicts the next but one event (DISTANCE2; D2), which we call Runahead Metadata Table . When issuing multi-degree prefetching, the first prefetching is issued using only D1. For issuing the second prefetch, D1 is searched using its previous prediction, similar to multi-degree prefetching of previous methods; meanwhile, D2 is searched using the actual input (not prediction); the prefetch request is issued only if the prediction of both tables match; otherwise, the prefetching is finished. From the third prefetch request (if any) onward, both tables are searched using the corresponding inputs from the previous steps; if their predictions match, the prefetch request is issued and the process continues; otherwise, the prefetching is finished, concluding that the stream has come to an end.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">THE PROPOSAL</head><p>We propose Runahead MetaData (RMD), a general method for harnessing pairwise-correlating prefetching. The main component of RMD is an additional D2 The reason for adding D2 is to harness the multi-degree prefetching of D1: until when the recursive lookups should resume? As D2 operates one step ahead of D1, what D2 offers is what D1 is expected to offer in the next step. Hence, when D1's second prediction (i.e., prediction using the previous prediction as input) is not equal with D2's prediction, we intuitively conclude that the stream has been finished, and do not further issue prefetch requests for the current stream. However, as long as the predictions match, we continue prefetching to provide efficient timeliness, while preserving accuracy.  Note that this mechanism is fundamentally different from confidence-based methods like SPP <ref type="bibr" target="#b7">[8]</ref>. RMD, unlike confidence-based methods, does not assign probability numbers to correlation entries, and hence, does not admit/deny prefetching probabilistically. Instead, it relies on the effectiveness of the underlying prefetcher and ceases prefetching when it determines an end-of-stream.</p><p>Using Fig. <ref type="figure" target="#fig_0">2</ref>, we epitomize how RMD works. First off, the entries in tables are interpreted in this way: hA, Bi in D1 shows that immediately after A, we expect B to happen; hC, Ji in D2 is intended to mean that two steps away from C, we expect J to happen. Consider that A happens. We index D1 by A. The prediction of D1 is B; we issue the first prefetch request for B. Then, we index D1 by B; meanwhile, we index D2 by A. The predictions of both D1 and D2 are C; their predictions match, and we prefetch C. Then, we index D1 by C and D2 by B. The prediction of D1 is D, and the prediction of D2 is P ; their predictions do not match, and we no longer issue prefetch requests.</p><p>Note that RMD is a general technique and is not limited to any specific pairwise-correlating prefetcher. It can be used in the context of either address-based or delta-based pairwise-correlating prefetchers. Moreover, RMD makes no assumption about the underlying metadata tables of a prefetching method, e.g., what is stored in the table, how the table gets updated, the replacement policy of the table, etc. It just adds a new copy of the main metadata table of the prefetcher (D1), and trains and uses it to predict the next but one event. For example, with Variable Length Delta Prefetcher (VLDP) <ref type="bibr" target="#b8">[9]</ref>, the D1 itself is three tables each indexed by a different length of history. With RMD on top of VLDP, the D2 likewise would be three tables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EVALUATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Methodology</head><p>We use ChampSim <ref type="bibr" target="#b30">[31]</ref> to simulate a system whose configuration is shown in Table <ref type="table" target="#tab_1">1</ref>. The primary target of RMD and similar methods is multi-and many-core systems where the resources such as area and memory bandwidth are scarce and accordingly, hardware optimizers like data prefetchers should be low-overhead and bandwidth-efficient. Having said that, in this paper, we evaluate RMD in the context of a system with four computational cores and show that even in such a system, RMD is still effective and superior to competing methods. Noteworthy, we expect larger superiorness from RMD in the context of systems with more computational cores.</p><p>We use SPEC 2006 benchmark <ref type="bibr" target="#b31">[32]</ref> for our evaluations. For single-core experiments, we report the results for 15 memory-intensive programs; we create MIX workloads of these programs for our multi-core evaluations. The details of the simulated processor are shown in Table <ref type="table" target="#tab_1">1</ref>. The memory channel is modeled based on borrowed data from commercial DDR4-2133 technology specification <ref type="bibr" target="#b32">[33]</ref>, which provides peak bandwidth of around 17064 MB/s. We run the simulations for at least 100 M instructions on every core and use the first 20 M as the warm-up and the rest for actual measurements. All data prefetchers are implemented near L1 data cache.</p><p>We compare the following approaches: Best-Offset Prefetcher. BOP <ref type="bibr" target="#b6">[7]</ref> is a state-of-the-art offset prefetcher <ref type="bibr" target="#b1">[2]</ref>, that tries to find certain offsets, prefetching with which would result in better timeliness. The storage overhead of this method is 1.85 KB.</p><p>Variable Length Delta Prefetcher. VLDP <ref type="bibr" target="#b8">[9]</ref> is a state-of-the-art delta-based pairwise-correlating prefetcher. VLDP operates on multiple lengths of history to efficiently learn and prefetch irregular delta patterns. The storage overhead of this method is 998 bytes.</p><p>Signature Path Prefetcher. SPP <ref type="bibr" target="#b7">[8]</ref> is a state-of-the-art method that targets the same goal our proposal does; nonetheless, in a different manner. SPP monitors the accuracy of pairwise-correlating prefetcher and adjusts the prefetching degree, considering both accuracy and timeliness of prefetch requests. The storage overhead of this method is 5.37 KB. We use T P ? 0:5 and T F ? 0:8 as the throttling parameters since this setting provides higher performance improvements as compared to the parameters chosen in the original paper.</p><p>Runahead MetaData. RMD is our proposal for harnessing the multi-degree prefetching in the context of pairwise-correlating prefetchers. While there are many prefetching methods that can potentially benefit from RMD, in this paper, we evaluate our proposal on top of VLDP (named VLDP+RMD) and SPP (named SPP+RMD). For VLDP+RMD, we make a copy of Delta Prediction Table and train/use it as the runahead metadata. The overall storage overhead is 1.6 KB. For SPP+RMD, we remove the baseline throttling mechanism (set the thresholds to zero), then make a copy of Pattern Table as the runahead metadata. The overall storage overhead is 8.38 KB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>Fig. <ref type="figure" target="#fig_3">3</ref> shows miss coverage and overpredictions (i.e., inaccurate prefetches normalized to baseline cache misses <ref type="bibr" target="#b1">[2]</ref>) of competing methods. Moreover, numbers on the bars indicate the performance of methods, normalized to a baseline system with no prefetcher.   As Fig. <ref type="figure" target="#fig_3">3</ref> shows, RMD significantly reduces the overpredictions of both VLDP and SPP. The reduction for VLDP is 1.4x on average and up to 3.6x; and for SPP, it is 77.5 percent on average and up to 1.9x. These large reductions in overpredictions result in substantially less memory bandwidth consumption and cache pollution, which are crucially important for performance and energy-efficiency especially in multi-and many-core substrates. While offering large reductions in mispredictions, RMD reduces the miss coverage negligibly; with RMD, VLDP and SPP offer only 1.9 and 0.3 percent lower miss coverage as compared to without RMD. The performance of methods with RMD is on par with that of without it. Note that, single-core substrates typically are not bandwidth-limited <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>, and that is why the reduction in the overprediction does not translate into performance enhancement.</p><p>Fig. <ref type="figure">4</ref> shows the performance of all methods normalized to a baseline with no data prefetcher. The evaluated workloads in this figure are four-core MIX workloads, where MIX i is created by picking programs ?i; i ? 1; i ? 2; i ? 3?%15 (modulo 15) from Fig. <ref type="figure" target="#fig_3">3</ref>. As the results show, augmenting VLDP and SPP by RMD results in significant performance improvements. The performance improvement of RMD on top of VLDP/SPP is 5.8/9.6 percent on average and up to 15/16.1 percent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>Pairwise-correlating prefetching, thanks to its extremely small storage requirements, has been recently gaining ever-increasing attention. One major problem of pairwise-correlating prefetching is the lack of sufficient lookahead information, which makes end-of-thestream detection task particularly challenging, resulting in poor accuracy with prior multi-degree prefetching mechanisms. In this paper, we addressed this issue and proposed a novel technique to harness the prefetching degree in the context of pairwise-correlating prefetching. We evaluated our proposal on top of state-of-the-art methods in the literature and showed that it could largely reduce the overpredictions, resulting in significant performance improvements.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>2</head><label>2</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Comparison of streaming, footprint-based, and pairwise-correlating prefetchers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. An illustration of how the proposed method works.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. The results of single-core experiments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>table, namely Runahead Metadata Table, which runs a step (e.g., one delta) ahead of the conventional D1 table.</figDesc><table><row><cell>More specifically, D2 predicts what address/delta will happen next</cell></row><row><cell>but one (two steps away from now); in contrast, D1 (the conventional</cell></row><row><cell>metadata table of pairwise-correlating prefetching) predicts what</cell></row><row><cell>address/delta will happen next (one step away from now).</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 1</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell>Evaluation Parameters</cell></row><row><cell>Parameter</cell><cell>Value</cell></row><row><cell>Processor</cell><cell>4 cores, 8-wide OoO</cell></row><row><cell>L1-I/D</cell><cell>32 KB, 8-way set-associative, 1-cycle load-to-use, 64 B lines</cell></row><row><cell>L2 Cache</cell><cell>1 MB per core, 16-way set-associative, unified, 11-cycle access latency</cell></row><row><cell></cell><cell>DDR4-2133 MHz, 2 ranks/channel,</cell></row><row><cell>Memory</cell><cell>8 banks/rank, 2 KB row buffer/bank,</cell></row><row><cell></cell><cell>tCL-tRCD-tRP-tRAS = 15-15-15-39</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>1556-6056 ? 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.See ht_ tps://www.ieee.org/publications/rights/index.html for more information.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Note that this may result in livelock for some particular access patterns. To prevent livelock, we limit the number of outstanding prefetches to a predefined large number (in this paper, 8).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>Authorized licensed use limited to: Tsinghua University. Downloaded on January 01,2024 at 08:05:28 UTC from IEEE Xplore. Restrictions apply.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>IEEE COMPUTER ARCHITECTURE LETTERS, VOL. 19, NO. 2, JULY-DECEMBER 2020 Authorized licensed use limited to: Tsinghua University. Downloaded on January 01,2024 at 08:05:28 UTC from IEEE Xplore. Restrictions apply.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>" For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/csdl.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A primer on hardware prefetching</title>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synth. Lect. Comput. Archit</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Evaluation of hardware data prefetchers on server processors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bakhshalipour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page">52</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">DSM: A case for hardware-assisted merging of DRAM rows with same content</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Vakil Ghahani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Meas. Anal. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">33</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scale-out processors</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 39th Annu. Int. Symp. Comput. Archit</title>
		<meeting>39th Annu. Int. Symp. Comput. Archit</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="500" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Scale-out processors &amp; energy efficiency</title>
		<author>
			<persName><forename type="first">P</forename><surname>Esmaili-Dokht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Khodabandeloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.04864</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sandbox prefetching: Safe run-time evaluation of aggressive prefetchers</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Pugsley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 20th Int. Symp. High Perform</title>
		<meeting>IEEE 20th Int. Symp. High Perform</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="626" to="637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Best-offset hardware prefetching</title>
		<author>
			<persName><forename type="first">P</forename><surname>Michaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. High Perform</title>
		<meeting>IEEE Int. Symp. High Perform</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="469" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Path confidence based lookahead prefetching</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Pugsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V</forename><surname>Gratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Narasimha Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chishti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 49th Annu</title>
		<meeting>49th Annu</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficiently prefetching complex address patterns</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shevgoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Koladiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balasubramonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Pugsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chishti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 48th Annu</title>
		<meeting>48th Annu</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="141" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-lookahead offset prefetching</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shakerinava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Third Data Prefetching Championship</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">B-Fetch: Branch prediction directed prefetching for in-order processors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V</forename><surname>Gratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim Enez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Archit. Lett</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="41" to="44" />
			<date type="published" when="2012-12">Jul.-Dec. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Divide and conquer frontend bottleneck</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM/IEEE 47th Annu. Int. Symp. Comput. Archit</title>
		<meeting>ACM/IEEE 47th Annu. Int. Symp. Comput. Archit</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="65" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">MANA: Microarchitecting an instruction prefetcher</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Golshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Temporal streaming of shared memory</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hardavellas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 32nd Int. Symp. Comput. Archit</title>
		<meeting>32nd Int. Symp. Comput. Archit</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="222" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Practical off-chip meta-data for temporal memory streaming</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 15th Int. Symp. High Perform</title>
		<meeting>IEEE 15th Int. Symp. High Perform</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="79" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Domino temporal data prefetcher</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. High Perform</title>
		<meeting>IEEE Int. Symp. High Perform</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="131" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Exploiting spatial locality in data caches using spatial footprints</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th Annu. Int. Symp. Comput. Archit</title>
		<meeting>25th Annu. Int. Symp. Comput. Archit</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="357" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Spatial memory streaming</title>
		<author>
			<persName><forename type="first">S</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 33rd Int. Symp. Comput. Archit</title>
		<meeting>33rd Int. Symp. Comput. Archit</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="252" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bingo spatial data prefetcher</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shakerinava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. High Perform</title>
		<meeting>IEEE Int. Symp. High Perform</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="399" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Accurately and maximally prefetching spatial data access patterns with bingo</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shakerinava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Third Data Prefetching Championship</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Prefetching using Markov predictors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grunwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th Annu</title>
		<meeting>24th Annu</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="252" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Timekeeping in the memory system: Predicting and optimizing memory behavior</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaxiras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 29th Annu. Int. Symp. Comput. Archit</title>
		<meeting>29th Annu. Int. Symp. Comput. Archit</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="209" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">TCP: Tag correlating prefetchers</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaxiras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th Int. Symp. High Perform</title>
		<meeting>9th Int. Symp. High Perform</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="317" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dead-block prediction &amp; dead-block correlating prefetchers</title>
		<author>
			<persName><forename type="first">A.-C</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 28th Annu</title>
		<meeting>28th Annu</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="144" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An efficient temporal data prefetcher for L1 caches</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Archit. Lett</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="102" />
			<date type="published" when="2017-12">Jul.-Dec. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fast data delivery for many-core processors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bakhshalipour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1416" to="1429" />
			<date type="published" when="2018-10">Oct. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Low-cost epoch-based correlation prefetching for commercial applications</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 40th Annu</title>
		<meeting>40th Annu</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="301" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Using a user-level memory thread for correlation prefetching</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Solihin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Torrellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 29th Annu. Int. Symp. Comput. Archit</title>
		<meeting>29th Annu. Int. Symp. Comput. Archit</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="171" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Temporal streams in commercial server applications</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Workload Characterization</title>
		<meeting>IEEE Int. Symp. Workload Characterization</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="99" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Effective instruction prefetching in chip multiprocessors for modern commercial applications</title>
		<author>
			<persName><forename type="first">L</forename><surname>Spracklen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Abraham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th Int. Symp. High Perform</title>
		<meeting>11th Int. Symp. High Perform</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="225" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName><surname>Champsim</surname></persName>
		</author>
		<ptr target="https://github.com/ChampSim/" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">SPEC CPU2006 benchmark descriptions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Henning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">SIGARCH Comput. Archit. News</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName><surname>Jedec-Ddr</surname></persName>
		</author>
		<ptr target="https://www.jedec.org/sites/default/files/docs/JESD79-4.pdf" />
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Reducing writebacks through in-cache displacement</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bakhshalipour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Des. Autom. Electron. Syst</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">16</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Scaling the bandwidth wall: Challenges in and avenues for CMP scaling</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Rogers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp. Comput. Archit</title>
		<meeting>Int. Symp. Comput. Archit</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="371" to="382" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
