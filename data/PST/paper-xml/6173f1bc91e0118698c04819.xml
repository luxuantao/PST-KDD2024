<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Morrigan: A Composite Instruction TLB Prefetcher</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Georgios</forename><surname>Vavouliotis</surname></persName>
							<email>georgios.vavouliotis@bsc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Barcelona Supercomputing Center Universitat Politècnica de Catalunya</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lluc</forename><surname>Alvarez</surname></persName>
							<email>lluc.alvarez@bsc.es</email>
							<affiliation key="aff1">
								<orgName type="department">Barcelona Supercomputing Center Universitat Politècnica de Catalunya</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Boris</forename><surname>Grot</surname></persName>
							<email>boris.grot@ed.ac.uk</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Edinburgh</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Jiménez</surname></persName>
							<email>djimenez@acm.org</email>
							<affiliation key="aff3">
								<orgName type="institution">Texas A&amp;M University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marc</forename><surname>Casas</surname></persName>
							<email>marc.casas@bsc.es</email>
							<affiliation key="aff4">
								<orgName type="department">Barcelona Supercomputing Center Universitat Politècnica de Catalunya</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Morrigan: A Composite Instruction TLB Prefetcher</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3466752.3480049</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>virtual memory</term>
					<term>address translation</term>
					<term>translation lookaside buffer</term>
					<term>TLB prefetching</term>
					<term>TLB management</term>
					<term>markov prefetching</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The effort to reduce address translation overheads has typically targeted data accesses since they constitute the overwhelming portion of the second-level TLB (STLB) misses in desktop and HPC applications. The address translation cost of instruction accesses has been relatively neglected due to historically small instruction footprints. However, state-of-the-art datacenter and server applications feature massive instruction footprints owing to deep software stacks, resulting in high STLB miss rates for instruction accesses.</p><p>This paper demonstrates that instruction address translation is a performance bottleneck in server workloads. In response, we propose Morrigan, a microarchitectural instruction STLB prefetcher whose design is based on new insights regarding instruction STLB misses. At the core of Morrigan there is an ensemble of table-based Markov prefetchers that build and store variable length Markov chains out of the instruction STLB miss stream. Morrigan further employs a sequential prefetcher and a scheme that exploits page table locality to maximize miss coverage. An important contribution of the work is showing that access frequency is more important than access recency when choosing replacement candidates. Based on this insight, Morrigan introduces a new replacement policy that identifies victims in the Markov prefetchers using a frequency stack while adapting to phase-change behavior. On a set of 45 industrial server workloads, Morrigan eliminates 69% of the memory references in demand page walks triggered by instruction STLB misses and improves geometric mean performance by 7.6%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>• Software and its engineering → Virtual memory; • Applied computing → Data centers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Paging-based virtual memory is a fundamental feature of today's computers. To mitigate the high latency cost of page walks, Translation Lookaside Buffers (TLBs) cache the most recently used virtualto-physical translations. Despite the use of multi-level TLB hierarchies and other hardware and software schemes for accelerating address translation, frequent data TLB misses still cause significant performance degradation due to long miss penalties <ref type="bibr" target="#b24">[30,</ref><ref type="bibr" target="#b26">32,</ref><ref type="bibr" target="#b34">40,</ref><ref type="bibr" target="#b41">47,</ref><ref type="bibr" target="#b48">54,</ref><ref type="bibr" target="#b52">58,</ref><ref type="bibr" target="#b57">63]</ref>. In response, the research community has proposed many techniques for reducing the overhead of address translation associated with data accesses <ref type="bibr" target="#b30">[36,</ref><ref type="bibr" target="#b32">38,</ref><ref type="bibr" target="#b47">53,</ref><ref type="bibr" target="#b50">56,</ref><ref type="bibr" target="#b54">60,</ref><ref type="bibr" target="#b60">66,</ref><ref type="bibr" target="#b62">68,</ref><ref type="bibr" target="#b63">69,</ref><ref type="bibr" target="#b67">73,</ref><ref type="bibr" target="#b68">74,</ref><ref type="bibr" target="#b73">79,</ref><ref type="bibr" target="#b76">82]</ref>.</p><p>Recent work <ref type="bibr" target="#b48">[54,</ref><ref type="bibr" target="#b56">62,</ref><ref type="bibr" target="#b59">65,</ref><ref type="bibr" target="#b77">83]</ref> has shown that modern server and datacenter applications not only have big datasets, but also large code footprints. Huge binaries and deep software stacks cause frequent instruction cache and instruction TLB misses, compromising performance due to unavoidable pipeline stalls. The instruction footprint of these applications increases at around 20-30% per year <ref type="bibr" target="#b48">[54]</ref>, indicating that the front-end bottleneck is likely to get worse.</p><p>When it comes to instruction address translation, TLB pressure caused by massive code working set sizes is amplified by contention in the second-level TLB (STLB), which is shared between instruction and data translations. Instruction references evict useful data translations and vice versa, imposing additional performance penalties. However, instruction STLB (iSTLB) misses are more critical than data STLB (dSTLB) 1 misses since instruction references are on the critical path of pipeline execution, while data misses can overlap independent instructions thanks to out-of-order execution, partially hiding their latency costs. Indeed, a recent work <ref type="bibr" target="#b59">[65]</ref> shows that iSTLB misses are a critical bottleneck in Facebook workloads. Therefore, iSTLB misses are a growing problem in servers.</p><p>The impact of instruction address translation in terms of performance and page walk memory references has received minimal attention over the years. Existing software approaches comprise either compile-time techniques for code layout optimization <ref type="bibr" target="#b58">[64]</ref> or operating system schemes leveraging large pages <ref type="bibr" target="#b37">[43,</ref><ref type="bibr" target="#b53">59,</ref><ref type="bibr" target="#b77">83]</ref>. On the hardware side, there are incremental and disruptive schemes 1 iSTLB and dSTLB refer to instruction and data references to the STLB, respectively.</p><p>for reducing TLB misses. While developed for data TLB misses, these approaches could also be effective for instruction TLB misses. Incremental approaches try to increase TLB reach <ref type="bibr" target="#b35">[41,</ref><ref type="bibr" target="#b62">68,</ref><ref type="bibr" target="#b63">69]</ref>, but they are limited by coalescing opportunities exposed by the application and the OS. Disruptive approaches call for an overhaul of the virtual memory subsystem <ref type="bibr" target="#b22">[28,</ref><ref type="bibr" target="#b49">55]</ref>, which hinders their adoption and may introduce new security vulnerabilities.</p><p>This paper highlights that iSTLB misses are a bottleneck in server workloads because their large code footprints pressure the STLB, resulting in long-latency page walks for fetching the corresponding address translations. Specifically, on a suite of contemporary industrial server workloads, we find that over 40% of all STLB misses are caused by instruction references. Our findings corroborate the conclusions of previous industry works showing iSTLB pressure to be a performance bottleneck in their workloads <ref type="bibr" target="#b48">[54,</ref><ref type="bibr" target="#b56">62,</ref><ref type="bibr" target="#b59">65]</ref>.</p><p>Furthermore, we show that prior dSTLB prefetchers <ref type="bibr" target="#b47">[53]</ref> are ineffective at capturing the iSTLB misses because (i) they correlate patterns with features that are unable to provide accurate iSTLB prefetches, and (ii) they use access recency for choosing prefetch candidates which does not correlate well with iSTLB misses. When applied to iSTLB prefetching, existing dSTLB prefetchers improve the performance on industrial server workloads by up to 1.6%, whereas the opportunity from perfect iSTLB prefetching is 11.1%.</p><p>We also examine the state-of-the-art instruction cache prefetchers <ref type="bibr" target="#b16">[22]</ref> and conclude that they, too, are ineffective at prefetching for the iSTLB miss stream. Instruction prefetchers target the L1 I-cache and typically find the needed cache blocks in the L2 or the LLC <ref type="bibr" target="#b41">[47,</ref><ref type="bibr" target="#b66">72]</ref>, which means that they are tuned for relatively short prefetch distances. Meanwhile, iSTLB misses result in page walks that cause serialized accesses to the memory hierarchy. Depending on the memory hierarchy level where these accesses are served, the page walk can take from tens to hundreds of cycles, which cannot be always covered by instruction cache prefetchers.</p><p>Based on these observations, this paper introduces Morrigan, a microarchitectural iSTLB prefetcher. To the best of our knowledge, this is the first work to characterize iSTLB misses and the first iSTLB prefetcher. Morrigan is composed of two complimentary prefetching modules. The first module is the Irregular Instruction TLB Prefetcher (IRIP), an ensemble of four prediction tables that efficiently build and store variable length Markov chains from the iSTLB miss stream. IRIP is enhanced with a new replacement policy, named Random-Least-Frequently-Used (RLFU), that drives replacements based on a frequency stack of iSTLB misses. RLFU uses randomness to avoid evicting recently installed but not yet frequently accessed entries, thus efficiently accommodating changes in the instruction access patterns, e.g., due to phase-based behavior. The second module of Morrigan is the Small Delta Prefetcher (SDP), a sequential prefetcher activated when the IRIP module is unable to produce new prefetches. Finally, both IRIP and SDP exploit page table locality <ref type="bibr" target="#b63">[69,</ref><ref type="bibr" target="#b73">79]</ref> to perform cost-effective spatial prefetching.</p><p>In summary, this paper makes the following contributions:</p><p>• We provide a first study on iSTLB prefetching using a set of 45 industrial server workloads <ref type="bibr" target="#b11">[14,</ref><ref type="bibr" target="#b16">22]</ref>. Key conclusions of the study are that (i) state-of-the-art designs of dSTLB prefetchers are unable to cover iSTLB misses, and (ii) instruction cache prefetchers are ineffective at eliminating iSTLB misses.</p><p>• We demonstrate that iSTLB misses (i) follow a skewed distribution, with a modest number of instruction pages responsible for the majority of the iSTLB misses, and (ii) have spatial locality limited to a small region around the triggering miss.</p><p>• We propose Morrigan, a novel iSTLB prefetcher composed of two specialized prefetch engines: a novel Markov-based prefetching module that uses a new frequency-based replacement policy to manage its internal state, and an enhanced small delta prefetcher.</p><p>• Across a set of 45 industrial server workloads <ref type="bibr" target="#b11">[14,</ref><ref type="bibr" target="#b16">22]</ref>, Morrigan provides a geometric mean speedup of 7.6% and reduces the references to the memory hierarchy due to demand page walks for instructions by 69% over a baseline without iSTLB prefetching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">VIRTUAL MEMORY SUBSYSTEM</head><p>Each memory access on a paging-based virtual memory system requires a virtual-to-physical address translation. To accelerate address translation and improve virtual memory management, modern systems use a combination of software and hardware support.</p><p>On the software side, the page table is an OS-managed and architecturally-visible structure that contains the virtual-to-physical translations for all pages loaded to memory. In x86-64 architectures, the page table is implemented as a multi-level radix tree.</p><p>On the hardware side, the Translation Lookaside Buffer (TLB) and the MMU-Caches are hardware structures dedicated to alleviate the address translation overheads. TLBs cache the most recently used virtual-to-physical translations. Modern architectures implement multi-level TLB hierarchies, with small instruction and data firstlevel TLBs (I-TLB and D-TLB) and a large second-level TLB (STLB).</p><p>On each memory access (either instruction or data), the corresponding first-level TLB is accessed and, in case of a miss, the STLB is looked up. On STLB misses, the page table walker is invoked, traversing the page table to find the requested translation. Frequent page walks have a pernicious performance impact since they require multiple accesses to the memory hierarchy. To reduce page walk latency, MMU caches (called Page Structure Caches (PSCs) on x86 <ref type="bibr" target="#b61">[67]</ref>) cache partial translations, hence reducing the number of page walk accesses to the memory hierarchy. Finally, page table entries (PTEs) from both intermediate and leaf nodes of the page table are also cached in the existing cache hierarchy. <ref type="table">Locality</ref>. In x86-64 architectures, the cache line size is 64 bytes and each PTE occupies precisely 8 bytes. As a result, a single 64-byte cache line can accommodate up to 8 contiguouslystored PTEs <ref type="bibr" target="#b31">[37,</ref><ref type="bibr" target="#b63">69,</ref><ref type="bibr" target="#b70">76,</ref><ref type="bibr" target="#b73">79]</ref>. When a requested PTE is read from memory, it is grouped with 7 neighboring PTEs and they are stored into a 64-byte cache line. Therefore, a single cache line stores the requested PTE plus 7 more PTEs that do not require additional accesses to the memory hierarchy to be prefetched.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Page Table</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Translation Prefetching</head><p>STLB misses (either instruction or data) trigger long-latency page walks. Accurately prefetching PTEs ahead of demand STLB accesses can improve performance by reducing STLB misses.</p><p>Figure <ref type="figure">1</ref> depicts the operation of a system with STLB prefetching, considering the most common scenario whereby a Prefetch Buffer (PB) is used to store the prefetched PTEs and the prefetch logic is engaged on STLB misses <ref type="bibr" target="#b20">[26,</ref><ref type="bibr" target="#b47">53,</ref><ref type="bibr" target="#b73">79]</ref>. When an instruction or data memory access occurs, the corresponding first-level TLB is looked up and, on a miss, the STLB is probed. In case the STLB misses, the requested PTE is searched for in the PB. If the translation is present in the PB, it is moved to the STLB, the page walk is avoided, and the processor replays the request. On a PB miss, a demand page walk is initiated to fetch the corresponding translation. In case of either PB hit or miss, the STLB prefetcher is activated and produces new prefetches. Each prefetch requires a prefetch page walk to fetch the corresponding translation into the PB. Note that (i) the prefetch page walks are triggered in the background, (ii) prefetches are speculative events, thus only non-faulting prefetches are permitted, and (iii) before issuing new prefetches, the prefetch logic checks if the translation already resides in the PB, but not in the STLB, since searching the STLB for duplicates would contend with demand STLB accesses, potentially delaying the latter.</p><p>To the best of our knowledge, there is no previously proposed instruction STLB (iSTLB) prefetcher. However, state-the-art data STLB (dSTLB) prefetchers, discussed next, can also be used to attempt to capture the iSTLB miss stream.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sequential Prefetcher (SP)</head><p>. SP <ref type="bibr" target="#b47">[53,</ref><ref type="bibr" target="#b72">78]</ref> prefetches the PTE of the page located next to the one triggered the STLB miss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Arbitrary Stride Prefetcher (ASP)</head><p>. ASP <ref type="bibr" target="#b25">[31,</ref><ref type="bibr" target="#b47">53]</ref> targets varying stride patterns. To do so, it uses a prediction table indexed by the PC of the instruction that triggered the STLB miss.</p><p>Distance Prefetcher (DP). DP <ref type="bibr" target="#b47">[53]</ref> correlates patterns with the distance between pages. To do so, DP uses a prediction table indexed by the distance between the current and the previous missing pages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Markov Prefetcher (MP)</head><p>. MP <ref type="bibr" target="#b47">[53]</ref> targets irregular STLB patterns by building Markov chains out of the STLB miss stream. MP employs a prediction table with three fields per entry; the virtual page for indexing, and two prediction slots that store the pages of the PTEs to be prefetched when a new STLB miss occurs on that page.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MOTIVATION</head><p>This section elaborates on the front-end bottleneck of servers and motivates the need for new approaches that alleviate the instruction address translation overheads, highlighting the potential performance gains of applying instruction STLB (iSTLB) prefetching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Front-end Bottleneck</head><p>Modern server workloads have massive instruction working sets that span many levels of the software stack, making the front-end of the processor a major performance pain point <ref type="bibr" target="#b41">[47]</ref>. Indeed, recent work from Google <ref type="bibr" target="#b48">[54,</ref><ref type="bibr" target="#b56">62]</ref> demonstrates that their server workloads face severe problems due to pressure on front-end structures.</p><p>ca ss an dr a to m ca t av ro ra tra de so ap xa lan ht tp ch irp er 0.0 0.5 1.0 1.5 2.0 2.5 iSTLB MPKI Figure <ref type="figure">2</ref>: iSTLB MPKI of Java server workloads from the Java DaCapo <ref type="bibr" target="#b33">[39]</ref> and Java Renaissance <ref type="bibr" target="#b65">[71]</ref> benchmark suites.</p><p>Moreover, they highlight that the front-end bottleneck is increasing, since most of these server applications exhibit high instruction growth rates (∼20-30% per year), outpacing the growth in instruction cache and TLB sizes. Specifically, Kanev et al. <ref type="bibr" target="#b48">[54]</ref> reveal that the front-end stalls of the Google server workloads account for 15-30% of pipeline slots, with many workloads being starved for instructions for 5-10% of cycles. Similarly, another recent work <ref type="bibr" target="#b59">[65]</ref> reveals that Facebook workloads experience serious bottlenecks due to front-end stalls mostly caused by iSTLB misses.</p><p>To justify that instruction address translation is a significant bottleneck in server applications, we analyze the iSTLB behavior of server applications from (i) the Java DaCapo suite <ref type="bibr" target="#b33">[39]</ref> (cassandra, tomcat, avrora, tradesoap, xalan), and (ii) the Java Renaissance suite <ref type="bibr" target="#b65">[71]</ref> (http, chirper). We run these server applications on an Intel Skylake CPU with a 1536-entry STLB, and gathered performance counters associated with the iSTLB accesses using perf <ref type="bibr" target="#b12">[17]</ref>.</p><p>Figure <ref type="figure">2</ref> presents the iSTLB MPKI rates of these workloads. For this experiment, we enable the Transparent Huge Page support to use 2MB pages for data accesses while mapping the code pages into 2MB pages using libhugetlbfs since there is no transparent way to map code pages into huge pages today (Section 5 elaborates on the implications of using huge pages for code). We observe that, even with huge pages, these applications experience high iSTLB MPKI rates that range between 0.6 and 2.1, which results in over 5% of their execution cycles spent in iSTLB miss handling.</p><p>Intuitively, the increasing instruction footprint of server applications affects the performance of the I-TLB as well as the STLB, since more instruction page table entries (PTEs) must be allocated to map the instruction working set of the applications. Hence, the I-TLB experiences high MPKI rates and, as a result, more requests for instruction address translations are sent to the STLB. Since the STLB contains both data and instruction PTEs, there is increasing contention between them. Higher contention leads to more frequent STLB misses that must be resolved through a long-latency page walk. However, iSTLB misses are more critical than data STLB (dSTLB) misses because instruction references are on the critical path of execution, while data misses can overlap the execution of independent instructions in out-of-order processors. This is the reason why processor vendors (i) employ larger I-TLBs than D-TLBs (e.g., Intel's Skylake 2018 chips have an 128-entry (8-way) I-TLB and an 64-entry (4-way) D-TLB <ref type="bibr" target="#b21">[27]</ref>), and (ii) keep increasing the STLB size -from a 512-entry STLB for Sandy Bridge <ref type="bibr" target="#b4">[5]</ref> to a 1024-entry STLB for Haswell [6], and a 1536-entry STLB for Coffe Lake [9].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Analyzing Industrial Server Workloads</head><p>To validate the observations of Section 3.1, we analyze the instruction cache (I-cache) and TLB behavior of 45 industrial server workloads provided by Qualcomm (QMM) for CVP-1 <ref type="bibr" target="#b11">[14]</ref> and IPC-1 <ref type="bibr" target="#b16">[22]</ref>.   The QMM workloads were also used in recent works on TLB management <ref type="bibr" target="#b55">[61,</ref><ref type="bibr" target="#b73">79]</ref>. We further study the SPEC CPU 2006 <ref type="bibr" target="#b1">[2]</ref> and SPEC CPU 2017 <ref type="bibr" target="#b7">[10]</ref> benchmark suites. This analysis is conducted using ChampSim [15] enhanced with a realistic x86 page table walker. Section 5 explains in detail our experimental setup. Figure <ref type="figure">3</ref> presents the average MPKI rates of the L1 I-cache, the I-TLB, and the STLB (considering only the instruction misses) for the SPEC and the QMM workloads. We observe that (i) the QMM workloads experience an order of magnitude more instruction misses in the three hardware structures compared to the SPEC workloads, corroborating the conclusions of prior industrial works from Google <ref type="bibr" target="#b48">[54,</ref><ref type="bibr" target="#b56">62]</ref>, presented in Section 3.1, and (ii) the iSTLB MPKI rates of the QMM workloads are similar to the ones of the Java DaCapo and Java Renaissance workloads (Section 3.1).</p><p>Focusing on the QMM workloads, we measured the fraction of the STLB misses that are caused by instruction and data references. We found that the iSTLB misses constitute 41.6%, on average, of the total STLB misses (the rest 58.4% are dSTLB misses). We further measured that the average page walk latency of iSTLB and dSTLB misses is 69 cycles and 112 cycles, respectively. Higher page walk latency is observed for the dSTLB misses because the data footprint is larger than the instruction footprint, thus, data PTEs experience worse cache locality than the instruction PTEs, resulting in higher page walk latencies. However, unlike dSTLB misses -whose latency can be partially hidden by exploiting ILP and MLP in out-of-order cores -iSTLB misses cause unavoidable pipeline stalls. Hence, iSTLB misses constitute an important performance bottleneck in server workloads.</p><p>Intel's VTune profiler <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b5">7,</ref><ref type="bibr" target="#b36">42]</ref> considers instruction address translation as a bottleneck when the stall cycles due to iSTLB accesses represent more than 5% of the total execution cycles. Figure <ref type="figure">4</ref> shows the cycles spent serving iSTLB accesses as a percentage of the total execution cycles for the QMM workloads. We observe that the QMM workloads spend 6.6%-11.7% of their execution cycles serving iSTLB requests, exceeding the 5% threshold. Therefore, instruction address translation is a bottleneck for the QMM workloads. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Understanding the iSTLB Misses</head><p>To understand the behavior of iSTLB misses, Figure <ref type="figure" target="#fig_2">5</ref> depicts the accumulative distribution of deltas (absolute values) between pages that produce consecutive iSTLB misses for the QMM workloads in order of increasing deltas. While we observe a wide distribution of deltas, we note that small deltas occur frequently (e.g., deltas from 1 to 10 account for 19% of the total deltas).</p><p>Finding 1. iSTLB misses have only limited spatial locality mostly restricted to a small region around the triggering miss.</p><p>Next, we analyze the distribution of iSTLB misses. Figure <ref type="figure">6</ref> plots the accumulative distribution of iSTLB misses per page in order of decreasing page occurrence frequency, considering a set of representative QMM workloads. The rest of the QMM workloads follow a distribution that is either close or in between the ones presented in Figure <ref type="figure">6</ref>. We observe that a small number of pages is responsible for a significant fraction of all iSTLB misses. Specifically, 400-800 pages cause 90% of the iSTLB misses across all QMM workloads. Finding 2. Most iSTLB misses can be attributed to a modest number of instruction pages.</p><p>We define successor page as a page immediately following a given page in the iSTLB miss stream. <ref type="foot" target="#foot_0">2</ref> Figure <ref type="figure">7</ref> shows a breakdown of the average number of successors per each instruction page that missed in the STLB, across all QMM workloads. It can be observed that (i) a significant fraction of instruction pages has only 1 or 2 successor pages, (ii) the percentage of instruction pages that have up to 4 and up to 8 successor pages is also large, and (iii) only a small number of instruction pages have more than 8 successor pages.</p><p>Figure <ref type="figure">7</ref> reveals that a significant fraction of the instruction pages has more than 2 and up to 8 successors. However, to alleviate the instruction address translation bottleneck, it is natural to mainly focus on the instruction pages that miss the most in the STLB. Figure <ref type="figure" target="#fig_4">8</ref> shows the probability of accessing a specific successor for the top 50 instruction pages that miss the most in the STLB, across all QMM workloads. On average, 51% of the time the most-frequent successor is accessed after an iSTLB miss, while 21% and 11% of the time the same second and third most-frequent successors are accessed after a miss, respectively. The remaining 17% of the times, the access after a miss is to a less-frequent successor page.</p><p>Finding 3. Instruction pages that miss frequently in the STLB have only a few likely successor pages whose reference probability is high.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Can Existing dSTLB Prefetchers Help?</head><p>Followingly, we measure the effectiveness of the prior dSTLB prefetchers (SP, ASP, DP, MP), presented in Section 2.1, on the iSTLB miss stream. We set the configuration parameters of each dSTLB prefetcher as proposed in the original papers, the prefetched PTEs are placed into a 64-entry Prefetch Buffer (PB), and new prefetch requests are issued on iSTLB misses (Section 2.1). Figure <ref type="figure">9</ref> illustrates the performance of the existing dSTLB prefetchers when prefetching for the iSTLB miss stream, including the performance of an idealized scenario; a Perfect STLB for instruction accesses where all iSTLB lookups are hits (Perfect iSTLB). This ideal scenario quantifies the upper bound for the performance improvement by optimizing STLB operation for instruction references.</p><p>The ideal scenario (Perfect iSTLB) delivers a geometric speedup of 11.1%. Meanwhile, dSTLB prefetchers provide negligible speedups because they are mainly unable to capture the iSTLB miss patterns. SP improves performance by 1.6% because some of the instruction accesses are sequential but it fails at capturing the complex delta patterns (Figure <ref type="figure" target="#fig_2">5</ref>). ASP and DP provide almost no speedup because they use features (PC and distances, respectively) that do not correlate well with the iSTLB misses, thus, their prediction tables experience massive conflicting accesses (96.3% and 93.7%, respectively). Intuitively, we were expecting MP to improve performance since Figure <ref type="figure">7</ref> shows that the instruction pages that miss in the STLB have a small number of successors pages. Yet we observe that MP performs poorly, improving performance by a mere 0.2%.</p><p>To explain the poor performance of MP and examine its potential for iSTLB prefetching, we evaluate two idealized versions of MP; both versions have an unbounded prediction table that accommodates all instruction pages that miss in the STLB. The two only differ in the number of successor pages they can store per prediction table entry; one version maintains up to two successors, and the other can store any number of successor pages per entry. The unbounded MP with two and infinite successor pages per prediction table entry deliver 7.9% and 10.3% geomean performance, respectively.</p><p>There are two important conclusions from this study. First, increasing the number of entries in the prediction table significantly improves MP's performance (from 0.2% speedup with the baseline having a 128-entry prediction table to 7.9% speedup with infinite number of prediction table entries). Our analysis indicates that the replacement policy of MP is one of the reasons why MP does not improve performance with practical prediction table sizes. Since MP uses the LRU policy we conclude that recency is not a useful feature for replacement decisions. Secondly, accommodating multiple successors per page, beyond just two, further increases the speedup from 7.9% to 10.3%, which approaches the ideal of 11.1%.</p><p>Finding 4. A Markov prefetcher has potential for iSTLB prefetching but it requires dynamically building variable length Markov chains out of the iSTLB miss stream in a storage-efficient manner and an effective replacement policy for its prediction table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Instruction Cache Prefetching</head><p>Modern I-cache prefetchers may trigger instruction prefetches across page boundaries <ref type="bibr" target="#b16">[22]</ref>. When that happens, if the corresponding translation is absent in the TLB, a page walk is triggered. Hence, I-cache prefetchers implicitly work as instruction TLB prefetchers; however, their effectiveness in this role has not been analyzed.</p><p>To quantify how effective state-of-the-art I-cache prefetchers are at prefetching for the iSTLB miss stream, we consider the three top performers of the IPC-1 contest: EPI, FNL+MMA, and D-Jolt. IPC-1 infrastructure does not model instruction address translation, i.e., all I-cache prefetches that cross page boundaries are translated without cost. We extend the IPC-1 infrastructure to consider address translation costs (Section 5) and configure the IPC-1 prefetchers to store in the STLB PB the PTEs of the beyond-page-boundaries prefetches, thus providing iSTLB prefetches.</p><p>Our analysis indicates that FNL+MMA outperforms the other IPC-1 prefetchers when address translation is taken into account, thus we focus on this I-cache prefetcher. Figure <ref type="figure">10</ref> shows the performance of FNL+MMA. Line FNL+MMA+TLB (FNL+MMA) shows the measured performance of the prefetcher when instruction address translation is (is not) considered. When address translation is taken into account (FNL+MMA+TLB), we observe significantly lower speedups than the ones reported in IPC-1. This degradation comes from the instruction prefetches that cross page boundaries and fail to find the corresponding translation in the TLB hierarchy, thus requiring long-latency page walks to fetch it. Such prefetches hurt the timeliness of the FNL+MMA and delay demand STLB accesses by occupying the page table walker ports, resulting in poor performance. Moreover, we observe only a small reduction (29.6% on average) in demand iSTLB misses because FNL+MMA is unable to cover iSTLB misses due to their poor timeliness in the face of long-latency page walks that require serialized memory accesses. Therefore, state-of-the-art I-cache prefetchers require a smart iSTLB prefetcher to effectively cross page boundaries.</p><p>Finding 5. I-cache prefetchers are mainly ineffective at reducing iSTLB misses due to poor timeliness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MORRIGAN</head><p>To alleviate the instruction address translation performance bottleneck, this paper proposes Morrigan (Irish goddess of destiny), a composite iSTLB prefetcher. Morrigan is fully legacy-preserving and does not disrupt the existing virtual memory subsystem. Morrigan is also synergistic with I-cache prefetchers as it improves their timeliness when they cross page boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Design</head><p>Morrigan is inspired by our analysis findings regarding the iSTLB miss behavior (Section 3) and consists of two complementary modules: the Irregular Instruction TLB Prefetcher (IRIP) which builds and stores Markov chains out of the iSTLB miss stream, and the Small Delta Prefetcher (SDP), an enhanced sequential prefetcher. Sections 4.1.1 and 4.1.2 present the IRIP and SDP modules while Section 4.2 explains the operation of Morrigan.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Irregular Instruction TLB Prefetcher (IRIP).</head><p>The IRIP module is designed as a Markov prefetcher since our analysis indicates that a Markov prefetcher has potential for iSTLB prefetching (Finding 4, Section 3.4). Specifically, IRIP is an ensemble of four table-based Markov prefetchers that efficiently build and store variable length Markov chains from the iSTLB miss stream. IRIP also takes into account the variable number of successor pages (Figure <ref type="figure">7</ref>) of the instruction pages that miss in the STLB. Designing IRIP as a Markov prefetcher with a single prediction table and a fixed number of successors per entry-as the state-of-the-art MP does (Section 2.1)results in suboptimal performance gains (Section 6.3).</p><p>IRIP employs four prediction tables (PRT-S1, PRT-S2, PRT-S4, PRT-S8) that dynamically build a store variable length Markov chains from the iSTLB miss stream. Each prediction table entry stores up to a pre-defined number of successors; PRT-S1, PRT-S2, PRT-S4, and PRT-S8 accommodate instruction pages that have one, two, up to four, and up to eight successor pages, respectively. Each prediction table is realized as a set-associative buffer and stores the virtual page of the missed instruction for indexing, s prediction slots, and s confidence counters, one per prediction slot. For example, each PRT-S2 entry has s=2 prediction slots, and s=2 confidence counters. The only difference in the design of the prediction tables is the number of prediction slots and confidence counters. For simplicity, we illustrate in Figure <ref type="figure" target="#fig_6">11</ref> the design and the operation of PRT-S2.</p><p>A naive IRIP design would store the full virtual page number (VPN) in each prediction slot (as the state-of-the-art MP <ref type="bibr" target="#b47">[53]</ref>  . . However, such a design choice is expensive, storage-wise, since each VPN requires 36 bits of state. To lower this storage cost, IRIP stores the distances between the current and the previous virtual pages that produced an iSTLB miss. This approach lowers the amount of storage for the prediction tables without any performance loss.</p><p>The confidence counters associated with the prediction slots are exploited in a two-fold manner: (i) to drive the replacement policy of the prediction slots, i.e., when all the prediction slots are occupied and a new distance has to be placed in one of these slots, the distance with the lowest confidence is replaced, and (ii) the distance with the highest confidence is selected to apply spatial prefetching, leveraging page table locality (Section 2). Specifically, on PRT-S2 hits, IRIP issues one prefetch request per predicted distance of the hit entry. Each prefetch requires a page walk to fetch the corresponding translation (Section 2.1). At the end of a prefetch page walk, page table locality can be exploited to prefetch for free the PTEs that share the cache line with the target PTE. However, prefetching all the free PTEs in all prefetch page walks might harm performance by fetching a lot of inaccurate prefetches. To mitigate this problem, IRIP prefetches cache-line adjacent PTEs only for the distance with the highest confidence.</p><p>Figure <ref type="figure" target="#fig_6">11</ref> shows an operational example of PRT-S2, starting with an iSTLB miss for virtual page 0xA1. Initially, a PRT-S2 lookup takes place to determine if there is an entry corresponding to virtual page 0xA1 1 . In the example, the PRT-S2 lookup experiences a hit. Hence, the predicted distances 17 and 2 of the hit entry are separately summed with the currently missed page (0xA1) to generate new prefetch requests for pages 0xB2 and 0xA3, respectively 2 . In parallel, IRIP finds the predicted distance with the highest confidence counter 3 . Since distance 2 has the highest confidence value, IRIP applies spatial prefetching for the prefetch 0xA3 4 . Specifically, at the end of the prefetch page walk for 0xA3, IRIP leverages page table locality to also prefetch the PTEs adjacent to the PTE of 0xA3 5 . To update PRT-S2, IRIP calculates the distance between the currently missed (0xA1) and previously missed (0xB5) virtual pages and stores the outcome into a register 6 . Meanwhile, IRIP finds which of the predicted distances for the previously missed virtual page has the lowest confidence counter 7 . Since distance 666 has the lowest confidence, IRIP replaces it with the current distance for future reuse, while resetting the corresponding confidence counter 8 . Finally, IRIP stores the currently missed virtual Updating the confidence counters. When a prefetch is proved to be accurate, i.e., it produces a hit that eliminates a demand page walk, the confidence counter of the corresponding prediction slot is incremented by 1.</p><p>Replacement policy. A critical aspect of the IRIP design is the replacement policy of the prediction tables. While previous tablebased dSTLB prefetchers, like MP <ref type="bibr" target="#b47">[53]</ref>, use the LRU policy, we find that LRU does not keep the most useful entries in the prediction tables because it is prone to lose track of important entries (Section 3.4). Our analysis findings indicate that the miss frequency of virtual pages is a good feature to correlate the iSTLB miss stream. Therefore, we employ a frequency-based replacement policy for all the prediction tables of IRIP which (i) maintains a frequency stack of the iSTLB misses to drive the replacement of entries on prediction table conflicts, similar to Least-Frequently-Used (LFU) policy, and (ii) uses a random component that gives recently installed entries, which have not yet accumulated a large number of hits, a chance to persist when a replacement candidate is selected. This policy gives IRIP the ability to adjust to phase-based behavior in workloads. We refer to this policy as Random-Least-Frequently-Used (RLFU). Finally, the complexity of RLFU is similar to LRU.</p><p>A problem with a frequency-based replacement policy is that it may be slow to adapt to phase changes in application behavior (e.g., when a page causes frequent iSTLB misses in one phase but not in another). To avoid the associated performance pathologies, Morrigan periodically resets the frequency stack to better identify instruction pages causing the most iSTLB misses in a given interval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Small Delta Prefetcher (SDP)</head><p>. SDP prefetches the PTE of the virtual page adjacent to the missed virtual page, similar to SP <ref type="bibr" target="#b47">[53]</ref>. SDP further exploits page table locality to prefetch all the adjacent PTEs within the target cache line. In this way, SDP captures the majority of the small-strided iSTLB misses (Finding 1, Section 3.3).</p><p>For instance, assume an iSTLB miss for page 0xA7. First, SDP issues a prefetch request for page 0xA8 (0xA7+1). After the completion of the prefetch page walk for page 0xA8, SDP prefetches all the PTEs that share the cache line with the PTE of page 0xA8. Note that in this example, fetching the PTEs of pages 0xA7 and 0xA8 requires two separate page walks since the PTE of 0xA7 resides in the last position of a cache line (0xA7 &amp; 0x07) while the PTE of 0xA8 is stored in the first position within another cache line.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Operation of Morrigan</head><p>This section explains the operation of Morrigan, considering the most common case where the iSTLB prefetcher is invoked on iSTLB misses, and the prefetched PTEs are stored into a Prefetch Buffer (PB), as explained in Section 2.1.</p><p>Figure <ref type="figure">12</ref> illustrates the operation of Morrigan. When an iSTLB miss occurs 1 , the requested translation is looked up in the PB 2 . On PB misses, a demand page walk is initiated 3 to fetch the corresponding translation into the TLB 4 . On PB hits, the demand page walk is avoided and the corresponding translation is transferred from the PB to the TLB 5 , and in the background we increment the confidence counter of the prediction table entry that produced the PB hit, if the prefetch was produced by the IRIP module 6 .</p><p>Morrigan is engaged in case of either PB hit or miss 7 . First, Morrigan looks up in parallel all prediction tables (PRT-S1, PRT-S2, PRT-S4, PRT-S8) of IRIP 8 (step 1 in Figure <ref type="figure" target="#fig_6">11</ref>). When there is a hit in one prediction table (there is no duplication of entries in the prediction tables, thus only one hit might occur), Morrigan generates one prefetch per valid prediction slot of the hit entry 9 (step 2 in Figure <ref type="figure" target="#fig_6">11</ref>) of the corresponding prediction table. Before issuing the prefetch requests, Morrigan checks whether the translations already reside in the PB 10 . For the prefetches that are already stored in the PB the corresponding requests are discarded 11 . For the rest, separate prefetch page walks are initiated to fetch the translations 12 . At the end of the prefetch page walks the corresponding PTEs are stored into the PB 13 . Then, Morrigan leverages page table locality to apply lookahead prefetching by fetching in the PB the adjacent PTEs that are transferred together with the prefetched PTE solely for the prefetch with the highest confidence 14 (steps 3 -5 in Figure <ref type="figure" target="#fig_6">11</ref>). When all the prediction tables of IRIP experience a miss, Morrigan has to store the currently missed virtual page in one of the prediction tables. Since this page does not have any valid prediction, it is always placed in the PRT-S1 15 but it might be moved into another prediction table if future STLB misses reveal that it has multiple successor pages. If PRT-S1 is full, Morrigan uses the RLFU policy to find a victim entry. Therefore, on prediction table misses Morrigan is unable to produce prefetch requests based on the IRIP module. At this point, SDP is activated and issues prefetches 16 by exploiting page table locality, which are eventually stored into the PB 17 . SDP is enabled only on IRIP misses, thus Morrigan does not loose any potential for performance improvement since it produces new prefetches on every iSTLB miss.</p><p>In case of either hit or miss in the prediction tables of IRIP, Morrigan inserts the new predicted distance in one of the prediction slots of the prediction table entry that accommodates the previously missed virtual page 18 . If the previously missed page resides in one of PRT-S1, PRT-S2, and PRT-S4 19 and the prediction slots are fully occupied 20 , then instead of victimizing one of the prediction slots we simply transfer this entry into the next prediction table that has more prediction slots 21 ; if it is full, Morrigan uses the RLFU replacement policy to open up space for the transferred entry 22 . Next, this entry is removed from the previous prediction table <ref type="table">23</ref> . If the previously missed page resides in the PRT-S8 and the prediction slots are fully occupied 24 , the new distance is placed into the prediction slot that has the lowest confidence counter 25 . Note that in step 19 we do not search all prediction tables to find the previously missed page, but we use a register to store the identifier of the table that stores the previously missed page.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Additional Aspects</head><p>Operation on SMT Cores. Morrigan can operate under SMT colocation by sharing the IRIP module among the threads. To do so, it only requires a different register per thread holding the virtual page that produced the previous iSTLB miss (step 9 , Figure <ref type="figure" target="#fig_6">11</ref>) to ensure that each thread builds its own Markov chains without intermixing.</p><p>Context Switches. The prediction tables of the IRIP module must be flushed on a context switch. Their small sizes ensures that, following a context switch, they are quickly refilled. SDP is stateless; as such, it requires no action on a context switch.</p><p>Multiple Page Sizes. Sections 4.1 and 4.2 focus on a single page size to describe the design and operation of Morrigan. This is not a limitation of the design as multiple page sizes are supported without any modification. The page size is known only after address translation, thus, Morrigan can issue two prefetches per request to target 4KB and 2MB pages. Once the page size is known, Morrigan discards the outcome of the prefetch page walk for the mismatched page size. This approach does not add complexity in the design since modern architectures support speculative page walks <ref type="bibr" target="#b61">[67]</ref>.</p><p>Page Replacement Policy and TLB Shootdowns. Morrigan sets the access bit of all prefetched pages since the x86 memory consistency model dictates that all TLB prefetches are obliged to do so <ref type="bibr" target="#b21">[27]</ref>. Therefore, Morrigan does not complicate TLB shootdowns because the information about the prefetched instruction PTEs is conveyed to the OS as usual. Regarding the impact on the page replacement policy, a prefetch is harmful for the page replacement policy if it is evicted from the STLB PB without providing any hit and does not belong to the active footprint of the application. Morrigan issues prefetches based on the control-flow behavior and does not permit faulting prefetches, thus the probability of negatively affecting the page replacement policy is negligible. To annihilate this probability, Morrigan could issue a correcting page walk to reset the access bit of the PTEs that are evicted from the PB without providing any hit. These correcting page walks could be issued when the TLB MSHR is not full to avoid delaying any other page walk.</p><p>Synergy with I-Cache Prefetching. Morrigan is complementary to I-cache prefetchers because it prefetches instruction PTEs, thus improving the timeliness of I-cache prefetches that go beyond page boundaries by avoiding long-latency page walks (Section 3.5). Section 6.5 quantifies the performance gains of using Morrigan to improve the timeliness of a state-of-the-art I-cache prefetcher.</p><p>Different Architectures. We focus on x86 architectures; however, architectural support for virtual memory used in x86 architectures <ref type="bibr" target="#b17">[23,</ref><ref type="bibr" target="#b19">25]</ref> is similar to other architectures (e.g., ARM <ref type="bibr" target="#b6">[8]</ref> and RISC-V <ref type="bibr" target="#b8">[11]</ref>). Thus, Morrigan would be applicable to these architectures.</p><p>Page Tables. Morrigan is compatible with a 5-level radix tree page table <ref type="bibr" target="#b9">[12]</ref>, and may deliver higher performance gains because the extra page table level might increase the page walk latency. If a hashed page table <ref type="bibr" target="#b71">[77,</ref><ref type="bibr" target="#b76">82]</ref> is used, Morrigan would operate the same since hashed page tables preserve page table locality. TLB Prefetching Strategy. TLB prefetching schemes are typically engaged on STLB misses and store the prefetched PTEs into a PB (Section 2.1). Our analysis indicates that these two strategies have a positive effect on performance. Nonetheless, Morrigan could be also activated on STLB hits and prefetch directly into the STLB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">METHODOLOGY</head><p>Simulation Infrastructure. To evaluate Morrigan, we use the latest version of ChampSim [15], a detailed simulator that models a 4-wide out-of-order processor. We extend ChampSim to simulate a realistic x86 page table walker, modeling the variable latency cost of page walks and also the variable number of memory references require to complete. Specifically, added a 4-level page table, page table and 3-level PSC. The table walker up to 4 TLB similar to <ref type="bibr" target="#b21">[27]</ref>, one page walk can be initiated per our baseline uses next-line I-cache but we also consider I-cache prefetchers from IPC1 in Sections 3.5 and 6.5. Table summarizes our setup.</p><p>We also extended ChampSim to a dual-threaded SMT core to evaluate our proposal under workload colocation. Every cycle, a different thread fetches one basic block of instructions. Our SMT model fully accounts for the contention due to colocation in all shared microarchitectural structures (TLBs, PSCs, cache hierarchy).</p><p>Our work focuses on 4KB pages, similar to prior work using the QMM workloads <ref type="bibr" target="#b55">[61]</ref>. So why not use huge pages to mitigate the address translation overhead? Although profitable when the application exhibits high locality and the system is not fragmented, huge pages are not a stop-gap solution to the address translation bottleneck for both data and code accesses. In practise, using huge pages for data and code potentially hurts performance in datacenters and exposes security vulnerabilities, as we explain below. Furthermore, the performance of legacy systems and cloud applications that continue to use 4KB pages still matters for their users.</p><p>Huge pages have been shown to introduce performance pathologies <ref type="bibr" target="#b23">[29,</ref><ref type="bibr" target="#b53">59,</ref><ref type="bibr" target="#b77">83]</ref>, particularly for servers. Another problem is the lack of flexibility in memory management with huge pages compared to standard 4KB pages <ref type="bibr" target="#b18">[24,</ref><ref type="bibr" target="#b44">50,</ref><ref type="bibr" target="#b64">70]</ref>. Specifically, huge pages require memory contiguity and defragmentation that is not guaranteed in datacenters due to high uptimes and the fact that datacenters handle thousands of diverse applications <ref type="bibr" target="#b18">[24,</ref><ref type="bibr" target="#b48">54,</ref><ref type="bibr" target="#b75">81]</ref>. Indeed, <ref type="bibr" target="#b53">[59]</ref> demonstrates that memory defragmentation can result in tail latency spikes and performance variability, both of which might negatively impact the performance of datacenter applications. Moreover, a recent work <ref type="bibr" target="#b18">[24]</ref> shows that transparent 2MB support for data pages is not adequate anymore and there is need for creating transparent support for 1GB pages. Finally, <ref type="bibr" target="#b42">[48]</ref> reveals that huge pages can harm the performance of NUMA machines; this problem might be amplified with the advent of heterogeneous memories where the OSes have to migrate data between fast and slow tiers of memory.</p><p>In addition to the above, concurrently supporting multiple page sizes is a complex problem; this is the reason why Linux has support for transparent 2MB pages only for data, which, in fact, took a long time to be properly implemented <ref type="bibr" target="#b21">[27]</ref>. Today, Linux does not have support for 2MB transparent huge pages for code blocks. The only way to map executable files onto huge pages in Linux is to use libhugetlbfs <ref type="bibr" target="#b3">[4]</ref>. However, libhugetlbfs does not provide automatic and transparent support for huge page code mappings since it requires shaping the text layout in the application's address space <ref type="bibr" target="#b38">[44]</ref>. Indeed, a recent work <ref type="bibr" target="#b58">[64]</ref> reveals that (i) mapping the .text section of server applications onto huge pages provides performance degradation since it puts pressure on the limited number of L1 I-TLB entries that can accommodate huge pages, and (ii) mapping too many huge pages using libhugetlbfs in production machines makes the Linux kernel misbehave as it becomes overwhelmed by the need to relocate physical pages to satisfy requests for huge pages.</p><p>Another concern with mapping code in huge pages is that doing so represents a security risk. Modern systems use Address Space Layout Randomization (ASLR) to obstruct certain security attacks by making it difficult for an adversary to predict target addresses.</p><p>Prior work has shown that using huge pages for code significantly diminishes the effectiveness of ASLR <ref type="bibr" target="#b28">[34,</ref><ref type="bibr" target="#b29">35,</ref><ref type="bibr" target="#b40">46,</ref><ref type="bibr" target="#b69">75]</ref>. Another security risk is the iTLB multihit [16] vulnerability that arises when huge pages are used for code. Specifically, when an instruction fetch hits multiple entries in the I-TLB it may incur a machine check error.</p><p>To mitigate this issue, cloud providers such as Microsoft Azure and Amazon force all executable instruction pages to be mapped into 4KB pages <ref type="bibr" target="#b10">[13,</ref><ref type="bibr">[18]</ref><ref type="bibr" target="#b13">[19]</ref><ref type="bibr" target="#b14">[20]</ref><ref type="bibr" target="#b15">[21]</ref>, removing the possibility of multiple hits.</p><p>For these reasons, we focus our evaluation on 4KB pages but Morrigan is entirely compatible with larger page sizes (Section 4.2).</p><p>Workloads. We use a set of server workloads provided by Qualcomm (QMM) for the CVP-1 <ref type="bibr" target="#b11">[14]</ref> and IPC-1 <ref type="bibr" target="#b16">[22]</ref> contests that were previously used in other TLB-related research works <ref type="bibr" target="#b55">[61,</ref><ref type="bibr" target="#b73">79]</ref>. Workloads with an iSTLB MPKI of at least 0.5 are considered instruction TLB intensive, thus our evaluation considers 45 instruction TLB intensive QMM server workloads. Our simulations use 50 million warmup instructions, then 100 million instructions are executed to measure the experimental results, similar to prior work <ref type="bibr" target="#b55">[61]</ref>.</p><p>We also analyze the SPEC CPU 2006 <ref type="bibr" target="#b1">[2]</ref> and SPEC CPU 2017 <ref type="bibr" target="#b7">[10]</ref> benchmark suites, but we find that these workloads have an iSTLB MPKI of 0.5 or less, so they are not considered in our evaluation. However, we use the SPEC CPU workloads in Section 3 to show that we are consistent with the conclusions of previous works <ref type="bibr" target="#b48">[54,</ref><ref type="bibr" target="#b56">62]</ref>.</p><p>Finally, datacenters colocate applications on SMT cores for better CPU and memory utilization <ref type="bibr" target="#b48">[54,</ref><ref type="bibr" target="#b74">80]</ref>. To consider colocation, we simulate a dual-threaded SMT core executing two different QMM workloads. Our evaluation (Section 6.6) considers 50 randomly chosen pairs of QMM workloads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EVALUATION 6.1 IRIP Module</head><p>The IRIP module of Morrigan is an ensemble of table-based hardware Markov prefetchers. Therefore, the effectiveness of Morrigan directly depends on the number entries in the prediction tables (PRT-S1, PRT-S2, PRT-S4, PRT-S8) of the IRIP module. Each prediction table entry requires 16 bits for storing a partial tag of the virtual page for indexing, 15 bits per predicted distance of the prediction slots, and a 2-bit saturating counter per predicted distance (Section 4). Note that Sections 6.1.1 and 6.1.2 consider fully associative prediction tables and a 64-entry Prefetch Buffer (PB); Section 6.1.3 examines different prediction table associativities and PB sizes.</p><p>6.1.1 Miss Coverage. Figure <ref type="figure" target="#fig_7">13</ref> presents the miss coverage of Morrigan across all QMM workloads as a function of different storage budgets. Starting with small storage budgets, we observe a large increase in the miss coverage of Morrigan as the storage budget et al.  increases. However, after 5KBs, the miss coverage begins to plateau. Going beyond 7.5KB of storage budget provides negligible benefits.</p><p>6.1.2 Replacement Policy. The prediction tables of the IRIP module use the RLFU policy (Section 4). To highlight the benefits of RLFU we compare against the following alternatives: (i) LRU policy, (ii) Random policy, and (iii) LFU policy that replaces the least frequently accessed entry. Figure <ref type="figure" target="#fig_9">14</ref> shows the miss coverage of Morrigan when the IRIP module leverages the above explained replacement policies as a function of different budgets, similar to Section 6.1.1.</p><p>Looking at Figure <ref type="figure" target="#fig_9">14</ref>, we observe that the RLFU replacement policy provides significantly higher miss coverage than the other replacement policies when the prediction tables of the IRIP module accommodate a small number of entries. As the size of the prediction tables increases, the miss coverage gap between RLFU and the other policies shrinks because the prediction tables can store the majority of the virtual pages that produce iSTLB misses (Sections 3.3 and 3.4), thus making the replacement policy irrelevant.</p><p>Considering Morrigan with 3.76KB of storage budget, Figure <ref type="figure" target="#fig_9">14</ref> reveals that the LRU and Random replacement policies provide the lowest miss coverage since the former evicts useful entries based on their recency position and the latter randomly selects victims without any insight. The LFU replacement policy provides higher coverage than LRU and Random replacement policies, highlighting that the iSTLB miss stream correlates well with the miss frequency of the virtual pages. Finally, the RLFU policy improves miss coverage over the LFU policy by 4.9%. This happens because RLFU randomly replaces one of the least recently used entries, acting like a second-chance policy for not yet frequently accessed entries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3">Configuring IRIP.</head><p>Taking into account the results of Sections 6.1.1 and 6.1.2, we conclude that there is a cost-performance tradeoff in the design space of Morrigan. For the rest of the paper, we focus on the configuration of Morrigan with 3.76KB of storage budget, which achieves 81% miss coverage (Figure <ref type="figure" target="#fig_7">13</ref>). We select this configuration because it represents an attractive point in terms of miss coverage and required storage budget.</p><p>Using the above selected version of Morrigan, we evaluated different capacities and associativities for the prediction tables of IRIP. Empirically, we found the following preferred configuration: 128-entry (32 ways) PRT-S1, 128-entry (32 ways) PRT-S2, 128-entry (32 ways) PRT-S4, and a 64-entry (16 ways) PRT-S8. Among the prediction tables, PRT-S8 is the smallest one because the number of instruction pages that have more than 4 and up to 8 successors is lower than the number of instruction pages that have 1, 2, and up to 4 successor pages (Section 3.3) and the probability of accessing a non frequent successor page is relatively low (Figure <ref type="figure" target="#fig_4">8</ref>). Finally, the empirically selected configuration provides a miss coverage of 76% (5% lower than the version with fully associative prediction tables).</p><p>Regarding the PB size, we consider a 64-entry PB because a PB with 16 or 32 entries provides rather poor miss coverage compared to the 64-entry PB (4%-12% reduction), whereas a 128-entry PB increases coverage by 2% compared to the 64-entry PB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">ISO-Comparison with dSTLB Prefetchers</head><p>This section compares Morrigan with the state-of-the-art dSTLB prefetchers (Section 2.1) that are configured to prefetch for the iSTLB miss stream, similar to Section 3.4. To make a fair comparison, we set the configuration parameters of these prefetchers in such a way that they match the storage budget of Morrigan (3.76KB).</p><p>Performance Comparison. Figure <ref type="figure" target="#fig_10">15</ref> shows the performance comparison between Morrigan and the dSTLB prefetchers. The baseline considers the system without STLB prefetching. SP, DP, ASP, MP, and Morrigan provide a geometric speedup of 1.6%, 0.1%, 0.4%, 0.7%, and 7.6%, respectively. Morrigan significantly outperforms all previously proposed dSTLB prefetchers because the QMM workloads exhibit highly complex patterns that the dSTLB prefetchers are unable to capture. Specifically, SP captures only the sequential patterns, DP and ASP experience massive conflicts in their prediction tables, and MP uses the LRU policy that fails at keeping in the prediction table the most useful instruction pages (Section 3.4).</p><p>In terms of PB hits provided by the two modules of Morrigan (IRIP and SDP), we measured that 93% of the prefetches that hit in the PB were triggered by the IRIP, while the remaining 7% by SDP.</p><p>Cost of Prefetching &amp; Analysis. Figure <ref type="figure" target="#fig_11">16</ref> presents the distribution of the normalized number of memory references triggered by demand and prefetch page walks for Morrigan and the prior dSTLB prefetchers. For the purposes of this study, the term memory reference refers to a page walk reference that is served by the memory hierarchy (L1, L2, LLC, DRAM). Note that (i) we take into account cache locality in page walks (Section 5), and (ii) a page walk memory reference is triggered only for references that miss in the PSC, which we also model. The normalization factor, 100% in Figure <ref type="figure" target="#fig_11">16</ref>, is the number of memory references due to demand page walks without STLB prefetching. SP, ASP, DP, MP, and Morrigan reduce the memory references due to demand page walks by 11%, 1%, 2%, 8%, and 69%, respectively. Regarding the prefetch page walks, SP, ASP, DP, MP, and Morrigan  trigger 20%, 1%, 6%, 7%, and 117% additional memory references due to prefetch page walks with respect to the baseline, respectively. The prior dSTLB prefetchers do not reduce demand page walk memory references for instructions, so they provide negligible performance improvements, as Figure <ref type="figure" target="#fig_10">15</ref> shows. They also introduce only a small number of memory references for prefetch page walks because (i) SP issues only one prefetch per iSTLB miss, (ii) ASP and DP experience a lot of conflicting accesses in their prediction tables which does not allow them to produce prefetch requests, and (iii) MP leverages the LRU replacement policy that fails at keeping the most useful entries in the prediction table; on prediction table lookup misses, no prefetches are issued.</p><p>While Morrigan does generate more memory references for prefetch page walks than the existing dSTLB prefetchers, it achieves much higher coverage than the prior designs. Indeed, Morrigan reduces the memory references for demand page walks by 69% due to its high coverage. The vast majority of memory references due to prefetch page walks are caused by the IRIP module since the SDP module (i) issues only one prefetch at a time that requires a prefetch page walk, and (ii) is enabled only when the IRIP module is unable to issue prefetch requests (Section 4.1.2). However, the demand page walks are responsible for the iSTLB performance bottleneck since they take place on the critical path of execution causing unavoidable pipeline stalls, while the prefetch page walks are performed in the background without stalling the pipeline execution.</p><p>Finally, we examine the fraction of prefetch page walk memory references served by each level of the memory hierarchy. We find that 20%, 25%, 45%, and 10% of Morrigan's prefetch page walk memory references are served by L1, L2, LLC, and DRAM, respectively. Hence, the large reduction of demand page walk memory references that Morrigan achieves, lowers the instruction address translation overhead, thus providing significant performance gains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Comparing Different IRIP Designs</head><p>This section highlights the benefits of using multiple prediction tables with different number of prediction slots per entry for the IRIP module over the state-of-the-art approach that uses a single prediction table with fixed number of successors per entry. To do so, we implement Morrigan-mono whose operation is identical to Morrigan but its IRIP module leverages a single prediction table with a fixed number of successors per entry, as the state-of-theart MP <ref type="bibr" target="#b47">[53]</ref> does. We opt to provide an ISO-storage comparison between Morrigan and Morrigan-mono, so we configure the IRIP module of Morrigan-mono with a 203-entry prediction table with 8 prediction slots per entry, <ref type="foot" target="#foot_1">3</ref> and a 2-bit confidence counter per prediction slot to match the storage and the operation of Morrigan's IRIP module.</p><p>Figure <ref type="figure" target="#fig_12">17</ref> reveals that Morrigan outperforms Morrigan-mono (1.9% on average) across all the QMM server workloads. We observe this behavior because Morrigan makes better use of the available storage budget, hence tracking a much larger effective working set. Whereas Morrigan dynamically tracks required number of prediction slots per instruction page and enables efficient transferring of entries between the prediction tables, Morrigan-mono accommodates eight prediction slots per prediction table entry. Specifically, Morrigan-mono tracks 203 entries and Morrigan effectively tracks 448 entries (128*3+64). Indeed, we find that Morrigan-mono requires 6.9KB of storage to match the performance of Morrigan having a 3.76KB storage budget.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Comparison with Other Approaches</head><p>Figure <ref type="figure" target="#fig_13">18</ref> compares Morrigan with other approaches that improve TLB performance and the ideal case of the Perfect STLB for instruction references (Perfect iSTLB), as explained in Section 3.4.</p><p>ISO-Storage Comparison. We compare Morrigan against a system that does not apply STLB prefetching but for fairness it is enhanced with an enlarged STLB. Specifically, STLB is augmented with 388 additional entries to match the storage budget of Morrigan (including the PB) without affecting its access time. Figure <ref type="figure" target="#fig_13">18</ref> shows that Morrigan outperforms the this scenario by 4.1%.</p><p>Prefetching into TLB. Prior STLB prefetchers <ref type="bibr" target="#b32">[38,</ref><ref type="bibr" target="#b47">53]</ref> and patents <ref type="bibr" target="#b20">[26,</ref><ref type="bibr" target="#b46">52]</ref> use a PB to store the prefetched PTEs. Figure <ref type="figure" target="#fig_13">18</ref> shows that placing the prefetches of Morrigan directly into the STLB (P2TLB) provides a 18.9% performance degradation because it causes STLB pollution when the prefetches are inaccurate. Our results are consistent with prior work <ref type="bibr" target="#b21">[27,</ref><ref type="bibr" target="#b32">38,</ref><ref type="bibr" target="#b47">53]</ref> stating that prefetching directly into the STLB causes pollution and performance degradation. Prefetched Address Translation (ASAP) <ref type="bibr" target="#b54">[60]</ref>. ASAP is a microarchitectural scheme which lowers the latency cost of page walks by prefetching deeper levels of the radix tree page table, avoiding serialized memory references on PSC misses. Figure <ref type="figure" target="#fig_13">18</ref> depicts that Morrigan outperforms ASAP by 4.8% (on average) because the PSCs experience high hit rates for the QMM workloads, thus limiting the performance gains of ASAP. We find that, on average, 1.4 memory references are required per page walk due to PSC misses. The leaf page table level always triggers a memory reference, hence only 0.4 memory references (on average) are triggered due to the other 3 page table levels. Therefore, the high PSC hit rate of the QMM workloads hurts the effectiveness of ASAP.</p><p>Combining Morrigan with ASAP. STLB prefetching is orthogonal to techniques that aim at lowering page walk latency. Consequently, it is natural to combine Morrigan with ASAP. The core idea is that ASAP lowers the page walk latency, thus it can be further used to accelerate the prefetch page walks of Morrigan. Figure <ref type="figure" target="#fig_13">18</ref> illustrates that combining Morrigan with ASAP improves geometric mean performance by 10.1%, approaching the ideal performance results (Perfect iSTLB) for most QMM workloads. We observe such behavior because ASAP improves the timeliness of Morrigan's prefetches by accelerating the corresponding prefetch page walks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Synergy with I-Cache Prefetching</head><p>This section demonstrates that Morrigan is synergistic with Icache prefetching. Recall that our baseline includes next-line Icache prefetching that does not cross page boundaries (Section 5). However, modern I-cache prefetchers cross page boundaries, as explained in Section 3.5. This section studies a state-of-the-art I-cache prefetcher, FNL+MMA, which crosses page boundaries, because it provides the highest performance among the IPC1 prefetchers <ref type="bibr" target="#b16">[22]</ref> when instruction address translation is considered (Section 3.5).</p><p>Figure <ref type="figure" target="#fig_14">19</ref> shows the performance results of (i) FNL+MMA, (ii) Morrigan with next-line I-cache prefetcher (Morrigan), as evaluated in all previous sections, and (iii) Morrigan when combined with FNL+MMA (Morrigan+FNL+MMA). The baseline corresponds to a system with a next-line I-cache prefetcher and no STLB prefetching.</p><p>Overall, FNL+MMA, Morrigan, and Morrigan+FNL+MMA provide a geometric speedup of 1.2%, 7.6%, and 10.9%, respectively. We observe that the performance of Morrigan+FNL+MMA exceeds the sum of the benefits of the individual prefetchers. The reason why the total is greater than the sum of its parts is that Morrigan improves the timeliness of FNL+MMA. Specifically, 51.7% of the beyond-page-boundary prefetches of FNL+MMA that require a page walk hit in the PB of Morrigan+FNL+MMA, thus improving the timelines of the respective instruction prefetches. The main takeaway is that Morrigan is synergistic with I-cache prefetching. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Workload Colocation in SMT Cores</head><p>This section quantifies the performance of Morrigan under SMT colocation (Section 5). For this experiment, we double the size of the prediction tables of the IRIP module since Morrigan has to separately build Markov chains for two threads in the same prediction tables. This increases the storage budget of Morrigan to 7.5KBs. We compare the same set of as in Section 6.5: Morrigan, FNL+MMA, and Morrigan+FNL+MMA. The baseline corresponds to a system with the next-line I-cache prefetcher and no STLB prefetching. Figure <ref type="figure" target="#fig_15">20</ref> presents the performance results.</p><p>The overall trends are consistent with Section 6.5; however, the absolute performance gains are higher under SMT, since colocating two QMM workloads increases the pressure on the cache and the TLB hierarchy, providing higher opportunity for prefetching. Morrigan and FNL+MMA provide speedups of 8.9% and 3.4%, respectively. Morrigan+FNL+MMA improves performance by 13.7% because it (i) eliminates the majority of the observed iSTLB misses, and (ii) improves the timeliness of the FNL+MMA (Section 6.5).</p><p>If the size of the prediction tables of the IRIP module is not doubled in the SMT setup, Morrigan and Morrigan+FNL+MMA improve performance by 6.4% and 11.1%, on average, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RELATED WORK</head><p>Increasing TLB reach. Prior work increases the effective capacity of TLBs by coalescing virtually and physically contiguous PTEs into a single TLB entry <ref type="bibr" target="#b62">[68,</ref><ref type="bibr" target="#b63">69]</ref>. These approaches are (i) limited by coalescing opportunities exposed by the OS since physical contiguity is not guaranteed, and (ii) susceptible to security issues when applied for code pages because an adversary could exploit this contiguity to attack the system. In addition, Bhattacharjee et al. <ref type="bibr" target="#b31">[37]</ref> propose a shared among cores last-level TLB that exploits page table locality only on demand page walks. Instead, Morrigan improves the performance of private-per-core TLBs via microarchitectural prefetching, exploits page table locality for both demand and prefetch walks, and does not disrupt the existing virtual memory subsystem.</p><p>Speculative address translation. Speculation-based approaches <ref type="bibr" target="#b27">[33,</ref><ref type="bibr" target="#b43">49,</ref><ref type="bibr" target="#b64">70]</ref> predict the address translation of a non TLB-resident page, the processor continues executing instructions speculatively, and a page walk is initiated in the background to validate whether the predicted translation is correct. In case of valid speculation, the verification page walk overlaps useful work, hiding its latency cost. Speculation-based approaches are affected by the system state since they rely on explicit virtual and physical contiguity to predict the missing address translations which is not guaranteed in systems today. Morrigan exploits only virtual contiguity which comes at zero cost and is independent of the system state.</p><p>Mitigating TLB miss latency. Improving the performance of the MMU-Caches <ref type="bibr" target="#b26">[32,</ref><ref type="bibr" target="#b30">36]</ref> is an effective way to reduce the latency penalty of frequent TLB misses. POM-TLB <ref type="bibr" target="#b67">[73]</ref> is a large die-stacked L3 TLB that reduces the page walk memory references to just one reference. DVMT <ref type="bibr" target="#b22">[28]</ref> allows the application to define the appropriate page table format for an address space portion, reducing the required page walk memory references. Alternatively, hashed page tables <ref type="bibr" target="#b45">[51,</ref><ref type="bibr" target="#b71">77,</ref><ref type="bibr" target="#b76">82]</ref> have been proposed to resolve TLB misses faster than the conventional radix tree page tables. Morrigan is complimentary to these approaches as it eliminates iSTLB misses via prefetching PTEs ahead of demand STLB accesses.</p><p>TLB management. Typically TLBs employ a variation of the LRU replacement policy. Mirbagher-Ajorpaz et al. <ref type="bibr" target="#b55">[61]</ref> propose a new predictive replacement policy for the STLB. However, STLB replacement policies aim at keeping in the STLB the most useful PTEs while STLB prefetchers proactively fetch the PTE(s) that would be requested by the next memory access(es). Elnawawy et al. <ref type="bibr" target="#b39">[45]</ref> identify heterogeneity in TLB behavior of data-intensive applications, i.e., a few data pages have high reuse but poor temporal locality In response, they propose Diligent TLBs, a scheme that pins in the STLB such delinquent data pages. Although effective for data pages, our analysis (Section 3.3) indicates that <ref type="bibr" target="#b39">[45]</ref> needs to pin hundreds of instruction pages in the STLB to achieve significant MPKI reductions for instruction accesses; such extensive pinning raises the STLB MPKI of data pages. Software schemes. Compile-time optimization approaches <ref type="bibr" target="#b38">[44,</ref><ref type="bibr" target="#b58">64]</ref> modify hugetlbfs to place only hot functions in huge pages. Moreover, OS schemes using superpages <ref type="bibr" target="#b37">[43,</ref><ref type="bibr" target="#b53">59,</ref><ref type="bibr" target="#b77">83]</ref> map small code regions into superpages via superpage promotion and page table sharing. Recency-based TLB Preloading <ref type="bibr" target="#b68">[74]</ref> builds a recency stack of PTEs in the page table to derive prefetches based on past access patterns. There are two major differences between Morrigan and <ref type="bibr" target="#b68">[74]</ref>. First, Morrigan is a microarchitectural prefetcher that does not imply any page table or software modification while <ref type="bibr" target="#b68">[74]</ref> is a software prefetching scheme that modifies the page table. Secondly, Morrigan considers access frequency for prefetching while <ref type="bibr" target="#b68">[74]</ref> relies on recency to drive prefetching -a feature that does not correlate well with iSTLB prefetching (Section 3.4).</p><p>Instruction cache prefetching. Numerous I-cache prefetchers have been proposed in recent literature <ref type="bibr" target="#b16">[22,</ref><ref type="bibr" target="#b66">72]</ref>. Although effective for capturing the L1 I-cache miss stream, these prefetchers fall short at prefetching for the iSTLB miss stream because they are tuned for short prefetch distances and low latencies, as the prefetched blocks are often found in the L2 or the LLC <ref type="bibr" target="#b41">[47]</ref>. In contrast, iSTLB misses require larger prefetch distances and incur higher latency, caused by the serialized accesses to the memory hierarchy due to page walks. Reinman et al. <ref type="bibr" target="#b66">[72]</ref> propose FDIP, a prefetching scheme that speculatively identifies instruction blocks that would potentially cause an L1 I-cache miss in the future and prefetch them from the lower level caches. Intuitively, the impact of FDIP on tolerating iSTLB misses is relatively small since it would just bring instruction PTEs into the STLB when the prefetched instruction blocks reside in memory pages different from the page where the initially missed instruction block resides. Finally, FDIP would pollute the STLB when the prefetched PTEs are inaccurate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSIONS</head><p>This paper provides evidence that instruction address translation is a significant performance bottleneck in server applications. To mitigate this bottleneck, this paper proposes Morrigan, a composite instruction TLB prefetcher whose design is based on new reuse and locality insights of instruction TLB misses. Morrigan consists of two complimentary prefetch engines; (i) the Irregular Instruction TLB Prefetcher (IRIP), an ensemble of table-based hardware Markov prefetchers that build and store variable length Markov chains out of the instruction TLB miss stream while leveraging a new frequencybased replacement policy to manage their internal state, and (ii) the Small Delta Prefetcher (SDP), an enhanced sequential prefetcher that is engaged only when the IRIP module of Morrigan is unable to issue prefetch requests. Considering an extensive set of industrial server workloads, this paper demonstrates that Morrigan provides large performance enhancements by saving the majority of the instruction TLB misses while significantly reducing the references to the memory hierarchy due to page walks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Figure 3: Instruction MPKI for front-end structures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Accumulative distribution of deltas (absolute values) between pages that produce consecutive iSTLB misses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Figure 6: Instruction pages sorted by STLB miss frequency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Probability of accessing the same successor page after an iSTLB miss for a given page.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 9 :Figure 10 :</head><label>910</label><figDesc>Figure 9: Performance comparison between state-of-the-art dSTLB prefetchers and an ideal scenario.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Operation of IRIP on PRT-S2 hits.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Miss coverage of Morrigan for various budgets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 14 :</head><label>14</label><figDesc>Figure 14: Miss coverage of Morrigan when the prediction tables of the IRIP module use different replacement policies for various storage budgets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 15 :</head><label>15</label><figDesc>Figure 15: Performance comparison between Morrigan and the state-of-the-art data STLB (dSTLB) prefetchers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 16 :</head><label>16</label><figDesc>Figure 16: Normalized page walk memory references. QMM server workloads 0 2 4 6 8 10 12 Speedup (%)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 17 :</head><label>17</label><figDesc>Figure 17: Performance of Morrigan when the IRIP module uses an ensemble of four tables (Morrigan) versus a singletable design (Morrigan-mono).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 18 :</head><label>18</label><figDesc>Figure 18: Performance comparison with other approaches that improve TLB performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 19 :</head><label>19</label><figDesc>Figure 19: Impact of Morrigan on I-cache prefetching.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 20 :</head><label>20</label><figDesc>Figure 20: Performance of Morrigan under SMT colocation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>does).</figDesc><table><row><cell>6</cell><cell>-</cell><cell cols="3">Distance</cell><cell></cell><cell cols="6">Prediction Table PRT-S2</cell></row><row><cell cols="2">Current VPN Previous VPN 9</cell><cell cols="2">. 0xA1</cell><cell>1</cell><cell cols="2">VPN i . . . 0xB5 0xA1</cell><cell cols="2">D i 1000 1 . . . 17</cell><cell></cell><cell cols="2">C 2 i 1 . . . 0</cell><cell>D i 666 2 . . . 2</cell><cell>C . . . 2 i 0 1</cell><cell>8</cell><cell>7</cell><cell>victim</cell></row><row><cell cols="5">0xB2 Prefetch Page Walk 0XA3 + + 2 )</cell><cell></cell><cell cols="4">Storage Prefetch</cell><cell>)</cell><cell>5 )</cell><cell>3 Max? ) )</cell><cell>Min? lookahead prefetching</cell></row><row><cell></cell><cell cols="2">MUX 2:1</cell><cell>4</cell><cell></cell><cell>0xA0 PTE of</cell><cell cols="2">0xA1 PTE of</cell><cell>0xA2 PTE of</cell><cell cols="3">0xA3 PTE of</cell><cell>0xA4 PTE of</cell><cell>0xA5 PTE of</cell><cell>0xA6 PTE of</cell><cell>0xA7 PTE of</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Figure 12: Design and operation of Morrigan. Diamonds indicate decision points, circles are actions.page into the register holding the previously missed virtual page to be used on the next IRIP operation 9 . Note that when Morrigan operates, steps 7 and 8 take place only for PRT-S8; for PRT-S1, PRT-S2, and PRT-S4 Morrigan transfers the entry coupled with the new distance into a prediction table with more prediction slots per entry. Section 4.2 explains the operation of Morrigan in detail.</figDesc><table><row><cell>v@ .</cell><cell>L1 TLB</cell><cell>H</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>to cpu</cell><cell>7</cell><cell>enable</cell><cell>v@ .</cell><cell></cell><cell>PRT-S1</cell><cell></cell><cell></cell><cell>)</cell><cell cols="2">Prefetch Requests 9</cell><cell>. . .</cell><cell>10</cell><cell>PB</cell><cell>M . . .</cell><cell>12 Prefetch Page Walk</cell><cell>. . .</cell><cell>13 Store to PB</cell></row><row><cell></cell><cell>STLB H to cpu M</cell><cell>M</cell><cell>1 Instr? Y . N</cell><cell>2</cell><cell>PB H .</cell><cell>M</cell><cell>Demand Page Walk 3 5</cell><cell>Store to TLB 4</cell><cell>Morrigan</cell><cell>. . . .</cell><cell>8</cell><cell>PRT-S8 PRT-S2 PRT-S4</cell><cell>OR</cell><cell>0 1</cell><cell>18 6</cell><cell cols="3">PRT-S1 Update Confidence Counter</cell><cell>Pred. Full? 11 Discard H</cell><cell>Transfer to PRT-S2 MUX . . . 14</cell><cell>Remove from PRT-S1 Locality Page Table</cell></row><row><cell></cell><cell></cell><cell></cell><cell>background critical path</cell><cell></cell><cell cols="4">IRIP : Irregular Instruction TLB Prefetcher SDP : Small Delta Prefetcher RLFU : Random Least Frequently Used</cell><cell cols="7">Insert PRT-S1 . ) 15 Store to PB Page Table Locality SDP Prefetch Page Walk 16 17</cell><cell>previous v@ . .</cell><cell cols="2">PRT-S2 PRT-S4 19 PRT-S8</cell><cell>24</cell><cell>20</cell><cell>Pred. Full? Pred. Full? Full? Pred.</cell><cell>RLFU Transfer to PRT-S4 21 22 RLFU Transfer to PRT-S8 RLFU Victimize Successor Remove from 23 PRT-S2 Remove from PRT-S4 25</cell></row></table><note>RLFU.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>System configuration.</figDesc><table><row><cell>Component</cell><cell>Description</cell></row><row><cell>L1 I-TLB</cell><cell>128-entry, 8-way, 1-cycle, 4-entry MSHR</cell></row><row><cell>L1 D-TLB</cell><cell>64-entry, 4-way, 1-cycle, 4-entry MSHR</cell></row><row><cell>L2 TLB</cell><cell>1536-entry, 6-way, 8-cycle, 4-entry MSHR, 1 page walk / cycle</cell></row><row><cell>Page Structure</cell><cell>3-level Split PSC, 2-cycle.</cell></row><row><cell>Caches</cell><cell>PML4: 2-entry, fully; PDP: 4-entry, fully; PD: 32-entry, 4-way.</cell></row><row><cell>Prefetch Buffer (PB)</cell><cell>64-entry, fully assoc, 2-cycle</cell></row><row><cell>L1 I-Cache</cell><cell>32KB, 8-way, 4-cycle, 8-entry MSHR, next line prefetcher</cell></row><row><cell>L1 D-Cache</cell><cell>32KB, 8-way, 4-cycle, 8-entry MSHR, next line prefetcher</cell></row><row><cell>L2 Cache</cell><cell>512KB, 8-way, 8-cycle, 32-entry MSHR, SPP [57]</cell></row><row><cell>LLC (per core)</cell><cell>2MB, 16-way, 10-cycle, 64-entry MSHR</cell></row><row><cell>DRAM</cell><cell>tRP=tRCD=tCAS=12, 12.8 GB/s</cell></row><row><cell>Branch Predictor</cell><cell>hashed perceptron</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">Page Y is a successor of page X if an iSTLB miss on page X is immediately followed by an iSTLB miss on page Y.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1">The IRIP module of Morrigan-mono is enhanced with 8 prediction slots per prediction table entry to make a fair comparison with the IRIP module of Morrigan since PRT-S8 can store up to 8 predictions per entry.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">ACKNOWLEDGEMENTS</head><p>The authors are profoundly grateful to (i) the anonymous reviewers for their constructive feedback, and (ii) the anonymous shepherd for his/her valuable comments that significantly improved the quality of the paper. This work is partially supported by the Spanish Ministry of Science and Technology through the PID2019-107255GB project, the Generalitat de Catalunya (contract 2017-SGR-1414), the NSF grant CCF-1912617, the Semiconductor Research Corporation grant 2936.001, and generous gifts from Intel Labs. Georgios Vavouliotis has been supported by the Spanish Ministry of Economy, Industry and Competitiveness and the European Social Fund under the FPI fellowship No. PRE2018-087046. Marc Casas has been supported by the Spanish Ministry of Economy, Industry and Competitiveness under the Ramon y Cajal fellowship No. RYC-2017-23269.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A ARTIFACT APPENDIX A.1 Abstract</head><p>Our artifact provides (i) the implementation of Morrigan, (ii) the simulation infrastructure, (iii) the set of workloads, (iv) scripts for launching simulations, and (v) python scripts to reproduce the most important evaluation figures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Artifact check-list (meta-information)</head><p>• Program: Memory traces of server applications provided by Qualcomm for CVP-1 <ref type="bibr" target="#b11">[14]</ref> and IPC-1 <ref type="bibr" target="#b16">[22]</ref>. A.3.4 Data sets. We use memory traces provided by Qualcomm for CVP-1 <ref type="bibr" target="#b11">[14]</ref> and IPC-1 <ref type="bibr" target="#b16">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Installation</head><p>Download the artifact from https://doi.org/10.5281/zenodo.5496052. Then, extract it by executing the following command.</p><p>tar xvzf paper-47-AE.zip</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Experiment workflow</head><p>To reproduce the most important evaluation results, take the following steps.</p><p>• cd paper-47-AE/ChampSim-SC • set the paths in run_champsim.sh (line 2)</p><p>• set the paths in generate_binary.sh (lines 2, 4, 8)</p><p>• compile the binaries by executing bash micro_ae.sh • cd /path-to/paper-47-AE • set the paths in submit.sh (lines 52, 55)</p><p>• execute bash launch.sh (it submits the jobs in batches; around 30 minutes to submit all jobs)</p><p>To check the status of the jobs, use the following command.</p><p>watch squeue -&lt;user-name&gt; It takes 1-3 hours to finish all jobs, depending on the machine and the number of jobs that can be launched in parallel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.6 Evaluation and expected results</head><p>When all jobs are finished, generate the evaluation figures by executing the following commands. cd /path-to/paper-47-AE/ChampSim-SC bash generate_figures.sh After executing these commands, there will be two figures under /path-to/paper-47-AE/ChampSim-SC/Figures with names speedup_sota </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.7 Methodology</head><p>Submission, reviewing and badging methodology:</p><p>• https://www.acm.org/publications/policies/artifact-reviewbadging • http://cTuning.org/ae/submission-20201122.html • http://cTuning.org/ae/reviewing-20201122.html</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Before Memory Was Virtual</title>
		<ptr target="http://denninginstitute.com/pjd/PUBS/bvm.pdf" />
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">SPEC CPU</title>
		<ptr target="https://www.spec.org/cpu2006/" />
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<ptr target="https://denninginstitute.com/pjd/PUBS/ENC/locality08.pdf" />
		<title level="m">The Locality Principle</title>
				<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Huge Pages and libhugetlbfs</title>
		<ptr target="https://lwn.net/Articles/374424/" />
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<ptr target="https://en.wikichip.org/wiki/intel/microarchitectures/sandy_bridge_(client" />
		<title level="m">Sandy Bridge -Microarchitectures</title>
				<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Using Intel VTune Amplifier XE to tune software on the 6th generation Intel Core processor family</title>
		<ptr target="https://software.intel.com/content/dam/develop/external/us/en/documents/using-intel-vtune-amplifier-xe-on-6th-generation-intel-core-processors-1-0.pdf" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">ARMv8 Architecture Reference Manual</title>
		<ptr target="https://developer.arm.com/documentation/ddi0553/bp" />
		<imprint>
			<date type="published" when="2015">2015-2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<ptr target="https://www.spec.org/cpu2017/" />
	</analytic>
	<monogr>
		<title level="j">SPEC CPU</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The RISC-V Instruction Set Manual</title>
		<ptr target="https://content.riscv.org/wp-content/uploads/2017/05/riscv-privileged-v1.10.pdf" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<ptr target="https://software.intel.com/content/www/us/en/develop/download/5-level-paging-and-5-level-ept-white-paper.html" />
		<title level="m">Intel. 5-Level Paging and 5-Level EPT</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<ptr target="https://www.principledtechnologies.com/Intel/Xeon-8272CL-Microsoft-Azure-WordPress-science-0920.pdf" />
		<title level="m">Principled Technologies report: Hands-on testing. Real-world results</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Championship Value Prediction (CVP</title>
		<ptr target="https://www.microarch.org/cvp1/" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<ptr target="https://perf.wiki.kernel.org" />
		<title level="m">Linux profiling with performance counters</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<ptr target="https://ppisar.fedorapeople.org/perl_rebuild/scratch/latest/packages/perl-Net-Amazon-EC2/hw_info.log" />
		<title level="m">perl-Net-Amazon-EC2</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<ptr target="https://ppisar.fedorapeople.org/perl_rebuild/scratch/latest/packages/perl-Net-Amazon-S3/hw_info.log" />
		<title level="m">perl-Net-Amazon-S3</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Public clouds and vulnerable CPUs: are we secure?</title>
		<ptr target="https://archive.fosdem.org/2020/schedule/event/vai_pubic_clouds_and_vulnerable_cpus/attachments/slides/3650/export/events/attachments/vai_pubic_clouds_and_vulnerable_cpus/slides/3650/FOSDEM2020_vkuznets.pdf" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<ptr target="https://research.ece.ncsu.edu/ipc/" />
		<title level="m">The 1st Instruction Prefetching Championship</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<ptr target="https://www.amd.com/system/files/TechDocs/24593.pdf" />
		<title level="m">AMD64 Architecture Programmer Manual</title>
				<imprint>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Beyond malloc efficiency to fleet efficiency: a hugepage-aware memory allocator</title>
		<ptr target="https://www.usenix.org/system/files/osdi21-hunter.pdf" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Intel ® 64 and IA-32 Architectures Software Developer Manuals</title>
		<ptr target="https://software.intel.com/en-us/articles/intel-sdm" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Inter-core cooperative TLB prefetchers</title>
		<author>
			<persName><forename type="first">Abishek</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<ptr target="https://patents.google.com/patent/US8880844B1/en" />
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Advanced Concepts on Address Translation, Appendix L in</title>
		<author>
			<persName><forename type="first">Abishek</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<ptr target="http://www.cs.yale.edu/homes/abhishek/abhishek-appendix-l.pdf" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Computer Architecture: A Quantitative Approach</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Do-It-Yourself Virtual Memory Translation</title>
		<author>
			<persName><forename type="first">Hanna</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mattan</forename><surname>Erez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Etsion</surname></persName>
		</author>
		<idno type="DOI">10.1145/3079856.3080209</idno>
		<ptr target="https://doi.org/10.1145/3079856.3080209" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th Annual International Symposium on Computer Architecture (ISCA &apos;17)</title>
				<meeting>the 44th Annual International Symposium on Computer Architecture (ISCA &apos;17)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="457" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Experimental Evaluation of Software Aging Effects on the Eucalyptus Cloud Computing Infrastructure</title>
		<author>
			<persName><forename type="first">Jean</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rubens</forename><surname>Matos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Maciel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rivalino</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ibrahim</forename><surname>Beicker</surname></persName>
		</author>
		<idno type="DOI">10.1145/2090181.2090185</idno>
		<ptr target="https://doi.org/10.1145/2090181.2090185" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Middleware 2011 Industry Track Workshop (Middleware &apos;11)</title>
				<meeting>the Middleware 2011 Industry Track Workshop (Middleware &apos;11)<address><addrLine>New York, NY, USA, Article</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Memory Hierarchy for Web Search</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2018.00061</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2018.00061" />
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="643" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Effective Hardware-Based Data Prefetching for High-Performance Processors</title>
		<author>
			<persName><forename type="first">Jean-Loup</forename><surname>Baer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tien-Fu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1109/12.381947</idno>
		<ptr target="https://doi.org/10.1109/12.381947" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="609" to="623" />
			<date type="published" when="1995-05">1995. May 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Translation Caching: Skip, Don&apos;T Walk (the Page Table)</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">W</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Rixner</surname></persName>
		</author>
		<idno type="DOI">10.1145/1815961.1815970</idno>
		<ptr target="https://doi.org/10.1145/1815961.1815970" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual International Symposium on Computer Architecture (ISCA &apos;10)</title>
				<meeting>the 37th Annual International Symposium on Computer Architecture (ISCA &apos;10)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="48" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">SpecTLB: A Mechanism for Speculative Address Translation</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">W</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Rixner</surname></persName>
		</author>
		<idno type="DOI">10.1145/2000064.2000101</idno>
		<ptr target="https://doi.org/10.1145/2000064.2000101" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Annual International Symposium on Computer Architecture (ISCA &apos;11)</title>
				<meeting>the 38th Annual International Symposium on Computer Architecture (ISCA &apos;11)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="307" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Side-channels beyond the cloud edge: New isolation threats and solutions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bazm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sudholt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Menaud</surname></persName>
		</author>
		<idno type="DOI">10.1109/CSNET.2017.8241986</idno>
		<ptr target="https://doi.org/10.1109/CSNET.2017.8241986" />
	</analytic>
	<monogr>
		<title level="m">2017 1st Cyber Security in Networking Conference (CSNet)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Side Channels in the Cloud: Isolation Challenges, Attacks, and Countermeasures</title>
		<author>
			<persName><forename type="first">Mohammad-Mahdi</forename><surname>Bazm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Sudholt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Marc</forename><surname>Menaud</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/hal-01591808workingpaperorpreprint" />
		<imprint>
			<date type="published" when="2017-03">2017. March 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Large-reach Memory Management Unit Caches</title>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<idno type="DOI">10.1145/2540708.2540741</idno>
		<ptr target="https://doi.org/10.1145/2540708.2540741" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO-46)</title>
				<meeting>the 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO-46)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="383" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Shared Last-level TLBs for Chip Multiprocessors</title>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lustig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Martonosi</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2014698.2014896" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 IEEE 17th International Symposium on High Performance Computer Architecture (HPCA &apos;11)</title>
				<meeting>the 2011 IEEE 17th International Symposium on High Performance Computer Architecture (HPCA &apos;11)<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="62" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Inter-core Cooperative TLB for Chip Multiprocessors</title>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Martonosi</surname></persName>
		</author>
		<idno type="DOI">10.1145/1736020.1736060</idno>
		<ptr target="https://doi.org/10.1145/1736020.1736060" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Edition of ASPLOS on Architectural Support for Programming Languages and Operating Systems (ASPLOS XV)</title>
				<meeting>the Fifteenth Edition of ASPLOS on Architectural Support for Programming Languages and Operating Systems (ASPLOS XV)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="359" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Blackburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Garner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asjad</forename><forename type="middle">M</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathryn</forename><forename type="middle">S</forename><surname>Khang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rotem</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amer</forename><surname>Bentzur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Diwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">Z</forename><surname>Frampton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Guyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antony</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Hosking</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Jump</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="middle">B</forename><surname>Eliot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aashish</forename><surname>Moss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Darko</forename><surname>Phansalkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Stefanović</surname></persName>
		</author>
		<author>
			<persName><surname>Vandrunen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Daniel Von Dincklage</surname></persName>
		</author>
		<author>
			<persName><surname>Wiedermann</surname></persName>
		</author>
		<idno type="DOI">10.1145/1167473.1167488</idno>
		<ptr target="https://doi.org/10.1145/1167473.1167488" />
		<title level="m">Proceedings of the 21st Annual ACM SIGPLAN Conference on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA &apos;06)</title>
				<meeting>the 21st Annual ACM SIGPLAN Conference on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA &apos;06)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="169" to="190" />
		</imprint>
	</monogr>
	<note>The DaCapo Benchmarks: Java Benchmarking Development and Analysis</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Performance of the VAX-11/780</title>
		<author>
			<persName><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><forename type="middle">S</forename><surname>Emer</surname></persName>
		</author>
		<idno type="DOI">10.1145/214451.214455</idno>
		<ptr target="https://doi.org/10.1145/214451.214455" />
	</analytic>
	<monogr>
		<title level="j">Translation Buffer: Simulation and Measurement. ACM Trans. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="31" to="62" />
			<date type="published" when="1985-02">1985. Feb. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Efficient Address Translation for Architectures with Multiple Page Sizes</title>
		<author>
			<persName><forename type="first">Guilherme</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<idno type="DOI">10.1145/3037697.3037704</idno>
		<ptr target="https://doi.org/10.1145/3037697.3037704" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS &apos;17)</title>
				<meeting>the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS &apos;17)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="435" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><surname>Denning</surname></persName>
		</author>
		<idno type="DOI">10.1145/356571.356573</idno>
		<ptr target="https://doi.org/10.1145/356571.356573" />
	</analytic>
	<monogr>
		<title level="j">Virtual Memory. ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="153" to="189" />
			<date type="published" when="1970-09">1970. Sept. 1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Shared Address Translation Revisited</title>
		<author>
			<persName><forename type="first">Xiaowan</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhya</forename><surname>Dwarkadas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Cox</surname></persName>
		</author>
		<idno type="DOI">10.1145/2901318.2901327</idno>
		<ptr target="https://doi.org/10.1145/2901318.2901327" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh European Conference on Computer Systems (EuroSys &apos;16)</title>
				<meeting>the Eleventh European Conference on Computer Systems (EuroSys &apos;16)<address><addrLine>New York, NY, USA, Article Article</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Using Hugetlbfs for Mapping Application Text Regions</title>
		<author>
			<persName><forename type="first">Kshitij</forename><surname>Doshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jantz</forename><surname>Tran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Diligent TLBs: A Mechanism for Exploiting Heterogeneity in TLB Miss Behavior</title>
		<author>
			<persName><forename type="first">Hussein</forename><surname>Elnawawy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rangeen</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amro</forename><surname>Awad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><forename type="middle">T</forename><surname>Byrd</surname></persName>
		</author>
		<idno type="DOI">10.1145/3330345.3330363</idno>
		<ptr target="https://doi.org/10.1145/3330345.3330363" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Supercomputing (ICS &apos;19)</title>
				<meeting>the ACM International Conference on Supercomputing (ICS &apos;19)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="195" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Jump over ASLR: Attacking Branch Predictors to Bypass ASLR</title>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Evtyushkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Ponomarev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nael</forename><surname>Abu-Ghazaleh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO-49)</title>
				<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">40</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Clearing the Clouds: A Study of Emerging Scale-out Workloads on Modern Hardware</title>
		<author>
			<persName><forename type="first">Almutaz</forename><surname>Michael Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Adileh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stavros</forename><surname>Kocberber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Volos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Djordje</forename><surname>Alisafaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cansu</forename><surname>Jevdjic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><forename type="middle">Daniel</forename><surname>Kaynak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><surname>Falsafi</surname></persName>
		</author>
		<idno type="DOI">10.1145/2150976.2150982</idno>
		<ptr target="https://doi.org/10.1145/2150976.2150982" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS XVII)</title>
				<meeting>the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS XVII)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Large Pages May Be Harmful on NUMA Systems</title>
		<author>
			<persName><forename type="first">Fabien</forename><surname>Gaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baptiste</forename><surname>Lepers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremie</forename><surname>Decouchant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Funston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Fedorova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivien</forename><surname>Quéma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 USENIX Conference on USENIX Annual Technical Conference (USENIX ATC&apos;14)</title>
				<meeting>the 2014 USENIX Conference on USENIX Annual Technical Conference (USENIX ATC&apos;14)</meeting>
		<imprint>
			<publisher>USENIX Association, USA</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="231" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Devirtualizing Memory in Heterogeneous Systems</title>
		<author>
			<persName><forename type="first">Swapnil</forename><surname>Haria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
		<idno type="DOI">10.1145/3173162.3173194</idno>
		<ptr target="https://doi.org/10.1145/3173162.3173194" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS &apos;18)</title>
				<meeting>the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS &apos;18)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="637" to="650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">HUB: Hugepage Ballooning in Kernel-Based Virtual Machines</title>
		<author>
			<persName><forename type="first">Jingyuan</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaokuang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sai</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingwei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenlin</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3240302.3240420</idno>
		<ptr target="https://doi.org/10.1145/3240302.3240420" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Memory Systems (MEMSYS &apos;18)</title>
				<meeting>the International Symposium on Memory Systems (MEMSYS &apos;18)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="31" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Architectural Support for Translation Table Management in Large Address Space Machines</title>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jim</forename><surname>Hays</surname></persName>
		</author>
		<idno type="DOI">10.1145/165123.165128</idno>
		<ptr target="https://doi.org/10.1145/165123.165128" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual International Symposium on Computer Architecture (ISCA &apos;93)</title>
				<meeting>the 20th Annual International Symposium on Computer Architecture (ISCA &apos;93)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="39" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">James</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://patents.google.com/patent/US20110010521" />
		<title level="m">TLB Prefetching</title>
				<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Going the Distance for TLB Prefetching: An Application-driven Study</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gokul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Kandiraju</surname></persName>
		</author>
		<author>
			<persName><surname>Sivasubramaniam</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=545215.545237" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual International Symposium on Computer Architecture (ISCA &apos;02)</title>
				<meeting>the 29th Annual International Symposium on Computer Architecture (ISCA &apos;02)<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="195" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Profiling a Warehousescale Computer</title>
		<author>
			<persName><forename type="first">Svilen</forename><surname>Kanev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">Pablo</forename><surname>Darago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Hazelwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tipp</forename><surname>Parthasarathy Ranganathan</surname></persName>
		</author>
		<author>
			<persName><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><surname>Gu-Yeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><surname>Brooks</surname></persName>
		</author>
		<idno type="DOI">10.1145/2749469.2750392</idno>
		<ptr target="https://doi.org/10.1145/2749469.2750392" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42Nd Annual International Symposium on Computer Architecture (ISCA &apos;15)</title>
				<meeting>the 42Nd Annual International Symposium on Computer Architecture (ISCA &apos;15)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="158" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Redundant Memory Mappings for Fast Access to Large Memories</title>
		<author>
			<persName><forename type="first">Vasileios</forename><surname>Karakostas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jayneel</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furkan</forename><surname>Ayar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrián</forename><surname>Cristal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathryn</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Nemirovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Osman</forename><surname>Ünsal</surname></persName>
		</author>
		<idno type="DOI">10.1145/2749469.2749471</idno>
		<ptr target="https://doi.org/10.1145/2749469.2749471" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42Nd Annual International Symposium on Computer Architecture (ISCA &apos;15)</title>
				<meeting>the 42Nd Annual International Symposium on Computer Architecture (ISCA &apos;15)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="66" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Energy-efficient address translation</title>
		<author>
			<persName><forename type="first">V</forename><surname>Karakostas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cristal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nemirovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">S</forename></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2016.7446100</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2016.7446100" />
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="631" to="643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Path confidence based lookahead prefetching</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Pugsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V</forename><surname>Gratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L N</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chishti</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO.2016.7783763</idno>
		<ptr target="https://doi.org/10.1109/MICRO.2016.7783763" />
	</analytic>
	<monogr>
		<title level="m">2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Blasting Through the Front-End Bottleneck with Shotgun</title>
		<author>
			<persName><forename type="first">Rakesh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Grot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Nagarajan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3173162.3173178</idno>
		<ptr target="https://doi.org/10.1145/3173162.3173178" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS &apos;18)</title>
				<meeting>the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS &apos;18)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="30" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Coordinated and Efficient Huge Page Management with Ingens</title>
		<author>
			<persName><forename type="first">Youngjin</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hangchen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Rossbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmett</forename><surname>Witchel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation (OSDI &apos;16)</title>
				<meeting>the 12th USENIX Conference on Operating Systems Design and Implementation (OSDI &apos;16)</meeting>
		<imprint>
			<publisher>USENIX Association, USA</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="705" to="721" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Prefetched Address Translation</title>
		<author>
			<persName><forename type="first">Artemiy</forename><surname>Margaritov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitrii</forename><surname>Ustiugov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Bugnion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Grot</surname></persName>
		</author>
		<idno type="DOI">10.1145/3352460.3358294</idno>
		<ptr target="https://doi.org/10.1145/3352460.3358294" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52Nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO &apos;52)</title>
				<meeting>the 52Nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO &apos;52)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1023" to="1036" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">CHiRP: Control-Flow History Reuse Prediction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirbagher-Ajorpaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Garza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pokam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jiménez</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO50266.2020.00023</idno>
		<ptr target="https://doi.org/10.1109/MICRO50266.2020.00023" />
	</analytic>
	<monogr>
		<title level="m">2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="131" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">AsmDB: Understanding and Mitigating Front-End Stalls in Warehouse-Scale Computers</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Nagendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>August</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kanev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="56" to="63" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Design Tradeoffs for Software-Managed TLBs</title>
		<author>
			<persName><forename type="first">David</forename><surname>Nagle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Uhlig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Sechrest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Mudge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Brown</surname></persName>
		</author>
		<idno type="DOI">10.1145/165123.165127</idno>
		<ptr target="https://doi.org/10.1145/165123.165127" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual International Symposium on Computer Architecture (ISCA &apos;93)</title>
				<meeting>the 20th Annual International Symposium on Computer Architecture (ISCA &apos;93)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="27" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Optimizing function placement for large-scale data-center applications</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ottoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Maher</surname></persName>
		</author>
		<idno type="DOI">10.1109/CGO.2017.7863743</idno>
		<ptr target="https://doi.org/10.1109/CGO.2017.7863743" />
	</analytic>
	<monogr>
		<title level="m">2017 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="233" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">BOLT: A Practical Binary Optimizer for Data Centers and Beyond</title>
		<author>
			<persName><forename type="first">Maksim</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Auler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Nell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guilherme</forename><surname>Ottoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 IEEE/ACM International Symposium on Code Generation and Optimization</title>
				<meeting>the 2019 IEEE/ACM International Symposium on Code Generation and Optimization</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="2" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Hybrid TLB Coalescing: Improving TLB Translation Coverage Under Diverse Fragmented Memory Allocations</title>
		<author>
			<persName><forename type="first">Hyun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taekyung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jungi</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaehyuk</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><surname>Huh</surname></persName>
		</author>
		<author>
			<persName><surname>Isca</surname></persName>
		</author>
		<idno type="DOI">10.1145/3079856.3080217</idno>
		<ptr target="https://doi.org/10.1145/3079856.3080217" />
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Computer Architecture: A Quantitative Approach</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">L</forename><surname>Hennessy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<pubPlace>San Francisco, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Increasing TLB reach by exploiting clustering in page translations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Eckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Loh</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2014.6835964</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2014.6835964" />
	</analytic>
	<monogr>
		<title level="m">2014 IEEE 20th International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="558" to="567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Aamer Jaleel, and Abhishek Bhattacharjee</title>
		<author>
			<persName><forename type="first">Binh</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viswanathan</forename><surname>Vaidyanathan</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO.2012.32</idno>
		<ptr target="https://doi.org/10.1109/MICRO.2012.32" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 45th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO-45)</title>
				<meeting>the 2012 45th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO-45)<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="258" to="269" />
		</imprint>
	</monogr>
	<note>CoLT: Coalesced Large-Reach TLBs</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Large Pages and Lightweight Memory Management in Virtualized Environments: Can You Have It Both Ways</title>
		<author>
			<persName><forename type="first">Binh</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ján</forename><surname>Veselý</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Loh</surname></persName>
		</author>
		<author>
			<persName><surname>Bhattacharjee</surname></persName>
		</author>
		<idno type="DOI">10.1145/2830772.2830773</idno>
		<ptr target="https://doi.org/10.1145/2830772.2830773" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th International Symposium on Microarchitecture (MICRO-48)</title>
				<meeting>the 48th International Symposium on Microarchitecture (MICRO-48)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Renaissance: Benchmarking Suite for Parallel Applications on the JVM</title>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Prokopec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Rosà</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Leopoldseder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Duboscq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petr</forename><surname>Tůma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Studener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lubomír</forename><surname>Bulej</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yudi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Villazón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Würthinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><surname>Binder</surname></persName>
		</author>
		<idno type="DOI">10.1145/3314221.3314637</idno>
		<ptr target="https://doi.org/10.1145/3314221.3314637" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation</title>
				<meeting>the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="31" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Fetch directed instruction prefetching</title>
		<author>
			<persName><forename type="first">G</forename><surname>Reinman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Austin</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO.1999.809439</idno>
		<ptr target="https://doi.org/10.1109/MICRO.1999.809439" />
	</analytic>
	<monogr>
		<title level="m">MICRO-32. Proceedings of the 32nd Annual ACM/IEEE International Symposium on Microarchitecture</title>
				<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="16" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Rethinking TLB Designs in Virtualized Environments: A Very Large Part-of-Memory TLB</title>
		<author>
			<persName><forename type="first">Jee</forename><surname>Ho Ryoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nagendra</forename><surname>Gulur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizy</forename><forename type="middle">K</forename><surname>John</surname></persName>
		</author>
		<idno type="DOI">10.1145/3079856.3080210</idno>
		<ptr target="https://doi.org/10.1145/3079856.3080210" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th Annual International Symposium on Computer Architecture (ISCA &apos;17)</title>
				<meeting>the 44th Annual International Symposium on Computer Architecture (ISCA &apos;17)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="469" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Recency-based TLB Preloading</title>
		<author>
			<persName><forename type="first">Ashley</forename><surname>Saulsbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fredrik</forename><surname>Dahlgren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Per</forename><surname>Stenström</surname></persName>
		</author>
		<idno type="DOI">10.1145/339647.339666</idno>
		<ptr target="https://doi.org/10.1145/339647.339666" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual International Symposium on Computer Architecture (ISCA &apos;00)</title>
				<meeting>the 27th Annual International Symposium on Computer Architecture (ISCA &apos;00)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="117" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">On the Effectiveness of Address-Space Randomization</title>
		<author>
			<persName><forename type="first">Hovav</forename><surname>Shacham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Pfaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eu-Jin</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nagendra</forename><surname>Modadugu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Boneh</surname></persName>
		</author>
		<idno type="DOI">10.1145/1030083.1030124</idno>
		<ptr target="https://doi.org/10.1145/1030083.1030124" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th ACM Conference on Computer and Communications Security (CCS &apos;04)</title>
				<meeting>the 11th ACM Conference on Computer and Communications Security (CCS &apos;04)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="298" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Neighborhood-Aware Address Translation for Irregular GPU Applications</title>
		<author>
			<persName><forename type="first">Seunghee</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Lebeane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Solihin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arkaprava</forename><surname>Basu</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO.2018.00036</idno>
		<ptr target="https://doi.org/10.1109/MICRO.2018.00036" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO-51)</title>
				<meeting>the 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO-51)</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="352" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Elastic Cuckoo Page Tables: Rethinking Virtual Memory Translation for Parallelism</title>
		<author>
			<persName><forename type="first">Dimitrios</forename><surname>Skarlatos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apostolos</forename><surname>Kokolis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josep</forename><surname>Torrellas</surname></persName>
		</author>
		<idno type="DOI">10.1145/3373376.3378493</idno>
		<ptr target="https://doi.org/10.1145/3373376.3378493" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS &apos;20)</title>
				<meeting>the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS &apos;20)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1093" to="1108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">P</forename><surname>Vanderwiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Lilja</surname></persName>
		</author>
		<idno type="DOI">10.1145/358923.358939</idno>
		<ptr target="https://doi.org/10.1145/358923.358939" />
	</analytic>
	<monogr>
		<title level="j">Data Prefetch Mechanisms. ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="174" to="199" />
			<date type="published" when="2000-06">2000. June 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Exploiting Page Table Locality for Agile TLB Prefetching</title>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Vavouliotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lluc</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasileios</forename><surname>Karakostas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantinos</forename><surname>Nikas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nectarios</forename><surname>Koziris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Jiménez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Casas</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISCA52012.2021.00016</idno>
		<ptr target="https://doi.org/10.1109/ISCA52012.2021.00016" />
	</analytic>
	<monogr>
		<title level="m">2021 ACM/IEEE 48th Annual International Symposium on Computer Architecture (ISCA)</title>
				<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="85" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Large-Scale Cluster Management at Google with Borg</title>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Pedrosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madhukar</forename><surname>Korupolu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Oppenheimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Tune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Wilkes</surname></persName>
		</author>
		<idno type="DOI">10.1145/2741948.2741964</idno>
		<ptr target="https://doi.org/10.1145/2741948.2741964" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth European Conference on Computer Systems (EuroSys &apos;15)</title>
				<meeting>the Tenth European Conference on Computer Systems (EuroSys &apos;15)<address><addrLine>New York, NY, USA, Article</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Translation Ranger: Operating System Support for Contiguity-Aware TLBs</title>
		<author>
			<persName><forename type="first">Zi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lustig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Nellans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<idno type="DOI">10.1145/3307650.3322223</idno>
		<ptr target="https://doi.org/10.1145/3307650.3322223" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th International Symposium on Computer Architecture (ISCA &apos;19)</title>
				<meeting>the 46th International Symposium on Computer Architecture (ISCA &apos;19)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="698" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Hash, Don&apos;T Cache (the Page Table)</title>
		<author>
			<persName><forename type="first">Idan</forename><surname>Yaniv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Tsafrir</surname></persName>
		</author>
		<idno type="DOI">10.1145/2896377.2901456</idno>
		<ptr target="https://doi.org/10.1145/2896377.2901456" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Science (SIGMETRICS &apos;16)</title>
				<meeting>the 2016 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Science (SIGMETRICS &apos;16)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="337" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">On the Impact of Instruction Address Translation Overhead</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dwarkadas</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISPASS.2019.00018</idno>
		<ptr target="https://doi.org/10.1109/ISPASS.2019.00018" />
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="106" to="116" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
