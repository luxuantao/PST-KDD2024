<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Estimating the cognitive value of YouTube&apos;s educational videos: A learning analytics approach</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Abdulhadi</forename><surname>Shoufan</surname></persName>
							<email>abdulhadi.shoufan@kustar.ac.ae</email>
							<affiliation key="aff0">
								<orgName type="department">Electrical and Computer Engineering Department</orgName>
								<orgName type="institution">Khalifa University</orgName>
								<address>
									<settlement>Abu Dhabi</settlement>
									<country key="AE">UAE</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Electrical and Computer Engineering Department</orgName>
								<orgName type="institution">Khalifa University</orgName>
								<address>
									<settlement>Abu Dhabi</settlement>
									<country key="AE">UAE</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Estimating the cognitive value of YouTube&apos;s educational videos: A learning analytics approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9593B9C8FEE15A65025F2EF40B05F244</idno>
					<idno type="DOI">10.1016/j.chb.2018.03.036</idno>
					<note type="submission">Received Date: 13 May 2017 Revised Date: 10 March 2018 Accepted Date: 22 March 2018</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Computers in Human Behavior</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The literature provides some evidence for the effectiveness of online educational videos in students' learning. Also, general features of educational videos such as production style and video length were investigated to some extent. However, the actual cognitive features of educational videos available on the Internet have remained almost untreated, so far. The main goal of this study is to use learning analytics to investigate how far educational videos on YouTube support cognitive features -as formulated in the cognitive theory of multimedia learning-and how far these features support students' learning. We measure the Video Cognitive Value (VCV) by viewers' rating, particularly using the number of Likes based on a survey that we conducted to understand the semantics of Likes and Dislikes of YouTube's educational videos. Then, a sample of 105 videos was collected and analyzed with respect to cognitive features. A regression analysis showed that only four out of ten investigated features are significant for V CV (pretraining, modality, spatial contiguity, and embodiment) and the regression model could only explain 63% of the data variance. Further tests were performed to include other factors such as the video production style, the video length, the talking speed, the gender of the speaker, and whether she/he speaks English as native language. The expanded model showed only a slightly improved adjusted R-square value (68%). These results suggest that further research is required to identify and specify additional cognitive features in educational videos towards deeper understanding of the video cognitive value.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abstract-The literature provides some evidence for the effectiveness of online educational videos in students' learning. Also, general features of educational videos such as production style and video length were investigated to some extent. However, the actual cognitive features of educational videos available on the Internet have remained almost untreated, so far. The main goal of this study is to use learning analytics to investigate how far educational videos on YouTube support cognitive features -as formulated in the cognitive theory of multimedia learning-and how far these features support students' learning. We measure the Video Cognitive Value (V CV ) by viewers' rating, particularly using the number of Likes based on a survey that we conducted to understand the semantics of Likes and Dislikes of YouTube's educational videos. Then, a sample of 105 videos was collected and analyzed with respect to cognitive features. A regression analysis showed that only four out of ten investigated features are significant for V CV (pretraining, modality, spatial contiguity, and embodiment) and the regression model could only explain 63% of the data variance. Further tests were performed to include other factors such as the video production style, the video length, the talking speed, the gender of the speaker, and whether she/he speaks English as native language. The expanded model showed only a slightly improved adjusted R-square value (68%). These results suggest that further research is required to identify and specify additional cognitive features in educational videos towards deeper understanding of the video cognitive value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Information seeking is a strong motive for viewing online videos available on social networks including YouTube <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. For example, university students seem to visit YouTube regularly in a purposeful way to learn how to solve specific problems <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>. Youtube, however, is a social medium where every subscribed member can upload videos. This feature has led to an apparent redundancy in content: tens to hundreds of videos can be found that address the same topic. Thus, students and learners are increasingly facing the problem of finding the video that help them learn what they are intending to learn efficiently. The current filters that can be applied while searching a video and the offered sorting criteria seem to be less helpful in finding educational videos with the desired quality. It should be expected that the content redundancy problem and the associated problem of finding the "right" educational video will increase. This will affect three parties: the producers of educational videos, the consumers of the material, and the provider of the sharing platform, i.e., Google in this case. We believe that it is not too early -and hopefully not too late-to start thinking about -(i) the quality features of educational videos, -(ii) how to promote the production of educational videos with these features, and -(iii) how to facilitate the learners' access to these video.</p><p>This paper addresses the first point and tries to identify and specify the factors that contribute to the quality of an educational video. Identifying such factors is the first step towards an aware production or selection of videos that support students' learning. Thus, the goal of this research is in alignment with the general objectives of learning analytics and can be approached by its tools <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>. More specifically, Papamitsiou and Economides identified the organization and recommendation of educational resources as one of the significant, yet not sufficiently handled issues in the learning analytics and educational data mining research <ref type="bibr" target="#b6">[7]</ref>. Specifying the quality features of educational on-line videos is an urgent requirement to support video producers, platform providers, and instructors towards high-quality production, organization, and recommendation of educational video content.</p><p>Intuitively, the quality of an educational video should be defined by the level of learning or understanding it provides. One way to do this is to expose a group of learners to the video, assess their learning level, and compare this with the learning level of a control group that learned using alternative methods. The cognitive theory of multimedia learning frequently uses such an approach, whereas the control group watches a similar video with some features switched on or off according to the objective of the study <ref type="bibr" target="#b7">[8]</ref>. Although quantitative in terms of the number of students, this method can only focus on one or a small number of videos.</p><p>A wider understanding of the quality of educational videos on YouTube requires the analysis of a statistically significant number of -probably subject-related-videos. Exposing many students to a big number of videos to asses the quality of these videos is impracticable. An alternative method is to use the feedback of the wide community of students and learners who visited these videos in the past and left a sentiment note in terms of Like or Dislike. According to the author's knowledge, however, the semantics of Like and Dislike of YouTube's educational videos has never been investigated, so far. The first contribution of this paper, therefore, is to establish a relationship between the quality of an educational video and the number of Likes/Dislikes. For this purpose, we conducted a survey, to which 428 students responded. The results of this survey indicate a strong or a moderate relationship between the number of Likes or Dislikes and the cognitive value of an educational video, respectively. We use this finding to formulate the quality of an educational video as a function of the number of Likes. We call this function or metric the Video Cognitive Value (V CV ). In this respect, the number of Likes is used as an observed variable to measure a latent variable which is the cognitive value of the video.</p><p>The second contribution of this paper is to investigate the features of a video, which affect its V CV , i.e., which cause a higher or lower number of Likes. Originally, the objective was to verify whether V CV can be described solely by built-in</p><formula xml:id="formula_0">M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT 2</formula><p>cognitive features as proposed in the cognitive theory of multimedia learning <ref type="bibr" target="#b7">[8]</ref>. Among ten features that we investigated, however, only four were significant and the regression model was not especially strong with an adjusted R-square value of 63%. This motivated us to investigate -in two separate testsother features related to the video production style as well as to general features including the video length, the talking speed, the speaker gender, and whether she/he speaks English as native. We found that on-paper explanation, PowerPoint presentation, and khan-style recording, are the only production styles that affect V CV . In contrast to the native language feature and the talking speed, the gender of the speaker and the length of the video were found to be insignificant. In a final test we investigated the significant features identified in the previous three tests together. We found out that three cognitive features (modality, pretraining, and embodiment), the native-speaker feature, and the on-paper explanation style are the only features that affect V CV with an adjusted R-square value of 68%. These results suggests that cognitive features are highly important for the video cognitive value, however, more research is required to identify and specify other cognitive and non-cognitive features that affect V CV and improve the predictive models.</p><p>The paper is organized as follows. Section II reviews related work. Section III describes the survey design and results and how the survey data were used to define V CV . Section IV describes the research methodology. Section V summarizes the results of the statistical tests. Section VI discusses the paper findings. SectionVII describes the implications and limitations of this research and Section VIII concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>This study relates to the broad area of multimedia learning <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref> with focus on its cognitive aspects <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b10">[11]</ref> and selfregulated learning through social media <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, specifically using YouTube videos.</p><p>In contrast to other social media technologies such as Facebook and Twitter, Youtube seems to be an under-researched platform in general <ref type="bibr" target="#b0">[1]</ref>. Apart from the study by Hove and van der Meij <ref type="bibr" target="#b13">[14]</ref>, the quality of educational videos on YouTube obtained almost no attention in related work, so far. Hove and van der Meij analyzed what they call "physical characteristics" of YouTube's instructional videos and how these characteristics affect the popularity of a video. Video popularity was measured using the number of Likes (L), the number of Dislikes (D), the number of views (V ), and the number of shares (S). The authors formulated a metric called popularity rating (P R) as P R = (2L r + V + S)/4, whereas L r refers to what the authors called the like ratio. This ratio was defined as L r = (L/(L + 2D) * 100). The investigated physical characteristics include the resolution of the video, the frequency of static and dynamic pictures, on-screen texts, subtitles in different languages, background music, background noise, and the speaking rate in words per minute. The authors analyzed 75 videos providing general factual and conceptual knowledge that are not of academic nature, e.g., in form of lectures. They found out that the video's popularity increases with higher resolution of the video, higher frequency of static and dynamic pictures, higher frequency of on-screen texts, more subtitles in different language, more background music, less background noise, and higher speaking rates. Hove and van der Meij's work seems to be the first study that tries to connect features of YouTube educational videos to users' rating in terms of Likes and Dislikes. However, it is not clear if and how the proposed popularity rating P R relates to the cognitive value of a video. Also, the accumulation of the number of views, the number of shares, and the like-ratio in the P R formula does not seem obvious, especially because the upload time of the video is not considered. Furthermore, the authors assume that the actual number of dislikers is twice the number of viewers who hit the Dislike button. This assumption is not obvious, too.</p><p>Massive open on-line courses make extensive use of video content and belong to the educational settings that are widely addressed by learning analytics researchers <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b16">[17]</ref>. However, only few authors discussed quality features of MOOC videos <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>. Guo et al. investigated the factors that affect students' engagement while watching MOOC videos <ref type="bibr" target="#b17">[18]</ref>. They found out that informal talking-head videos and Khanstyle videos are more engaging than pre-recorded classroom lectures, PowePoint slides, or code screencasts. Also, they observed that students' engagement increases when the video is short and the instructor speaks fairly fast. As measures of engagement the authors used the watching time of a video and whether students attempted to answer post-video assessment problems. Related data were available to the authors on the edX MOOC platform. In contrast, YouTube does not support post-video assessment but watching time data are available through the YouTube API. However, we estimate that the watching time on YouTube is a weaker engagement indicator than it is on MOOC platforms: Guo et al. discussed that engagement factors in MOOC videos cannot be generalized to all online videos since edX students are "more likely to be self-motivated learners". While MOOC students seek specific videos on a MOOC platform, YouTube viewers are frequently on the search for the right one. So, videos on YouTube are more likely to be interrupted. But in both cases, the watching time is measured on the server side as playback time; not as the actual watching time. The difference between both is obvious: Students can playback a video without watching it for various reasons. More importantly, like Hove and van der Meij, Guo did not address quality factors on the cognitive level and no link between engagement and learning was established: A longer watching of a video and an attempt to answer postvideo questions do not reveal how far a student has learned.</p><p>Khan studied users' motives for consumption (viewing videos and reading comments) and participation (liking, disliking, commenting, sharing, and uploading) on YouTube <ref type="bibr" target="#b0">[1]</ref>. His study was based on the Uses and Gratifications framework, which premises that media consumers seek to fulfill specific needs and feel satisfied when the media meet these needs <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>. Khan differentiated between five types of motives including seeking information, giving information, self-status seeking, social interaction, and relaxing environment. He tried to establish regression models that use these motives</p><formula xml:id="formula_1">M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT 3</formula><p>as independent variables to predict users' consumption and participation, e.g., to predict the number of Likes and Dislikes. He found out, for example, that "a typical YouTube user who has the information-seeking motive is likely to engage in participatory acts of liking or disliking videos, and commenting on them" rather than sharing and uploading videos. Khan did not classify or analyze any YouTube videos and performed his study from the viewer's perspective using a pilot survey with 1143 students. Nevertheless, his work is significant for our study because it confirms that users seeking information on Youtube are likely to like or dislike a video depending on whether this video has satisfied their need or not. Haridakis and Hanson performed a similar study on user's motivation on YouTube <ref type="bibr" target="#b1">[2]</ref>. However, they limited their observation to the motives for viewing and sharing videos. Likes and Dislikes were not considered.</p><p>To our knowledge, an in-depth study of cognitive features of online videos is missing in the literature. In the best case, researchers analyzed technical aspects of video production <ref type="bibr" target="#b21">[22]</ref>- <ref type="bibr" target="#b23">[24]</ref> and some "surface" features that can either be identified quickly such as the production style or extracted from the video meta data such as video length and talking rate. We are not aware of any related work that investigates the cognitive value of online videos by assessing cognitive features, which proved effective in the cognitive theory of multimedia learning <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. TOWARDS DEFINING THE COGNITIVE VALUE OF AN</head><p>EDUCATIONAL VIDEO: A SURVEY The goal of the survey is to understand the semantics of the Like/Dislike rating of educational videos on YouTube and to find an appropriate definition for V CV . The idea behind the survey is intuitive: people watch educational videos for the sake of learning, they like videos, which help them learn, and dislike the ones, which do not help them learn. This idea, however, needs some evidence because there are other components in each educational video that may affect users' perception and sentiment. The personal and professional skills of the speaker, the technical quality of video and audio, and the video length are factors that may affect users' rating. The survey was designed to find out the contributions of these different factors on learners' ratings, both the Like and Dislike.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Survey Design and Results</head><p>An email with a link to the survey was sent to more than 4000 students in different universities in Germany, Italy, South Korea, UAE, UK, and USA. The email text is given here: "Dear students, When you don't understand what professors say, you may try it on YouTube. But there are so many videos out there on each small and big topic. Wouldn't you be happy to get to the best one right away? We are trying to specify good educational videos. This survey is a step towards this. I promise, it should not take more than 5 minutes. Thank you for your response in advance!".</p><p>A total of 428 students responded to the survey. The questions, the answer choices, and the frequency distributions of the students' responses are given in Fig. <ref type="figure" target="#fig_1">1</ref>. Note that the first four answer choices for Questions 1 and Question 2 were selected based on the possible factors discussed above. The fifth choice was added to identify whether students' rating of educational videos has a social factor that may motivate them to follow the trend of previous ratings. Question 3 was added to learn what understanding means for students. It is interesting to find out that most students watch YouTube educational videos essentially to learn how to solve a problem, probably to manage homework assignments. Students' responses to Question 1 and 2 allow the following statements: 1) Understanding or not-understanding the material are the most important reasons for students to like or dislike an educational video. This shows a strong/moderate relationship between the number of Likes/Dislikes and the cognitive value of the video as will be specified in the next subsection.</p><p>2) The video/audio quality represents a stronger reason when it comes to disliking an educational video. In particular, a video is disliked due to bad quality 3.5 times more frequently than a video that is liked due to good quality (14.0% vs. 4.1%). 3) Similarly to previous point, the professional and personal skills of the speaker represent a stronger motivation to dislike a video. In particular, a video is disliked due to an incompetent, unfriendly or not enthusiastic speaker almost twice more frequently than a video that is liked due to a competent, enthusiastic, and friendly speaker (19.6% vs. 10.1%). 4) Also, the video length is almost twice as important when it comes to disliking a video.</p><p>We also analyzed what students specified as other reasons for liking or disliking a video. A frequent answer was in the form "I never "like"/"dislike" YouTube videos". Apparently these students did not consider the word "would" in the asked questions. Another frequent reason relates to the title of the video. Many students dislike the video when they find out that the content is not strongly related to video title and that they did not get the information they are looking for. Some students spoke of "clickbait" and "fake videos" that aim at increasing the number of views artificially without providing any useful content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Video Cognitive Value</head><p>The main finding of the survey is that the cognitive value (level of understanding provided by the video) is the major factor for liking or disliking an educational video. Thus the number of Likes (N L ) and Dislikes (N D ) can be used to define V CV . However, the survey results show that not all students, who hit the Like/Dislike buttons, do so due to the cognition factor and that the latter has a different weight in the Like and Dislike rating. Therefore, N L and N D should be modulated to reflect these findings. of students who dislike an educational video due its cognitive value. According to the survey results, W L = 0.733 and W D = 0.476. The Video Cognitive Value can then be formulated as follows, whereas N V refers to the total number of views:</p><formula xml:id="formula_2">V CV = W L × N L -W D × N D N V<label>(1)</label></formula><p>While Equation 1 sounds reasonable, it does not consider another important factor: many or perhaps most YouTube viewers, who do not a like an educational video, do not hit the Dislike button, rather they just skip it. This may explain the observation that educational videos obtain more Likes than Dislikes in general. We refer to this as the Factor of Asymmetric Engagement of "likers" and "dislikers" (A). Table <ref type="table">I</ref> summarizes some statistical data of the 105 videos analyzed in this study and shows how A is determined. As can be seen from the table A &gt; 20. Note that A just describes the observed ratio of engagement, not the ratio of "actual likers" to "actual dislikers". Of course, there are "likers" who do not hit the Like button, too. This discussion shows that more research is required to estimate the numbers of "hidden likers and dislikers" which will be part of future work. For the sake of this study, we use the fact that N L &gt;&gt; N D in general and that W L &gt; W D to simplify Equation 1 into Equation <ref type="formula" target="#formula_3">2</ref>. In other words we only use the Likes to express the video cognitive value.</p><formula xml:id="formula_3">V CV = W L × N L N V<label>(2)</label></formula><p>V CV has small values due to the low engagement ratio of "likers". For a better presentation of regression results, therefore, we multiply the V CV from Equation 2 by 10 4 . </p><formula xml:id="formula_4">E L Engagement ratio of lik- ers E L = N L ΣN V 0.00389 E D Engagement ratio of dis- likers E D = N D ΣN V 0.00019 A Factor of Asymmetric Engagement A = E L E D = N L N D &gt;<label>20</label></formula><p>Thus, the final formula used to determine V CV in this study is given as:</p><formula xml:id="formula_5">V CV = W L × N L N V × 10 4<label>(3)</label></formula><p>IV. METHODOLOGY</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Video Selection and Pre-Annotation</head><p>105 videos were selected that address different topics of digital logic design as detailed in Table <ref type="table">II</ref>. The author has multiple-year experience in teaching this subject which is important for a reliable analysis of the selected videos. The videos were searched using key words and sorted according to rating. This, however, causes videos with zero Dislikes to appear first even when the number of Likes is very low. For example, a video with only one Like and zero Dislikes is listed before a video with 90 Likes and one Dislike. We only considered videos with at least 30 ratings, where both the Likes and Dislikes are represented. Refer to Table <ref type="table">I</ref> for some statistical data on the total number of views, Likes, and Dislikes. From this table it can determined that the average number of Likes and Dislikes is 310 or 15.3, respectively. Further analysis showed that the maximum number of Likes and Dislikes is 2,418 and 73, respectively. The maximum and the average number of views is 443,884 and 79,685, respectively.</p><p>To facilitate the analysis, each video was assigned an identity number. An Excel sheet was created that includes the video identity number, the video title, a link to the video, and the upload date. Other columns contained dynamic data including, the number of views N V , the number of Likes N L , the number of Dislikes N D , as well as the calculated video cognitive value V CV according to Equation <ref type="formula" target="#formula_5">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Video Annotation with Built-in Cognitive Features</head><p>Over the last 15 years, the cognitive theory of multimedia learning (CToML) has provided multiple principles for the design of instructional multimedia relying on or inspired by the cognitive load theory <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>. These principles were derived based on a psychological model of the cognitive process in human mind with three basic assumptions: (i)-Information flows into human mind through two separate channels (auditory and visual). (ii)-Both channels have limited capacity. (iii)-Learning is an active process of filtering, selecting, and organizing of new information, as well as integrating this information with prior knowledge. The design principles proposed by CToML aim either at reducing extraneous processing, managing essential processing, or fostering generative processing. In the following we list and explain the 10 principles that we analyzed in the sample videos. We refer to these principles as Cognitive Features in this paper. The abbreviation of each feature in brackets refers to the name of the corresponding independent variable as used in the regression analysis later:</p><p>1) Modality principle (MODAL). Words are presented as narration rather than as on-screen text. 2) Pretraining principle (PRETRAIN). The names and behaviors of new system components are explained before explaining the entire system. 3) Coherence principle (COHER). Extraneous material such as unrelated images or background music are excluded. 4) Signaling principle (SIGNAL). Aspects that are currently described verbally are highlighted or pointed to visually. 5) Spatial contiguity principle (SPATCONTIG). Printed words are placed near corresponding parts of graphics. 6) Redundancy principle (REDUNDANC). Words are presented as narration rather than narration and onscreen text. 7) Temporal contiguity principle (TEMPCONTIG). Related animation and narration are presented simultaneously rather than successively. 8) Personalization principle (PERSON). A conversational rather than a formal style is used. 9) Voice principle (VOICE). A spoken friendly human voice is used rather than a machine voice. 10) Embodiment principle (EMBOD). A diagram is drawn during explanation instead of explaining an alreadydrawn diagram Note that there are a few other principles in the CToML that we did not consider in this study for different reasons. For example, the segmenting principle is not listed because the YouTube technology supports it permanently by allowing the viewer to pause the video at any time point to focus on or review specific segments of the video.</p><p>In the analysis phase we went through the videos one by one and annotated each video with the cognitive features  it supports in a binary manner according to the following scheme: 1) When the video supports a cognitive feature entirely or essentially, the corresponding predictor variable was annotated as 1. 2) When the video does not support a cognitive feature entirely or essentially, the corresponding predictor variable was annotated as 0. At the start, the videos were played back several times to track the cognitive features one-by-one. After gaining some experience less playbacks were required. In general, the manual tracking of cognitive features is time-consuming but not especially difficult due to the binary nature of these features and the simplified scheme we followed to assess their presence or absence. Some features can be identified quickly in the first seconds of a video because they typically don't change. For example, the voice principle relates to whether a human voice is used or a machine voice. Also, the personalization principle relates to the style used by the speaker which is usually characteristic and does not change in the course of the video. The embodiment principle is also easy to identify early in a video because it essentially depends on the video production style. Most YouTube presenters who prefer the Khan-Academy style develop diagrams while explaining them. Speakers who use PowerPoint slides tend to use ready diagrams and images, as a rule. Other features are easy to identify in a short segment of the video but cannot be confirmed until an essential part of the video is analyzed. Coherence is an example for these features. Some videos include an "attractive" but unrelated image at the start. This alone should not be seen as violation of the coherence principle and the video should be analyzed longer to confirm or invalidate the lack of coherence. On the other hand, some features need a careful watching of the whole or a major part of the video. Pretraining is an example for these features. Here we should verify if the speaker explains the new terms or components that she/he uses, or at least refers to a previous video in which he or she provided this explanation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Video Annotation with Production Style</head><p>There are many production styles for educational videos but only six styles were identified in the selected videos, which seem to be the common styles in general. To understand the impact of the video production style on the video cognitive value, six binary variables were used to specify the production style of the selected videos. These variables are:</p><p>1) KHAN: this variable is 1 if the video is produced using Khan-Academy style; otherwise 0. 2) SLIDES: this variable is 1 if the video is produced using PowerPoint slides or the similar; otherwise 0. 3) HEAD: this variable is 1 if the video is produced using talking-head style; otherwise 0. 4) PAPER: this variable is 1 when the speaker used a paper or whiteboard to explain the topic; otherwise 0. 5) ANIM: this variable is 1 if the video is produced using animations; otherwise 0. 6) CLASS: this variable is 1 if the video is produced in classroom in the front of students; otherwise 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Video Annotation with Additional Features</head><p>To understand the impact of video length, talking speed, gender of the speaker, and whether she or he speaks English as a native language, four additional variables were added and specified for each of the collected videos. These variables are:</p><p>1) LENGTH: this variable gives the length of the video in minutes. 2) SPEED: this variable represents the talking speed measured in words per minute. The value of this variable was determined based on the number of words in the auto-generated transcript and the video length taking into account time segments without speech especially at the start and at the end of some videos. 3) Gender: this binary variable is 0 or 1 when the speaker is female or male, respectively. 4) NATIVE: this binary variable is 1 when -according to our perception-the spoken English sounds native; otherwise 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Regression Analysis</head><p>The last step is to establish a relationship between the video cognitive value V CV and supported cognitive features using multiple linear regression analysis. This analysis starts from an initial hypothesized model of the form V CV = β 0 + β 1 X 1 + β 2 X 2 + ... + β n X n , whereas X 1 , X 2 , ..., X n represents the cognitive variables, and β 0 , β 1 , β 2 , ..., β n are called the regression parameters. The analysis aims at estimating the regression parameters using the method of least squares as a standard approach. The model's "goodness of fit" is then determined using regression statistics as well as analysis of variance statistics. Regression analysis is not a single-run process but a procedure that is iterated to determine the significant variables out of all the potential variables. As mentioned before, additional analyses were performed to study the effect of the video production style and other features. Next section details the results of all tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RESULTS</head><p>First, a correlation analysis was performed to check if any collinearity between the ten cognitive features exists. The purpose is to simplify the succeeding regression analysis by omitting highly-correlated variables. Table <ref type="table">III</ref> shows the results of the correlation analysis for the sample videos analyzed in this study. The table shows that the two pairs (EMBOD and SIGNAL) and (PRETRAIN and TEMPCONTIG) show moderate correlation. We performed regression analysis with and without removing one variable from each pair but did not find any significant change in the regression model. Similar results were obtained from correlation analyses for the production style variables and the additional variables (LENGTH, SPEED, etc.).</p><p>Four regression tests were performed. In each test, a stepwise backward elimination approach was used, whereby independent variables were eliminated one by one until all independent variables showed significance at a confidence level of 5% <ref type="bibr" target="#b26">[27]</ref>. Table <ref type="table" target="#tab_3">IV</ref> summarizes the results of the four tests that are explained in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Test 1-V CV as Function of Cognitive Features</head><p>Test 1 generated a regression model that explains 63% of the data variance and has four cognitive features significant for the video cognitive value. These features relate to the pretraining, modality, spatial contiguity, and embodiment principles as defined in the cognitive theory of multimedia learning. The order of their significance can be derived from the values of the corresponding regression coefficients in Table <ref type="table" target="#tab_3">IV</ref> because all these features are binary. Thus, pretraining is the most significant feature followed by modality and spatial contiguity. Surprisingly, the embodiment feature has a negative regression coefficient. That means, videos in which the speaker draws diagrams manually has less cognitive values than videos in which the speaker explained already-drawn diagrams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Test 2-V CV as Function of Production Style Features</head><p>Test 2 generated a regression model that explains 56% of the data variance and has three features significant for the video cognitive value. These features relate to video production styles using paper-based explanation, slide presentation, and Khan-Academy format. Like in the previous test, all the related variables are binary which allows to use the values of the regression coefficients directly to compare their significance. Accordingly, videos with paper/white board explanations or using slides cause video cognitive values that are almost twice as high as videos using Khan-Academy style.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Test 3-V CV as Function of Additional Features</head><p>Test 2 showed that the length of the video and the gender of the speaker are not significant for the video cognitive value. 59% of the data variance can be explained by the talking speed and whether the presenter speaks English as native language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Test 4-V CV as Function of All Previous Features</head><p>In Test 4, the nine significant features from the previous tests were analyzed together. The generated regression model showed a better adjusted R-square value. The spatial contiguity, talking speed, PowerPoint format, and Khan-style format were all not significant in the final model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. DISCUSSION</head><p>The regression results of Test 1 show that only four out of ten cognitive features are significant for the video cognitive value. Explaining this finding is not easy but there are two aspects that can help. First, the frequency of some feature in the analyzed videos can indicate the significance or insignificance of this feature. Specifically, if a feature is always (or almost always) supported, or if it is never (or almost never) supported, then this can explain why such a feature is insignificant. Table <ref type="table">V</ref> shows the frequencies of the cognitive features in the analyzed 105 videos with the significant features marked bold. The coherence, the spatial contiguity, the redundancy, and the voice features have very high frequency. Three of these features were rejected in Test 1 and the fourth feature (spatial contiguity) was rejected in Test 4. Then, the cognitive theory of multimedia learning describes the presented cognitive principles as effective on average but not always. The extensive research in this areas showed that the proposed cognitive principles do not show positive and significant effect sizes in all tests <ref type="bibr" target="#b7">[8]</ref>.</p><p>While modality, pretraining, and spatial contiguity have positive regression coefficients, the embodiment feature affects the video cognitive value negatively. We regard this finding as surprising because we had expected that drawing a diagram while explaining it is more effective for learning than explaining an already-drawn diagram. In an attempt to understand this result let's consider some characteristics of the addressed subject, namely digital logic design. The main learning objective of DLD is to design logical circuits, i.e. to construct circuits following standard approaches rather than analyzing given circuits. During the design process different diagrams and representations are created such as truth tables, state diagrams, and k-maps. Towards the end, a logical circuit is drawn containing a set of logic elements (gates, multiplexers, flip-flops, etc.) and wires to connect these elements. However, it is important to note that drawing a digital circuit is not mysterious if the student has or has derived the correct logical function. Such a statement applies to many other cases. During the design of a finite state machine, for example, setting up a state table is not especially difficult if the student has set up a state diagram correctly and selected an appropriate state code. After obtaining the state table, minimizing nextstate and output functions is a routine step that is trivial at this stage of learning. Remember that our survey revealed  <ref type="figure" target="#fig_1">1</ref>. It should be assumed that students do not expect to find YouTube videos that present solutions for the same problems which the students are trying to solve. Rather than the details of the specific problem addressed in a YouTube video, students would appreciate a clear presentation of essential ideas and steps of the design process. When a student has understood why a state diagram should be mapped to a state table and how to do this mapping, the repeated entry (embodiment) of logical values representing the current and next state as well as the input and output signals for the addressed problem may rather appear lengthy and not effective. This discussion would suggest that the embodiment feature should be considered in the context of the treated subject of learning.</p><p>Test 2 shows that three production styles are significant. However, the Khan-style, which is highly appreciated in the literature <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b27">[28]</ref>, comes clearly behind using paper/white board explanations and PowerPoint presentations. In Test 4, the paper/white board format remained even the only significant production style. Again, a definite explanation of this result is difficult. Some -partly DLD-specific-points that speaks for paper format and PowerPoint over Khan-style are: 1) Writing on paper or on white board shows at least the hand of the speaker and enhances the social factor in the YouTube's distance learning environment. Especially writing on paper simulates the way people traditionally use to explain something to others. 2) It seems that most people write more comfortably, faster, and more clearly on paper than on a tablet computer. 3) We observed that many instructors who use papers to solve problems have prepared some templates, e.g., for truth tables or k-maps. This let them focus on problem solving rather than repeated creation of same diagrams. 4) Digital logic design often requires working with tables and diagrams with sometimes huge number of 1's and 0's. Having tables and diagrams with good layout as provided in PowerPoint presentation may support readability and learning. 5) Powerpoint presentations allow gradual but fast presentation of the steps of digital design process. "Getting to the point quickly" seems to be important for students seeking to learn how to solve a problem. Test 3 shows that the gender and the video length are not significant for VCV. The gender of the speaker in educational videos does not seem to have had any consideration in related work, so far. So, we believe that this is an interesting but probably expected result. In contrast to our finding, most related work emphasizes that shorter videos are more important for students' engagement <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b28">[29]</ref>- <ref type="bibr" target="#b30">[31]</ref>. However, Lagerstrom talked about what he called the "Myth of the Six Minute Rule" <ref type="bibr" target="#b31">[32]</ref>. He referred to Guo's recommendation in this regard and argued that the suggested time of six minutes was based on the median engagement time. So, it should not be interpreted as the maximum period in which students can maintain attention. The mean value, the standard deviation, the maximum value, and the minimum value of the length of the videos analyzed in this study are 15.2 minutes, 12.8 minutes, 55.9 minutes, and 1.9 minutes, respectively. Thus, although widely distributed, the video length did not affect the video cognitive value. From own experience in teaching digital logic design, students can maintain attention for long time when the design procedure is well understood.</p><p>Furthermore, Test 3 shows that VCV is higher when the instructor speaks English as native language and increases with the talking speed. One may suspect high correlation between the speed and the native speaker features. However, we found out that the Pearson correlation coefficient is 0.31. The native-speaker feature has not been considered in related work, so far. However, Guo et al. showed that a higher talking rate encourages higher students' engagement <ref type="bibr" target="#b17">[18]</ref>. In contrast to the native speaker feature, the talking speed proved insignificant in Test 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. RESEARCH IMPLICATIONS AND LIMITATIONS</head><p>The effectiveness of videos in learning is well-studied <ref type="bibr" target="#b32">[33]</ref>- <ref type="bibr" target="#b35">[36]</ref> and the acceptance of the YouTube technology is apparent <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b36">[37]</ref>. The fact that YouTube is a social platform, however, has led to content redundancy: tens to hundreds of videos that address or claim to address the same topic are uploaded to YouTube <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>. Both students and instructors need to spend more time to find what they seek. Suggestions, recommendations, and filters provided by the platform seem to be less helpful since the YouTube algorithm is kept secret to prevent video producers from "gaming the system" to increase profit.</p><p>The paper used a learning analytics approach first to find out whether and how far viewers' ratings on the YouTube platform can help identify videos that support learning. Then, multiple regression analyses were performed to highlight significant features of such videos. A first implication of this work is that students and instructors can use the number of Likes given to a video as a strong indicator of its cognitive quality. This is supported by the survey results. However, the number of Likes should be related to the number of views when considering the on-line life of a video: videos which are longer on-line are more likely to be assessed. This suggests that Google should consider replacing or extending current Like/Dislike reports by metrics similar to what proposed in this paper, i.e., Likes per View and Dislikes per View, as well as displaying the number of views per day instead of the absolute number of views.</p><p>Another implication of this research relates to what producers of educational videos should focus on to improve the cognitive and non-cognitive quality of their videos. Although the derived regression models do not explain all the variance in the data, several features were identified as significant, e.g., the native speaker feature, the talking rate, using paper/white board, as well as paying attention to significant cognitive principles, specifically pretraining, modality, and embodiment.</p><p>In this respect, the paper presents in the first instance a contribution to the production and recommendation of educational resources which is regarded as a fundamental objective in learning analytics and educational data mining research <ref type="bibr" target="#b6">[7]</ref>. Several aspects of this study fit into the framework proposed by Sheffel et al. <ref type="bibr" target="#b39">[40]</ref> towards identifying quality features in learning analytics research. For example, data ownership and data privacy are found to be two important quality indicators in this area. Analyzing public videos, avoiding concrete examples of analyzed videos, and using Like/Dislike reports, which do not reveal viewers' identities, are examples of the aware treatment of data in this study.</p><p>This research has some limitations. First, the analyzed videos relate to a specific subject, i.e., digital logic design. As shown in the previous section, some results could be discussed in the light of this specific subject. This raises the question whether the results can be applied to other subjects. Future studies should answer this question.</p><p>Another limitation relates to the educational level of addressed videos, specifically high-education level targeting university students and dealing with academic topics in all related conceptual and non-conceptual details. It should be expected that the behavior of this target audience differs from the behavior of other learner groups such as school students or general knowledge seekers on YouTube. But also the videos for the latter can differ in features and production style significantly. So, the generalizability of the study results to other classes of educational videos should be investigated in future research.</p><p>In this work, the number of Likes was used as an observed variable to measure the video cognitive value as a latent variable. This was based on the survey results. However, the students who responded to the survey are most likely not the same who have rated the analyzed YouTube's videos. This approach may sound strange in methodological research. However, there are two points that support it. First, the survey was essentially directed to students in ECE and Computer Science departments at seven different universities, where digital logic design is offered a as core course. Second, the high number of responses (428) supports the statistical significance of the survey results. Nevertheless, it would be desired to show the statistical validity of this approach in future work. VIII. CONCLUSION While educational online videos are an essential resource for students, common metrics for measuring the quality of such videos are missing. Researchers try to use viewers' ratings and participation to measure the quality of educational videos without looking into the cognitive value of such videos. This study used a different approach by linking viewers' ratings to several cognitive and non-cognitive features. The investigated cognitive features correspond to principles, which were established in the cognitive theory of multimedia learning over the last two decades.</p><p>The main finding of this study is that viewers' ratings in terms of the number of Likes does relate to some cognitive features but this relationship is not significantly stronger than the one between the viewers' ratings and the video production style or other surface features. Even the combined model that integrates the cognitive and non-cognitive features doesn't provide a significantly stronger explanation of viewers' ratings.</p><p>This suggests that more research is required to find out how to help students and instructors identify higher-quality videos before viewing them. To address this question we first need to look into quality features of educational videos beyond the cognitive theory of multimedia learning. In recent years, for example, some researchers in cognitive psychology started to study the effectiveness of instructional explanations and identified important factors for the generation and delivery of effective explanations. The study of instructional explanations can be of high relevance to the analytics of educational video, because explanation is typically the sole instructional method in such videos. After the identification and specification of new quality features, regression studies can be performed to link these features (in combination with the features proposed in this paper) to viewers' rating of educational videos.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Value of YouTube's Educational Videos: A Learning Analytics Approach</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Relative frequency distributions of students responses to the survey questions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV RESULTS</head><label>IV</label><figDesc>OF REGRESSION ANALYSIS: V CV AS A FUNCTION OF COGNITIVE FEATURES</figDesc><table><row><cell>Test</cell><cell>Predictor Variables</cell><cell>Adjusted</cell><cell>Standard</cell><cell>Significant Vari-</cell><cell>Regression</cell></row><row><cell></cell><cell></cell><cell>R-Square</cell><cell>Error of</cell><cell>ables</cell><cell>Coeffi-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Estimates</cell><cell></cell><cell>cients</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>PRETRAIN***</cell><cell>24.2</cell></row><row><cell>1</cell><cell>Cognitive features</cell><cell>63%</cell><cell>31.3</cell><cell>MODAL** SPATCONTIG*</cell><cell>23.5 19.4</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>EMBOD*****</cell><cell>-26.9</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>PAPER*****</cell><cell>50.7</cell></row><row><cell>2</cell><cell>Video production style</cell><cell>56%</cell><cell>34.2</cell><cell>SLIDES*****</cell><cell>48.3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>KHAN*****</cell><cell>28.9</cell></row><row><cell>3</cell><cell>Video length and speed, speaker gender and native language</cell><cell>59%</cell><cell>33.1</cell><cell>NATIVE* SPEED*****</cell><cell>14.3 0.209</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">PRETRAIN***** 26.5</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>MODAL**</cell><cell>21.3</cell></row><row><cell>4</cell><cell>All significant features from</cell><cell>68%</cell><cell>29.2</cell><cell>EMBOD***</cell><cell>-22.9</cell></row><row><cell></cell><cell>previous tests</cell><cell></cell><cell></cell><cell>PAPER**</cell><cell>20.1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>NATIVE**</cell><cell>17.5</cell></row><row><cell cols="6">*:p-value&lt;0.05, **:p-value&lt;0.01, ***:p-value&lt;0.001, ****:p-value&lt;0.0001, *****:p-value&lt;0.00001</cell></row><row><cell cols="3">that most students seek YouTube to learn how to solve a</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">problem, see responses to Question 3 in Figure</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>The gender of the speaker is not relevant for liking or disliking an educational video on YouTube.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>Videos by native speakers and with higher talking rates are more likely to be liked</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>The Dislike rating of YouTube's educational videos seems to be arbitrary and useless for analytics</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Social media engagement: What motivates user participation and consumption on youtube?</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="236" to="247" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Social interaction and co-viewing with youtube: Blending mass communication reception and social connection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Haridakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Broadcasting &amp; Electronic Media</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="317" to="335" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Students&apos; acceptance of youtube for procedural learning</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">X</forename><surname>Chew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Leow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B M</forename><surname>Rozlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Yong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Handbook of Research on Leveraging Consumer Psychology for Effective Customer Engagement</title>
		<imprint>
			<biblScope unit="page">57</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Youtube acceptance by university educators and students: a cross-cultural perspective</title>
		<author>
			<persName><forename type="first">I</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Innovations in education and teaching international</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="243" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Penetrating the fog: Analytics in learning and education</title>
		<author>
			<persName><forename type="first">G</forename><surname>Siemens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EDUCAUSE review</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">30</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning analytics: drivers, developments and challenges</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ferguson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Technology Enhanced Learning</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="304" to="317" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning analytics and educational data mining in practice: A systematic literature review of empirical evidence</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Papamitsiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Economides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Technology &amp; Society</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">49</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The Cambridge handbook of multimedia learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Mayer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Multimedia for learning: Methods and development</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Alessi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Trollip</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Allyn &amp; Bacon, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multimedia information and learning</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Najjar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of educational multimedia and hypermedia</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cognitive load during problem solving: Effects on learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sweller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="257" to="285" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Personal learning environments, social media, and self-regulated learning: A natural formula for connecting formal and informal learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dabbagh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kitsantas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Internet and higher education</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="8" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Personalised and self regulated learning in the web 2.0 era: International exemplars of innovative pedagogy using social software</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mcloughlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Australasian Journal of Educational Technology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Like it or not. what characterizes youtube&apos;s more popular instructional videos?</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Van Der Meij</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="48" to="62" />
		</imprint>
	</monogr>
	<note type="report_type">Technical communication</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Alas-ka: A learning analytics extension for better understanding the learning process in the khan academy platform</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Ruipérez-Valiente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Muñoz-Merino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Leony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Kloos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="139" to="148" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unsupervised modeling for understanding mooc discussion forums: a learning analytics approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ezen-Can</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Boyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kellogg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Booth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth international conference on learning analytics and knowledge</title>
		<meeting>the fifth international conference on learning analytics and knowledge</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="146" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The mooc and learning analytics innovation cycle (molac): a reflective summary of ongoing research and its challenges</title>
		<author>
			<persName><forename type="first">H</forename><surname>Drachsler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kalz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Assisted Learning</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="281" to="290" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">How video production affects student engagement: An empirical study of mooc videos</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the first ACM conference on Learning@ scale conference</title>
		<meeting>the first ACM conference on Learning@ scale conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="41" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">What drives a successful mooc? an empirical examination of criteria to assure design quality of moocs</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M F</forename><surname>Yousef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Chatti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wosnitza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Learning Technologies (ICALT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="44" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Mass communication theory: an introduction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Denis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Communication theory and the western bias</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mcquail</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Language Power and Social Process</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Data-driven interaction techniques for improving navigation of educational videos</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-W</forename><forename type="middle">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Z</forename><surname>Gajos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th annual ACM symposium on User interface software and technology</title>
		<meeting>the 27th annual ACM symposium on User interface software and technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="563" to="572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Lights, camera, but no action: Exploring affective audio-visual features of educational videos</title>
		<author>
			<persName><forename type="first">A</forename><surname>Doke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pedanekar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th ACM Technical Symposium on Computing Science Education</title>
		<meeting>the 47th ACM Technical Symposium on Computing Science Education</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="686" to="686" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A comparison of video formats for online teaching</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Malaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Koppel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Contemporary Issues in Education Research (Online)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Cognitive architecture and instructional design</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sweller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">G</forename><surname>Paas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational psychology review</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="251" to="296" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cognitive load theory, educational research, and instructional design: some food for thought</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">De</forename><surname>Jong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Instructional science</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="105" to="134" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Regression analysis by example</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Hadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Friendly handmade explanation videos</title>
		<author>
			<persName><forename type="first">J</forename><surname>Loviscach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMOOCs 2014</title>
		<meeting>EMOOCs 2014</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="240" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Investigating the effectiveness of video segmentation on decreasing learners&apos; cognitive load in mobile learning</title>
		<author>
			<persName><forename type="first">P.-Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shadiev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-T</forename><surname>Chu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Web-Based Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="122" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Promoting engagement in online courses: What strategies can we learn from three highly rated moocs</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Hew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Educational Technology</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="320" to="341" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Success factors of online learning videos</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diwanji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Korkut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dornberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 International Conference on Interactive Mobile Communication Technologies and Learning</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The myth of the six minute rule: Student engagement with online videos</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lagerstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Johanes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">U</forename><surname>Ponsukcharoen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">age</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The potential benefits of using videos in higher education</title>
		<author>
			<persName><forename type="first">I</forename><surname>Vieira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Soares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EDULEARN14 Conference</title>
		<meeting>EDULEARN14 Conference</meeting>
		<imprint>
			<publisher>IATED Publications</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="750" to="0756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Tutorial video use by senior undergraduate electrical engineering students</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Australasian Journal of Engineering Education</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="47" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Designing videos with pedagogical strategies: Online students&apos; perceptions of their effectiveness</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Joyner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Haynes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third</title>
		<meeting>the Third</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="141" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Teaching programming: Understanding lecture capture youtube analytics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mcgowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM Conference on Innovation and Technology in Computer Science Education</title>
		<meeting>the 2016 ACM Conference on Innovation and Technology in Computer Science Education</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="35" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">User acceptance of youtube for procedural learning: An extension of the technology acceptance model</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lehto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Education</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="193" to="208" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Equal but different: a contextual analysis of duplicated videos on youtube</title>
		<author>
			<persName><forename type="first">T</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Benevenuto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gonc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Brazilian Computer Society</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="201" to="214" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Video pollution on the web</title>
		<author>
			<persName><forename type="first">F</forename><surname>Benevenuto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gonc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">First Monday</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Quality indicators for learning analytics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Scheffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Drachsler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Specht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Technology &amp; Society</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">117</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
