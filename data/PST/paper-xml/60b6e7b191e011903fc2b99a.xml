<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">How Attentive are Graph Attention Networks?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shaked</forename><forename type="middle">Brody</forename><surname>Technion</surname></persName>
							<email>shakedbr@cs.technion.ac.il</email>
							<affiliation key="aff0">
								<address>
									<settlement>Technion</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Uri</forename><forename type="middle">Alon</forename><surname>Technion</surname></persName>
							<affiliation key="aff0">
								<address>
									<settlement>Technion</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eran</forename><surname>Yahav</surname></persName>
							<email>yahave@cs.technion.ac.il</email>
							<affiliation key="aff0">
								<address>
									<settlement>Technion</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">How Attentive are Graph Attention Networks?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph Attention Networks (GATs) are one of the most popular GNN architectures and are considered as the state-of-the-art architecture for representation learning with graphs. In GAT, every node attends to its neighbors given its own representation as the query. However, in this paper we show that GATs can only compute a restricted kind of attention where the ranking of attended nodes is unconditioned on the query node. We formally define this restricted kind of attention as static attention and distinguish it from a strictly more expressive dynamic attention. Because GATs use a static attention mechanism, there are simple graph problems that GAT cannot express: in a controlled problem, we show that static attention hinders GAT from even fitting the training data. To remove this limitation, we introduce a simple fix by modifying the order of operations and propose GATv2: a dynamic graph attention variant that is strictly more expressive than GAT. We perform an extensive evaluation and show that GATv2 outperforms GAT across 11 OGB and other benchmarks while we match their parametric costs. Our code is available at https://github.com/tech-srl/how_attentive_are_gats .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Graph neural networks (GNNs; <ref type="bibr" target="#b20">Gori et al., 2005;</ref><ref type="bibr" target="#b49">Scarselli et al., 2008)</ref> have seen increasing popularity over the past few years <ref type="bibr" target="#b12">(Duvenaud et al., 2015;</ref><ref type="bibr" target="#b2">Atwood and Towsley, 2016;</ref><ref type="bibr">Bronstein et al., 2017;</ref><ref type="bibr" target="#b41">Monti et al., 2017)</ref>. GNNs provide a general and efficient framework to learn from graph-structured data. Thus, GNNs are easily applicable in domains where the data can be represented as a set of nodes and the prediction depends on the relationships (edges) between the nodes. Such domains include molecules, social networks, product recommendation, computer programs and more.</p><p>A GNN can be viewed as a message-passing network <ref type="bibr" target="#b18">(Gilmer et al., 2017)</ref>, where each node iteratively updates its state by interacting with its neighbors. GNN variants <ref type="bibr" target="#b60">(Wu et al., 2019;</ref><ref type="bibr" target="#b62">Xu et al., 2019;</ref><ref type="bibr" target="#b37">Li et al., 2016)</ref> mostly differ in how each node aggregates the representations of its neighbors and combines them with its own representation. <ref type="bibr" target="#b53">Veličković et al. (2018)</ref> pioneered the use of attentionbased neighborhood aggregation, in one of the most popular GNN variants -Graph Attention Network (GAT). In GAT, every node updates its representation by attending to its neighbors using its own representation as the query. This generalizes the standard averaging or max-pooling of neighbors <ref type="bibr" target="#b31">(Kipf and Welling, 2017;</ref><ref type="bibr" target="#b21">Hamilton et al., 2017)</ref>, by allowing every node to compute a weighted average of its neighbors. The work of Veličković et al. also generalizes the Transformer's <ref type="bibr" target="#b52">(Vaswani et al., 2017)</ref> self-attention mechanism, from sequences to graphs <ref type="bibr" target="#b29">(Joshi, 2020)</ref>.</p><p>While GAT is one of the most popular GNN architectures <ref type="bibr" target="#b7">(Bronstein et al., 2021)</ref> and is considered as the state-of-the-art neural architecture for learning with graphs <ref type="bibr" target="#b55">(Wang et al., 2019a)</ref>, we show that GATs do not actually compute dynamic attention, a fact that severely hinders their expressiveness. Instead, we show that GAT only uses a restricted "static" form of attention: for every query node, attention is monotonic with respect to its neighbor key scores. That is, the ranking (the argsort) of attention coefficients is shared across all nodes in the graph, and is unconditioned on the query node. This limitation of the standard GAT is demonstrated in Figure <ref type="figure">1a</ref>. arXiv: <ref type="bibr">2105.14491v1 [cs.</ref>LG] 30 May 2021 k0 k1 k2 k3 k4 k5 k6 k7 k8 k9 q0 q1 q2 q3 q4 q5 q6 q7 q8 q9 0.08 0.10 0.10 0.07 0.08 0.08 0.11 0.09 0.20 0.08 0.05 0.10 0.10 0.04 0.04 0.04 0.13 0.06 0.38 0.04 0.05 0.10 0.10 0.04 0.05 0.05 0.13 0.06 0.38 0.05 0.08 0.10 0.10 0.07 0.08 0.08 0.10 0.09 0.24 0.08 0.08 0.09 0.09 0.07 0.07 0.07 0.10 0.08 0.27 0.07 0.09 0.11 0.11 0.08 0.09 0.08 0.11 0.10 0.16 0.09 0.04 0.10 0.11 0.03 0.04 0.04 0.14 0.06 0.40 0.04 0.07 0.09 0.09 0.06 0.07 0.07 0.10 0.08 0.29 0.07 0.04 0.11 0.11 0.02 0.04 0.03 0.14 0.07 0.41 0.04 0.07 0.09 0.09 0.06 0.07 0.07 0.11 0.08 0.30 0.07 k0 k1 k2 k3 k4 k5 k6 k7 k8 k9 (a) Attention in standard GAT <ref type="bibr" target="#b53">(Veličković et al. (2018)</ref>) k0 k1 k2 k3 k4 k5 k6 k7 k8 k9 q0 q1 q2 q3 q4 q5 q6 q7 q8 q9 0.95 0.00 0.00 0.01 0.01 0.00 0.00 0.02 0.01 0.00 0.01 0.92 0.01 0.01 0.01 0.00 0.01 0.01 0.00 0.02 0.00 0.00 0.95 0.00 0.00 0.01 0.02 0.01 0.00 0.00 0.01 0.01 0.00 0.94 0.00 0.01 0.00 0.00 0.02 0.01 0.00 0.00 0.00 0.00 0.96 0.00 0.00 0.01 0.01 0.00 0.00 0.01 0.01 0.01 0.01 0.89 0.01 0.01 0.04 0.02 0.00 0.01 0.04 0.00 0.01 0.01 0.86 0.02 0.01 0.03 0.04 0.02 0.01 0.01 0.03 0.01 0.00 0.87 0.00 0.01 0.01 0.00 0.01 0.01 0.01 0.01 0.01 0.00 0.94 0.00 0.01 0.02 0.01 0.01 0.01 0.01 0.01 0.00 0.00 0.93  <ref type="figure">1a</ref>) computes static attention: the ranking of attention coefficients is global for all nodes in the graph, and is unconditioned on the query node. For example, all queries (q0 to q9) attend mostly to the 8th key (k8). In contrast, GATv2 (Figure <ref type="figure">1b</ref>) can actually compute dynamic attention, where every query has a different ranking of attention coefficients of the keys.</p><p>Supposedly, the conceptual idea of attention as the form of interaction between GNN nodes is orthogonal to the specific choice of attention function. However, Veličković et al.'s original design of GAT has spread to a variety of domains <ref type="bibr" target="#b55">(Wang et al., 2019a;</ref><ref type="bibr" target="#b44">Qiu et al., 2018;</ref><ref type="bibr" target="#b63">Yang et al., 2020;</ref><ref type="bibr" target="#b57">Wang et al., 2019c;</ref><ref type="bibr" target="#b27">Huang and Carley, 2019;</ref><ref type="bibr" target="#b40">Ma et al., 2020;</ref><ref type="bibr" target="#b32">Kosaraju et al., 2019;</ref><ref type="bibr" target="#b42">Nathani et al., 2019;</ref><ref type="bibr" target="#b61">Wu et al., 2020;</ref><ref type="bibr" target="#b66">Zhang et al., 2020)</ref> and has become the default implementation of "graph attention network" in all popular GNN libraries such as PyTorch Geometric <ref type="bibr" target="#b15">(Fey and Lenssen, 2019)</ref>, DGL <ref type="bibr" target="#b56">(Wang et al., 2019b), and</ref><ref type="bibr">others (Dwivedi et al., 2020;</ref><ref type="bibr">Gordić, 2020;</ref><ref type="bibr" target="#b5">Brockschmidt, 2020)</ref>.</p><p>To overcome the limitation we identified in GAT, we introduce a simple fix to its attention function by modifying the order of internal operations. The result is GATv2 -a graph attention variant that has a universal approximator attention function, and is thus strictly more expressive than GAT. The effect of fixing the attention function in GATv2 is demonstrated in Figure <ref type="figure">1b</ref>.</p><p>In summary, our main contribution is identifying that one of the most popular GNN types, the graph attention network, cannot actually compute dynamic attention. We introduce formal definitions for analyzing the expressive power of graph attention mechanisms (Definitions 3.1 and 3.2), and derive our claims theoretically (Theorem 1) from the equations of <ref type="bibr" target="#b53">Veličković et al. (2018)</ref>. Empirically, we use a synthetic problem to show that standard GAT cannot express alignment problems that require dynamic attention (Section 4.1). We introduce a simple fix by switching the order of internal operations in the attention function of GAT, and propose GATv2, which does compute dynamic attention (Theorem 2). We further conduct a thorough empirical comparison of GAT and GATv2 and find that GATv2 outperforms GAT across 11 benchmarks of node-, link-, and graph-prediction. For example, GATv2 outperforms extensively tuned GNNs by over 1.4% in the difficult "UnseenProj Test" set of the VarMisuse task <ref type="bibr" target="#b0">(Allamanis et al., 2018)</ref>, without any hyperparameter tuning; and GATv2 improves over an extensively-tuned GAT by 11.5% in 13 prediction objectives in QM9. In node-prediction benchmarks from OGB <ref type="bibr" target="#b26">(Hu et al., 2020)</ref>, not only that GATv2 outperforms GAT with respect to accuracy -we find that GATv2 is also much more robust to noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>A directed graph G = (V, E) contains nodes V = {1, ..., n} and edges E ⊆ V × V, where (j, i) ∈ E denotes an edge from a node j to a node i. We assume that every node i ∈ V has an initial representation h (0) i ∈ R d0 . An undirected graph can be represented with bidirectional edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Graph Neural Networks</head><p>A graph neural network (GNN) layer updates every node representation by aggregating its neighbors' representations. A layer's input is a set of node representations {h i ∈ R d | i ∈ V} and the set of edges E. A layer outputs a new set of node representations {h i ∈ R d | i ∈ V}, where the same parametric function is applied to every node given its neighbors N i = {j ∈ V | (j, i) ∈ E}:</p><formula xml:id="formula_0">h i = f θ (h i , AGGREGATE ({h j | j ∈ N i }))<label>(1)</label></formula><p>The design of f and AGGREGATE is what mostly distinguishes one type of GNN from the other. For example, a common variant of GraphSAGE <ref type="bibr" target="#b21">(Hamilton et al., 2017)</ref> performs an element-wise mean as AGGREGATE, followed by concatenation with h i , a linear layer and a ReLU as f .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Graph Attention Networks</head><p>GraphSAGE and many other popular GNN architectures <ref type="bibr" target="#b62">(Xu et al., 2019;</ref><ref type="bibr" target="#b12">Duvenaud et al., 2015)</ref> weigh all neighbors j ∈ N i with equal importance (e.g., mean or max-pooling as AGGREGATE). To address this limitation, GAT <ref type="bibr" target="#b53">(Veličković et al., 2018)</ref> instantiates Equation ( <ref type="formula" target="#formula_0">1</ref>) by computing a learned weighted average of the representations of N i . A scoring function e : R d × R d → R computes a score for every edge (j, i), which indicates the importance of the features of the neighbor j to the node i:</p><formula xml:id="formula_1">e (h i , h j ) = LeakyReLU a • [W h i W h j ]<label>(2)</label></formula><p>where a ∈ R 2d , W ∈ R d ×d are learned, and denotes vector concatenation. These attention scores are normalized across all neighbors j ∈ N i using softmax, and the attention function is defined as:</p><formula xml:id="formula_2">α ij = softmax j (e (h i , h j )) = exp (e (h i , h j )) j ∈Ni exp (e (h i , h j ))<label>(3)</label></formula><p>Then, GAT computes a weighted average of the transformed features of the neighbor nodes (followed by a nonlinearity σ) as the new representation of i, using the normalized attention coefficients:</p><formula xml:id="formula_3">h i = σ j∈Ni α ij • W h j<label>(4)</label></formula><p>From now on, we will refer to Equations (2) to (4) as the definition of GAT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Expressive Power of Graph Attention Mechanisms</head><p>In this section, we explain why attention is limited when it is not dynamic (Section 3.1). We then show that GAT is severely constrained, because it can only compute static attention (Section 3.2). Next, we show how GAT can be fixed (Section 3.3), by simply modifying the order of operations.</p><p>We refer to a neural architecture (e.g., the scoring or the attention function of GAT) as a family of functions, parameterized by the learned parameters. An element in the family is a concrete function with specific trained weights. In the following, we use [n] to denote the set [n] = {1, 2, ..., n} ⊂ N.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Importance of Dynamic Weighting</head><p>Attention is a mechanism for computing a distribution over a set of input key vectors, given an additional query vector. If the attention function always weighs one key at least as much as any other key, unconditioned on the query, we say that this attention function is static: Definition 3.1 (Static attention). A (possibly infinite) family of scoring functions F ⊆ R d × R d → R computes static scoring for a given set of key vectors K = {k 1 , ..., k n } ⊂ R d and query vectors Q = {q 1 , ..., q m } ⊂ R d , if for every f ∈ F there exists a "highest scoring" key j f ∈ [n] such that for every query i ∈ [m] and key j ∈ [n] it holds that f q i , k j f ≥ f (q i , k j ). We say that a family of attention functions computes static attention given K and Q, if its scoring function computes static scoring, possibly followed by monotonic normalization such as softmax.</p><p>Static attention is very limited because every function f ∈ F has a key that is always selected, regardless of the query. Such functions cannot model situations where different keys have different relevance to different queries. Static attention is demonstrated in Figure <ref type="figure">1a</ref>.</p><p>The general and powerful form of attention is dynamic attention: Definition 3.2 (Dynamic attention). A (possibly infinite) family of scoring functions F ⊆ R d × R d → R computes dynamic scoring for a set of key vectors K = {k 1 , ..., k n } ⊂ R d and a set of query vectors Q = {q 1 , ..., q m } ⊂ R d , if for any mapping ϕ: [m] → [n] there exists f ∈ F such that for any query i ∈ [m] and any key j =ϕ(i) ∈ [n]: f q i , k ϕ(i) &gt; f (q i , k j ). We say that a family of attention functions computes dynamic attention for K and Q, if its scoring function computes dynamic scoring, possibly followed by monotonic normalization such as softmax.</p><p>That is, dynamic attention can select every key ϕ (i) using the query i, by making f q i , k ϕ(i) the maximal in {f (q i , k j ) | j ∈ [n]}. Note that Dynamic and static attention are exclusive properties, but they are not complementary. Further, every dynamic attention family has strict subsets of static attention families with respect to the same K and Q. Dynamic attention is demonstrated in Figure <ref type="figure">1b</ref>.</p><p>Attending by decaying Another way to think about attention is the ability to "focus" on the most relevant inputs, given a query. Focusing is only possible by decaying other inputs, i.e., giving these decayed inputs lower scores than others. If one key is always given an equal or greater attention score than other keys (as in static attention), no query can decay or ignore this key.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Limited Expressivity of GAT</head><p>Although the scoring function e can be defined in various ways, the original definition of <ref type="bibr" target="#b53">Veličković et al. (2018)</ref> (Equation ( <ref type="formula" target="#formula_1">2</ref>)) has become the de facto practice: it has spread to a variety of domains <ref type="bibr" target="#b66">(Zhang et al., 2020;</ref><ref type="bibr" target="#b63">Yang et al., 2020;</ref><ref type="bibr" target="#b57">Wang et al., 2019c;</ref><ref type="bibr" target="#b27">Huang and Carley, 2019;</ref><ref type="bibr" target="#b40">Ma et al., 2020;</ref><ref type="bibr" target="#b32">Kosaraju et al., 2019;</ref><ref type="bibr" target="#b42">Nathani et al., 2019;</ref><ref type="bibr" target="#b61">Wu et al., 2020)</ref>, and is now the standard implementation of "graph attention network" in all popular GNN libraries <ref type="bibr" target="#b15">(Fey and Lenssen, 2019;</ref><ref type="bibr" target="#b56">Wang et al., 2019b;</ref><ref type="bibr">Dwivedi et al., 2020;</ref><ref type="bibr">Gordić, 2020;</ref><ref type="bibr" target="#b5">Brockschmidt, 2020)</ref>.</p><p>The motivation of GAT is to compute a representation for every node as a weighted average of its neighbors. Statedly, GAT is inspired by the attention mechanism of <ref type="bibr" target="#b3">Bahdanau et al. (2014)</ref> and the self-attention mechanism of the Transformer <ref type="bibr" target="#b52">(Vaswani et al., 2017)</ref>. Nonetheless: Theorem 1. A GAT layer computes only static attention, for any set of node representations K = Q = {h 1 , ..., h n }. In particular, for n &gt; 1, a GAT layer does not compute dynamic attention.</p><p>Proof. Let G = (V, E) be a graph modeled by a GAT layer with some a and W values (Equations ( <ref type="formula" target="#formula_1">2</ref>) and ( <ref type="formula" target="#formula_2">3</ref>)), and having node representations {h 1 , ..., h n }. The learned parameter a can be written as a concatenation a = [a 1 a 2 ] ∈ R 2d such that a 1 , a 2 ∈ R d , and Equation ( <ref type="formula" target="#formula_1">2</ref>) can be re-written as:</p><formula xml:id="formula_4">e (h i , h j ) = LeakyReLU a 1 W h i + a 2 W h j (5)</formula><p>Since V is finite, there exists a node j max ∈ V such that a 2 W h jmax is maximal among all nodes j ∈ V. Due to the monotonicity of LeakyReLU and softmax, for every query node i ∈ V, the node j max also leads to the maximal value of its attention distribution {α ij | j ∈ V}. Thus, α computes only static attention. This also implies that α does not compute dynamic attention, because Definition 3.2 holds only for constant mappings ϕ that map all inputs to the same output.</p><p>The consequence of Theorem 1 is that for any set of nodes V and a trained GAT layer, the attention function α defines a constant ranking (argsort) of the nodes, unconditioned on the query nodes i. That is, we can denote s j = a 2 W h j and get that for any choice of h i , α is monotonic with respect to the per-node scores {s j | j ∈ V}. This global ranking induces the local ranking of every neighborhood N i . The only effect of h i is in the "sharpness" of the produced attention distribution. This is demonstrated in Figure <ref type="figure">1a</ref> (bottom), where different curves denote different queries (h i ).</p><p>Generalization to multi-head attention <ref type="bibr" target="#b53">Veličković et al. (2018)</ref> found it beneficial to employ H separate attention heads and concatenate their outputs, similarly to Transformers. In this case, Theorem 1 holds for each head separately: every head h has a (possibly different) node that maximizes {s (h) j</p><p>| j ∈ V} , and the output is the concatenation of H static attention heads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Building Dynamic Graph Attention Networks</head><p>To create dynamic graph attention networks, we modify the order of internal operations in GAT and introduce GATv2 -a simple fix of GAT that is strictly more expressive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GATv2</head><p>The main problem in the standard GAT scoring function (Equation ( <ref type="formula" target="#formula_1">2</ref>)) is that the learned layers W and a are applied consecutively, and thus can be collapsed into a single linear layer. To fix this limitation, we simply apply the a layer after the nonlinearity and the W layer after the concatenation,<ref type="foot" target="#foot_0">1</ref> effectively applying an MLP to compute the score for each query-key pair:</p><p>GAT <ref type="bibr" target="#b53">(Veličković et al., 2018)</ref>:</p><formula xml:id="formula_5">e (h i , h j ) =LeakyReLU a • [W h i W h j ] (6) GATv2 (our fixed version): e (h i , h j ) =a LeakyReLU (W • [h i h j ])<label>(7)</label></formula><p>The simple modification makes a significant difference in the expressiveness of the attention function: Theorem 2. A GATv2 layer computes dynamic attention for any set of node representations</p><formula xml:id="formula_6">K = Q = {h 1 , ..., h n } .</formula><p>We prove Theorem 2 in Appendix A. The main idea is that we can define an appropriate function that GATv2 will be a universal approximator <ref type="bibr" target="#b9">(Cybenko, 1989;</ref><ref type="bibr" target="#b24">Hornik, 1991)</ref> of. In contrast, GAT (Equation ( <ref type="formula">52</ref>)) cannot approximate any such desired function (Theorem 1).</p><p>DPGAT We also consider DPGAT which follows <ref type="bibr" target="#b39">Luong et al. (2015)</ref> and the scaled dot-product attention of <ref type="bibr" target="#b52">Vaswani et al. (2017)</ref>, and is theoretically weaker than GATv2. DPGAT is defined as:</p><p>DPGAT <ref type="bibr" target="#b52">(Vaswani et al., 2017)</ref>:</p><formula xml:id="formula_7">e (h i , h j ) = h i Q • h j K / d k (8)</formula><p>Variants of DPGAT were used in prior work <ref type="bibr" target="#b17">(Gao and Ji, 2019;</ref><ref type="bibr">Dwivedi and Bresson, 2020;</ref><ref type="bibr" target="#b46">Rong et al., 2020a;</ref><ref type="bibr" target="#b54">Veličković et al., 2020;</ref><ref type="bibr" target="#b30">Kim and Oh, 2021)</ref>, and we consider it here for the conceptual and empirical comparison with GAT. DPGAT provably performs dynamic attention for any set of node representations that are linearly independent (see Theorem 3 and its proof in Appendix B).</p><p>Otherwise, there are examples of node representations that are linearly dependent and mappings ϕ, for which dynamic attention does not hold (Appendix B.1). This constraint is not harmful when violated in practice, because every node has only a small set of neighbors, rather than all possible nodes in the graph; further, some nodes possibly never need to be "selected" in practice.</p><p>Complexity GATv2 and DPGAT have the same time-complexity as GAT's declared complexity: O (|V|dd + |E|d ). However, by merging its linear layers, GAT can be computed faster than stated by <ref type="bibr" target="#b53">Veličković et al. (2018)</ref>. For a detailed time-and parametric-complexity analysis, see Appendix C.</p><p>Static vs. dynamic graph problems Many prior GAT-based models had focused on datasets that apparently did not require dynamic attention, where the data had an underlying static ranking of "globally important" nodes. With the growing popularity of GNNs, their adoption expanded to domains that required more complex interactions, and thus required dynamic attention that depends on the representation of the query node as well. In this paper, we revisit the traditional assumptions and show that many modern graph benchmarks and datasets require dynamic attention (Section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>First, we demonstrate the weakness of GAT using a simple synthetic problem that GAT cannot even fit, but is easily solvable by GATv2 (Section 4.1). Second, we show that GATv2 and DPGAT are much more robust to edge noise, because their dynamic attention mechanisms allow them to decay noisy (false) edges, while GAT's performance severely decreases as noise increases (Section 4.2). Finally, we compare GAT, GATv2, and DPGAT across 11 benchmarks overall. (Sections 4.3 to 4.6). We find that GAT is always inferior to GNNs that perform dynamic attention such as GATv2.</p><p>Setup All models use skip connections <ref type="bibr" target="#b23">(He et al., 2016)</ref> as in <ref type="bibr" target="#b53">Veličković et al. (2018)</ref>. When previous results exist, we take hyperparameters that were tuned for GAT and use them in GATv2 and DPGAT, without any additional tuning. Self-supervision <ref type="bibr" target="#b30">(Kim and Oh, 2021;</ref><ref type="bibr" target="#b46">Rong et al., 2020a;</ref><ref type="bibr" target="#b22">Hassani and Khasahmadi, 2020)</ref>, graph regularization methods <ref type="bibr" target="#b55">(Wang et al., 2019a;</ref><ref type="bibr" target="#b67">Zhao and Akoglu, 2020;</ref><ref type="bibr" target="#b47">Rong et al., 2020b)</ref>, and other tricks <ref type="bibr" target="#b58">(Wang, 2021;</ref><ref type="bibr" target="#b28">Huang et al., 2021)</ref> are orthogonal to the contribution of the GNN layer itself, and might further improve all GNNs. In all experiments of GATv2 and DPGAT, we constrain the learned matrix by setting W = [W W ] in GATv2 and Q = K in DPGAT, to rule out the increased number of parameters over GAT as the source of empirical difference (see</p><formula xml:id="formula_8">A,4 B,3 C,2 D,1</formula><p>A,? B,? C,? D,?</p><p>Figure <ref type="figure">2</ref>: The DICTIONARY-LOOKUP problem of size k=4: every node in the bottom row has an alphabetic attribute ({A, B, C, ...}) and a numeric value ({1, 2, 3, ...}); every node in the upper row has only an attribute; the goal is to predict the value for each node in the upper row, using its attribute. Appendix C.2). Training details and data statistics are provided in the Appendix E. An implementation of GATv2 is available at https://github.com/tech-srl/how_attentive_are_gats , the rest of the code will be made publicly available.</p><p>Our main goal is to compare dynamic and static graph attention mechanisms. However, for reference, we also include non-attentive baselines such as GCN (Kipf and Welling, 2017), GIN <ref type="bibr" target="#b62">(Xu et al., 2019)</ref> and GraphSAGE <ref type="bibr" target="#b21">(Hamilton et al., 2017)</ref>. These non-attentive GNNs can be thought of as a special case of attention, where every node gives all its neighbors the same attention score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Synthetic Benchmark: DICTIONARYLOOKUP</head><p>The DICTIONARYLOOKUP problem is a contrived problem that we designed to test the ability of a GNN architecture to perform dynamic attention. Here, we demonstrate that GAT cannot learn this simple problem. The graph in Figure <ref type="figure">2</ref> is a bipartite graph of 2k nodes. Each "key node" in the bottom row has an attribute and a value. Each "query node" in the upper row has only an attribute.</p><p>The goal is to predict the value of every query node (upper row), according to its attribute. Each graph in the dataset has a different mapping from attributes to values. We created a separate dataset for each k = {1, 2, 3, ...}, for which we trained a different model, and measured per-node accuracy.</p><p>This problem tests the layer itself because it can be solved using a single GNN layer, without suffering from multi-layer side-effects such as over-smoothing <ref type="bibr" target="#b36">(Li et al., 2018;</ref><ref type="bibr" target="#b61">Wu et al., 2020)</ref>, over-squashing <ref type="bibr" target="#b1">(Alon and Yahav, 2021)</ref>, or vanishing gradients <ref type="bibr" target="#b35">(Li et al., 2019)</ref>. Our PyTorch Geometric code will be made publicly available, to serve as a testbed for future graph attention mechanisms.</p><p>Results Figure <ref type="figure" target="#fig_1">3</ref> shows the following surprising results: GAT with a single head (GAT 1h ) failed to fit the training set for any value of k, no matter for how many iterations it was trained, and after trying various training methods (see Appendix D). Thus, it expectedly fails to generalize (resulting in low test accuracy). Using 8 heads, GAT 8h successfully fits the training set, but generalizes poorly on the test set. In contrast, GATv2 and DPGAT easily achieve 100% training and 100% test accuracies, even for k=100 (not shown) and using a single head, thanks to their ability to perform dynamic attention. These results clearly show the limitations of GAT, which are easily solved by GATv2. An additional comparison to GIN, which could not fit this dataset, is provided in Appendix F.1.</p><p>The role of multi-head attention <ref type="bibr" target="#b53">Veličković et al. (2018)</ref> found the role of multi-head attention to be stabilizing the learning process. Nevertheless, Figure <ref type="figure" target="#fig_1">3</ref> shows that increasing the number of heads has an even more important role -strictly increasing the expressiveness. This is evident by the increased training accuracy of GAT 8h over GAT 1h , which could not even fit the training set.</p><p>Figure <ref type="figure">1a</ref> (top) shows a heatmap of GAT's learned attention scores. As shown, all query nodes q0 to q9 (the nodes in the upper row of Figure <ref type="figure">2</ref>) attend mostly to the eighth key (k8), and have the same ranking of attention coefficients (Figure <ref type="figure">1a</ref> (bottom)). In contrast, Figure <ref type="figure">1b</ref> shows how GATv2 can select the relevant key node for every query node, because it can compute dynamic attention. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Robustness to Noise</head><p>We examine the robustness of dynamic and static attention to noise. In particular, we focus on structural noise: given an input graph G = (V, E) and a noise ratio 0 ≤ p ≤ 1, we randomly sample |E|×p non-existing edges E from V×V\E. We then train the GNN on the noisy graph G =(V, E ∪E ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Figure <ref type="figure" target="#fig_2">4</ref> shows the accuracy on two node-prediction datasets from the Open Graph Benchmark (OGB; <ref type="bibr" target="#b26">Hu et al., 2020)</ref> as a function of the noise ratio p. As p increases, all models show a natural decline in test accuracy in both datasets. Yet, thanks to their ability to compute dynamic attention, GATv2 and DPGAT show a milder degradation in accuracy compared to GAT, which shows a steeper descent. We hypothesize that the ability to perform dynamic attention helps the models distinguishing between given data edges (E) and noise edges (E ); in contrast, GAT cannot distinguish between edges, because it scores the source and target nodes separately. These results demonstrate the robustness of dynamic attention over static attention in such noisy data scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Programs: VARMISUSE</head><p>Setup VARMISUSE <ref type="bibr" target="#b0">(Allamanis et al., 2018</ref>) is an inductive node-pointing problem that depends on 11 types of syntactic and semantic interactions between elements in computer programs. We used the framework of <ref type="bibr" target="#b5">Brockschmidt (2020)</ref> GATv2 is more accurate than all GNNs in both test sets, using GAT's hyperparameters. †previously reported by <ref type="bibr" target="#b5">Brockschmidt (2020)</ref>.</p><p>by searching over 30 configurations for every GNN type. We took their best GAT hyperparameters and used them to train GATv2 and DPGAT, without any further tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>As shown in Table <ref type="table">1</ref>, GATv2 and DP-GAT are more accurate than GAT and other GNNs in the SeenProj test sets; GATv2 achieves an even higher improvement in the UnseenProj test set. Overall, these results demonstrate the power of GATv2 in modeling complex relational problems, especially since it outperforms extensively tuned models, without any tuning by us.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Node-Prediction</head><p>We further compare GATv2, GAT, and other GNNs on four node-prediction datasets from OGB.  Table <ref type="table">3</ref>: Average Hits@50 (Table <ref type="table">3a</ref>) and mean reciprocal rank (MRR) (Table <ref type="table">3b</ref>) in link-prediction benchmarks from OGB (10 runs±std). † -previously reported by <ref type="bibr" target="#b26">Hu et al. (2020)</ref>.</p><p>Results Results are shown in Table <ref type="table" target="#tab_3">2</ref>. In all settings and all datasets, GATv2 is more accurate than GAT and the non-attentive GNNs, and GATv2 is more accurate than DPGAT in all settings except one. Interestingly, in the datasets of Table <ref type="table" target="#tab_3">2a</ref>, there is no significant difference between using 1 or 8 heads; however in Table <ref type="table" target="#tab_3">2b</ref> (ogbn-proteins), increasing the number of heads results in a major improvement for GAT, while GATv2 already gets most of the benefit using a single attention head. These results demonstrate the superiority of GATv2 over GAT, thanks to GATv2's dynamic attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Link-Prediction</head><p>We compare GATv2, GAT, and other GNNs in link-prediction datasets from OGB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Results are shown in Table <ref type="table">3</ref>. In ogbl-collab (Table <ref type="table">3a</ref>), DPGAT 8h achieves higher accuracy than all models. This is consistent with <ref type="bibr" target="#b30">Kim and Oh (2021)</ref>, who found that DPGAT predicts edge presence better, but in much smaller datasets (Cora, CiteSeer, PubMed, and PPI). In ogbl-citation2 (Table <ref type="table">3b</ref>), GATv2 achieves a higher MRR than GAT and DPGAT with the same number of heads, but the non-attentive GraphSAGE performs better than all attentive GNNs. We hypothesize that attention is not needed in this dataset. In all datasets, the lowest score is achieved by a standard GAT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Graph-Prediction: QM9</head><p>Setup In the QM9 dataset <ref type="bibr" target="#b45">(Ramakrishnan et al., 2014;</ref><ref type="bibr" target="#b18">Gilmer et al., 2017)</ref> contains ~130,000 graphs with ~18 nodes. Each graph is a molecule where nodes are atoms, and the goal is to regress each graph to 13 real-valued quantum chemical properties. We used the implementation of <ref type="bibr" target="#b5">Brockschmidt (2020)</ref> who performed an extensive hyperparameter search over 500 configurations; we took their best-found configurations and modified the code of GAT to implement GATv2 and DPGAT. 2.65 4.28 1.41 1.47 2.29 16.37 14.03 6.07 6.28 6.60 5.97 3.57 1.59 -11.5%</p><p>Table <ref type="table">4</ref>: Average error rates (lower is better), 5 runs for each property, on the QM9 dataset. † was previously tuned and reported by <ref type="bibr" target="#b5">Brockschmidt (2020)</ref>. Standard deviation is reported in Appendix F.</p><p>Results Results are shown in Table <ref type="table">4</ref>. The main results are that GATv2 achieves a lower (better) error rate than GAT, with both 8 and a single attention head. Overall, GATv2 achieves the lowest average error rate. GAT 1h achieves the overall highest error rate, and GAT 8h achieves the highest error rate among the attentive GNNs that use 8 heads and among the non-attentive GNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Attention in GNNs Modeling pairwise interactions between elements in graph-structured data goes back to interaction networks <ref type="bibr" target="#b4">(Battaglia et al., 2016;</ref><ref type="bibr" target="#b25">Hoshen, 2017)</ref> and relational networks <ref type="bibr" target="#b48">(Santoro et al., 2017)</ref>. The GAT formulation of <ref type="bibr" target="#b53">Veličković et al. (2018)</ref> rose as the most popular framework for attentional GNNs, thanks to its simplicity, generality, and applicability beyond reinforcement learning <ref type="bibr" target="#b10">(Denil et al., 2017;</ref><ref type="bibr" target="#b11">Duan et al., 2017)</ref>. Nevertheless, in this work, we show that the popular and widespread definition of GAT is severely constrained to static attention only.</p><p>Transformers and GNNs Many works employed GNNs with Transformer-style attention (dotproduct) <ref type="bibr" target="#b65">(Zhang et al., 2018;</ref><ref type="bibr" target="#b51">Thekumparampil et al., 2018;</ref><ref type="bibr" target="#b17">Gao and Ji, 2019;</ref><ref type="bibr" target="#b38">Lukovnikov and Fischer, 2021;</ref><ref type="bibr" target="#b50">Shi et al., 2020;</ref><ref type="bibr">Dwivedi and Bresson, 2020;</ref><ref type="bibr" target="#b8">Busbridge et al., 2019;</ref><ref type="bibr" target="#b46">Rong et al., 2020a;</ref><ref type="bibr" target="#b54">Veličković et al., 2020)</ref>, and Lee et al. ( <ref type="formula">2018</ref>) conducted an extensive survey of attention types in GNNs. However, none of these works identified the monotonicity of GAT's attention mechanism, the theoretical differences between attention types, nor empirically compared their performance. <ref type="bibr" target="#b30">Kim and Oh (2021)</ref> compared the standard GAT with dot-product attention empirically, but in a specific self-supervised scenario, without observing the theoretical difference in their expressiveness.</p><p>The static attention of GAT Qiu et al. ( <ref type="formula">2018</ref>) recognized the order-preserving property of GAT, but did not identify the severe theoretical constraint that this property implies: the inability to perform dynamic attention (Theorem 1). Furthermore, they presented GAT's monotonicity as a desired trait (!) To the best of our knowledge, our work is the first work to recognize the inability of GAT to perform dynamic attention and its practical harmful consequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we identify that the popular and widespread Graph Attention Networks do not compute dynamic attention. Instead, the attention mechanism in the standard definition and implementations of GAT is only static, and for any query, its scoring is monotonic with respect to per-node scores. As a result, GAT cannot even express simple alignment problems. To address this limitation, we introduce a simple fix and propose GATv2: by modifying the order of operations in GAT, GATv2 achieves a universal approximator attention function and is thus strictly more powerful than GAT.</p><p>We demonstrate the empirical advantage of GATv2 over GAT in a controlled problem that requires alignment of nodes, and in 11 OGB and additional public benchmarks overall. Our experiments show that GATv2 outperforms GAT in all benchmarks while having the same parametric cost.</p><p>We encourage the community to use GATv2 instead of GAT whenever comparing new GNN architectures to the common strong baselines. In complex tasks and domains, a model that uses GAT as an internal component can replace it with GATv2 to benefit from a strictly more powerful model.</p><p>To this end, we will make our code publicly available at https://github.com/tech-srl/how_ attentive_are_gats .</p><p>A Proof for Theorem 2</p><p>For brevity, we repeat our definition of dynamic attention (Definition 3.2):</p><p>Definition 3.2 (Dynamic attention). A (possibly infinite) family of scoring functions F ⊆ R d × R d → R computes dynamic scoring for a set of key vectors K = {k 1 , ..., k n } ⊂ R d and a set of query vectors Q = {q 1 , ..., q m } ⊂ R d , if for any mapping ϕ: [m] → [n] there exists f ∈ F such that for any query i ∈ [m] and any key j =ϕ(i) ∈ [n]: f q i , k ϕ(i) &gt; f (q i , k j ). We say that a family of attention functions computes dynamic attention for K and Q, if its scoring function computes dynamic scoring, possibly followed by monotonic normalization such as softmax. Theorem 2. A GATv2 layer computes dynamic attention for any set of node representations K = Q = {h 1 , ..., h n } .</p><p>Proof. Let G = (V, E) be a graph modeled by a GATv2 layer, having node representations {h 1 , ..., h n }, and let ϕ : [n] → [n] be any node mapping [n] → [n]. We define g : R 2d → R as follows:</p><formula xml:id="formula_9">g (x) = 1 ∃i : x = h i h ϕ(i) 0 otherwise (9)</formula><p>Next, we define the continues function g : R 2d → R that equals to g in specific n 2 inputs:</p><formula xml:id="formula_10">g([h i h j ]) = g([h i h j ]), ∀i, j ∈ [n]<label>(10)</label></formula><p>For all other inputs x ∈ R 2d , g(x) realizes to values that maintain the continuity of g (this is possible because we fixed the values of g for only a finite set of points).</p><p>Thus, for every node i ∈ V and j =ϕ(i) ∈ V:</p><formula xml:id="formula_11">1 = g h i h ϕ(i) &gt; g ([h i h j ]) = 0<label>(11)</label></formula><p>If we concatenate the two input vectors, and define the scoring function e of GATv2 (Equation ( <ref type="formula" target="#formula_5">7</ref>)) as a function of the concatenated vector [h i h j ], from the universal approximation theorem <ref type="bibr" target="#b24">(Hornik et al., 1989;</ref><ref type="bibr" target="#b9">Cybenko, 1989;</ref><ref type="bibr" target="#b16">Funahashi, 1989;</ref><ref type="bibr" target="#b24">Hornik, 1991)</ref>, e can approximate g for any compact subset of R 2d .</p><p>Thus, for any sufficiently small (any 0 &lt; &lt; 1 /2) there exist parameters W and a such that for every node i ∈ V and every j =ϕ(i) :</p><formula xml:id="formula_12">e W ,a h i , h ϕ(i) &gt; 1 − &gt; 0 + &gt; e W ,a (h i , h j )<label>(12)</label></formula><p>and due to the increasing monotonicity of softmax:</p><formula xml:id="formula_13">α i,ϕ(i) &gt; α i,j<label>(13)</label></formula><p>The choice of nonlinearity In general, these results hold if GATv2 had used any common nonpolynomial activation function (such as ReLU, sigmoid, or the hyperbolic tangent function). The LeakyReLU activation function of GATv2 does not change its universal approximation ability <ref type="bibr" target="#b34">(Leshno et al., 1993;</ref><ref type="bibr" target="#b44">Pinkus, 1999;</ref><ref type="bibr" target="#b43">Park et al., 2021)</ref>, and it was chosen only for consistency with the original definition of GAT.</p><p>B Proof that DPGAT Performs Dynamic Attention Theorem 3. A DPGAT layer computes dynamic attention for any set of node representations K = Q = {h 1 , ..., h n } that are linearly independent.</p><p>Proof. Let G = (V, E) be a graph modeled by a DPGAT layer, having linearly independent node representations {h 1 , ...,</p><formula xml:id="formula_14">h n }. Let ϕ : [n] → [n] be any node mapping [n] → [n].</formula><p>We denote the i th row of a matrix M as M i .</p><p>We define a matrix P as:</p><formula xml:id="formula_15">P i,j = 1 j = ϕ(i) 0 otherwise (14)</formula><p>Let X ∈ R n × R d be the matrix holding the graph's node representations as its rows:</p><formula xml:id="formula_16">X =     -h 1 - -h 2 - . . . -h n -    <label>(15)</label></formula><p>Since the rows of X are linearly independent, it necessarily holds that d ≥ n.</p><p>Next, we find weight matrices</p><formula xml:id="formula_17">Q ∈ R d × R d and K ∈ R d × R d such that: (XQ) • (XK) = P<label>(16)</label></formula><p>To satisfy Equation ( <ref type="formula" target="#formula_17">16</ref>), we choose Q and K such that XQ = U and XK = P U where U is an orthonormal matrix (U</p><formula xml:id="formula_18">• U = U • U = I).</formula><p>We can obtain U using the singular value decomposition (SVD) of X:</p><formula xml:id="formula_19">X = U ΣV<label>(17)</label></formula><p>Since Σ ∈ R n × R n and X has a full rank, Σ is invertible, and thus:</p><formula xml:id="formula_20">XV Σ −1 = U<label>(18)</label></formula><p>Now, we define Q as follows:</p><formula xml:id="formula_21">Q = V Σ −1<label>(19)</label></formula><p>Note that XQ = U , as desired.</p><p>To find K that satisfies XK = P U , we use Equation ( <ref type="formula" target="#formula_19">17</ref>) and require:</p><formula xml:id="formula_22">U ΣV K = P U<label>(20)</label></formula><p>and thus:</p><formula xml:id="formula_23">K = V Σ −1 U T P U<label>(21)</label></formula><p>We define:</p><formula xml:id="formula_24">z (h i , h j ) = e (h i , h j ) • d k (22)</formula><p>Where e is the attention score function of DPGAT (Equation ( <ref type="formula">8</ref>)). Now, for a query i and a key j, and the corresponding representations h i , h j :</p><formula xml:id="formula_25">z (h i , h j ) = h i Q • h j K (23) = (X i Q) • (X j K)<label>(24)</label></formula><p>Since X i Q = (XQ) i and X j K = (XK) j , we get</p><formula xml:id="formula_26">z (h i , h j ) = (XQ) i • (XK) j = P i,j<label>(25)</label></formula><p>Therefore:</p><formula xml:id="formula_27">z (h i , h j ) = 1 j = ϕ(i) 0 otherwise<label>(26)</label></formula><p>And thus:</p><formula xml:id="formula_28">e (h i , h j ) = 1/ √ d k j = ϕ(i) 0 otherwise<label>(27)</label></formula><p>To conclude, for every selected query i and any key j =ϕ(i) :</p><formula xml:id="formula_29">e h i , h ϕ(i) &gt; e (h i , h j )<label>(28)</label></formula><p>and due to the increasing monotonicity of softmax:</p><formula xml:id="formula_30">α i,ϕ(i) &gt; α i,j<label>(29)</label></formula><p>Hence, a DPGAT layer computes dynamic attention.</p><p>In the case that d &gt; n, we apply SVD to the full-rank matrix XX ∈ R n×n , and follow the same steps to construct Q and K.</p><p>In the case that Q</p><formula xml:id="formula_31">∈ R d × R d k and K ∈ R d × R d k and d k &gt; d,</formula><p>we can use the same Q and K (Equations ( <ref type="formula" target="#formula_21">19</ref>) and ( <ref type="formula" target="#formula_23">21</ref>)) padded with zeros. We define the Q ∈ R d × R d key and K ∈ R d × R d key as follows:</p><formula xml:id="formula_32">Q i,j = Q i,j j ≤ d 0 otherwise (30) K i,j = K i,j j ≤ d 0 otherwise<label>(31)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 DPGAT is strictly weaker than GATv2</head><p>There are examples of node representations that are linearly dependent and mappings ϕ, for which dynamic attention does not hold. First, we show a simple 2-dimensional example, and then we show the general case of such examples.</p><p>x y</p><formula xml:id="formula_33">h 0 = x h 1 = x + ŷ h 2 = x + 2 ŷ</formula><p>Figure <ref type="figure">5</ref>: An example for node representations that are linearly dependent, for which DPGAT cannot compute dynamic attention, because no query vector q ∈ R 2 can "select" h 1 .</p><p>Conisder the following linearly dependent set of vectors K = Q (Figure <ref type="figure">5</ref>):</p><formula xml:id="formula_34">h 0 = x (32) h 1 = x + ŷ (33) h 2 = x + 2 ŷ (34)</formula><p>where x and ŷ are the cartesian unit vectors. We define β ∈ {0, 1, 2} to express {h 0 , h 1 , h 2 } using the same expression:</p><formula xml:id="formula_35">h β = x + β ŷ<label>(35</label></formula><p>) Let q ∈ Q be any query vector. For brevity, we define the unscaled dot-product attention score as s:</p><formula xml:id="formula_36">s (q, h β ) = e (q, h β ) • d k (<label>36</label></formula><formula xml:id="formula_37">)</formula><p>Where e is the attention score function of DPGAT (Equation ( <ref type="formula">8</ref>)). The (unscaled) attention score between q and {h 0 , h 1 , h 2 } is:</p><formula xml:id="formula_38">s (q, h β ) = q Q h β K (37) = q Q ( x + β ŷ) K (38) = q Q x K + β ŷ K (39) = q Q x K + β q Q ŷ K<label>(40)</label></formula><p>C.1 Time Complexity GAT As noted by <ref type="bibr" target="#b53">Veličković et al. (2018)</ref>, the time complexity of a single GAT head may be expressed as O (|V|dd + |E|d ). Because of GAT's static attention, this computation can be further optimized, by merging the linear layer a 1 with W , merging a 2 with W , and only then compute a {1,2} W h i for every i ∈ V.</p><p>GATv2 require the same computational cost as GAT's declared complexity:</p><formula xml:id="formula_39">O (|V|dd + |E|d ): we denote W = [W 1 W 2 ],</formula><p>where W 1 ∈ R d ×d and W d ×d 2 contain the left half and right half of the columns of W , respectively. We can first compute W 1 h i and W 2 h j for every i, j ∈ V. This takes O (|V|dd ).</p><p>Then, for every edge (j, i), we compute LeakyReLU DPGAT also takes the same time. We can first compute h i Q and h j K for every i, j ∈ V. This takes O (|V|dd ). Computing the dot-product h i Q h j K for every edge (j, i) takes additional O (|E|d ) time, and overall O (|V|dd + |E|d ). All parametric costs are summarized in Table <ref type="table">5</ref>. All following calculations refer to a single layer having a single attention head, omitting bias vectors.</p><formula xml:id="formula_40">(W • [h i h j ]) using the precomputed W 1 h i and W 2 h j , since W • [h i h j ] = W 1 h i + W 2 h j . This takes O (|E|d ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Parametric Complexity</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GAT</head><p>GAT has learned vector and a matrix: a ∈ R 2d and W ∈ R d ×d , thus overall 2d + dd learned parameters.</p><p>GATv2 has a matrix that is twice larger: W ∈ R d ×2d , because it is applied on the concatenation [h i h j ]. Thus, the overall number of learned parameters is d + 2dd . However in our experiments, to rule out the increased number of parameters over GAT as the source of empirical difference, we constrained W = [W W ], and thus the number of parameters were d + dd .</p><p>DPGAT has Q and K matrices of sizes dd k each, and additional dd parameters in the value matrix V , thus 2dd k + dd parameters overall. However in our experiments, we constrained Q = K and set d k = d , and thus the number of parameters is only 2dd .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Training details</head><p>In this section we elaborate on the training details of all of our experiments. All used code and data are publicly available under the MIT license.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Node-and Link-Prediction</head><p>We used the provided splits of OGB <ref type="bibr" target="#b26">(Hu et al., 2020)</ref> and the Adam optimizer. We tuned the following hyperparameters: number of layers ∈ {2, 3, 6}, hidden size ∈ {64, 128, 256}, learning rate ∈ {0.0005, 0.001, 0.005, 0.01} and sampling method -full batch, GraphSAINT <ref type="bibr" target="#b64">(Zeng et al., 2019)</ref> and NeighborSampling <ref type="bibr" target="#b21">(Hamilton et al., 2017)</ref>. We tuned hyperparameters according to validation score and early stopping. The final hyperparameters are detailed in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Additional Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.1 DICTIONARYLOOKUP</head><p>Figure <ref type="figure">6</ref> shows additional comparison between GATv2 and GIN <ref type="bibr" target="#b62">(Xu et al., 2019)</ref> in the DICTIO-NARYLOOKUP problem. GATv2 easily achieves 100% train and test accuracy even for k=100 and using only a single head. GIN, although considered as more expressive than other GNNs, cannot perfectly fit the training data (with a model size of d = 128) starting from k=20.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 QM9</head><p>Standard deviation for the QM9 results of Section 4.6 are presented in Table <ref type="table">10</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure1: Standard GAT (Figure1a) computes static attention: the ranking of attention coefficients is global for all nodes in the graph, and is unconditioned on the query node. For example, all queries (q0 to q9) attend mostly to the 8th key (k8). In contrast, GATv2 (Figure1b) can actually compute dynamic attention, where every query has a different ranking of attention coefficients of the keys.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: The DICTIONARYLOOKUP problem: GATv2 (not shown) easily achieves 100% train and test accuracy even for k=100 and using only a single head.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Test accuracy compared to the noise ratio: GATv2 and DPGAT are more robust to structural noise compared to GAT. Each point is an average of 10 runs, error bars show standard deviation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Finally</head><label></label><figDesc>, computing the results of the linear layer a takes additional O (|E|d ) time, and overall O (|V|dd + |E|d ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>d + 2dd 2dd k + dd In our experiments 2d + dd d + dd 2dd Table 5: Number of parameters for each GNN type, in a single layer and a single attention head.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>, who performed an extensive hyperparameter tuning</figDesc><table><row><cell></cell><cell>Model</cell><cell cols="2">SeenProj UnseenProj</cell></row><row><cell>No-</cell><cell>GCN  †</cell><cell>87.2±1.5</cell><cell>81.4±2.3</cell></row><row><cell>Attention</cell><cell>GIN  †</cell><cell>87.1±0.1</cell><cell>81.1±0.9</cell></row><row><cell></cell><cell>GAT  †</cell><cell>86.9±0.7</cell><cell>81.2±0.9</cell></row><row><cell>Attention</cell><cell cols="2">DPGAT 88.0±0.8</cell><cell>81.5±1.2</cell></row><row><cell></cell><cell>GATv2</cell><cell>88.0±1.1</cell><cell>82.8±1.7</cell></row><row><cell cols="4">Table 1: Accuracy (5 runs±stdev) on VARMIS-</cell></row><row><cell>USE.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Average accuracy (Table2a) and ROC-AUC (Table2b) in node-prediction datasets (10 runs±std). In all datasets, GATv2 outperforms GAT. † -previously reported by<ref type="bibr" target="#b26">Hu et al. (2020)</ref>.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">ogbl-collab</cell><cell>ogbl-citation2</cell></row><row><cell></cell><cell>Model</cell><cell cols="2">w/o val edges w/ val edges</cell><cell></cell></row><row><cell>No-</cell><cell>GCN  †</cell><cell>44.75±1.07</cell><cell>47.14±1.45</cell><cell>80.04±0.25</cell></row><row><cell>Attention</cell><cell>GraphSAGE  †</cell><cell>48.10±0.81</cell><cell>54.63±1.12</cell><cell>80.44±0.10</cell></row><row><cell>Attention 1 head</cell><cell>GAT 1h DPGAT 1h GATv2 1h</cell><cell>39.32±3.26 44.15±1.59 42.00±2.40</cell><cell>48.10±4.80 49.61±3.16 48.02±2.77</cell><cell>79.84±0.19 80.31±0.21 80.33±0.13</cell></row><row><cell>Attention 8 heads</cell><cell>GAT 8h DPGAT 8h GATv2 8h</cell><cell>42.37±2.99 48.99±0.70 42.85±2.64</cell><cell>46.63±2.80 56.90±1.45 49.70±3.08</cell><cell>75.95±1.31 79.64±0.42 80.14±0.71</cell></row><row><cell></cell><cell></cell><cell>(a)</cell><cell></cell><cell>(b)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 .</head><label>6</label><figDesc></figDesc><table><row><cell>Dataset</cell><cell># nodes</cell><cell cols="3"># edges Avg. node degree Diameter</cell></row><row><cell>ogbn-arxiv</cell><cell>169,343</cell><cell>1,166,243</cell><cell>13.7</cell><cell>23</cell></row><row><cell>ogbn-mag</cell><cell cols="2">1,939,743 21,111,007</cell><cell>21.7</cell><cell>6</cell></row><row><cell cols="3">ogbn-products 2,449,029 61,859,140</cell><cell>50.5</cell><cell>27</cell></row><row><cell>ogbn-proteins</cell><cell cols="2">132,534 39,561,252</cell><cell>597.0</cell><cell>9</cell></row><row><cell>ogbl-collab</cell><cell>235,868</cell><cell>1,285,465</cell><cell>8.2</cell><cell>22</cell></row><row><cell>ogbl-citation2</cell><cell cols="2">2,927,963 30,561,187</cell><cell>20.7</cell><cell>21</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Statistics of the OGB datasets<ref type="bibr" target="#b26">(Hu et al., 2020)</ref>.</figDesc><table><row><cell></cell><cell cols="2">Training Validation</cell><cell>Test</cell></row><row><cell># examples</cell><cell>110,462</cell><cell cols="2">10,000 10,000</cell></row><row><cell># nodes -average</cell><cell>18.03</cell><cell>18.06</cell><cell>18.09</cell></row><row><cell># edges -average</cell><cell>18.65</cell><cell>18.67</cell><cell>18.72</cell></row><row><cell>Diameter -average</cell><cell>6.35</cell><cell>6.35</cell><cell>6.35</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 :</head><label>8</label><figDesc>Statistics of the QM9 chemical dataset<ref type="bibr" target="#b45">(Ramakrishnan et al., 2014)</ref> as used by Brockschmidt (2020).E.3 VARMISUSEStatistics of the VARMISUSE dataset, as used in<ref type="bibr" target="#b0">Allamanis et al. (2018)</ref> and<ref type="bibr" target="#b5">Brockschmidt (2020)</ref>, are shown in Table9.</figDesc><table><row><cell></cell><cell cols="4">Training Validation UnseenProject Test SeenProject Test</cell></row><row><cell># graphs</cell><cell>254360</cell><cell>42654</cell><cell>117036</cell><cell>59974</cell></row><row><cell># nodes -average</cell><cell>2377</cell><cell>1742</cell><cell>1959</cell><cell>3986</cell></row><row><cell># edges -average</cell><cell>7298</cell><cell>7851</cell><cell>5882</cell><cell>12925</cell></row><row><cell>Diameter -average</cell><cell>7.88</cell><cell>7.88</cell><cell>7.78</cell><cell>7.82</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 9 :</head><label>9</label><figDesc>Statistics of the VARMISUSE dataset<ref type="bibr" target="#b0">(Allamanis et al., 2018)</ref> as used by<ref type="bibr" target="#b5">Brockschmidt (2020)</ref>.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">We also add a bias vector b before applying the nonlinearity, we omit this in Equation (7) for brevity.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Gail Weiss for the helpful discussions, thorough feedback, and inspirational paper <ref type="bibr" target="#b59">(Weiss et al., 2018)</ref>. We also thank Petar Veličković for the useful discussion about the complexity and implementation of GAT.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The first term q Q x K is unconditioned on β, and thus shared for every h β . Let us focus on the second term β q Q ŷ K . If q Q ŷ K &gt; 0, then: e (q, h 2 ) &gt; e (q, h 1 ) (41)</p><p>Otherwise, if q Q ŷ K ≤ 0:</p><p>e (q, h 0 ) ≥ e (q, h 1 ) (42) Thus, for any query q, the key h 1 can never get the highest score, and thus cannot be "selected". That is, the key h 1 cannot satisfy that e (q, h 1 ) is strictly greater than any other key.</p><p>In the general case, let h 0 , h 1 ∈ R d be some non-zero vectors , and λ is some scalar such that 0 &lt; λ &lt; 1.</p><p>Consider the following linearly dependent set of vectors:</p><p>For any query q ∈ Q and β ∈ {0, λ, 1} we define:</p><p>Where e is the attention score function of DPGAT (Equation ( <ref type="formula">8</ref>)).</p><p>Therefore:</p><p>Thus, for any query q, the key h λ cannot be selected. That is, the key h λ cannot satisfy that e (q, h λ ) is strictly greater than any other key. Therefore, there are mappings ϕ, for which dynamic attention does not hold.</p><p>While we prove that GATv2 computes dynamic attention (Appendix A) for any set of node representations K = Q, there are sets of node representations and mappings ϕ for which dynamic attention does not hold for DPGAT. Thus, DPGAT is strictly weaker than GATv2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Complexity Analysis</head><p>We repeat the definitions of GAT, GATv2 and DPGAT:</p><p>GAT <ref type="bibr" target="#b53">(Veličković et al., 2018)</ref>:</p><p>GATv2 (our fixed version):</p><p>DPGAT <ref type="bibr" target="#b52">(Vaswani et al., 2017)</ref>: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Robustness to Noise</head><p>In these experiments, we used the same best-found hyperparameters in node-prediction, with 8 attention heads in ogbn-arxiv and 1 head in ogbn-mag. Each point is an average of 10 runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 Synthetic Benchmark: DICTIONARYLOOKUP</head><p>In all experiments, we used a learning rate decay of 0.5, a hidden size of d = 128, a batch size of 1024, and the Adam optimizer.</p><p>We created a separate dataset for every graph size (k), and we split each such dataset to train and test with a ratio of 80:20. Since this is a contrived problem, we did not use a validation set, and the reported test results can be thought of as validation results. Every model was trained on a fixed value of k. Every key node (bottom row in Figure <ref type="figure">2</ref>) was encoded as a sum of learned attribute embedding and a value embedding, followed by ReLU.</p><p>We experimented with layer normalization, batch normalization, dropout, various activation functions and various learning rates. None of these changed the general trend, so the experiments in Figure <ref type="figure">3</ref> were conducted without any normalization, without dropout and a learning rate of 0.001.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4 Programs: VARMISUSE</head><p>We used the code, splits, and the same best-found configurations as <ref type="bibr" target="#b5">Brockschmidt (2020)</ref>, who performed an extensive hyperparameter tuning by searching over 30 configurations for each GNN type. We trained each model five times.</p><p>We took the best-found hyperparameters of <ref type="bibr" target="#b5">Brockschmidt (2020)</ref> for GAT and used them to train GATv2 and DPGAT, without any further tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.5 Graph-Prediction: QM9</head><p>We used the code and splits of <ref type="bibr" target="#b5">Brockschmidt (2020)</ref> who performed an extensive hyperparameter search over 500 configurations. We took the best-found hyperparameters of <ref type="bibr" target="#b5">Brockschmidt (2020)</ref> for GAT and used them to train GATv2 and DPGAT. The only minor change from GAT is placing a residual connection after every layer, rather than after every other layer, which is within the experimented hyperparameter search that was reported by Brockschmidt ( <ref type="formula">2020</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Data Statistics E.1 Node-and Link-Prediction Datasets</head><p>Statistics of the OGB datasets we used for node-and link-prediction are shown in Table <ref type="table">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 QM9</head><p>Statistics of the QM9 dataset, as used in <ref type="bibr" target="#b5">Brockschmidt (2020)</ref> are shown in Table <ref type="table">8</ref>. easily achieves 100% train and test accuracy even for k=100 and using only a single head. GIN <ref type="bibr" target="#b62">(Xu et al., 2019)</ref>, although considered as more expressive than other GNNs, cannot perfectly fit the training data (with a model size of d = 128) starting from k=20.  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to represent programs with graphs</title>
		<author>
			<persName><forename type="first">Miltiadis</forename><surname>Allamanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmoud</forename><surname>Khademi</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=BJOFETxR-" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the bottleneck of graph neural networks and its practical implications</title>
		<author>
			<persName><forename type="first">Uri</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eran</forename><surname>Yahav</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=i80OPhOCVH2" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Diffusion-convolutional neural networks</title>
		<author>
			<persName><forename type="first">James</forename><surname>Atwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Don</forename><surname>Towsley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="1993">1993-2001, 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>CoRR, abs/1409.0473</idno>
		<ptr target="http://arxiv.org/abs/1409.0473" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Interaction networks for learning about objects, relations and physics</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Neural Information Processing Systems</title>
				<meeting>the 30th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4509" to="4517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Gnn-film: Graph neural networks with feature-wise linear modulation</title>
		<author>
			<persName><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning, ICML</title>
				<meeting>the 36th International Conference on Machine Learning, ICML</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Geometric deep learning: going beyond euclidean data</title>
		<author>
			<persName><forename type="first">Joan</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="18" to="42" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Geometric deep learning: Grids, groups, graphs, geodesics, and gauges</title>
		<author>
			<persName><forename type="first">M</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joan</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taco</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petar</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><surname>Veličković</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Dan</forename><surname>Busbridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dane</forename><surname>Sherburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Cavallo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nils</forename><forename type="middle">Y</forename><surname>Hammerla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.05811</idno>
		<title level="m">Relational graph attention networks</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Approximation by superpositions of a sigmoidal function</title>
		<author>
			<persName><forename type="first">George</forename><surname>Cybenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematics of control, signals and systems</title>
				<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="303" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Misha</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergio</forename><forename type="middle">Gómez</forename><surname>Colmenarejo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serkan</forename><surname>Cabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Saxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nando</forename><surname>De Freitas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.06383</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Programmable agents. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">One-shot imitation learning</title>
		<author>
			<persName><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bradly</forename><surname>Stadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
				<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1087" to="1098" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Convolutional networks on graphs for learning molecular fingerprints</title>
		<author>
			<persName><forename type="first">Dougal</forename><surname>David K Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Iparraguirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Bombarell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alán</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">P</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2224" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A generalization of transformer networks to graphs</title>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dwivedi</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.09699</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Prakash Dwivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaitanya</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.00982</idno>
		<title level="m">Benchmarking graph neural networks</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fast graph representation learning with PyTorch Geometric</title>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the approximate realization of continuous mappings by neural networks</title>
		<author>
			<persName><forename type="first">Ken-Ichi</forename><surname>Funahashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="183" to="192" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Graph representation learning via hard and channel-wise attention networks</title>
		<author>
			<persName><forename type="first">Hongyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuiwang</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="741" to="749" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">F</forename><surname>Samuel S Schoenholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">E</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
				<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title/>
		<ptr target="https://github.com/gordicaleksa/pytorch-GAT" />
	</analytic>
	<monogr>
		<title level="j">Aleksa Gordić. pytorch-gat</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A new model for learning in graph domains</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriele</forename><surname>Monfardini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franco</forename><surname>Scarselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 2005 IEEE International Joint Conference on Neural Networks</title>
				<meeting>2005 IEEE International Joint Conference on Neural Networks</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="729" to="734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Contrastive multi-view representation learning on graphs</title>
		<author>
			<persName><forename type="first">Kaveh</forename><surname>Hassani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Hosein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khasahmadi</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4116" to="4126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
				<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Approximation capabilities of multilayer feedforward networks</title>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Hornik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<editor>Kurt Hornik, Maxwell Stinchcombe, and Halbert White</editor>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="359" to="366" />
			<date type="published" when="1989">1991. 1989</date>
		</imprint>
	</monogr>
	<note>Neural networks</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Vain: attentional multi-agent predictive modeling</title>
		<author>
			<persName><forename type="first">Yedid</forename><surname>Hoshen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
				<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2698" to="2708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Open graph benchmark: Datasets for machine learning on graphs</title>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00687</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Syntax-aware aspect level sentiment classification with graph attention networks</title>
		<author>
			<persName><forename type="first">Binxuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathleen</forename><forename type="middle">M</forename><surname>Carley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5472" to="5480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Combining label propagation and simple models out-performs graph neural networks</title>
		<author>
			<persName><forename type="first">Qian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Horace</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhay</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ser-Nam</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Austin</forename><surname>Benson</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=8E1-f3VhX1o" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Transformers are graph neural networks. The Gradient</title>
		<author>
			<persName><forename type="first">Chaitanya</forename><surname>Joshi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">How to find your friendly neighborhood: Graph attention design with selfsupervision</title>
		<author>
			<persName><forename type="first">Dongkwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><surname>Oh</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Wi5KUNlqWty" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Social-bigat: Multimodal trajectory forecasting using bicycle-gan and graph attention networks</title>
		<author>
			<persName><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Martín-Martín</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2019/file/d09bf41544a3365a46c9077ebb5e35c3-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Alché-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Attention models in graphs: A survey</title>
		<author>
			<persName><forename type="first">John</forename><surname>Boaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">A</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungchul</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nesreen</forename><forename type="middle">K</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunyee</forename><surname>Koh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.07984</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multilayer feedforward networks with a nonpolynomial activation function can approximate any function</title>
		<author>
			<persName><forename type="first">Moshe</forename><surname>Leshno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><forename type="middle">Ya</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allan</forename><surname>Pinkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shimon</forename><surname>Schocken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="861" to="867" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deepgcns: Can gcns go as deep as cnns?</title>
		<author>
			<persName><forename type="first">Guohao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Thabet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
				<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="9267" to="9276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deeper insights into graph convolutional networks for semisupervised learning</title>
		<author>
			<persName><forename type="first">Qimai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhichao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao-Ming</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Gated graph sequence neural networks</title>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Gated relational graph attention networks</title>
		<author>
			<persName><forename type="first">Denis</forename><surname>Lukovnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asja</forename><surname>Fischer</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=v-9E8egy_i" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/D/D15/D15-1166.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09-17">2015. September 17-21, 2015. 2015</date>
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Entity-aware dependency-based deep graph attention network for comparative preference classification</title>
		<author>
			<persName><forename type="first">Nianzu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sahisnu</forename><surname>Mazumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5782" to="5788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Geometric deep learning on graphs and manifolds using mixture model cnns</title>
		<author>
			<persName><forename type="first">Federico</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davide</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emanuele</forename><surname>Rodola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Svoboda</surname></persName>
		</author>
		<author>
			<persName><surname>Michael M Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
				<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5115" to="5124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning attention-based embeddings for relation prediction in knowledge graphs</title>
		<author>
			<persName><forename type="first">Deepak</forename><surname>Nathani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jatin</forename><surname>Chauhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charu</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manohar</forename><surname>Kaul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4710" to="4723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Minimum width for universal approximation</title>
		<author>
			<persName><forename type="first">Sejun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chulhee</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaeho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=O-XJwyoIF-k" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deepinf: Social influence prediction with deep learning</title>
		<author>
			<persName><forename type="first">Allan</forename><surname>Pinkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">; Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD&apos;18)</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD&apos;18)</meeting>
		<imprint>
			<date type="published" when="1999">1999. 1999. 2018</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="143" to="195" />
		</imprint>
	</monogr>
	<note>Approximation theory of the mlp model</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Quantum chemistry structures and properties of 134 kilo molecules</title>
		<author>
			<persName><forename type="first">Raghunathan</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Pavlo O Dral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Von</forename><surname>Anatole</surname></persName>
		</author>
		<author>
			<persName><surname>Lilienfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">140022</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Selfsupervised graph transformer on large-scale molecular data</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yatao</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tingyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiyang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenbing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2020">2020a</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Dropedge: Towards deep graph convolutional networks on node classification</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenbing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tingyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Hkx1qkrKPr" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2020">2020b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A simple neural network module for relational reasoning</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Razvan</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
				<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4974" to="4983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The graph neural network model</title>
		<author>
			<persName><forename type="first">Franco</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chung</forename><surname>Ah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriele</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName><surname>Monfardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="80" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Masked label prediction: Unified massage passing model for semi-supervised classification</title>
		<author>
			<persName><forename type="first">Yunsheng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengjie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shikun</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.03509</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Attention-based graph neural network for semi-supervised learning</title>
		<author>
			<persName><forename type="first">Chong</forename><surname>Kiran K Thekumparampil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sewoong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li-Jia</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.03735</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Pointer graph networks</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Buesing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Overlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Improving graph attention networks with large margin-based constraints</title>
		<author>
			<persName><forename type="first">Guangtao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.11945</idno>
		<imprint>
			<date type="published" when="2019">2019a</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Deep graph library: A graph-centric, highly-performant package for graph neural networks</title>
		<author>
			<persName><forename type="first">Minjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Da</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihao</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mufei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinjing</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingfan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Gai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianjun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.01315</idno>
		<imprint>
			<date type="published" when="2019">2019b</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Heterogeneous graph attention network</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houye</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanfang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
				<imprint>
			<date type="published" when="2019">2019c</date>
			<biblScope unit="page" from="2022" to="2032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Bag of tricks of semi-supervised classification with graph neural networks</title>
		<author>
			<persName><forename type="first">Yangkun</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.13355</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">On the practical computational power of finite precision rnns for language recognition</title>
		<author>
			<persName><forename type="first">Gail</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eran</forename><surname>Yahav</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="740" to="745" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Simplifying graph convolutional networks</title>
		<author>
			<persName><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amauri</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Fifty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6861" to="6871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=ryGs6iA5Km" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Distilling knowledge from graph convolutional networks</title>
		<author>
			<persName><forename type="first">Yiding</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiayan</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingli</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinchao</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020-06">June 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Graphsaint: Graph sampling based inductive learning method</title>
		<author>
			<persName><forename type="first">Hanqing</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongkuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajitesh</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajgopal</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Prasanna</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.04931</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Gaan: Gated attention networks for learning on large and spatiotemporal graphs</title>
		<author>
			<persName><forename type="first">Jiani</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingjian</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irwin</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dit-Yan</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Fourth Conference on Uncertainty in Artificial Intelligence</title>
				<meeting>the Thirty-Fourth Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="339" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Adaptive structural fingerprints for graph attention networks</title>
		<author>
			<persName><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaokang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=BJxWx0NYPr" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Pairnorm: Tackling oversmoothing in gnns</title>
		<author>
			<persName><forename type="first">Lingxiao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leman</forename><surname>Akoglu</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rkecl1rtwB" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
