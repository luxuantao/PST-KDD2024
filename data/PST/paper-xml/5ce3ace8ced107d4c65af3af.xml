<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Sequential Deep Learning Application for Recognising Human Activities in Smart Homes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-04-24">April 24, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Daniele</forename><surname>Liciotti</surname></persName>
							<email>d.liciotti@pm.univpm.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering (DII)</orgName>
								<orgName type="institution">Università Politecnica delle Marche</orgName>
								<address>
									<addrLine>Via Brecce Bianche 12</addrLine>
									<postCode>60131</postCode>
									<settlement>Ancona</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering (DII)</orgName>
								<orgName type="institution">Università Politecnica delle Marche</orgName>
								<address>
									<addrLine>Via Brecce Bianche 12</addrLine>
									<postCode>60131</postCode>
									<settlement>Ancona</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michele</forename><surname>Bernardini</surname></persName>
							<email>m.bernardini@pm.univpm.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering (DII)</orgName>
								<orgName type="institution">Università Politecnica delle Marche</orgName>
								<address>
									<addrLine>Via Brecce Bianche 12</addrLine>
									<postCode>60131</postCode>
									<settlement>Ancona</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering (DII)</orgName>
								<orgName type="institution">Università Politecnica delle Marche</orgName>
								<address>
									<addrLine>Via Brecce Bianche 12</addrLine>
									<postCode>60131</postCode>
									<settlement>Ancona</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luca</forename><surname>Romeo</surname></persName>
							<email>l.romeo@univpm.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering (DII)</orgName>
								<orgName type="institution">Università Politecnica delle Marche</orgName>
								<address>
									<addrLine>Via Brecce Bianche 12</addrLine>
									<postCode>60131</postCode>
									<settlement>Ancona</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering (DII)</orgName>
								<orgName type="institution">Università Politecnica delle Marche</orgName>
								<address>
									<addrLine>Via Brecce Bianche 12</addrLine>
									<postCode>60131</postCode>
									<settlement>Ancona</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Emanuele</forename><surname>Frontoni</surname></persName>
							<email>e.frontoni@univpm.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering (DII)</orgName>
								<orgName type="institution">Università Politecnica delle Marche</orgName>
								<address>
									<addrLine>Via Brecce Bianche 12</addrLine>
									<postCode>60131</postCode>
									<settlement>Ancona</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering (DII)</orgName>
								<orgName type="institution">Università Politecnica delle Marche</orgName>
								<address>
									<addrLine>Via Brecce Bianche 12</addrLine>
									<postCode>60131</postCode>
									<settlement>Ancona</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Sequential Deep Learning Application for Recognising Human Activities in Smart Homes</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-04-24">April 24, 2019</date>
						</imprint>
					</monogr>
					<idno type="MD5">50C354A0FC81FFF86488CCCB02CED54D</idno>
					<idno type="DOI">10.1016/j.neucom.2018.10.104</idno>
					<note type="submission">Received date: 31 March 2018 Revised date: 8 September 2018 Accepted date: 12 October 2018 Preprint submitted to Neurocomputing</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Smart Home</term>
					<term>Human Activity Recognition</term>
					<term>Deep Learning</term>
					<term>LSTM</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The recent advancement and development of computer electronic devices has led to the adoption of smart home sensing systems, stimulating the demand for associated products and services. Accordingly, the increasingly large amount of data calls the machine learning (ML) field for automatic recognition of human behaviour. In this work, different deep learning (DL) models that learn to classify human activities were proposed. In particular, the long short-term memory (LSTM) was applied for modelling spatio-temporal sequences acquired by smart home sensors. Experimental results performed on the Center for Advanced Studies in Adaptive Systems datasets show that the proposed LSTM-based approaches outperform existing DL and ML methods, giving superior results compared to the existing literature.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In the last few decades, human activity recognition (HAR) has been a lively and challenging research area, due to its applicability to different active and assisted living (AAL) domains, as well as the increasing demand for home automation and convenience services for the elderly <ref type="bibr" target="#b0">[1]</ref>. Nowadays, mainly because of the rapid increase in 5 the world's ageing population <ref type="bibr" target="#b1">[2]</ref>, HAR has acquired much interest in the field of ambi-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T ent intelligence and assisted living technologies in smart homes. It is meant to improve the residents' quality of life with the use of simple and ubiquitous sensors <ref type="bibr" target="#b2">[3]</ref>. According to <ref type="bibr" target="#b3">[4]</ref>, a smart home provides independence and comfort to the residents by using all technological devices interconnected within the network, capable of communicat-10 ing and learning through the user's habits, creating an interactive space. In particular, HAR is the most salient process for incorporating ambient intelligence into smart environments. It involves a series of complex modelling, reasoning, and decision-making procedures <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. The goal of HAR is to detect and then identify simple and complex human activities in real-world settings by processing spatial and temporal information 15 acquired by visual and non-visual sensory data <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. The adopted sensors may be fused in the environment, connected with its objects, or worn directly by the occupant. Compared to wearable sensors, object or environment sensors are advantageous, as they can give an indirect indication of the occupant's activities; moreover, they can discriminate similar actions <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8]</ref>. According to <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9]</ref>, HAR application domains are 20 among the most varied, but they can be enclosed in three macro categories: healthcare monitoring applications <ref type="bibr" target="#b9">[10]</ref>, monitoring and surveillance systems for indoor and outdoor activities <ref type="bibr" target="#b10">[11]</ref>, and lastly, AAL systems <ref type="bibr" target="#b11">[12]</ref> for smart homes.</p><p>AAL systems are to provide an adequate, non-invasive, technological support, allowing the inhabitants to live independently in safety and in comfort for as long as 25 possible in their homes. Achievement of this goal depends on how the HAR system is able to learn the person's behaviour during daily life. However, the real-world settings are complex and full of uncertainties: data captured by sensors may be ambiguous, as well as noisy and sparse. This leads to the design and implementation of consistent machine learning (ML) techniques to discover knowledge from data and provide a reli-30 able prediction of human behaviour <ref type="bibr" target="#b12">[13]</ref>. In order to manage uncertainties and temporal information, data-driven approaches require very large datasets to learn human activities and behaviours <ref type="bibr" target="#b13">[14]</ref>. Unfortunately, large real-world datasets are rarely available, and this limitation is one of the major challenges in the AAL field. Accordingly, the knowledge-driven approaches are easy to apply, but they are less robust for managing 35 noisy and temporal data <ref type="bibr" target="#b14">[15]</ref>. Hence, it is common practice to consider the HAR task a classification problem. In the past, various classification algorithms have been em-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T ployed, such as naive bayes (NB) <ref type="bibr" target="#b15">[16]</ref>, random forest (RF) <ref type="bibr" target="#b16">[17]</ref>, hidden markov model (HMM) <ref type="bibr" target="#b15">[16]</ref>, conditional random field (CRF) <ref type="bibr" target="#b15">[16]</ref>, k-nearest neighbour (k-NN) <ref type="bibr" target="#b17">[18]</ref>, and support vector machine (SVM) <ref type="bibr" target="#b18">[19]</ref>. Most existing ML approaches result in static 40 models, without the need of evolving and adapting with the changing environment.</p><p>However <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref> proposed an automatic context management system which is able to discover dynamically contextual information, incorporate new data sources, and identify the context with greater discriminative power. Moreover, the self-verification and the reliability measure of the HAR prediction can be performed automatically, measur-45 ing the confidence score based on posterior probability and clustering approaches <ref type="bibr" target="#b21">[22]</ref>.</p><p>Each ML algorithm for the HAR task has its own advantages, but none of these approaches prevail over others in all application scenarios <ref type="bibr" target="#b2">[3]</ref>. The authors in <ref type="bibr" target="#b22">[23]</ref> developed a framework for smart home datasets analysis, employing also the artificial neural network with one hidden layer. Their analysis suggested that the performance 50 of different classifiers is influenced by the dataset characteristic.</p><p>For instance, the NB probabilistic classifier obtains good accuracy with large amounts of sample data but does not fit any temporal information. Instead, the HMM and CRF are the most popular approaches for inclusion of such temporal information. Other approaches <ref type="bibr" target="#b23">[24]</ref> include hierarchical methods for modelling high-level features which 55 encapsulate past information. Therefore, few existing sensor-based HAR approaches comprehensively explore the temporal patterns among actions <ref type="bibr" target="#b24">[25]</ref>, handling sequential, interleaved, and concurrent temporal relations <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref>.</p><p>In recent years, there has been an increasing interest in DL techniques for HAR applications <ref type="bibr" target="#b12">[13]</ref> and human pose recognition <ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref>, which are able to learn multiple, 60 non-linear representations of raw data through multiple hidden layers <ref type="bibr" target="#b30">[31]</ref>. This allows the DL application to perform a feature extraction and transformation without prior knowledge. The deep neural network (DNN), convolutional neural network (CNN), recurrent neural network (RNN), and long short-term memory (LSTM) represent the most popular DL techniques in HAR <ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref>. In particular, CNN has been widely used 65 to address the human pose recognition <ref type="bibr" target="#b27">[28]</ref> and the HAR task <ref type="bibr" target="#b34">[35]</ref> by using convolutions across two or three dimensions in order to capture an image's spatial patterns.</p><p>Recent research trends in CNN aim to learn the optimal activation functions in a data-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>driven way <ref type="bibr" target="#b35">[36]</ref> while learning a Euclidean embedding <ref type="bibr" target="#b36">[37]</ref> of the feature's space.</p><p>In this work, we propose a novel application of LSTM networks to improve HAR 70 within a sensor-fused AAL scenario. We started from the unidirectional LSTM (Uni-LSTM), and we explored more complex LSTM architectures, such as the bidirectional LSTM (Bi-LSTM) and cascade bidirectional and unidirectional LSTM (Casc-LSTM).</p><p>Two ensemble LSTM approaches named Ensemble2LSTM (Ens2-LSTM) and Cas-cadeEnsemble (CascEns-LSTM) are also proposed. Unlike other DL approaches for 75 video- <ref type="bibr" target="#b12">[13]</ref> and wearable-based HAR <ref type="bibr" target="#b8">[9,</ref><ref type="bibr">38,</ref><ref type="bibr" target="#b37">39]</ref>, this paper contextualizes the problem in the smart home scenario where a typical home is equipped with several sensors and the captured data is voluminous and structurally rich <ref type="bibr" target="#b15">[16]</ref>. Moreover, the proposed setting is (i) closest to the real-world situation <ref type="bibr" target="#b2">[3]</ref>, (ii) privacy compliant <ref type="bibr" target="#b2">[3]</ref>, and (iii) based on an HAR task that is much more challenging due to the variability of activities 80 and residents <ref type="bibr" target="#b15">[16]</ref> (e.g., some residents may be younger adults, healthy older adults, or older adults with pathological conditions, and some may perform interactions with pets). Two conditions motivate this particular application of the LSTM network: it allows (i) extracting highly discriminative non-linear feature representations while (ii) modelling temporal sequences by learning long-term dependency situations. This is 85 often the case with human activities, where the action can be divided into a sequence of gestures and postures, and each sample can be related to the previous ones <ref type="bibr" target="#b38">[40]</ref>. The reliability of the proposed approach for HAR is investigated in a smart home scenario using the widely spread Center for Advanced Studies in Adaptive Systems (CASAS) benchmark datasets <ref type="bibr" target="#b39">[41]</ref>. Even though the CASAS datasets are widely used and in-90 vestigated by researchers using supervised ML algorithms, to the best of the authors' knowledge, there is still a lack of HAR works related to the use of DL approaches which take into account the temporal information.</p><p>The overall performance of the proposed LSTM-based approaches has been compared with one-dimensional CNN <ref type="bibr">[38]</ref>) and traditional ML techniques (e.g., NB, HMM, 95 CFR) widely used in literature for HAR <ref type="bibr" target="#b15">[16]</ref>.</p><p>Results of this study show that the application of standard LSTM leads to significant performance improvement with respect to ML approaches (from 10.60% to 16.04% of accuracy improvement) and with respect to one-dimensional CNN (from 11.03% to  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Taking all of these facts into account, it may be useful to fill this gap by applying an adaptive, well-known DL model (i.e., LSTM) on a "rarely been used" dataset in this context. Likewise, it seems challenging to compare the results obtained with other DL and traditional ML models largely present and already discussed in the literature. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">CASAS datasets background</head><p>This section focuses on the HAR approaches where the CASAS datasets were employed. In this context, several ML techniques were applied and tested to solve the activity recognition task.</p><p>The authors in <ref type="bibr" target="#b15">[16]</ref> applied three ML algorithms (i.e., NB, CRF, and HMM) for 110 HAR in the 11 labelled CASAS datasets. A further comparison with SVM was introduced in <ref type="bibr" target="#b18">[19]</ref>. Once the SVM model was determined to perform better than other traditional ML techniques, it had been applied for recognising activities in the real world <ref type="bibr" target="#b18">[19]</ref>.</p><p>The reliability of standard, supervised classifiers varies dramatically between datasets 115 and within the single activities <ref type="bibr" target="#b15">[16]</ref>. In particular, the classification accuracy is influenced by (i) the amount and nature of training data, (ii) the ambiguity of the label, and (iii) the number of residents investigated at the same time. Different approaches have tried to overcome these crucial issues. In <ref type="bibr" target="#b40">[42]</ref>, the authors developed a supervised behaviour classification model (BCM) derived from an SVM classifier to differentiate 120 a person from an inhabitant group. Considering only the early morning routine, the BCM extracted features and interpreted the temporal sequence of all users' information captured by sensors. The multiple kernel SVM approach was applied in <ref type="bibr" target="#b41">[43]</ref> for the recognition of individual activities. Additionally, the CRF was used to discover sequential future behaviour patterns. In <ref type="bibr" target="#b17">[18]</ref>, the authors proposed an activity recog- in <ref type="bibr" target="#b42">[44]</ref>, in order to classify the ongoing activity through probabilistic reasoning. This hybrid segmentation approach can automatically segment continuous and sparse sensor 130 events into discrete sequences, ensuring a correct interpretation of the input raw data that the sensors generated.</p><p>The key finding of several state-of-the-art approaches is to model the action as a sequence of subsequent gestures/behaviours over time. This leads to recognition of time-dependent patterns of events, predicting future behaviours starting from the 135 current activity or state.</p><p>In <ref type="bibr" target="#b43">[45]</ref>, the authors proposed an activity-prediction model using probabilistic Bayesian networks and a novel two-step inference process to predict (i) the next activity and (ii) its related start time. In <ref type="bibr" target="#b44">[46]</ref>, the authors tried to estimate prior probabilities of an activity happening at a certain time, in order to reduce the error rate of a given classi-140 fication algorithm. Several temporal models such as frequency map enhancement and Gaussian mixtures model were evaluated. The time relevance was analysed in <ref type="bibr" target="#b16">[17]</ref>,</p><p>where the authors proposed a time-space feature importance analysis in order to compare the potential relevance of features for activities classification. RF, NB, and SVM were the adopted techniques used for discriminating the feature relevance. In <ref type="bibr" target="#b45">[47]</ref>,</p><p>145 the authors presented an activity forecasting method that can predict the expected time until an activity occurs. This method generates an activity forecast using a regression tree classifier and offers an advantage over sequence prediction methods, such as linear regression and SVM classifiers.</p><p>DL algorithms for HAR applied to CASAS datasets have still been scarcely ex-150 plored in the literature. The authors in <ref type="bibr" target="#b46">[48]</ref> implemented a deep belief network comprising many restricted Boltzmann machines. Then, the performance of the proposed network was compared with other traditional ML algorithms such as HMM, NB, and CRF, which were also employed in <ref type="bibr" target="#b15">[16]</ref>, showing interesting results.</p><p>Unlike the above-mentioned work, this paper proposes the application of a sequen-155 tial DL LSTM approach for HAR. This leads to some advantages with respect to traditional ML models:</p><p>• LSTM allows automatic learning of spatio-temporal information from the sensor</p><formula xml:id="formula_0">A C C E P T E D M A N U S C R I P T</formula><p>data without the need of handcrafted features <ref type="bibr" target="#b48">[49]</ref> or kernel fusion approaches <ref type="bibr" target="#b41">[43]</ref>;</p><p>• LSTM, as a sequential approach, models the temporal evolution of the features, 160 using recurrent connections in the hidden layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">DL for HAR using time series data</head><p>DL approaches were employed to capture the temporal dependency of a human action, considering time series data <ref type="bibr" target="#b12">[13]</ref>. In particular, CNNs adopt convolutions across a one-dimensional temporal sequence to capture local dependencies among input data, 165 using parameter sharing across time <ref type="bibr">[38]</ref>. However, the geometry of convolutional kernels restricts the captured range of dependencies between data samples; likewise, local connectivity limits the output to a function of a small number of neighbouring input samples <ref type="bibr" target="#b37">[39]</ref>. As a result, CNNs may be unsuitable to a wide range of HAR configurations and require fixed-length input windows. The use of LSTM may overcome 170 these limitations by exploiting their internal memories to capture long-range dependencies in variable-length input sequences. As we shall see in the Results section, our LSTM-based approaches perform favorably over CNN <ref type="bibr">[38]</ref>.</p><p>Moreover, in accordance with the most recent state-of-the-art contributions <ref type="bibr" target="#b12">[13]</ref>,</p><p>ensemble DL models, RNN, and LSTM have not yet been well investigated for HAR 175 using multimodal channels. Specifically, Bi-LSTM and Casc-LSTM models have already been employed to recognise human activity using wearable and on-body sensor input data <ref type="bibr" target="#b37">[39]</ref>. However, deviating from <ref type="bibr" target="#b37">[39]</ref>, we aim to explore an LSTM-based methodology for HAR using only a sequence of data acquired by domotic fused sensors (e.g., motion sensors, temperature sensors, magnetic door sensors). The proposed mul-180 timodal data configuration is more challenging than wearable sensor data are, because smart home data do not always display a discriminative pattern, due to the intrinsic variability of activities and residents <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Material and Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Smart home datasets 185</head><p>Several datasets were used by researchers in a smart home scenario for HAR applications <ref type="bibr" target="#b49">[50]</ref><ref type="bibr" target="#b50">[51]</ref><ref type="bibr" target="#b51">[52]</ref><ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref>. Since the collection of real house data is costly, time consuming,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>and difficult to obtain, the publicly available datasets have a crucial importance for the research community. Additionally, they are useful for testing HAR algorithms and providing the baseline for comparison. In Table <ref type="table" target="#tab_0">1</ref>, a brief overview of the widely used, 190 publicly available smart home datasets is reported. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">CASAS datasets</head><p>The CASAS datasets were introduced by Washington State University <ref type="bibr" target="#b39">[41]</ref>. The testbed smart apartment used in the CASAS smart home project comprised three apartments that include three bedrooms, one bathroom, a kitchen, and a living/dining room.</p><p>195</p><p>Each apartment was equipped with different kinds of sensors (e.g., motion sensors, temperature sensors, door sensors) and actuators for sensing the environment and providing information to inhabitants. Five annotated datasets, named Milan, Cairo, Ky-oto2, Kyoto3, and Kyoto4 were selected among all available CASAS datasets <ref type="bibr" target="#b54">[55]</ref>.</p><p>This choice was motivated by the fact that these datasets present the same sensor data 200 representation, defined as date-time, sensor, and state/value (see Table <ref type="table" target="#tab_1">2</ref>).</p><p>• The Milan dataset contains sensor data collected in the home of a volunteer adult.</p><p>The residents were a woman and a dog. The woman's children visited on several occasions. The sensor events were generated from motion (M), door closure (D), and temperature (T) sensors;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>205</head><p>• the Cairo dataset contains sensor data collected in the home of a volunteer adult couple. The residents were a man, a woman, and a dog. The couple's children also visited the home on at least one occasion. The sensor events were generated from M and T sensors;  Table <ref type="table" target="#tab_2">3</ref> shows the main information of these datasets, including the number of 215 activities as well as number of occurrences, the type and the number of sensors, the number of residents, and the number of monitored days. resented by the previous categories, as well as activities named "None", in which the resident performed no activity, was grouped as "Other".</p><formula xml:id="formula_1">A C C E P T E D M A N U S C R I P T</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Proposed LSTM models</head><p>The proposed HAR framework comprised the preprocessing and classification stage (see Figure <ref type="figure" target="#fig_6">1</ref>). The preprocessing stage included the filtering and data aggregation   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">LSTM background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>245</head><p>LSTM networks <ref type="bibr" target="#b55">[56]</ref> can be seen as a very successful extension of the RNN, explicitly designed to avoid the long-term dependency problem associated with RNNs. In particular, <ref type="bibr" target="#b56">[57]</ref> demonstrated that the RNN can model the short time-lags between input and labels. However, this short-term memory can be insufficient when dealing with real-world time series data <ref type="bibr" target="#b56">[57]</ref>. LSTM methodology proposed a special node, called 250 the constant error carousel (CEC), that allows constant propagation of the error signal over time. Additionally, it uses the gating mechanism over an internal memory cell to control access to the CEC and to learn and represent a more complex representation of the long-term dependencies. Hence, an LSTM model is well suited to classify, process, and predict time series with time lags of unknown sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>255</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>The LSTM layer's main component is the memory cell. The cell is responsible for "remembering" values or states for long or short time periods over arbitrary time intervals. An LSTM block usually contains input, output, and forget gates, which are respectively, seen as write, read, and reset operations for the memory cell. Each of the three gates can be thought of as a "conventional" artificial neuron, as in a multi-260 layer neural network. Thus, using particular activation functions, gates can regulate the flow of values that go through the connections of the LSTM layer. An LSTM cell state is the key component which carries the information between each LSTM block.</p><p>Modifications to the cell state are controlled with the three gates described above. The single cell, as well as the gates, are interconnected and connected to the cell state itself. Figure <ref type="figure" target="#fig_9">2</ref> shows the LSTM single cells over time. The single cell layer is presented 275 at time t, where X t and Y t are the input and output states, respectively. Data from each sensor reported in Table <ref type="table" target="#tab_1">2</ref> represent the input, while the different activities for each dataset represent the output (see Table <ref type="table" target="#tab_3">4</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3.">Bi-LSTM</head><p>The Bi-LSTM [59] includes two parallel LSTM tracks defined by forward and 280 backward loops, which extract patterns from the past and the future, in order to better model time dependency (see Figure <ref type="figure" target="#fig_12">3</ref>). The forward track (green arrow) reads the input data X t from left to right, whereas the backward track (red arrow) reads the input data from right to left. The output prediction is the weighted sum of the prediction score,   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4.">Casc-LSTM</head><p>The cascade architecture is inspired by <ref type="bibr">[60]</ref>. The input layer is a Bi-LSTM cascaded with the Uni-LSTM. Thus, the output of one-layer Bi-LSTM is considered as the features vector to feed into the Uni-LSTM (see Figure <ref type="figure" target="#fig_14">4</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.5.">Ens2-LSTM 290</head><p>The Ens2-LSTM aims to combine the output of a Bi-LSTM and Uni-LSTM. In particular, the softmax function combines the output of the two models in order to predict human activity (see Figure <ref type="figure" target="#fig_16">5</ref>).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.6.">CascEns-LSTM</head><p>The CascEns-LSTM is the cascade of the Ens2-LSTM and Uni-LSTM. In particu-295 lar, the Ens2-LSTM prediction represents the input vector to feed into the Uni-LSTM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental</head><p>The same experimental setup employed in <ref type="bibr" target="#b15">[16]</ref> was designed (see Figure <ref type="figure">7</ref>) in order to perform a fair comparison between our LSTM approach and the HMM, CRF, and NB approaches. Hence, a stratified (over class) threefold cross-validation procedure was 300 performed, and the accuracy result is the average of all folds. The hyperparameters were optimised with a hold-out procedure. Twenty percent of the training data was used as validation data and was not considered for training the model. The sparse categorical cross-entropy loss was evaluated in order to select the best hyperparameters.  Different configurations in the number of units (i.e., 32, 64, and 128) and the learning 305 rate were considered as common hyperparameters of the LSTM-based models. Hence, a configuration of n = 64 was found to be the optimal compromise to avoid overfitting and achieving a low generalisation error. Based on the analysis presented by <ref type="bibr" target="#b15">[16]</ref>, the Bosch and Kyoto1 datasets were not considered: the Bosch datasets were excluded because they are not publicly available, while the Kyoto1 dataset has a limited number 310 of occurrences/samples.  Figure <ref type="figure">9</ref> shows the averaged accuracy of each fold and the related standard deviation for all the LSTM-based models. They achieved an accuracy of above 65% and significantly higher-than-chance level (i.e., 1/number of classes). Even if each LSTM model, except Casc-LSTM for Cairo, Kyoto2, and Kyoto3, obtained very similar results, the Bi-LSTM was the most effective methodology for the Cairo and Kyoto2 320 datasets. However, the Ens2-LSTM achieved the best accuracy for the largest datasets, in terms of number of observations for each class (e.g., Milan, Kyoto3, and Kyoto4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>The overall results of the LSTM approaches are also reported in Table <ref type="table" target="#tab_4">5</ref>, in terms of averaged precision, recall, and f1-score. Although all datasets are highly unbalanced, the precision, recall, and f1-score follow the same trend of accuracy.        Figure <ref type="figure" target="#fig_24">12</ref> shows the computation time for testing the LSTM-based methodologies, considering the five employed datasets. The testing time was averaged over the threefold cross-validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Computation time</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Comparison with other DL approaches 345</head><p>The proposed LSTM-based methodologies were compared with respect to onedimensional CNN, widely employed for HAR, using multimodal time series data <ref type="bibr" target="#b30">[31,</ref><ref type="bibr">38]</ref>. Table <ref type="table" target="#tab_5">6</ref> shows the CNN results for each dataset, as compared with the standard 360 Uni-LSTM.</p><p>The Uni-LSTM overcomes all the CNN-based models for all the considered datasets. This can be explained by the potential of LSTM to capture long-term temporal dependencies of human action, achieving the best human activity prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>Figure <ref type="figure" target="#fig_25">13</ref> shows the confusion matrices of the CNN-based models for the Milan 365 dataset. It is noted that the misclassified activities increase by employing CNN models.</p><p>Generally, the CNN1 model was less affected by class unbalance and performed better than the CNN2 and CNN3 models for the Milan dataset. In addition to the misclassified activities in common with LSTM approaches (i.e., Bed to toilet as Bathing, Eat as Other), CNN models were unable to correctly classify Take medicine and Work, which Below, the percentage number of occurrences for each class is reported: Bathing = 14.95%, Bed to toilet = 2.09%, Cook = 13.03%, Eat = 0.52%, Leave home = 5.03%, Relax = 10.06%, Sleep = 2.26%, Take medicine = 1.41%, Work = 1.81%, and Other = 48.84%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Comparison with other ML approaches</head><p>Table <ref type="table" target="#tab_6">7</ref> shows the comparison between the proposed LSTM approach and the ML methods employed in <ref type="bibr" target="#b15">[16]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion and Conclusions</head><p>The results presented in this paper show that the applied DL approach based on LSTM can lead to a viable solution to improve significantly the ADLs' recognition 380 task in the smart home scenario.</p><p>In particular, after a comprehensive comparison with the best recent literature focused on HAR techniques, the LSTM methodology applied to the CASAS datasets evidently outperforms both alternative DL approaches (i.e., DNN, CNN) and existing traditional ML techniques (i.e., NB, HMM, CRF).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>385</head><p>Starting from the standard LSTM formulation, we explored more complex LSTMbased models in order to improve the generalisation performance of HAR prediction.</p><p>However, the increase in complexity did not always lead to a significant improvement of performance. Even if the metrics of all proposed LSTM models (excluding Casc-LSTM for Kyoto2) are very close to each other for every dataset, the best results were information is typically also useful for HAR. The Bi-LSTM exploits all available input information in the past and future of a specific time frame. Moreover, the Ens2-LSTM slightly overcomes the Bi-LSTM in all datasets with the higher number of occurrences (i.e., Milan, Kyoto3, and Kyoto4; see Table <ref type="table" target="#tab_2">3</ref>). However, a unique best performer were monitored. This suggests that in future works, the proposed approach has considerable opportunities for improvement and could be easily adapted and implemented for better multi-user activity recognition. Hence, a multi-task approach may be proposed for discriminating ADLs while learning the subject variability.</p><p>The performed comparison with respect to the one-dimensional CNN outlines the 410 main advantage of the proposed methodology. The geometry of convolutional kernels restricts the captured range of dependencies between data samples, while the LSTM overcomes this limitation by exploiting their internal memories to capture long-range dependencies in variable-length input sequences.</p><p>The comparison with respect to traditional ML literature employed in <ref type="bibr" target="#b15">[16]</ref> outlines 415 the ability of the LSTM to automatically extract spatio-temporal information while reducing the time-consuming effort for preprocessing data and handcrafted features extraction. For instance, considering the same setting (i.e., Kyoto), the most improvement of the LSTM with respect to ML was achieved in Kyoto4, where a higher number of test days and activities were considered. This is in line with the advantage of DL 420 approaches in terms of learning a representation of a huge amount of data with a large number of classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>18 .</head><label>18</label><figDesc>39% of accuracy improvement).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>100</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>105</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>125</head><label></label><figDesc>nition approach by clustering-based classification. They combined the k-NN with the Dempster-Shafer theory of evidence to discriminate and split activity instances of different classes enclosed inside a unique cluster. A Markov logic network was designed A C C E P T E D M A N U S C R I P T</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>210residents, R1 and R2, when they performed normal daily activities. The sensor layout comprised M, D, and T sensors, a burner sensor (AD1-A), a hot water sensor (AD1-B), a cold water sensor (AD1-C), an item sensor (I) for selected items in the kitchen, and an electricity usage sensor (P001).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>230</head><label></label><figDesc>from the CASAS datasets. The input features were the raw data collected from different smart home sensors (e.g., M, D, T). Considering the time lapse from the beginning to the end of the human activity, the data aggregation was performed in order to encapsulate all changes in sensor status. This processing led to associate an input matrix of sensor events for each activity. The input data was fed into the LSTM-based model 235 in order to predict the class-membership. A brief background of the LSTM model is provided in Section 3.3.1. Afterwards, we investigated more details of the LSTM by not only implementing and testing the standard Uni-LSTM (see Section 3.3.2) but also considering more complex architectures such as Bi-LSTM (see Section 3.3.3) and Casc-LSTM (see Section 3.3.4). Moreover, we presented two different ensemble strate-240 gies named Ens2-LSTM and CascEns-LSTM. The former combined the output of a Bi-LSTM and LSTM (see Section 3.3.5), while in the latter, the output of the Ens2-LSTM was fed into an LSTM (see Section 3.3.6). These ensemble strategies aim to improve the generalisation performance while learning more complex patterns from data. A C C E P T E D M A N U S C R I P T</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The proposed HAR approach. Different data modalities acquired by different sensors are fed into the LSTM-based model in order to predict human activity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>265 3 . 3 . 2 .</head><label>332</label><figDesc>Uni-LSTMIn order to classify the action time series, the use of an RNN architecture with one hidden layer of LSTM cells is proposed. The input layer of this RNN comprises an embedded vector that contains the sequence of sensor events. Then, n LSTM cells are fully connected to these inputs and have recurrent connections with all the LSTM 270 cells. A dense output layer performs the classification task. The number of cells (n) and the learning rate are the common hyperparameters for all LSTM-based approaches selected in the validation procedure. The RMSProp optimiser [58] was used for training the network and minimising the categorical cross entropy loss function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overview of the unidirectional LSTM (Uni-LSTM) architecture, comprising one input, hidden, and output layer: X represents the binary vector for sensor inputs, and Y represents the activity label prediction of the LSTM network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>285</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Bidirectional LSTM-based (Bi-LSTM) architecture [59], comprising one input, hidden, and output layer. The forward and backward tracks are defined for each layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Cascaded bidirectional and unidirectional LSTM-based (Casc-LSTM) architecture [60]. The upper layers are unidirectional, whereas the input layer is bidirectional. We set one hidden unidirectional layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 8</head><label>8</label><figDesc>Figure 8 reports the training and validation accuracy of Uni-LSTM for different numbers of units (i.e., n = 32, n = 64, and n = 128). The lowest generalisation error in the validation set was achieved with n = 64.315</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Ensemble2LSTM (Ens2-LSTM) architecture. The unidirectional and bidirectional models comprise of one input, hidden, and output layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>325</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 10</head><label>10</label><figDesc>Figure 10 shows the confusion matrices for the Milan dataset, obtained by each different LSTM model. Although most of the considered activities were correctly classified, the most relevant errors can be summarised as follows: (i) Bed to toilet as Bathing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: CascadeEnsemble (CascEns-LSTM) architecture. The unidirectional and bidirectional models comprise one input, hidden, and output layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 7 :Figure 8 :Figure 9 :</head><label>789</label><figDesc>Figure 7: Classification stage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 10 : 4 Figure 11 :</head><label>10411</label><figDesc>Figure 10: Confusion matrices of the Milan dataset for Uni-LSTM (Figure 10a), Bi-LSTM (Figure 10b), Casc-LSTM (Figure 10c), Ens2-LSTM (Figure 10d), and CascEns-LSTM (Figure 10e) approaches: rows are the true classes; columns are the predicted ones. Below, the percentage number of occurrences for each class is reported: Bathing = 14.95%, Bed to toilet = 2.09%, Cook = 13.03%, Eat = 0.52%, Leave home = 5.03%, Relax = 10.06%, Sleep = 2.26%, Take medicine = 1.41%, Work = 1.81%, and Other = 48.84%.</figDesc><graphic coords="23,231.59,452.18,103.45,88.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 11 shows</head><label>11</label><figDesc>Figure 11 shows the box plot of the computation time, for each epoch, for the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Computation time testing phase averaged over the threefold cross-validation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Confusion matrices of the Milan dataset for CNN1 (Figure 13b), CNN2 (Figure 13c), and CNN3 (Figure 13d) approaches: rows are the true classes; columns are the predicted ones.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>390</head><label></label><figDesc>achieved by Bi-LSTM and Ens2-LSTM models. This result confirms how future inputA C C E P T E D M A N U S C R I P T</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>395</head><label></label><figDesc>model did not emerge across the different CASAS datasets, which display several reallife challenges. Even though the nature of the collected data is the same, other factors may have affected the performance of the LSTM models, such as the number of residents, the number and type of sensors, the number of different activities, and the duration of test days. Additionally, the proposed LSTM methodology is consistent with the 400 highly unbalanced setting of the smart home dataset, without requiring data augmentation techniques. Results show that the LSTM approaches are able to better generalise across different samples of the same user. This is the case of the Milan dataset, where there was only one inhabitant. Accordingly, the performance of the LSTM models decreased in the Cairo and Kyoto datasets, where the activities of two/three residents 405</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="38,132.47,162.02,289.38,289.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="39,132.55,151.02,289.38,289.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="40,132.97,151.27,249.01,249.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Smart home datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="4"># Houses Residents # Sensors # Activities</cell></row><row><cell>CASAS [41]</cell><cell>7</cell><cell>Multi</cell><cell>20 -86</cell><cell>11</cell></row><row><cell>Kasteren [50]</cell><cell>3</cell><cell>Multi</cell><cell>14 -21</cell><cell>14 -16</cell></row><row><cell>Domus [51]</cell><cell>1</cell><cell>Single</cell><cell>78</cell><cell>User's feelings</cell></row><row><cell>ARAS [52]</cell><cell>2</cell><cell>Multi</cell><cell>20</cell><cell>27</cell></row><row><cell>HIS [53]</cell><cell>1</cell><cell>Multi</cell><cell>20 -30</cell><cell>7</cell></row><row><cell cols="2">OPPORTUNITY [54] 1</cell><cell>Multi</cell><cell>72</cell><cell>15 -20</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Example of sensors data representation.</figDesc><table><row><cell>Date-Time</cell><cell cols="2">Sensor State/Value</cell></row><row><cell>02/02/2009 12:18:44</cell><cell>M16</cell><cell>On</cell></row><row><cell>02/02/2009 12:18:46</cell><cell>M17</cell><cell>Off</cell></row><row><cell>02/02/2009 12:28:50</cell><cell>D12</cell><cell>Open</cell></row><row><cell>02/02/2009 12:29:55</cell><cell>I03</cell><cell>Present</cell></row><row><cell cols="2">05/02/2009 08:05:52 AD1-B</cell><cell>0.0448835</cell></row><row><cell>05/02/2009 12:21:51</cell><cell>D09</cell><cell>Closed</cell></row><row><cell>10/02/2009 17:03:57</cell><cell>I03</cell><cell>Absent</cell></row><row><cell>. . .</cell><cell>. . .</cell><cell>. . .</cell></row></table><note><p>• the Kyoto datasets contain sensor data collected in an apartment that housed two</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>CASAS datasets.The different activities for each dataset are summarized in Table4. According to the configuration used in<ref type="bibr" target="#b15">[16]</ref>, the original activities listed below for each dataset have been grouped into 11 activities of daily living (ADL) to make a consistent comparison 220 of the results. Moreover, this choice is motivated by the fact that the selected activities occur in the majority of the investigated datasets and are typically used to discriminate the functional health of an individual within a clinical scenario. Therefore, the chosen activity classes are as follows: Personal hygiene, Sleep, Bed to toilet, Eat, Cook, Work, Leave home, Enter home, Relax, Take medicine, and Bathing. Activities not rep-</figDesc><table><row><cell>CASAS Dataset</cell><cell>Milan</cell><cell>Cairo</cell><cell>Kyoto2</cell><cell>Kyoto3</cell><cell>Kyoto4</cell></row><row><cell>Residents</cell><cell>1+pet</cell><cell>2+pet</cell><cell>2</cell><cell>3</cell><cell>3</cell></row><row><cell>Sensors</cell><cell>32</cell><cell>27</cell><cell>71</cell><cell>86</cell><cell>72</cell></row><row><cell>Type of sensor</cell><cell>M,T,D</cell><cell>M,T</cell><cell>M,T,D,I,P001 AD1-A/B/C</cell><cell>M,T,D,I,P001 AD1-A/B/C</cell><cell>M,T,D,I,P001 AD1-A/B/C</cell></row><row><cell>Activities</cell><cell>15</cell><cell>13</cell><cell>13</cell><cell>12</cell><cell>25</cell></row><row><cell cols="2">Activity occurrences 1513</cell><cell>600</cell><cell>497</cell><cell>1342</cell><cell>844</cell></row><row><cell>Days</cell><cell>92</cell><cell>56</cell><cell>46</cell><cell>64</cell><cell>250</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>ADLs of the tested CASAS datasets.</figDesc><table><row><cell></cell><cell>Milan</cell><cell>Cairo</cell><cell>Kyoto2</cell><cell>Kyoto3</cell><cell>Kyoto4</cell></row><row><cell>Bathing</cell><cell>Master Bathroom Guest Bathroom</cell><cell>-</cell><cell>-</cell><cell>R1 Shower R2 Shower</cell><cell>R1 Bathing R2 Bathing</cell></row><row><cell>Bed to toilet</cell><cell>Bed to Toilet</cell><cell>Bed to Toilet</cell><cell>R1 Bed to Toilet R2 Bed to Toilet</cell><cell>Bed to Toilet</cell><cell>R1 Bed to Toilet R2 Bed to Toilet</cell></row><row><cell>Cook</cell><cell>Kitchen Activity</cell><cell>-</cell><cell>Meal Preparation</cell><cell>Cooking</cell><cell>R1 Meal Preparation R2 Meal Preparation</cell></row><row><cell>Eat</cell><cell>Dining Rm Activity</cell><cell>Breakfast Dinner Lunch</cell><cell>-</cell><cell>-</cell><cell>R1 Eating R2 Eating</cell></row><row><cell>Enter home</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>R1 Enter Home R2 Enter Home</cell></row><row><cell>Leave home</cell><cell>Leave Home</cell><cell>Leave Home</cell><cell>-</cell><cell>-</cell><cell>R1 Leave Home R2 Leave Home</cell></row><row><cell cols="2">Personal hygiene -</cell><cell>-</cell><cell>R1 Personal Hygiene R2 Personal Hygiene</cell><cell>-</cell><cell>R1 Personal Hygiene R2 Personal Hygiene</cell></row><row><cell>Relax</cell><cell>Read Watch TV</cell><cell>-</cell><cell>Watch TV</cell><cell>-</cell><cell>R1 Watch TV R2 Watch TV</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>R1 Sleep</cell></row><row><cell>Sleep</cell><cell>Sleep</cell><cell>R1 Sleep R2 Sleep</cell><cell>R1 Sleep R2 Sleep</cell><cell>R1 Sleep R2 Sleep</cell><cell>R1 Sleeping Not in Bed R2 Sleep</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>R2 Sleeping Not in Bed</cell></row><row><cell>Take medicine</cell><cell>Morning Meds Evening Meds</cell><cell cols="2">R2 Take medicine -</cell><cell>-</cell><cell>-</cell></row><row><cell>Work</cell><cell>Chores Desk Activity</cell><cell>R1 Work in Office Laundry</cell><cell>Clean R1 Work R2 Work</cell><cell>Cleaning R1 Work R2 Work</cell><cell>R1 Work R2 Work R1 Housekeeping</cell></row><row><cell>Other</cell><cell>Master Bedroom Meditate</cell><cell>R1 Wake Night Wandering R2 Wake</cell><cell>Study Wash Bathtub</cell><cell>Grooming R1 Wake R2 Wake</cell><cell>R1 Wandering in Room R2 Wandering in Room</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>LSTM results: accuracy, precision, recall, and f1-score for each of the five datasets.</figDesc><table><row><cell cols="2">Metric Model</cell><cell>Dataset</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">Milan Cairo Kyoto2 Kyoto3 Kyoto4</cell></row><row><cell></cell><cell>LSTM</cell><cell>93.42 83.75 69.76</cell><cell>88.71</cell><cell>85.57</cell></row><row><cell>Accuracy (%)</cell><cell>Bi-LSTM Casc-LSTM Ens2-LSTM</cell><cell>94.12 86.90 74.37 92.55 79.94 66.92 94.24 86.23 74.22</cell><cell>93.25 85.42 93.38</cell><cell>85.82 83.97 86.02</cell></row><row><cell></cell><cell cols="2">CascEns-LSTM 93.60 83.66 70.06</cell><cell>88.47</cell><cell>85.20</cell></row><row><cell></cell><cell>LSTM</cell><cell>93.67 83.33 70.00</cell><cell>88.67</cell><cell>85.67</cell></row><row><cell>Precision (%)</cell><cell>Bi-LSTM Casc-LSTM Ens2-LSTM</cell><cell>94.00 86.67 75.00 92.00 79.33 68.33 94.33 86.33 74.67</cell><cell>93.33 85.67 93.67</cell><cell>86.00 83.67 86.33</cell></row><row><cell></cell><cell cols="2">CascEns-LSTM 93.33 84.33 70.33</cell><cell>86.67</cell><cell>85.00</cell></row><row><cell></cell><cell>LSTM</cell><cell>93.67 82.33 71.00</cell><cell>88.33</cell><cell>85.33</cell></row><row><cell>Recall (%)</cell><cell>Bi-LSTM Casc-LSTM Ens2-LSTM</cell><cell>94.00 87.00 74.33 92.67 80.00 67.00 94.33 86.33 74.33</cell><cell>93.33 85.67 93.33</cell><cell>86.00 84.00 86.00</cell></row><row><cell></cell><cell cols="2">CascEns-LSTM 93.33 84.00 70.33</cell><cell>88.00</cell><cell>85.33</cell></row><row><cell></cell><cell>LSTM</cell><cell>93.33 83.33 69.67</cell><cell>88.33</cell><cell>85.33</cell></row><row><cell>f1-score (%)</cell><cell>Bi-LSTM Casc-LSTM Ens2-LSTM</cell><cell>94.00 86.67 74.33 92.00 78.67 66.00 94.00 86.00 73.67</cell><cell>93.33 85.33 93.33</cell><cell>86.00 83.33 86.00</cell></row><row><cell></cell><cell cols="2">CascEns-LSTM 93.33 83.67 69.67</cell><cell>88.33</cell><cell>85.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>CNN results: accuracy, precision, recall, and f1-score for each of the five datasets.</figDesc><table><row><cell cols="2">Metric Model</cell><cell>Dataset</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">Milan Cairo Kyoto2 Kyoto3 Kyoto4</cell></row><row><cell>Accuracy (%)</cell><cell cols="2">Uni-LSTM 93.42 83.75 69.76 CNN1 75.03 70.67 58.56 CNN2 68.33 74.16 58.54 CNN3 62.50 69.23 49.65</cell><cell>88.71 77.68 73.92 71.93</cell><cell>85.57 69.39 61.82 59.34</cell></row><row><cell>Precision (%)</cell><cell cols="2">Uni-LSTM 93.67 83.33 70.00 CNN1 73.67 70.00 57.00 CNN2 64.33 73.33 59.33 CNN3 61.66 66.33 50.33</cell><cell>88.67 76.33 71.66 71.66</cell><cell>85.67 67.00 59.33 58.00</cell></row><row><cell>Recall (%)</cell><cell cols="2">Uni-LSTM 93.67 83.67 70.00 CNN1 75.00 70.67 58.67 CNN2 68.33 74.00 58.67 CNN3 62.66 69.33 49.67</cell><cell>88.67 77.67 73.67 72.00</cell><cell>85.67 69.33 62.00 59.33</cell></row><row><cell>f1-score (%)</cell><cell cols="2">Uni-LSTM 93.33 83.33 69.67 CNN1 73.66 69.67 57.33 CNN2 65.66 72.66 57.67 CNN3 61.66 67.00 49.33</cell><cell>88.33 76.67 72.33 71.33</cell><cell>85.33 67.00 56.67 58.67</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>NB, HMM, CRF, and LSTM recognition accuracies for each of the five datasets.The LSTM model outperformed ML methods for all considered datasets. For Milan 375 and Kyoto4, the LSTM achieved the highest improvement (Milan: 16.77%, 15.98%, 32.41%; Kyoto4: 22.30%, 24.67%, 27.16%) compared to NB, HMM, and CRF.</figDesc><table><row><cell>Dataset</cell><cell>NB (%)</cell><cell>HMM (%)</cell><cell>CRF (%)</cell><cell>LSTM (%)</cell></row><row><cell>Milan</cell><cell>76.65</cell><cell>77.44</cell><cell>61.01</cell><cell>93.42</cell></row><row><cell>Cairo</cell><cell>82.79</cell><cell>82.41</cell><cell>68.07</cell><cell>83.75</cell></row><row><cell>Kyoto2</cell><cell>63.98</cell><cell>65.79</cell><cell>66.20</cell><cell>69.76</cell></row><row><cell>Kyoto3</cell><cell>77.50</cell><cell>81.67</cell><cell>87.33</cell><cell>88.71</cell></row><row><cell>Kyoto4</cell><cell>63.27</cell><cell>60.90</cell><cell>58.41</cell><cell>85.57</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>Future work could also test other similar datasets (e.g., <ref type="bibr" target="#b49">[50]</ref>) that have already been used in literature for the HAR task <ref type="bibr" target="#b30">[31]</ref>.</p><p>In conclusion, given the evidenced, almost-equal HAR task performance, it would 425 be advisable to prefer the LSTM-based model that offers fewer parameter complexities and computational costs. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Social inclusion in ambient assisted living 430 environments: Home automation and convenience services for elderly user</title>
		<author>
			<persName><forename type="first">C</forename><surname>Röcker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ziefle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Holzinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="55" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">World report on ageing and health</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>World Health Organization</publisher>
			<pubPlace>Geneva Switzerland</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sensor-based activity recogni-435 tion</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Nugent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="790" to="808" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Satpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mathew</surname></persName>
		</author>
		<title level="m">Technology to Aid Aging in Place -New Opportunities and Challenges</title>
		<meeting><address><addrLine>Saarbrücken, Germania</addrLine></address></meeting>
		<imprint>
			<publisher>VDM Verlag</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Ambient intelligence and smart en-440 vironments: A state of the art</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Augusto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nakashima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Aghajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Handbook of Ambient Intelligence and Smart Environments</title>
		<imprint>
			<biblScope unit="page" from="3" to="31" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Augusto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Jakkula</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ambient intelligence: Technologies, applications, and opportunities</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="277" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A review on applications of activity recognition systems with regard to performance and evaluation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ranasinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Al Machot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Mayr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Distributed Sensor Networks</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">1550147716665520</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Sonar: Smart ontology activity recognition framework to fulfill semantic web in smart homes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zolfaghari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Keyvanpour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second International 450 Conference on Web Research</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="139" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Transfer learning for activity recognition: A survey</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Feuz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="537" to="556" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Group level activity recognition in crowded environments across multiple cameras</title>
		<author>
			<persName><forename type="first">M.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Krahnstoever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh IEEE International 455 Conference on Advanced Video and Signal Based Surveillance</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="56" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi-sensor surveillance of indoor environments by an autonomous mobile robot</title>
		<author>
			<persName><forename type="first">D</forename><surname>Di Paola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Naso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Milella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cicirelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Distante</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Intelligent Systems Technologies and Applications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="18" to="35" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Combining ontological and temporal formalisms for composite activity modelling and recognition in smart homes</title>
		<author>
			<persName><forename type="first">G</forename><surname>Okeyo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="29" to="43" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Recent trends in machine learning for human activity recognition-A survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ramasamy Ramamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wiley Interdisciplinary Reviews: Data Mining 465 and Knowledge Discovery</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">1254</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A data-driven approach for event prediction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="707" to="720" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Kcar: A knowledge-driven approach for concurrent activity recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dobson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pervasive and Mobile Computing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="47" to="70" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning setting-generalized activity models for smart spaces</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="38" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Feature space analysis for human activity recognition in smart environments</title>
		<author>
			<persName><forename type="first">E</forename><surname>Chinellato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Hogg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th International Conference on Intelligent Environments</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="194" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Activity recognition in smart homes using clustering based classification</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Fahad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Tahir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rajarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">22nd International Conference on Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1348" to="1353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Activity discovery and activity recognition: A new partnership</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rashidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">828</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An autonomic context management system for pervasive computing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Indulska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth Annual IEEE International Conference on Pervasive Computing and Communications</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="213" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sensor-based adaptive activity recognition with dynamically 485 available sensors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">218</biblScope>
			<biblScope unit="page" from="307" to="317" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Activity recognition in smart homes with self verification of assignments</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Fahad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rajarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">149</biblScope>
			<biblScope unit="page" from="1286" to="1298" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Analysis and effects of smart home dataset characteristics for daily life activity recognition</title>
		<author>
			<persName><forename type="first">I</forename><surname>Fatima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fahim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Supercom-490 puting</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="760" to="780" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hierarchical modeling for first-person vision activity recognition</title>
		<author>
			<persName><forename type="first">G</forename><surname>Abebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cavallaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">267</biblScope>
			<biblScope unit="page" from="362" to="377" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">From action to activity: Sensor-based activity recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Rosenblum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="page" from="108" to="115" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Improving the recognition of interleaved activities</title>
		<author>
			<persName><forename type="first">J</forename><surname>Modayil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th international conference on Ubiquitous Computing</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="40" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Modeling temporal interactions with interval temporal bayesian networks for complex activity recog-500 nition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Swears</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Larios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2468" to="2483" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Pose recognition using convolutional neural networks on omni-directional images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Georgakopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kottari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Delibasis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Plagianakos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Maglogiannis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">280</biblScope>
			<biblScope unit="page" from="23" to="31" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multitask autoencoder model for recovering human poses</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="5060" to="5068" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multimodal deep autoencoder for human pose recovery</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5659" to="5670" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Convolutional and recurrent neural networks for activity recognition in smart environment</title>
		<author>
			<persName><forename type="first">D</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Merdivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hanke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kropf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Geist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Holzinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Towards Integrative Machine Learning and Knowledge Extraction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="194" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning deep generative models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Statistics 515 and its Application</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="361" to="385" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A robust human activity recognition system using smartphone sensors and deep learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>Uddin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Almogren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="307" to="313" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep learning for sensor-based activity 520 recognition: A survey</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">3D convolutional neural networks for human action recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="221" to="231" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Adaptive activation functions in 525 convolutional neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">San</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">272</biblScope>
			<biblScope unit="page" from="204" to="212" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The euclidean embedding learning based on convolutional neural network for stereo matching</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>You</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.08880</idno>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">267</biblScope>
			<biblScope unit="page" from="195" to="200" />
			<date type="published" when="2016">2017. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep recurrent neural networks for human activity recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Murad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Pyun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="25" to="56" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Human activity analysis: A review</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Ryoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Assessing the quality of activities in a smart environment</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schmitter-Edgecombe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods of Information in Medicine</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">480</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Nugent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoey</surname></persName>
		</author>
		<title level="m">Activity recognition in Pervasive Intelligent Environments</title>
		<imprint>
			<publisher>Springer Science &amp; Business Media</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A unified framework for activity 540 recognition-based behavior analysis and action prediction in smart homes</title>
		<author>
			<persName><forename type="first">I</forename><surname>Fatima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fahim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="2682" to="2699" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Probabilistic ontology based activity recognition in smart homes using markov logic network, Knowledge-Based Systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gayathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Easwarakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Elias</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="173" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">CRAFFT: An activity prediction model based on bayesian networks</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nazerfard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Ambient Intelligence and Humanized Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="193" to="205" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning temporal context for activity recognition</title>
		<author>
			<persName><forename type="first">C</forename><surname>Coppola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Krajník</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Duckett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bellotto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">22nd European Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">550</biblScope>
			<biblScope unit="page" from="107" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Forecasting occurrences of activities</title>
		<author>
			<persName><forename type="first">B</forename><surname>Minor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pervasive and Mobile Computing</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="77" to="91" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Recognizing human activity in smart home using deep learning algorithm</title>
		<author>
			<persName><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">rd Chinese Control Conference</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="4716" to="4720" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<author>
			<persName><surname>A C C E P T E D M A N U S C R I P T</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Sequential deep learning for human action recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Baccouche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mamalet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Baskurt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Human Behavior Understanding</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="29" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Human activity recognition from wireless sensor network data: Benchmark and software</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Van Kasteren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Englebienne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Kröse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Activity Recognition 560 in Pervasive Intelligent Environments</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="165" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Using the multicom domus dataset</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gallissot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Caelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bonnefond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Meillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pons</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
		<respStmt>
			<orgName>Laboratoire d&apos;Informatique de Grenoble</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Alemdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ertan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">D</forename><surname>Incel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ersoy</surname></persName>
		</author>
		<title level="m">Seventh International Conference on 565 Pervasive Computing Technologies for Healthcare</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="232" to="235" />
		</imprint>
		<respStmt>
			<orgName>Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering</orgName>
		</respStmt>
	</monogr>
	<note>ARAS human activity datasets in multiple homes with multiple residents</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Supervised classification of activities of daily living in health smart homes using svm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fleury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Noury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of the IEEE 570 Engineering in Medicine and Biology Society</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="6099" to="6102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Collecting complex activity datasets in highly rich networked sensor environments</title>
		<author>
			<persName><forename type="first">D</forename><surname>Roggen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Calatroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Holleczek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Förster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tröster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lukowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bannach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pirkl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ferscha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh International Conference on Networked Sensing Systems</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schmitter-Edgecombe</surname></persName>
		</author>
		<author>
			<persName><surname>Casas Datasets</surname></persName>
		</author>
		<ptr target="http://ailab.wsu.edu/casas/datasets/" />
		<imprint>
			<date type="published" when="2018-09-06">06 September 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning precise timing with 580 lstm recurrent networks</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Schraudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="115" to="143" />
			<date type="published" when="2002-08">Aug. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Biography of the authors Daniele Liciotti received the B.Sc. degree in Computer and Automation Engineering from Polytechnic University of Marche with a thesis entitled &quot;Analisi di modelli dinamici per turbine eoliche</title>
		<author>
			<persName><surname>A C C E P T E D M A N U S C R I P T</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>supervisor Prof. Giuseppe Orlando</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Sc. degree in Computer and Automation Engineering from the Polytechnic University of Marche with a thesis entitled</title>
	</analytic>
	<monogr>
		<title level="m">From November 2014 to October 2017 he was a Ph</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>Analisi automatica del comportamento dei consumatori in ambienti di retail intelligenti. supervisor Prof. Emanuele Frontoni. D. Student at Polytechnic University of Marche, under the supervision of Prof. Emanuele Frontoni</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Michele Bernardini received the B.Sc. degree in Biomedical Engineering from the Polytechnic University of Marche with a thesis entitled &quot;Ischemia miocardica acuta: dall&apos; attivazione elettrica del cuore al segnale ECG</title>
		<imprint/>
	</monogr>
	<note>supervisor Prof. Laura Burattini</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">he received the M.Sc. degree in Electronic Engineering from the Polytechnic University of Marche with a thesis entitled &quot;Development of an automatic procedure to mechanically characterize soft tissue materials using visual sensors</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>in collaboration with Université Libre de Bruxelles (supervisors: Prof. Bernardo Innocenti, Prof. Emanuele Frontoni</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m">Since November 2017 he is Ph.D. Student at Polytechnic University of Marche (supervisor Prof. Emanuele Frontoni)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Luca Romeo received the Master of Science degree (cum laude) in Electronic Engineering at Università Politecnica delle Marche</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>with a master thesis on the analysis of human-robot interaction (Ksera project</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">From December 2017 he has a research fellowship at Università Politecnica delle Marche. He is also affiliated with the Department of CSML (Prof. Massimiliano Pontil) and C&apos;MON (Prof. Cristina Becchio) from the Italian Institute of Technology (Genova)</title>
		<author>
			<persName><forename type="first">Ai*</forename><surname>Ia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Università Politecnica delle Marche, as a Ph.D. student in &quot;Intelligent Artificial Systems&quot;. He obtained his Ph.D. in 2006 discussing a thesis on Vision-Based Robotics. His research focuses on applying computer science, artificial intelligence and computer vision techniques to mobile robots and innovative IT applications</title>
		<meeting><address><addrLine>Ancona, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">November 2014 to October 2017. 2003</date>
		</imprint>
		<respStmt>
			<orgName>D. Student in Informatic Engineering at Università Politecnica delle Marche</orgName>
		</respStmt>
	</monogr>
	<note>Emanuele Frontoni is Professor of &quot;Fondamenti di Informatica&quot; and &quot;Computer Vision&quot; at the Università Politecnica delle Marche. He received the Master degree in electronic engineering from the University of. In the same year, he joined the Dept. of Ingegneria Informatica (DIIGA</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
