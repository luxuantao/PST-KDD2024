<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On Positional and Structural Node Features for Graph Neural Networks on Non-attributed Graphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hejie</forename><surname>Cui</surname></persName>
							<email>hejie.cui@emory.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Emory University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zijie</forename><surname>Lu</surname></persName>
							<email>zijielu2@illinois.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Urbana</orgName>
								<address>
									<settlement>Champaign</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pan</forename><surname>Li</surname></persName>
							<email>panli@purdue.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Purdue University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Carl</forename><surname>Yang</surname></persName>
							<email>j.carlyang@emory.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Emory University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">On Positional and Structural Node Features for Graph Neural Networks on Non-attributed Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph neural networks (GNNs) have been widely used in various graph-related problems such as node classification and graph classification, where the superior performance is mainly established when natural node features are available. However, it is not well understood how GNNs work without natural node features, especially regarding the various ways to construct artificial ones. In this paper, we point out the two types of artificial node features, i.e., positional and structural node features, and provide insights on why each of them is more appropriate for certain tasks, i.e., positional node classification, structural node classification, and graph classification. Extensive experimental results on 10 benchmark datasets validate our insights, thus leading to a practical guideline on the choices between different artificial node features for GNNs on non-attributed graphs. The code is available at https://github.com/zjzijielu/gnn-exp/.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Graphs provide a concise yet rich representation of data across different domains such as social networks, citation networks, geneprotein interactions, molecular structures and so on. How to effectively mine valuable information underneath graph data has become an appealing problem for data mining community. Recently, various kinds of powerful Graph Neural Networks (GNNs) demonstrate their privilege on common graph tasks such as node classification <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>, link prediction <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b51">52]</ref> and graph classification <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b50">51]</ref>. GNNs combine node features and graph structures by aggregating node features through links into low-dimensional vector representations. Recently, considerable efforts have been put on studying the complicated contents of attributed networks, such as user attributes <ref type="bibr" target="#b43">[44]</ref>, node types <ref type="bibr" target="#b41">[42]</ref>, pooling layers <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b26">27]</ref>, design spaces <ref type="bibr" target="#b48">[49]</ref>, long-range dependency <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b25">26]</ref>, heterophily graph <ref type="bibr" target="#b53">[54]</ref>, subgraph contexts <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b44">45]</ref>, robust graph representation <ref type="bibr" target="#b37">[38]</ref>, informativeness of nodes <ref type="bibr" target="#b17">[18]</ref> and so on, where the superior performances are mainly established when natural node features (i.e., attributes) are available.</p><p>However, a great number of graphs in the wild do not contain node attributes <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b9">10]</ref>, which deteriorates the performance of GNNs <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11]</ref>. For example, in the molecules dataset QM9 <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b32">33]</ref>, a graph represents a molecule, i.e., nodes are atoms and edges are chemical bonds. For typical tasks on this dataset such as predicting the properties of molecules, i.e., toxicity or biological activity, GNNs cannot be directly applied under this situation due to the lack of natural node features <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>To apply GNNs on non-attributed graphs, several intuitive methods have been commonly practiced to initialize node features, such as degree-based <ref type="bibr" target="#b12">[13]</ref>, random <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b33">34]</ref>, one-hot <ref type="bibr" target="#b7">[8]</ref>, positionbased <ref type="bibr" target="#b47">[48]</ref>, distance-based <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b46">47]</ref> and so on. However, to the best of our knowledge, there exists no generic understanding or guideline towards the initialization of artificial node features based on the needs of downstream tasks. In this paper, we categorize common artificial node features and study their utility towards different types of graph mining tasks. From a high level, these intuitive node feature initialization methods can be grouped into two categories, positional and structural ones (Section 2). Take Figure <ref type="figure" target="#fig_0">1</ref> as an example. Positional features can help GNNs put node A and node B closer in the embedding space, whereas structural features facilitates putting node A and node C closer.</p><p>Extensive experiments are performed on 10 datasets with 8 common artificial features. Based on the information needs of different tasks, we further categorize them into multiple divisions, namely, positional node classification, structural node classification and graph classification (Section 3). Observations on the results validate our understanding that positional node features are more suitable for positional node classification, while structural node features benefit more for structural node classification and graph classification tasks. With appropriately designed artificial node features, the performance of GNNs can even surpass that with real features in some cases (Table <ref type="table" target="#tab_3">3</ref>). Besides, our proposed novel degree-based node feature initialization method, i.e., degree bucket range, achieves state-of-the-art performance on structural node classification (Section 2.3). We believe this empirical study on the selection of artificial node features can facilitate the understanding of feature initialization on non-attributed graphs and inspire new designs of artificial node features, thus shedding light on various GNN applications on graphs in the wild.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">TWO TYPES OF ARTIFICIAL NODE FEATURES</head><p>Several node feature initialization methods have been proposed for non-attributed graphs and commonly applied in various GNN models. We group these artificial node features into two main families: positional node features and structural node features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Positional node features</head><p>Positional node features help GNNs capture node distance information regarding their relative positions in the graph. For example, in Figure <ref type="figure" target="#fig_0">1</ref>, nodes A and B are positionally close. A real case is the publication network, where two authors who cite each other and also cite / get cited by similar other authors should be close considering their graph positions, and recognized as sharing similar research interests. Some intuitive positional node feature initialization methods include:</p><p>? random: A feature vector following random distribution is generated for each node, which is decided by the random seed in the data initialization. The random feature of each node varies among training runs with different random seeds initialization. This feature itself does not reflect relative positions, but it records a high-dimensional identity for each node, which can indirectly help GNNs learn the relative node positions. ? one-hot: A unique one-hot feature vector is initialized for each node <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b47">48]</ref>. This feature is essentially equivalent to the random feature, when the parameters in the first linear layer of the GNN are randomly initialized. ? eigen: Eigen decomposition is performed on the normalized adjacency matrix and then the top k eigen vectors are used to generate a k-dimensional feature vector for each node <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b52">53]</ref>, where the optimal value of k is decided by grid search <ref type="bibr" target="#b24">[25]</ref>. ? deepwalk: The initial feature of a node is generated based on the DeepWalk algorithm from <ref type="bibr" target="#b28">[29]</ref> with the walk length set as 40 by default. Deep walk features with walk length longer than 2 can help to capture higher-order positional information in the graph. Correspondingly, positional node classifications target at grouping nodes with respect to their positions, which corresponds to coarse global information in the graph. For example, in Figure <ref type="figure" target="#fig_0">1</ref>, nodes A and B should be classified into the same class in the task of positional node classification. Specifically, eigen and deepwalk methods which generate features by matrix decomposition <ref type="bibr" target="#b29">[30]</ref>, are essentially dimension reduction, where the complex graph structures (i.e., adjacency matrices) information are embedded into a low dimensional representation. Therefore, eigen and deepwalk methods also incorporate structural information. However, as the features based on eigen and deepwalk reflect the position of nodes, with some abuse of terminology, we keep calling them positional features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Structural node features</head><p>On the other hand, structural node features help GNNs capture structural information of nodes, such as degree information and neighborhood connection patterns. For example, in Figure <ref type="figure" target="#fig_0">1</ref>, node A and C are similar regarding their neighborhood structures in the graph, though they are far away from each other in position. A real case is the molecular network, where two nodes with similar degrees and connection patterns should be put close considering their structures, and recognized as atoms with similar properties or functions. Some intuitive node feature initialization methods focusing on the structural aspects include:</p><p>? shared: An initial feature vector is shared across all nodes <ref type="bibr" target="#b10">[11]</ref>.</p><p>The shared feature vector used in the experiments is simply a vector of all 1's. ? degree: The degree value is converted to a one-hot degree vector for each node, where the vector dimension is selected based on the max degree of all nodes <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b38">39]</ref>. ? pagerank: The original PageRank score <ref type="bibr" target="#b3">[4]</ref> of a given node is calculated and then flattened into a vector in order to fully utilize the embedding dimensions of neural networks, where the dimension of the extended vector is selected by grid-search <ref type="bibr" target="#b24">[25]</ref>. It can be viewed as generalized higher-order node degree information.</p><p>Structural node classifications target at classifying nodes according to their structural patterns. For example, nodes A and C in Figure <ref type="figure" target="#fig_0">1</ref> should be put into the same class considering their similar "structural roles". Different from positional node features that characterize the position of nodes in a graph, structural node features target at representing node structural roles. Note that recent distance-based features <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b46">47]</ref> also helps to learn node structural roles while GNNs that leverage distance-based features cannot make inference over multiple nodes in parallel, which increases the computational complexity. Interested readers may refer to the experiments in <ref type="bibr" target="#b45">[46]</ref> to check how distance-based features help with learning node structural roles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Byproduct: new SOTA for structural node classification</head><p>Motivated by our empirical studies on structural node features, we propose a novel node feature initialization method based on bucketing node degrees, which we name as degree+. Specifically, we divide degree values into several buckets, then map the degree values distributed in each bucket range into one class, and finally construct a unique one-hot vector for each class. Our proposed degree+ feature can be regarded as an improved version of the original degree-based node feature, which better handles the sparse and skewed distribution of node degrees in the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Basic settings</head><p>To conduct a fair and unbiased evaluation on the effectiveness of node features, we adopt the popular GNN of GraphSAGE <ref type="bibr" target="#b14">[15]</ref> with mean and sum aggregators for all the artificial node feature initialization methods across different types of graph mining tasks. Results with real features are also provided wherever natural node features are available. The train/test/validation split of each dataset follows the standard practice in the literature <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b31">32]</ref>. Graph level experiments are conducted with artificial features of sizes ranging from 100 to 500 with step 100. In addition, we perform comprehensive grid search for the best hyper-parameter settings including the learning rate, number of epochs and neighborhood sample size. The final performance of each feature initialization method is averaged over five runs under the optimal hyper-parameter settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Positional node classification</head><p>Definition and Datasets. The tasks of positional node classification target at predicting the "positional role" of each node <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b35">36]</ref>.</p><p>We consider three datasets for positional node classification tasks, including Cora <ref type="bibr" target="#b34">[35]</ref>, Citeseer <ref type="bibr" target="#b34">[35]</ref> and Pubmed <ref type="bibr" target="#b27">[28]</ref>. These three citation networks consist of scientific publications as nodes, which can be classified into several content categories. Edges connecting those nodes denote the citation relationships between publications.</p><p>Real features for each publication node are included in these three datasets, which are bag-of-word vectors indicating the word presence in the text content. In these three datasets, since the publications are connected by citation links, the research topic based node classification tasks should be mainly driven by the positions of nodes in the graph. Performance with the real node feature is also presented as a baseline for comparison.</p><p>Protocols. We train and test the GraphSAGE model using the same data splits as in <ref type="bibr" target="#b21">[22]</ref>, namely 20 randomly-selected samples for each class during training with an additional validation set of 500 samples. Observations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performances</head><p>? Aggregation: For positional node classification, mean aggregation shows better performance than sum aggregation. This is because mean aggregation can effectively filter out the influence of neighborhood size, which makes little contribution to and even impairs the performance on positional node classification tasks. However, shared feature plus mean aggregation gives the same embedding for every node, so the results are constantly poor with no variance. ? Cross Feature Type Comparison: For positional node classification tasks, most positional node feature initialization methods achieve much better performance than structural node feature ones. The advantage of position node features over structural node features is especially remarkable with mean aggregation. ? Within Feature Type Comparison: Among all positional node features: 1. random and one-hot initialization achieve comparable results. This is because they are essentially the same: after passing through the first layer of neural network where the parameters are randomly initialized, one-hot initialization is equivalent to random initialization except for possible differences in dimensions (e.g., on Pubmed). 2. among all positional features, deepwalk and eigen demonstrate the best performance across all the datasets, which owes to the higher-order positional information they can capture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Structural node classification</head><p>Definition and Datasets. The tasks of structural node classification target at predicting the "structural role" of each node <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17</ref>]. Here we choose three datasets for structural node classification, namely American air-traffic network, Brazilian air-traffic network and European air-traffic network <ref type="bibr" target="#b31">[32]</ref>. Given an airport node in the air-traffic network, the target is to predict passenger flow level of that node solely based on the structure of air-traffic network. These three datasets are chosen because the node labels of them indicate the structural roles (vary in four levels from hubs to switches), rather than the traditional community identifiers of nodes <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b34">35]</ref>.</p><p>Protocols. Following struc2vec <ref type="bibr" target="#b31">[32]</ref>, we use 80% of nodes for training. To highlight the performance of our novel degree+ method, we adopt logistic regression with L2 regularization to train the classifier using the representation learned by struc2vec <ref type="bibr" target="#b31">[32]</ref>, which demonstrates SOTA results on these datasets.</p><p>Performances. Experiment results of different node initialization methods on structural node classification datasets are presented in Table <ref type="table" target="#tab_1">2</ref>. Note that there is no real feature in these datasets to compare with.</p><p>Observations. tural node features, degree+ improves on degree by using a degree bucket, where nodes with degree values in a certain range are projected into one bucket. This alleviates the node degree sparsity and skewness problem. 2. shared can only capture the sizes of multi-hop neighborhoods, but loses track of specific neighborhood structures, thus performing rather poorly. 3. In contrast, pagerank can be viewed as a generalized higher-order node degree, and we conjecture that its performance deterioration arises from over-smoothing which in the worst cases renders it as similar to shared.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Graph classification</head><p>Definition and Datasets. For graph classification tasks, we consider two datasets with real node features, MUTAG <ref type="bibr" target="#b8">[9]</ref> and PRO-TEINS <ref type="bibr" target="#b2">[3]</ref> from chemical domain. In addition, we also consider two datasets without real node features, IMDB-BINARY and IMDB-MULTI <ref type="bibr" target="#b39">[40]</ref> from the social domain.</p><p>Protocols. We take advantage of the GNN comparison framework proposed in <ref type="bibr" target="#b10">[11]</ref>. On top of their experiment settings, we introduce the initialization methods, and use mean-and sum-pooling when applying GraphSAGE for graph classification.</p><p>Performances. Experiment results of different node initialization methods on graph classification datasets are presented in Table <ref type="table" target="#tab_3">3</ref>, where the real feat. is only available for MUTAG and PROTEINS.</p><p>Observations.  ? Aggregation: Similar to structural classification tasks, sum aggregation outperforms mean aggregation on graph classification tasks, since the number of neighbors contributes as an important type of structural information for graph classification tasks. ? Cross Feature Type Comparison: For graph classification, though the best performance is not consistently achieved on a particular feature initialization method across four datasets, it always falls in the category of structural node features. This is because we do not care about positional features such as the specific position of each node in graph classification tasks. Instead, similar to structural node classification task, the overall structural information of the graph plays the important role. ? Within Feature Type Comparison: 1. Among the structural node features, pagerank demonstrates better performance in most of the cases. 2. Impressively, the performances of GNN on degree on MUATG and pagerank on PROTEIN with the sum aggregator even surpass those with real features. This further demonstrates the importance of choosing the appropriate artificial node features, sometimes even when natural node features are available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>Graphs in the real world do not always have natural node features available, due to the lack of task-specific node attributes, privacy concerns and/or difficulties in data collection. In this paper, we study the usage of artificial node features when applying GNNs on non-attributed graphs. We categorize commonly used artificial node features into two groups, positional node features and structural node features, based on what kind of information they can help GNNs capture. Extensive empirical experiments are conducted across three graph mining tasks, positional node classification, structural node classification and graph classification.</p><p>The results validate our insights that positional node features are more suitable for positional node classification, while structural node features benefit more for structural node classification and graph classification tasks. We hope our empirical study can provide a generic and practical guideline for choosing the appropriate artificial node features and exploring more useful artificial features based on the needs of downstream tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>CFigure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of Position vs. Structure: A and B are "positionally close"-having relatively close positions in the global network, whereas A and C are "structurally close"having relatively similar local neighborhood structures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Positional node classification resultsization methods on the three positional node classification datasets are presented in Table1, where P and S indicate the Type of artificial node features, corresponding to Positional or Structural respectively. Aggr. denotes the aggregation method used in each GNN layer. Classification accuracy Acc.(%) is adopted here for evaluation and comparison.</figDesc><table><row><cell cols="2">Aggr. Type Feature</cell><cell>Cora Acc.(%)</cell><cell cols="2">Pubmed Citeseer Acc.(%) Acc.(%)</cell></row><row><cell></cell><cell>random</cell><cell>56.1?1.6</cell><cell>42.3?1.4</cell><cell>36.0?1.0</cell></row><row><cell>P</cell><cell>one-hot eigen</cell><cell>58.2?4.0 73.2?2.3</cell><cell>51.4?3.1 70.0?4.8</cell><cell>37.3?2.5 42.9?2.3</cell></row><row><cell>Mean</cell><cell cols="4">deepwalk 75.3?1.0 74.0?2.6 46.8?0.9</cell></row><row><cell></cell><cell>shared</cell><cell>17.9?0.0</cell><cell>38.6?0.0</cell><cell>20.2?0.0</cell></row><row><cell>S</cell><cell>degree</cell><cell>37.4?2.1</cell><cell>41.1?2.9</cell><cell>36.0?1.3</cell></row><row><cell></cell><cell cols="2">pagerank 25.2?2.4</cell><cell>39.8?1.9</cell><cell>20.5?3.4</cell></row><row><cell></cell><cell>real feat.</cell><cell>80.2?1.1</cell><cell>79.0?2.2</cell><cell>68.0?4.0</cell></row><row><cell></cell><cell>random</cell><cell>45.2?3.9</cell><cell>41.7?2.7</cell><cell>32.8?2.7</cell></row><row><cell>P</cell><cell>one-hot eigen</cell><cell>47.0?3.7 70.5?5.1</cell><cell>46.4?4.4 68.8?4.1</cell><cell>33.0?1.8 40.1?5.0</cell></row><row><cell>Sum</cell><cell cols="2">deepwalk 70.0?2.3</cell><cell>72.5?2.2</cell><cell>43.7?2.7</cell></row><row><cell></cell><cell>shared</cell><cell>17.1?5.2</cell><cell>33.3?6.4</cell><cell>22.3?4.6</cell></row><row><cell>S</cell><cell>degree</cell><cell>50.7?3.7</cell><cell>42.6?1.8</cell><cell>32.0?3.5</cell></row><row><cell></cell><cell cols="2">pagerank 27.8?4.4</cell><cell>33.0?6.3</cell><cell>23.4?1.3</cell></row><row><cell></cell><cell>real feat.</cell><cell>70.5?3.7</cell><cell>75.4?3.7</cell><cell>59.3?4.0</cell></row></table><note><p>. Experiment results of different node feature initial-</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Structural node classification results number of neighbors, which is an important structural feature in graphs. ? Cross Feature Type Comparison: For structural node classification tasks, in most cases structural node features demonstrate superiority compared with positional ones, and our proposed structural node feature degree+ manifests the most distinct advantage over other positional features, reaching the new state-of-the-art. ? Within Feature Type Comparison: 1. among all four types of struc-</figDesc><table><row><cell cols="2">Aggr. Type Initial.</cell><cell cols="3">USA-air Brazil-air Europe-air Acc.(%) Acc.(%) Acc.(%)</cell></row><row><cell></cell><cell>random</cell><cell>59.3?1.8</cell><cell>45.7?5.9</cell><cell>44.9?5.8</cell></row><row><cell>P</cell><cell>one-hot eigen</cell><cell>59.2?2.6 55.3?1.5</cell><cell>48.6?7.4 40.0?6.9</cell><cell>44.0?0.7 31.6?2.1</cell></row><row><cell>Mean</cell><cell>deepwalk</cell><cell>58.1?2.8</cell><cell>42.1?9.6</cell><cell>41.5?3.3</cell></row><row><cell></cell><cell>shared</cell><cell>25.0?0.0</cell><cell>25.0?0.0</cell><cell>25.0?0.0</cell></row><row><cell>S</cell><cell>degree degree+</cell><cell>53.8?1.9 59.2?2.7</cell><cell>48.6?4.1 60.0?3.0</cell><cell>42.7?2.7 50.6?3.9</cell></row><row><cell></cell><cell>pagerank</cell><cell>39.7?2.9</cell><cell>47.9?7.4</cell><cell>25.9?0.0</cell></row><row><cell></cell><cell>random</cell><cell>60.7?3.2</cell><cell>47.9?7.4</cell><cell>48.9?5.1</cell></row><row><cell>P</cell><cell>one-hot eigen</cell><cell>59.2?3.3 67.8?2.5</cell><cell>50.7?8.5 57.8?5.3</cell><cell>48.9?5.4 49.4?4.5</cell></row><row><cell>Sum</cell><cell>deepwalk</cell><cell>68.8?3.0</cell><cell>65.0?6.4</cell><cell>54.1?2.8</cell></row><row><cell></cell><cell>shared</cell><cell>55.7?2.0</cell><cell>61.4?4.7</cell><cell>45.4?1.0</cell></row><row><cell>S</cell><cell>degree degree+</cell><cell>63.6?3.0 69.1?2.6</cell><cell>70.0?4.1 76.4?4.1</cell><cell>58.0?3.6 61.2?3.8</cell></row><row><cell></cell><cell>pagerank</cell><cell>58.8?2.0</cell><cell>73.6?5.4</cell><cell>45.9?1.0</cell></row><row><cell>SOTA</cell><cell>struc2vec</cell><cell>63.8?1.6</cell><cell>73.6?9.6</cell><cell>58.8?3.0</cell></row></table><note><p>? Aggregation: For structural node classification tasks, sum aggregation outperforms mean aggregation because it can capture the</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Graph classification results</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Ralph</forename><surname>Abboud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>?smail ?lkan Ceylan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Grohe</surname></persName>
		</author>
		<author>
			<persName><surname>Lukasiewicz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.01179</idno>
		<title level="m">The Surprising Power of Graph Neural Networks with Random Node Initialization</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Contextual graph markov model: A deep and generative approach to graph processing</title>
		<author>
			<persName><forename type="first">Davide</forename><surname>Bacciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Federico</forename><surname>Errica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessio</forename><surname>Micheli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Protein function prediction via graph kernels</title>
		<author>
			<persName><forename type="first">Karsten</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soon</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><surname>Sch?nauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><forename type="middle">J</forename><surname>Svn Vishwanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hans-Peter</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="47" to="56" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Anatomy of a Large-Scale Hypertextual Web Search Engine</title>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Page</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Networks</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="107" to="117" />
			<date type="published" when="1998">1998. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A simple yet effective baseline for non-attribute graph classification</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusu</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Spectral clustering of graphs with general degrees in the extended planted partition model</title>
		<author>
			<persName><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Tsiatas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning on Attribute-Missing Graphs</title>
		<author>
			<persName><forename type="first">Siheng</forename><surname>Xu Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiangchao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huangjie</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ya</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivor</forename><forename type="middle">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Tsang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Supervised Community Detection with Line Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Zhengdao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisha</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. correlation with molecular orbital energies and hydrophobicity</title>
		<author>
			<persName><forename type="first">Asim</forename><surname>Kumar Debnath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosa</forename><forename type="middle">L</forename><surname>Lopez De Compadre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gargi</forename><surname>Debnath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">J</forename><surname>Shusterman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corwin</forename><surname>Hansch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of medicinal chemistry</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="786" to="797" />
			<date type="published" when="1991">1991. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">On Node Features for Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Chi Thang</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thanh</forename><forename type="middle">Dat</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ha</forename><surname>The</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hien</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Viet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hung</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Aberer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A fair comparison of graph neural networks for graph classification</title>
		<author>
			<persName><forename type="first">Federico</forename><surname>Errica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Podda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davide</forename><surname>Bacciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessio</forename><surname>Micheli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Implicit Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Fangda</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Somayeh</forename><surname>Sojoudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><forename type="middle">El</forename><surname>Ghaoui</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Inductive Representation Learning on Large Graphs</title>
		<author>
			<persName><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Representation Learning on Graphs: Methods and Applications</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Engineering Bulletin</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="52" to="74" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Inductive Representation Learning on Large Graphs</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Rolx: structural role extraction &amp; mining in large graphs</title>
		<author>
			<persName><forename type="first">Keith</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tina</forename><surname>Eliassi-Rad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sugato</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leman</forename><surname>Akoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danai</forename><surname>Koutra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">It&apos;s who you know: graph mining using recursive structural features</title>
		<author>
			<persName><forename type="first">Keith</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leman</forename><surname>Akoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tina</forename><surname>Eliassi-Rad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Graph Policy Network for Transferable Active Learning on Graphs</title>
		<author>
			<persName><forename type="first">Shengding</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingdi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc-Alexandre</forename><surname>C?t?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Combining Label Propagation and Simple Models Out-performs Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Qian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Horace</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhay</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ser-Nam</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Austin</forename><forename type="middle">R</forename><surname>Benson</surname></persName>
		</author>
		<idno>CoRR abs/2010.13993</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Optimization of Graph Neural Networks with Natural Gradient Descent</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Rasool Izadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yihao</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizhen</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE BigData</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="171" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Variational graph auto-encoders</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Bayesian Deep Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Graph Cross Networks with Vertex Infomax Pooling</title>
		<author>
			<persName><forename type="first">Maosen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ya</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivor</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Distance Encoding: Design Provably More Powerful Neural Networks for Graph Representation Learning</title>
		<author>
			<persName><forename type="first">Pan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanbang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Graph Entropy Guided Node Embedding Dimension Selection for Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Gongxu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifang</forename><surname>He</surname></persName>
		</author>
		<idno>CoRR abs/2105.03178</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Path Integral Based Convolution and Pooling for Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyu</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><forename type="middle">Guang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Li?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Rethinking pooling in graph neural networks</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Diego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amauri</forename><forename type="middle">H</forename><surname>Mesquita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Souza</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><surname>Kaski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Querydriven Active Surveying for Collective Classification</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Galileo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Namata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lise</forename><surname>London</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bert</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Mining and Learning with Graphs</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<title level="m">Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>WSDM</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Quantum chemistry structures and properties of 134 kilo molecules</title>
		<author>
			<persName><forename type="first">Raghunathan</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Pavlo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Dral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName><surname>Anatole Von Lilienfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Data</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">struc2vec: Learning node representations from structural identity</title>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">Hp</forename><surname>Leonardo Fr Ribeiro</surname></persName>
		</author>
		<author>
			<persName><surname>Saverese</surname></persName>
		</author>
		<author>
			<persName><surname>Daniel R Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Enumeration of 166 Billion Organic Small Molecules in the Chemical Universe Database GDB-17</title>
		<author>
			<persName><forename type="first">Lars</forename><surname>Ruddigkeit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruud</forename><surname>Van Deursen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Louis</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><surname>Reymond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Inf. Model</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="2864" to="2875" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Random features strengthen graph neural networks</title>
		<author>
			<persName><forename type="first">Ryoma</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Makoto</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hisashi</forename><surname>Kashima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIAM International Conference on Data Mining (SDM)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Collective classification in network data</title>
		<author>
			<persName><forename type="first">Prithviraj</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Galileo</forename><surname>Namata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Bilgic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Galligher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tina</forename><surname>Eliassi-Rad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="93" to="93" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">On the Equivalence between Positional Node Embeddings and Structural Graph Representations</title>
		<author>
			<persName><forename type="first">Balasubramaniam</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Ribeiro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Graph convolutional networks for graphs containing missing features</title>
		<author>
			<persName><forename type="first">Hibiki</forename><surname>Taguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsuyoshi</forename><surname>Murata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Gener. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="155" to="168" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Graph Information Bottleneck</title>
		<author>
			<persName><forename type="first">Tailin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">How Powerful are Graph Neural Networks?</title>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deep graph kernels</title>
		<author>
			<persName><forename type="first">Pinar</forename><surname>Yanardag</surname></persName>
		</author>
		<author>
			<persName><surname>Vishwanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">MultiSage: Empowering GCN with Contextualized Multi-Embeddings on Web-Scale Multipartite Networks</title>
		<author>
			<persName><forename type="first">Carl</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikil</forename><surname>Pancha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Heterogeneous Network Representation Learning: A Unified Framework with Survey and Benchmark</title>
		<author>
			<persName><forename type="first">Carl</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Co-Embedding Network Nodes and Hierarchical Labels with Taxonomy Based Generative Adversarial Networks</title>
		<author>
			<persName><forename type="first">Carl</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Relation Learning on Social Networks with Multi-Modal Graph Edge Variational Autoencoders</title>
		<author>
			<persName><forename type="first">Carl</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haonan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sha</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myungwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiou</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Conditional Structure Generation through Graph Variational Generative Adversarial Nets</title>
		<author>
			<persName><forename type="first">Carl</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peiye</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pan</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Revisit graph neural networks and distance encoding in a practical view</title>
		<author>
			<persName><forename type="first">Yanbang</forename><surname>Haoteng Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.12228</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Identity-Aware Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Gomes-Selman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Position-aware graph neural networks</title>
		<author>
			<persName><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In ICML</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Design Space for Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Link Prediction Based on Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">An End-to-End Deep Learning Architecture for Graph Classification</title>
		<author>
			<persName><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhicheng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marion</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Revisiting Graph Neural Networks for Link Prediction</title>
		<author>
			<persName><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinglong</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Jin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.16103</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Understanding Regularized Spectral Clustering via Graph Conductance</title>
		<author>
			<persName><forename type="first">Yilin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Rohe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Beyond Homophily in Graph Neural Networks: Current Limitations and Effective Designs</title>
		<author>
			<persName><forename type="first">Jiong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingxiao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Heimann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leman</forename><surname>Akoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danai</forename><surname>Koutra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
