<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Trust management in ubiquitous computing: A Bayesian approach</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010-02-01">1 February 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mieso</forename><forename type="middle">K</forename><surname>Denko</surname></persName>
							<email>denko@cis.uoguelph.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing and Information Science</orgName>
								<orgName type="institution">University of Guelph</orgName>
								<address>
									<settlement>Guelph</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tao</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing and Information Science</orgName>
								<orgName type="institution">University of Guelph</orgName>
								<address>
									<settlement>Guelph</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Isaac</forename><surname>Woungang</surname></persName>
							<email>iwoungan@scs.ryerson.-</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Ryerson University</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">ca (I. Woungang)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Trust management in ubiquitous computing: A Bayesian approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2010-02-01">1 February 2010</date>
						</imprint>
					</monogr>
					<idno type="MD5">CE3BE61614126D04F8A770AC53028279</idno>
					<idno type="DOI">10.1016/j.comcom.2010.01.023</idno>
					<note type="submission">Received 15 August 2009 Received in revised form 21 January 2010 Accepted 26 January 2010</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Pervasive computing Probabilistic trust management Security Ubiquitous computing Bayesian approach</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Designing a trust management scheme that can effectively evaluate the relationships among devices in pervasive computing environments is a challenging task. This paper continues the investigation of our recently proposed probabilistic trust management scheme for pervasive computing environments. We argue that in addition to allowing a device to find other appropriate devices with which to interact, while detecting those that are malicious, our trust management scheme is also capable of (1) allowing a device to judge the trustworthiness of another device it interacts with, while making a better use of the received recommendations and (2) behaving as expected when a device has little or enough experience of interactions with other devices and changes dynamically occur in the proportion of malicious devices. Simulation experiments are provided to assess the achievement of the stated goals, using some representative performance metrics.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the widespread availability of open and distributed infrastructures such as grid, wireless networks and the Internet, computing systems are evolving towards the novel area of pervasive computing <ref type="bibr" target="#b0">[1]</ref>. In a pervasive computing environment, software agents, services, and applications, in different physical locations, are expected to be seamlessly integrated and to cooperate, with the goal to achieve user's objectives in an anywhere-and-anytime manner. It is expected that devices that are embedded in physical objects can collect, process and transmit information without human intervention.</p><p>Yet, the paradigm of pervasive computing indicates the goals for research and development of integrated computing and communication systems, but this vision cannot be fully realized without addressing privacy and security relevant issues <ref type="bibr" target="#b1">[2]</ref>. For instance, in a pervasive computing environment, the context in which devices operate may be unknown, complicating the establishment of a descent trust relationship from environment to device level or from device to device level.</p><p>In pervasive computing environments, only well-behaved devices should be allowed to cooperate with each other, and distinguishing between malicious and non-malicious devices is not a straightforward task. One way to resolve this issue is to devise a mechanism upon which entities should be able to evaluate the trust that they have in each other, with the goal that each entity be able to decide which entities to cooperate with.</p><p>Designing a trust management model to provide trust in pervasive computing is thus an important step towards achieving the privacy and security of entities in such a decentralized, distributed and mobile space. In this context, without human judgment, the challenge for devices in pervasive computing environments is to be able to distinguish other peers' identities and behaviors autonomously. Trust can be used as a natural way to achieve this goal. For instance, trust can allow a device to evaluate or predict the security and the quality of potential interactions with other devices before those interactions actually occur. In other words, by using trust, a device would be able to distinguish which interactions should take place and what type of data should be transmitted securely.</p><p>In a recent work <ref type="bibr" target="#b2">[3]</ref>, we have proposed a deterministic trust management scheme for pervasive computing; in which devices can independently handle the trust issues under the absence of a central management. This scheme promotes the use of a single trust value for evaluating a device's behavior. As such, it might not be suitable for use when handling any potential uneven behavior of a device. To this effect, an alternative probabilistic trust management scheme has recently been proposed by us <ref type="bibr" target="#b3">[4]</ref>, which makes use of Bayesian learning, a probabilistic tool based on Bayes' theorem on conditional probability. This novel probabilistic trust management scheme provides a graphical model based on causality to represent the problem of trust among devices, which includes the necessary functions for reasoning and learning and can evolve according to data changes. For this reason, we have cho-0140-3664/$ -see front matter Ã“ 2010 Elsevier B.V. All rights reserved. doi:10.1016/j.comcom.2010.01.023 sen to use it to represent the relations between the various types of trust and to evaluate the global trust value of a given device.</p><p>More precisely, our targeted trust management model evaluates the trust in a device by taking into account both direct experiences with the device (direct trust computation) and recommendations from other devices concerning its services (indirect trust computation). The final value of trust that a device puts on another device is a combination of direct and indirect trust values.</p><p>In order to estimate the final trust value of a device, the following key points have been considered in our model: <ref type="bibr" target="#b0">(1)</ref> the evaluation of trust in a device depends on the outcomes of interactions that the device has had in the past (causal relationship), while accounting for previous trust information, and (2) evaluating the trust value of a device is equivalent to estimating a conditional probability.</p><p>This paper continues on the investigation of the above-mentioned trust management scheme <ref type="bibr" target="#b3">[4]</ref>. We argue that in addition to allow a device to find other appropriate devices with which to interact, while detecting those that are malicious, the targeted trust management scheme is also capable of achieving the following tasks. (1) It allows a device to judge the trustworthiness of another device it interacts with. (2) It allows a device to make a better use of recommendations. (3) It behaves as expected when a device has little or enough experience of interactions with other devices. (4) It behaves as expected when changes occur in the proportion of malicious devices in the system.</p><p>The rest of the paper is organized as follows. Section 2 presents the related work. Section 3 gives an overview of the proposed probabilistic trust management scheme. Section 4 describes the trust computation models. Section 5 discusses how the trust management scheme can be used to defend against typical attacks targeted at trust management systems. In Section 6, simulation experiments are provided to assess the achievement of the stated goals. Finally, Section 7 concludes our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Trust has been used in various ways as a solution for enhancing security in pervasive computing [2,5, and the references cited therein]. Using trust, devices can be reliant to run trust computations and guide their behaviors. To this effect, a method is needed to evaluate the level of trust between devices, while providing a way to reflect the relationships between devices. The mechanism that deals with the evaluation, collection, and propagation of trust is referred to as trust management.</p><p>Designing a trust management solution in pervasive computing requires addressing some specific characteristics of trust in this field. This includes for instance, trust models design, trust evaluation techniques and security enhancement using trust systems. Several authors have investigated this issue. In <ref type="bibr" target="#b4">[5]</ref>, the authors discussed trust issues that devices encounter when communicating with each other in a pervasive computing environment, arguing that transforming trust relationships from the real world into the virtual one requires the negotiation of trust between devices based on their security properties. Similarly, in <ref type="bibr" target="#b5">[6]</ref>, trust is used as a way to deal with the relationship between devices in pervasive computing. In <ref type="bibr" target="#b6">[7]</ref>, a trust management scheme for social and computer networks is introduced. Both entropy-based and probability-based models are designed to protect the devices in distributed networks against several typical attacks. A similar investigation is carried in <ref type="bibr" target="#b7">[8]</ref>, where a trust model for enhancing the collaborations in mobile ad hoc networks is proposed. In <ref type="bibr" target="#b8">[9]</ref>, a trust analysis methodology is proposed to assist in the design of pervasive systems, by addressing trust in the system. In <ref type="bibr" target="#b9">[10]</ref>, trust is used as a way to improve the quality of interactions and services between devices. In <ref type="bibr" target="#b10">[11]</ref>,</p><p>an agent-based trust negotiation framework is proposed, in which a communication control mechanism is used to allocate the communication channels, and protocols are defined to carry and monitor the data traffic between trusted devices. In <ref type="bibr" target="#b11">[12]</ref>, a trust framework is proposed, which uses a chain to transfer trust between devices when providing services. Access rights are dynamically assigned to different devices and services based on delegations and revocations. In <ref type="bibr" target="#b12">[13]</ref>, a trust model is proposed, where the trust evaluation is determined based on the experience, knowledge, and recommendations from devices. In <ref type="bibr" target="#b13">[14]</ref>, a trust management scheme for pervasive computing is proposed, which is based on a decomposition of the environment into two parts: purely ad hoc network-based and managed ad hoc network-based environments.</p><p>Unlike previous trust management schemes, the probability theory can also be exploited to design trust models. For instance, the Bayes' theorem has been used as a tool for designing Bayesian trust models that promote a probabilistic view of trust. In this case, a Bayesian learning process is introduced to make predictions based on previous trust information and outcomes of interactions between devices. In <ref type="bibr" target="#b14">[15]</ref>, a framework referred to as B-Trust is proposed for pervasive computing, in which an n-level discrete Bayesian theorem-based trust metric is developed for trust formation and updates. In <ref type="bibr" target="#b15">[16]</ref>, a naÃ¯ve Bayes Classifier based on the Bayes theorem is used to design a trust model, in which recommendations from peers provide the necessary information to enhance the decision-making on trust. The Beta distribution is used to model the trust and reputation, and the binary evaluation is used for the observation of interactions. The reputation system in <ref type="bibr" target="#b16">[17]</ref> and the TRAVOS model in <ref type="bibr" target="#b17">[18]</ref> are examples of systems built upon the Beta distribution.</p><p>Most trust management schemes are based on recommendations as a means of enhancing the trust evaluation method, assuming that all recommendations are qualified as honest and accurate -i.e., they are not false, nor inaccurate -which is not always guarantee <ref type="bibr" target="#b18">[19]</ref>. An effective trust management schemes is one that should account for recommendations from other devices while reducing as much as possible or even avoiding the influence of false or inaccurate recommendations <ref type="bibr" target="#b18">[19]</ref>. Many proposals have explored this idea. For instance, in <ref type="bibr" target="#b6">[7]</ref>, the concept of Trust of Providing Recommendations (TPRs) is introduced. The authors showed that devices which are qualified to provide honest and accurate recommendations are those who have gained the highest values of TPRs upon running the trust computations on recommendations. However, their proposed trust computation model is not disclosed. In <ref type="bibr" target="#b17">[18]</ref>, the concept of Provider's Reputation (PR) is introduced. A PR is determined by a specific device (Rater) based on its judgement on the provider's opinion (PO), which in turn, depends on previous actions carried out by this provider. A probability of accuracy is assigned to a PO and is used by the Rater to determine its belief towards this provider. Paper <ref type="bibr" target="#b19">[20]</ref> studied the deceptions of providing false ratings, and proposed a weighted majority algorithm that assigns weights to belief ratings. Using a cluster-filtering scheme, the authors in <ref type="bibr" target="#b20">[21]</ref> proposed a clusterbased decomposition of the set of ratings, distinguishing unfair ratings from fair ones. Similarly, a filtering algorithm is proposed in <ref type="bibr" target="#b18">[19]</ref>, which iteratively expels the ratings that fall outside of a certain Beta distribution interval. Finally, few other trust management schemes consider the quality of context information as design features in addition to recommendations <ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref>.</p><p>Unlike previous work, in the probabilistic trust management scheme proposed in <ref type="bibr" target="#b3">[4]</ref>, the trust computation is performed before each interaction happens. It is based on (1) the experience of previous interactions between devices -where a device uses its firsthand experience of interactions to compute the trust value -and on (2) the interaction information gained through recommendations. More precisely, the experience of previous interactions is stored in a suitable data structure, and is used to maintain the history of interactions as a reference for future trust computations. The indirect trust computation is performed with the assistance of recommendations issued from other devices (when the direct trust computation cannot be invoked). The judgments on recommendations are enhanced in order to prevent potential damage that might be caused by false recommendations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Targeted trust management scheme</head><p>The targeted trust management scheme introduced in <ref type="bibr" target="#b3">[4]</ref> is illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. Here, the definition used for trust is inherited from <ref type="bibr" target="#b7">[8]</ref>, i.e., the trust that device A places in device B is the strength of device A's belief that device B will behave without malicious intent, and the service or interaction that device B provides will satisfy device A's request. In fact, trust is not only a measure of a device's faithfulness, but also an indicator of the quality of service that a device can provide. A trust value is determined as a probability that a device provides satisfactory interactions, and multiple trust values are used to evaluate each aspect of the device's interaction with its neighbours. A filtering method and a weighting technique are used to eliminate the effect of false recommendations, and to quantify the effect of time on current devices' behaviors.</p><p>The trust management scheme in Fig. <ref type="figure" target="#fig_0">1</ref> is composed of four main modules:</p><p>Trust computation module: This module performs the most important function of the trust management scheme, which is trust computation. Trust computation happens before each interaction occurs between devices. First, the module selects the desired entry (history of interactions between devices) from the Histories of Interactions module. Then, based on this, it makes a decision on the computation method that should be employed. The direct computation is done based on the history of interactions while the indirect computation is executed with the help of the Recommendation management module. Both are invoked to obtain trust values. This module includes three sub-modules: (a) Computation Method Selection sub-module -whose function is to choose a suitable method for computing the trust values, (b) Direct Computation sub-module -which is used when the direct observation is adequate, and; (c) Indirect Computation sub-module is employed when the direct observation is inadequate. The operational aspects of these sub-modules are further described in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>History of interactions module:</head><p>In the above Trust Computation module, the methods used to perform trust computation are different from those proposed in <ref type="bibr" target="#b2">[3]</ref>. Indeed, since the experience of previous interactions between devices must account when performing the trust computation, a data structure called the history of interaction has been introduced. This is used to store the information on previous interactions. The history of interactions embedded in a device A about a device B is denoted by H A Ã°BÃž. Device A keeps a list H A Ã°BÃž Â¼ fH 1 ; . . . ; H n g, where each entry H i represents the trust record of a single interaction with device B. Each H i is defined as a tuple he i ; s i ; d i i, where e i is the interaction's evaluation, which equals to 1 if the quality of interaction is satisfactory (i.e., the requirement of the interaction is fulfilled by the interaction's provider) and 0 otherwise, s i is the type of interaction between devices A and B or the type of service provided to device A by device B, and d i is the time the interaction had occurred. The later can influence the current trust evaluation of a device since the quality of the services provided by the same device may change over time, and recent experiences may be more important than older ones when used as a reference for the trust evaluation. The Histories of Interactions Module provides the information from previous interactions to the Trust Computation module. It also provides information to the Recommendations Management module when offering recommendations to other devices.</p><p>History maintenance module: This module is used to manage and maintain the Histories of Interactions Module. This capacity is operated via three sub-modules: (1) the Initialization of History of Interactions sub-module -which sets up a record for the history of interactions for each device, (2) the Interaction Evaluation submodule -which evaluates the result of each interaction, and (3) the History of Interactions Updating sub-module -which updates the corresponding history of interactions by adding one new entry to the existing ones.</p><p>Recommendation management module: This module has two major functions: (1) requesting recommendations from other devices, and ( <ref type="formula" target="#formula_1">2</ref> module then collects these recommendations. Next, the received recommendations are processed by the Recommendation Processing sub-module whose function is to filter false recommendations.</p><p>It should be noticed that this module does not calculate recommendation values. Finally, upon receiving the request for recommendations from other devices, the Recommendation Providing sub-module picks the desired history of interactions' record from the Histories of Interactions module, and sends it as recommendation (as opposed to sending a trust value as recommendation as in <ref type="bibr" target="#b2">[3]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Trust computations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Direct trust computation</head><p>The direct trust computation is performed when two devices that are attempting to interact with each other have no experience so far with each other. In this case, the trust computation is based on the direct observation, derived either from personal identification or from the identity information embodied in devices.</p><p>In probability theory, the beta distribution (via its probability density function) is an important notion that has been proven useful for describing the probability distribution of binary events <ref type="bibr" target="#b21">[22]</ref>. By means of its probability density function, the beta distribution can be used as a prior distribution in Bayesian inference <ref type="bibr" target="#b22">[23]</ref>, which in turn, can be used for decision making. Indeed, the Bayesian interference is a statistical process through which the current state of the observed distribution is evaluated, then new data are gathered to address remaining questions, and then, the distribution incorporating both new and old data are updated and refined. This way, it can be used to make an estimation of the underlying distribution based on the observed distribution. Several authors have exploited this feature by introducing the beta distribution and Bayesian interference in trust computation <ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b21">22]</ref>.</p><p>Inspired by these pioneered works, the trust management scheme proposed in <ref type="bibr" target="#b3">[4]</ref> also makes use of this feature. When a device, say A, computes the trust value of another device, say B, with which it interacts, the notation T A Ã°BÃž is used to represent the probability that a satisfying interaction can be provided by B. Considering the interaction between devices A and B, the two parameters used in the beta distribution to represent the observations are, respectively, choose as n s the number of previous satisfying interactions with B, and n u the number of unsatisfying interactions with B. When computing the values of n s and n u , it is assumed that the desired type of future interactions is identical to that of previous interactions. By setting a Â¼ n s Ã¾ 1 and b Â¼ n u Ã¾ 1, the estimated value of T A Ã°BÃž is obtained by computing the expected value of the probability distribution function of the beta distribution as follows:</p><formula xml:id="formula_0">T A Ã°BÃž Â¼ EÃ°f Ã°x; a; bÃžÃž Â¼ a a Ã¾ b Â¼ n s Ã¾ 1 Ã°n s Ã¾ 1Ãž Ã¾ Ã°n u Ã¾ 1Ãž Â¼ n s Ã¾ 1 n s Ã¾ n u Ã¾ 2<label>Ã°1Ãž</label></formula><p>where f Ã°x; a; bÃž Â¼</p><formula xml:id="formula_1">x aÃ€1 Ã°1 Ã€ xÃž bÃ€1 R 1 0 u aÃ€1 Ã°1 Ã€ uÃž bÃ€1 du Â¼ CÃ°a Ã¾ bÃž CÃ°aÃžCÃ°bÃž x aÃ€1 Ã°1 Ã€ xÃž bÃ€1 Â¼ x aÃ€1 Ã°1 Ã€ xÃž bÃ€1 BÃ°a; bÃž<label>Ã°2Ãž</label></formula><formula xml:id="formula_2">CÃ°zÃž Â¼ Z 1 0 t zÃ€1 e Ã€t dt;<label>and</label></formula><formula xml:id="formula_3">BÃ°a; bÃž Â¼ Z 1 0 z aÃ€1 Ã°1 Ã€ zÃž bÃ€1 dz Â¼ CÃ°aÃžCÃ°bÃž CÃ°a Ã¾ bÃž<label>Ã°3Ãž</label></formula><p>In Eq. ( <ref type="formula" target="#formula_0">1</ref>), the values of n s and n u are obtained by searching the entries in H A Ã°BÃž, the history of interactions. Unlike the direct trust computation method in <ref type="bibr" target="#b2">[3]</ref>, where the trust computation is performed once before the first interaction between two devices occurs, and the trust value is updated during the period of interactions, the trust computation in <ref type="bibr" target="#b3">[4]</ref> is performed before every interaction. Here, the behavior of a device is dynamic, and the trust value of a device is computed using the device's firsthand experience of interactions. This value is then adjusted regularly to track the trend of changes in the device's behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Indirect trust computation</head><p>The indirect trust computation requires that a device use not only its own experience of interactions, but also recommendations from other devices to run a trust computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Decision on running the indirect trust computation</head><p>A device is not always able to gather enough information from its own history of interactions to run a direct trust computation. Therefore, a method is introduced to aid a device estimating whether the information it has gather so far is enough for running the direct trust computation. In the trust model, the trust value is based on the expected value of the beta distribution (see Eq. ( <ref type="formula" target="#formula_0">1</ref>)), which in turn, may be the same for combinations of different values of a and b. In other words, long-term and short-term experiences of interactions may lead to the same level of trust. However, it is expected that more interactions would ensure more accurate trust computations. Thus, a parameter is introduced in the trust computation to distinguish the trust values that are created in different ways while achieving this goal. Inspired from the work in <ref type="bibr" target="#b5">[6]</ref>, the trust model <ref type="bibr" target="#b3">[4]</ref> considers the ''confidence" as the desired parameter. More precisely, the ''level of confidence" (denoted as Conf) that one device has in the trust evaluation on another device, is obtained via the variance of the beta distribution:</p><formula xml:id="formula_4">Conf Â¼ 1 Ã€ VarÃ°XÃž Â¼ 1 Ã€ ab Ã°a Ã¾ bÃž 2 Ã°a Ã¾ b Ã¾ 1Ãž Â¼ 1 Ã€ Ã°n s Ã¾ 1ÃžÃ°n u Ã¾ 1Ãž Ã°Ã°n s Ã¾ 1Ãž Ã¾ Ã°n u Ã¾ 1ÃžÃž 2 Ã°Ã°n s Ã¾ 1Ãž Ã¾ Ã°n u Ã¾ 1Ãž Ã¾ 1Ãž Â¼ 1 Ã€ Ã°n s Ã¾ 1ÃžÃ°n u Ã¾ 1Ãž Ã°n s Ã¾ n u Ã¾ 2Ãž 2 Ã°n s Ã¾ n u Ã¾ 3Ãž<label>Ã°4Ãž</label></formula><p>To illustrate how this parameter can help achieving the mentioned goal, let's consider the combinations of n s and n u shown in Table <ref type="table" target="#tab_0">1</ref>, which leads to equal values of E(X). Fig. <ref type="figure" target="#fig_1">2</ref> shows that with an increase of n s and n u values, the value of Conf becomes higher, i.e., the stated goal is met. Using Eq. ( <ref type="formula" target="#formula_4">4</ref>), if Conf is low, the conclusion is drawn that the confidence in the current trust information is inadequate for running a direct trust computation and more information is needed. The indirect trust computation is then invoked and run with the help of recommendations as described next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Executing the indirect trust computation</head><p>In the targeted trust model, recommendations and firsthand experience are treated equally because they provide information on interactions with same device. On this basis, the indirect trust computation is run by combining firsthand experience and the interaction information gained through recommendations. Upon receiving a request for recommendations from a recommendation requester (RR), other devices respond back with their recommendations. Meantime, recommendation providers provide their histories of interactions as recommendations. Using these responses, the RR calculates for each recommendation the number of satisfying interactions and the number of unsatisfying ones, then, makes use of these numbers and the numbers of satisfying and unsatisfying interactions in its history of interactions to run the trust computation.</p><p>Let i be the number of accepted recommendations, and n m s and n m u be, respectively, the number of satisfying interactions and that of unsatisfying interactions, calculated based on the recommendation provided by a device D m . Let n r s (respectively, n r u ) be the total number of satisfying interactions (respectively, of unsatisfying interactions) in the recommendations, we get n r s Â¼</p><formula xml:id="formula_5">X i kÂ¼1 n k s Ã°5Ãž n r u Â¼ X i jÂ¼1 n j u<label>Ã°6Ãž</label></formula><p>Using the beta distribution with the values a and b defined as</p><formula xml:id="formula_6">a Â¼ n s Ã¾ n r s Ã¾ 1 Â¼ n s Ã¾ X i kÂ¼1 n k s Ã¾ 1<label>Ã°7Ãž</label></formula><formula xml:id="formula_7">b Â¼ n u Ã¾ n r u Ã¾ 1 Â¼ n u Ã¾ X i jÂ¼1 n j u Ã¾ 1<label>Ã°8Ãž</label></formula><p>It can be verified that T A Ã°BÃž, the trust value that device A puts on device B is obtained as:</p><formula xml:id="formula_8">T A Ã°BÃž Â¼ EÃ°f Ã°x; a; bÃžÃž Â¼ a a Ã¾ b Â¼ n s Ã¾ n r s Ã¾ 1 Ã°n s Ã¾ n r s Ã¾ 1Ãž Ã¾ Ã°n u Ã¾ n r u Ã¾ 1Ãž Â¼ n s Ã¾ P i kÂ¼1 n k s Ã¾ 1 n s Ã¾ n u Ã¾ P i kÂ¼1 n k s Ã¾ P i jÂ¼1 n j u Ã¾ 2<label>Ã°9Ãž</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3.">Judging the recommendations</head><p>When the firsthand information gather by a device is not sufficient enough to run a direct trust computation, the indirect trust computation is invoked with the help of recommendations from other devices and recommendation providers. However, not all these recommendations are guaranteed to be honest and accurate. For instance, some devices may launch attacks by providing false recommendations or false recommendations may be issued by dishonest recommendation providers. Thus, it is essential to design a method that can be used to judge the recommendations and recommenders when running the indirect computation. Such a method could also be used to filter out false or inaccurate recommendations <ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4.">Judging each recommender</head><p>After all recommendations have been received by a device, say A, the device searches in its records of interactions to identify those devices D i which have provided a recommendation. It should be noticed that the type of interaction resumes only to the action of providing recommendations. Once the device A has collected the records about each device D i that has provided a recommendation, it calculates T r A Ã°D i Ãž, the trust value that this recommender D i did provide a honest recommendation. If this value is low, device A considers that device D i is a dishonest one and will not use it in the indirect trust computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.5.">Judging each accepted recommendation</head><p>Once the above judgment on the recommenders is established and the accepted recommendations from honest recommenders are collected by a device prior to running the indirect computation, these recommendations undergo a second level of judgement, in order for the trust model to ensure about their accuracy. Indeed, device A computes the average trust value, say T, based on the recommendations. Then it compares T with the trust value T j computed based on recommendation R i from D j . If the trust value T j deviates dramatically from T, then R i is qualified as inaccurate. Next, device A adds a new record of interaction into its records of interactions H A Ã°D j Ãž. The type of interaction of this new record is ''recommendation", and the result of the interaction is 0, meaning that this interaction is not satisfactory.</p><p>The overall process of filtering out the honest recommenders, while also ensuring the accuracy of their recommendations, has been achieved by designing an iterative filtering method, whose idea is borrowed from <ref type="bibr" target="#b18">[19]</ref>. The pseudo-code of the iterative filtering method is given in <ref type="bibr" target="#b3">[4]</ref>. In addition to this, we provide here a stepwise description of the algorithm:</p><p>Step 1:</p><p>Device A broadcasts the request for recommendations about device B. Let i be the number of accepted recommendations collected from honest (trustworthy) recommenders. Recommendations are denoted as pairs</p><formula xml:id="formula_9">Ã°n 1 s ; n 1 u Ãž; Ã°n 2 s ; n 2 u Ãž; . . . ; Ã°n i s ; n i u Ãž, where n R s (respectively, n R</formula><p>u ) represents the number of satisfying interactions (respectively, the number of unsatisfying interactions) in the device R's recommendation.</p><p>Step 2:</p><p>Based on each recommendation Ã°n R s ; n R u Ãž, compute a trust value T R Ã°BÃž. This value represents the trust opinion of device R on device B.</p><p>Step 3:</p><p>Calculate the average trust value T ave Ã°BÃž using T ave Ã°BÃž Â¼  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.6.">Assigning weight to the interaction over time</head><p>In the targeted trust management scheme, the trust computations are based on the records in the history of interactions. If each record is treated equally regardless of the time when the interaction had happened, the computed trust values might not accurately reflect the devices' behaviors, and may result in a misleading outcome. Instead, in the trust model, the results of recent interactions are considered more important than those of older ones because they represent the current behavior of the device. Here, some weights are assigned to records of interactions based on when they have occurred. More weights are assigned to recent interactions to illustrate their importance compared to older ones. The method used to achieve this is motivated by the work in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b18">19]</ref>. More precisely, assuming that: (1) the current time is t cur , and ( <ref type="formula" target="#formula_1">2</ref>) each interaction record is assigned a weight WT according to the time it had happened, i.e.,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H m</head><p>A Ã°BÃž ) WT m Â¼ w tcur Ã€dm Ã°10Ãž</p><p>where w is a weighting factor in the interval [0,1], and (3) there exists n records of satisfying interactions (respectively, m records of unsatisfying interactions) in H A Ã°BÃž, the weighted n s and n u are computed <ref type="bibr" target="#b3">[4]</ref> as follows:</p><formula xml:id="formula_10">n s Â¼ X n iÂ¼1 WT i Â¼ X n iÂ¼1 w tcur Ã€d i<label>Ã°11Ãž</label></formula><formula xml:id="formula_11">n u Â¼ X m jÂ¼1 WT j Â¼ X m jÂ¼1 w tcur Ã€d j<label>Ã°12Ãž</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Trust management for enhancing security in pervasive computing</head><p>Critical privacy and security challenges confront researchers and developers working on ever more pervasive computing systems because in such systems, opportunities are offered for malicious entities to launch attacks to other peers. Various mechanisms, including those based on trust, have been designed to enhance the security in pervasive computing and ubiquitous environments <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25]</ref>, and the references therein. Focusing on the use of trust management schemes for security purpose in pervasive computing, a well-designed scheme should provide protection against attacks from selfish and malicious devices. Such typical attacks are discussed in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b17">18]</ref>. Here, we discuss how the targeted trust management scheme can be used to protect against three attacks, namely, low quality interaction attacks, false recommendation attacks and dynamic behavior attacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Low quality interaction attacks</head><p>Low quality interaction attacks are typical in pervasive computing environment. It includes denial of service, delaying of service, packets dropping, to name a few. In our trust model, if we perceived a low quality interaction attack as the action of maliciously dropping the packets in the system, the design features of the trust computations models can help reducing the damage caused by this type of attack. Indeed, when such an attack is detected, the trust computation mechanism will perform the following duties: (1) it will use Eq. ( <ref type="formula" target="#formula_4">4</ref>) to determine the confidence (Conf) any device has in the trust evaluation on another one, (2) it will use this value to decide on whether to run the direct or indirect trust computation, (3) then in both scenarios, and within long-term period, it will accumulate enough records of interactions so as to be able to compute the trust values with adequate confidence, leading to the detection and avoidance of malicious devices, thereby to the reduction of packet losses in the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">False recommendation attacks</head><p>In the targeted trust model, recommendations are typically required when an indirect trust computation is invoked following a lack of sufficient information on a device's history of interactions to run a direct trust computation. In this scenario, providing a recommendation is considered as a type of interaction, and dishonest devices can take advantage of this opportunity to provide false recommendations or ruin the reputation of good devices or even compliment other cooperated malicious devices <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b17">18]</ref>. This is referred to as false recommendation attacks. The targeted trust model can help protecting against this type of attacks <ref type="bibr" target="#b3">[4]</ref>. In addition, it is also capable to help a device make a better use of received recommendations from honest recommenders. To this effect, the trust computation model first computes the trust value of a given recommender on providing recommendations. Based on this value, it makes a decision to either accept or reject the recommendations depending on the trustworthiness of this recommender. Then, it invokes the aforementioned filtering algorithm (see Fig. <ref type="figure" target="#fig_1">2</ref>) to expel the false recommendations from the currently received recommendations. This scenario is justified through simulation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Dynamic behavior attacks</head><p>In a pervasive computing environment, some malicious devices may behave well and badly alternatively, in specific subsequent periods of time, hoping that they can still be undetectable while running their malicious activities. This type of attack is referred to as dynamic behavior attack (also known as on-off attack) <ref type="bibr" target="#b6">[7]</ref>.</p><p>In the targeted trust model, when the trust computation is performed, each past interaction with a device is assigned a certain weight according to the time the interaction had happened. This is realized through a weighting method implemented using Eqs. ( <ref type="formula">10</ref>)- <ref type="bibr" target="#b11">(12)</ref>. These weights are used to determine the trust value that a given device puts on another one, allowing the trust model to detect devices that behaved badly, thus preventing them from acting like ''good" devices fraudulently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Performance evaluation</head><p>To extend the performance evaluation of the targeted trust management scheme <ref type="bibr" target="#b3">[4]</ref> and realize the aforementioned stated goals, a series of simulation experiments were conducted, and implemented using the Java programming environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Simulation environment</head><p>The simulation environment is composed of 20 service providers (SPs) and multiple service requesters (SRs). The following assumptions are made: (1) SPs do not interact with each other and do not provide recommendations, (2) a SP serves only one SR at a time, (3) SRs can interact with each other for providing the recommendations, (4) SRs can interact with all SPs, for packets relaying purpose, and (5) all SRs have the same expectations on their interactions with SPs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Performance metrics</head><p>The following performance metrics are used: Average throughput: the throughput is defined as the number of packets that an intermediate node has successfully delivered during a predefined period of time. The average throughput for a node is obtained as:</p><formula xml:id="formula_12">Average throughput Â¼ Pack suc Time total<label>Ã°13Ãž</label></formula><p>where Pack suc is the total number of packets successfully transmitted and Time total is the total interaction time. It should be noticed that the results in the simulations are obtained by taking the average throughput of the entire network.</p><p>Recommendation overhead: defined as the overhead caused when dealing with received recommendations:</p><formula xml:id="formula_13">Recommendation overhead Â¼ Recomm unused RecommRequest total<label>Ã°14Ãž</label></formula><p>where Recomm unsed is the number of recommendations received by a device, but not adequate for accumulating confidence to run an indirect trust computation. RecommRequest total is the number of recommendation requests made during the experiment. Average packet loss ratio: defined as the ratio of packets that were lost during the transmission to the total packets generated in a certain period of time:</p><formula xml:id="formula_14">Average packet loss ratio Â¼ Pack loss Pack total<label>Ã°15Ãž</label></formula><p>where Pack total is the total number of packets generated by devices and Pack loss is the number of packets that were lost during the transmission.</p><p>Percentage of detection: percentage of requesters that detected malicious SPs. This metric is used to investigate how fast the malicious SPs can be detected by the SRs in the environment:</p><formula xml:id="formula_15">Percentage of detection Â¼ N dtct N total<label>Ã°16Ãž</label></formula><p>where N dtct is the number of SRs which have detected the malicious SPs, and N total is the total number of SRs in the environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Simulation parameters</head><p>The following varying parameters are used to observe the above performance metrics:</p><p>Length of the simulation: This is used to investigate the performance of the proposed scheme over varying lengths of time periods. With trust management, a device chooses appropriate devices to communicate with, based on certain trust values. In the experiments, we change the length of the simulation to see how the performance metrics are influenced when applying different trust computations.</p><p>Network size: Total number of devices in the environment. In the experiments, we set different values of network size to investigate how performance metrics are influenced by different percentages of recommendations.</p><p>Proportion of false recommenders: Represents the number of SRs that provide false recommendations over the total number of SRs.</p><p>Proportion of malicious devices: Number of malicious SPs over the total number of SPs. In the experiments, we change the value of this parameter to investigate the influence it has on the average packet loss ratio and average throughput.</p><p>It is also assumed that the interaction time, the waiting time, and the interval time between two interactions, follow an exponential distribution. During the interaction, a Poisson process is used to generate the packet arrival time. If no service provider is idle, the service requester waits for a period of time, then, re-attempts the interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Simulation experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.1.">Effects of trust value threshold</head><p>After running the trust computation, a SR needs to judge whether a SP is trustworthy to interact with. In the pervasive computing environment that we setup, when a SR searches for a SP to interact with, two methods can be used: (1) the SR tries to find all idle SPs first, then selects the one with the highest trust value to interact with. In this case, the SP with the lowest trust value might be chosen by the SR for interaction if it is the only idle one, (2) the SR only selects the idle SP which is trustworthy. In this case, a trust value threshold is needed for assessing whether the SP is trustworthy or not. To this effect, a SP is trustworthy only when its trust value is not lower than the prescribed threshold. If a SR cannot find a trustworthy SP among idle ones, it will rather wait until one becomes idle. In this scenario, choosing a proper trust value threshold becomes essential. In this experiment, we investigate how the choice of a trust value threshold influences the performance of trust computation, and we also try to find the appropriate range of trust value thresholds. We assume that in this environment, there are 20 SPs and 80 SRs. We give different values to the trust value threshold: 0.05, 0.1, 0.15, 0.2, and 0.25. The results of our experiments are depicted in Figs. <ref type="figure">3</ref><ref type="figure">4</ref><ref type="figure">5</ref>. In Fig. <ref type="figure">3</ref>, it is observed that an increase in trust value thresholds corresponds to a decrease in average packet loss ratios. In addition, the average packet loss ratios with trust value thresholds 0.1 and 0.05 are much higher than others. This can be justified as follows. From Eq. (1) used to calculate the trust value, when the trust value threshold is 0.1, at least eight interactions are required in order for the trust value to reach the prescribed threshold. When the trust value threshold is equal to 0.05, at least 18 interactions are needed, which increases the chance that a SR interacts with malicious SPs having high packet loss ratios. Therefore, when the trust value threshold is either 0.1 or 0.05, the average packet loss ratio is high.</p><p>Fig. <ref type="figure">4</ref> shows that at a given simulation time, the highest trust value threshold generates the highest average throughput. This observation further validates the above result obtained in Fig. <ref type="figure">3</ref>. It means that using the highest trust value threshold will help the devices to find good SPs to interact with. Therefore, based on our experimental results, the appropriate trust value threshold might be not less than 0.15.</p><p>In Fig. <ref type="figure">5</ref>, it is observed that with an increase in trust value threshold, there is a decrease in recommendation overhead value. When the trust value threshold is higher, a device makes better use of recommendations. When the simulation time is greater than about 800, the recommendation overhead with different thresholds becomes low and similar to each other. At this phase of simulation, most SRs perform the direct computation without recommendations, thus, the overhead becomes low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.2.">Effects of network size</head><p>In a pervasive computing environment, devices enter and leave the environment constantly. In this experiment, we investigate the influence of network size on the performance of the proposed trust model. We change the network size from 10 to 80 and focus on two phases of the simulation: the beginning and the intermediate phases. At the beginning phase, i.e., when the simulation time is short, SRs lack the experience of interactions with SPs, while at the intermediate phase, SRs have accumulated some experience of interactions. We investigate how the trust model performs at these two phases with the varying network size. Fig. <ref type="figure">6</ref> depicts the result of our experiment.</p><p>In Fig. <ref type="figure">6</ref>, it is observed that at a given simulation time, an increase in network size also results to an increase in the throughput. In addition, when the simulation time is longer, the average throughput is higher.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.3.">Protection against false recommendation attacks</head><p>In this experiment, we investigate if our proposed trust model can protect the device against false recommendation attacks. There are 80 SRs in the environment, among which some provide false recommendations and others provide honest ones. Here, we change the proportion of SRs that provide false recommendations to study how our proposed iterative filtering method reacts. The number of devices that provide false recommendations increases from 4 to 36, i.e., from 5% to 45% in proportion. We also assume that: (1) among the 20 SPs, four are malicious ones that drop packets during the interaction, (2) when providing recommendations about malicious devices, false recommendation providers will provide a high value as number of satisfying interactions and 0 as the number of unsatisfying interactions (these are often called false positive recommendations). Two scenarios are designed for this experiment:</p><p>The scenario of false recommendation attack without protection (no-filtering): Here, the trust management scheme does not differentiate the recommendations when running the indirect trust computation. All recommendations are accepted without making any judgment. We study if the performance of the trust management scheme can be influenced when some recommendations are false.</p><p>The scenario with protection against false recommendation attack (with-filtering): Here, the trust management scheme uses the iterative filtering method to evaluate the accuracy and honesty of the recommendations when running the indirect trust computation. Our goal is to check whether the aforementioned iterative filtering method can effectively protect devices against false recommendation attacks.</p><p>The result of our experiment is depicted in Fig. <ref type="figure">7</ref>. In Fig. <ref type="figure">7</ref>, it is observed that the average throughput without filtering method (no-filtering) remains low when the proportion of false recommenders increases. When there are no more than 16 false recommenders (i.e., 20% in proportion), the average throughput with the proposed iterative filtering method (with-filtering) remains at a level around 0.95. The average throughput decreases progressively and slowly, when the proportion of false recommenders is more than 20%. When the proportion of false recommenders is more than 40%, the average throughputs of the two scenarios are almost the same. Thus, we can conclude that the proposed iterative filtering method works effectively when the proportion of false recommenders is no more than 30%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.4.">Effects of proportion of malicious devices</head><p>The number of malicious devices in a pervasive computing environment is not static. In this experiment, we change the proportion of malicious devices and we investigate the performance of our trust model. Here, the simulation time is set to 100 and 3000. The number of SPs is 20 and the number of SRs is 80. We change the proportion of malicious SPs from 1 to 8, i.e., from 5% to 40% in proportion. The result obtained is depicted in Fig. <ref type="figure">8</ref>.</p><p>In Fig. <ref type="figure">8</ref>, it is observed that for a given simulation time, when the proportion of malicious SPs increases, the average throughputs decreases. With the same proportion of malicious devices, the average throughput obtained when using the simulation time 100 is much lower than that obtained when using the simulation time 3000. This can be justified as follows. When the simulation time is as short as 100, a SR has to use its direct experience of interactions with SPs to perform trust computation because only few of the other SRs can provide recommendations. When the proportion of malicious devices increases, a SR interacts with more malicious SPs, hence, the average packet loss ratio increases quickly and the average throughput decreases quickly too. When the simulation time is 3000, a SR collects trust information by means of recommendations from other SPs. When the proportion of malicious devices increases, a SR can still find an appropriate SP to interact with, hence, the average packet loss ratio increases slightly and the average throughput decreases slightly too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions and future work</head><p>We have extended the investigation of a recently proposed probabilistic trust management scheme for pervasive computing environments. Using this scheme, it has been proven that devices can effectively discover other devices with which they can interact, while screening malicious ones. From our simulation experiments, additional features of the scheme have been established. More precisely, it is found that the proposed trust model is also capable of (1) allowing a device to judge the trustworthiness of another device it interacts with while using effectively the recommendations from its peers, (2) behaving as expected when the proportion of malicious devices changes dynamically, and when a device have accumulated little or enough experience of interactions with other devices in the environment, and finally (3) protecting against false recommendation attacks based on the proportion of false recommenders. A possible future work is to design a generic pervasive computing environment that can be used as a standard platform to evaluate existing trust management schemes while serving the need for new trust management designs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. The targeted probabilistic trust management architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The relation of interactions and confidence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .Fig. 4 .Fig. 5 .</head><label>345</label><figDesc>Fig. 3. Average packet loss ratio under varying simulation time (s).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 . 7 .</head><label>67</label><figDesc>Fig. 6. Average throughput under varying network size. Fig. 7. Average throughput under varying false recommenders.</figDesc><graphic coords="8,318.33,619.82,237.57,118.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>An example for confidence of trust computation.</figDesc><table><row><cell>ns</cell><cell>nu</cell><cell>a</cell><cell>b</cell><cell>E(X)</cell><cell>Var(X)</cell><cell>Conf</cell></row><row><cell>4</cell><cell>1</cell><cell>5</cell><cell>2</cell><cell>0.714286</cell><cell>0.012346</cell><cell>0.987654</cell></row><row><cell>9</cell><cell>3</cell><cell>10</cell><cell>4</cell><cell>0.714286</cell><cell>0. 009191</cell><cell>0.990809</cell></row><row><cell>14</cell><cell>5</cell><cell>15</cell><cell>6</cell><cell>0.714286</cell><cell>0.007089</cell><cell>0.992911</cell></row><row><cell>19</cell><cell>7</cell><cell>20</cell><cell>8</cell><cell>0.714286</cell><cell>0.005735</cell><cell>0.994265</cell></row><row><cell>24</cell><cell>9</cell><cell>25</cell><cell>10</cell><cell>0.714286</cell><cell>0.004806</cell><cell>0.995194</cell></row><row><cell>29</cell><cell>11</cell><cell>30</cell><cell>12</cell><cell>0.714286</cell><cell>0.004132</cell><cell>0.995868</cell></row><row><cell>34</cell><cell>13</cell><cell>35</cell><cell>14</cell><cell>0.714286</cell><cell>0.003623</cell><cell>0.996377</cell></row><row><cell>39</cell><cell>15</cell><cell>40</cell><cell>16</cell><cell>0.714286</cell><cell>0.003225</cell><cell>0.996775</cell></row><row><cell>44</cell><cell>17</cell><cell>45</cell><cell>18</cell><cell>0.714286</cell><cell>0.002905</cell><cell>0.997095</cell></row><row><cell>49</cell><cell>19</cell><cell>50</cell><cell>20</cell><cell>0.714286</cell><cell>0.002642</cell><cell>0.997358</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>M.K. Denko et al. / Computer Communications 34 (2011) 398-406</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>M.K. Denko et al. / Computer Communications 34 (2011) 398-406</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Computer for the 21st Century</title>
		<author>
			<persName><forename type="first">M</forename><surname>Weiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific American</title>
		<imprint>
			<biblScope unit="volume">265</biblScope>
			<biblScope unit="page" from="66" to="75" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A security framework for executables in a ubiquitous computing environment</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lewellyn-Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Merabti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Askwith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE GLOBECOM&apos;04</title>
		<meeting>the IEEE GLOBECOM&apos;04</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2158" to="2163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deterministic trust management in pervasive computing</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Denko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Woungang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Mobile Multimedia</title>
		<imprint>
			<publisher>Rinto Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="64" to="080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Probabilistic trust management in pervasive computing</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Denko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/IFIP International Conference on Embedded and Ubiquitous Computing (EUC&apos;08)</title>
		<meeting>the IEEE/IFIP International Conference on Embedded and Ubiquitous Computing (EUC&apos;08)<address><addrLine>Shangai, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">December 17-20. 2008</date>
			<biblScope unit="page" from="610" to="615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Trustworthy pervasive computing: the hard security problem</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second IEEE Annual Conference on Pervasive Computing and Communications Workshops</title>
		<meeting>the Second IEEE Annual Conference on Pervasive Computing and Communications Workshops</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="117" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The meanings of trust</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Mcknight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Chervany</surname></persName>
		</author>
		<idno>94-04</idno>
	</analytic>
	<monogr>
		<title level="s">The MISRC Working Paper Series</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A trust evaluation framework in distributed networks: vulnerability analysis and defence against attacks</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J R</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the INFOCOM</title>
		<meeting>the INFOCOM</meeting>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Bayesian network-based trust model for improving collaboration in mobile ad hoc networks</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Camp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Loiseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Research, Innovation &amp; Vision for the Future</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="144" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A trust analysis methodology for pervasive computing systems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Presti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leuschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Booth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LNCS</title>
		<imprint>
			<biblScope unit="volume">3577</biblScope>
			<biblScope unit="page" from="129" to="143" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Capra, trust and mobility aware service provision for pervasive computing</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mascolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Workshop on Requirements and Solutions for Pervasive Software Infrastructures</title>
		<meeting>the First International Workshop on Requirements and Solutions for Pervasive Software Infrastructures</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="603" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Agent-based automated trust negotiation for pervasive computing</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on Embedded Software and Systems</title>
		<meeting>the Second International Conference on Embedded Software and Systems</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="300" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Trust-based security in pervasive computing environments</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kagal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Finin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="154" to="157" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A trust model for pervasive computing environments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CollaborateCom2006</title>
		<meeting>CollaborateCom2006</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A trust framework for pervasive computing environments</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Ahamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zulkernine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Systems and Applications</title>
		<meeting>the IEEE International Conference on Computer Systems and Applications</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="312" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Bayesian trust framework for pervasive computing</title>
		<author>
			<persName><forename type="first">D</forename><surname>Quercia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hailes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Capra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B-Trust</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LNCS</title>
		<imprint>
			<biblScope unit="volume">3986</biblScope>
			<biblScope unit="page" from="298" to="312" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A dynamic trust model based on naive Bayes classifier for ubiquitous environments</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LNCS</title>
		<imprint>
			<biblScope unit="volume">4208</biblScope>
			<biblScope unit="page" from="562" to="571" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The effect of rumor spreading in reputation systems for mobile ad hoc networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Buchegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Le</forename><surname>Boudec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Modeling and Optimization in Mobile, Ad Hoc and Wireless Networks (WiOpt&apos;03)</title>
		<meeting>the Modeling and Optimization in Mobile, Ad Hoc and Wireless Networks (WiOpt&apos;03)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Coping with inaccurate reputation sources: experimental analysis of a probabilistic trust model</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T L</forename><surname>Teacy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Jennings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Luck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Joint Conference on Autonomous Agents and Multiagent Systems</title>
		<meeting>the Fourth International Joint Conference on Autonomous Agents and Multiagent Systems</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="997" to="1004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Filtering out unfair ratings in Bayesian reputation systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Whitby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>JÃ¸sang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Indulska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Icfain Journal of Management Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="48" to="64" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Detecting deception in reputation management</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAMAS&apos;03</title>
		<meeting>AAMAS&apos;03</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Immunizing online reputation reporting systems against unfair ratings and discriminatory behavior</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dellarocas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second ACM Conference on Electronic Commerce</title>
		<meeting>the Second ACM Conference on Electronic Commerce</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="150" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The beta reputation system</title>
		<author>
			<persName><forename type="first">A</forename><surname>JÃ¸sang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ismail</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Bled Conference on Electronic Commerce</title>
		<meeting>the 15th Bled Conference on Electronic Commerce</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J C</forename><surname>Mackay</surname></persName>
		</author>
		<title level="m">Information Theory, Inference, and Learning Algorithms</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>David</surname></persName>
		</editor>
		<editor>
			<persName><surname>Mackay</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2003-09">September 2003</date>
			<biblScope unit="volume">640</biblScope>
		</imprint>
	</monogr>
	<note>Bayesian inference and sampling theory. Chapter 37</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">User centric trust-based access control management for ubiquitous computing environments</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>O'sullivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International IEEE Workshop on Management of Ubiquitous Communications and Services (MUCS 2008)</title>
		<meeting>the Fifth International IEEE Workshop on Management of Ubiquitous Communications and Services (MUCS 2008)<address><addrLine>Salvador Bahia, Brazil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-04-11">April 11. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A comprehensive security, privacy and trust management framework for ubiquitous computing environment</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Lakshmi Eswari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Raghuram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Chaithanya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Manjulatha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jyostna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sarat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the UbiComp 2008 Workshop</title>
		<meeting>the UbiComp 2008 Workshop<address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Security in mobile ad hoc networks using soft encryption and trust-based multi-path routing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Narula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Dhurandher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Misra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Communications</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="760" to="769" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<title level="m">Trust Modeling and Management in Digital Environments: From Social Concept to System Development</title>
		<imprint>
			<publisher>IGI Global</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A context-based trust management model for pervasive computing systems</title>
		<author>
			<persName><forename type="first">N</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rahmani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohsenzadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Science and Information Security (IJCSIS)</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="137" to="142" />
			<date type="published" when="2009-10">October 2009</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Trustworthiness and quality of context information</title>
		<author>
			<persName><forename type="first">R</forename><surname>Neisse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wegdam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Sinderen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 International Smposium on Trusted Computing (TrustCom)</title>
		<meeting>the 2008 International Smposium on Trusted Computing (TrustCom)<address><addrLine>Hunan, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">November 18-20, 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Average throughput under varying malicious devices</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
