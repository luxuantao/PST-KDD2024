<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An active three-way clustering method via low-rank matrices for multi-view data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-03-05">March 5, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hong</forename><surname>Yu</surname></persName>
							<email>yuhong@cqupt.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Xincheng</forename><surname>Wang</surname></persName>
							<email>xincheng_wang@foxmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Guoyin</forename><surname>Wang</surname></persName>
							<email>wanggy@cqupt.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Xianhua</forename><surname>Zeng</surname></persName>
							<email>zengxh@cqupt.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Information Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Chongqing Key Laboratory of Computational Intelligence</orgName>
								<orgName type="institution">Chongqing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>400065</postCode>
									<settlement>Chongqing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An active three-way clustering method via low-rank matrices for multi-view data</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-03-05">March 5, 2018</date>
						</imprint>
					</monogr>
					<idno type="MD5">DC88465F379E217066A74FB68A10D4E2</idno>
					<idno type="DOI">10.1016/j.ins.2018.03.009</idno>
					<note type="submission">Received date: 26 September 2017 Revised date: 27 December 2017 Accepted date: 3 March 2018 Preprint submitted to Information Sciences</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Multi-view clustering</term>
					<term>Uncertain</term>
					<term>Three-way decisions</term>
					<term>Low-rank representation</term>
					<term>Active learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In recent years, multi-view clustering algorithms have shown promising performance by combining multiple sources or views of datasets. A problem that has not been addressed satisfactorily is the uncertain relationship between an object and a cluster. Thus, this paper investigates an active three-way clustering method via low-rank matrices that can improve clustering accuracy as clustering proceeds for the multi-view data of high dimensionality. We adopt a three-way clustering representation to reflect the three types of relationships between an object and a cluster, namely, belong-to definitely, uncertain and not belong-to definitely. We construct the consensus low-rank matrix from each weighted low-rank matrix by taking account of the diversity of views, and give the method to solve the optimization problem of objective function based on the improved augmented Lagrangian multiplier algorithm. We suggest an active learning strategy to learn important informative pairwise constraints after measuring the uncertainty of an object based on the entropy concept. The experimental results conducted on real-world datasets have validated the effectiveness of the proposed method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Highlights</head><p>• We research the problem for clustering on multi-view data with high dimensionality.</p><p>• We utilize the three-way clustering approach to cope with the uncertain relationship between objects and clusters.</p><p>• We present an active learning method by taking the advantage of three-way representation of clustering.</p><p>• We propose a multi-view information fusion method by using the low-rank matrix representation to capture the global structure from the weighted multiple views.</p><p>• The proposed framework is flexible for semi-supervised clustering as well as unsupervised clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Multi-view data are very common in some scientific data analytics problems such as computer video, social computing and environmental sciences, due to the use of different measuring methods (e.g. infrared and visual cameras), or of different media, like text, video and audio. Multi-view clustering (MVC), which makes use of the complementary information embedded in multiple views to improve clustering performance, has attracted more and more attentions <ref type="bibr" target="#b30">[30]</ref>. In the existing methods, spectral clustering is a popular one for multi-view data because it represents multi-view data via graph</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>structure and makes it possible to handle complex data such as high-dimensional and heterogeneous as well as it can easily use the pairwise constraint information provided by users <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b28">28]</ref>.</p><p>In some practical applications, particularly in the multimedia domain, a view is usually represented in a high-dimensional feature space. For high-dimensional data, the feature distribution is usually more sparse, the traditional similarity measurement methods based on distance measures become inapplicable. In order to solve this problem, the approaches based on low-rank representation try to learn a common lowdimensional subspace from the high-dimensional multi-view data and each object can be represented linearly by others objects in the same subspace, which contributes to reduce the computation cost and improves the robustness to noise corruptions <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b44">44]</ref>.</p><p>On the other hand, we find that a problem of the existing cluster analysis methods has not been addressed satisfactorily is the uncertain relationship between an object and a cluster. It is obviously that there are three relationships between an object and a cluster, namely, belong-to definitely, not belong-to definitely and uncertain. In most of the existing work, a cluster is represented by a single set, the set naturally divides the space into two regions. Objects belong to the cluster if they are in the set, otherwise they do not. Here, only two relationships are considered, no matter in hard clustering or in soft clustering. They are typically based on two-way (i.e., binary) decisions.</p><p>Let's obverse the third relationship, which means the object may or may not belong to the cluster. We just cannot make decisions based on the present obtained knowledge or information. We can make further certain decisions when we have further information. It is a typical idea of three-way decisions. Inspired by the theory of three-way decisions as suggested by Yao <ref type="bibr" target="#b35">[35,</ref><ref type="bibr" target="#b36">36]</ref>, Yu <ref type="bibr" target="#b37">[37]</ref> has introduced a framework of threeway cluster analysis (TWC). The previous results on three-way clustering <ref type="bibr" target="#b40">[40,</ref><ref type="bibr" target="#b38">38,</ref><ref type="bibr" target="#b41">41]</ref> provide us with a tool for studying the problem of clustering with uncertainty.</p><p>In this paper, we focus on a general framework based on the theory of three-way decisions, which is appropriate for soft clustering or hard clustering. This three-way representation with two sets brings more insight into interpretation of clusters. Objects in the core region certainly belong to the cluster, objects in the trivial region definitively do not belong to the cluster, and objects in the fringe region maybe or may not belong to the cluster. Obviously, the two-way representation with a single set is a special case of three-way representation with two sets when fringe regions are empty.</p><p>Compared with the supervised learning, clustering process lacks the user guidance or the class label information and may not produce the desired clusters. Thus, some semi-supervised clustering methods are proposed. These methods that use certain weak supervision form, such as pairwise constraints, can significantly improve the quality of unsupervised clustering. Pairwise constraints describe two objects whether they should be assigned to the same cluster or the different clusters. However, choosing the supervised information is random in most of existing methods, and it does not produce positive effect on improving the clustering result when the algorithm itself can find the prior information or there are amounts of noises in the prior information. Therefore, the active learning method is introduced to optimize the selection of the constraints for semi-supervised clustering <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b29">29]</ref>.</p><p>Hence, our work consider active learning of constraints in an iterative framework</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>based on spectral clustering. In each iteration, we determine objects with the most important information toward improving the current clustering result and form queries accordingly instead of choosing the information randomly. The responses to the queries (i.e., constraints) are then used to update the clustering. This process repeats until we reach a stable solution or we reach the maximum number of queries allowed. Such an iterative framework is widely used in active learning for semi-supervised clustering.</p><p>The measurement of information is designed based on the entropy concept. Besides, to take the advantage of three-way representation of clustering, it is reasonable to choose pairwise constraints in fringe regions instead of the universe, which will improve the search efficiency.</p><p>In this paper, we address the problem of clustering on multi-view data of high dimensionality. The main contributions are summarized as follows:</p><p>• A novel active three-way clustering method via low-rank matrices for multi-view data is proposed. It considers the diversity of multiple views and to improve the quality of clustering for multi-view data. A multi-view information fusion algorithm is presented via low-rank matrix representation for high-dimensional multi-view data, and the weights are adjusted adaptively on each view during solving the optimization problem of objective function.</p><p>• A three-way clustering representation is utilized to reflect the three relationships between an object and a cluster, namely, belong-to definitely, uncertain and not belong-to definitely. The three-way clustering approach provides us with a tool for studying the problem of clustering with uncertainty.</p><p>• An active three-way clustering algorithm is developed by taking the advantage of three-way representation of clustering, which can produce the three-way results as well as two-way results accordingly. The idea of farthest-first traversal scheme is used to construct the cores of clusters, then to expand cores to fringes by using the idea of k nearest neighbors, and the rules to adjust the consensus similarity matrix are also introduced.</p><p>• The proposed method is flexible for semi-supervised clustering as well as unsupervised clustering.</p><p>• We evaluate the proposed method with some other algorithms on seven realworld datasets. The results of comparative experiments demonstrate the effectiveness of the proposed method and show that it is appropriate for multi-view data of high dimensionality.</p><p>The rest of the paper is organized as follows. In Section 2, we review existing clustering algorithms for multi-view data, clustering approaches for uncertain relationships and active learning approaches for clustering. In Section 3, we give a detailed description of the proposed method termed Active Three-way Clustering via Low-rank Matrices (ATCLM). In Section 4, we report on an extensive experimental evaluation of the proposed method. Finally, we summarize the present study in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>In this section, we briefly introduce the background of the proposed method, which consists of multi-view clustering, clustering methods for uncertain relationships and active learning methods for clustering, and we point out several issues not addressed satisfactorily to motivate the present study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Multi-view clustering</head><p>Multi-view clustering algorithms have been developed to cluster multiple views simultaneously to derive a solution which uncovers the common latent structure shared by multiple views. In some application fields, the data may be of high dimensionality, which leads to high computational complexity. To address this problem, some achievements are presented. We can roughly classify them into two categories, namely, feature selection and subspace-based methods.</p><p>For some specific views which have a large number of redundant features, feature selection is a superior method that can both simplify calculation and improve clustering accuracy. Tzortzis and Likas <ref type="bibr" target="#b23">[23]</ref> proposed a multi-view kernel k-means algorithm which assigns a weight for each view according to the view's contribution to clustering result, and then combines the kernels derived from the weighted views together. However, it is based on the inner product kernels for all views and has no explicit mechanism for feature selection. Thus, Wang et al. <ref type="bibr" target="#b25">[25]</ref> developed a feature selection method for multi-view clustering which learns different weights for each feature via joint structured sparsity-inducing norms. Similarity, Chen et al. <ref type="bibr" target="#b6">[7]</ref> proposed an automated two-level variable weighting clustering algorithm for multi-view data, which can simultaneously compute weights for multiple views and each feature. One limitation of these methods lies in the fact that the same weighting scheme in their algorithms is applied both for view weighting and feature selection. Xu et al. <ref type="bibr" target="#b32">[32]</ref> designed two weighting schemes for weighting each view and feature, which can select the best view and the most representative feature space.</p><p>Subspace-based methods are another category to deal with the data of high dimensionality. Spectral clustering methods is a popular subspace-based method. Chaudhrui et al. <ref type="bibr" target="#b3">[4]</ref> developed canonical correlation analysis for multi-view spectral clustering by projecting the multiple views into one common lower dimensional subspace, where the spectral clustering is subsequently conducted. Kumar et al. <ref type="bibr" target="#b9">[10]</ref> presented a coregularized method for multi-view clustering which ensures the consistency of clustering on different views. Xia et al. <ref type="bibr" target="#b28">[28]</ref> proposed the multi-view spectral embedding algorithm which can learn a low-dimensional embedding wherein the distribution of each view is sufficiently smooth. Liu et al. <ref type="bibr" target="#b17">[18]</ref> proposed an adaptation of the non-negative matrix factorization for multi-view clustering. In their methods, the high-dimensional data are mapped in low-dimensional subspace by decomposing feature matrices into the liner combination of base vectors in subspace.</p><p>In recent years, low-rank representation has been successfully applied in clustering. Specifically, it can capture the global structure of data and has a good robustness to noisy data. The methods based on low-rank representation have shown great performance on single-view clustering, but quite few researches on multi-view clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T Xia et al. <ref type="bibr" target="#b27">[27]</ref> applied low-rank constraint to Markov chain method for multi-view clustering. It constructs a consensus matrix from the transition probability matrix on each view, but the diversity among views has not been considered adequately. Similarity, Zhao et al. <ref type="bibr" target="#b44">[44]</ref> proposed a multi-view clustering via low-rank representation, which obtains a low-rank consensus matrix. And the matrix-induced regularization term is incorporated in their algorithm to reduce the redundancy and enhance the diversity among multiple views.</p><p>Overall, the multi-view clustering methods indeed improve clustering performance for multi-view high dimensional datasets. However, they rarely consider the uncertain relationship between an object and a cluster. A cluster is represented by a single set in the most of existing work. Then, the universe is divided into two regions. These methods just assign an object into a cluster or not. We can resolve this problem by introducing a third region into the representation, which has been shown to be helpful for clustering in some data mining applications <ref type="bibr" target="#b38">[38,</ref><ref type="bibr" target="#b41">41]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Clustering approaches for uncertain relationships</head><p>The aim of clustering is to cluster similar objects into the same cluster and dissimilar objects into different clusters. Generally, there are three types of relationship between objects and clusters, namely, belong-to definitely, uncertain and not belongto definitely. In fact, three are some approaches such as fuzzy clustering, three-way clustering, interval clustering and rough clustering, are researched to deal with this kind of uncertain relationship. Sometimes, we also say that these approaches are soft clustering or overlapping clustering based on the meaning that an object can belong to more than one clusters. In other words, soft clustering technologies aim to relax the hard boundary of clusters by soft constraints, so that it can deal with problems such as overlapping clusters, outliers and uncertain objects <ref type="bibr" target="#b20">[21]</ref>. In this paper, we consider the three types of relationships between objects and clusters and take further measures for uncertainty.</p><p>Fuzzy c-means (FCM) is a method of clustering which allows an object to belong to two or more clusters. In the FCM, similarities between objects and each cluster are described by membership degrees based on the fuzzy sets theory, and all objects are assigned to k fuzzy clusters. However, it cannot get an exact representation of clusters by the fuzzy sets theory. To solve this issue, Lingras and Peters <ref type="bibr" target="#b14">[15]</ref> applied the rough sets theory to clustering, they present a new cluster representation that an object can belong to multiple clusters with the concepts of lower and upper approximations. In rough clustering, every cluster might have the fringe region (boundary region) to decrease cluster errors. Objects in fringe regions need more information so that they can be assigned to certain clusters eventually. Next, they combined rough sets to k-means and proposed the rough k-means clustering which each cluster is described by a lower and upper approximation. Since changes in general lead to uncertainty, the appropriate methods for uncertainty modeling are needed in order to capture, model, and predict the respective phenomena considered in dynamic environments, and Peters et al. <ref type="bibr" target="#b22">[22]</ref> proposed the dynamic rough clustering to detect changing data structures. In addition, Lingras and Yan <ref type="bibr" target="#b15">[16]</ref> developed fuzzy clustering by combining rough clustering, which a cluster is represented by a lower and upper approximation and two thresholds α and β are used to divide the two approximations. Considering clusters presented as</p><formula xml:id="formula_0">A C C E P T E D M A N U S C R I P T</formula><p>interval sets with lower and upper approximations in rough k-means clustering are not adequate to describe clusters, Chen and Miao <ref type="bibr" target="#b4">[5]</ref> proposed an interval set clustering based on decision theory.</p><p>The rough sets theory has played an important role in dealing with uncertain information. Yao introduced the Bayes risk decision-making into rough sets and proposed the decision-theoretic rough set model, then proposed the concept of three-way decisions <ref type="bibr" target="#b34">[34]</ref>. The theory of three-way decisions extends binary-decisions in order to overcome some drawbacks of binary-decisions. In the last few years, we have witnessed a fast growing development and applications of three-way approaches in areas of decision making <ref type="bibr" target="#b33">[33]</ref>, email spam filtering <ref type="bibr" target="#b45">[45]</ref>, three-way investment decisions <ref type="bibr" target="#b12">[13]</ref> and many others <ref type="bibr" target="#b39">[39]</ref>.</p><p>Inspired by the three-way decisions, Yu <ref type="bibr" target="#b37">[37]</ref> proposed a framework of three-way cluster analysis. The three-way clustering redefines the clustering representation and has been applied to dealing with some problems such as overlapping incremental clustering <ref type="bibr" target="#b41">[41]</ref>, community detection <ref type="bibr" target="#b38">[38]</ref> and high-dimensional data clustering <ref type="bibr" target="#b42">[42]</ref>. Similarity to rough clustering using a pair of lower and upper approximations to represent a cluster, three-way clustering describes a cluster by a pair of interval sets or two sets. General speaking, rough clustering usually restricts to the rough k-means and its extension algorithms. Different to that in rough clustering, which assumes that the intersection between any two lower approximations is empty, it seems more realistic for three-way clustering that the intersections do not have to be empty. For example, we have shown some real-world cases in the reference <ref type="bibr" target="#b38">[38]</ref>. Usually, uncertain objects in fringe regions need further treatment in three-way clustering when further information can be obtained.</p><p>In the above, we have analysed the existing approaches for dealing with uncertain relationships. Though these approaches such as fuzzy clustering, interval clustering and rough clustering are successful to deal with uncertain relationships, they often focus on single view data and have rarely been applied to multi-view datasets. Therefore, we employ the idea of three-way clustering for the problem of multi-view clustering with uncertainty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Active learning approaches for clustering</head><p>Compared to traditional semi-supervised clustering algorithms which randomly select objects to mark or select labelled objects for clustering, active learning methods actively select required objects, namely, the most valuable object. Thus, active learning approaches can reduce the cost of manual marking and obtain better clustering performance. Until now, it has been successfully applied in dealing with many fields such as natural language processing task and image classification.</p><p>Basu et al. <ref type="bibr" target="#b0">[1]</ref> proposed a semi-supervised clustering algorithm combining with active learning, and the algorithm terms as PCKMeans. The PCKmeans is a two phase's active learning algorithm based on farthest-first traversal scheme, but it is sensitive to noisy data. Mallapragada et al. <ref type="bibr" target="#b18">[19]</ref> proposed an improved active k-means based on Min-Max which modifies the consolidate phase by choosing the most uncertain object to query. Zhao et al. <ref type="bibr" target="#b43">[43]</ref> proposed a semi-supervised document clustering via active learning. Their algorithm introduces the pair-wise constraints for the DBSCAN to improve clustering performance, in which the objects in high density area and objects in</p><formula xml:id="formula_1">A C C E P T E D M A N U S C R I P T</formula><p>low density area are considered as core objects and fringe objects respectively. Xiong et al. <ref type="bibr" target="#b29">[29]</ref> proposed to select the most informative object by active learning method based on uncertainty, and pair-wise constraints are selected based on the concept of neighborhood which contains labeled objects.</p><p>In general, the active learning approaches can improve the clustering accuracy greatly, because the active learning approaches select the most informative unlabeled objects to the experts who help to label objects. However, the existing active learning clustering approaches have rarely focused on the high-dimensional multi-view datasets. Thus, we introduce the active learning method into our method. Besides, three-way clustering can be used to describe the uncertainty between objects and clusters, in which those uncertain objects are assigned to fringe regions and the searching space of active learning can be reduced greatly.</p><p>Hence, in this paper, we address the problem of clustering on multi-view data with high dimensionality, and some issues are considered: (1) the three-way clustering approach is used to cope with the uncertain relationship between objects and clusters, (2) the active leaning method, based on the advantage of three-way representation of clustering, is utilized to improve the accuracy of clustering, (3) the low-rank matrix representation is employed in capturing the global structure from the multiple views and improving the robustness to noisy data, and (4) the method to weight the different views adaptively is conducive to considering the diversity of views.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The proposed method</head><p>In this section, we propose the active three-way clustering method for multi-view data (ATCLM), the goal is to group the N objects into their corresponding classes. To make this paper clear, Table <ref type="table" target="#tab_0">1</ref> summarizes the symbols used in this paper. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Symbol Meaning X</head><p>The whole dataset N Number of objects in each view d (v)  Number of features in the v-th view</p><formula xml:id="formula_2">X (v)</formula><p>The v-th view dataset and</p><formula xml:id="formula_3">X (v) ∈ R N ×d (v) x (v) i</formula><p>The i-th object of the v-th view data and x</p><formula xml:id="formula_4">(v) i ∈ R d (v) ω v</formula><p>Weight for the v-th view λ Balance parameter controlling the effects of noise γ Scale parameter avoiding weights overfitting to a view</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">The framework of ATCLM</head><p>Assuming that we have a dataset</p><formula xml:id="formula_5">X = {x 1 , • • • , x i , • • • , x N }</formula><p>with N objects (data points) represented by V views, and X (1) , X (2) </p><formula xml:id="formula_6">, • • • , X (v) , • • • , X (V ) be the data matrix of each view respectively. For v-th view, X (v) ∈ R N ×d (v) , and d (v) is the feature dimension of the v-th view. X (v) = {x (v) 1 , x (v) 2 , • • • , x (v) i , • • • , x (v) N }, where A C C E P T E D M A N U S C R I P T x (v) i = (x 1 i,v , x 2 i,v , • • • , x j i,v , • • • , x d (v) i,v</formula><p>) is its i-th object, and x j i,v is the j-th feature of i-th object in the v-th view.</p><p>Fig. <ref type="figure">1</ref> describes the framework of the ATCLM method. It mainly consists of two stages. The first stage is the multi-view information fusion via low-rank representation (MIF), which aims to obtain the consensus similarity matrix from multiple views. The second stage is the active three-way clustering (ATC), which produces three-way clustering clusters. We will describe them in the following subsections. </p><formula xml:id="formula_7">1,1 1, * ,1 , N N N N w w W w w           </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-view data Low-rank matrix</head><p>The consensus low-rank matrix View 1</p><p>MIF: multi-view information fusion algorithm</p><formula xml:id="formula_8">1,1 1, * ,1 , N N N N z z Z z z            q&gt;Q or stable ... View V 1,1 1, ( ) ,1 , N V N N N z z Z z z            1,1 1, ( ) ,1 , N v N N N z z Z z z            1,1 1,<label>(1)</label></formula><p>, <ref type="bibr" target="#b0">1</ref> ,</p><formula xml:id="formula_9">N N N N z z Z z z            (1) X ( ) v X ( ) V X * x 1 1 {( ( ), ( )) Co C Fr C  C ,( ( ), ( ))} K K Co C Fr C 1  v  V  Figure 1</formula><p>The structural framework of the ATCLM method</p><p>As we have known, similarity measurement methods based on distance become inapplicable when the data be of high-dimensional. Multi-view clustering algorithms based on low-rank representation project the multiple views into one common lower dimensional subspace, which can capture the global structure and have great robustness to noisy. In order to describe the diversity of multiple views, we introduce the consensus low-rank matrix and measure the disagreement with each low-rank matrix, so that the consensus low-rank matrix can obtain the shared latent clustering structure of multiple views.</p><p>In order to make the clustering result more clear and describe the three types of relationships between objects and clusters, we adopt the framework of three-way clustering. That is, we assign definite objects to core regions and uncertain objects to fringe regions. First, the ATC algorithm obtains a coarse result based on the input of the consensus similarity matrix; in fact, the procedure can be implemented through any existing outstanding clustering approach. In this paper, we choose the spectral clustering approach <ref type="bibr" target="#b19">[20]</ref>, due to its ability to the data of high dimensionality. In other words, the ATC algorithm constructs the initial core regions, then extends the core regions and constructs fringe regions until the stop condition satisfied. Here, an active learning strategy is suggested after measuring the uncertainty based on the entropy concept. The strategy just takes the advantage of the three-way representation and to learn actively informative pairwise constraints from the fringe regions.</p><p>We have to note that the framework becomes an unsupervised clustering algorithm when there are no prior information can be obtained during clustering processing. If we need to take a further decision for those uncertain objects, the framework is an iterative process. It stops when the clustering result is stable or the iterative times q reaches the maximus number Q. Specifically, the clustering result is of two-way representation if the fringe regions of all clusters are empty. Otherwise, the output of clustering result is of three-way representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Multi-view information fusion algorithm</head><p>The basic idea of the multi-view information fusion algorithm is depicted in the left side of Fig. <ref type="figure">1</ref>, and it is described in Algorithm 1. First, for the multi-view data X (1) , • • • , X (V ) , we find the low-rank matrix of each view Z (1) , • • • , Z (V ) respectively. In order to obtain the shared latent clustering structure of multiple views, we normalize the multiple low-rank matrices to the consensus low-rank matrix Z * . Then, we get the consensus similarity matrix W * .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: MIF: the multi-view information fusion algorithm</head><formula xml:id="formula_10">Input: the multi-view data X (v) ∈ R d (v) ×N (v ∈ 1, • • • , V</formula><p>), the regularization parameter λ, the scale parameter γ Output: the consensus similarity matrix W *</p><formula xml:id="formula_11">1 t = 0, Z (v) 0 = Q (v) 0 = Y (v) 2,0 = 0, E v 0 = Y (v) 1,0 = 0, µ0 = 10 -6 , µmax = 10 10 , ρ = 1.9, ωv = 1/V , ε = 10 -9 2 repeat 3 for v = 1 to V do 4 update variable Q (v) t+1 , Z (v) t+1 , E (v)</formula><p>t+1 according to Eq. 8, Eq. 9, Eq. 10 respectively; 5 update weights ωv,t+1 according to Eq. 12; </p><formula xml:id="formula_12">6 update Lagrange multipliers Y (v) 1,t+1 , Y (v)</formula><formula xml:id="formula_13">10 until min X (v) -X (v) Z (v) -E (v) ∞ , Z (v) -Q (v) ∞ ≤ ε;</formula><p>11 construct the consensus similarity matrix W * by Eq. 1.</p><p>In Algorithm 1, Line 1 initializes some parameters. Line 2 to Line 10 is the iteration process to update the consensus low-rank matrix Z * . As explicitly revealed by most of the multi-view clustering research <ref type="bibr" target="#b9">[10]</ref>, it is always expected that the critical issue to ensure ideal multi-view clustering performance is to achieve the clustering agreement among all views. Based on that, we aim to minimize the difference of such low-rank representations from different views by proposing a consensus term to coordinate all views to reach clustering agreement. That is, the problem of constructing the consensus low-rank matrix is a typical low-rank optimization problem.</p><p>Besides, as the number of view increasing, some redundant views or views with data corruption may significantly affect the clustering performance, we calculate the weight of each view, i.e., ω 1 , • • • , ω V respectively, by measuring the disagreement between the consensus low-rank matrix Z * with low-rank matrix of each view Z (v) . These factors will be taken into account the objective function of the low-rank optimization problem.</p><p>Therefore, in what follows, we describe how to build the objective function of the rank optimization problem and how to solve the function in subsection 3.2.1 and subsection 3.2.2, respectively.</p><p>Once the consensus low-rank matrix Z * is obtained, a symmetrical similarity matrix W * can be defined as follows:</p><formula xml:id="formula_14">W * = (Z * + (Z * ) T )/2.</formula><p>(1)</p><p>Then, the similarity matrix W * serves as the initial input of the active three-way clustering algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">The objective function of rank optimization problem</head><p>As we have discussed above, the problem of constructing the consensus low-rank matrix is a typical rank minimization problem. Thus, in this subsection, we will introduce the objective function of the low-rank optimization problem.</p><p>First, let's review the representation of the rank minimization problem for a given single view. Given a set of objects, each of which can be represented as a linear combination of the bases in a dictionary. Liu et al. <ref type="bibr" target="#b16">[17]</ref> presented the Low-Rank Representation (LRR) method which seeks the lowest rank representation among all the candidates that can represent the data samples as linear combinations of the bases in a given dictionary. Considering the collected data are usually corrupted with some noisy and outliers, the objective function of the rank minimization problem can be formulated as follows:</p><formula xml:id="formula_15">min Z Z * + λ E 2,1 , s.t.X = XZ + E,<label>(2)</label></formula><p>where Z * is the nuclear norm of Z. E 2,1 is the l 2,1 -norm of noise E. The parameter λ &gt; 0 is used to balance the effects of the two terms.</p><p>When dealing with multi-view data, we can naturally derive the following objective function from Eq. 2 by minimizing the sum of the difference of such low-rank representations from different views, in order to propose a consensus term to coordinate all views to reach clustering agreement. Since it is commonly agreed that the key issue to ensure ideal multi-view clustering performance is to achieve the clustering agreement among all views. That is, the objective function of the rank minimization problem for multi-view data can be expressed as follows: min</p><formula xml:id="formula_16">Z (v) ,E (v) V v=1 Z (v) * + λ E (v) 2,1 , s.t. X (v) = X (v) Z (v) + E (v) , Z (v) ≥ 0,<label>(3)</label></formula><p>where Z (v)   * is the low-rank matrix of the v-th view X (v) , Z (v) ≥ 0 is a nonnegative constraint.</p><p>Generally, there are some complementary and diversity information among multiple views, and a clustering result of lower quality may be obtained while dealing with multi-view data using single-view clustering algorithm simply. Hence, we introduce the consensus low-rank matrix Z * and measure the disagreement with low-rank matrix of each view. In addition, considering the views which suffer data missing or data corruption seriously may affect the clustering performance, we calculate different weight for each view. Then, the objective function becomes as:</p><formula xml:id="formula_17">min Z * V v=1 Z (v) * + λ E (v) 2,1 + ω v 2 Z (v) -Z * 2 F + γ ω 2 , s.t. X (v) = X (v) Z (v) + E (v) , Z (v) ≥ 0, ω = (ω 1 , • • • , ω v , • • • , ω V ) T , ω v &gt; 0, V v=1 ω v = 1,<label>(4)</label></formula><formula xml:id="formula_18">A C C E P T E D M A N U S C R I P T where Z (v) -Z * 2</formula><p>F is a measure of disagreement between the consensus low-rank matrix and the low-rank matrix of the v-th view. γ is a tradeoff parameter avoiding weights overfitting to a view.</p><p>Eq. 4 is a typical low-rank optimization problem, and a lot of methods are available to solve it. In this paper, we employ the augmented Lagrange multipliers (ALM) method <ref type="bibr" target="#b13">[14]</ref>. To resolve this, we first introduce an auxiliary matrix Q (v) = R N ×N , then solving Eq. 4 with respect to Z * can be written as follows.</p><formula xml:id="formula_19">min Z * V v=1 ||Q (v) || * + λ||E (v) || 2,1 + ω v 2 ||Z (v) -Z * || 2 F + γ||ω|| 2 , s.t. X (v) = X (v) Z (v) + E (v) , Z (v) 0, Q (v) = Z (v) , ω = (ω 1 , • • • , ω v , • • • , ω V ) T , ω v &gt; 0, V v=1 ω v = 1.</formula><p>(</p><formula xml:id="formula_20">)<label>5</label></formula><p>We then present the augmented lagrangian function of Eq. 5 as follows:</p><formula xml:id="formula_21">min Q * V v=1 (||Q (v) || * + λ||E (v) || 2,1 + ω v 2 ||Z (v) -Z * || 2 F ) + γ||ω|| 2 + V v=1 Y (v) 1 , X (v) -X (v) Z (v) -E (v) + µ 2 ||X (v) -X (v) Z (v) -E (v) || 2 F + V v=1 Y (v) 2 , Z (v) -Q (v) + µ 2 ||Z (v) -Q (v) || 2 F s.t. X v = X (v) Z (v) + E (v) , Z (v) 0, Z (v) = Q (v) ω = (ω 1 , ω 2 , • • • , ω V ) T , ω v &gt; 0, V v=1 ω v = 1.<label>(6) where Y</label></formula><formula xml:id="formula_22">(v) 1 ∈ R d(v)×N , Y (v) 2</formula><p>∈ R N ×N are Lagrange multipliers. •, • denotes the inner product of two matrices, µ &gt; 0 is an adaptive penalty parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Solving the objective function</head><p>The optimization in Eq. 6 is difficult because of the nuclear norm and the l 2,1 -norm. In this subsection, we apply the Augmented Lagrange Multipliers (ALM) scheme <ref type="bibr" target="#b13">[14]</ref> to solve it. Moreover, the Entropic Mirror Descent Algorithm (EMDA) <ref type="bibr" target="#b1">[2]</ref> is used to optimize the weights for it is a convex minimization over the unit simplex. From the perspective of multivariable, the object function is non-convex function. However, when we consider only one variable and others variables are fixed, the objective function becomes a convex function. Thus, we solve each variable alternatively through minimizing the objective function.</p><p>Observing that the solving variables in each view follows the same type of strategy, we only present the optimization strategy for the v-th view.</p><formula xml:id="formula_23">• Updating Q (v) A C C E P T E D M A N U S C R I P T</formula><p>When with fixed other variables except Q (v) , the subproblem with regard to Q (v)  is:</p><formula xml:id="formula_24">Q (v) t+1 = argmin Q (v) ||Q (v) || * + µ 2 ||Q (v) -(Z (v) + Y (v) 2 /µ)|| 2 F .<label>(7)</label></formula><p>The subproblem can be solved by the Singular Value Threshold method <ref type="bibr" target="#b2">[3]</ref>. Assume U ΣV T is the Singular Value Decomposition (SVD) form, then we have:</p><formula xml:id="formula_25">Q (v) t+1 = U S 1/µt (Σ)V T ,<label>(8)</label></formula><p>where S δ (X) = max(Xδ, 0) + min(X + δ, 0) is a shrinkage operator.</p><formula xml:id="formula_26">• Updating Z (v)</formula><p>When with fixed other variables except Z (v) , the problem is converted to that:</p><formula xml:id="formula_27">Z (v) t+1 = (ω v,t + µ t )I + µ t (X (v) ) T X (v) -1 ω v,t Z * t + µ t (X (v) ) T (X (v) -E (v) t + Y (v) 1,t /µ t ) + µ t Q (v) t+1 -Y (v) 2,t .<label>(9)</label></formula><p>• Updating E (v)   When with fixed other variables except E (v) , the subproblem is:</p><formula xml:id="formula_28">E (v)</formula><p>t+1 =argmin</p><formula xml:id="formula_29">E (v) λ||E (v) || 2,1 + Y (v) 1 , X (v) -X (v) Z (v) -E (v) + µ 2 X (v) -X (v) Z (v) -E (v) 2 F =argmin E (v) λ||E (v) || 2,1 + µ 2 ||E (v) -(X (v) -X (v) Z (v) + Y (v) 1 /µ)|| 2 F =Ω λµ -1 t (X (v) -X (v) Z (v) t+1 + Y (v) t /µ t ),<label>(10)</label></formula><p>where Ω is the l 2,1 minimization operator <ref type="bibr" target="#b17">[18]</ref>.</p><p>• Updating Z * When with fixed other variables except Z * , the subproblem is:</p><formula xml:id="formula_30">Z * t+1 = argmin Z * V v=1 ω v ||Z (v) -Z * || 2 F = V v=1 ω v,t Z (v) t+1 V v=1 ω v,t .<label>(11)</label></formula><p>• Updating ω</p><p>When with fixed other variables except ω, the subproblem is:</p><formula xml:id="formula_31">argmin ωv V v=1 ω v ||Z (v) -Z * || 2 F + γ||ω|| 2 s.t. ω = (ω 1 , ω 2 , • • • , ω V ) T , V v=1 ω v = 1, ω v &gt; 0.<label>(12)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>The problem can be solved by the EMDA cause it is a convex minimization over the unit simplex. To apply the EMDA, its objective function f must be a convex Lipschitz continuous function and the Lipschitz constance L f is restricted to fixed paradigm. In this paper, the Lipschitz constance of ω is:</p><formula xml:id="formula_32">L f (ω) = V v=1 ||Z (v) -Z * || 2 F + 2γ.<label>(13)</label></formula><p>• Updating Y</p><formula xml:id="formula_33">(v) 1</formula><p>and</p><formula xml:id="formula_34">Y (v) 2</formula><p>We update Lagrange multipliers</p><formula xml:id="formula_35">Y (v) 1 via Y (v) 1,t+1 = Y (v) 1,t + µ t (X (v) -X (v) Z (v) t+1 -E (v) t+1 ),<label>(14)</label></formula><p>and</p><formula xml:id="formula_36">Y (v) 2 via Y (v) 2,t+1 = Y (v) 2,t + µ t (Z (v) t+1 -Q (v) t+1 ). (<label>15</label></formula><formula xml:id="formula_37">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Active three-way clustering algorithm</head><p>In order to describe the three types of relationships between objects and clusters, we adopt the idea of three-way decisions in this paper. In this subsection, we briefly review the three-way representation of clustering in our previous work <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b38">38,</ref><ref type="bibr" target="#b41">41]</ref> before introducing the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Three-way representation of clustering</head><p>Let a universe be</p><formula xml:id="formula_38">X = {x 1 , • • • , x n , • • • , x N }</formula><p>, and the result of clustering scheme,</p><formula xml:id="formula_39">C = {C 1 , • • • , C k , • • • , C K },</formula><p>is a family of clusters of the universe.</p><p>In the existing works, a cluster is usually represented by a single set, namely,</p><formula xml:id="formula_40">C k = {x 1 , • • • , x i , • • • , x |C k | },</formula><p>abbreviated as C without ambiguous. From the view of making decisions, the representation of a single set means that, the objects in the set belong to this cluster definitely, the objects not in the set do not belong to this cluster definitely. This is a typical result of two-way decisions. For hard clustering, one object just belong to one cluster; for soft clustering, one object might belong to more than one cluster. However, this two-way representation can not intuitively reveal the fact that which objects just are fringe to a cluster. The use of three regions to represent a cluster is more appropriate than the use of a crisp set, which also directly leads to three-way decisions based interpretation of clustering.</p><p>In contrast to the two-way representation of a cluster with a single set, we represent a three-way cluster as a pair of sets:</p><formula xml:id="formula_41">C = (Co (C) , F r (C)) .<label>(16)</label></formula><p>Here, Co(C) ⊆ X and F r(C) ⊆ X. Let T r(C) = X -Co(C) -F r(C). Then, Co(C), F r(C) and T r(C) naturally form the three regions related to a cluster as core region, fringe region and trivial region respectively. That is:</p><formula xml:id="formula_42">CoreRegion(C) = Co(C), F ringeRegion(C) = F r(C), T rivialRegion(C) = X -Co(C) -F r(C).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>If x ∈ CoreRegion(C), the object x belongs to the cluster C definitely; if x ∈ F ringeRegion(C), the object x might belong to C; if x ∈ T rivialRegion(C), the object x does not belong to C definitely. These subsets have the following properties:</p><formula xml:id="formula_43">X = Co(C) ∪ F r(C) ∪ T r(C), Co(C) ∩ F r(C) = ∅, F r(C) ∩ T r(C) = ∅ and T r(C) ∩ Co(C) = ∅.</formula><p>Obviously, the representation of a single set is a special case of the representation of three-way cluster when the fringe regions are empty. Furthermore, we know that it is enough and expedient to store a cluster by the core region and the fringe region. Compared to the two-way representation of clustering, the three-way representation only need an extra indicator, but it can bring us more advantages, especially when we need to work under the uncertain environment. The representation gives us an insight into the fringe of a cluster and reduces the computing time when we focus on these objects.</p><p>With respect to the family of clusters, C, we have the following family of clusters formulated by three-way representation as:</p><formula xml:id="formula_44">C = {(Co(C 1 ), F r(C 1 )), • • • , (Co(C k ), F r(C k )), • • • , (Co(C K ), F r(C K ))} .</formula><p>(17) Obviously, we have the following family of clusters formulated by two-way decisions as:</p><formula xml:id="formula_45">C = {Co(C 1 ), • • • , Co(C k ), • • • , Co(C K )} .<label>(18)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Description of Algorithm ATC</head><p>The active three-way clustering algorithm is described in Algorithm 2. Obviously, it is an iteration processing and it mainly consists of five procedures, namely, the spectral clustering processing, initial core regions construction, to extend core regions and construct fringe regions, to select the most informative object and to construct pairwise query.</p><p>The three-way clustering results are constructed by two steps. That is, we produce a preliminary result firstly, then to extend core regions and construct fringe regions. Thus, the goals of the spectral clustering processing are in two aspects as to produce a preliminary clustering result and to optimize the result by iterations as well. Basically, we can choose the other existing clustering approaches. In this paper, we adopt the spectral clustering algorithm from <ref type="bibr" target="#b19">[20]</ref>, which is described in Line 2 to Line 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Pairwise constraints</head><p>For understanding the work easily, we plug into the introduction of the pairwise constraints, which is one kind of typical prior information for semi-supervised clustering. Wagstaff and Cardie <ref type="bibr" target="#b24">[24]</ref> introduce must-link (positive association) and cannotlink (negative association) to reflect the constraint relations between the data points. For the universe</p><formula xml:id="formula_46">X = {x 1 , • • • , x i , • • • , x N }, let Y = {y 1 , • • • , y i , • • • , y N }</formula><p>be the class labels of objects respectively. Must-link constraint requires that the two objects must belong to the same cluster, and this relation is denoted by M L = {(x i , x j ) | y i = y j , f or i = j, x i , x j ∈ X, y i , y j ∈ Y }. Cannot-link constraint requires that the two objects must belong to different clusters, and this relation is denoted by CL = {(x p , x q ) | y p = y q , f or p = q, x p , x q ∈ X, y p , y q ∈ Y }. For x i , x j , x k ∈ X, Klein</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T et al. <ref type="bibr" target="#b8">[9]</ref> found that must-link constraint has the following transitivity properties on objects, that is:</p><formula xml:id="formula_47">(x i , x j ) ∈ M L &amp; (x j , x k ) ∈ M L ⇒ (x i , x k ) ∈ M L, (x i , x j ) ∈ M L &amp; (x j , x k ) ∈ CL ⇒ (x i , x k ) ∈ CL. (<label>19</label></formula><formula xml:id="formula_48">)</formula><p>Algorithm 2: The active three-way clustering algorithm</p><p>Input: the consensus similarity matrix W * , the number of clusters K; Output: the final clustering result     In this paper, we set a matrix R to store the constraint pairs, and initialize as R = ∅. When a pair of objects are must-link constraint relation, namely (x i , x j ) ∈ M L, the corresponding value of element in R updated to 1; when a pair of objects are cannotlink constraint relation, namely (x i , x j ) ∈ CL, the corresponding value of element in R updated to 0; At the end of each iteration, we update R according to the response of expert and the transitivity properties of Eq. 19, which is described in Line 31.</p><formula xml:id="formula_49">C = {(Co(C1), F r(C1)), • • • , (Co(C k ), F r(C k )), • • • , (Co(CK ), F r(CK ))}.</formula><formula xml:id="formula_50">if q = 1 then 7 CandidateSet ← X; l ← 1; q ← 0; for i=1 to K do {; 8 Co(C k ) ← ∅; F r(C k ) ← ∅}; 9 x ← Random(X); Co(C1) ← x; R ← ∅;</formula><formula xml:id="formula_51">if (x, xi) ∈ M L then { Co(Ci) ← Co(Ci) ∪ {x}; CandidateSet ← CandidateSet -{x}; M L count + = 1;} ; 15 if M L count = K /* no ML constraint is satisfied */ then 16 l + +; Co(C l ) ← Co(C l ) ∪ {x}; CandidateSet ← CandidateSet -{x};</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>Then, the consensus similarity matrix W * is adjusted by the following formula:</p><formula xml:id="formula_52">if (x i , x j ) ∈ M L, then w ij = w ji = 1; if (x i , x j ) ∈ CL, then w ij = w ji = 0. (<label>20</label></formula><formula xml:id="formula_53">)</formula><p>• Initialize core regions construction For the problem of clustering multi-category data, objects located on the fringe of a cluster contain more information than ones in the center. In this paper, we propose a method to select the core objects by using the farthest-first traversal scheme <ref type="bibr" target="#b0">[1]</ref>. The basic idea of farthest-first traversal of a set of points is to find K points such that they are far from each other.</p><p>Specifically, during the procedure of initial core regions construction, we first select a starting point at random, as indicated in Line 8. We then choose the next point to be farthest from the untraversed set CandidateSet by Eq. 21, which is described in Line 10 of Algorithm 2. Set l count the number of constructed core regions. Set AllCo denote the set of all core objects, i.e., AllCo = ∪ l i=1 Co(C i ). Based on the minmax criterion <ref type="bibr" target="#b18">[19]</ref>, the distance between an object x and AllCo is d(x, AllCo(i)) = min</p><formula xml:id="formula_54">y∈AllCo(i)</formula><p>||x -y||; then, the farthest one is picked by the following formula:</p><formula xml:id="formula_55">x ← arg max x∈CandidateSet d(x, AllCo) = arg max x∈CandidateSet ( min y∈AllCo(i)</formula><p>||x -y||).</p><p>(21) Next, we need to decide whether x and a point x i ∈ Co(C i )(1 ≤ i ≤ l) are in the same cluster. We make pair-wise queries through the form as: do points x and x i belong to the same cluster? If the ML constraint is satisfied, x is assigned to Co(C i ). If no one ML constraint is satisfied after traversing all core regions, a new core region Co(C l+1 ) is constructed and assign x to the new core region Co(C l+1 ). Line 11 to Line 15 describe the process.</p><p>• Extend core regions and construct fringe regions The algorithm extends core regions and constructs fringe regions after executing the spectral clustering processing as long as it is not in the first iteration. Set N (x) be a set of k neighbor objects of x. We extends regions by observing the relationship between a unlabelled (untraversed) object x and a labelled random object x i from Co(C i ). Here we resort to the last iteration result π to build N (x). If x is a neighbor of x i and x i is a neighbor of x, it seems they are much similar, and we assign x to the core region of C i . In contrast, if x is a neighbor of x i but x i is not a neighbor of x, obviously they are not similar as the front kind of situation, and we assign x to the fringe region of C i . Of course, if x is not a neighbor of x i , we think it is trivial to the cluster. That is, we have the following three-way decision rules:</p><formula xml:id="formula_56">if (x ∈ N (x i )) ∧ (x i ∈ N (x)), then Co(C i ) = Co(C i ) ∪ {x}, if (x ∈ N (x i )) ∧ (x i / ∈ N (x)), then F r(C i ) = F r(C i ) ∪ {x}.<label>(22)</label></formula><p>• Select the most informative object x * from fringe regions In addition, the active learning strategy is used in order to improve the performance of clustering. We select the most informative object and construct the pairwise query</p><formula xml:id="formula_57">A C C E P T E D M A N U S C R I P T</formula><p>to the expert through measuring the uncertain entropy of an object. A number of query strategies with various criteria of optimality have been devised. Perhaps the simplest and most commonly used query strategy is uncertainty sampling <ref type="bibr" target="#b11">[12]</ref>. In this framework, an active learner queries the objects that it can label with least confidence. This of course requires the use of a model that is capable of assessing prediction uncertainty.</p><p>In this work, we present a model to measure the uncertainty of object based on the similarity. Let w .j denote the similarity between x and x j , the similarity matrix W * has been obtained in the previous steps. Set U = ∪ K i=1 F r(C i ) denotes all uncertain objects currently. Xiong et al. <ref type="bibr" target="#b29">[29]</ref> have estimated the probability of an object belonging to each of the existing "labeled" neighborhoods. In our work, since we have gather the uncertainty objects into the fringe regions and the certain learned clusters are the core regions, we propose the following formula to estimate the probability of an uncertain object x belonging to a core region Co(C i ) as:</p><formula xml:id="formula_58">P (x ∈ Co(C i )) = 1 |Co(Ci)| xj ∈Co(Ci) w .j K l=1 1 |Co(C l )| xj ∈Co(C l ) w .j ,<label>(23)</label></formula><p>where |Co(C i )| is the number of objects in the core region Co(C i ).</p><p>Next, we measure the uncertainty of an object by the entropy as follows:</p><formula xml:id="formula_59">H(x) = - 1 K K i=1 (P (x ∈ Co(C i ))log 2 P (x ∈ Co(C i ))),<label>(24)</label></formula><p>where x ∈ U . Then, the most informative object is:</p><formula xml:id="formula_60">x * = arg max x∈U H(x).<label>(25)</label></formula><p>• Construct pairwise query Finally, the algorithm constructs pairwise queries after finding the most informative object x * . The measure of uncertainty will show its advantage in reducing the time of queries due to the uncertain objects are gathered in fringe regions. And to do this, we try to query the constraint relationship between x * and an object from a core region. When the probability P (x ∈ Co(C k )) is bigger, the object more likely belongs to the cluster. Thus, we sort the clusters by P (x ∈ Co(C k )) in descending order before making pairwise choice.</p><p>In order to further state our active learning strategy, we call the processing between Line 22 to Line 30 in Algorithm 2 as the active learning method based on three-way decisions (or ALT, for short).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Complexity anslysis</head><p>In this subsection, we firstly analyze the time complexity of the proposed ATCLM method. Becasue the proposed Eq. 23 to estimate the probability is inspired by the reference <ref type="bibr" target="#b29">[29]</ref> and the normalized point-based uncertainty (NPU) method in the reference is also an active learning algorithm, we then give a brief discussion between them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>The ATCLM consists of two stages, namely, Algorithm 1 and Algorithm 2. The most time-consuming of Algorithm 1 is the process of undating Q (v) by solving the SVD which costs O(N 3 ). Thus, the time complexity of Algorithm 1 is around O(N 3 ). For Algorithm 2, the spectral clustering processing from Line 1 to Line 4 is performed on a N × N matrix, which costs N 3 . The process of initializing core regions from Line 6 to Line 15 costs O(N K 2 ), and the cost of extending core regions and constructing fringe regions from Line 17 to Line 21 is O(F rN K), where F r = | ∪ K i=1 F r(C i )| is the number of objects in all fringe regions. From Line 22 to Line 30, the algorithm costs max(O(F r), O(K)) times elementary operations.</p><p>Then, we analyze two active learning strategies ALT and NPU from searching time cost and acquiring number of pairwise constraints. Observing the processing of selecting the most informative object, the runtime of NPU is O(N ) and the ALT costs O(F r). Because we construct the fringe regions to store uncertain objects, which can restrict the searching space to fringe regions instead of the universe. By contrast, the NPU searches the universe to find the most informative object. Here, Q is the maximus iteration times as well as the total number of queries allowed to ask. Therefore, the total runtime of NPU is O(N Q) and the ALT is O(F rQ). Obviously, F r N , thus the ALT is much efficient than the NPU in selecting the most informative object.</p><p>On the other hand, when we have more labeled pairwise objects in the last matrix R, we might obtain more constraint pairs in the new updated matrix according to the transitivity properties in Formula 19. In our method, we have constructed and extended core regions with the help of three-way decisions before selecting the most informative object and querying, that is, we have Co labeled objects, where</p><formula xml:id="formula_61">Co = | ∪ K i=1 Co(C i )|.</formula><p>Set L be the number of labelled objects in the NPU. Take the first iteration as an example, it is easy to know that Co &gt; L in general case. Then, the ALT can obtain more constraint pairs after the first iteration. And with the implementation of the iterations, the ALT could obtain more constraint pairs than the NPU.</p><p>In other words, the ALT can reduce the searching cost and increase the number of pairwise constraints in each iteration, which is helpful to produce more accurate and stable clustering result compared to the NPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental results</head><p>In this section, we conduct extensive experiments to evaluate the effectiveness of the proposed ATCLM clustering method on seven real-world data sets. We first test the performance sensitivity to the parameters λ and γ over three datasets and adopt such setting for other datasets in the following experiments. Then, we compare the proposed method with eight algorithms by measuring some standard indices such as the clustering accuracy (ACC), the F-measure and the normalized mutual information (NMI), where the objects in fringe regions are deemed to be core regions to fit these common formula. All experiments are repeated 10 times, and we report their averaged mean value and the standard deviation variances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Evaluation indices and datasets</head><p>Before reporting the results, we indicate the performance indices that we will adopt firstly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>The clustering accuracy is measured by counting the number of correctly assigned objects and dividing by the number of all objects. Formally, it is given by <ref type="bibr" target="#b31">[31]</ref>:</p><formula xml:id="formula_62">ACC = 1 N N i=1 δ(h i , map(l i )). (<label>26</label></formula><formula xml:id="formula_63">)</formula><p>where N is the number of objects, h i and l i denote the true label and the assigned cluster label of the ith object, respectively. δ(x, y) is a function that equals one when x = y and equals zero otherwise. The F-measure is defined as the harmonic mean between precision and recall <ref type="bibr" target="#b10">[11]</ref>:</p><formula xml:id="formula_64">F -measure = 2 × precision × recall precision + recall . (<label>27</label></formula><formula xml:id="formula_65">)</formula><p>The normalized mutual information (NMI) <ref type="bibr" target="#b7">[8]</ref> is defined as follows:</p><formula xml:id="formula_66">N M I(X, Y ) = H(X) + H(Y ) -H(X, Y ) (H(X) + H(Y ))/2 . (<label>28</label></formula><formula xml:id="formula_67">)</formula><p>where H(X) and H(Y ) are the entropy of random variables X and Y respectively, and H(X, Y ) is the joint entropy of X and Y . The value of NMI is between 0 and 1 and equals 1 only when the detected cluster and the real cluster are exactly coincident.</p><p>Next, we will introduce the used seven benchmark data sets, and the description of the datasets are summarized in Table <ref type="table" target="#tab_3">2</ref>. In the third column, every element records the number of dimensions for every corresponding view. For example, {3068, 3631, 3560} means there are 3068, 3631 and 3560 dimensions respectively for the three views of the 3-Sources dataset. </p><p>• 3-Sources dataset: 1 It is collected from three online news sources: BBC, Reuters and the Guardian. In total it consists of 416 distinct news manually categorized into six classes. Among them, 169 are reported in all three sources and each story was manually annotated with one of the six topical labels.</p><p>• WebKB dataset: 2 It consists of webpages collected from four universities: Texas, Cornell, Washington and Wisconsin. Each webpage can be described by the four views: content, inbound, view and cites. Since the four subsets of the dataset are similar in content and organization, we test our method on the Texas dataset. It contains 187 documents over 5 labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>• SensIT dataset: <ref type="foot" target="#foot_2">3</ref> It uses two sensors to classify three types of vehicle. We randomly sample 100 data for each class, and then conduct experiments on 2 views and three classes.</p><p>• Movies617 dataset: <ref type="foot" target="#foot_1">2</ref> It was extracted from IMDb(http://www.imdb.org), and consists of 617 movies over 17 labels. The two views are the 1878 keywords and the 1398 actors with a keyword used for at least 2 movies and an actor appeared in at least 3 movies.</p><p>• UCI handwritten digit dataset: <ref type="foot" target="#foot_3">4</ref> It consists of features of hand-written digits (0-9). The dataset is represented by 6 feature sets and contains 2000 samples with 200 in each category. We choose 76 Fourier coefficients of the character shapes and the 240 pixel averages in 2 × 3 windows as two views.</p><p>• Cora dataset: 2 It collects kinds of scientific publication, with the first view being the textural content of documents and the second view being citation links between documents.</p><p>• Citeseer dataset: 2 It collects kinds of scientific publication, with the first view being the textural content of documents and the second view being citation links between documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Parameter study</head><p>During the process of the multi-view information fusion in the proposed ATCLM framework, there are two parameters λ and γ. λ controls the effect of noise term and γ is used to avoid the weights of multiple views over fitting on one view. In this subsection, we investigate how the performance varies with the change of these two parameters on 3-Sources, WebKB and Movies617 datasets. Specifically, we test each value of one parameter while fixing the value of the other parameter, the accuracy and the NMI are illustrated in Fig. <ref type="figure">2</ref> and Fig. <ref type="figure">3</ref>.</p><p>Observe Fig. <ref type="figure">2</ref> and Fig. <ref type="figure">3</ref>, we can make the following conclusions. The parameter γ makes little effect on the performance of the proposed method. In other words, our method can generate stable results for a wide range of γ. For the parameter λ, the performance is relatively good when λ is in the range of [1e -6, 1e -3]. When λ = 1e -4, the performance is a little bit better on γ = 0.1 than other values. Thus, we suggest λ = 1e -4 and γ = 0.1 for the following experiments in all the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparison results</head><p>As we have discussed, the ATCLM method would be a unsupervised processing when there is no supervisory information obtained. That is, Algorithm 2 does not carry out Line 5 to Line 31. In this scenario, we call it as Unsupervised Clustering algorithm via Low-rank Matrices for multi-view data, shorted by UCLM. Correspondingly, the semi-supervised method is the proposed ATCLM, in which the active three-way learning strategy is used. To evaluate the performance of the proposed work, we compare our methods with the following algorithms. For fair comparison, we implement these competitors by following their experimental setting and the parameter tuning steps in their papers.</p><p>• Best Single View (BSV): running the clustering method UCLM on each input view, and then reporting the results of the view that achieves the best performance.</p><p>• Feature Concatenation (FeatCon): concatenating the features of all the views, and then run clustering method via UCLM on this concatenated view.</p><p>• Average Weighted Clustering (AWC): combining multiple views with equal weights to obtain the consensus similarity matrix and then run the spectral clustering processing in Line 2 to Line 4 of Algorithm 2.</p><p>• Co-regularized Spectral Clustering (CRSC) <ref type="bibr" target="#b9">[10]</ref>: adopting the coregularization framework in spectral clustering, and the Gussian kernel function is used to construct similarity matrix on each view. The parameter is set to 0.01 as suggested.</p><p>• Weighted Clustering with Feature Selection (WCFS) <ref type="bibr" target="#b32">[32]</ref>: designing different weighting schemes for view and feature. p and β are set to 10 and 0.1 respectively in the experiments.</p><p>• Low-rank and Matrix-induced Regularization (LRMIR) <ref type="bibr" target="#b44">[44]</ref>: obtaining transition probability matrix via LRR, and can reduce the redundancy and enforce diversity among multiple views. Two parameters are set to 0.25 in the experiments.</p><p>• Random strategy for pairwise queries (R-ATCLM): a variant from the proposed ATCLM method except the strategy of choosing pairwise constraints, namely, a baseline in which pairwise constraints are randomly sampled from the dataset.</p><p>• Normalized Point-based Uncertainty (NPU) <ref type="bibr" target="#b29">[29]</ref>: a neighborhood-based approach</p><formula xml:id="formula_69">A C C E P T E D M A N U S C R I P T</formula><p>which incrementally expands the neighborhoods by posing pairwise queries. Obviously, we know that the first six algorithms are unsupervised methods and the latter two algorithms are semi-supervised methods.</p><p>The BSV and the FeatCon are common contrastive strategies used to demonstrate the performance of dealing with multi-view data. The difference between the AWC and the proposed UCLM is that to deal with weights of views with different strategy, one is with equal weights and another one is with adaptive adjusting weights. The CRSC is a typical spectral clustering approach, one of most outstanding characteristics of the WCFS is that it designs different weighting schemes for views, and the LRMIR is a high performance clustering method via low-rank representation. What they have in common is that they are presented for dealing with multi-view data.</p><p>The R-ATCLM, the NPU and the ATCLM are based on active learning and are the semi-supervised clustering methods. The strategy of choosing pairwise constraints in the R-ATCLM is random, and the strategy in the NPU is to find pairwise constraints from the expanded neighborhoods. In contrast, the strategy in the ATCLM is to find the informative objects from the fringe regions by taking the advantage of three-way representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Results of unsupervised methods</head><p>To show the performance of dealing with multi-view data, we test the proposed method UCLM, the BSV, the FeatCon, the AWC, the CRSC <ref type="bibr" target="#b9">[10]</ref>, the WCFS <ref type="bibr" target="#b32">[32]</ref> and the LRMIR <ref type="bibr" target="#b44">[44]</ref> on the seven datasets. For fair comparison, the proposed UCLM is executed in this experiment because the compared algorithms are unsupervised methods. The ACC and the NMI are recorded in Table <ref type="table" target="#tab_4">3</ref>. Here, for the results of every dataset, the best one is in bold print and the second one is in italic print. Now, we can find that the proposed method almost outperforms all the compared ones for multi-view clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>As we expect, the BSV is poor for all datasets. The FeatCon is poor in most cases except on two datasets. It is interesting that, the AWC, which is also one of our work and different from the ATCLM in the strategy of wights on views, is the second best algorithm in the indices of both ACC and NMI. The result also demonstrate indirectly the effectiveness of the proposed method. Now, let us observe the CRSC, the WCFS and the LRMIR. The CRSC is a little bit better than the WCFS. The LRMIR is the best one of three. For example, the LRMIR is better in four datasets than the other two on the ACC index; and it is better in six datasets than the other two on the NMI index. The reason maybe that the lowrank representation can better capture the latent structure of datasets than the Gaussian kernel based Euclidean distance.</p><p>In a word, the results show that the method based on spectral clustering via lowrank representation is effective for multi-view data of high dimensionality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Results of semi-supervised methods</head><p>To show the performance of the active three-way learning strategy proposed in this paper, we test the proposed method ATCLM, the R-ATCLM and the NPU <ref type="bibr" target="#b29">[29]</ref> on SensIT, WebKb, Digits and 3-sources datasets. Fig. <ref type="figure" target="#fig_6">4</ref> and Fig. <ref type="figure" target="#fig_7">5</ref> depicts the NMI and the F-measure respectively with different number of queries on every dataset. From Fig. <ref type="figure" target="#fig_6">4</ref> and Fig. <ref type="figure" target="#fig_7">5</ref>, we see that the performance of the three methods are fairly close for all datasets when the number of queries is small. As the number of queries increases, the advantages of ATCLM and NPU become more and more pronounced. This is because the two active learning methods select the most informative object in each iterative process. Especially for the ATCLM, it outperforms the NPU in very early stage, since it searches the most informative object from the fringe region of each cluster instead of the whole datasets. However, there is no obvious law for the R-ATCLM method. It cannot enhance the clustering performance for the SensIT dataset,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>and actually degrades the performance in the Movies617 dataset. The reason maybe that there are some noisy data in the datasets and these noise points are selected as pairwise constraints. In short, the proposed method reaches the high performance with less queries compared with the contrast methods. That is, the framework of ATCLM not only can be applied in the scenario of unsupervised clustering for multi-view data, but also behaves well in the scenario of semi-supervised clustering for multi-view data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we have addressed the problem of clustering on multi-view data as well as the uncertain relationship between an object and a cluster. Therefore, we have proposed an active three-way clustering via low-rank matrices (ATCLM) to improve clustering performance for the multi-view data. We adopt a three-way clustering representation to reflect the three relationships between an object and a cluster, namely, belong-to definitely, uncertain and not belong-to definitely. The basic framework of ATCLM consists of two parts, namely the multi-view information fusion algorithm and the active three-way clustering algorithm. We solve the problem of constructing the consensus low-rank matrix as a typical low-rank optimization problem by applying the augmented Lagrange multipliers approach, and weight of each view is adjusted adaptively during solving the objective function. After measuring the uncertainty of an object based on the entropy concept, an active learning strategy to learn important informative pairwise constraints is suggested. The strategy just search in fringe regions instead of in the universe by taking the advantage of three-way representation of clustering, which makes the query more efficient. Experimental results on real-world datasets demonstrate the effectiveness of the proposed method. In the future work, we plan to reduce the computational burden of the active learning process by improving</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 repeat 2 / 5 /</head><label>25</label><figDesc>* the spectral clustering processing: */ 3 construct the normalized Laplacian matrix by L = I -D -1/2 W * D -1/2 ; 4 calculate the K smallest eigenvectors of L and let E ∈ R K×N be the matrix containing these eigenvectors as rows; normalize the columns of E to have unit Euclidean norm; cluster the columns of E into π = {C1, • • • , CK } using k-means; * initialize core regions construction: */ 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>10 while l &lt; K do 11 select 12 for i=1 to K do 13 xi</head><label>10111213</label><figDesc>x from CandidateSet according to Eq.21; M L count ← 0; ← Random(Co(Ci)); query (x, xi);</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>14</head><label>14</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>17 / 18 for every x ∈ CandidateSet do 19 for i=1 to K do 20 xi 23 /</head><label>1718192023</label><figDesc>* extend core regions and construct fringe regions: */ ← Random(Co(Ci)); 21 if x ∈ N (xi) then 22 assign xi to Co(Ci) or F r(Ci) by the three-way rules 22; continue; * select the most informative object x * from fringe regions: */</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 2 Figure 3</head><label>23</label><figDesc>Figure 2 ACC of the proposed ATCLM for λ and γ on three datasets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4</head><label>4</label><figDesc>Figure 4 NMI on four real-world datasets with three algorithms</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 F</head><label>5</label><figDesc>Figure5F-measure on four real-world datasets with three algorithms</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Symbols used in this paper</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>2,t+1 according to Eq. 14 and Eq. 15;</figDesc><table /><note><p>7 update variable Z * t+1 according to Eq. 11; 8 update µ : µt+1 = min(µmax, ρµt); 9 update t : t ← t + 1;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc>Information of the multi-view datasets</figDesc><table><row><cell>Datasets</cell><cell># of objects</cell><cell># of dimensions</cell><cell cols="2"># of views # of clusters</cell></row><row><cell>3-Sources WebKB SensIT Movies617 Digits Cora Citeseer</cell><cell>169 187 300 617 2000 2708 3312</cell><cell>{3068,3631,3560} {1703,187,187,187} {50,50} {1878,1398} {240,76} {2708,1433} {3703,3312}</cell><cell>3 4 2 2 2 2</cell><cell>6 5 3 17 10 7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>Comparison results on ACC and NMI with seven algorithms</figDesc><table><row><cell cols="3">Indices Algorithms 3Source</cell><cell>WebKB</cell><cell>SensIT</cell><cell>Movies617 Digits</cell><cell>Cora</cell><cell>Citeseer</cell></row><row><cell></cell><cell>BSV</cell><cell cols="5">0.61±0.02 0.66±0.00 0.66±0.00 0.23±0.01 0.67±0.01 0.32±0.00 0.29±0.00</cell></row><row><cell></cell><cell>FeatCon</cell><cell cols="5">0.70±0.00 0.68±0.00 0.74±0.00 0.24±0.01 0.69±0.00 0.35±0.00 0.31±0.00</cell></row><row><cell></cell><cell>AWC</cell><cell cols="5">0.75±0.02 0.70±0.00 0.74±0.00 0.30±0.01 0.73±0.05 0.46±0.00 0.48±0.00</cell></row><row><cell>ACC</cell><cell cols="6">CRSC [10] 0.50±0.01 0.45±0.00 0.76±0.00 0.28±0.01 0.59±0.01 0.32±0.01 0.46±0.11</cell></row><row><cell></cell><cell cols="6">WCFS [32] 0.40±0.05 0.60±0.05 0.65±0.01 0.11±0.01 0.61±0.06 0.32±0.01 0.22±0.01</cell></row><row><cell></cell><cell cols="6">LRMIR [44] 0.58±0.02 0.59±0.01 0.66±0.02 0.25±0.01 0.70±0.03 0.41±0.00 0.49±0.00</cell></row><row><cell></cell><cell>Proposed</cell><cell cols="4">0.77±0.01 0.69±0.01 0.71±0.00 0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>.30±0.01 0.78±0.00 0.47±0.00 0.49±0.00</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>BSV</cell><cell>0.38±0.03 0.30±0.00 0.27±0.00 0.21±0.01 0.59±0.00 0.03±0.00 0.04±0.00</cell></row><row><cell></cell><cell>FeatCon</cell><cell>0.56±0.00 0.32±0.00 0.37±0.00 0.22±0.01 0.60±0.00 0.07±0.00 0.05±0.00</cell></row><row><cell></cell><cell>AWC</cell><cell>0.62±0.02 0.32±0.01 0.37±0.00 0.27±0.01 0.66±0.03 0.22±0.00 0.21±0.00</cell></row><row><cell>NMI</cell><cell cols="2">CRSC [10] 0.30±0.01 0.16±0.00 0.17±0.00 0.22±0.01 0.50±0.00 0.11±0.01 0.17±0.00</cell></row><row><cell></cell><cell cols="2">WCFS [32] 0.13±0.05 0.15±0.09 0.27±0.02 0.08±0.02 0.61±0.04 0.04±0.04 0.01±0.00</cell></row><row><cell></cell><cell cols="2">LRMIR [44] 0.41±0.04 0.16±0.02 0.29±0.02 0.24±0.01 0.66±0.02 0.15±0.00 0.22±0.00</cell></row><row><cell></cell><cell>Proposed</cell><cell>0.63±0.00 0.27±0.01 0.32±0.00 0.27±0.01 0.72±0.00 0.24±0.00 0.25±0.00</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://mlg.ucd.ie/datasets/3sources.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://membres-lig.imag.fr/grimal/data.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://www.csie.ntu.edu.tw/˜cjlin/libsvmtools/datasets/multiclass.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://archive.ics.uci.edu/ml/datasets.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>This work was supported in part by the National Natural Science Foundation of China under Grant Nos. 61379114, 61533020 &amp; 61672120.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>An active threeway clustering method via low-rank matrices for multi-view data, Information Sciences (2018),</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>the algorithm to select multiple query samples at each iteration. Determination of parameters used in the algorithm automatically will by one of our planned future work. To extend the method to multi-view clustering with missing data is another direction for future research. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Active semisupervision for pairwise constrained clustering</title>
		<author>
			<persName><forename type="first">Sugato</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arindam</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th SIAM International Conference on Data Mining (SDM 2004)</title>
		<meeting>the 4th SIAM International Conference on Data Mining (SDM 2004)</meeting>
		<imprint>
			<publisher>SIAM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="333" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Mirror descent and nonlinear projected subgradient methods for convex optimization</title>
		<author>
			<persName><forename type="first">Amir</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research Letters</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="167" to="175" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A singular value thresholding algorithm for matrix completion</title>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmanuel</forename><forename type="middle">J</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zuowei</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1956" to="1982" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multi-view clustering via canonical correlation analysis</title>
		<author>
			<persName><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Livescu</surname></persName>
		</author>
		<author>
			<persName><surname>Sridharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning (ICML 2009)</title>
		<meeting>the 26th Annual International Conference on Machine Learning (ICML 2009)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Interval set clustering. Expert Systems with Applications</title>
		<author>
			<persName><forename type="first">Min</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duoqian</forename><surname>Miao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="2923" to="2932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Spectral clustering: a semi-supervised approach</title>
		<author>
			<persName><forename type="first">Weifu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guocan</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">neurocomputing</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="229" to="242" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>Neurocomputing</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tw-kmeans: Automated two-level variable weighting clustering algorithm for multiview data</title>
		<author>
			<persName><forename type="first">Xiaojun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">Zhexue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunming</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="932" to="944" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Comparing community structure identification</title>
		<author>
			<persName><forename type="first">Leon</forename><surname>Danon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Diaz-Guilera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordi</forename><surname>Duch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Arenas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Mechanics: Theory and Experiment</title>
		<imprint>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">9008</biblScope>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">From instancelevel constraints to space-level constraints: Making the most of prior knowledge in data clustering</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sepandar</forename><forename type="middle">D</forename><surname>Kamvar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<pubPlace>Stanford</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Co-regularized multi-view spectral clustering</title>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piyush</forename><surname>Rai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hal</forename><surname>Daume</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Annual Conference on Neural Information Processing Systems (NIPS 2011)</title>
		<meeting>the 25th Annual Conference on Neural Information Processing Systems (NIPS 2011)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1413" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast and effective text mining using lineartime document clustering</title>
		<author>
			<persName><forename type="first">Bjornar</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chinatsu</forename><surname>Aone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD</title>
		<meeting>the 5th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999. 1999</date>
			<biblScope unit="page" from="16" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A sequential algorithm for training text classifiers</title>
		<author>
			<persName><forename type="first">D</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">A</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><surname>Gale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 1994)</title>
		<meeting>the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 1994)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Systematic studies on three-way decisions with interval-valued decision-theoretic rough sets</title>
		<author>
			<persName><forename type="first">Decui</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">276</biblScope>
			<biblScope unit="page" from="186" to="203" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">The augmented lagrange multiplier method for exact recovery of corrupted low-rank matrices</title>
		<author>
			<persName><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minming</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Ma</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1009" />
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">5055</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Applying rough set concepts to clustering</title>
		<author>
			<persName><forename type="first">Pawan</forename><surname>Lingras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Rough Sets, Fuzzy Sets, Data Mining and Granular Computing</title>
		<meeting>the 14th International Conference on Rough Sets, Fuzzy Sets, Data Mining and Granular Computing</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">RSFDGrC 2013. 2012</date>
			<biblScope unit="page" from="23" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Interval clustering using fuzzy and rough set theory</title>
		<author>
			<persName><forename type="first">Pawan</forename><surname>Lingras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Annual Meeting of the North American Fuzzy Information Processing Society (NAFIPS 2004)</title>
		<meeting>Annual Meeting of the North American Fuzzy Information Processing Society (NAFIPS 2004)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="780" to="784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Robust recovery of subspace structures by low-rank representation</title>
		<author>
			<persName><forename type="first">Guangcan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ju</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="171" to="184" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-view clustering via joint nonnegative matrix factorization</title>
		<author>
			<persName><forename type="first">Jialu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th SIAM International Conference on Data Mining (SMD 2013)</title>
		<meeting>the 13th SIAM International Conference on Data Mining (SMD 2013)</meeting>
		<imprint>
			<publisher>SIAM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="252" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Active query selection for semi-supervised clustering</title>
		<author>
			<persName><forename type="first">Rong</forename><surname>Pavan K Mallapragada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anil K</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Pattern Recognition (ICPR 2008)</title>
		<meeting>the 19th International Conference on Pattern Recognition (ICPR 2008)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yair</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Neural Information Processing Systems Conference (NIPS 2001)</title>
		<meeting>the 15th Annual Neural Information Processing Systems Conference (NIPS 2001)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="849" to="856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Soft clustering-fuzzy and rough approaches and their extensions and derivatives</title>
		<author>
			<persName><forename type="first">Georg</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Crespo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pawan</forename><surname>Lingras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Approximate Reasoning</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="307" to="322" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName><surname>A C C E P T E D M A N U S C R I P T</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dynamic rough clustering and its applications</title>
		<author>
			<persName><forename type="first">Georg</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">René</forename><surname>Nowatzke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3193" to="3207" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Kernel-based weighted multi-view clustering</title>
		<author>
			<persName><forename type="first">Grigorios</forename><surname>Tzortzis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aristidis</forename><surname>Likas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Data Mining (ICDM 2012)</title>
		<meeting>the 12th International Conference on Data Mining (ICDM 2012)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="675" to="684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Clustering with instance-level constraints</title>
		<author>
			<persName><forename type="first">Kiri</forename><surname>Wagstaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Machine Learning (ICML 2000)</title>
		<meeting>the 7th International Conference on Machine Learning (ICML 2000)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1103" to="1110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multi-view clustering and feature learning via structured sparsity</title>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feiping</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Huang</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning (ICML 2013)</title>
		<meeting>the 30th International Conference on Machine Learning (ICML 2013)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="352" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On multi-view active learning and the combination with semi-supervised learning</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihua</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Machine Learning (ICML 2008)</title>
		<meeting>the 25th International Conference on Machine Learning (ICML 2008)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1152" to="1159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Robust multi-view spectral clustering via low-rank and sparse decomposition</title>
		<author>
			<persName><forename type="first">Rongkai</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th AAAI Conference on Artifical Intelligence (AAAI 2014)</title>
		<meeting>the 28th AAAI Conference on Artifical Intelligence (AAAI 2014)</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2149" to="2155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multiview spectral embedding</title>
		<author>
			<persName><forename type="first">Tian</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongdong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1438" to="1446" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Active learning of constraints for semi-supervised clustering</title>
		<author>
			<persName><forename type="first">Sicheng</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javad</forename><surname>Azimi</surname></persName>
		</author>
		<author>
			<persName><surname>Xiaoli Z Fern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="54" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">A survey on multi-view learning</title>
		<author>
			<persName><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1304.5634" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Document clustering based on non-negative matrix factorization</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yihong</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval (SIGIR 2003)</title>
		<meeting>the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval (SIGIR 2003)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="267" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Weighted multi-view clustering with feature selection</title>
		<author>
			<persName><forename type="first">Yumeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianhuang</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="25" to="35" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Web-based medical decision support systems for three-way medical decision making with game-theoretic rough sets</title>
		<author>
			<persName><forename type="first">Jingtao</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nouman</forename><surname>Azam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="15" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Three-way decision: An interpretation of rules in rough set theory</title>
		<author>
			<persName><forename type="first">Yiyu</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Conference on Rough Sets and Knowledge Technology (RSKT 2009)</title>
		<meeting>the 4th International Conference on Rough Sets and Knowledge Technology (RSKT 2009)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="642" to="649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">An outline of a theory of three-way decisions</title>
		<author>
			<persName><forename type="first">Yiyu</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Rough Sets and Current Trends in Computing (RSCTC 2012)</title>
		<meeting>the 8th International Conference on Rough Sets and Current Trends in Computing (RSCTC 2012)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Three-way decisions and cognitive computing</title>
		<author>
			<persName><forename type="first">Yiyu</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="543" to="554" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A framework of three-way cluster analysis</title>
		<author>
			<persName><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Rough Sets (IJCRS 2017)</title>
		<meeting>the International Joint Conference on Rough Sets (IJCRS 2017)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="300" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Detecting and refining overlapping regions in complex networks with three-way decisions</title>
		<author>
			<persName><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiyu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoyin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">373</biblScope>
			<biblScope unit="page" from="21" to="41" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Methods and practices of threeway decisions for complex problem solving</title>
		<author>
			<persName><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoyin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baoqing</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Rough Sets and Knowledge Technology (RSKT 2015)</title>
		<meeting>the 10th International Conference on Rough Sets and Knowledge Technology (RSKT 2015)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="255" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Three-way decisions: methods and practices for complex problem solving</title>
		<author>
			<persName><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoyin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianrui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiye</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duoqian</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiyu</forename><surname>Yao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Science Publication</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Beijing</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A tree-based incremental overlapping clustering method using the three-way decision theory</title>
		<author>
			<persName><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoyin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="189" to="203" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A three-way decision clustering approach for high dimensional data</title>
		<author>
			<persName><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibo</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Rough Sets (IJCRS 2016)</title>
		<meeting>the International Joint Conference on Rough Sets (IJCRS 2016)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="229" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Effective semisupervised document clustering via active learning with instance-level constraints</title>
		<author>
			<persName><forename type="first">Weizhong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huifang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongzhi</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and information systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="569" to="587" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A novel multi-view clustering method via low-rank and matrix-induced regularization</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinwang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">216</biblScope>
			<biblScope unit="page" from="342" to="350" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Cost-sensitive three-way email spam filtering</title>
		<author>
			<persName><forename type="first">Bing</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiyu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jigang</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Information Systems</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="45" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
