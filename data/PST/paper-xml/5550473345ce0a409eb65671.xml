<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Guidelines for Snowballing in Systematic Literature Studies and a Replication in Software Engineering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Claes</forename><surname>Wohlin</surname></persName>
							<email>claes.wohlin@bth.se</email>
							<affiliation key="aff0">
								<orgName type="institution">Blekinge Institute of Technology</orgName>
								<address>
									<postCode>SE -371 79</postCode>
									<settlement>Karlskrona</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<address>
									<postCode>2014 ACM 978-1-4503-2476-2/14/05â€¦$15.00</postCode>
									<settlement>London</settlement>
									<region>BC</region>
									<country>England, United Kingdom Copyright</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Guidelines for Snowballing in Systematic Literature Studies and a Replication in Software Engineering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F18F1B561FC2C88DE9164FCC0CC867CF</idno>
					<idno type="DOI">10.1145/2601248.2601268</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>D.2 [Software Engineering]: Management</term>
					<term>and G.3 [Probability and Statistics]: Experimental design Experimentation</term>
					<term>Measurement Systematic literature review</term>
					<term>systematic mapping studies</term>
					<term>snowballing</term>
					<term>snowball search</term>
					<term>replication</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Background: Systematic literature studies have become common in software engineering, and hence it is important to understand how to conduct them efficiently and reliably. Objective: This paper presents guidelines for conducting literature reviews using a snowballing approach, and they are illustrated and evaluated by replicating a published systematic literature review. Method: The guidelines are based on the experience from conducting several systematic literature reviews and experimenting with different approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results:</head><p>The guidelines for using snowballing as a way to search for relevant literature was successfully applied to a systematic literature review. Conclusions: It is concluded that using snowballing, as a first search strategy, may very well be a good alternative to the use of database searches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Systematic literature studies, including both reviews and maps, have emerged as a way of synthesizing evidence and then ultimately allowing researchers to come to a joint understanding of the status of a research area in software engineering in the last decade. Inspired by medicine, the concept of evidence-based software engineering was coined by Kitchenham et al. <ref type="bibr" target="#b14">[1]</ref>. Similar ideas have been brought into information systems research, e.g. by Webster and Watson <ref type="bibr" target="#b15">[2]</ref>.</p><p>However, the need to synthesize research results in software engineering was discussed already in the late 1990s <ref type="bibr" target="#b16">[3,</ref><ref type="bibr" target="#b17">4,</ref><ref type="bibr" target="#b18">5]</ref>. Pickard et al. <ref type="bibr" target="#b16">[3]</ref> discuss combining research results, Miller <ref type="bibr" target="#b17">[4]</ref> addresses the issue of combining research results through metaanalysis and Hayes <ref type="bibr" target="#b18">[5]</ref> uses the concept of synthesis of research results. They all have in common that they stress the need for a systematic approach to not only conducting individual research studies, but also to building knowledge from combining findings from different studies on a topic. One such early example is the work by Basili et al. <ref type="bibr" target="#b19">[6]</ref>, where the authors look into combining the research and hence knowledge we have regarding research on software inspections.</p><p>Based on the original EBSE ideas <ref type="bibr" target="#b14">[1]</ref>, research related to systematic literature studies has subsequently evolved. Guidelines for conducting systematic literature reviews have been developed <ref type="bibr" target="#b20">[7]</ref>. Systematic mapping studies have been highlighted as a complement to systematic literature reviews <ref type="bibr">[8]</ref>. Kitchenham et al. <ref type="bibr" target="#b22">[9]</ref> discuss the use of systematic mapping studies as a starting point for further research. Here, we use systematic literature studies as a collective term for systematic literature reviews and systematic mapping studies. This paper complements previous guidelines for systematic literature reviews in software engineering. It does so by extending and detailing the steps for using snowballing as a search approach for systematic literature studies. Snowballing refers to using the reference list of a paper or the citations to the paper to identify additional papers. However, snowballing could benefit from not only looking at the reference lists and citations, but to complement it with a systematic way of looking at where papers are actually referenced and where papers are cited. Using the references and the citations respectively is referred to as backward and forward snowballing. It builds on ideas presented by for example Webster and Watson <ref type="bibr" target="#b15">[2]</ref> in information systems and the procedure outlined by Wohlin and Prikladnicki <ref type="bibr" target="#b23">[10]</ref>. The snowballing guidelines are illustrated and evaluated by replicating a published reliability study of systematic literature reviews <ref type="bibr" target="#b24">[11]</ref>. In this paper, the authors conducted two systematic literature reviews in parallel to evaluate the reliability of literature reviews.</p><p>The evaluation here provides a third data point using snowballing as the main approach to identify relevant literature while a database-driven search was applied in the reliability study by MacDonell et al. <ref type="bibr" target="#b24">[11]</ref>.</p><p>Based on the above motivation, this paper has two main research objectives:</p><p>1. Formulate a systematic snowballing procedure for systematic literature studies in software engineering, 2. Illustrate and evaluate the snowballing procedure by replicating a published systematic literature review.</p><p>The remainder of the paper is outlined as follows. Related work is presented in Section 2. The snowballing procedure is presented in Section 3. The replication of the systematic literature reviews presented in <ref type="bibr" target="#b24">[11]</ref> using the snowballing procedure is presented in Section 4. A discussion of the snowballing procedure is provided in Section 5. Finally, a summary is presented in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>The guidelines for systematic literature reviews <ref type="bibr" target="#b20">[7]</ref> are very important in supporting researchers in conducting systematic literature studies. However, they have also generated discussions.</p><p>According to the guidelines, the objective is to identify all relevant research. This is fine as an objective, but it is unlikely to work in practice in particular for literature studies of a broader area. The challenge related to population of papers vs. the actual sample identified is discussed in, for example, <ref type="bibr" target="#b25">[12]</ref>. A study by Kitchenham et al. <ref type="bibr" target="#b26">[13]</ref> may be used to exemplify the challenge. They conducted a systematic literature review using manual search and found 20 relevant papers. When the authors discussed limitations of the study, they mentioned the fact that they used manual search and may have missed some relevant studies. Due to this limitation, Kitchenham et al. <ref type="bibr" target="#b27">[14]</ref> repeated the study using an automated database search and found 33 additional studies. This example illustrates that we end up being forced into accepting samples of relevant papers; the challenge is to get the best possible sample from the population. Thus, the search strategy is key to ensure a good starting point for the identification of studies and ultimately for the actual outcome of the study.</p><p>The example from Kitchenham et al. <ref type="bibr" target="#b26">[13,</ref><ref type="bibr" target="#b27">14]</ref> gives the impression that automation is better than manual search. However, the point is not really about manual vs. automatic; it is really about being systematic. The claim is based on the fact that even if database searches can be made automatically, the search is not better than the search string used. It is very difficult to formulate good search strings, since all too often the terminology used is not standardized and if using broad search terms then a large number of irrelevant papers will be found in the search. The latter creates substantial manual work that also is error-prone.</p><p>The guidelines <ref type="bibr" target="#b20">[7]</ref> take database searches using search strings from the area of study as a starting point. However, the guidelines also state that other complementary searches are needed. The latter includes for example: reference lists, grey literature, specific research outlets (journals or conferences) and researchers in the field. Unfortunately, most systematic literature studies stop short of these complementary searches. This may be understandable given the amount of work it is to conduct systematic searches in a number of databases and then identify the relevant papers of sufficiently high quality. The searches in databases are challenging for several reasons, including selection of databases, different interfaces for the databases, different ways of constructing search strings, different search limitations in the databases and identification of synonyms of terms used. This reasoning leads to two conclusions: 1) the choice of the first step in the search strategy often becomes the only step, i.e. search databases (if using the guidelines), and 2) given the challenges with the database searches, we may miss important literature. Thus, other alternative approaches may be considered, for example, the use of a snowballing procedure <ref type="bibr" target="#b15">[2]</ref>.</p><p>Greenhalgh and Peacock <ref type="bibr" target="#b28">[15]</ref> applied three different search methods in their research, and concluded that protocol-driven search approaches by themselves are not necessarily the most efficient method regardless of the number of databases used, since some sources may be found through personal knowledge/contacts (e.g. browsing library shelves and asking colleagues), and snowballing is the best approach for identifying sources published in obscure journals according to their study.</p><p>Skoglund and Runeson <ref type="bibr" target="#b29">[16]</ref> studied a reference-based search approach with the primary objective to reduce the number of initial articles found in systematic literature studies. Despite that the proposed method increased the precision without missing too many relevant papers for the technically focused reviews, its results were not satisfactory when the search area was wide or the searches included general terms. This implies that the choice of approach to searching may be context-dependent.</p><p>In summary, too few studies have addressed the reliability of systematic literature studies. As discussed here, they have either compared different systematic literature studies to check whether the same results are achieved <ref type="bibr" target="#b24">[11]</ref>, <ref type="bibr" target="#b25">[12]</ref> and <ref type="bibr" target="#b30">[17]</ref>, or investigated more efficient approaches of searching <ref type="bibr" target="#b28">[15]</ref>, <ref type="bibr" target="#b29">[16]</ref> and <ref type="bibr" target="#b31">[18]</ref>. As a complement to previous studies, Jalali and Wohlin <ref type="bibr" target="#b32">[19]</ref> investigated the reliability of systematic literature studies using different search strategies. This was done by comparing the outcome of two studies on the same topic using the guidelines by Kitchenham and Charters <ref type="bibr" target="#b20">[7]</ref> and the steps for snowballing outlined by Webster and Watson <ref type="bibr" target="#b15">[2]</ref> for finding the relevant literature. Here, it should be noted that the steps for snowballing are only outlined and they cannot be viewed as a guideline in the same way as those presented by Kitchenham and Charters. Thus, there is a need for more detailed guidelines for snowballing to conduct thorough and repeatable systematic literature studies using a snowballing approach as the first step.</p><p>When it comes to the reliability of systematic literature reviews, the paper by MacDonell et al. <ref type="bibr" target="#b24">[11]</ref> is of particular interest. The reason being that the snowballing procedure presented next is evaluated in Section 4 based on study presented in <ref type="bibr" target="#b24">[11]</ref>. MacDonell et al. evaluated the reliability of systematic reviews through comparing the results of two studies with a common research question performed by two independent groups of researchers. In their case, the systematic literature review seemed to be robust to differences in process and people, and it produced stable outcomes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">SNOWBALLING PROCEDURE</head><p>The basic planning and motivation of a systematic literature study is independent of the search approach, which is the main concern here. Thus, the basic steps for planning a literature study as presented in <ref type="bibr" target="#b20">[7]</ref> are still relevant even if applying a different approach to the search.</p><p>The snowballing procedure is outlined in steps in Figure <ref type="figure" target="#fig_0">1</ref> and described in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Start Set</head><p>In database searches, the first step is to identify keywords and formulate search strings. When applying a snowballing approach, the first challenge is to identify a start set of papers to use for the snowballing procedure. The start set is shown in the top of Figure <ref type="figure" target="#fig_0">1</ref>. Any search for papers to include in the start set generates a tentative start set. The actual start set is only those papers in the tentative start set that at the end will be included in the systematic literature study.</p><p>A good start set may be identified by using, for example, Google Scholar. It is a good alternative to avoid bias in favour of any specific publisher. A good start set has the following characteristics:</p><p>â€¢ If relevant papers may come from different communities, then it is important to have these covered in the start set. This is particularly crucial if there is a risk that relevant papers may be in independent clusters, i.e. in clusters of papers not referring to each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>â€¢</head><p>The number of papers in the start set should not be too small. The actual size of the start set depends on the breadth of the area being studied. A smaller area (more specific focus) requires fewer papers than a broad area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>â€¢</head><p>If too many papers are found, for example due to having very general search terms in Google Scholar, then identifying a number of relevant and highly cited papers may be an alternative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>â€¢</head><p>The start set should cover several different publishers, years and authors. The important issue here is diversity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>â€¢</head><p>The start set ought to be formulated from keywords in the research question, while preferably also taking synonyms into account. The latter is to avoid only capturing papers using a specific terminology and missing papers using a slightly different terminology.</p><p>There is no silver bullet for identifying a good start set, which is very similar to the challenges in identifying search strings in database searches. One possibility in snowballing is to identify a seminal and highly cited paper in the area of the systematic literature study. The challenge of identifying a good start set for snowballing is an area for future research. An illustrative example of terminology challenges is provided in <ref type="bibr" target="#b32">[19]</ref>, where agile practices in global software engineering were studied. In the database search, a paper using the formulation "cross-continent" development was not caught, but it became obvious in the snowballing that the paper should be included. This illustrates the difficulty with inconsistent terminology. The actual results from the systematic literature review are presented in <ref type="bibr" target="#b33">[20]</ref>. This example also illustrates the need for a more consistent usage of terminology to enable good systematic literature studies. An attempt to address this in the area of global software engineering is presented in <ref type="bibr" target="#b34">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Iterations</head><p>Once the start set is decided, including only papers that will be included in the final analysis, it is time to start the first iteration conducting backward and forward snowballing. To finally decide to include a paper means that the full paper should be examined before deciding to use it as a paper in the snowballing. If not doing this, a rollback is needed if other papers are included based on a paper that later is excluded. Thus, it is important to be certain on inclusion before using the paper for snowballing at all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Backward Snowballing</head><p>If starting to the left in Figure <ref type="figure" target="#fig_0">1</ref>, backward snowballing means using the reference list to identify new papers to include. The first step is to go through the reference list and exclude papers that do not fulfil the basic criteria such as, for example, language, publication year and type of publication (if only considering peerreviewed papers). The next step is to remove papers from the list that have already been examined based on being found earlier through either backward or forward snowballing in this or a previous iteration. Once these are removed, the remaining papers are real candidates for inclusion.</p><p>The first two steps in the backward snowballing is to extract as much information as possible from the paper being examined and not go to the new paper until no more information is available in the paper being examined. The following is examined in the reference list:</p><p>â€¢ Title -Is it tentatively a paper to include?</p><p>â€¢ Publication venue -Is it published in a place where relevant papers may be published?</p><p>â€¢ Authors -Do we know that the authors have published relevant paper in the area studied before?</p><p>Papers cannot be excluded based on, for example, that the author is not known for publishing in the area, but a paper may be more likely to be included if the author regularly publishes in the area. Thus, the information found in the reference list must be examined and evaluated carefully. If the paper still is a candidate for inclusion after having looked at it in the reference list, then the next step is to examine where and how the paper is referenced.</p><p>The place and context of the reference may provide important information about the actual content of the candidate paper, and it is practical to get this information from the paper being examined instead of having to find the candidate paper directly.</p><p>If the paper is candidate for inclusion after having examined all information available in the paper being examined, then it is time to find the potentially new paper to include.</p><p>Once the paper is found, the abstract is read first and then other parts of the paper are read until a definitive decision can be taken to either include or exclude the paper. It is recommended not to start reading the paper from the beginning to end directly, instead it is recommended to browse through the paper and read the most relevant parts of the paper to be able to make a decision about inclusion of exclusion in an efficient way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Forward Snowballing</head><p>Forward snowballing refers to identifying new papers based on those papers citing the paper being examined, and it is displayed to the right in Figure <ref type="figure" target="#fig_0">1</ref>. The citations to the paper being examined are studied using Google Scholar. Quotes are removed in Google Scholar, and only citations are used.</p><p>Each candidate citing the paper is examined. The first screening is done based on the information provided in Google Scholar. If this information is insufficient for a decision, the citing paper is studied in more detail. First, the abstract is studied, and if this is insufficient, the place citing the paper already included is examined. If this is insufficient, the full text is studied to make a decision regarding the new paper. The approach to go through the papers is similar as to papers identified using backward snowballing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Inclusion and Exclusion</head><p>As shown in Figure <ref type="figure" target="#fig_0">1</ref>, it is important to decide on either inclusion or exclusion before starting to use a new paper for snowballing. If moving too quickly into using a paper for snowballing and then later realizing that the paper should not have been included there is a problem, and the process has to be rolled back and papers removed if being wrongly included. Only papers found through included papers should be used in the analysis.</p><p>After backward and forward snowballing, new papers identified in the iteration are put into a pile to go into the next iteration. It is important to do one iteration at the time to get traceability. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Authors</head><p>Once no new papers are found in the iterations using both backward and forward snowballing, the loop is ended. To complement the snowballing, it is recommended to contact the authors of included papers to potentially identify some additional papers. It is most important to contact the most active researchers in the area. Based on any new papers identified, the snowballing procedure outlined in Figure <ref type="figure" target="#fig_0">1</ref> must be re-started.</p><p>Other alternative methods to identify additional papers may also be considered, for example, searching in specific journals or conferences that are likely to include more papers on the topic. The journals and conferences may be identified through looking at where included papers are published.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Data Extraction</head><p>All papers identified go into data extraction, which should be conducted in accordance with the research questions posed in the systematic literature study. Given that the full papers have to be investigated before they go into the snowballing procedure, it may be considered to conduct the data extraction at the same time as deciding whether the paper should be included or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">REPLICATION 4.1 Introduction</head><p>The paper by MacDonell et al. <ref type="bibr" target="#b24">[11]</ref> was read 6-12 months before deciding to replicate it using the snowballing procedure formulated in this paper. Once it was decided to replicate the systematic literature review, Sections 1-3 were read in detail to ensure that the replication was conducted in a fair way in relation to the original study. In particular, the research question in the paper is carefully studied to enable replication. The research question in MacDonell et al. <ref type="bibr" target="#b24">[11]</ref> is formulated as follows: What evidence is there that cross-company estimation models are at least as good as within-company estimation models for predicting effort for software projects?</p><p>Thus, the objective of the replication is primarily to illustrate and evaluate the snowballing procedure proposed in Section 3. While doing this, the intention is to answer the research question posed above, and then to reflect on the results in comparison with the two systematic literature reviews presented in <ref type="bibr" target="#b24">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Start Set</head><p>As mentioned above a key challenge is to identify a good tentative start set. In this particular case, the research question posed in <ref type="bibr" target="#b24">[11]</ref> was a good starting point. It was decided to avoid publisher bias (e.g. searching in one publisher's database) and do the search in Google Scholar. The following string of words was put into Google Scholar: cross-company within-company software effort estimation, and the time frame chosen was 1995-2005. The latter is for replication purposes. The actual search was conducted August 20, 2013. But given the time frame of the search, the actual search date is of less importance in this case. However, under other circumstances the date could be of importance since the content of the databases changes and what Google Scholar indexes may also change over time.</p><p>In total, 13 candidates for inclusion were identified; they are denoted C1, C2 and so forth to indicate that they are candidates for inclusion. The 13 papers are:</p><p>First non-peer reviewed candidates were excluded and then candidates covering the same study were excluded. Candidates 9, 12 and 13 were excluded based on not being a peer-reviewed journal of conference/workshop paper. Candidate 8 was excluded since it was judged that Candidate 7 is an extension of Candidate 8. The other candidates were reviewed more in-depth. After which, it was decided to exclude Candidates 4, 5, 6, 7, 10 and 11 due to being out of scope. Based on the inclusion/exclusion criteria, it was decided to include candidates 1, 2 and 3. The latter three are denoted P1, P2 and P3 respectively and these papers form the start set for the snowballing.</p><p>The identified start set is far from perfect, since the three papers identified have one author in common. It would have been better to have at least one paper from someone else to mitigate the risk of missing papers not being linked to these three papers. However, given that it was decided to use the research question in <ref type="bibr" target="#b24">[11]</ref> as a starting point no action was taken.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Iteration 1</head><p>From the start set of three papers, both backward and forward snowballing were conducted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Backward Snowballing</head><p>In backward snowballing, the references of the three included papers are studied to identify more papers to include in the study.</p><p>Only references in the time frame studied are considered. The three papers are evaluated one at the time.</p><p>P1 includes 17 references where one reference is already included and one reference is already excluded. This leaves 15 references to evaluate. Four references are excluded based on publication year, and four references are excluded based on title or type of publication. Two references identified as candidates based on their title (denoted P6 and P8 below). Three papers were identified based on how they were used when referring to them (denoted P4, P5 and P7 below), and two papers were excluded based on the place and context of the reference. The full text of the five candidate papers were evaluated to avoid using a paper in the snowballing procedure that later may be excluded, since final inclusion must be based on the full paper. All five papers were judged as relevant and hence included in the study. Thus, the following five papers were added to the list of papers to be included:</p><p>P4 P2 has 18 references, but a majority of them are the same as for P1. Only four new references were identified. Neither the title nor the place and context of the references gave definitive information about whether or not to include or exclude the four papers. Thus, the abstract was first studied and it was still inconclusive, and hence the full papers were evaluated. After having gone through the full papers, it was decided that all four papers should be excluded.</p><p>P3 includes 21 references with many references in common with P1 and P2. In total six new references were identified. One was excluded based on the publication year and three were excluded based on the titles. The other two papers were candidates for inclusion. One paper was identified based on the title (P10) and one was identified from the place and context of the reference (P9). The full text of the papers was evaluated and it was decided to include both papers. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Forward Snowballing</head><p>In forward snowballing, the papers citing the three papers in the start set are evaluated. The citation analysis is conducted using Google Scholar. Given that the three papers in the start set are published in the end of the time frame considered, it is no surprise that there are few citations. The time frame studied is 1995-2005, and the three papers are published in 2004, 2004 and 2005 respectively. Five papers cite P1, but all of them are in the tentative start set (C1-C13). The situation is similar for P2 and P3. Four papers cite P2 and one paper cites P3 in the time frame studied, and once again the papers are already in the tentative start set. Thus, no new papers were identified from forward snowballing from the start set (P1-P3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Summary of Status</head><p>The tentative start set included 13 candidates, which were evaluated. From these 13 candidates, three papers were included in the study. From these three papers, 25 candidates were evaluated (15 from P1, 4 from P2 and 6 from P3) from the backward snowballing. Seven new papers were included, denoted P4-P10. No new candidates needed to be evaluated based on the forward snowballing. In total 38 papers have been evaluated so far and 10 papers have been included in the study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Iteration 2</head><p>The seven new papers identified (P4-P10) go into the first iteration. Thus, first backward snowballing is conducted for these seven papers and then a forward snowballing is done too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Backward Snowballing</head><p>P4 includes 33 references, and 28 of them are perceived as new.</p><p>Here it should be noted that given the number of references studied, there is always a risk that the same reference is studied more than once. The reason being that it is not deemed efficient to put a number of references into a tool, which later are excluded immediately and hence there may be some random errors in the actual numbers. For example, among the perceived new 28 references, a paper already evaluated maybe hiding but the researcher may not remember.</p><p>Out of the 28 references, 14 of them are excluded based on the publication year and 12 references are excluded based on the title. Only two references call for a closer examination. For these two papers, the places and context of the reference were identified in the paper, and it was concluded that none of them should be included. Thus, no new paper was identified from P4.</p><p>P5 has 32 references, but a large number of them have already been examined. In total, 12 references are perceived as new. Out of these 12 references, three references are excluded based on the publication year and the others are excluded based on the title. Thus, no new paper was identified from P5. P9 has also 28 references, but in this case 18 references are perceived as new. Although having many new references, no new paper is identified for inclusion. Six references are excluded based on the year and the remaining 12 references are excluded based on their title.</p><p>P10 is the oldest paper of those included, and hence the following outcome is not so surprising. P10 includes 28 references with 21 of them being perceived as new. Unfortunately, all 21 references left are excluded based on the publication year.</p><p>In summary, 97 (28+12+8+9+1+18+21) references were examined after having removed those that had already been investigated. A large majority of the 97 references were excluded based on publication year or title. For only three references there was a need to look in the paper for the place and context of the reference. In all other cases, the references could be excluded based on either publication year or the title of the reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Forward Snowballing</head><p>The next step is to examine the seven papers from a forward snowballing point of view. This includes examining the citation to the seven papers within the studied time frame <ref type="bibr">(1995)</ref><ref type="bibr">(1996)</ref><ref type="bibr">(1997)</ref><ref type="bibr">(1998)</ref><ref type="bibr">(1999)</ref><ref type="bibr">(2000)</ref><ref type="bibr">(2001)</ref><ref type="bibr">(2002)</ref><ref type="bibr">(2003)</ref><ref type="bibr">(2004)</ref><ref type="bibr">(2005)</ref>. The outcome of the examination of these seven papers is as follows:</p><p>62 candidates for inclusion cite P4. 11 of these have already been examined. 40 candidates are excluded based on the information available in Google Scholar, which includes publication year, type of publication, language and title. This leaves 11 candidates. The abstract is examined for these 11 candidates, and it is concluded to exclude 10 of them. One paper is viewed as a candidate for inclusion, and it is decided to include the paper after having investigated the full paper. The new paper is: P5 has 74 relevant citations in Google Scholar. 37 of these citations have already been examined and 36 of the citations were excluded based on the information available in Google Scholar. Thus, only one abstract was investigated and it was decided to exclude the paper.</p><formula xml:id="formula_0">P11. E.</formula><p>36 citations are found for P6. A majority of these have already been examined (26 candidates citing P6), and the other 10 candidates for inclusion are excluded based on the information available in Google Scholar.</p><p>P7 has 47 citations in Google Scholar, and 31 of them have already been examined. The remaining 16 candidates are excluded based on the information available in Google Scholar.</p><p>12 candidates for inclusion cite P8. 10 of these citations have already been examined and the other two citations can be excluded based on the information provided in Google Scholar.</p><p>Only three citations are identified for P9. Two of them have already been examined and the third can be excluded based on information available in Google Scholar.</p><p>Finally, P10 has 17 citations in Google Scholar. Eight of these citations have already been examined and the other nine citations can be excluded based on the information available in Google Scholar.</p><p>In summary, 126 citations have been examined for these seven papers (51+37+10+16+2+1+9) after having removed those that have already been examined. Most of the papers were excluded based on information available in Google Scholar and only 12 abstracts were read to make the decisions. At the end, only one paper was included based on the forward snowballing in Iteration 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Iteration 3</head><p>Given that Iteration 2 only identified one paper, the backward and forward snowballing become easy in the third iteration. In the backward snowballing, it is noted that P11 has 39 references. Four of them are excluded based on the publication year, and 13 references have already been examined. The remaining 22 references are excluded based on the title. Moving on to forward snowballing, P11 is cited by seven candidates for inclusion. All seven of them are excluded based on information available in Google Scholar.</p><p>In summary, the second iteration resulted in examining 33 (4+22+7) additional candidates for inclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Efficiency</head><p>One important efficiency measure for systematic literature studies is the number of included papers in relation to the total number of candidate papers examined. It is well known that there is a large risk for noise, i.e. papers that preferably should never have been examined since they were not included at the end. If looking at the efficiency in the different steps:</p><p>Number of investigated papers:</p><p>â€¢ Start set: 13 candidates for start set and 3 papers were included, i.e. efficiency = 3/13 =23%.</p><p>â€¢ Iteration 1: 25 candidates from snowballing from start set, and 7 papers were included, i.e. efficiency = 7/25 = 28%.</p><p>â€¢ Iteration 2: 223 candidates for inclusion were generated in backward and forward snowballing, only one paper was included, i.e. efficiency 1/223 = 0.4%.</p><p>â€¢ Iteration 3: 33 candidates were examined and no paper was included, and hence the efficiency becomes 0%.</p><p>1. Direct exclusion in reference lists are very quickly done when it comes to basic criteria such as, for example, language, publication year and type of publication. The extra work from these is negligible.</p><p>2. A large number of references are found in several papers. It is particularly obvious when it comes to papers by the same authors. This has some implication, either it means that a good portion of the papers in the area has been captured or a cluster of papers has been found (e.g. overlap in authors), and other clusters may exist. This comes back to the necessity to identify a good start set, i.e. to avoid bias.</p><p>3. It is very difficult to decide whether or not to exclude a paper or evaluate it on the next level, for example, to exclude a paper based on its title, or read the abstract or even read the full paper. This is an important balance. On the one hand, it generates a lot of work to read the full text of papers that are excluded, but on the other hand, it is important to not exclude papers early that actually should be included.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>In backward snowballing, it is recommended to iterate between the reference list and the place and context for the reference in the paper. Once a paper is found for inclusion, then look at other papers referred to in a similar way. They may be strong candidates for inclusion too.</p><p>5. In forward snowballing, for papers included, look where the paper leading to the new paper is referenced and identify papers referenced in a similar way. This is easily missed in backward snowballing since the paper leading to the new paper (through forward snowballing) is already found and hence it is typically not looked at in the backward snowballing.</p><p>6. The papers to be examined for a specific paper may very depending on the order in which the papers are investigated.</p><p>In other words, a paper is examined the first time it is found, which means that the number of papers to be investigated varies. However, the number of papers in each step in the snowballing procedure should be stable. In summary, the replication was straightforward, and the actual case was very suited for snowballing given that finding one of the papers finally included papers meant</p><p>The main threat is that the researcher read the original study before deciding to conduct the replication. However, this is very hard to avoid since the main reason to replicate the study was driven by having read it and being convinced that it would be an interesting case to both illustrate and evaluate the snowballing approach to conducting systematic literature studies.</p><p>Having said this, the replication was run 6-12 months after reading the paper, which means that the researcher does not remember all details of the original study. However, the researcher did remember approximately the expected number of papers to find. The researcher did not remember the exact number, but remembered that the number of papers found in the original studies were in the interval 10-19 papers. This may have affected the decisions on inclusion and exclusion. Independently, if it has affected the outcome it has only affected where the decisions are taken and not the actual number of papers examined in the replication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.10">Comparison</head><p>The same papers are identified. Nine studies are in common with both previous systematic literature reviews presented in <ref type="bibr" target="#b24">[11]</ref>. In <ref type="bibr" target="#b24">[11]</ref>, it is noted that one study should have been excluded due to the type of analysis conducted. The analysis was not conducted to this detail here, since the main objective is to evaluate the snowballing procedure. However, it is interesting to note that the paper to exclude is P11, which somewhat surprisingly was not cited by P1-P3. Thus, the citation matrix may indicate some issues that need a more detailed investigation.</p><p>It is difficult to compare efficiency numbers. What does it mean to look at a paper in the reference list? Should papers denoted "retrieved" in <ref type="bibr" target="#b24">[11]</ref> be compared with all papers in the reference list, or should those being removed based on publication year, non-peer reviewed papers or papers that have already been included not be counted? The papers denoted "Detailed reviewed" in <ref type="bibr" target="#b24">[11]</ref> are compared with those where either place of reference, abstract or full paper were evaluated here. This gives the results in Table <ref type="table">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2. Efficiency comparison.</head><p>Review 1 <ref type="bibr" target="#b24">[11]</ref> Review 2 <ref type="bibr" target="#b24">[11]</ref> Snowballing Detailed 24 38 38</p><p>If using the papers studied in detail as a efficiency measure, then the different approaches requires about the same effort. Unfortunately, the actual effort for conducting the different reviews is not available for comparison. However, further studies are needed to better understand the advantages and disadvantages with different approaches and how they may complement each other in the best possible way. One of the main benefits with snowballing is its focus on papers actually referenced or papers citing papers included, and hence there is a possibility that the noise is less than using a database approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">DISCUSSION SNOWBALLING</head><p>One of the main advantages of snowballing is that it starts from relevant papers and then uses these to drive the further study.</p><p>Reference lists are quite easily examined and when combined with the place and context of the reference, it becomes in most cases quite straightforward to identify relevant papers. The citation analysis may result in examining a large number of papers (when a paper is highly cited), but the information in Google Scholar is in most cases quite helpful to make a decision about tentative inclusion or exclusion.</p><p>Snowballing should not necessarily be seen as an alternative to database searches. Different approaches to identifying relevant literature should preferably used to ensure the best possible coverage of the literature. Future research is needed when it comes to several areas: 1) Identification of a good start set of papers for snowballing, 2) Evaluation of the efficiency for different approaches to systematic literature searches, and 3) Determination of advantages and disadvantages of different approach, in particular in different type of literature searches (e.g. broad area or very focused area), and 4) Formulation of a good hybrid approach where different approaches to identifying the relevant research literature complement each other.</p><p>In particular, it should be noted that snowballing is particularly useful for extending a systematic literature study, since new studies almost certainly must cite at least one paper among the previously relevant studies or the systematic study already conducted in the area. Thus, snowballing is by deduction a better approach than a database search for extending systematic literature studies. The actual evidence for this assertion is left for further research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">SUMMARY</head><p>The two objectives stated in Section 1 are both fulfilled. A procedure for snowballing has been formulated, and it has successfully been illustrated and evaluated. The snowballing procedure is detailed in several steps including both backward and forward snowballing. Ten lessons learned from using the snowballing procedure have been reported, which hopefully will help others using snowballing in their systematic literature studies.</p><p>The replication illustrated the usefulness of the snowballing procedure, and the actual outcome from the replication was similar to the outcome of the original systematic literature reviews. The snowballing procedure was particularly suitable for this case, since it turned out that it was sufficient to find one of the 10-11 papers to be able to find the other papers.</p><p>To conclude, a systematic approach to snowballing as the procedure formulated here is definitively an alternative to use as a starting point for a systematic literature study instead of always start by searching different databases. The next challenge is to figure out under which circumstances the snowballing procedure is to prefer over the database approach.</p><p>Finally, it should be noted that a key to success for using the snowballing procedure for systematic literature studies is the place and the context of the references in both backward and forward snowballing. In addition, a citation matrix and a timeline have been proposed to get a better overview of papers in the area of the systematic literature study.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Snowballing procedure.</figDesc><graphic coords="4,54.24,70.32,503.76,384.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>P6 includes 19</head><label>19</label><figDesc>references, and the situation is quite similar as for P5. Only eight new references are identified. Two references are excluded based on publication year and the other six references are excluded based on title. Once again no new papers are identified.P7 has 31 references, and nine of them are perceived as new. These nine are examined. It is concluded that three references can be excluded based on the publication year and five are excluded based on the title. It leaves one paper for further examination. The place and context of the reference to this paper is investigated, and it is concluded to exclude the paper. No new papers are included from P7. P8 includes 28 references, and only one of them is new. The new paper is excluded based on title.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Mendes, N. Mosley and S. Counsell, "Early Web Size Measures and Effort Prediction for Web Costimation", Proceedings Ninth International Software Metrics Symposium, pp. 18-39, 2003.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">ACKNOWLEDGMENTS</head><p>The author wishes to express his sincere thanks to Samireh Jalali, Deepika Badampudi and Rafael Prikladnicki for inspiring and valuable discussion regarding systematic literature studies in general and the use of snowballing in particular.</p><p>The Industrial Excellence Center EASE -Embedded Applications Software Engineering, (http://ease.cs.lth.se) partially funded this research.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The overall efficiency becomes (3+7+1+0)/(13+25+223+33) = 3.7%. It is important to note that the efficiency is calculated on all candidates. If removing those in backward snowballing where the decision is taken either on publication year (trivial) or title in reference list the efficiency increases. The papers in forward snowballing are handled in the same way, due to that they require either that the information in Google Scholar is read or going to the actual paper. Then the overall efficiency increases substantially. In the backward and forward snowballing from the three papers in the start set, the abstract was examined for 12 papers and five of these were included. Here, four full papers were read that were not included. In Iteration 2, 12 abstracts were read and one paper was included. The total efficiency with this calculation becomes: Start set:</p><p>â€¢ 3 of 13 from Start set (as before)</p><p>Backward:</p><p>â€¢ 7 of 12 from Iteration 1 (instead of 7 of 25)</p><p>â€¢ 0 of 3 from Iteration 2 (instead of 3 of 97)</p><p>â€¢ 0 of 0 from Iteration 3 (instead of 0 of 26) Forward:</p><p>â€¢ 1 of 133 (0+126+7) from the three different sets after the start set.</p><p>If removing the candidates where they were removed either on publication year in the reference list or on title, the efficiency becomes: (10+1)/(28+133) = 6.8% with the backward snowballing being very effective.</p><p>However, it must be noted that it is a delicate balance to not be too restrictive on titles. If being very restrictive on titles, the following papers would not have been included: P4, P5, P7, P9 and P11.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Authors</head><p>If following the snowballing procedure as described in Section 3 and illustrated in Figure <ref type="figure">1</ref>, authors of included papers should be contacted. Thus, snowballing should not only be on papers, but also on authors. This has not been done since several of the authors of the included papers also authored the systematic literature review being replicated here. Furthermore, any responses from the authors may be biased by already having seen the published systematic literature review. Otherwise, the following authors would have been candidates to contact:</p><p>â€¢ Authored more than one paper: Briand, Jeffrey, Kitchenham, Maxwell, Mendes, Ruhe and Wieczorek.</p><p>â€¢ Authored one paper: Counsell, Dutta, El Emam, Harrison, Lefley, Lokan, Mosely, Shepperd, Surmann, Triggs and Wassenhove.</p><p>Other complementary searches were not done either since the objective is to compare snowballing with a database-firstapproach in a similar way as in <ref type="bibr" target="#b32">[19]</ref>, although with a better specified procedure for using snowballing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Citation Matrix and Timeline</head><p>To understand the referencing and citing between the papers, a citation matrix is created for illustration purposes. Table <ref type="table">1</ref> shows how the eleven papers refer to each other, denoted with "X". For example, it can be seen how P2 refer to P4-P8 (row 2), and how P10 is cited by P3, P4, P6 and P9 (column 10). For reason of space in the table, the paper numbers are given without the preceding "P".</p><p>In Table <ref type="table">1</ref>, it can be seen how P10 does not refer to any of the other papers, this is no surprise if looking at the timeline of the publications. The timeline is as follows: The timeline means that Table <ref type="table">1</ref> can be complemented with information about possibility to cite. Table <ref type="table">1</ref> is complemented with this information by introducing "-" when a paper cannot be referenced due to it not being published yet. For example, for P10 the row is filled with "-", since P10 could not refer to any of the other papers, and the column for P10 is left with empty cells since all other papers could have cited this paper given that it was published first. This may not be entirely true for two reasons: 1) it takes time for a paper to be published so although it looks like it should be available it may not have been at the point in time when another paper was written, and 2) authors are aware of their own papers and can cite them even if they are not officially published yet (as P2 is cited by P11). Independently, Table <ref type="table">1</ref> provides some additional information by introducing "-" as a sign for most likely not being able to cite another paper.</p><p>A closer look at Table <ref type="table">1</ref> provides some interesting observations:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>â€¢</head><p>The timeline together with Table <ref type="table">1</ref> show that the three papers from the start set (P1-P3) are relatively new in the studied time frame. Thus, most other papers are found through backward snowballing.</p><p>â€¢ P10 may not have received the citations it deserves despite it being the first study published, only four out of ten papers cite it.</p><p>â€¢ P11 is not cited by any of the other papers, despite three papers being published after its publication. This is surprising in particular since P1-P3 have one author in common with P11.</p><p>It is worth noting that finding one of the eleven papers in Table <ref type="table">1</ref> means that the other papers can be found with snowballing. It does not matter which paper is identified; the other papers will be found. This illustrates one of the strengths with snowballing, i.e. papers may be found even if they use different terminology but the authors within the area refer to each other despite these differences. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9">Reflections</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9.1">Ten Lessons Learned from Snowballing</head><p>The actual use of the snowballing procedure presented in Section 3 comes with ten lessons learned:</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Further Comparison of Cross-Company and Within Company Effort Estimation Models for Web Applications</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kitchenham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Metrics&apos;04</title>
		<meeting>Metrics&apos;04<address><addrLine>Chicago, Illinois</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2004">September 11-17th 2004. 2004</date>
			<biblScope unit="page" from="348" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Comparison of Crosscompany and Within-company Effort Estimation Models for Web Applications</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mendes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 8th International Conference on Empirical Assessment in Software Engineering EASE 2004</title>
		<meeting>8th International Conference on Empirical Assessment in Software Engineering EASE 2004</meeting>
		<imprint>
			<publisher>Computer Society Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="47" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Replicated Comparison of Cross-company and Withincompany Effort Estimation Models using the ISBSG Database</title>
		<author>
			<persName><surname>C3</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lokan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Metrics&apos;05</title>
		<meeting>Metrics&apos;05<address><addrLine>Como</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Consistency of Empirical Comparisons of Regression and Analogy-based Software Project Cost Prediction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shepperd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp. On Empirical Software Engineering</title>
		<meeting>Int. Symp. On Empirical Software Engineering</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An Empirical Analysis of Software Productivity over Time</title>
		<author>
			<persName><surname>C5</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Premraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shepperd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Forselius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp. On Software Metrics</title>
		<meeting>Int. Symp. On Software Metrics</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Software Productivity Measurement using Multiple Size Measures</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mendes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. On Softw. Eng</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1023" to="1035" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Investigating Web Size Metrics for Early Web Cost Estimation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mosley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Counsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Systems and Software</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="172" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Investigating Early Web Size Measures for Web Cost Estimation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mosley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Counsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EASE&apos;2003 Conference</title>
		<meeting>EASE&apos;2003 Conference<address><addrLine>Keele</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-04">April, 2003</date>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">How Valuable is it for a Web Company to Use a Cross-company Cost Model, Compared to Using Its Own Single-company Model?</title>
		<author>
			<persName><surname>C9</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dinakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mosley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Value of Cooperative Planning in Supply Chains -A Simulative Approach</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Buxmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings European Conference on Information Systems</title>
		<meeting>European Conference on Information Systems</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Computer-Mediated Communication as Employee Voice: A Case Study</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Industrial and Labor Relations Review</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="213" to="233" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">An Exploratory Empirical study of the Role of Manufacturing in Product Formulation</title>
		<author>
			<persName><surname>C12</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C-S</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Consumers are Having Second Thoughts about Online Dating -Are the Real Benefits Getting Lost in Over Promises?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zimbardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hutchinson</surname></persName>
		</author>
		<idno>weAttract.com</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Evidence-based software engineering</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>DybÃ¥</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>JÃ¸rgensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 27th IEEE International Software Engineering Conference</title>
		<meeting>27th IEEE International Software Engineering Conference</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="page" from="273" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Analyzing the past to prepare for the future: Writing a literature review</title>
		<author>
			<persName><forename type="first">J</forename><surname>Webster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MIS Quarterly</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="xiii" to="xxiii" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Combining empirical results in software engineering</title>
		<author>
			<persName><forename type="first">L</forename><surname>Pickard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information &amp; Software Technology</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="811" to="821" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Can results from software engineering experiments be safely combined?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE 6th International Symposium on Software Metrics</title>
		<meeting>IEEE 6th International Symposium on Software Metrics</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="152" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Research synthesis in software engineering: A case for meta-analysis</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 6th IEEE International Software Metrics Symposium</title>
		<meeting>6th IEEE International Software Metrics Symposium</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="143" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Building knowledge through families of experiments</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Basili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lanubile</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="456" to="473" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Guidelines for performing systematic literature reviews in software engineering. Version 2.3, EBSE</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Charters</surname></persName>
		</author>
		<idno>EBSE- 2007-01</idno>
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>Keele University</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Systematic mapping studies in software engineering</title>
		<author>
			<persName><forename type="first">K</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Feldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mujtaba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 12 th International Conference on Evaluation and Assessment in Software Engineering</title>
		<meeting>12 th International Conference on Evaluation and Assessment in Software Engineering</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Using mapping studies as the basis for further research -a participant-observer case study</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Budgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">P</forename><surname>Brereton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Software Technology</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="638" to="651" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Systematic literature reviews in software engineering</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wohlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Prikladnicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Software Technology</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="919" to="920" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">How reliable are systematic reviews in empirical software engineering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Macdonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shepperd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mendes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="676" to="687" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On the reliability of mapping studies in software engineering</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wohlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Runeson</surname></persName>
		</author>
		<author>
			<persName><surname>Da Mota Silveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Neto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>EngstrÃ¶m</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Do Carmo Machado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>De Almeida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Systems and Software</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2594" to="2610" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Systematic literature reviews in software engineering: A systematic literature review</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">P</forename><surname>Brereton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Budgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Linkman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Software Technology</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="7" to="15" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Systematic literature reviews in software engineering: A tertiary study</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pretorius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Budgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">P</forename><surname>Brereton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Linkman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Software Technology</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="792" to="805" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Effectiveness and efficiency of search methods in systematic reviews of complex evidence: Audit of primary sources</title>
		<author>
			<persName><forename type="first">T</forename><surname>Greenhalgh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peacock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMJ</title>
		<imprint>
			<biblScope unit="volume">331</biblScope>
			<biblScope unit="page" from="1064" to="1065" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Reference-based search strategies in systematic reviews</title>
		<author>
			<persName><forename type="first">M</forename><surname>Skoglund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Runeson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 13th Evaluation and Assessment in Software Engineering</title>
		<meeting>13th Evaluation and Assessment in Software Engineering</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Repeatability of systematic literature reviews</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">P</forename><surname>Brereton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Budgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Burn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on Evaluation and Assessment in Software Engineering</title>
		<meeting>the 15th International Conference on Evaluation and Assessment in Software Engineering</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="46" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Identifying relevant studies in software engineering</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Babar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Software Technology</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="625" to="637" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Systematic literature studies: Database searches vs. backward snowballing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jalali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wohlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 6th International Symposium on Empirical Software Engineering and Measurement</title>
		<meeting>6th International Symposium on Empirical Software Engineering and Measurement</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="29" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Global software engineering and agile practices: A systematic review</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jalali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wohlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Software: Evolution and Process</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="643" to="659" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">An empirically based terminology and taxonomy for global software engineering</title>
		<author>
			<persName><forename type="first">D</forename><surname>Smite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wohlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Galvina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Prikladnicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Software Engineering: An International Journal</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="153" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
