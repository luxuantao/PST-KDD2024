<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013-04-12">April 12, 2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Farsiu</forename><forename type="middle">Xinfeng</forename><surname>Zhang</surname></persName>
							<email>xfzhang@jdl.ac.cn</email>
						</author>
						<author>
							<persName><forename type="first">R</forename><surname>Xiong</surname></persName>
							<email>rqxiong@pku.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">S</forename><surname>Ma</surname></persName>
							<email>swma@pku.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">W</forename><surname>Gao</surname></persName>
							<email>wgao@pku.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">Key Lab of Intelligent Information Processing</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100049</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Institute of Digital Media</orgName>
								<orgName type="department" key="dep2">School of Electronic Engineering and Computer Science</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Institute of Digital Media</orgName>
								<orgName type="department" key="dep2">School of Electronic Engineering and Computer Science</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Harbin Institute of Technology (HIT)</orgName>
								<address>
									<postCode>150001</postCode>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2013-04-12">April 12, 2013</date>
						</imprint>
					</monogr>
					<idno type="MD5">5D7A2244FAE84AD2846724487EF47183</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. received September 12, 2012; revised January 17, 2013 and</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Block transform coding</term>
					<term>compression artifacts</term>
					<term>block similarity</term>
					<term>denoising</term>
					<term>post-processing Compression Artifact Reduction by Overlapped-Block Transform Coefficient Estimation with Block Similarity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Block transform coded images usually suffer from annoying artifacts at low bit rates, caused by the coarse quantization of transform coefficients. In this paper, we propose a new method to reduce compression artifacts by overlapped-block transform coefficient estimation from non-local blocks. In the proposed method, the DCT coefficients of each block are estimated by adaptively fusing two prediction values based on their reliabilities. One prediction is the quantized values of coefficients decoded from the compressed bitstream, whose reliability is determined by quantization steps. The other prediction is the weighted average of coefficients in non-local blocks, whose reliability depends on the variance of coefficients in these blocks. The weights are utilized to distinguish the effectiveness of coefficients in non-local blocks to predict original coefficients and are determined by block similarity in transform domain. To solve the optimization problem, the overlapped blocks are divided into several subsets. Each subset contains non-overlapped blocks covering the whole image and is optimized independently. Therefore, the overall optimization is reduced to a set of sub-optimization problems, which can be easily solved. Finally, we provide a strategy for parameter selection based on the compression levels. Experimental results show that the proposed method can remarkably reduce compression artifacts and significantly improve both the subjective and the objective quality of block transform coded images.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>ISCRETE cosine transform (DCT) is widely adopted in the existing image and video compression standards, such as JPEG, MPEG-1/2/4, H.261/263/264, etc., to exploit the spatial correlation among neighboring pixels. At the encoder of such schemes, the input image is usually divided into a group of small image blocks, each of which is transformed into the frequency domain using block-DCT (BDCT). For each transformed block, the DCT coefficients are then compressed into a binary stream via quantization and entropy coding. At the decoder, the image is reconstructed by inversely transforming the quantized DCT coefficients extracted from the bitstream. A problem in block transform coding is that, due to the coarse quantization of transform coefficients, the images compressed at low bit rate usually suffer from visually annoying artifacts [1], including the blocking and ringing effects.</p><p>In order to reduce the compression artifacts while maintaining compatibility with the existing coding standards, various post-processing techniques have been proposed in the literatures. These methods mainly include filtering approaches <ref type="bibr" target="#b4">[2]</ref>- <ref type="bibr" target="#b8">[6]</ref>, iterative approaches based on the theory of projections onto convex sets (POCS) <ref type="bibr" target="#b9">[7]</ref>, <ref type="bibr" target="#b10">[8]</ref>, maximum a posteriori (MAP) estimation methods <ref type="bibr" target="#b11">[9]</ref>, <ref type="bibr" target="#b12">[10]</ref> and wavelet-based methods <ref type="bibr" target="#b13">[11]</ref>. Reeve and Lim <ref type="bibr" target="#b4">[2]</ref> applied a 3×3 Gaussian filter to the pixels around block boundaries to smooth out the blocking artifacts. Ramamurthi and Gersho <ref type="bibr" target="#b5">[3]</ref> employed nonlinear space-variant filters based on edge-oriented classifiers to smooth out blocking artifacts. Buades et al. <ref type="bibr" target="#b6">[4]</ref>, <ref type="bibr" target="#b7">[5]</ref> proposed the nonlocal means filter to predict each pixel by a weighted average of its surrounding pixels, where the weights are determined by the similarity of the corresponding image patches located at the source and target coordinates. Takeda et al. <ref type="bibr" target="#b8">[6]</ref> proposed a signal-dependent steering kernel regression framework for denoising. The above methods only considered the smoothness or the regularity in pixel intensities, but did not exploit the information in the compressed bitstream. Therefore, the true edges or texture details might be smoothed out undesirably in the reconstructed images. To avoid this issue, Zakhor et al. <ref type="bibr" target="#b9">[7]</ref>, <ref type="bibr" target="#b10">[8]</ref> utilized the quantization intervals of transform coefficients as a convex set, resulting in an algorithm which applies low pass filtering and projection onto quantization convex set alternately. There are also many approaches based on probability estimation <ref type="bibr" target="#b11">[9]</ref>, <ref type="bibr" target="#b12">[10]</ref>. Rourke and Stevenson <ref type="bibr" target="#b11">[9]</ref> employed Huber-Markov random field (Huber-MRF) as an image prior model to seek the MAP estimation of the original image. The Gibbs distribution therein models both the smoothness and the discontinuities of images in the spatial domain. Sun and Cham <ref type="bibr" target="#b12">[10]</ref> modeled the original image as a high order Markov random field (MRF) based on the field of experts (FoE) framework. In some other approaches, the a priori knowledge is expressed by the statistical characteristics of coefficients in transform domain, e.g. wavelet, contourlet. Wu et al. <ref type="bibr" target="#b13">[11]</ref> proposed a deblocking algorithm by adaptively shrinking the wavelet coefficients.</p><p>Since the compression artifacts are solely caused by the quantization of transform coefficients, some previous works tackle the problem in the DCT domain <ref type="bibr" target="#b14">[12]</ref>- <ref type="bibr" target="#b18">[16]</ref>. Chen et al. <ref type="bibr" target="#b14">[12]</ref> applied a low pass filter to the DCT coefficients of neighboring blocks. The DCT-domain filtering method was also adopted in <ref type="bibr" target="#b15">[13]</ref>. Although the filter was adaptively chosen, it remains constant with respect to all subbands. Therefore, the filtering operation in DCT domain is essentially equivalent to the corresponding filter in spatial domain. Choy et al. <ref type="bibr" target="#b16">[14]</ref> estimates the original DCT coefficients from the quantized ones with the local mean and variance of the coefficients in each subband. Lee et al. <ref type="bibr" target="#b17">[15]</ref> proposed to reduce artifacts by first low pass filtering the decoded image and then predicting the image by a linear regression model in transform domain. Foi et al. <ref type="bibr" target="#b18">[16]</ref> utilized a point wise shape adaptive DCT for denoising.</p><p>In this paper, we propose a new approach to reduce compression artifacts by estimating the original image from transform domain. This is achieved by estimating the DCT coefficients in all the transform-blocks located at any pixel position. For each block, the DCT coefficients are estimated by adaptively fusing two prediction values according to their reliabilities. One prediction is the quantized values of coefficients decoded from the compressed bitstream, whose reliability is determined by quantization steps. The other prediction is the weighted average of coefficients in non-local blocks which are similar with the estimated blocks. Its reliability depends on the variance of coefficients in these similar blocks. The weights are utilized to distinguish the effectiveness of coefficients in similar blocks to predict the original coefficients. They are determined by block similarity in transform domain. In order to depress the negative effects of noise in similarity calculation, we take the Euclidean Distance of low frequency coefficients in transform-blocks to measure their similarities. Furthermore, we employ quantization steps to exclude outlier coefficients in similar blocks, which are far away from the estimated original coefficients. The proposed framework needs to optimize transform coefficients in all the transform-blocks in image, which are overlapped. It involves a large set of dependent variables. To tackle the optimization problem, the overlapped blocks are divided into several subsets. Each subset contains non-overlapped blocks covering the whole image and is optimized independently. Therefore, the overall optimization is reduced to a set of sub-optimization problems that can be easily solved. A method is also proposed to enforce the quantization constraint for each of these sub-optimization problems. Finally, we provide a strategy for parameter selection according to the compression levels or quantization steps, which can be extracted from the compression bitstream.</p><p>The remainder of this paper is organized as follows. Section II briefly reviews block-transform image coding and introduces some notations. Section III formulates the compression artifact reduction as a MAP estimation problem under the Bayesian framework. The proposed image prior models are described in detail, and the performances of different prior models are compared in this section. Section IV describes the optimization solution of the proposed algorithm and the enforced quantization constraint method. Experimental results are reported in Section V, and Section VI concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. REVIEW OF BLOCK-TRANSFORM IMAGE CODING</head><p>In this section, we briefly review a few concepts and notations in block transform image coding for the convenience of later discussion. Suppose we have an image  (a two-dimensional grid) of size H×W, where (i, j) denotes a pixel and the indices i and j are the coordinates in the vertical and the horizontal directions, respectively. Suppose that the size of block-DCT used for image coding is N×N. We use  m,n to denote an image block of size N×N in , with its top left pixel being (m, n). To be specific, the pixels in this block are</p><formula xml:id="formula_0"> m,n (i, j) = (m + i, n + j), i, j = 0, 1,…, N-1. (1)</formula><p>For the block-DCT based image coding, the input image  is divided into a group of non-overlapped blocks of size N×N.</p><p>The data in each block is transformed, quantized and entropy coded into the compressed bitstream. We call these blocks coding blocks. Obviously, a block  m,n is a coding block only when m and n are multiples of N. We define</p><formula xml:id="formula_1">Ω CB = { m,n | m, n ≡ 0 (mod N)}.</formula><p>(2) The complete set of blocks in image  is defined as</p><formula xml:id="formula_2">Ω= { m,n | 0≤ m &lt; H -N, 0≤ n &lt; W -N }.</formula><p>(3) The blocks in Ω are obviously overlapped. The blocks in Ω NCB =Ω\Ω CB are called non-coding blocks. Although the data in non-coding blocks are not directly acquired from the bistream by inverse transform and quantization, they can be retrieved from the bitstream when the image is reconstructed.</p><p>We use x to represent the original data (i.e. pixel intensity) of image  and use x  and X  to represent the data and the transform coefficients of a block , respectively. They are related by the block-DCT , X  = (x  ), (inverse transform x  =  -1 (X  )). The transform coefficients in X  are quantized according to a quantization matrix Q of size N×N.</p><formula xml:id="formula_3">      = u,v u,v X Y    . (<label>4</label></formula><formula xml:id="formula_4">)</formula><p>Y  (u,v) is the reconstructed coefficients in the block . This is achieved by</p><formula xml:id="formula_5">I  (u,v)=round(X  (u,v)/Q(u,v))</formula><p>and</p><formula xml:id="formula_6">Y  (u,v)=Q(u,v)I  (u,v).</formula><p>Here, I  (u,v) is the index of the quantization interval for the block  and Q(u,v) is a quantization step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. FRAMEWORK OF COEFFICIENT ESTIMATION WITH BLOCK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SIMILARITY</head><p>In a standard decoder, the image is reconstructed simply by inversely transforming the quantized coefficients for each coding block. In this paper, we seek a better image recovery from the view point of statistical inference. This is formulated as follows: given the quantized transform coefficients Y  for each coding block ∈Ω CB , find the image x which has the maximum a posteriori probability:</p><formula xml:id="formula_7">  CB argmax ˆ        Y x P r x x   . (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>Based on the Bayesian rule, the problem can be reformulated as</p><formula xml:id="formula_9">    CB argmax ˆ         x logPr Y x logPr x x   . (<label>6</label></formula><formula xml:id="formula_10">)</formula><p>Here, the first term in ( <ref type="formula" target="#formula_9">6</ref>) is the likelihood and the second term is the prior model of image x. In the literatures, many image prior models have been proposed (e.g. <ref type="bibr" target="#b19">[17]</ref>- <ref type="bibr" target="#b22">[20]</ref>). In this paper, we propose a block similarity prior model (BS-PM), which infers the coefficient distribution of an image transform-block utilizing the coefficients of similar blocks in a nonlocal area of the image. This is mainly based on the assumption that the coefficients in similar blocks usually have similar statistical properties. The quantization noise prior model (Q-PM) is also used in this paper, which employs the quantization version of coefficients as an estimation of the original ones. Based on the two models, the optimization problem in ( <ref type="formula" target="#formula_9">6</ref>) is rewritten as,</p><formula xml:id="formula_11">      CB argmax Q B S ˆ          x x l o gPr Y x logPr x logPr x   .<label>(7)</label></formula><p>Here, Pr Q (x) and Pr BS (x) represent the probability distributions of Q-PM and BS-PM, respectively. These probability distributions are described in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Quantization Constraint</head><p>Since the quantization is independent for each coding block ([21]- <ref type="bibr" target="#b25">[23]</ref>), the conditional probability for quantization value is</p><formula xml:id="formula_12">        CB CB CB 1 = 0 , , ,                     X X X Y Pr Y x Pr Y Y             . (<label>8</label></formula><formula xml:id="formula_13">)</formula><p>Since log(0) approaches negative infinity, each of the estimated coefficients in <ref type="bibr" target="#b9">(7)</ref> should be in the quantization interval</p><formula xml:id="formula_14">[Y min  (u,v),Y max  (u,v)]. Y min  (u,v) = Y  (u,v) - 1 2 Q(u,v). (<label>9</label></formula><formula xml:id="formula_15">)</formula><formula xml:id="formula_16">Y max  (u,v) = Y  (u,v) + 1 2 Q(u,v). (<label>10</label></formula><formula xml:id="formula_17">)</formula><p>This requirement is referred as quantization constraint. It can be implemented by a projection operation,</p><formula xml:id="formula_18">X '  = Q (X  , Y  ), defined as,                       min min min max max max u,v if u,v u,v u,v u,v if u,v u,v u,v u,v if u,v u,v , , ,              Y X Y X X Y X Y Y X Y           <label>(11)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Image Quantization Noise Prior Model</head><p>In compressed image, the noises in the coding blocks and the non-coding blocks are both caused by quantizing coding block coefficients. In this paper, we refer to them as quantization noise together. With the reconstructed coefficients in quantization intervals, the distribution of quantization noise can reflect the distribution characteristic of original coefficients in quantization intervals and is denoted as Pr Q (x)=Pr(X-(X)).</p><p>There are many quantization noise models in the literatures (e.g. <ref type="bibr" target="#b11">[9]</ref>, <ref type="bibr" target="#b12">[10]</ref>, <ref type="bibr" target="#b26">[24]</ref>- <ref type="bibr" target="#b28">[26]</ref>). Robertson and Stevenson <ref type="bibr" target="#b26">[24]</ref> utilize the Laplacian quantization noise model for quantized DCT coefficients equal to zero and uniform quantization noise model for nonzero quantized DCT coefficients. Sun and Cham <ref type="bibr" target="#b12">[10]</ref> employed Gaussian distribution for quantization noises in the spatial domain.</p><p>In Fig. <ref type="figure">1</ref>, we illustrate the histogram of the quantization noises for the coding blocks and the non-coding blocks in Lena compressed by JPEG. From Fig. <ref type="figure">1</ref>, we can see that the quantization noises resemble Gaussian distribution in low frequency bands and resemble Laplacian distribution in high frequency bands. Therefore, we take the generalized Gaussian distribution (GGD) <ref type="bibr" target="#b40">[38]</ref> to approximately model quantization noises with different parameters for different bands. The quantization noise distribution is formulated as follows,</p><formula xml:id="formula_19">        1 = 1 , Q Q v β v v β                        Pr x exp X Y X Y       ,<label>(12)</label></formula><p> </p><formula xml:id="formula_20">CB NCB 1 1 1 + 2 2 , 1 0 Q , Q , Q and , , o t h e r s                     X Y Y X Y        . (<label>13</label></formula><formula xml:id="formula_21">)</formula><p>In principle, the parameter, v, in the GGD model should be estimated from a large volume of compressed image block samples. However, it is easy to observe from Fig. <ref type="figure">1</ref>  IEEE TRANSACTION ON IMAGE PROCESSING, VOL. XX, NO. X 4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Image Block Similarity Prior Model</head><p>Since the above Q-PM is a global prior model for natural images, it cannot reflect the variation of image local structure efficiently. Choy et al. <ref type="bibr" target="#b16">[14]</ref> proposed a local smoothness prior model using the average of local coefficients as the expectation of original coefficient distribution. The prior distribution of original coefficient in <ref type="bibr" target="#b16">[14]</ref> can be formulated as,</p><formula xml:id="formula_22">            1 1 2 = 1 2 1 LS T                 Pr x exp X X C X X C          , (14)     1     X X        , (<label>15</label></formula><formula xml:id="formula_23">)       m,n m,n k,l m L k m L n L l n L ,              \ . (<label>16</label></formula><formula xml:id="formula_24">)</formula><p>Here, ( m,n ) is the neighborhood of block  m,n with radius L.</p><p>|()| is the number of blocks in this neighborhood. C () is a diagonal matrix with the variance of neighboring coefficients, σ 2 ()(u,v), as its diagonal element, which is calculated by,</p><formula xml:id="formula_25">              2 2 1 , , , u v u v u v       X X          . (<label>17</label></formula><formula xml:id="formula_26">)</formula><p>Unfortunately, this assumption is not reasonable for some regions, e.g. edges or textures.</p><p>To better infer the coefficient distribution, we propose to employ the transform-blocks with different weights as extra samples to form a prior distribution of original coefficients. In fact, it utilizes the weighted average of the coefficients in non-local blocks as the expectation of the original coefficient distribution. Here, we define the estimated transform-block as target block, and the ones used to infer the distribution of coefficients in the target block as sample blocks. The weight reflecting the block similarity between sample block and target block, is called sample weight. Based on the central limit theorem (CLT) <ref type="bibr" target="#b29">[27]</ref>, the proposed block similarity prior model is formulated as,</p><formula xml:id="formula_27">            1 1 2 = 1 2 1 BS T                 Pr x exp X X C X X C          ,<label>(18)</label></formula><formula xml:id="formula_28">  w      X X       , (<label>19</label></formula><formula xml:id="formula_29">)             2 2 u ,v u,v u ,v w        X X         . (<label>20</label></formula><formula xml:id="formula_30">)</formula><p>Here, w ' is the sample weight for block ' and the variance of coefficients in sample blocks, σ 2 ()(u,v) , is calculated from equation <ref type="bibr" target="#b22">(20)</ref>. Based on the assumption that the similar blocks have similar statistical characteristics for transform coefficients, the more similar blocks can provide better prediction for the distribution of coefficients in target blocks. Therefore, higher weights should be assigned to the sample blocks that are more similar with the target block. On the other hand, lower weights should be assigned to sample blocks that are less similar with the target block, because the dissimilar sample blocks usually provide less meaningful information for the distribution.</p><p>In order to find reasonable sample weights, the relationship of block similarity and prediction accuracy needs to be investigated. Motivated by the well-known nonlocal means filter ( <ref type="bibr" target="#b6">[4]</ref>, <ref type="bibr" target="#b7">[5]</ref>), we employ the square root of difference of transform-blocks (i.e. L 2 norm distance in DCT domain) to measure their similarity. When the L 2 norm distance of two transform-blocks is smaller, the two blocks are more similar, vice versa. In addition, we utilize the mean square of prediction errors to measure the prediction accuracy for target block. In Fig. <ref type="figure" target="#fig_1">2</ref>, the relationship between the mean square of prediction errors and block similarity is illustrated based on the uncompressed images. The horizontal axis represents the L 2 norm distance between sample blocks and target blocks in DCT domain. The vertical axis represents the mean square of prediction errors. From Fig. <ref type="figure" target="#fig_1">2</ref>, we can see that the mean square of prediction errors increases rapidly along with the increase of the distance between sample blocks and target blocks, and their relationship can be fitted with an exponent function very well. Therefore, the sample weights for blocks in neighborhood () are defined,</p><formula xml:id="formula_31">2 1 Z h w                X X exp    , (<label>21</label></formula><formula xml:id="formula_32">)   2 Z h                 X X exp      . (<label>22</label></formula><formula xml:id="formula_33">)</formula><p>Here, Z is the normalization constant. The parameter, h, is a smoothness factor to control the distribution of sample weights. In order to analyze the efficiency of our proposed block similarity image prior model, we compare its prediction performance with the other two image prior models. One is the local image prior model in <ref type="bibr" target="#b16">[14]</ref> utilizing the average of local coefficients as the expectation of the original coefficients. The other one is a global image prior model that assumes the DCT transform coefficients following zero-mean Laplacian distribution, which takes zero as the expectation of original coefficients. We take some common test images, i.e. Barbara, Elaine, Motor, Lena, and Peppers, to calculate mean square error (MSE) of the predictions using different prior models for all the bands in 8×8 transform-blocks. Fig. <ref type="figure" target="#fig_2">3</ref> illustrates the MSE comparison results with the three models. We can see that the local average prior model and our proposed BS-PM achieve better prediction performance in low frequency bands than that of the Laplacian prior model, which cannot adapt to image local variants. The proposed BS-PM also has better prediction performance than that of the local average model due to the block similarity also varying in local areas. In addition, along with the increase of the neighborhood size, more and more sample blocks with different structures are employed in prediction. However, they have little positive effects or even have negative effects in predicting original coefficients. They degrade the prediction performance of local average model. In the proposed BS-PM, the sample blocks are employed distinctively based on block similarity and the negative effects of dissimilar sample blocks are depressed by assigning small weights. Therefore, the BS-PM achieves the best prediction results in the three models, and the neighborhood size has little effects on its performance as illustrated in Fig. <ref type="figure" target="#fig_2">3</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Block Similarity Prior Model with Compressed Images</head><p>Although the block similarity prior model has been proposed, there are still some problems when applying them to the compression artifact reduction application, where only compressed images exist. There are two variations compared with that in original images. First, we employ the reconstructed coefficients in similar transform-blocks to predict the original coefficients, but the accuracy of block similarity measurement is impaired by the presence of compression noises. Therefore, the coefficients only in low frequency bands are used to calculate the block similarity, which are not sensitive to noises. Second, we take advantage of the reconstructed values to distinguish coefficients used in prediction. Since the original coefficients lie in the quantization interval indicated by the reconstructed values, some outlier coefficients in sample blocks, which are far away from the reconstructed values, should be excluded to improve the prediction accuracy. Based on the two discussions, the sample weight for each band is rewritten as, In Fig. <ref type="figure" target="#fig_4">5</ref>, we compare the prediction performance of the BS-PM and local average model on the same test images in III-C, which are compressed by JPEG at QF = 20. The sample weight used in Fig. <ref type="figure" target="#fig_4">5</ref> is calculated from equation ( <ref type="formula" target="#formula_34">23</ref>). From Fig. <ref type="figure" target="#fig_4">5</ref>, we can see that the prediction performance of the proposed BS-PM is still much better than that of local average model on compressed images and is more robust to the neighborhood size due to employing block similarity and the outlier exclusion with the step function in <ref type="bibr" target="#b25">(23)</ref>. In addition, we also test the performance of BS-PM at different QFs illustrated in Fig. <ref type="figure" target="#fig_5">6</ref>. It shows another advantage of the proposed model that the MSE of the prediction decreases along with the increase of QF. This is mainly because more and more coefficients in similar blocks are regarded as outliers and excluded along with the decrease of the quantization step.  IEEE TRANSACTION ON IMAGE PROCESSING, VOL. XX, NO. X 6</p><formula xml:id="formula_34">        2 1 M M γQ u ,v u ,v u ,v Z h                  W Y Y exp Y Y  ，     . (<label>23</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. OPTIMIZATION SOLUTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Separation of Optimization Function</head><p>Under overlapped framework, the number of blocks involved in <ref type="bibr" target="#b9">(7)</ref> equals to the total number of blocks in the image  and these blocks are dependent. Therefore, to make the optimization feasible, we divide the block set Ω into several subsets:</p><formula xml:id="formula_35">      ; m o d sub m,n i, j m i n j N      .</formula><p>(24) Obviously, there are a total of N×N subsets (by setting i, j = 0, 1, …, N-1). Each subset forms a complete coverage of the image  with non-overlapped blocks except at image boundaries. To find the solution to the problem (7), we perform N×N sub-optimizations which minimizes (7) w.r.t. the variable X  in a block subset Ω sub (i, j) while keeping the estimated X  in other subsets temporarily constant and irrelevant. Since the blocks in each subset are non-overlapped, the optimization problem ( <ref type="formula" target="#formula_11">7</ref>) can be solved by optimizing X  in each subset separately. Assuming prior distributions being independent for different bands, the optimization solution to subset Ω sub (i, j) for each band can be derived by setting the deviation of (7) to zero. The final solution is illustrated in ( <ref type="formula">25</ref>)-( <ref type="formula" target="#formula_38">28</ref>). The solution ( <ref type="formula">25</ref>) is used for estimating the coefficients in bands with Gaussian quantization noise distribution, and the solution ( <ref type="formula" target="#formula_37">26</ref>) is used for estimating the coefficients in bands with Laplacian quantization noise distribution. From equations ( <ref type="formula">25</ref>) and ( <ref type="formula" target="#formula_37">26</ref>), we can see that the estimation of original coefficients is generated by adaptively fusing two prediction values based on their reliability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head> </head><formula xml:id="formula_36">                        2 2 2 2 2 2 = Q Q Q u,v u,v u,v u,v u,v u,v u,v u,v u,v           Y Y X          </formula><p>, ∈Ω sub (i,j). ( <ref type="formula">25</ref>)</p><formula xml:id="formula_37">                                                                  2 2 2 2 2 2 2 2 2 2 2 2 Q Q Q Q Q Q u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v                                   Y Y Y X Y Y Y Y Y Y                            ∈Ω sub (i,j), (<label>26</label></formula><formula xml:id="formula_38">)         ( ) sub i , j u ,v u ,v u ,v       Y W Y      (27)   = Q ˆ,  X X Y     CB    . (<label>28</label></formula><formula xml:id="formula_39">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Enforcement of Quantization Constraint</head><p>According to ( <ref type="formula">25</ref>)-( <ref type="formula" target="#formula_38">28</ref>), the optimization in <ref type="bibr" target="#b9">(7)</ref> for each subset can be easily solved. However, the quantization constraint in ( <ref type="formula" target="#formula_38">28</ref>) is limited to the sub-optimization solution of Ω sub (0,0). When i and j are not zero simultaneously, the blocks in Ω sub (i,j) correspond to non-coding blocks. In this case, to enforce the quantization constraint, the optimization solution to each subset can be obtained as follows: (1) for every block in Ω sub (i,j), find the optimal estimation  X  via equation ( <ref type="formula">25</ref>) and ( <ref type="formula" target="#formula_37">26</ref>); (2) construct the whole estimated image by inversely transforming all the estimated blocks in this subset; (3) divide the estimated image into blocks as Ω sub (0,0) and convert them to block-DCT domain; (4) apply the quantization constraint operation in <ref type="bibr" target="#b30">(28)</ref> to blocks generated in stage (3); ( <ref type="formula" target="#formula_7">5</ref>) convert estimated blocks in stage (4) to the spatial domain, and get the estimated image for the subset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Adaptive Parameter Selection and Algorithm Description</head><p>In image process algorithms, different parameter sets may affect the performance of algorithms significantly. For practical algorithms, the parameters should be constant or decided adaptively. In our proposed scheme, there are six parameters to be decided, i.e., the first N b bands with Gaussian quantization noise distribution, the parameter M and γ in ( <ref type="formula" target="#formula_34">23</ref>) used in sample weight, the variance of the quantization noises σ 2 Q , the neighborhood size L, and the smoothness factor h in <ref type="bibr" target="#b25">(23)</ref>. We set N b as 10 for all the experiments empirically. For the parameters M and γ, we simply set them as 16 and 6 for 8×8 blocks respectively, which do not have significantly influence on the performance. For the variance of quantization noises, we estimate it from the quantization step in this paper,</p><formula xml:id="formula_40">    2 2 1 Q u,v Q u,v    . (<label>29</label></formula><formula xml:id="formula_41">)</formula><p>For JPEG compressed images, we set α set as 7 and 0.5 for Gaussian quantization noise and Laplacian quantization noise respectively.</p><p>For the parameters, L and h, which have obvious influence on the final performance, we employ some test images to find the reasonable parameter values. The test images, Airplane, Barbara, Motor, Elaine, Lena and Peppers, are compressed by JPEG at different QFs. Firstly, we test the effect of the neighborhood size according to objective quality of estimated images measured by peak signal-noise ratio (PSNR). In Fig. <ref type="figure" target="#fig_6">7</ref>, we illustrate the results of Lena with size of 256×256 and Airplane with size of 384×256, for different neighborhood sizes and QFs with the same smoothness factor h. It can be easily observed that the performance of our proposed scheme is improved along with the increase of the neighborhood size, L, at different QFs. When L is beyond 8, the performance is almost stable. Considering the performance and complexity, we take the parameter L as 8 in our scheme. Secondly, we search for the best smoothness factor, h, given the neighborhood size parameter as 8. Based on the previous research, e.g. nonlocal means filter <ref type="bibr" target="#b6">[4]</ref> [5], the smoothness factor is closely related to compression noise levels. For simplicity, in this paper, we take quantization step of DC band, Q(0,0), as a measurement of compression noise levels, which can be obtained from the compressed bitstream. In order to find the relationship between h and Q(0,0), we try out h from 5 to 60 with increment one for the test images, Barbara, Elaine, Lena, Pepper with size 512×512 and Motor with size 768×512, compressed by JPEG at QFs in {5, 10, 15, 20 … 90}. The relationship between h and QF is approximately expressed by linear regression in Eqn. <ref type="bibr" target="#b32">(30)</ref>.</p><formula xml:id="formula_42">      0 0 16 0.2546 0 0 12 557 0 0 16 16 63 Q , Q , . h Q , .       <label>(30)</label></formula><p>Based on the above discussion, our proposed algorithm is described as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENT RESULTS</head><p>In this section, we first test the performance of the overlapped strategy. The overlapped step size is defined as the distance between two adjacent blocks to be estimated. If the overlapped step size is the same as the block size, all the blocks are non-overlapped. If the overlapped step size is 1, there is only one column of pixels are different between the two adjacent blocks in horizontal direction. In Fig. <ref type="figure" target="#fig_7">8</ref>, the performance of different overlapped step sizes for images, Lean, Peppers with size of 512×512 and Parrot with size of 768×512 compressed by JPEG at QF=15 is tested. The results illustrate that the smaller overlapped step size provides the higher quality of restored images. This is mainly because more predictions are generated for the image with smaller overlapped step sizes. In addition, the overlapped strategy takes advantage of the correlations between blocks to depress the blocking artifacts. We also evaluate the performance of the proposed method with state-of-the-art compression artifact reduction algorithms and denoising algorithms, including Choy's method <ref type="bibr" target="#b16">[14]</ref>, the nonlocal means filter (NLM) <ref type="bibr" target="#b7">[5]</ref>, BM3D method <ref type="bibr" target="#b30">[28]</ref>, PSW <ref type="bibr" target="#b31">[29]</ref>, Nosratinia's method <ref type="bibr" target="#b32">[30]</ref>, steering kernel regression (SKR) <ref type="bibr" target="#b8">[6]</ref>, KSVD <ref type="bibr" target="#b33">[31]</ref>, Sun's method <ref type="bibr" target="#b12">[10]</ref> and PLOW <ref type="bibr" target="#b34">[32]</ref>. The test images in our experiments includes popular images Barbara, Fishingboat, Lena, Peppers with size of 512×512, Cameraman with size of 256×256 and Kodak image set, as listed in Table <ref type="table">I</ref>. These gray images are first encoded by a JPEG coder <ref type="bibr" target="#b35">[33]</ref> with different quality factors and then reconstructed using standard JPEG decoder and different compression artifact reduction methods. For our proposed method, the parameter L is set as 8 and the smoothness factor h is set according to <ref type="bibr" target="#b32">(30)</ref>. For the compared methods, we also try out many parameters with some test images to find the reasonable ones under different compression ratios. Table <ref type="table">I</ref> illustrates the PSNR results of the reconstructed images with different methods. Our proposed scheme outperforms all of the other methods and achieves up to 1.19dB gain over JPEG decoder on average. Compared with other artifact reduction methods, our proposed method also achieves about 0.25~0.75dB on average. Especially, our method achieves up to 1.50dB gains over JPEG for image Parrot. In table II, we illustrate the Structural Similarity Index Metric (SSIM) results of the reconstructed images. The SSIM is another image quality assessment method, which is known to be able to provide a more consistent measurement of image quality with human eye perception <ref type="bibr" target="#b38">[36]</ref>.</p><p>Our proposed method also achieves better performance compared with other methods on average. The best results are highlighted for each image in Table <ref type="table">I</ref> and Table <ref type="table" target="#tab_0">II</ref>. Fig. <ref type="figure" target="#fig_8">9</ref> shows the reconstruction quality and the improvement vary with JPEG quality factors. We can see that our proposed scheme works well over a wide quality (or bit rate) range. Especially, for the image Barbara, the performance of our proposed method is much better than that of others due to lots of similar patches existing in this image. To evaluate the influence of noise models, we compare the performance of two alternative quantization noise models with the hybrid Gaussian-Laplacian noise model used in our proposed method. The other two quantization noise modeling schemes use the Gaussian distribution alone and the Laplacian distribution alone, respectively. We denote the compression artifact reduction method with Gaussian quantization noise model alone as Method-G and the other method with Laplacian quantization noise model alone as Method-L. Table <ref type="table" target="#tab_0">III</ref> illustrates PSNR results of the three methods. We can see that the three methods achieve very similar performance (with difference smaller than 0.2dB and average difference smaller than 0.02dB), which suggests that the three quantization noise models do not have significant difference on the overall performance. The reason is that in our framework, we estimate the original coefficients by adaptively fusing the two predictions, i.e., predicted coefficients from the decoded image and from the group of similar blocks. The weights of the two predictions are determined by their variance. Since coefficients from the group of similar blocks with current block fall into a small range constrained by quantization intervals, their variance in general is much smaller than that of coefficient quantization errors in current block, which is formed by all possible image blocks. Therefore, the prediction from the group of similar bocks will dominate the ultimate prediction result.</p><p>In Fig. <ref type="figure" target="#fig_9">10</ref>, we illustrate the mean square error of coefficients for Lena, reconstructed with our proposed method and JPEG for different bands. We can see that our proposed method can significantly reduce the mean square error of coefficients in low and middle frequency bands. In Fig. <ref type="figure">11</ref> and 12, we show the subjective quality of the reconstructed images which are also compressed at QF=15. From the subjective quality comparison, we can see that the compression artifacts are obvious in the images reconstructed by the standard JPEG decoder. The compared methods are able to reduce the compression artifacts partially, but some blocking and ringing artifacts are still observed obviously in the images, e.g. on the airscrew in Fig. <ref type="figure">11</ref> and on the back of the rider in Fig. <ref type="figure" target="#fig_1">12</ref>. Our proposed method produces more pleasing visual quality than that of other methods, especially in the region of the red box. It does not only reduce most of the compression artifacts significantly, but also preserves image edges very well.</p><p>In the following experiment, we compare our proposed method with the in-loop filter of H.264/AVC <ref type="bibr" target="#b37">[35]</ref>. The software of H.264/AVC is JM18.2 <ref type="bibr" target="#b38">[36]</ref>. The sequences are common test sequences with WQVGA format widely used in video coding standards, BaskeballPass, BQSquare, BlowingBubbles, RaceHorses. These sequences are compressed with intra coding method of H.264/AVC, in which we make only 8×8 block partition enable for convenience. The quantization parameters are set as 37 and 47 respectively. The parameter α in ( <ref type="formula" target="#formula_40">29</ref>) is set as 25 for Gaussian quantization noise distribution and 20 for Laplacian quantization noise distribution, because the transform coefficients of the prediction residuals are more concentrated around zero, which causes the quantization noises with a lower variance. The other parameters are the same as the above experiments. Table <ref type="table" target="#tab_1">IV</ref> and V illustrate the objective quality of the luminance component with two quality assessment methods, PSNR and SSIM. Our proposed method achieves up to 0.31 dB gain over the in-loop filter of H.264/AVC for RaceHorses at QP=37. On average, our proposed method achieves 0.20 dB gain over in-loop filter of H.264/AVC at QP=37, and achieves 0.16 dB gain at QP=47.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>In this paper, we propose a new transform-domain approach to reduce the compression artifacts. In the proposed scheme, the transform coefficients of a compressed image are restored by adaptive estimation of DCT coefficients in overlapped transform-blocks. The quality of restored images is improved via combining the quantization noise model and block similarity prior model. To tackle the optimization problem, the overlapped blocks are divided into several subsets containing non-overlapped blocks so that the overall optimization is reduced to a set of sub-optimization problems that can be easily solved. An effective parameter selection method is proposed to make our scheme more practical. Experimental results demonstrate that our proposed method can remarkably improve both the subjective and the objective quality of the block transform coded images.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>In order to solve the sub-optimization problem, we substitute the probabilities in ( <ref type="formula" target="#formula_12">8</ref>), ( <ref type="formula" target="#formula_19">12</ref>) and ( <ref type="formula" target="#formula_27">18</ref>) into <ref type="bibr" target="#b9">(7)</ref>. For the bands with Gaussian quantization noise distribution, the optimization problem is formulated as,  .</p><formula xml:id="formula_43">                       1 1 2 1 1 2 1 1 2 1 argmax argmax 1 2 Q T Q i, j Q i, j sub T sub BS ˆ                                                   </formula><formula xml:id="formula_44">Q Q Q Q Q Q , ,</formula><p>Here, X  , Y () and Y  -are vectors whose elements are taken row-wise from corresponding blocks. The function, diag(•), constructs a diagonal matrix with its elements. Assuming that the blocks in image  are independent, the optimization problem in ( <ref type="formula">31</ref>) is equal to that in <ref type="bibr" target="#b34">(32)</ref> for all the blocks in Ω sub (i,j).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>   </head><formula xml:id="formula_45">          1 1 argmin 1 2 1 2 T Q T          X X X Y C X Y X Y C X Y               . (<label>32</label></formula><formula xml:id="formula_46">)</formula><p>Therefore, the solution of optimization problem in <ref type="bibr" target="#b34">(32)</ref> is derived by setting its derivative to zero w.r.t. X  in each block subset.</p><formula xml:id="formula_47">        1 1 =0 Q      C X Y C X Y        . (<label>33</label></formula><formula xml:id="formula_48">)</formula><p>The solution is derived as follows.</p><formula xml:id="formula_49">          1 1 1 1 1 = Q Q         X C C C Y C Y         . (<label>34</label></formula><formula xml:id="formula_50">)</formula><p>Because the two matrices C</p><p>-1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q and C</head><p>-1 () are diagonal ones, the solution for bands in ( <ref type="formula" target="#formula_37">26</ref>) is obtained by substituting the matrices with their elements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head> </head><formula xml:id="formula_51">                        2 2 2 2 2 2 = Q Q Q u ,v u ,v u ,v u ,v u ,v u ,v u ,v u ,v u ,v σ σ σ σ σ      Y X Y           . (<label>35</label></formula><formula xml:id="formula_52">)</formula><p>For the bands with Laplacian quantization noise distribution, the optimization problem is formulated as, The optimization process is similar with that in <ref type="bibr" target="#b39">[37]</ref>. The derivative of the equation ( <ref type="formula">36</ref>) is set to zero w.r.t. X  in each block subset.</p><formula xml:id="formula_53">                    1 2 1 1 2 1 2 2 1 1 argmax argmax 2 1 2 Q Q i, j Q i, j sub T sub BS ˆ                                                  </formula><formula xml:id="formula_54">        1 1 2 2 =0 Q sign      C X Y C X Y        ,<label>(37)</label></formula><p> </p><formula xml:id="formula_55">1 0 0 0 1 0 x sign x x x           . (<label>38</label></formula><formula xml:id="formula_56">)</formula><p>The solution for bands in ( <ref type="formula">27</ref>) is obtained by substituting the matrices with their elements.</p><formula xml:id="formula_57">                                                             2 2 2 2 2 2 2 2 2 2 2 2 Q Q Q Q Q Q u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v u,v                                   Y Y Y X Y Y Y Y Y Y                            (39)</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Fig. 1: The histogram of quantization noises in the coding blocks (a) and the non-coding blocks (b) for Lena compressed by JPEG at quality factor 15.</figDesc><graphic coords="3,437.88,627.48,102.36,91.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Fig.2:The relationship of the mean square of prediction errors and the L2 norm distance between blocks in DCT domain (over 30,000,000 blocks) fitted with exponent function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: The mean square error of the prediction for different image prior models on uncompressed images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: The relationship of the mean square of the prediction errors and the L 2 norm distance between blocks (over 30,000,000 blocks) in compressed images at different quality factors.</figDesc><graphic coords="5,70.20,246.24,195.84,115.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: The mean square error of the prediction for local average model and weighted average prediction (BS-PM) on JPEG compressed images at QF=20.</figDesc><graphic coords="5,325.44,465.48,203.58,115.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: The mean square error of the prediction for the weighted average prediction (BS-PM) on JPEG compressed images at different quality factors.</figDesc><graphic coords="5,323.10,601.20,208.44,118.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 :</head><label>7</label><figDesc>Fig. 7: The performance of our proposed method with different neighborhood sizes.</figDesc><graphic coords="7,69.48,84.72,197.10,121.32" type="vector_box" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 :</head><label>8</label><figDesc>Fig. 8: The performance of our proposed method with different overlapped step sizes. The images are compressed by JPEG at QF=15.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>9 :</head><label>9</label><figDesc>The quality of the reconstructed images with different methods at different compression quality factors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 :</head><label>10</label><figDesc>Fig. 10: The mean square error of coefficients in coding blocks for Lena reconstructed by the proposed method and JPEG.</figDesc><graphic coords="8,309.84,359.82,234.60,168.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE II :</head><label>II</label><figDesc>SSIM RESULTS OF RESTORED IMAGES USING DIFFERENT METHODS FOR TEST IMAGES COMPRESSED BY JPEG AT QF = 15 . The reconstructed images with different methods. The test image, Motor, is compressed by JPEG at QF = 15.</figDesc><table><row><cell cols="2">Original</cell><cell></cell><cell cols="2">JPEG decoder</cell><cell></cell><cell cols="2">Choy's method</cell><cell></cell><cell cols="2">Nosratinia's method</cell><cell></cell></row><row><cell></cell><cell>PSW</cell><cell></cell><cell cols="2">Sun's method</cell><cell></cell><cell></cell><cell>NLM</cell><cell></cell><cell></cell><cell>BM3D</cell><cell></cell></row><row><cell></cell><cell>SKR</cell><cell></cell><cell cols="2">KSVD</cell><cell></cell><cell></cell><cell>PLOW</cell><cell></cell><cell cols="2">Our proposed method</cell><cell></cell></row><row><cell></cell><cell>Fig.12:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TestImages</cell><cell>JPEG</cell><cell>Choy's</cell><cell>Nosratinia's</cell><cell>PSW</cell><cell>Sun's</cell><cell>NLM</cell><cell>BM3D</cell><cell>SKR</cell><cell>KSVD</cell><cell>PLOW</cell><cell>Proposed</cell></row><row><cell>Barbara</cell><cell>0.816</cell><cell>0.824</cell><cell>0.830</cell><cell>0.830</cell><cell>0.832</cell><cell>0.841</cell><cell>0.845</cell><cell>0.833</cell><cell>0.838</cell><cell>0.843</cell><cell>0.844</cell></row><row><cell>Cameraman</cell><cell>0.836</cell><cell>0.845</cell><cell>0.854</cell><cell>0.844</cell><cell>0.863</cell><cell>0.858</cell><cell>0.858</cell><cell>0.852</cell><cell>0.850</cell><cell>0.858</cell><cell>0.862</cell></row><row><cell>FishingBoat</cell><cell>0.804</cell><cell>0.815</cell><cell>0.825</cell><cell>0.813</cell><cell>0.823</cell><cell>0.823</cell><cell>0.828</cell><cell>0.824</cell><cell>0.807</cell><cell>0.826</cell><cell>0.827</cell></row><row><cell>Lena</cell><cell>0.852</cell><cell>0.872</cell><cell>0.876</cell><cell>0.873</cell><cell>0.878</cell><cell>0.878</cell><cell>0.879</cell><cell>0.877</cell><cell>0.870</cell><cell>0.881</cell><cell>0.882</cell></row><row><cell>Peppers</cell><cell>0.817</cell><cell>0.838</cell><cell>0.843</cell><cell>0.839</cell><cell>0.849</cell><cell>0.845</cell><cell>0.845</cell><cell>0.845</cell><cell>0.842</cell><cell>0.847</cell><cell>0.850</cell></row><row><cell>Hats</cell><cell>0.859</cell><cell>0.875</cell><cell>0.880</cell><cell>0.875</cell><cell>0.884</cell><cell>0.885</cell><cell>0.883</cell><cell>0.880</cell><cell>0.880</cell><cell>0.877</cell><cell>0.887</cell></row><row><cell>Kodim04</cell><cell>0.809</cell><cell>0.824</cell><cell>0.828</cell><cell>0.822</cell><cell>0.828</cell><cell>0.827</cell><cell>0.831</cell><cell>0.826</cell><cell>0.815</cell><cell>0.824</cell><cell>0.831</cell></row><row><cell>Motor</cell><cell>0.808</cell><cell>0.818</cell><cell>0.829</cell><cell>0.817</cell><cell>0.831</cell><cell>0.831</cell><cell>0.838</cell><cell>0.835</cell><cell>0.822</cell><cell>0.836</cell><cell>0.836</cell></row><row><cell>Window</cell><cell>0.889</cell><cell>0.908</cell><cell>0.916</cell><cell>0.908</cell><cell>0.921</cell><cell>0.921</cell><cell>0.920</cell><cell>0.916</cell><cell>0.915</cell><cell>0.915</cell><cell>0.923</cell></row><row><cell>Sailboats</cell><cell>0.867</cell><cell>0.880</cell><cell>0.887</cell><cell>0.878</cell><cell>0.890</cell><cell>0.890</cell><cell>0.887</cell><cell>0.885</cell><cell>0.885</cell><cell>0.882</cell><cell>0.893</cell></row><row><cell>Sailboats2</cell><cell>0.846</cell><cell>0.860</cell><cell>0.869</cell><cell>0.858</cell><cell>0.871</cell><cell>0.873</cell><cell>0.875</cell><cell>0.869</cell><cell>0.861</cell><cell>0.870</cell><cell>0.876</cell></row><row><cell>Statue</cell><cell>0.838</cell><cell>0.858</cell><cell>0.864</cell><cell>0.859</cell><cell>0.867</cell><cell>0.866</cell><cell>0.867</cell><cell>0.866</cell><cell>0.855</cell><cell>0.863</cell><cell>0.869</cell></row><row><cell>Tower</cell><cell>0.811</cell><cell>0.820</cell><cell>0.825</cell><cell>0.819</cell><cell>0.824</cell><cell>0.823</cell><cell>0.826</cell><cell>0.821</cell><cell>0.811</cell><cell>0.822</cell><cell>0.827</cell></row><row><cell>Airplane</cell><cell>0.873</cell><cell>0.879</cell><cell>0.884</cell><cell>0.878</cell><cell>0.887</cell><cell>0.886</cell><cell>0.886</cell><cell>0.883</cell><cell>0.878</cell><cell>0.882</cell><cell>0.888</cell></row><row><cell>Parrot</cell><cell>0.884</cell><cell>0.907</cell><cell>0.910</cell><cell>0.907</cell><cell>0.915</cell><cell>0.913</cell><cell>0.910</cell><cell>0.910</cell><cell>0.905</cell><cell>0.906</cell><cell>0.916</cell></row><row><cell>Average</cell><cell>0.841</cell><cell>0.855</cell><cell>0.861</cell><cell>0.855</cell><cell>0.864</cell><cell>0.864</cell><cell>0.865</cell><cell>0.861</cell><cell>0.856</cell><cell>0.862</cell><cell>0.867</cell></row></table><note><p>IEEE TRANSACTION ON IMAGE PROCESSING, VOL. XX, NO. X 11</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE IV OBJECTIVE</head><label>IV</label><figDesc>QUALITY OF RESTORED IMAGES USING DIFFERENT METHODS FOR TEST IMAGES COMPRESSED WITH H.264 INTRA CODING AND QP = 37.</figDesc><table><row><cell>Test Images</cell><cell cols="6">H.264 w/o Deblocking H.264 Deblocking PSNR SSIM PSNR SSIM PSNR SSIM Proposed</cell></row><row><cell>BQSquare</cell><cell>28.68</cell><cell>0.843</cell><cell>28.79</cell><cell>0.849</cell><cell>28.88</cell><cell>0.859</cell></row><row><cell>BasketballPass</cell><cell>31.94</cell><cell>0.844</cell><cell>32.21</cell><cell>0.852</cell><cell>32.45</cell><cell>0.857</cell></row><row><cell>BlowingBubbles</cell><cell>29.98</cell><cell>0.815</cell><cell>30.15</cell><cell>0.822</cell><cell>30.34</cell><cell>0.827</cell></row><row><cell>RaceHorses</cell><cell>30.25</cell><cell>0.839</cell><cell>30.46</cell><cell>0.847</cell><cell>30.77</cell><cell>0.855</cell></row><row><cell>Average</cell><cell>30.21</cell><cell>0.835</cell><cell>30.40</cell><cell>0.843</cell><cell>30.60</cell><cell>0.850</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>IEEE TRANSACTION ON IMAGE PROCESSING, VOL. XX, NO. X</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The first author would like to thank Dr. Jiaying Liu for her work in revising the paper. He would like to also thank the three anonymous reviewers for their helpful comments and suggestions.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>. This work was supported in part by the National Basic Research Program of China (973 Program) under Grant 2009CB320904, the National Natural Science Foundation of China under Grants 61073083, 61121002 and 61103088, the Beijing Natural Science Foundation under Grants 4112026 and 4132039, and the Research Fund for the Doctoral Program of</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><surname>Table I</surname></persName>
		</author>
		<title level="m">PSNR RESULTS OF RESTORED IMAGES USING DIFFERENT METHODS FOR TEST IMAGES COMPRESSED BY JPEG AT QF = 15 (Unit: dB)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m">NO. X 10 TABLE III: PSNR RESULTS OF RESTORED IMAGES USING DIFFERENT QUANTIZATION NOISE MODELS FOR TEST IMAGES COMPRESSED BY JPEG (Unit: dB)</title>
		<imprint>
			<publisher>IEEE TRANSACTION ON IMAGE PROCESSING</publisher>
			<biblScope unit="volume">XX</biblScope>
		</imprint>
	</monogr>
	<note>TestImages QF=15 QF=25 QF=35 QF=45</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Proposed Method-G Method-L Proposed Method-G Method-L Proposed Method-G Method-L Proposed Barbara 28</title>
		<author>
			<persName><forename type="first">Method-G Method-L</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">54</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Review of Postprocessing Techniques for Compression Artifact Removal</title>
		<author>
			<persName><forename type="first">M.-Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C. Jay</forename><surname>Kuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Communication and Image Representation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="14" />
			<date type="published" when="1998-03">Mar. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reduction of blocking effect in image coding</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Reeve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<date type="published" when="1983-04">Apr. 1983</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1212" to="1215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Nonlinear Space-variant Postprocessing of Block Coded Images</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ramamurthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gersho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1258" to="1268" />
			<date type="published" when="1986-10">Oct. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Review of Image Denoising Algorithms, with A New One</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Multiscale Modeling and Simulation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="490" to="530" />
			<date type="published" when="2005-01">Jan. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Non-Local Algorithm for Image Denoising</title>
		<author>
			<persName><forename type="first">Antoni</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bartomeu</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Michel</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE international conference on Computer Vision Pattern Recognition</title>
		<imprint>
			<date type="published" when="2005-06">Jun. 2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Kernel regression for image processing and reconstruction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Takeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="349" to="366" />
			<date type="published" when="2007-02">Feb. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Iterative Procedures for Reduction of Blocking Effects in Transform Image Coding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zakhor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transl. on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="95" />
			<date type="published" when="1992-03">Mar. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An Optimization Approach for Removing Blocking Effects in Transform Image Coding</title>
		<author>
			<persName><forename type="first">S</forename><surname>Minami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zakhor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transl. on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="74" to="82" />
			<date type="published" when="1995-04">Apr. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Improved image decompression for reduced transform coding artifacts</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>O'rourke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE trans. on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="490" to="499" />
			<date type="published" when="1995-12">Dec. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Postprocessing of Low Bit-Rate Block DCT Coded Images Based on a Fields of Experts Prior</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-K</forename><surname>Cham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2743" to="2751" />
			<date type="published" when="2007-11">Nov. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An Efficient Wavelet-Based Deblocking Algorithm for Highly Compressed Images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1193" to="1198" />
			<date type="published" when="2001-04">Apr. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adaptive Postfiltering of Transform Confidents for the Reduction of Blocking Artifacts</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="594" to="602" />
			<date type="published" when="2001-05">May 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Efficient DCT-domain Blind Measurement and Reduction of Blocking Artifacts</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1139" to="1149" />
			<date type="published" when="2002-12">Dec. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Reduction of Block-transform Image Coding Artifacts by Using Local Statistics of Transform Coefficients</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S O</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Siu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="7" />
			<date type="published" when="1997-01">Jan. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Regression-based Prediction for Blocking Artifact Reduction in JPEG-Compressed Images</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="36" to="48" />
			<date type="published" when="2005-01">Jan. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Pointwise Shape-Adaptive DCT for High-Quality Denoising and Deblocking of Grayscale and Color Images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1395" to="1411" />
			<date type="published" when="2007-05">May 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Image denoising with an orientation-adaptive Gaussian scale mixture model</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Hammond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2006-10">Oct. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Exploiting the sparse derivative prior for super-resolution and image demosaicing</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Tappen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Russel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop on Statistical and Computational Theories of Vision</title>
		<meeting>IEEE Workshop on Statistical and Computational Theories of Vision</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A content-Aware Image Prior</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE international conference on Computer Vision Pattern Recognition</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fields of Experts: A framework for learning image priors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE international conference on Computer Vision Pattern Recognition</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="860" to="867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">JPEG Still Image Data Compression Standard</title>
		<author>
			<persName><forename type="first">W</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Van Nostrand</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">MPEG Video Compression Standard</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Fogg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Legall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Chapman &amp; Hall</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Overview of the H.264/AVC Video Coding Standard</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gisle</forename><surname>Bjøntegaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Luthra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="560" to="576" />
			<date type="published" when="2003-07">Jul. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">DCT Quantization Noise in Compressed Images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Circuits Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="38" />
			<date type="published" when="2005-01">Jan. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Superresolution Reconstruction of Compressed Video Using Transform-domain Statistics</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Gunturk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Altunbasak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mersereau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="43" />
			<date type="published" when="2004-01">Jan. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Neuhoff &quot;Quantization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Information Theory</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="1998-10">Oct. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Probability and Measure</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Billingsley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>John Wiley &amp; sons</publisher>
		</imprint>
	</monogr>
	<note>Third ed.</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2080" to="2095" />
			<date type="published" when="2007-08">Aug. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Efficient Image Deblocking Based on Postfiltering in Shifted Windows</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transl. on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="122" to="126" />
			<date type="published" when="2008-01">Jan. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Enhancement of JPEG-Compressed Image by Re-application of JPEG</title>
		<author>
			<persName><forename type="first">Aria</forename><surname>Nosratinia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of VLSI Signal Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="69" to="79" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Image Denoising Via Sparse and Redundant Representations Over Learned Dictionaries</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3736" to="3745" />
			<date type="published" when="2006-12">Dec. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Patch-Based Near-Optimal Image Denoising</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1635" to="1649" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title/>
		<ptr target="http://www.ijg.org/" />
	</analytic>
	<monogr>
		<title level="j">JPEG Encoder and Decoder</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Image Quality Assessment: From Error Visibility to Structural Similarity</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004-04">Apr. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Adaptive Deblocking Filter</title>
		<author>
			<persName><forename type="first">P</forename><surname>List</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lainema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bjøntegaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><surname>Karczewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2003-07">Jul. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>The</surname></persName>
		</author>
		<ptr target="http://iphome.hhi.de/suehring/tml/download/old_jm/" />
		<title level="m">AVC reference software is available from</title>
		<imprint>
			<biblScope unit="volume">264</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Fast and robust multiframe super-resolution</title>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1327" to="1344" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A mathematical analysis of the DCT coefficient distributions for images</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1661" to="1666" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
