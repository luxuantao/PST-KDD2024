<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Efficient Deformable Template Detection and Localization without User Initialization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">James</forename><surname>Coughlan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Smith-Kettlewell Eye Research Institute</orgName>
								<address>
									<postCode>94115</postCode>
									<settlement>San Francisco</settlement>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alan</forename><surname>Yuille</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Smith-Kettlewell Eye Research Institute</orgName>
								<address>
									<postCode>94115</postCode>
									<settlement>San Francisco</settlement>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Camper</forename><surname>English</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Smith-Kettlewell Eye Research Institute</orgName>
								<address>
									<postCode>94115</postCode>
									<settlement>San Francisco</settlement>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dan</forename><surname>Snow</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Smith-Kettlewell Eye Research Institute</orgName>
								<address>
									<postCode>94115</postCode>
									<settlement>San Francisco</settlement>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Efficient Deformable Template Detection and Localization without User Initialization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FBBC472180CB7A2382ABD87E85E9D1C1</idno>
					<idno type="DOI">10.1006/cviu.2000.0842</idno>
					<note type="submission">Received October 13, 1998; accepted March 16, 2000</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T17:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A novel deformable template is presented which detects the boundary of an open hand in a grayscale image without initialization by the user. A dynamic programming algorithm enhanced by pruning techniques finds the hand contour in the image in as little as 19 s on a Pentium 150 MHz. The template is translation-and rotationinvariant and accomodates shape deformation, significant occlusion and background clutter, and the presence of multiple hands.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>A promising approach to the detection and recognition of flexible objects involves representing them by deformable template models, for example, <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25]</ref>. These models specify the shape and intensity properties of the objects. They are defined probabilistically to take into account the variability of the shapes and their intensity properties.</p><p>The flexibility of such models means that to determine if the object is present in the image and to find where it is located are formidable computational problems. In simple images, standard edge detection techniques may be sufficient to segment the objects from the background, though we are still faced with the difficult task of determining how edge segments should be grouped to form an object. In more realistic images, however, large segments of object boundaries will not be detected by standard edge detectors. It often seems impossible to do segmentation without using high-level models such as deformable templates <ref type="bibr" target="#b12">[13]</ref>.</p><p>Many optimization strategies have been proposed for deformable templates. For a description of approaches and theoretical comparisions between certain methods see <ref type="bibr" target="#b25">[26]</ref>. Broadly speaking, either the algorithms are too slow for real time processing or they require initialization by the user. If initialization is provided, then algorithms based on dynamic programming <ref type="bibr" target="#b3">[4]</ref>, such as <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>, or on gradient descent <ref type="bibr" target="#b4">[5]</ref> can find the optimal solution. (Dynamic programming was also used in some previous work, such as <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b18">19]</ref>, to find generic contours in images.) Other graph-search algorithms related to dynamic programming are used to perform template matching, such as <ref type="bibr" target="#b10">[11]</ref>, and also <ref type="bibr" target="#b9">[10]</ref>, which searches automatically for the optimal match given a set of local features extracted from an image.</p><p>In this paper we show that dynamic programming can, in principle, be used to detect deformable objects in reasonable time without initialization. We test this result with a Bayesian deformable hand template (an earlier, non-Bayesian version of this work appears in <ref type="bibr" target="#b5">[6]</ref>). Adaptive quantization is used for the continuous variables. This enables the algorithm to find a hand in 6 min in a 388 × 512 image. The use of pruning techniques allows us to speed the algorithm up by an order of magnitude. Our current algorithm runs in 25 s on a Pentium 150 MHz and as little as 19 s for simple images. Adding an occlusion process allows the algorithm to find the hand even when it is significantly occluded (and to identify the location of the occlusion) and to detect multiple hands in the same image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">THE DEFORMABLE HAND TEMPLATE</head><p>Our deformable template is designed to detect planar views of a hand (or multiple hands) in a grayscale image. The template consists of four elements: a geometric prior, an occlusion process, an imaging model (all three of which make up the Bayesian model), and a dynamic programming optimization algorithm. The geometric prior describes probabilistically what configurations (shapes) the hand template is likely to assume, and the imaging model together with the occlusion process describe probabilistically how any particular configuration will appear in a grayscale image. Given an image, the Bayesian model assigns an a posteriori probability to each possible hand configuration. A dynamic programming algorithm searches for the maximum a posteriori (MAP) configuration, the configuration that optimally fits the image data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">The Geometric Prior</head><p>The first part of the Bayesian model is the geometric prior, which assigns a probability to each hand configuration. The configuration is represented by a chain of points x 1 , x 2 , . . . , x N in the plane which trace the boundary of the 2-dimensional hand shape and by an associated chain θ 1 , θ 2 , . . . , θ N of normal orientations which describe the direction of outward-pointing normal vectors at the points (see Fig. <ref type="figure" target="#fig_0">1</ref>). Each point x i has two components x i and y i and is quantized to the image pixel lattice. For brevity we define q i = (x i , θ i ).</p><p>The geometric prior is defined so as to assign high probabilities to configurations q 1 , q 2 , . . . , q N that are hand-like and low probabilities to configurations that are not. This is achieved by comparing a configuration to a fixed prototype shape q1 , q2 , . . . , qN (constructed manually from a representative photograph of a hand) and penalizing any deviation in shape between the two, irrespective of global rotation and translation. (The scale of the prototype is fixed and we assume knowledge of this scale when we execute our algorithm.)</p><p>Deviations in shape are measured by two kinds of shape similarity. First, the relative orientation of θ i and θ i+1 should be similar to that of θi and θi+1 . Expressed in terms of probabilities, this similarity is written where G(x; σ ) = (1/ √ 2πσ ) e -x<ref type="foot" target="#foot_2">2</ref> /2σ 2 and σ a,i is the standard deviation governing the angular relationship between stage i and stage i + 1 of the configuration. 2 This expression holds for all but three values of i, the ones corresponding to points x j 1 , x j 2 , x j 3 which precede the "hinges" between the index fingers. At these special values of i = j 1 , j 2 , or j 3 , we define the conditional probability to be uniform between certain limits: P(θ i+1 | θ i ) = 1/δ j if θ i+1 -θ i is between π and π + δ j and P(θ i+1 | θ i ) = 0 otherwise. Here the "hinge angle" between adjacent fingers is assumed to range uniformly from 0 (i.e., fingers together) to δ j (maximum spread angle in radians).</p><formula xml:id="formula_0">P(θ i+1 | θ i ) = G(θ i+1 -θ i -( θi+1 -θi ); σ a,i ),<label>(1)</label></formula><p>Second, we expect the geometric relationship of x i , θ i , and x i+1 to be similar to that of xi , θi , and xi+1 . Specifically, the displacement vector xi = xi+1xi that connects xi to xi+1 need only be rotated the proper amount to make a prediction x p i of the unknown displacement x i = x i+1x i . As Fig. <ref type="figure">2 suggests,</ref><ref type="figure">x</ref> p i = R(θ i -θi ) xi where R(θ ) denotes counterclockwise rotation by θ. In our model we allow x i+1 to deviate from x p i+1 = x i + x p i more freely in the normal direction perpendicular to x p i than along the tangent direction parallel to x p i . The rationale is that the length of x i is determined by the scale of the template and should not change much across stages, whereas the direction of x i varies as the contour bends. This may be expressed as</p><formula xml:id="formula_1">P(x i+1 | x i , θ i ) = G x i -x p i • xp i ; σ t i G x i -x p i ⊥ • xp i ; σ n i , (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where</p><formula xml:id="formula_3">xp i = x p i /| x p i</formula><p>| and (x, y) ⊥ = (-y, x) represents rotation of a vector by 90 • . <ref type="foot" target="#foot_3">3</ref> Here σ t,i and σ n,i are standard deviations along the tangent and normal directions, respectively (σ t,i &lt; σ n,i ). The dependence of these standard deviations, as well as the form of P(θ i+1 |θ i ), on stage i allows the prior to "bend" more easily at certain stages, such as the "hinge" between two fingers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FIG. 2.</head><p>The prototype displacement xi need only be rotated by θ i -θi to make a displacement prediction</p><formula xml:id="formula_4">x p i . x i+1 is expected in a neighborhood of x p i+1 = x i + x p i .</formula><p>Combining these two elements of the shape prior yields</p><formula xml:id="formula_5">P(q i+1 | q i ) = P(θ i+1 | θ i )P(x i+1 | x i , θ i ),<label>(3)</label></formula><p>and the prior of the entire configuration is</p><formula xml:id="formula_6">P(q 1 • • • q N ) = P(q 1 ) N-1 i=1 P(q i+1 | q i ),<label>(4)</label></formula><p>where P(q 1 ) is a uniform constant. Notice that the prior is a Markov chain invariant under global translations and rotations, and the behavior of the prior is similar to the deformations that a piece of wire bent into the shape of a hand contour may assume. The values of the standard deviations were chosen experimentally by statistically sampling the prior, i.e., generating samples from the prior distribution to illustrate what shapes have high probability (see Figs. <ref type="figure">3,</ref><ref type="figure">4</ref> for examples). Learning techniques such as Minimax Entropy Learning <ref type="bibr" target="#b27">[28]</ref> could be employed to determine more accurate values.</p><p>FIG. <ref type="figure">3</ref>. Samples of the hand prior with high standard deviations σ a,i , σ t,i , and σ n,i . (For simplicity the hinges were removed). Observe that an excessive range of deformations is permitted: several samples have overlapping fingers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FIG. 4.</head><p>Samples of the hand prior with medum standard deviations σ a,i , σ t,i , and σ n,i (hinges removed). The samples are fairly realistic and show a good range of variability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">THE OCCLUSION PROCESS</head><p>An occlusion process which interacts with the imaging model (see next section) has been added to the prior to allow the deformable template to detect a hand even when part of the hand is occluded or obscured by noise. The occlusion process is a chain of occlusion state variables h 1 , h 2 , . . . , h N associated with the configuration points x 1 , x 2 , . . . , x N . Each occlusion state variable h i may assume one of three values: 0, for nonocclusion; 1/2, denoting a triple point (i.e., corner or T-junction); and 1, for occlusion. These three occlusion states have distinct image properties (e.g., there is much less image information about the hand in an occluded region than in an unoccluded region), and using an occlusion process allows us to exploit these differences in the deformable template, rather than confound them.</p><p>We model the occlusion process as a Markov chain:</p><formula xml:id="formula_7">P(h 1 • • • h N ) = P(h 1 ) N-1 i=1 P(h i+1 | h i ). (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>The transition probabilities P(h i+1 | h i ) are chosen to be independent of i:</p><formula xml:id="formula_9">P(h i+1 = b | h i = a) = W ba , where W =   1 - β 0 0 α 0 1-β 1-α   .</formula><p>The entry W ba represents the transition probability from state a to state b, where the first, second, and third rows represent states 0, 1/2, and 1 respectively (and similarly for columns). These transition probabilities are shown in Fig. <ref type="figure" target="#fig_1">5</ref>. is the probability that state 0 will jump to state 1/2 and is chosen to be small, corresponding to the fact that occlusions are relatively rare. State 1/2 acts as a bridge between the nonocclusion state 0 and the occlusion state 1, representing the fact that the transition from a nonocclusion to an occlusion is usually signaled by a triple point, where the occluder and the object being occluded each produce edges at distinct orientations. (As the matrix indicates, our model forbids direct transitions between the 0 and 1 states.) β is the transition probability from state 1/2 to 0, and α is the probability that state 1 will jump back to the triple point state 1/2. The starting probability P(h 1 ) is set to (1, 0, 0); i.e., the first point is assumed to be nonoccluded. Finally, the occlusion process is independent of the geometric prior, so that the overall prior for the deformable template is given by</p><formula xml:id="formula_10">P(s 1 , s 2 , . . . s N ) = P(q 1 • • • q N )P(h 1 • • • h N ),<label>(6)</label></formula><p>where the notation s i is used to denote (q i , h i ). As we will describe in more detail in Section 4, we will have a specific cornerness measure C(x) which is statistically associated with the triple points which often occur at occlusions. C(x) measures the presence of a secondary edge at or near x with an orientation different from the primary edge at x, as occurs at corners and so-called "T-junctions" (see <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b19">20]</ref> for details). The cornerness measure provides evidence of occlusions: at most occlusion points there is a T-junction formed where the occluder and the object being occluded produce edges at distinct orientations. We will see how to exploit this information in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">THE IMAGING MODEL</head><p>A simple imaging model explains what image data may be expected given a specific hand configuration. Rather than explicitly modeling the grayscale intensities I (x) at each pixel location x we model three sets of data derived from the Nitzberg corner/edge detector <ref type="bibr" target="#b19">[20]</ref>. Our choice of this detector and its parameters was determined by statistical evaluation of its performance; see Section 4.1. The output of the detector was the edge map I e (x), the cornerness map C(x), and the image gradient orientation map θ I (x). Figure <ref type="figure" target="#fig_2">6</ref> shows a sample image and its edge map, and Fig. <ref type="figure" target="#fig_3">7</ref> shows another image and its cornerness map. For simplicity, we will use the symbol D to represent the entire edge map, the cornerness map, and the image gradient orientation map jointly, so that D(x) = (I e (x), C(x), θ I (x)).</p><p>Since D(x) depends heavily on the presence or absence of object boundaries in the image, our model accordingly divides the pixel lattice into three classes: the "on" points that are on the hand boundary in the occlusion state 0, the "triple" points that are on the template in the occlusion state 1/2, and the "off" points everywhere else (all points on the hand boundary in the occlusion state 1 and all points off the hand boundary). Each set of points is described by its own imaging model. The imaging model factors over all pixels in the lattice,<ref type="foot" target="#foot_4">4</ref> </p><formula xml:id="formula_11">P(D | s 1 • • • s N ) = all pixels y P(D(y) | s 1 • • • s N ) (<label>7</label></formula><formula xml:id="formula_12">)</formula><p>where</p><formula xml:id="formula_13">P(D(y) | s 1 • • • s N ) is set to P on (D(y) | θ i ), P triple (D(y))</formula><p>, or P off (D(y)). P on is chosen if there exists an i from 1 to N such that y = x i and h i = 0; P triple if there is an i for which y = x i and h i = 1/2; and P off if there is no i for which y = x i , or if there is an i for which y = x i and h i = 1. Note that the classification of points in an input image into "on," "triple," and "off" is specified by the configuration s 1 • • • s N , which is determined by the dynamic programming algorithm described in Section 5.</p><p>We assume the three imaging models factor into separate probabilities on the edge map, the cornerness map, and the image gradient orientation map, P on (D(y) | θ i ) = P e on (I e (y))P c on (C(y))P a on (θ i -θ I (y)),</p><p>P triple (D(y)) = P e triple (I e (y))P c triple (C(y))P a triple (θ i ),</p><p>and</p><formula xml:id="formula_16">P off (D(y)) = P e off (I e (y))P c off (C(y))P a off (θ i ). (<label>10</label></formula><formula xml:id="formula_17">)</formula><p>The probabilities P e on , P c on , P e triple , P c triple , P e off , and P c off were measured using histogramming techniques on a dataset of images (on which hand edges and triple points were selected manually). P a on was modeled as P e on (θ</p><formula xml:id="formula_18">-θ I ) = (1/2)[G(θ I -θ ; σ O ) + G(θ I + π -θ ; σ O )]</formula><p>, reflecting the fact that the orientation estimated from the image gradient usually points towards or 180 • against the true normal direction. Finally, P a triple and P a off were assumed uniform (i.e., an assumption of isotropy).</p><p>There are a large variety of edge and corner detectors to choose from. Our choice of the Nitzberg detector was motivated by the following experimental results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Evaluating Detectors using Chernoff Information</head><p>In this paper, we are concerned with discriminating between edges/corners and nonedges/ noncorners in the image. The task of edge detection is to determine whether the value of a filtered image I φ (x) at a specific point x is more likely caused by an edge or by a nonedge. From our perspective, this task can be formulated in terms of discriminating between two distributions <ref type="bibr" target="#b10">[11]</ref>-the distribution of filter responses when an edge is present, P on (y) = Prob(I φ (x) = y | x is on an edge) and the distribution of responses when there is no edge P off (y) = Prob(I φ (x) = y | x is off an edge).</p><p>The existence of probability distributions P on , P off which can reliably be determined from image data is crucial to the success of our approach. Ideally such distributions would change relatively little between images within similar domains. The justification for P on , P off is based on our statistical analysis of edge detectors on two classes of images: (i) images of hands in indoor scenes (described in this paper) and (ii) images of birds in outdoor scenes (used as a consistency check).</p><p>We considered several types of edge detector operator. It is clearly desirable to use operators whose on-edge and off-edge statistics differ as much as possible. It has been argued <ref type="bibr" target="#b26">[27]</ref> that a suitable measure of difference for such problems is the Chernoff information, which determines the error rates (i.e., rates of false positives and false negatives) in making the optimal statistical decision (using criteria motivated by the Neyman-Pearson lemma) (see <ref type="bibr" target="#b6">[7]</ref>). This is a good measure of difference because it defines the least error rate possible for distinguishing between data from the two distributions using a log-likelihood test with optimal choice of threshold. Moreover, Chernoff information also appeared naturally in our analysis of fundamental bounds and expected time convergence rates of search algorithms described elsewhere <ref type="bibr" target="#b26">[27]</ref>.</p><p>The first edge detector we considered was the modulus of the image gradient-i.e., φ(I (x)) = |∇I (x)|. This was computed at a range of scales obtained by convolving the image with a Gaussian filter before taking the gradient.</p><p>It was then necessary to determine reliable on-edge and off-edge histogram statistics from our images. For off-edge we tried two approaches which gave similar answers. First, we computed histograms over the entire image, reasoning that the vast majority of pixels would be off-edge and so the edges would only weakly contaminate the histograms. Second, we randomly sampled off-edge pixels by clicking with a mouse. Both histograms were very similar. The effect of convolving the image with a Gaussian was, not surprisingly, merely to smooth out the histograms. The P off were then calculated by normalizing the histograms. To determine the on-edge statistics we first had to locate reliable edges in the images. These edges should not be those most visually saliant because this would obviously compromise the statistics. Our technique was to select a long smooth edge of an object in the scene and fit this edge to a parameterized curve such as a spline. We could then gather statistics along the spline. The length and smoothness of the edge meant that we were getting a representative sample of edge strengths (i.e., the modulus gradients were high at some points on the curve but were low at others). In addition, to take into account errors in fitting the spline, we explored the edge strengths in neighbourhoods a few pixels away from the spline and perpendicular to it. Changing the neighbourhood size did not significantly alter our results. We then computed the histograms and calculated the P on as before.</p><p>The results of this process are shown in Fig. <ref type="figure" target="#fig_4">8</ref>. Empirically, the general shapes of the P on , P off and their log likelihood ratios are similar from image to image in datasets of hand images, and similar results have been obtained on bird images.</p><p>We also repeated this process for other edge detectors and rated them based on the Chernoff information of their P on , P off . Of the operators we considered, the one with best Chernoff information was the edge detector devised by Nitzberg.</p><p>In addition, studies of statistics of natural outdoor scenes and underwater images have demonstrated qualitative similarity between the edge and nonedge statistics in these two different domains and have related them to the receptive field properties of the retinas of animals <ref type="bibr" target="#b1">[2]</ref>. Finally, we observe that the work of Zhu and Mumford <ref type="bibr" target="#b28">[29]</ref> demonstrated that the statistics of certain edge detection filters such as first and second derivatives was very similar in form between different images. Since most of the points in images are nonedges these statistics will be dominated by the off-edge terms and so provide additional evidence that the P off are similar between images. More extensive tests on large image databases also confirm the consistency of P on and P off <ref type="bibr" target="#b16">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">DYNAMIC PROGRAMMING WITH PRUNING</head><p>After construction of the prior P(s</p><formula xml:id="formula_19">1 • • • s N ) and imaging model P(D | s 1 • • • s N ), Bayes'</formula><p>theorem may be used to find the a posteriori probability:</p><formula xml:id="formula_20">P(s 1 • • • s N | D) = (P(D | s 1 • • • s N )P(s 1 • • • s N )/P(D)</formula><p>). Fortunately we do not need to undertake the difficult calculation of P(D), since the MAP estimate is equivalent to</p><formula xml:id="formula_21">MAP = argmax s 1 ••• s N N i=1 P on i (s i ) P off (s i ) P(s 1 • • • s N ), (<label>11</label></formula><formula xml:id="formula_22">)</formula><p>where</p><formula xml:id="formula_23">P on i (s i ) denotes P on (D(x i ) | θ i ) if h i = 0, P triple (D(x i )) if h i = 1/2, and P off (D(x i )) if h i = 1.</formula><p>This result assumes all the members of the chain {x 1 , x 2 , . . . , x N } to be distinct (i.e., non-self-intersecting hand contour).</p><p>Since the coupling of the variables s i in the MAP expression is chain-like-s i is directly coupled by the prior only to s i-1 and s i+1 -dynamic programming (DP) may be applied to find the MAP, as long as the s i are quantized to finite sets. The occlusion process variables h i are discrete and the position variables x i are naturally quantized on the image lattice, but it is less clear how to quantize the real variables θ i . Rather than quantize the θ i densely from 0 to 2π and incur an enormous multiplication in the number of nodes to search in each stage of DP, we experimented with various adaptive quantization techniques to select only a small number of θ i 's to consider for each h i and x i . Of the several variations we experimented with, the most successful one selects two θ i candidates for each h i and x i . The first candidate is the angle predicted by the prior at stage i (i.e., argmax(θ i )P(θ i | θ i-1 ), where θ i-1 is the best predecessor of s i chosen by DP); the second is either θ I (x i ) or θ I (x i ) + π, whichever is closer to the θ i predicted by the prior.</p><p>We review the DP procedure briefly and introduce some new notation. DP searches for the best path, i.e., the best sequence of values s 1 , s 2 , . . . , s N (see Fig. <ref type="figure" target="#fig_5">9</ref>), in a stage-bystage procedure. At each stage i the best path to each s i is determined on the basis of previous computations of the best paths to each s i-1 ; by best path we mean the one that maximizes the score f i (s i ) = { i j=1 P on j (s i )/P off (s j )}P(s 1 , s 2 , . . . , s i ). (Note that, although we are describing the procedure in terms of probabilities, we perform the calculations on the computer in terms of sums of log probabilities to avoid the numerical instabilities that occur when many probabilities are multiplied together.) In the final stage, the best s N is determined and the other variables s N -1 , s N -2 , . . . , s 1 are successively recovered.</p><p>We use a linked-list data structure to represent the partial paths in the computer, allowing the computer to allocate memory dynamically at each stage to "grow" only those paths that have survived pruning. This technique saves a considerable amount of memory compared to standard dynamic programming implementations in which memory is allocated for every possible path at the start of the algorithm.</p><p>We also exploit the limited fan-out from one stage to the next: P(s i+1 | s i ) is negligible (or zero) for most pairs s i and s i+1 , and so the spatial component of the DP search can be narrowed. Given s i , only a fairly small region of spatial candidates x i+1 need be considered. This small region of pixels, whose size we denote R, is much smaller than the total number of lattice pixels P, reducing the computational complexity to 2 × 3 × P N × 2 × 2R = 24R P N . We now turn to a discussion of two pruning methods used to speed up the DP algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Relative Pruning</head><p>The addition of a relative pruning technique, inspired by pruning techniques developed in speech processing <ref type="bibr" target="#b14">[15]</ref> and natural language processing <ref type="bibr" target="#b11">[12]</ref>, reduces the running time to as little as 25 s (clocked on a Pentium 150 MHz when the occlusion process is turned off ). In this technique, all scores f i (s i ) at stage i are compared to the top score f * i at this stage, and all s i with scores f i (s i ) &lt; p f * i are eliminated from further consideration ( p = e -10 ). As we will show next, the scores are approximately proportional to partial path probabilities and so we are essentially removing all paths at each stage with probability sufficiently smaller than the most probable path.</p><p>If we make the approximation P(s 1 • • • s N ) ≈ N i=1 P(s i ), then we can calculate the probability of a partial path conditioned on the image data. From Bayes' rule we have</p><formula xml:id="formula_24">P(s 1 • • • s m | D) = s m+1 •••s N P(D | s 1 • • • s N )P(s 1 • • • s N )/P(D)<label>(12)</label></formula><p>and since P(D) and all pixels y P off (D(y)) depend only on D,</p><formula xml:id="formula_25">P(s 1 • • • s m | D) ∝ s m+1 •••s N N i=1 P on i (s i ) P off (s i ) P(s i ) (13) = m i=1 P on i (s i ) P off (s i ) s m+1 ••• s N N i=m+1 P on i (s i ) P off (s i ) P(s i ) (<label>14</label></formula><formula xml:id="formula_26">) ∝ P(s 1 • • • s m ) m i=1 P on i (s i ) P off (s i ) , (<label>15</label></formula><formula xml:id="formula_27">)</formula><formula xml:id="formula_28">since s m+1 •••s N { N i=m+1 P on i (s i ) P off (s i ) P(s i )} is independent of s 1 • • • s m .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Absolute Pruning</head><p>We devised another pruning technique, motivated by the probabilistic bounds on log likelihoods from <ref type="bibr" target="#b26">[27]</ref>, called absolute pruning. This technique prunes a partial path if the image data along it is deemed inconsistent with the partial path being on the true hand. More </p><p>as the log likelihood value from a single data sample (here we are ignoring the cornerness measure C(x) and image gradient orientation θ I (x) and omitting the superscript P e in P e on and P e off ), we can regard L as a random variable which is distributed according to Pon (L) if the sample belongs to an edge along the true hand or according to Poff (L) if not. (Note that the edge strength distributions induce the log likelihood distributions Pon (L) and Poff (L).) Since I e was quantized to produce P on (I e ) and P off (I e ), L can only assume a finite set of values and so Pon (L) and Poff (L) are sums of delta functions, depicted as weighted spikes in Fig. <ref type="figure" target="#fig_6">10</ref>.</p><p>If we sample L repeatedly and independently m times along a path s 1 • • • s m then the sum L m of the L's is also a random variable. To calculate the distribution Pon (L m ) we use the fact that the probability distribution of a sum of two independent random variables equals the probability distribution of one random variable convolved with the probability distribution of the other, i.e., P z (z = x + y) = (P x * P y )| z=x+y . Thus Pon (L m ) equals Pon (L) convolved with itself m times.</p><p>We can calculate Pon (L m ) numerically by representing the function Pon (L) as a discrete sequence of equally spaced samples (all zeros except for a small subset of values representing the delta functions) and convolving the sequence with itself m times to obtain Pon (L m ). Similarly, we can calculate Poff (L m ), which is shown side-by-side with Pon (L m ) in Fig. <ref type="figure" target="#fig_0">11</ref>. Noting that the peaks in Pon (L m ) and Poff (L m ) have little overlap for large enough m, we can devise a method for deciding whether to reject (i.e., prune) or accept a partial path of m segments: reject the partial path if L m &lt; t m and accept it otherwise. Here t m is defined so that</p><formula xml:id="formula_30">Pon (L m &lt; t m ) = t m -∞ d L m Pon (L m ) = , (<label>17</label></formula><formula xml:id="formula_31">)</formula><p>where is a small failure rate equal to the probability that the correct path has L m &lt; t m . We experimented with absolute pruning with the occlusion process switched off and found that it pruned paths successfully but much more conservatively than the relative FIG. <ref type="figure" target="#fig_0">14</ref>. Examples of occlusions. In these figures, the occlusion state at each point is designated as follows: a "+" means state 0 (i.e., unoccluded), a "λ" means state 1/2 (triple point), and a circle means state 1 (occluded). and so forth for all M hands. In other words, the M hands may be detected by finding the top M nonoverlapping DP paths. Note that, in the absence of pruning, finding the top M hands takes no additional time compared to finding the top hand alone, since the complexity scales with the number of pixels in the image, not M. (Of course, if pruning is used then the complexity will increase somewhat with M.)</p><p>To implement this, we run our standard dynamic programming algorithm to recover the top-scoring path as the first hand. Then we find the next best-scoring path whose pixel locations come no closer than d = 3 pixel units of any of the pixels {x 1  1 , x 1 2 , . . . x 1 N }. The third hand is the next best-scoring path after the second whose pixel locations {x 2 1 , x 2 2 , . . . x 2 N } come no closer than d pixels of any member of the set {x 1  1 , x 1 2 , . . . x 1 N , x 2 1 , x 2 2 , . . . x 2 N }, and similarly for more hands (see Fig. <ref type="figure" target="#fig_7">15</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">RESULTS</head><p>Two prototype shapes q1 , q2 , . . . , qN were used, one constructed with N = 83 (for speed) and the other with N = 101 (for reliability). σ a,i was set to 0.03 (radians), and at the hinge points we set δ j = 0.5. The values σ t,i and σ n,i were scaled in proportion to the scale of the prototype and will not be quoted here; their values were also increased at hinge points and the ratio σ n,i /σ t,i was fixed at 2.3. The orientation map standard deviation σ O was set to 0.1. The prototype was rescaled manually to match the scale of each input image.</p><p>Our template has been tested on a variety of grayscale images, some of which are shown in Fig. <ref type="figure" target="#fig_0">12</ref>. To reduce computational complexity, all calculations were performed on a decimated lattice (decimated by a factor of 4 in both dimensions) derived from the edge, corner and orientation maps computed on the original image lattice. Figure <ref type="figure" target="#fig_0">13</ref> demonstrates the ability of the algorithm to cope with hinge deformation.</p><p>When the occlusion process was enabled, the algorithm was able to handle severe occlusions, as demonstrated in Fig. <ref type="figure" target="#fig_0">14</ref>. In these figures, the occlusion state at each point is designated as follows: a "+" means state 0, a "λ" means state 1/2, and a circle means state 1. We are able to detect multiple hands in a single image by finding the top few nonoverlapping DP paths, as shown in Fig. <ref type="figure" target="#fig_7">15</ref> (with a run time of about 2 min on a Pentium 150 MHz).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">CONCLUSION</head><p>We have described a promising algorithm for detecting flexible objects in real images. The algorithm can handle substantial hinge deformations, occlusions and the presence of multiple hands.</p><p>It is desirable to speed up the algorithm further and to deal with certain limitations of the model. In particular, the first-order Markov geometric prior seems to be the weakest component of the Bayesian model. The local interactions of the prior are insufficient to prevent such problems as self-intersection and unrealistic deformations. These local interactions mean that points that are spatially close together, e.g., two points near the same knuckle on opposite sides of a finger, may be separated by many points on the Markov chain and have no direct influence on each other. Also, the current approach is only able to deal with limited scale variations. We anticipate that more sophisticated representations involving symmetry axes <ref type="bibr" target="#b17">[18]</ref> and key features will help solve both problems. Learning the prior systematically (and not merely relying on stochastic sampling experiments), as was done for the imaging model, will improve the reliability of the model. In addition, there are many other pruning techniques which we have not yet explored which offer more principled ways to speed up the algorithm <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b25">26]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIG. 1 .</head><label>1</label><figDesc>FIG. 1. Sample configuration points x 1 , x 2 , . . . , x N with arrows showing normal orientations θ 1 , θ 2 , . . . , θ N on thumb.</figDesc><graphic coords="3,79.05,48.37,235.92,184.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FIG. 5 .</head><label>5</label><figDesc>FIG. 5. Transition probabilities among states 0, 1/2, and 1.</figDesc><graphic coords="6,40.40,48.05,312.24,77.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FIG. 6 .</head><label>6</label><figDesc>FIG. 6. Original image on left, edge map on right.</figDesc><graphic coords="7,22.55,48.25,348.96,130.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FIG. 7 .</head><label>7</label><figDesc>FIG. 7. Original image on left, corner map on right.</figDesc><graphic coords="8,21.90,47.97,349.44,129.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>FIG. 8 .</head><label>8</label><figDesc>FIG. 8.On-edge probabilities P on-edge (left), off-edge probabilities P off-edge (center), and log likelihood ratios log (P on-edge /P on-edge ) (right). Each row represents results from a different edge filter. Top: Nitzberg filter, Chernoff information = 0.3541. Middle: magnitude of the image gradient (after smoothing with a Gaussian of σ = 2), Chernoff information = 0.2504. Bottom: magnitude of the image gradient (after smoothing with a Gaussian of σ = 4), Chernoff information = 0.0877. The horizontal axis is the bin number (1-40).</figDesc><graphic coords="9,19.55,47.93,354.72,272.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>FIG. 9 .</head><label>9</label><figDesc>FIG. 9. Schematic of DP algorithm showing limited fan-out from one stage to the next.</figDesc><graphic coords="10,114.40,578.06,164.40,56.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>FIG. 10 .</head><label>10</label><figDesc>FIG. 10. Pon (L) on left and Poff (L) on right.</figDesc><graphic coords="12,21.90,47.85,348.96,141.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>FIG. 15 .</head><label>15</label><figDesc>FIG.15. Two hands in one image.</figDesc><graphic coords="15,49.05,417.50,296.16,216.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="4,68.40,410.22,256.32,202.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="5,68.05,48.17,258.00,203.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="13,24.05,47.89,346.56,286.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="14,20.90,48.81,350.88,188.64" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>To whom correspondence should be addressed c/o Smith-Kettlewell Eye Research Institute,</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2318" xml:id="foot_1"><p>Fillmore St., San Francisco, CA 94115. Fax: 415-345-8455. E-mail: coughlan@ski.org.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>The argument of the Gaussian is to be evaluated modulo 2π since it is an angle. As a result, the standard normalization factor (1/ √ 2πσ ) is only approximately correct.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>Since x i+1 is quantized on a lattice, the normalization of the Gaussians will again differ from their standard form.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>Since the value of D(x) at each point x is derived from image intensities I (x ) in a neighborhood of x, the independence of D(x) from point to point is only an approximation.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We would like to thank Joshua Goodman, Richard Szeliski and Guy-Adrien Mounier for their useful comments and suggestions. Support was provided by NSF Grant IRI 92-23676 and the Center for Imaging Science Grant ARO DAAH049510494.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>pruning technique over a range of failure rates ( = 10 -4 , 10 -3 , 10 -2 ). The main reason for this conservative behavior lies in the limitation of the geometric prior, which should be included in the absolute pruning criterion but is too weak to prevent multiple DP paths from being geometrically distorted so as to cling to true edges. Thus many false paths have a disproportionate number of points along true edges, and their log likelihood evidence is comparable to that of the true path, making it difficult to prune these false paths. Even if the prior were strengthened, however, one limitation would remain: although the Pon (L m ) and Poff (L m ) distributions are quite distinct, many L m values reflect paths which are partially on and partially off the true hand, and it is unclear how to estimate the probability that the pruning rule fails to reject partially on/partially off paths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">MULTIPLE HANDS IN A SINGLE IMAGE</head><p>We will set up a model for M nonoverlapping hands in a single image, and show that the previous model for a single hand can be adapted with slight modification to find the MAP multiple-hand estimate.</p><p>The prior for M independent, nonoverlapping hands (s</p><p>, where µ labels different hands µ = 1, 2, . . . , M, is where P(s</p><p>is the single-hand prior from before. Similarly, the imaging model for M independent, nonoverlapping hands is modified only slightly from the single-hand imaging model:</p><p>Therefore, assuming all N M pixel locations {x µ i } are distinct (i.e., no overlap between hands and no self-intersection within hands) we get the MAP multiple-hand estimate</p><p>Because the multiple-hand MAP estimate factors into M independent pieces, the M hands may be recovered using the single-hand model as follows. The first hand is the MAP estimate according to the single-hand model, i.e., argmax {s i } P(s  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Graphical Templates for Image Matching</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Amit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kong</surname></persName>
		</author>
		<idno>373</idno>
		<imprint>
			<date type="published" when="1993-08">August 1993</date>
		</imprint>
		<respStmt>
			<orgName>Department of Statistics, University of Chicago</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">R</forename><surname>Balboa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>University of Allicante</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automatic finding of main Roads in aerial images by using geometricstochastic models and estimation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Barzohar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="459" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Bellman</surname></persName>
		</author>
		<title level="m">Applied Dynamic Programming</title>
		<meeting><address><addrLine>Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton Univ. Press</publisher>
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Active shape models-&quot;Smart snakes</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<meeting><address><addrLine>Leeds</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992-09">September 1992</date>
			<biblScope unit="page" from="266" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Global Optimization of a Deformable Hand Template Using Dynamic Programming</title>
		<author>
			<persName><forename type="first">J</forename><surname>Coughlan</surname></persName>
		</author>
		<idno>95-1</idno>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>Harvard Robotics Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<title level="m">Elements of Information Theory</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley-Interscience</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The representation and matching of pictorial structures</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Fischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Erschlager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput. C</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dynamic programming for detecting, tracking, and matching deformable contours</title>
		<author>
			<persName><forename type="first">D</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vlontzos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Visual deconstruction: Recognizing articulated objects</title>
		<author>
			<persName><forename type="first">D</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings EMMCVPR &apos;97</title>
		<meeting>EMMCVPR &apos;97<address><addrLine>Venice</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An active testing model for tracking roads in satellite images</title>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jedynak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Patt. Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Global thresholding and multiple-pass parsing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Second Conference on Empirical Methods in Natural Language Processing<address><addrLine>Providence</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="11" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Hands: A Pattern Theoretic Study of Biological Shapes</title>
		<author>
			<persName><forename type="first">U</forename><surname>Grenander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Keenan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin/New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A combined corner and edge detector</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Stephens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Alvey Vision Conference</title>
		<meeting>3rd Alvey Vision Conference</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="147" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Jelinek</surname></persName>
		</author>
		<title level="m">Statistical Methods for Speech Recognition</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Gray-Level Corner Detection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kitchen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
		<idno>TR-887</idno>
		<imprint>
			<date type="published" when="1980">1980</date>
			<pubPlace>College Park</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Science Center, University of Maryland</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">S</forename><surname>Konishi</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>in progress</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Segmenting by seeking the symmetry axis</title>
		<author>
			<persName><forename type="first">T.-L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the 14th International Conference on Pattern Recognition</title>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On the optimal detection of curves in noisy pictures</title>
		<author>
			<persName><forename type="first">U</forename><surname>Montanari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. ACM</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="335" to="345" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Nitzberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shiota</surname></persName>
		</author>
		<title level="m">Filtering, Segmentation and Depth</title>
		<meeting><address><addrLine>Berlin/New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Heuristics: Intelligent Search Stategies for Computer Problem Solving</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Classification and clustering in spatial and image data</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Ripley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Analyzing and Modeling Data and Knowledge</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Schader</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Parametrically deformable contour models</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Straib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Duncan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Computer Vision and Pattern Recognition</title>
		<meeting>Computer Vision and Pattern Recognition<address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="98" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A neural system for the recognition of partially occluded objects in cluttered scenes</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wiscott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Der Marlsburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="935" to="948" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deformable templates for face recognition</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cognitive Neurosci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="70" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Twenty questions, focus of attention, and A * : A theoretical comparison of optimization strategies</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Coughlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings EMMCVPR &apos;97</title>
		<meeting>EMMCVPR &apos;97<address><addrLine>Venice</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Visual search: Fundamental bounds, order parameters, and phase transitions</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Coughlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Minimax entropy principle and its application to texture modeling</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Prior learning and Gibbs reaction-diffusion</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1236" to="1250" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
