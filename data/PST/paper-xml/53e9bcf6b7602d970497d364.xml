<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Connection Machine e Lisv: Pine-Grained Parallel Symbolic Processing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Guy</forename><forename type="middle">L W Daniel</forename><surname>Steele</surname><genName>Jr</genName></persName>
							<affiliation key="aff0">
								<orgName type="department">Thinking Machines Corporation 245 First Street Cambridge</orgName>
								<address>
									<postCode>02142</postCode>
									<region>Massachusetts</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Hillis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Thinking Machines Corporation 245 First Street Cambridge</orgName>
								<address>
									<postCode>02142</postCode>
									<region>Massachusetts</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Connection Machine e Lisv: Pine-Grained Parallel Symbolic Processing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5FC185DC3696B29BBD111F5C899B52A7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Connection Machine Lisp is a dialect of Lisp extended to allow a fine.grained, data-oriented style of parallel execution. We introduce a new data structure, the xapping, that is like a sparse array whose elements can be processed in parallel. This kind of processing is suitable for implementation by such fine.grained parallel computers as the Connection Machine System and NON-VON.</p><p>Additional program notation is introduced to indicate various parallel operations. The symbols st and • are used, in a manner syntactically reminiscent of the backquote notation used in Common Lisp, to indicate what parts of an expression are to be executed in parallel. Ths symbol fl is used to indicate permutation and reduction of sets of data.</p><p>Connection Machine Lisp in practice leans heavily on APL and FP and their descendants. Many ideas and stylistic idioms can be carried over directly. Some idioms of Connection Machine Lisp are difficult to render in APL because Connection Machine Lisp xappings may be sparse while APL vectors are not sparse. We give many small examples of programming in Connection Machine Lisp.</p><p>Two met•circular interpreters for a subset of Connection Machine Lisp are presented. One is concise but suffers from defining a in terms of itself in such a way as to obscure its essential properties. The other is longer but facilitates presentation of these properties.</p><p>1 Introduction Connection Machine Lisp is intended for symbolic computing ap. plications that are amenable to a primarily fine-grained, dataoriented style of parallel solution. While the language wu invented with the architecture and capabilities of the Connection Machine System [11] in mind, its design is relatively hardware-</p><p>Permission to copy without fee eLl or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the floe of the publication and its date appear, and notice is given that copying it by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specfic permits/on. © 1986 ACM 0-89791-200-4/86/0800-0279 75¢ 279 independent, and may be suitable for implementation on other parallel computer,, such u NON- VON [22]  or the NYU Ultra. computer <ref type="bibr" target="#b20">[21]</ref>, as wen as mquonthd machines.</p><p>Connection Machine Lisp ~egins with a standard dialect of Lisp, and then adds a new data type (the zapping) and some additional progrua syntax for expressing parallelism. (We use Common Lisp [25] as our base language, but Scheme [~,27,S,2] would be an attraotive alteruativ~) The resulting Jangua~e is much like APL [13,<ref type="bibr" target="#b11">12,</ref>8,<ref type="bibr" target="#b3">4]</ref>, but with richer data structures; much like FP [1], but with variables and side effects; somewhat like KRC [29], in that one poRible semantic~ for Connection Machine Lisp includes luy data structures; but rather unlike QLAMBDA</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr" target="#b4">[5]</ref> <p>or Multiikp <ref type="bibr">[10]</ref>, which introduc, paraliclkm via control,true.</p><p>tures rather than data structure, (although it may be pomlble to copy certain good idea, from those languages into Connection Machine Lisp without ill effect).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Xapplng Data Type</head><p>All parallelism in Connection Machine Lisp is organized around a data structure called a zapping (rhymes with "mapping'). A xspping is something like an array and something like a hash tahie, but all the entriet of• xapping cus be operated on in parallel, for example to perform amociative searching. This data *tructure by itself is not a particularly original idea; the innovation in Connection Machine Lisp lies in the program notation used in conjunction with it.</p><p>To be precite, 8 xapping is an unordered set of ordered pairs. The first item of each pale is called an/ndez, and the second item is called a value. We write a pair u/ndec--*~alvs. An index or value may be any Lisp object. A xapping cannot contain two distinct pairs whine indices are the Irene; all the indices in a xapping are distinct (but the values need not be distinct). There is a question of what is meant by %sme~; for now assume that the Common Lisp function sql determines sameness.</p><p>Here is an example of a xspping that maps symbols to other symbok: {sky-*blue apple--,red srana-~srean)</p><p>The ~me xapping could have been written in this manner: {apple--,red sky-*blue ~ans-'..~Krsen}</p><p>The order in which the pair, are written makes no difference.</p><p>To Ipeak in term• of implementation on a parallel computer, one may think of an index as • label for a procemmr, and tht,k of the corresponding value as being stored in the local memory of that processor. The index might or might not be stored explio-itly also. The xapping shown above might be represented, for example, by storing pointem to the symbols apple and red in proceseor 6, !k"Y and blue in processor 7, and Kraal and green in processor 8. Additional header information indicating that the xapping is stored in three processore beginning with processor 6 must also be stored eomewhere. The ingenious reader can no doubt invent many other repreeentatious for xappinge suitable for particular purpoeee. In any case, it is well to think of indices as labelling al~tract processors, and to think of two values in two xappinge, a! beins stored in the same processor if they have the asme index, Semantically a xapping really is like an array or hash table, where the indiem maw be any Lkp object*. A xapping may be accessed by index to obtain a value:</p><p>(xre:[ "{aky--*bluo apple--*red graee-*green) "apple) =~ red</p><p>(Following <ref type="bibr" target="#b22">[23]</ref>, we use the symbol =~ to mean "evaluates to.') Sometimm the index und the value of a pair are the asrae (that is,.eql). As a convenient abbreviation, each a pair may be written within xapping-notation as just the value, without the index or the seperzting arrow. For example, {appla---.£X'u.t t color--*almtract$on abatractio~abstractiou) could be abbrevint4d to {apple-~ru2t color-*abetractlou abstractLon) This is most ccavenient in the cue where e/! the pairs may be so abbreviated: {red blue g~ten yellow beige uuve} meaue the enme ,., {red--~red blue-*blue Kreen---~Kreea yellov-*yellow betge--.betKr sauve--*aauve} but is cons/derably shorter. If all the elements of a xappin8 can be abbreviated in thk manner, then the xapping is called a set (rhymes with "set').</p><p>If a finite xapping has • set of indices that are consecutive nonnagative integem beginning with zero, then the xapping may be abbreviated by writing the values in order according to their indices, separated by whitespece as n~ and surrounded by bracket~ For example, the notation [red green blue] is merely an abbreviation for (O--*red 1--*Kreen 2-*blue}. A xapping that can be abbreviated in this manner is called a zector (rhymes with "vector'). The use of xectors in Connection Machine Lisp is similar to the use of vectors in APL.</p><p>One can have a theory of lists (or arrays) that can speak of both finite and inRnite llate and then use this theory to explain a language implementation that supports only finite lists. One might aim implement a very similar language that supports apparently infinite lkts by means such special reprmentation-as lazy lists or lists all of whme elements are the mane. In the same manner, we have a theory that epeake of infinite xappingm. For the next few sections we speak as if infinite xappinge renliy are supported. In section 6 we address the semantic and implementstion difficulties that can ~ when eupporting infinite xappinge and various trade-offs that can be made.</p><p>It is desirable to introduce three different kinds of infinite xappinge.</p><p>• A eon,tont xapping has the same value for every index.</p><p>A constant xapping with value e is written as (--,v). For example, the xapping (--.6) has the value 5 for every index. Constant xappingm are important to the implicit mapping (apply.to-all) notation discussed below in section 3.</p><p>• A ani~ermal xapp'mg, written (--.), is the xet of all objects; that is, for every Lisp object there is a ~ with that object as both index and value. There is an important operation in the ianguage, called doaaln, that takes a xapping and returns a xet of its indices; given that constant xappinge exist, universal xappinge are needed so that the domain operation can be tot~.</p><p>• A/a~ xapping uses a unary Lisp function to compute a value given an index. For example, the xapping ( . sqrt} mape every number to its square root. (No~e the dot that is part of the notation.) Lazy xappinge are a means of dealing with the mapping of arbitrary functions over infinite xzppinp.</p><p>Any of the three types of infinite xapping may have a finite number of explicit exceptione, where for a given index there is an explicitly repreeented value. The "infinite part" is conventionally written after all of the explicit pairs. For example, the lazy xapping {pI-*1.7724S386I e-+1.8487212 "1-~1 . 8qzt) is generally defined by the aqrt function but has explicit values for three particular indices.</p><p>3 Notation for Implicit Apply-to-All Paralklism is introduced into Connection Ma~ine Lisp primarily by having a way to apply a function to all the elements of+ a xappin t at once. This notion is not new; indeed, we.were inspired by the %pply.to.all" operator a of FP <ref type="bibr" target="#b0">[1]</ref>. The apply-to-all operntor takes a function [ and produces ... momethiag ... that, when applied to a sequence, appliee jr to all the elements of the sequence and yields a sequence of the results: FP is purely applicative, and so the question of order of upplication is irrelevant. In Connection Machine Lisp, which is not purely applicative, we must addrem thl-qumtion, and we also specify more preci~ly what is that JomeffdnO that apply. to-all produ~. We begin by treating "it as a simple operator (or rather a read.macro character fronting for an operator, much as "'" fronts for quote), but are led to regard it as a complex syntactic device rather than a pure functional.</p><p>The expression az, where z is a variable or COherent, con. structe a constant xappin 8 with the value of ~ For exmnple, aS =~ {-+6); this is % zimon fives, m loo~y speaking. 1 Sial. larly, the exprlsion aeqrt produc~ % zillion square-root functious." Putting it back into pseudo-FP syntax, it is as ff o.l -(l,l,l,...)</p><p>tThat'e "siillen~ not ~dllon."</p><p>We then make the rule that when a xapping is applied as a function, all of the arguments must also be xapplngs, and the xapping being applied must have functions as its elements (these elements may thenmelvee be xappings). An implicit apply-to-all operation (Ipacifically, apply-to-all of funcall) occurs: function elements and argument elements are matched up according to their indices. The result is a xapping that has a pair for every index appearing in the function xapping and all argument xappinge. Put another way, the result is defined for all indices for which the function and argument xappings are defined. In yet other words: the domain of the result is the intersection of the domains of the function and argument xappings.</p><p>Enongh! Time for an example! Note that the value of ~coms, namely {--* (cons function)} (again speaking rather loosely), is defined for all indices, and so does not restrict the domain of the result; the function is defined at whatever index it may be needed. On the other hand, the domains of the two arguments are both finite, and their intersection determines the domain of the result.</p><p>Operationally, this function can implicitly sets up the following calls to cons:</p><formula xml:id="formula_0">(cons 2 e) (cona 4 7) (cons 6 O)</formula><p>These calls are executed in parallel (perhaps asynchronoully~ see section 6). Resynchronization occurs, at latest, when all of the parallel computations have completed and the result rapping is to be constructed. Note that argument forms are not necessarily evaluated in parallel (as in the l~all construct of Multilisp [10]); that is an orthogonal notion. The parallel evaluation of arguments forms is a parallelism in eval (or more precisely in evlis). The parallelism in Connection Machine Lisp is a parallelism made manifest in apply. (This distinction is further discussed below in section</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.)</head><p>Consider now two forms: (~+ a2 c~3) and a(+ 2 3). The first evaluates the function and argument forms to produce {--*+}, {--~2}, and {--.3}. The first is then applied to the other two. All three are defined for all indices, and so an infinite number of calls to + are set up, all of the form (+ 2 3). (Kindly ignore for now the pragmatic and semantic difllculties of actually performing an infinite number of function calls, especially in a language with side effects. We will return to these difficulties in section 6.) All of these calls produce the result 6, and so the result is {--*6}. As for ~,(+ 2 3), we have not yet defined what ~." does when written before an arbitrary form such as (in this case) a function call, but it is tempting to define it simply to evaluate the form and then produce a constant xapping with the resulting value. If we adopt this definition, then a(+ 2 3) also produces {-*6}, and in fact we have an important syntactic property: %," distributes over function calls.</p><p>Suppose that we want to add 32 to every element of a xapping c; we may write (c~+ c a32). Now suppose instead that we wish to multiply each element of c by 9/6 before adding 32; we write (c~+ (cz* c cz9/5) c~32). Or perhaps we really want a xapping of 2-lists pairing each such computed value with the original element of c : (~ltst c (c~÷ (c~* c c~9/6) c~32)). As we construct ever more complicated expressions to be executed independently and in parallel, we find ever more apply-to-all op-erators creeping in. The distribution rule can be used to "factor out" these operators if euerlr subform of it function call has a preceding ~, but that is not the case here. We solve this problem by introducing %" as an "inveme ~ to "a': by definition, a.z =-z. We can then alwitye apply the distribution law by introducing occurrences of "a." first. To continue our example, we begin with the expression (allat c (a* (a* c a9/6) a32)) and make successive transformations: and derive the result a(ltat .c (+ (* .c 9/6) g2)).</p><p>We have ended up with a notation for fine-grained parallism that is similar to the familiar Common Lisp backquote notation. One may thi~k of a bacJcquote am meaning "make a copy of the following data structure" and of a comma as meaning "except don't copy the following expreuion, but instead use its value." Likewise think of "a" as meaning "perform many copies of the following code in parallel" and of %" as meaning "except don't do the following expre~ion in parallel, but use elements of its value (which must be a xapping)."</p><p>The template that followl a hackquote indicates part, of the constructed data ,tructure that s~e the mmae in all instances constructed by the backquoted expreuion, and comn~ indicate values that can vary from instance to instance (in time). Similarly, the template that follows an a indicat~ parts of the computation that are the same in all the parallel computations, and each • indicates a value that can vary from instance to instance (in</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>sp~).</head><p>This notation is powerful because it allow| two simultaneous points of view (us with a Necker cube). On the one hand, it can be understood as a computation with a single thread of control, operating on arrays of data. This allows one to have a global understanding of how the data is transformed, as in FP or APL. On the other hand, it can be undellflmod as an array of pro. ceases, with each procem executing the same code that follows the us" and with %" finning data values that may differ among processes. This allows one to take n piece of code written for a single processor and trivially change it to operate on a proccmmr array by annotating it with an" and %" in a few place. Thus the notation eimultaneoudy supports both macroscopic and mio croseopic views of a parallel computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Other Useful Operations</head><p>In this section we diecu~ various operations on xappinge, some primitive (for the purposes of this paper) and some derived. A number of programming examples are presented. Many of the examples are reminiscent of APL programming style; we point out important similarities and differences along the way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Common Lisp Sequence Functions</head><p>Xapplngs are just another kind of sequence (in the Common Lisp sense). Connection Machine Lisp extends the meaning of ninny Common Lisp functions to operate on xappings. For example, the length function will return the number of pairs in a finite xapping. Many important operations on xappings, such am selection, filtering, and sorting, may be performed using ordinary Common Lisp sequence functions: Many of these functions, such as subse( b depend on the argument sequencee to be ordered, aad so are eensible only if applied to a xector. Some'of the functions will still work if applied to any other kind of xapping, and will operate by first implicitly ordering the xappin~ (indeed, the explicit purpose of sort is to order a sequencel). Yet other operations do not require an argument to be ordered, and never implicitly order the xapping; remove-ifnot is an example of this. For other functions it is considered an error for a yappin~ argument not to he a xector. (Unfortunately, it appeals to be necemary to determine case by cam which of these is the moot useful behavior.  Using xunion we can define some composition operations (whose names are taken from <ref type="bibr" target="#b17">[18]</ref>, where the operationa are used to compose images):</p><p>(defun over (a b) (xunlon #' (laabda (x y) x) a b))</p><formula xml:id="formula_1">(de~un in (a b) (a(lunbda (x y) x) a b)) (defUn atop (a b) (in (over a b) b))</formula><p>The result of (over x y) is the union of x and y, as if they were both laid on a table with x over y, so that where x and y are both ddned the element from x is always taken. The result is not printed as a xector because there ;-no element with index 6. The result of (in x y) is the intersection of x and y, with values taken from x; that is, the domain of y serves as a mask on the domzin of x. The result of (atop x y) has the same domain as y, but the values are taken from x for indices that appear in x, and otherwise from y: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Reduction and Combining</head><p>The ~ syntax can he used, ;-effect, to replicate or broadcast data (constants and ~duee of variable,) and to operate in parallel on data (by applying a xapping of functions). Another syntax, using the "~' character, is used to exprem the gathering vp d parallel data to produce a single result, and to express the permuting and mul~pk~result comblnlnS of psrsll~ data. For gathering up, the expression (~I z) takes a binary function/.and a xapping z and returns the result of combining all the values of z using f, a process sometimes cared redaction of a vector? (This operation is written as flz in FP and APL.)</p><p>As an example, (fl+ foe) produces the sum of all the vshes in too, and (~mt.x too) returns the largest value in too. Note that in this case the indices associated with the values do not affect the result. Any binary combining function may be umd, but the result is unpredictable if the function is not associative and commutative, because the manner in which the values are combined is not predictable. For example, (fit ' (1 2 3}) might compute (f 1 (f 2 3)) or (t (t I 2) 3) or (f (t 3 1) 2) or any other method of arranging the values into a binary computation tree. (If the argument xapping is a xector, then the result is predictable up to associativity: the combining function need not be commutative, but should be associative.) Note that in APL and FP the order in which elements are combined is completely predictable. We eliminate predictability in Connection Machine Lisp for two reasons: first, the domain may be unordered; second, we wish to perform reductions in logarithmic time rather than linear time by using multiple processors.</p><p>Sometimes this unpredictability doesn't matter even though the function is not associative or commutative: the expression (fl(lambda (x y) y) too) is a standard way to choose n single value from foe without knowing any of the indices of ~oo. This operation, though not ]ngical]y primitive, is so useful that it has a standard name choice:</p><formula xml:id="formula_2">(defun choice (xappln&amp;) (~(lanbda (x y) y) rapping))</formula><p>Note that the combining function (lambda (x y) y) is not commutative. However, also note that executing the same expression twice might result in choosing the same element twice or two different elements. The choice is arbitrary; it might or might not be random. The expression (choice 'a b) n~ht return a the first ten million times it is executed and then might return b thereafter. Or it n~ht always return a. If a matrix is represented as a xector of row-xectore~ then we can perform reduction over rows or over columns by using ~ and o~ together: 2We use the character8 -%., a, and ~ knowing full well that a portable implementation cannot use them (although a nonportable lmplemextatlon on the Symbolics 3600 does use them). We have experimented with using Jt Jt ?J and $, respectively, to replace them (thereby burdening ajn with two purposes), but we find thk a~thetically displeasing, and h&amp;ve found no better alternative that is portable. We wlU eventually have to find another Syntax, not only for masons of portability, but because of u Ldditlonal, unanticipated problem with the use of "~': users have taken to roferring to the process of computing the sum (or maximum, or whatever) over a xapping as %et&amp;-reductiun" of the npplng~but that term al~ly ha8 a very different and long-~tablkhed m~nin~ within the Lisp communltyl For every distinct value g in d there will be a pair g--.s in the result. If that value q occurs in moss than one pair of d, then e is the result of combining all of the corresponding values from z. As an example, (~÷ '{grsas-*green sky-.blue banana--*yellow applo-.red tonato-~red sgg-*wh/to } • {grass--*1 sky--~2 bnnana-,3 appls--~4 tomato--,6 aango--~6} =~ (green--,1 blns--.2 yellow--,3 r6d--.O)</p><formula xml:id="formula_3">((~j3+ '[[1 2 3]</formula><p>The pair red--.9 appears be~u~ the values 4 from apple and 5 from tomato were summed by the combining function +. The result has no pair with index white or value 6 because neither egg nor mmgo appeared a8 an index in 6oth operand rappings.</p><p>Histogramming is n useful application of this more general form of t; many sums must be computed by counting I for each contributor:</p><formula xml:id="formula_4">(detnn ~tstogran (x) (D+ x '{-~1))) (hlstogran '[a b a c • f b c d :t • b a b g d e d el)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>=~ (A--*4 B--.4 C--~2 D--,S E--.$ Y--*2 G--*I)</head><p>This version of the p-syntax may be understood operationally u a very general kind of interpret communication. If we think of a fine-gralned multipr~r where a processor is assigned to every element of a xapping, then the index of a rapping pair is a processor label. If for some p there i8 a pair p--,f in d and a pair F'-,r in z, it mesas that the processor labeled p has a datum r and a pointer to another processor q. The ~]operation sends the datum r to processor q. Of course, many such ruessages may be sent in parallel; the combining function )' is used to resolve any message collisions at each destination. (This idea of a combining function that resolves collisions recurs in many places throughout the language, almost everywhere paralhl data movement is involved. Recall, for example, the function xnnlon presented above in section 4.2.)</p><p>Note the fo}lowing similarity between the two forms of~ syntax: (~[z) =~ v if und only if (pl '(-,g} s) =~ {V-.v}. Operationally speaking, (~ ' {--*q) s) causes all the values of z to be sent to processor q and combined there, whereas (~[ z) causes all the values of z to be ecnt to the hoes (or to a neutral corner, if you please) and combined there. It is this relationship that prompted us to use/9 for both p~.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Other Functional Operation8</head><p>Early in the development of Connection Machine Lkp there was a raft of other functional operators a8 well, which commmed a fair portion of the Greek alphabet. We have found that aoZ' and ~' along with the donln, snumratah xunlon and a very few other functions seem to constitute a comfortable set of primitives from which many other parallel operations are easily constructed. This is of cottree slmi|~t to the experience of the APL community, except that we have settled on a different set of primitives.</p><p>Consider for example the function order that takes say rapping and iraposes an ordering on it8 values (thereby producing an equivalent xector):</p><p>(defun order (x) (~O (enumerate x) x)) (The binary function @ merely signals un error when it is called:</p><p>(defun e (&amp;rest x) (error ~Conbi~ing :~unction erroneously called " "@[ on argument llst "S']" x))</p><p>It is c0nventiunally used to indicate that collkions should not occur.) Compa~ order, which produces an arbitrary ordering (that is, an ordering •t the discretion of the implementation) to sort, which imposes an m~ledng according to u umr-specified bin~v/oniering prodicate.</p><p>A usdul opm~tion defined in terms sip is transport, which tu~ • unary Lisp function to compute new indices from old ones:</p><formula xml:id="formula_5">(do:fun transport (:f • x) (pfaC¢ .(detain x)) x))</formula><p>(Aotua~y, thk definition is not correct. To render transport into legitimate Common Lisp syntax, we must first explain that (~[ 4[ S) E (coublll# it'/er s), and then write</p><formula xml:id="formula_6">(de:fun transport (:f g x) (combine :f a(funcall g ,(donain x)) x))</formula><p>Similarly, (~f z) --(rsduce it'/s). The fact that Common Lisp, like most Lisp dialects, has ecpar*te function and vsrisble a~ makes the use of functional arguments awkward. All remaining code in this paper adheres to Common Lisp syntax.)</p><p>Here *re some examples of the use of transport.</p><p>(do:fun double (x) (+ x x)) In this exsmp|e, every element in [123466] is trmported to an index equul to half (rounded down) of it, original index. The net effect is to combine adjacent pairs. This effect is rather more difBcult to achieve in standard APL.</p><formula xml:id="formula_7">(transport it'S in'double '[a b c d]) = {O--,u<label>2</label></formula><p>(do:fun rota~, (x J) (transport it'@ it'(lubdo (!0 (nod</p><formula xml:id="formula_8">(-k J) (length x))) x)) (do:fun nh/:ft (x J) (transport it's it'(lanbda (i0 (-k 1)) x)) (rotate "It bc de :f] 2) =~ [c do :f a b] (sh/ft '(a b c d • :f] 2) {-2--.a -l--,b O-,c l--~d 2--,e 3"':f}</formula><p>APL provides an function ~ equ/valent in effect to rotate, but ha, nothing quite like sh/:ft, which can renumber the indices of a vector so as to begin at any origin, even n negative origin. Such shifted vectors are handy on occesion, as in the definition of 8can presented further below. Note that [0 1 2 3 4 5 6 7 8 O| is the same data structure u{ox2s4567eg).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Examples Using Matrices</head><p>We t~ke ~ primit/ve the transpose opemtim~, H x is n rapping whores values are all x~ppinp, then {transpose x) Js also a xsppins who** values are xsppinss, and (transpose x) contains s pair p-*y when xspping IP commius n pair q--,r just in ¢~q x contains &amp; pair ¢--,z where xspping z contains a pair p--,v. To put it another way, (xrsf (xro:f (~r---pose s) i) k) = (xrs:f (xrs:f s k) i) for all j and k, and if one side of the equivalence is undefined then so is the other side. Note also that (transpose (transpose x)) --x as one mlght expect.</p><p>Examples ot using transpose:</p><formula xml:id="formula_9">(transpose '[[i 2 3] [4 s el]) = [(x 4)<label>(26)</label></formula><p>[s e)) The support of sparse arrays is one of the strengths and conveniences of the xapping data structure.</p><formula xml:id="formula_10">(transpose '[(012 3] [46e) [78) (9))) ~ [[o47 o) (1 as) (<label>2</label></formula><p>The function inner-product takes two functions land 0 and two xappings p and q and computes an inner product. This would be written p jr. O q in APL, +. x being, for example, the standard vector inner product.</p><p>(dRfun tnnsr-product (f g koptional (p nil pp) q) '(i~ (not pp) #' (lanbda (p q) (inner-product f g p q)) (reduce f a(~uncall g *p .q)))) Note that Inner-product is written so as to allow optional currying. One may supply all four arguments at once, or supply only two and get back a closure that will accept the other two arguments and then perform the operation. This technique avoids soma of the awkwardness of notation that would otherwise be required when using functional arguments and values in a Common Lisp framework. $</p><p>The function outer-product takes one n-ary function/and n xappinge, where n &gt; 0, and computes an outer product; for binary/this would be written p -. ff in APL. (The definition of outer-product is also written so as to allow optional currying.) SThis trick k m useful that we briefly conJldered Introducing S inmbda-lkt keyword &amp;¢ttrry so tl~t we could write simply (~.run inu,roproduc~ (~ g ~:urry p q) .</p><p>(z~d.ce ~ a(~mcall g .p .q)))</p><p>but then we thought better of It.</p><p>(   <ref type="figure">(((c q e) (e Q B</ref>))</p><formula xml:id="formula_11">[(c t Q) (q t Q)])]</formula><p>Here we have a standard matrix multiplication example; compare this to the definition in FP given by BackuJ <ref type="bibr" target="#b0">[1]</ref>. A matrix is represented as a xector of xectors; the second argument is transposed, and then the two matrices are combined by an outer product that uses an inner product as the operation. This operation can he implemented so as to execute in time logarithmic ill the mtmber of ~-permut~tion operation• (with no combining needed), iota operations, and a/operations, as follows:</p><p>(defun .,can (f x)</p><formula xml:id="formula_12">(if (xectorp x) (scan1 ~ x)</formula><p>(let ((q (enunerate x)))</p><p>(~@ (inv~e t'e q) (scan1 f (#@ q x))))))</p><p>(defun scsat (t z)</p><p>(do ((J I (+ j J)) (z x (over a(funcall</p><formula xml:id="formula_13">• (sht~t (in z (iota (-n J))) (-J)) -z) z)) (n (l.~ x))) ((&gt;-| n) z)))</formula><p>Here scan1 is the central part of the algorithm; it takes a xector and computes an APL4tyle scan in n number of iterations logarithmic in the length of the x~tor. (It should be noted that arguably any implementation of the 8hilt or iota operation might require time logarithmic in the length of the shifted or generated xector, for an overall time complexity of •(log s n).) The result of the call to in is the first. -y elements of z; thee are shlft~ 8o as to align with the last n -~ elements of z for combining. The results replace the last. -j elements of z (via the function over).</p><p>The main ~auctiou scan takes cam of handling arbitrary xappings; a non.xector is enumerated to impose an ordering q, the resnltin$ xector is scanned, and the scan results are then pro-ject~ back outs the original domain.</p><p>As an example of the power of the scan operation in a nonnumerical application, consider the problem of lexing, that is, diriding a character string into lexical token-. The ¢~ential work of this can be done in tim+ polylogarithmic in the length of the string. Lexing is normally performed by a finite-at•re automaton that makes tahiti•as as it reads the characters sequentially from left to right, and the states of the automaton indicate token boundaries. One can view a character (or • 8ingle-character string) as • fu:-ction that maps an automaton state into another state; taking string concatenation to be isomorphic to tempe•ition of these function., a string may therefore also be viewed as such • function. We can repreecnt state-to-state functions as xappings, and their composition by the conpoae function. Therefore a single scan operation using the compose function can compute the mapping corresponding to each prefix of a source text; applying each such mapping to the start state yields the state of the autonmton after each character of the input.</p><p>Let us consider a simple example where a token may be a sequence of alphabetic characters, n string surrounded by double quotes (where an embedded double quote is represented by two consecutive double quean), or any of +, -, *, -, &lt;, &gt;, &lt;% and &gt;=. Spaces, tab•, and newlines delimit token, but are not part of any token.</p><p>Our automaton will have nine states:</p><p>n means the last character processed is not part of a token. This is the initial state.</p><p>a means the character is the first in an alphabetic token. z •ureas the character is in an alphabetic token but not first.</p><p>&lt; means the charact+r is &lt; or &gt;.</p><p>• means the character is the = in a &lt;-or &gt;= token.</p><p>* means the character is ÷, -, *, or an m that is not part of s &lt;,. or &gt;-token.</p><p>q means the character is the. that begins a string.</p><p>• mm~ the character is part of aetring.</p><p>e ~ the character ,my be the" that +m~ a •t~ng, uulem the next character also is. in which caJe the string continuu.</p><p>(There is no ran.on why the states could not h~ve multicharacter names other than conciseness of pre~ntation.)</p><p>Characters are transformed into xappings by the following function:</p><p>(defun charact~r-to-state-nap (¢h) (if (alpha-char-p ch) "(n--~n a--~g g-~z &lt;--,a =--*a *--*a q--*8 s-as a-,a} (ecase ch </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>((#\')</head><p>'{n-*q n--.q z-~q &lt;--*q =-~q *-.q q~e s--.e e--,•}) ((#\Space l\Nevllno #\Tab) (defun conpute-all-statsa (x)</p><formula xml:id="formula_14">a(xr#f -(ac&amp;u ~'conpose •(character-to-state-nap -x)) 'n))</formula><p>The function lex tokes an input string and returns a xector of xectors; each nbxector contain, the characters for one token. The first •ubxector is alway• empty.</p><p>(&amp;,fun lax (x) (lot* ((s (compute-all-states x))</p><p>(fiz~t a(not (not (member .• '(n &lt; * q)))))</p><formula xml:id="formula_15">(nmm (•can t'* a(i~ .first 1 0))) (aaskad-nw a(if (eq .• 'n) 0 -nun•)) (lengths Cover ' [0] (hlstogrma aa•ked-nmu))) (or/gins ~nver•e #'(lanbda (x y) O)</formula><p>o(If -first .masked-nuns 0)))) a(subsoq x .or/gins (* .or/gins .lengths))))</p><p>The bulk of the work is done by coapute-all-jtate• and is nonnumerical in nature. A Jittle bit of numerical trickery involve ing a sum-•can and a histogram is used to perform the actual chopping of the string.</p><p>As an example of the operation d lox, let us consider how the input string "foe + "a÷b"&lt;=bar " would be processed. This string is rendes~d a8 ~ xector as follows: In uasksd-nuno, entries with the same value correspond to char. actors belonging to the same token, except that zero values indicate whiteapace belonging to no token. Note the use of over to replace the first element of lenKths with zero, and the use of a constant function with inverse to force the first element of origins to be zero.</p><formula xml:id="formula_16">[#\f 1\o #\o #\Space #\+ #\Sps.ce #\" #\a 41\+ #\b #\" #\&lt; #\-#\b #\a #\r]</formula><p>The final computed value is:</p><formula xml:id="formula_17">[{} [#\~ ~\o W\o] [w\+] [~\' t\a #\* #\b #\'] (s\&lt; ~\-] [*\b *\a #\r]]</formula><p>If you believe that the implementation actually executes lex in O(log z n) time, then lexing a megabyte of text should take about four times as long as lexing a kilobyte of text (assuming that enough processing resources are available to take advantage of the parallelism specified in the algorithm.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">A Metacircular Interpreter</head><p>Table I presents a metacircular interpreter for a subset of Connection 7Jachine Lisp. It is similar in style to published interpreters for Scheme <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b25">26]</ref> but differs in three respects. First, it uses such Common Lisp constructs as case and etypecaae to discriminate forms. Second, like Common Lisp, it maintains the distinction between ordinary forms (including ordinary variables) and functional forms (including names of functions). Third, it allows for the body of a lunbda expression to be an implicit progu, which Common Lisp also allows and some interpreters of Scheme do not.</p><p>Much of the machinery will be familiar to those who know Scheme. The function oval takes an expression and a lexical environment, as usual, but also takes a list of indices whose pur. pose is explained below. Numbers and strings are treated as eelf-ewduating. Ordinary variables are looked up in a lexical environment structure, here represented as an association list in the time-honored fashion. The following non-atomic forms are distinguished:</p><p>• (QUOTE z) evaluates to z.</p><p>• (FUNCTION /) evaluates / as a functional form by calling ~neval.</p><p>• (IF p z ¥), as usual, first evaluates p; then one of z and II is evaluated depending on whether the value of p was non-rill or nil.</p><p>• (ILPHA z) represents the construction ~,z. Briefly, this canses many evaluations of of s, one for every possible inalex. (Difficulties with this idea are discussed below.) of these many calls to oval gets a different indices argu-mona, obtained by coming the index for that call to aval onto the previous list of indieor. Note the use of • univemd zapping (-*} to allow each of the parallel ¢alk to obtain its own index.</p><p>• (BULLET z) represents the construction .z. The indices list must contain one entry for each a that is dynamically controlling the current call to eval. The first entry in the list corresponds to the innermost a, which is the one that the bullet of this expremion should cancel. Therefore the expression Z is evaluated (it must produce • xapping) using the rest of the indices, and then the first index is used to select an element of the resulting xapping.</p><p>• Any other list is a function call. The first element is evaluated as ~ functional form, av118 is called in the usual way to evaluate the argument forms, and then the function is applied to the arguments.</p><p>The function fMval constructs clmures from lanbda expree-sionL Symbols are tr~t~ as primitive operators (this suffices to allow the interpreter to execute properly in Common Lisp).</p><p>The function apply procenes closures in the usual manner, adding parameter/argument pairs onto the environment of closure before evaluating the body of the Inbda expression. The function evprogu lumdles the evaluation of the body. When the function is a zapping, then many applications must be performed. The function liat-zapptng-tram~poso merely takes • list of argnment xappings and producce its transpcee, s xgpplng of lists. This interpreter is not satisfactory for a number of reasons. One is that the form z in (BULLET z) is evaluated many times, once for every index being processed by the corresponding ¢z. This shouldn't matter in a pure theory, but we are interested in explicating side effects within the language, and prefer • semantics where z is evaluated only once (at least as far as the corresponding a is concerned; additional occurrences of ~, surrounding it might caum repeated evaluations).</p><p>A second objection is that when a form (aLPHA s) is proceded an apparently infinite number of recursive calls to oval are performed, one for every poesibk index (meaning every prosible Lisp objectl), for there is nothing in the syntax of the call to limit it. Theoretical objections aside, this is dimcult to implement.</p><p>The most telling objection, however, is that this interpreter explains (x in terms of itself in such • way that one cannot tell, just to look at the code of the interpreter, whether or not actually processes anything in parallel Thk is similar to the dilHculties noted by Reynolds <ref type="bibr" target="#b18">[19]</ref> for any interpreter that defines a construct in terms of itself.</p><p>In the next section we discuss • number of difficult semantic problems and then present a second metacirenlar interpreter that avoids defining a in terms of itself and also explicates some issues of parallelism and synchrony. That is the microscopic view. Let us now map this back to the macroscopic view, in terms of xappings. The predicate p is first evaluated (many times, in effect, once for each index) to produce a rapping. Now if side effects were not an issue, we could simply specify that both z and y are also evaluated and then combined according to the truth values in p; if would then be a purely functional conditional. But side effects are an issue, and we want if to be the usual control construct, not a function. We find that if is best macroscopically explained by postulating that z is evaluated only for indices in which p has true values, and that g is evaluated only for indices in which p has false values. In other words, evaluation of an expression that is under the control of an a must be dependent on a content that is a set (or xet, if you wish) of "active indices. ~ Suppose that there are nested occurrences of ~,. Then in general the context must be a nested structure. We can let t, say, represent the global context where no ~ is controlling, and in the genera] case a context is a tree of uniform height composed of nested xappings. Suppose that the value of rebus is a familiar quatrain:</p><formula xml:id="formula_18">rebus =~ [[Y Y V It] [Y Y V B] [I C U It] [Y Y 4 ME]] 4</formula><p>Then in the expression am(if (eq --rebus 'y) 'q ..rebus)</p><formula xml:id="formula_19">:~ [[QQUR] [QQUB] [I CURl [Q Q 4~]]s the consequent expression 'q is evaluated in the context lit t nil nil] it t nil ~l] [nil nil nil ntl] it t ~l nil]]</formula><p>and the alternative expression ..rebus (the second occurrence) is evaluated in the context</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[[nil nil t t] [nil nil t t] it t t t] [nll nil t t]]</head><p>A context, therefore, may be understood to be exactly the places where the controlling predicates have succeeded or failed as necessary to enable execution of the current expression.</p><p>It is technically convenient to eliminate the occurrences of nil from contexts (recursively eliminating any resulting empty rappings as well). The contexts just exhibited would therefore actually appear as</p><formula xml:id="formula_20">{0--~[t t] 1--,it t] 3---~[t t])</formula><p>and [{2--,t 3--*t} {2--,t 3--*t} it t t t] {2--*t 3--~t}] respectively. The more complex metacircular interpreter exhibited below will use contexts of this form to determine the indices for which to evaluate an expression. That will take care of the interaction between (~ and conditionals. No, because each closure behaves slightly differently: each uses a different value from y, according to indexl We conclude that "a j does not distribute over (lambda ... ) in a simple manner; rather, a closure must close not only over free iexical variables but also implicitly over the current set of indices.</p><p>An intuitive way to underltand this is the following technique for distributing za" over lambda~expreseions: a(laabda (x y ...) 6ody) ~ (lanbda (~x ay ...) ,.,body)</p><p>That is, a rapping of closures of the same lambda-expression can be understood to be a simple closure that accepts xappings as arguments and "destructures ~ them before executing the body in parallel. This can be made more formal: where the penultimate step is merely a renaming of the %ariables ~ ax and ay to be the otherwise unused names qx and qy, and the last step is a factoring back out of a. This mode of understanding is still only vaguely intuitive, because the result of ~#' (lanbda ... ) must really after all be a rapping and not a closure. One might go a step further and specify that in a function call where the function is a constant rapping of funcall operations, any argument that is not a xapping may be a closure that takes rappings as arguments; in other words, we arrange to ~transpese ~ the levels of closurenese and rappingnesa.</p><p>The complex metacircular interpreter that we yet promise to show you (please have patience, Gentle Reader) allows exactly that sort of transposition. It turns out that an appropriate representation for closures has/our components: the lambda expression, the lexical environment, the context, and the indices, all as of the point of closure. The context and indices informstion trade off against each other. A closure containing a context c that is a xapping (that is, anything except t) may regarded as representing a rapping whose values are closures whose context parts are the values in c. For concreteness amuse that a closure is represented as a 5-1ist beginning with the symbol closure:</p><p>(closure ezp env eontes$ ~nd/ces) Then we have the following identity: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(xref context k) .(cons k indices))</head><p>We will take this identity u the definition of a clmure containing a context other than t. It can be used to convert such a closure into a xapping, and if the original context is nested the procm can be iterated to produce a nested xapping whme structure will be the same as that of the original context and whose leaves will be clceurm whme contained context is t, that is, ordinary clmures. Indeed, we officially modify the definition of xref as follows:</p><p>(defun :,,x'e:[ ~ (etypecaee x (X~ING (prlaitlve-xref x k))</p><p>(CLOSUeZ</p><formula xml:id="formula_21">(saMe-closure (closure-exp x) (closure-env x) (pr/altlve-xrot (closure-context x) k) (cons k (closure-Indices x))))))</formula><p>The advantage of this dual representation, as we shall see in due course, is that it allows us to specify certain kinds of synchrony in the complex metacircular interpreter. First, however, let us turn to the matter of infinite xappings. Suppcee we were to write a(+ (random 8) -X) This seems cieur enough; we wish to add a random number (from 0 to 7) to each element of the xapping x. But shall a single random number be chceen, and that result added to every element of x? Or shall there be distinct computations of random numbers for each element of x? Our distribution law states that the previotm expremion means the same as (,,+ (arando, aS) x) and this clearly calls for many inltaaces of the x-nation function to be applied to many instances of 8, thereby producing many random numbers to be added. But /tow many? There is no problem with the addition operation if x is finite; the rule about the intersection of domains in a function call causes only a finite number of calls to + to occur. But the code calls for an infinite number of ~ to randoa to occur, one for every pmsible Lisp object. This is difficult to implement effectively. The reason is that random has a side effect. (If it did not, we could simply make one call to it and then effectively replicate the result. That is what we did earlier when we claimed that (a+ a2 a3) =~</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(-.6).)</head><p>We have investigated two ways out of this problem. One is to uas lasy xappinge: in that case (arandon as) ~ { . (],antxt, 0 (random e))} more or lees. This approec_~h_ has the disadvantage that side effects can occur out of order, sometimes unexpectedly late in the progrsm of the progran~ (This same problem can occur with futures in Multilkp [10]. Indeed, a lazy Yapping is in effect merely a collection of futures, all of a particular form.) For instance, in the code fragment a(tou (bar)) we cannot guarantee that all side eft'ecta caused by calls to too occur after all side effects caused by calls to bar. Neverthelms, we have implemented (on a single-procemor system, the Symbolics 3600) an experimental version of Connection Machine Lisp with lazy xappings and have found it tremendously complicated to implement b/at useful in practice.</p><p>The other way out is to forbid infinite xsppings. Unfortunately, a total ban on infmite xsppings greatly restricts the utility of the a-notation. We could allow just constant xappings, but then side effects cannot be treated consistently (the example of a(randon 8) could not be made to work, for example), and warts appear such as the donain function not being total.</p><p>We have found the following intermediate position tractable. We introduce two rules:</p><p>• One must not execute an infinite number of function cask or an infinite number of IF forms.</p><p>• An expression beginning with an explicit "a" must not produce an infinite xapping.</p><p>Violations of these restrictions be detected syntactically (by a compiler, for example). They allow infinite xappings to arise "virtually" in the notation, but an implementation can always arrange never to have to represent them explicitly. One consequence of these rules is that any function call or IF form within the control of a "a" must have as an immediate subform either a form preceded by %" [basis step] or another function call or IF form [induction step]. Another consequence is that the distributivity of "a" over function calls is partly destroyed in practice.</p><p>The metacireuler interpreter shown in Table <ref type="table" target="#tab_3">2</ref> makes use of a special representation for constant xappings, but only for the sake of repre~mting contexts. Infinite xappings can become visible to "user code" only if provided as part of the input to the interpreter.</p><p>The code in Table <ref type="table" target="#tab_3">2</ref> takes advantage of the Common Lisp type specifier hierarchy in two ways. First, the type specifier (NDBF£ T) specifies a type to which belongs the object t and no other object. Second, the type specifiers CONSTAFr-IAPPING and FINITE-XiPPING represent subtypes of the type YAPPING. The function choice is assumed to operate properly on a constant xapping by returning the object that is the value of that xapping at every index.</p><p>The code in Table <ref type="table" target="#tab_3">2</ref> is quite similar to that in Table <ref type="table">I</ref>. We remark here primarily on the differences.</p><p>The function oval of course takes an additional argument, context, which is the third argument and not the fourth for no good reason other than historical accident. An important invsriant to understand is that the value returned by a call to aval will match the context argument in its overall structure; that is, it will be a copy of the context with suitable values substitituted for the occurrences of t.</p><p>The handling of numbers, strings, and quoted objects is a bit different in that the context must be taken into consideration. The function contextualize in effect makes a copy of the context, substituting the value for e~ch occurrence of t; it thus replicates a value so as to match the context structure. For symbols, the function lookup performs a similar contextualization. (The strange maneuver involving the function lookup-contextualize is discussed below in conjunction with closures.)</p><p>The deseriptiou of the processing of ALPHA forms no longer uses a in any eNential way. A form (ALPHA z) is processed by evaluating the subform z in an extended context, one in which every occurrence of t in the current context has been replaced by {-*t), thereby increa~ng the height of the context tree by one. From this one can see that the topmost xapping in a nested context structure corresponds to the outermcet controlling a, and a xspping that contains a t corresponds to the innermost a. The function extend-context performs the straightforward mechanics of context extension.</p><p>The proosuLng of (BULLET z) becomes more complicated. If any indices are provided, then one is used as in Table </p><formula xml:id="formula_22">(cddr pair) context) (contextualize (eyabol-val~ exp) context)))) (defun lookup-contextualize (J value context) (cond ((&lt; J O) (error mMieplaced '*'")) ((= J O) (context-filter value context)) (t a(lookup-contexCnslize (-J l) value .context)))) (defun trim-context (context) (etypecaae context (CONSTANT-XAPPING (if (eq (choice context) t) t (aake-constant-xapping (tria-context (choice context))))) (FINITE-XAPPING (if (eq (choice context) t) t a(tria-context .context)))))</formula><p>(defun extend-context (context) (let ((alpha-t (make-constant-xapping t))) (labels ((ec (context alpha-t) (etypecaee context  </p><formula xml:id="formula_23">((MIDiBER T) alpha-t) (CONSTANT-XAPPING (aake-conetant-xapping (ec (choice context) alpha-t))) (FINITE-XAPPING a(e¢ -context alpha-t))))) (ec context)))) (defun</formula><formula xml:id="formula_24">((~ T) O) (lAPPING (+ 1 (context-height (choice context)))))) Table 2 (concluded).</formula><p>wise the context is "trimmed" to reduce its height by one. Because a bullet must cancel the innermost ~, this reduction must take place near the leaves. The function trim-context performs the straightforward mechanics of context trimming. The function context-filter eliminates any values that are not relevant to the current context.</p><p>The processing of an IF form becomes much more complicated. The predicate expression is evaluated in the usual way to produce, of course, a value structure that matches the structure of the current context. From this two new contexts are computed; truecontext is that part of the original context where non-nll values resulted for the predicate, and falsecontsxt is that part of the original context where nll resulted for the predicate. The function ifpart computes such a context part, its first argument determining whether non-nil or nll values are sought; Ifpaz-t might also return zuL1 if that part is entirely empty, in which case no evaluation should be performed for that arm of the IF expression. (We could have chosen to allow nll to stand generally for an empty context, and defined eval to return nll immediately if its context argument were nil. This would have simplified the code for processing IF forms, but would have complicated other parts of the interpreter. It struck us as needless generality.) If both arms of the IF form are to be evaluated, then the function merge-results, a one-line wonder, is used to combine the two result xappings to yield the value of the IF form. (To see why it works, one must realize that the results to be merged were computed in disjoint contexts; if therefore xapptng-union recursively calls merge-results, the two arguments given to nergereaults will necessarily also be xappings.)</p><p>No special changes are required in the processing of function call forms. The function fneval is also largely unchanged except for the call to contextualize and that fact that the current context is packaged up as part of a closure. Similarly evlia is changed only trivially..</p><p>The really interesting changes are in apply. When a closure is applied, the body of the laabda expression is executed in the usual way, but only after extending the lexical environment in an unusual manner. Instead of parameter/value pairs, the environment contains triples. The third element of each pair is information about the closure context, specifically its height. (The function context-height computes the height of a context. Recall that a context is a tree of uniform height.)" This extra piece of i-formation is used in the function lookup to deal with the implicit ~destructuring" alluded to near the beginning of this section.</p><p>The application of a xapping proceeds in three st~es. First, the domains of the xapping and the arguments are intersected; the result should be finite. The function get°finite-context computes the indices in this intersection and returns the result as a list, not as a xapping, to emphasize finiteness and eliminate any semantic confusion that might arise from using a xapping at this point. Second, for every index in this list an element of the function xappin$ is applied to a list of the corresponding elements from the argument xappings. Finally, the rssu]ts are used to construct a new xapping that is the result of the application.</p><p>The definition of aplis shown in Table <ref type="table" target="#tab_3">2</ref> does not provide for any parallelism; it performs applications one at a time. Note that aplis is identical in overall structure to evlis; hence its name. We are now in a position to distinguish between parallel argument evaluation and the parallelism in Connection Machine Lisp, as mentioned in section 3. General parallel argument evaluation is obtained by replacing the call (cons ... ) in evlla with the form (pcall #'cons ... ), where pcall is a Multilisp <ref type="bibr">[I0]</ref> special form that is like funcall in effect but evaluates all of its arguments in parallel The data-oriented parallelism of applying a xapping-full of functions to xappings-full of arguments is made manifest by making the identical change to aplis:</p><p>(defun aplle (fn Index-set) (and Index-set (pcall #'cons ;Allow parallelism. (:funcall fn (car Index-set)) (aplls fn (cdr Index-set)))))</p><p>The primary operational distinction between a xapping of closures and a elceure over a context that is a xapping is one of synchrony. For a clceure over a compound context, the code is executed in a synchronous lash/on for all indices in that context; but applying a xapping of clceures causes all the closures to execute asynchronouely in parallel. There are also questions of ef~ciency and of distributed versus centralized control: Applying a closure involves only one call to eval, not many in parallel, ud the computational overhead of interpretation is smaller but centralized. (For some computer architectures there is an advano tnge to expending additional resources for the interpretation of multiple, distributed copies of the same program.)</p><p>Note that the closure over a context could be treated as a xapping in apply and everything would continue to work if synchrony were not a~ imue. To see this, simply delete the arm of the etyl~tcnse for the type CLOSURE, and in the r~xt arm replace the guard XAPPIliG with the guard (0R XAPPIliG CLOSURE). Thanks to the extended semantics of xref when applied to a clceure, interpretation still works properly, but calls are not guaranteed to be synchronous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Unsolved Problems</head><p>The interpreter in Table <ref type="table" target="#tab_3">2</ref> is written so as to maintain a closure over a context in that form as long as possible, converting it into a xapping of closures only when forced to. This is done in an effort to maintain synchrony wherever possible. Control of synchrony, in turn, is desirable for two reasons. First, it gives the user more control over the behavior of the program. Second, we believe that synchronous parallelism in a program is easier to comprehend because control is always at a single place in the programtext, rather than at many pkces simultaneously. We believe, for example, that the masterly but complex proof by Giles [9] of a relatively small program with only two procem~ demonstrates the difficulty of understanding parallel programs of the MIMD style, s Consider this apparently straightforward code: a(set:E (x:re:g X-J)</p><formula xml:id="formula_25">(I (+ (xre~ x (-.J ~)) (:a'e~ x .J) (xre:r x (+ -J 1)))</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>a))</head><p>With synchronous execution, this causes every element of a xector x specified by the indices in J to be replaced by the average of itself with its left and right neighbors. With asynchronous execution, however, all sorts of behaviors can occur, because some ele. meats of x might be updated before the old value has been fetched eThe technique of the proof, which k due to Owick] <ref type="bibr" target="#b16">[17]</ref>, Is first to prove each process correct In isolation, and then to coulder all pomdble Interactlons by considerln$ all poeelbla (actually, all ainters4ting j) pairs of control points within the two procersee. The dlmculty of thIs technique increases exponentially (quite Ilterzlly) with the number of processes.</p><p>for other averaging operations. That is because the thread of execution for one index might reach the serf operation before the thread for another index has performed the necessary fetch; the points of control for different indices may be at different points in the program text. This example is particularly devastating if J is an infinite xapping.</p><p>We have found the particular approach to synchrony exhibited by the code in Table <ref type="table" target="#tab_3">2</ref> to be unsatisfactory in practice, because it depends on details of the operation of the interpreter and of the user program. Consider this expression: .z)</p><p>the calls to the closure that calls £oo will occur asynchronously, because the merging of the two closure-xappings to produce the value of the IF form requires conversion of each to a xapping of clcaures.</p><p>One possible patch that masks some of these symptoms is to change the code in apply that handles application of • xapping. The code can examine the elements of the xapping, and collect all the elements that are closures into equivalence classes, where members of the same equivalence class have eql expression, environment, and context components, differing therefore only in their indices lists. All the members of an equivalence class could then be processed by a single call to eval by constructing a new closure whose context is constructed from their various leading indices.</p><p>This patch seems rather hackish to us, however, and no less opaque in its operation. We would prefer that synchrony be enforced in a more manifest manner, such as a visible syntactic device.</p><p>An obvious point at which to synchronize is an explicit occurrence of c,. We lean toward defining the language in such a way that an expression preceded by c, is executed asynchronous]y for all relevant indices, but resynchronization occurs when assembling the result. For instance, in the expression a(foo (bar .x)) it might be that side effects of some calls to foo might occur before all side effects of calls to function bar had occurred. In contrait, the expression a(~oo .a(bar -x)) requires that all calm to bar be completed before any calm to foo occur. The averaging example shows above could then be fixed as follows:</p><formula xml:id="formula_26">a(set£ (xref x -J) • a(/ (+ (xref x (--J I)) (xre~ x -J) (xret x (+ .J 1)))<label>3</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>))</head><p>In this formulation we would expect =.¢,~ to be a widely used clich6 meaning "synchronize here." In the example it forces the parallel executions to synchronize after all divisions are cornplsted but before any values are stored. This approach to synchronization also partly destroys the syntactic transformations involving c, and *; one may always introduos ea in front of an exvreesion, but one may not not cancel it without endangering program correctness. Perhaps this convention is yet too delicate.</p><p>The implications of this definition for the structure of the interpreter are not entirely clear to us. The net result may be to shift the introduction of parallelism from apply back into eval, as in Table <ref type="table">1</ref>, but this will reintroduce all the problems of recursively calling aval for An infinite number of indices. We believe that this can be avoided by recasting the interpreter into the continuation-passing style <ref type="bibr" target="#b18">[19,</ref><ref type="bibr">24,</ref><ref type="bibr" target="#b24">25]</ref>, but that is beyond the scope of this paper.</p><p>Stylistically speaking, Connection Machine Lisp is primarily SIIvID in its approach (though providing completely general cornmunicatinns patterns with the ~ operator, as opposed to the fixed communications patterns that have historically been associated with most SIMD machine architectures). Some interpretations of the semantics of a permit some slight asynchrony, but only in the evaluation of many copies of the same expression. However, there is a hook that allows expression of completely general MIMD parallelkm: a function call where the function is a xapping whose elements are distinct. <ref type="bibr">For</ref>   The difficulty here is that in this case we would like for two indices to be considered the same if they are equal rather than merely eql; however, the fact that xappings are mutable creates grave difllculties. What if the xector [10] used as an index in the identity matrix were mutated to be [1 1] ? Remember that. no two, p~rs of • xapping may have the mune index. These nHty issues are the r~wou why indicel are compared mdng eql: the equivalence of indic~ must renmin invarinnt under mutability of data.) NIAL <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b19">20]</ref>. Many of the comments about APL apply to NIAL, except that NIAL allows nested arrays. NIAL, unlike APL, allows u~r-deflned functions to be used with the reduction and scan operators, and indeed all operators. NIAL has a cleaner and more convenient syntax for talking about functional operators than a Connection Machine Lisp based on Common Lisp, but a Connection Machine Lisp based on Scheme would have a syntax as clean as that of NIAL. We think Connection Machine Lisp has a better notation (a and .) for nested uses of the apply-to-all construct (which NIAL calls EACH). Such nested uses do not occur so frequently in NIAL because apply-to-all is implicit in many NIAL operations; this is pomfible because NIAL has a different theory of data structures than Lisp <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>. In NIAL data is immutable but variables are mutable. (The ren~ke about NIAL apply for the most part also to other "modern ~ APL implementations such as those of IBM, STSC, L P. Sharp, etc.)</p><p>FP <ref type="bibr" target="#b0">[1]</ref>. Many of the ideas and notations of FP are easily and usefully carried over into Connection Machine Lisp, and indeed we have traneisted some examples from Backns's paper. Like Lisp, however, Con-action Machine Lisp is oriented around variables and less around functional composition; PP does not explicitly name the data to be operated on, but relies on combinatorlike control of the flow of data. FP is an applicative language; data is immutable.</p><p>QLA-MBDA [5 I. Connection Machine Lisp orgunizes its parallelism around data structures rather than control structures, and thus may be more suited to a SIMD architecture than to a MIMD architecture; the opposite may be true of QLAMBDA.</p><p>Multil~p. Multilisp, like QLAMBDA has parallelism organized around control structures rather than data structures. Multilisp introduces parallelism in two ways, one structured and the other extremely unstructured. The structured way allows the elements of a very particular data structure to be computed in parallel; this data structure is the list of arguments for pcall. The unstructured way is the use of future, which allows an arbitrary computation (the argument form to future) to proceed in parallel with another computation of arbitrarily unrelated structure (the remainder of whatever computation surrounds the execution of future, that is, the continuation). KRC (Kent Recursive Calculator) <ref type="bibr" target="#b28">[29]</ref>. Lazy xsppinp are somewhat similar in their use to the infinite lists of KRC, and especially to the set abetraction expressions of KRC. Set abstraction expressions contain additional mechanisms for filtering and taking Cartesian products that lazy xsppings do not have; these lend KRC a great deal of expressive power. Xappinge have state and may be modified (even lazy xappings), whereas KRC is an applicative language without side effects.</p><p>Symmetric Lisp [6,7]. There is a pcseible confusion between our notation and that of Gelernter, because his work also involves parallelism in Lisp and uses ~ notation involving the word M.PHA. We regard highly his study of space-time symmetries in programruing languages, but believe that our notation and our approach to parallelism are rather different from his, despite the accident of similar terminology. 9 Implementation Status A Connection M~chine Lisp interpreter tlmt supports constant, universal, and lazy xappinge hu been implemented on the Symholies 3600, a sequential processor, for experimental purposes. It has been used to test the ideas in this paper and to execute a number of smallish progranw (up to fifty fines in size). All of the examples in this paper have been tried out on this interpreter.</p><p>An implementation is planned for the Connection Machine System <ref type="bibr" target="#b10">[11]</ref>, a 1000-MIPS, fine-grained, massively data-parallel computer with 65,536 (2 Is) processors, 32 megabytes (2 =s bytes) of memory, and a general communications network among the processors. However, we cannot now guarantee exactly when a full implementation of Connection Machine Lisp on the Connection Machine System will be ready.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Conclusions</head><p>We have designed a dialect of Lisp that we believe will be useful for symbolic proeemfing problems that are susceptible to solutions with fine-grained, data-oriented parallelism. This dialect features an array-like data structure designed to be processed in parallel using operations of the kind appearing in FP, APL, and NIAL. It also features a notation, similar in form to the Common Lisp backquote construct, for expressing parallelizm in a manner that facilitates both macroscopic and microscopic views of parallelism~ There renmins a design space of modest size to explore, in which several important design goak are in essential conflict:</p><p>• compatible extension of an existing Lisp dialect • convenience in using functional arguments and values • consistency between macroscopic (arrays of data) and microecopic (code within individual processors) understandiug of parallelism</p><p>• a model of data consistent with that of the base language (including that fact that data structures are mutable)</p><p>• a treatment of side effects consistent with that of the base language</p><p>• generality of the a-notation, including the rule of distribution over function calls</p><p>• control over parallelism and synchrony</p><p>We have teated a few points m this design space to determine which results in the most useful language design for practical purposes.</p><p>Other topics to explore include the integration of other notions of parallelimn into Connection Machine Lisp, such as the future and l~:all constructs of Multillsp, and which applications in symbolic computation are suited to this fine-grained, data-oriented style of parallel programming.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>a/: (z,,==,... ,=~) -(/: =1,/: as,...,/: =.) We may do the same thing in Connection Machine Lisp: (ammqrt '[1 2 3 4]) =~ [1 1.4142136 1.7320608 2]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>(</head><label></label><figDesc>acons '{a--*l b-~2 C--*$ d-~4 ~-.6} '{b'-*6 d-*7 e--*6 :t'-*9}) =~ (b--~(2 . 6) d--~(4 . 7) ~-~(5 . 9)}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>~* a*c o5)15) a82)) --~ (~ltat a-c (a+ a( * .C 9/5) a82)) -------(~ltst a.C a( + ( * .c 9</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>(</head><label></label><figDesc>subeeq '[the slick brown quux Jumped over the lazy frog] =~ [quux Jup*d over] (reaove-l~-not #'aton • { 8-. (pr~a, odd) 6-+(compoelte even perfect) e-+ (transcendental has-pretty-c onttnued-~rac tion) 5Y-*bo~ M pt-* (trmmcendeneal has-~l|ly-contlnued-frac tlon) 25--.odd ) ) ==~ {57-+borlng 25--.odd} (sort '{sky-~blue baua~--.yellow apple--,red 8reJs-~Ipreen 8hlrt--+plald} J' str/ni|-lessp) =~ [blue IPreen plaid red yellow]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>4. 2</head><label>2</label><figDesc>Dom__aJn, Enmneration, and Union The domain function takes any xapping and returns a xet of the indices. (doMtn '{sk~r---,blue Ipmae-+~een apple--,red)) = {e~ sraen aisle) The enmasnte function takes a x~pping and constructs a new yapping with the mune dom-;n but with coneecutive integere etarting from sero as values. The net effect is to impoee an (arbitrary) ordering on the domain. Enumerating the same yapping twice might produce two different results. (enmmrate '{sky-*blue Iraas--*sreen apple--.red}) =~ {sky-*O graee-~l apple-42} or {aky--.l Iprans--.O apple-.~) or {sky--.l grass--,2 apple-*O} or {akT--.2 I~'ans"-'l apple-*O) or {sky-~2 gras8-~O apple-~l) or {skT--*O Iprass--,2 apple-~l} The lector and xet functions are like list, in tl~t they take as~ number cg arguments and construct s xector or xet. Note that xet must eliminate duplicate elements. (xector ' red ' blue ' green "blue "yellov ' red) =~ [red blue 8teen blue yellov red] (xet 'red 'blue "green "blue 'Tellou 'red) =~ {blue Ipreen red yellow) The [unction xunion takes a combining function and two Xal~ plnp; the resul; is a yapping that is the union of the sets of pairs of the argument xappinss. The combining function is used to combine values for which the same index appears in both ~rgument xapping| (and furthermore xunLon guarantees that the first ursument to the combining function comes from the first yapping, and the second argument from the second xapping). (:cemlon I'+ '(alburt---,O ~L~i~iclwshvili--~l uerdandrea--*0 apaeeky--,g} ' {alburt-+O seirawan-.l s~assky-~1 racheZs--+0)) {albnrt-,,O dzinhtckaehvtlt-.-.l aardandrea--.0 rachela--.0 aeiravan--+l spaeskT-*3} It is not necessary to have a function called xlntereectlon~ b~use (~tnterlectton J 8 IO = (~/s y); all funetion calb implicitly perform an intersection operation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>(</head><label></label><figDesc>over '{l--.a S-~b 6--.c 7--.d) '[~ # e + • *]) ::~ {0-:-+~ 1---,a 2--*@ 3-.b 4--+= 5---+c 7--.d}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>(</head><label></label><figDesc>in '{l--,a 3--.b 6--,c 7--.,1} '[Z # e + -.]) :~ {i-.a 3-~b a-.e)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>(</head><label></label><figDesc>atop '{l---,a $--.b 6--.c 7---.d} '(~ # e + = *]) ::&gt; [~ a @ b -c]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>18 ]</head><label>18</label><figDesc>For a three-dimensional array (represented by nested xectors), the reduction functions indicated in APL by +/[0], +/[I], and +/[2] are written in Connection Machine Lisp as ~¢tot+, a~,+, and aa~+. For permuting data, the expression (~/ d z) takes a binary function )¢ and two rappings d and z and returns a new xapping z whose indices are specified by the values of d and whose values are specified by the values of z. To be more precise, the value of (~f d z) is {q-~e I S = {r I (p~q ~ d) ^ (p~r ~ z)} ^ IS1 &gt; 0 ^ • = (/~/8)}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>-.b 4-.c e-.d) Compare this to n ~mfl~ use of the APL expansion function: vector elements to have contiguous in. dlcee, and must therefore pad the expusion with seroes, Con* nection Machine Lisp allows u xspping simply to have holes. The inverse of the index-doubling operation shown just above is s contraction operation with combining: (defun halve (x) (:floor x 2)) (transport it'+ it'kalve '[123486]) =~ [S 711]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>The function inverse computes the inverse d s xspping con-sidm~l u • mspp'mz; for every pair p-.f in the argument, u pair t-*P •ppe~s in the result. As usual, • combining function must be provided agsinst the p~ibility of duplkste values f.(defWl inverse (:f X) (eosbiu t x (~u*~ x))) ;i. e., (~:f x (do--in x))(inverse it'@ '[• b c dO) =~ {u--,0 b--,l c-42 d--,3} (inverse it.+ "It b c b]) :~ {a---.O b-.*4 c.-.2} (inverse #'max '[• b c b]) =¢. {•-..O b~8 c-.-.2} (inverse #'a/n '[a b c b)) =~ {a--.0 b-,i c--.S} The function co•pose comput~ composition of two xappinss considered a, msppinp; for every peir p-~g in the first argument. there must be • pair g-~r in the second argument, and the pair p-,r appears in the result. (do:f~a compose (x y) et(xre:f y *x)) (compose '{p-*x q--*y r-~x s--*w} '{x-~3 y-*4 z--,6 w"*6}) As in APL, it is helpful to huve • primitive operator Iota to generate xectors of • given kngth. (lot• iO) =~ [0 I 23456789]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>e) [s)) (tr~pos, "{a-.~ s) t~.(s 4 s) c-,{o-.e 2-~7)}) : [{1---~1 S--.S C--.6} {A---.S e--.4} {S--.6 C--.7}] (transpose '{0--,(4--,14} 1--P{1-,67 $--,23) 3-,{1--,89} (o-.(4-.~) 1-.(1-~e7 s-~e~) a-.(1-.2s 4-.as) 4--*{0-.14 4--~66}}Note that the subxappin~ of the argument need not all have the muuc domain; the argument and result may be "ragged " (or even sparse) matrices. The last result above might be expressed ns ioooo 1in mathematical notation, but note that the xappings shown in that example do not represent the sero entries explicitly. The correspondence between the dense and sparse representations may be seen by properly formatting the sparse one:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>(</head><label></label><figDesc>f~mJ:all (Inner-product #'+ #'*) '[1 2 S] '[4 6 6]) =~ 32 (innsr-product #'aax #'nin '[6 2 7] '[2 8 6]) :~ 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>(c P e) (B p B)) ((c • P) (e t P)]]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>(</head><label></label><figDesc>ds~un aatrix-aulttply (f g &amp;optional (x nil xp) y) (:tf (not xp) #' (lanbda (x y) (matt/x-multiply f g x y)) (outer-product (Inner-product f g) X (trmpose y)))) (|atrtx-aulttply #'+ #'* '[(1 2) [3 4) [6 6)) '[[0 1 0 1) [1 I 1 0]]) :~ [[2 3 2 1] [4 7 4 3] [6 11 6 6]] (This result would be expressed as Large Example: Scan The sc an operation, written/\=in APL, computes a vector of the /-reductions over all preBxes of a vector ~ (This operation is also referred to as a apsrullel/'*prefix" computation.) In Connection Machine Lisp, using xectors, we have the examples (scan #'+ '[1 2 3 4 7 2]) =~ [1 3 6 10 17 19] (scan #'* '[1 2 3 4 5 6]) =~ [1 2 6 24 120 720] (scan #'max '[1 62 7 S 4]) =~ [1 6e 7 7 7]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>(</head><label></label><figDesc>(1%+ 4+\-e\*) '(n-** n-~* n-.* &lt;-.* --.* *-.* q-~o a-.a .-,*}) ((s\&lt; #\&gt;) '{,-.&lt; n-.&lt; --.&lt; &lt;-.&lt; --.&lt; *-~&lt; q-~..-., e-.&lt;}) ((#\-) '{n-** n--,* z--,* &lt;--,-=--** *--,* q-*s s-*8 e-**})</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>"</head><label></label><figDesc>{n-.,.n a.--,.n z-.n &lt;---,.n --..-,.n *-~n q-..+s s.-,.s ,.-.-,n}) ))) This fmaction computes the state of the automaton eRer every character of an in•mr string .(tepee•anted as a xector of character objects):</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>s</head><label></label><figDesc>=~ ItS Z N* IQ 8S 8 E&lt; = Jt Z Z] ~trst =~ iT NIL NIL NIL T NIL T NIL NIL NIL NIL T NIL T NIL NIL]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>It gets worse. Consider the interaction of ~, with closures. What does ~(aapcar #'(laabda (x z) (list x -y z)) a .b) mean? Taking the microscopic view, for every index we execute the computation (napcar #'(lanbda (x z) (flat x y z)) a b) where y is the value for that index within y, and b within b. If 4TOO wise you are, / Too wise you be; / I see you are / Too wise for me. STwo cues, your / Two queues, Eubie; / Icy ewer / Took youse for me. • =~ (three five) y =~ [little blind] b =~ [(kittens monkeys) (mice men)] then the result should be Lk(thrse little kittens) (five little monkeys)) ((three blind ulce) (five blind aen))] But now let us take the macroscopic view: a(napcar ~' (lambda (x z) (list x -y z)) a .b) means the same as (anapcara#' (la-,bda (x z) (list x -y z)) aa b) Thus a xapping containing a zillion aapcar operations must be applied to three other sappinge. The second is a constant rapping with the value of a, and the third is the rapping named by b. But what is the first xapping? Is it a constant xapping of closures?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>a(napcar #'(laabda (x y) (llst x y .z)) a .b) ----(cmapcar a#'(lanbda (x y) (list x y -z)) cm b) -----(~aapcar #' (lambda (a~ my) a(list x y .z)) ~a b) --(aaapcar #' (lanbda (ax my) (alist ax ay z)) c,a b) --(anapcar #'(lasbda (qx qy) (alist qx qy z)) aa b) --= (aaapcar #' (lanbda (qx qy) ~(list *qx *qy -z)) aa b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>(</head><label></label><figDesc>xref '(closure .exp .ear .context .indices) k) =--• (closure .exp .ear .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>get-finite-context (fn arKe) (coerce (reduce #' (laabda (p q) (a(laabda (x y) Y) P cA)) (aapcar #' (laabda (a) (domain (etypecase a (XAPPING a) (CLOSURE (closure-context a))))) (cons fn arks))) • LIST) )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head></head><label></label><figDesc>a(if .p (funcall #' (lastbda (x) (foo x .a)) .z) (funcall #'(lanbda (x) (bar x -b)) -z)) All the calls to the closure that calls foo will occur synchronously, as might be expected, and.similarly for the other clceure. But in the superficially similar expression a(~uncall (t~ -p #' (la.bda (x) (foo x .a)) #' (la,bda (x) (bar x .b)))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head></head><label></label><figDesc>. The general Connection Machine Lisp fl operator has no simple equivalent in'APL. APL has multidimensional arrays and a useful set of operations on them; in Connection Machine Lisp we have thus far represented multidimensional arrays by nesting one-dimensional xappings. (We have considered handling multidimensional arrays by letting an index itself be a xspping: a 2 x 2 identity matrix would then be represented as ([0 0]-.-,1 [0 1]-.0 [1 0]--,0 [1 1]-.-*1}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 (</head><label>2</label><figDesc>continued).</figDesc><table><row><cell>(defun tfpart (kind context)</cell></row><row><cell>(etypecaae context</cell></row><row><cell>((NOT IAPPIIIG) (if context kind (not kind)))</cell></row><row><cell>(CONSTANT-YAPPINg</cell></row><row><cell>(let ((z (ifpart kind (choice context))))</cell></row><row><cell>(and z (-ake-constant-xapping z))))</cell></row><row><cell>(FINITE-ZAPPING</cell></row><row><cell>(let ((z (renove-nils c~(tfpart kind .context))))</cell></row><row><cell>(and (not (empty z)) z)))))</cell></row><row><cell>(def~ merge-results (x y) (xapplng-unlon #'merge-results x y))</cell></row><row><cell>(defun context-filter (value context)</cell></row><row><cell>(if (eq context t) value</cell></row><row><cell>(etypecaee value</cell></row><row><cell>(CLOSURE</cell></row><row><cell>(aake-cloaure (cloeure-exp value)</cell></row><row><cell>(closure-env value)</cell></row><row><cell>~(context-filter *(cloeure-context value) -context)</cell></row><row><cell>(closure-indices value)))</cell></row><row><cell>(XAPPING a(context-filter .value .context)))))</cell></row><row><cell>(defun context-height (context)</cell></row><row><cell>(etypecaee context</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>The elements of xappings may be any Lisp objects; APL array elements must be numbers or characters. Indices of APL vectors are consecutive integers beginning at 0 or 1; the indices of xappings may I)e any Lisp objects, and need not be contiguous. (A xapping with n pairs may be represented as a 2 x n APL matrix, of course, but part of the point of xappings is notational and computational convenience.) Connection Machine Lisp has more expressive control structures, namely those of Lisp. Many of the ideas and specific operations in APL are useful in Connection Machine Lisp</figDesc><table><row><cell></cell><cell></cell><cell cols="2">example,</cell></row><row><cell cols="4">(funcall '[sin cos tan eval] '[0 1 2 Cfoo)])</cell></row><row><cell>causes the calls</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(sin 0)</cell><cell>(cos 1)</cell><cell>(tan 2)</cell><cell>(eval '(foo))</cell></row><row><cell cols="4">to proceed in parallel; this is equivalent in effect to writing</cell></row><row><cell cols="4">(pcall #'xector (sin O) (cos 1) (tan 2) (eval 'Cfoo)))</cell></row><row><cell cols="4">in Multilisp syntax. We have barely begun to explore the expres-</cell></row><row><cell cols="4">sive power and implementation requirements that arke from this</cell></row><row><cell>technique.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">8 Comparisons to Other Work</cell><cell></cell></row><row><cell cols="4">In this section we compare Connection Machine Lisp to seven</cell></row><row><cell cols="2">other programming languages.</cell><cell></cell><cell></cell></row><row><cell cols="4">APL [13,12,8,4]. Connection Machine Lisp xappings have</cell></row><row><cell cols="4">state (can be modified using serf of xref), whereas APL vec-</cell></row><row><cell cols="2">tors are immutable.</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">Acknowledgements</head><p>The term "xapping" was suggested to us by Will Clinger.</p><p>We are grateful for many comments from Michael Berry, Ted Tablceki, and others within Thinking Machines Corporation, and from the referees.</p><p>The ornamentation was taken from a volume of the Dover Pictorial Archive Series: Klimech, Karl. Florid Victorian Orna. ment. Dover Publications (New York, 1977).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Can programming be liberated from the yon Neumann style? A functional style and its algebra of pro. grams</title>
		<author>
			<persName><forename type="first">John</forename><surname>Backus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commvnications of the ACM</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="613" to="641" />
			<date type="published" when="1977">August 1978. 1977</date>
		</imprint>
	</monogr>
	<note>ACM Taring Award Lecture</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The Revised Revised Report on Bcheme; or, An Uncommon Lisp</title>
		<author>
			<persName><forename type="first">William</forename><surname>Clinger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985-06">June 1985</date>
			<pubPlace>Bloomington</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Science Department Technical Report 174. Indiana University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">William</forename><surname>Clinger</surname></persName>
		</author>
		<title level="m">The Revised Revised Report on Scheme; or, An Uncommon Lisp. AI Memo 848. MIT A.rtificial Intelligence Laboratory</title>
		<meeting><address><addrLine>Cambridge, Massachusetts</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1985-08">August 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Development of an APL standard</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Fslkoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Orth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">APL 79 Conference Proceedings. ACM SIG-PLAN/STAPL</title>
		<meeting><address><addrLine>Rochester, New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1979-06">June 1979. June 1979</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="400" to="453" />
		</imprint>
	</monogr>
	<note>Published as APL Quote Quad</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Queuebased multiprocessing Lisp</title>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">P</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Mccarthy</surname></persName>
		</author>
		<idno>ACM SIG- PLAN/SIGACT/SIGART</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. 1984 ACM Syrnpo. sium on Lisp and Functional Programming</title>
		<meeting>1984 ACM Syrnpo. sium on Lisp and Functional Programming<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1984-08">August 1984</date>
			<biblScope unit="page" from="25" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Symmetric Programming Languages</title>
		<author>
			<persName><forename type="first">David</forename><surname>Gelernter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984-07">July 1984</date>
			<pubPlace>New Haven</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Yale University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The Parallel World of S~mmetric Lisp</title>
		<author>
			<persName><forename type="first">David</forename><surname>Gelernter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>London</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985-02">February 1985</date>
			<publisher>Hew Haven</publisher>
		</imprint>
		<respStmt>
			<orgName>Yale University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>Extended abstract</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">APL: An Interactive Approach</title>
		<author>
			<persName><forename type="first">Leonard</forename><surname>Gilman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allen</forename><forename type="middle">J</forename><surname>Rose</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976">1976</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">An exercise in proving parallel programs correct. Commt;nlcotions Of the A CM</title>
		<author>
			<persName><forename type="first">David</forename><surname>Cries</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977-12">December 1977</date>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page" from="921" to="930" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">MultiIisp: a language for concurrent symbolic computation</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">H</forename><surname>Halstead</surname></persName>
		</author>
		<author>
			<persName><surname>Jr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">A CM Transactlo~ on Program. rain 9 Languages and Systems</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="501" to="538" />
			<date type="published" when="1985-10">October 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The Connection Machine</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hill;-</surname></persName>
		</author>
		<author>
			<persName><surname>Daniel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, Massachusetts</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m">APL\$60 User&apos;s Manual International Business Machines Corporation</title>
		<imprint>
			<date type="published" when="1998-08">August 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Kenneth</forename><forename type="middle">E A</forename><surname>Programming Language</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962">1962</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Q&apos;Nia/Reference Manual</title>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">A</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">H</forename><surname>Jenkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nial Systems Limited</title>
		<imprint>
			<date type="published" when="1985-07">July 1985</date>
			<pubPlace>Kingston, Ontario</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The nested rectangular array as a model of data</title>
		<author>
			<persName><forename type="first">Trenchard</forename><surname>More</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">APL 79 Conference Proceedings. ACM SIG-PLAN/STAPL</title>
		<meeting><address><addrLine>Rochester, New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1979-06">June 1979. June 1979</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="55" to="73" />
		</imprint>
	</monogr>
	<note>Published as. Invited address</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Rectangularly arranged collections of collections</title>
		<author>
			<persName><forename type="first">Trenchard</forename><surname>More</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">APL 82 Conference Proceedings. ACM SIG-PLAN/STAPL</title>
		<meeting><address><addrLine>Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1982-06">June 1982. June 1982</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="219" to="228" />
		</imprint>
	</monogr>
	<note>I. Invited address</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Aziomatic Proof Techniques for Par. alld Programs</title>
		<author>
			<persName><forename type="first">Susan</forename><surname>Owicki</surname></persName>
		</author>
		<author>
			<persName><surname>Speer</surname></persName>
		</author>
		<idno>TR 75- 251</idno>
		<imprint>
			<date type="published" when="1975-07">July 1975</date>
			<pubPlace>Ithaca, New York</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Cornell University ; Department of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Compositing digital images</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Duff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH &apos;84 Conference. ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH &apos;84 Conference. ACM SIGGRAPH<address><addrLine>Minneapolis</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1984-07">July 1984. July 1984</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="253" to="260" />
		</imprint>
	</monogr>
	<note>Published as</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Definitional interpreters for higher order programming languages</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">C</forename><surname>Reynolds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM National Confer. ante</title>
		<meeting>ACM National Confer. ante<address><addrLine>Boston, Au</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1972">1972</date>
			<biblScope unit="page" from="717" to="740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Rectangularly arranged collections of collections</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">I</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Jenkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">APL 8~ Conference Proceedings</title>
		<meeting><address><addrLine>Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1982-06">June 1982. June 1982</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="315" to="319" />
		</imprint>
	</monogr>
	<note>APL Quote Quad</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><surname>Ultracomputers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM ~ansaetions on Programming Languages and Systems ~</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="484" to="521" />
			<date type="published" when="1980-10">October 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">Elliot</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Non-Von</forename><surname>The</surname></persName>
		</author>
		<author>
			<persName><surname>Supercomputer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982-08">August 1982</date>
			<pubPlace>New York</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, Columbia University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Guy</forename><forename type="middle">L</forename><surname>Steele</surname></persName>
		</author>
		<author>
			<persName><surname>Jr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">E</forename><surname>Fahlman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">P</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">L Common</forename><surname>Weinreb</surname></persName>
		</author>
		<author>
			<persName><surname>Lisp</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>The Language. Digital Press</publisher>
			<pubPlace>Burlington, Mamachusetts</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Compiler Optimization Based on Viewing LAMBDA as Rename plus Goto. Master&apos;s thesis</title>
		<author>
			<persName><forename type="first">Guy</forename><surname>Steele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jr</forename><surname>Lewis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977-05">May 1977</date>
			<biblScope unit="volume">25</biblScope>
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note>Published ~</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">RABBIT: A Compiler for SCHEME (,4 Study in Compiler Optimization)</title>
		<author>
			<persName><forename type="first">Guy</forename><surname>Steele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jr</forename><surname>Lewis</surname></persName>
		</author>
		<idno>474</idno>
		<imprint>
			<date type="published" when="1978-05">May 1978</date>
			<biblScope unit="volume">24</biblScope>
		</imprint>
		<respStmt>
			<orgName>MIT Artificial Intelligence Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>This is a revised version of the author&apos;s master&apos;s thesk</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The Art of the Interpreter; or</title>
		<author>
			<persName><forename type="first">Guy</forename><surname>Steele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jr</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerald</forename><surname>Smmman</surname></persName>
		</author>
		<author>
			<persName><surname>Jay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Modtdarity Complez (Part* Zero, One, and Two). M Memo 453</title>
		<meeting><address><addrLine>Cambridge, Mamachueetts</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1978-05">May 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The Revised Report on SCHEME: A Dialect of LISP</title>
		<author>
			<persName><forename type="first">Guy</forename><surname>Steele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jr</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerald</forename><surname>Suuman</surname></persName>
		</author>
		<author>
			<persName><surname>Jay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MIT Artificial Intelligence Laboratory</title>
		<imprint>
			<biblScope unit="volume">452</biblScope>
			<date type="published" when="1978-01">January 1978</date>
			<pubPlace>Cambridge, Mas-8achnsetts</pubPlace>
		</imprint>
	</monogr>
	<note>AI Memo</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">SCHEME: An Interpreter for Eztended Lambda Caktdas</title>
		<author>
			<persName><forename type="first">Gerald</forename><surname>Susen~n</surname></persName>
		</author>
		<author>
			<persName><surname>Jay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Steele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jr</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MIT Artificial Intelligence Laboratory</title>
		<imprint>
			<biblScope unit="volume">349</biblScope>
			<date type="published" when="1975-12">December 1975</date>
			<pubPlace>Cambridge, Mamachneetts</pubPlace>
		</imprint>
	</monogr>
	<note>AI Memo</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The semantic elegance of applicative languages</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1981 Conference on Functional Program. ruing Langaages and Computer Architecture. ACM SIG-PLAN/SIGARCH/SIGOPS</title>
		<meeting>1981 Conference on Functional Program. ruing Langaages and Computer Architecture. ACM SIG-PLAN/SIGARCH/SIGOPS<address><addrLine>Portsmouth, New Hampshire</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1981-10">October 1981</date>
			<biblScope unit="page" from="85" to="92" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
