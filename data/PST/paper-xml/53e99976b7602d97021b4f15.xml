<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Active Reranking for Web Image Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2009-11-03">November 03, 2009</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xinmei</forename><surname>Tian</surname></persName>
							<email>xinmei@mail.ustc.edu.cn</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
							<email>dacheng.tao@gmail.com</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Xian-Sheng</forename><surname>Hua</surname></persName>
							<email>xshua@microsoft.com</email>
						</author>
						<author>
							<persName><forename type="first">Xiuqing</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronic Engineering and Information Science</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<postCode>230027</postCode>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Engineering</orgName>
								<orgName type="institution">The Nanyang Techno-logical University</orgName>
								<address>
									<addrLine>50 Nanyang Avenue, Blk N4</addrLine>
									<postCode>639798</postCode>
									<settlement>Singapore</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research Asia</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Microsoft Research Asia</orgName>
								<address>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">the Hong Kong Polytechnic University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Active Reranking for Web Image Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2009-11-03">November 03, 2009</date>
						</imprint>
					</monogr>
					<idno type="MD5">7D2A69F949ABA63A7ADAA9FA5F8468BD</idno>
					<idno type="DOI">10.1109/TIP.2009.2035866</idno>
					<note type="submission">received March 04, 2009; revised October 05, 2009. First</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Active reranking</term>
					<term>local-global discriminative (LGD) dimension reduction</term>
					<term>structural information (SInfo) based active sample selection</term>
					<term>web image search reranking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Image search reranking methods usually fail to capture the user's intention when the query term is ambiguous. Therefore, reranking with user interactions, or active reranking, is highly demanded to effectively improve the search performance. The essential problem in active reranking is how to target the user's intention. To complete this goal, this paper presents a structural information based sample selection strategy to reduce the user's labeling efforts. Furthermore, to localize the user's intention in the visual feature space, a novel local-global discriminative dimension reduction algorithm is proposed. In this algorithm, a submanifold is learned by transferring the local geometry and the discriminative information from the labelled images to the whole (global) image database. Experiments on both synthetic datasets and a real Web image search dataset demonstrate the effectiveness of the proposed active reranking scheme, including both the structural information based active sample selection strategy and the local-global discriminative dimension reduction algorithm.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>"panda" existing in its surrounding text. The other problem is that the textual information is insufficient to represent the semantic content of the images. The same query words may refer to images that are semantically different, e.g., we cannot differentiate an animal panda image from an image for a person whose name is Panda, just with the text word "panda".</p><p>Because the textual information is insufficient for semantic image retrieval, a natural recourse is the visual information. Recently a dozen of image/video reranking methods <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b33">[34]</ref> have been proposed to exploit the usage of the visual information for refining the text-based search result. Most of these reranking methods utilize the visual information in an unsupervised and passive manner. The only exception is the In-tentSearch <ref type="bibr" target="#b5">[6]</ref>, which reorders the text-based search result by using query by example (QBE), with the query image specified by the user from the initial text-based search result.</p><p>Unsupervised reranking methods, e.g., the clustering based algorithm <ref type="bibr" target="#b13">[14]</ref>, the random work <ref type="bibr" target="#b14">[15]</ref>, the VisualRank <ref type="bibr" target="#b16">[17]</ref> and the Bayesian reranking <ref type="bibr" target="#b33">[34]</ref>, can only achieve limited performance improvements. This is because the visual information is insufficient to infer the user's intention, especially when the query term is ambiguous. For example, "panda" can be either an animal or a person whose name is Panda. Without user interactions, we have no idea which kind of panda images are preferred by the user. However, if the user interactions are available, we can learn his/her intention and then rerank the initial search results to achieve a significant performance improvement. For instance, in the query "panda", if the user labels the animal pandas as relevant and other images as irrelevant, different kinds of animal pandas will be returned to the user. In this paper, reranking with user's interactions is named as active reranking. IntentSearch <ref type="bibr" target="#b5">[6]</ref> can be regarded as a simplified active reranking method with only one relevant image labelled by the user.</p><p>In active reranking, the essential problem is how to capture the user's intention, i.e., to distinguish query relevant images from irrelevant ones. Different from the conventional learning problems, in which each sample only has one fixed label, an image may be relevant for one user but irrelevant for another. In other words, the semantic space is user-driven, according to their different intentions but with identical query keywords. Therefore, we propose to target the user-driven intention from two aspects: collecting labeling information from users to obtain the specified semantic space, and localizing the visual characteristics of the user's intention in this specific semantic space, as detailed in Sections I-A and B, respectively.</p><p>Although IntentSearch <ref type="bibr" target="#b5">[6]</ref> can be deemed as a simplified version of active reranking, i.e., the user's intention is defined by only one query image, it cannot work well when the user's intention is too complex to be represented by one image. As shown in Fig. <ref type="figure" target="#fig_0">3</ref>, the query relevant images for "Animal" vary largely both in visual appearance and features, thus we cannot represent "Animal" only with one image. Instead, our proposed active reranking method can learn the user's intention more extensively and completely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Active User's Labeling Information Collection</head><p>To collect the labeling information from users efficiently, a new structural information (SInfo) based strategy is proposed to actively select the most informative query images.</p><p>It is boring and unacceptable to keep asking a user to label a lot of images in the interaction stage. Thus, it is essential to get the necessary information by labeling as few images as possible. Active learning is well-known for reducing the labeling efforts, by labeling most informative samples <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b19">[20]</ref>. Conventional active learning strategies can be divided into two categories: the error reduction strategy <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b42">[43]</ref> and the most uncertain (close-to-boundary) strategy <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b35">[36]</ref>. Both of them suffer from the small sample size problem, i.e., the unreliable estimation of the expected error risk and the uncertainty caused by the insufficient labelled samples.</p><p>In active reranking, however, only a few images will be labelled by a user. To avoid or alleviate the influence of the small sample size problem, our proposed SInfo sample selection strategy considers two aspects: the ambiguity and the representativeness, simultaneously.</p><p>The ambiguity denotes the uncertainty whether an image is relevant or not to the user's intention. Chang et al. <ref type="bibr" target="#b3">[4]</ref> and Wang et al. <ref type="bibr" target="#b35">[36]</ref> have demonstrated the effectiveness of the ambiguity in active learning for image retrieval. However, they are not specified for reranking problem. In this paper, the ambiguity is considered in a more natural way for reranking; it is derived from the ranking scores, which denotes the images' relevance degrees. Besides the ambiguity, the representativeness, another important aspect, is also considered. An image is more representative if it is located in a dense area with many images around it. Labeling a representative sample will bring more information than labeling an isolated one. In active reranking, the representativeness is derived in a totally unsupervised fashion and independent to the learning algorithms, to alleviate the influence of the aforementioned small sample size problem. Experiments on both synthetic data and a real Web image search dataset show that the SInfo is much more effective than other strategies, e.g., the most uncertain strategy and the error reduction strategy, in active reranking for Web image search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Visual Characteristic Localization</head><p>To localize the visual characteristics of the user's intention, we propose a novel local-global discriminative (LGD) dimension reduction algorithm. Basically, we assume that the query relevant images, which represent the user's intention, are lying on a low-dimensional submanifold of the original ambient (visual feature) space. LGD learns this submanifold by transferring both the local geometry and the discriminative information from labelled images to unlabelled ones. The learned submanifold preserves both the local geometry of labelled relevant images and the discriminative information to separate relevant from irrelevant images. As a consequence, we can eliminate the well-known semantic gap between low-level visual features and high-level semantics to further enhance the reranking performance on this submanifold.</p><p>In the past decades, a dozen of dimension reduction algorithms have been proposed, e.g., principal components analysis (PCA) <ref type="bibr" target="#b12">[13]</ref>, transductive component analysis <ref type="bibr" target="#b22">[23]</ref>, locally linear embedding (LLE) <ref type="bibr" target="#b26">[27]</ref>, Discriminant LLE <ref type="bibr" target="#b20">[21]</ref>, ISOMAP <ref type="bibr" target="#b30">[31]</ref>, nonparametric discriminant analysis <ref type="bibr" target="#b28">[29]</ref>, semi-supervised discriminant analysis (SDA) <ref type="bibr" target="#b2">[3]</ref>, biased marginal Fisher's analysis (BMFA) <ref type="bibr" target="#b36">[37]</ref>, locality preserving projections (LPP) <ref type="bibr" target="#b10">[11]</ref>, supervised LPP (SLPP) <ref type="bibr" target="#b1">[2]</ref>, geometric mean for subspace selection <ref type="bibr" target="#b27">[28]</ref>, local discriminant embedding (LDE) <ref type="bibr" target="#b4">[5]</ref>, semantic manifold learning (SML) <ref type="bibr" target="#b21">[22]</ref>, orthogonal Laplacianface <ref type="bibr" target="#b0">[1]</ref>, maximum margin projection (MMP) <ref type="bibr" target="#b9">[10]</ref> and the recently developed correlation metric based methods <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>. However, they are problematic for active reranking in Web image search for the following reasons. Unsupervised methods, e.g., PCA and LLE, exploit a subspace or submanifold on the whole image space but ignore user's labeling information. As a consequent, these algorithms fail to capture the user-driven intentions. Supervised linear algorithms, e.g., LDA <ref type="bibr" target="#b6">[7]</ref> and biased discriminant analysis (BDA) <ref type="bibr" target="#b40">[41]</ref>, learn a subspace on the labelled set so they ignore the submanifold of all relevant images. Supervised manifold learning algorithms, e.g., SLPP and BMFA, cannot transfer the learned submanifold from labelled images to unlabelled images. Although some semi-supervised algorithms, e.g., SML and SDA, have been developed to model both labelled and unlabelled images, they are not designed specifically for active reranking in Web image search. They assume both relevant and irrelevant unlabelled images are drawn from a nonlinear manifold. In Web image search, however, irrelevant images scatter in the whole space, i.e., they may be distributed uniformly, and thus popular manifold regularizations <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b21">[22]</ref> will over-fit to unlabelled images. As a consequence, the performance obtained by popular semi-supervised learning algorithms is poor. This paper presents a new algorithm to target user's intention. Preliminary experimental results on both synthetic data and a real Web image search dataset demonstrate the effectiveness of the proposed LGD.</p><p>The rest of the paper is organised as follows. Firstly, we introduce the overall framework for active reranking in Section II. The SInfo active sample selection strategy is detailed in Section III and the LGD dimension reduction algorithm is presented in Section IV. In Section V, the basic Bayesian reranking algorithm is briefly introduced and the overall procedure of active reranking based on it is given. Experimental results on synthetic datasets and a real Web image search dataset are reported in Section VI and Section VII, respectively. In Section VIII, we give some analysis to the important parameters in SInfo and LGD, followed by the conclusion in Section IX.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. ACTIVE RERANKING FOR WEB IMAGE SEARCH</head><p>Fig. <ref type="figure" target="#fig_2">1</ref> shows the proposed general framework for active reranking in Web image search. Take the query term "panda" as an example. When "panda" is submitted to the Web image search engine, an initial text-based search result is returned to the user, as shown in Fig. <ref type="figure" target="#fig_2">1</ref>(a) (only the top nine images are given for illustration). This result is unsatisfactory because both person and animal images are retrieved as top results. This is Fig. <ref type="figure" target="#fig_2">1</ref>. Framework for active reranking illustrated with the query "panda". When the query is submitted, the text-based image search engine returns a coarse result (a). Then the active reranking process is adopted to obtain a more satisfactory result (b), by learning the user's intention.</p><p>caused by the ambiguity of the query term. Without the user interactions, it is impossible to eliminate this ambiguity. In particular, which kind of images, animal panda or person whose name is Panda, are user's intention? Therefore, traditional reranking methods, which improve the initial search results by only utilizing the visual property of images, cannot achieve good performances.</p><p>To solve this problem, active reranking, i.e., reranking with user interactions, is proposed. As shown in Fig. <ref type="figure" target="#fig_2">1</ref>, four images are first selected according to an active sample selection strategy, and then the user is required to label them. If the user labels the animal pandas as query relevant (indicated by " " in Fig. <ref type="figure" target="#fig_2">1</ref>) and other two images (person, car) as query irrelevant. Then we can learn that the animal panda is the user's intention. To represent this intention, i.e., the animal panda, a discriminative submanifold should be exploited to separate query relevant images from irrelevant ones. A dimension reduction step is thus introduced to localize the visual characteristics of the user's intention.</p><p>With the knowledge of the user's intention, including both the labeling information and the learned discriminative submanifold, the reranking process is conducted and different kinds of animal pandas are returned, as shown in Fig. <ref type="figure" target="#fig_2">1(b</ref>). Sometimes, several interaction rounds are preferred to achieve a more satisfactory performance.</p><p>In summary, there are two key steps in learning the user's intention, i.e., the active sample selection strategy and the dimension reduction algorithm. This paper implements these two steps via a new SInfo sample selection strategy and a novel LGD dimension reduction algorithm, as will be discussed in Sections III and IV, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SINFO ACTIVE SAMPLE SELECTION</head><p>An SInfo active sample selection strategy is presented to learn the user's intention efficiently which selects images by considering not only the ambiguity but also the representativeness in the whole image database. Ambiguity and representativeness are two important aspects in active sample selection. Labeling a sample which is more ambiguous will bring more information. On the other side, the information provided by individual sample can be shared by its neighbors. Therefore, the more representative samples are preferred for labeling. In SInfo, the ambiguity of an image is measured by the entropy of the relevance probability distribution while the representativeness is measured by the density.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Ambiguity</head><p>The ambiguity denotes the uncertainty whether an image is relevant or not. It can be estimated via various sophisticated learning methods, e.g., support vector machine (SVM) <ref type="bibr" target="#b34">[35]</ref>, transductive SVM (TSVM) <ref type="bibr" target="#b17">[18]</ref> and the harmonic Gaussian filed method <ref type="bibr" target="#b41">[42]</ref>, by conducting a binary classification task.</p><p>However, in active reranking, it is direct and reasonable to measure the ambiguity with the ranking scores obtained in the reranking process. There are two reasons. One reason is that the reranking problem is essentially different from classification <ref type="bibr" target="#b33">[34]</ref>, thus the ambiguity estimated via conducting classification task may be not as accurate as that directly derived in reranking process. The other reason is that additional cost will be introduced if the ambiguity is estimated via other learning methods. In contrast, measuring ambiguity through the ranking scores avoids this additional cost.</p><p>For an image is its ranking score, where means is definitely query relevant, while means is totally irrelevant. and can be regarded as the probability of to be relevant and irrelevant respectively. Then the ambiguity can be measured via the information entropy, which is a widely used measurement in the information theory. The ambiguity of is <ref type="bibr" target="#b0">(1)</ref> Because the reranking is conducted based on the initial textbased search result <ref type="bibr" target="#b33">[34]</ref>, the ambiguity in the initial text-based search result should also be taken into account, i.e., <ref type="bibr" target="#b1">(2)</ref> where is the initial text-based search ranking score for .</p><p>By combining (1) and ( <ref type="formula">2</ref>), the total ambiguity for is <ref type="bibr" target="#b2">(3)</ref> where is a trade-off parameter to control the influence of the two ambiguity terms. Fig. <ref type="figure">2</ref>. Because "A" and "B" have the same distance to the hyper-plane (dashed line), they have an identical ambiguity. However, the more representative sample "A" is more preferable to "B".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Representativeness</head><p>Besides the ambiguity, representativeness, an important property but not well studied before, is also taken into account. Apart from the unreliable estimation led by insufficient labelled images, the ambiguity measures the importance of the image itself only. Once the Web image search system gets the labeling information of an image, it is very important to consider how many other images can share the labeling information with the labelled one. For example, given two unlabelled samples with the identical ambiguity, labeling the more representative one, i.e., many samples are distributed around it, will bring more information and achieve a better reranking performance.</p><p>To explain this, a simple synthetic dataset is shown in Fig. <ref type="figure">2</ref>. There are two labelled samples (a big "*" for the query relevant sample while a big "o" for the query irrelevant one) and several unlabelled ones (marked with black big dot "."). These six samples distribute along a line and the coordinates on the horizontal axis denote their positions. By using SVM <ref type="bibr" target="#b34">[35]</ref>, the classification hyper-plane , which separates the two labelled sample with the largest margin, crosses position 0 as shown in Fig. <ref type="figure">2</ref> with the dashed line. According to the most uncertainty criteria, i.e., the samples closest to having the maximum ambiguity, we can get that "A" and "B" have the maximum and identical ambiguity because they have the same distance, i.e., 0.4 for both, to the hyper-plane. However, if we can choose only one sample for labeling, it is better to label "A" than "B" because more unlabelled samples will share the labeling information of "A".</p><p>To avoid the small sample size problem in active sample selection, the representativeness can be estimated in an unsupervised manner. Intuitively, labeling an image in a dense area will be more helpful than labeling an isolated one because the labeling information of the image can be shared with other surrounding images. As a consequence, we can measure the representativeness of image via the probability density , which can be estimated by using the kernel density estimation (KDE) <ref type="bibr" target="#b25">[26]</ref> (4) where is the set of neighbors of . is the visual feature for image .</p><p>is a kernel function that satisfies both and . The Gaussian kernel is adopted in this paper. For the synthetic dataset in Fig. <ref type="figure">2</ref>, the estimated representativeness is given by the curve .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Active Sample Selection</head><p>Since the most informative images should meet both ambiguity and representativeness simultaneously, the structural information of image , can be measured by the product of the two terms, i.e., Then the most informative image is selected from the unlabelled image set according to <ref type="bibr" target="#b4">(5)</ref> In practical applications, to provide a good user experience, it would be better to ask users to label a small number of images than only one image in each round. This is because users will lose their patience after a few rounds. Thus, the batch mode is utilized to select several images in each round. A simple method is to select the top-most informative images. The disadvantage of this method is that the selected images may be redundant and cluster in a small area in the high-dimensional feature space. Thus, we seek to select a batch of most informative images and maintain their diversity at the same time.</p><p>The angle-diversity criterion <ref type="bibr" target="#b3">[4]</ref> is a good choice to achieve this purpose. This criterion iteratively selects images which are most informative and also be diverse to the already selected image set . For an unlabelled image , the diversity between and is measured by the minimal angle between and each image . Then, the images are selected iteratively according to <ref type="bibr" target="#b5">(6)</ref> where is a trade-off parameter which is introduced to balance the effects of the two components: the structural information and the angle-diversity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. LGD DIMENSION REDUCTION</head><p>In reranking, the images returned for a certain query term are represented by low-level visual features, i.e., with the -dimensional visual feature for image . The performance of reranking is usually poor because of the gap between the low-level visual features and high-level semantics.</p><p>With user interactions, this semantic gap can be reduced significantly. By mining user's labeling information, we can learn a submanifold to encode the user's intention. This submanifold is embedded in the ambient space, i.e., the high-dimensional visual feature space . In this paper, a linear subspace is used to approximate this submanifold and then the images can be represented as with for image . By using , an improved reranking performance can be further obtained.</p><p>This paper presents an LGD dimension reduction algorithm to learn such a .</p><p>LGD considers both the local information contained in the labelled images and the global information of the whole image database simultaneously. In detail, LGD transfers the local information, including both the local geometry of the labelled relevant images and the discriminative information in the labelled images, to the global domain (the whole image database). This cross domain transfer process is completed by building different local and global patches for each image, and then aligning those patches together to learn a consistent coordinate. One patch is a local area formed by a set of neighboring images. We have three types of images: labelled relevant, labelled irrelevant, and unlabelled. Therefore, we build 3 types of patches, which are: 1) local patches for labelled relevant images to represent the local geometry of them and the discriminative information to separate relevant images from irrelevant ones, 2) local patches for labelled irrelevant images to represent the discriminative information to separate irrelevant images from relevant ones, and 3) global patches for both labelled and unlabelled images for transferring both the local geometry and the discriminative information from all labelled images to the unlabelled ones.</p><p>For convenience, we use superscript " " to denote the labelled relevant images and " " to denote the labelled irrelevant ones. If there is no superscript, it refers to an arbitrary image which may be labelled relevant, labelled irrelevant or unlabelled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Local Patches for Labelled Relevant Images</head><p>BDA, a popular dimension reduction algorithm for image retrieval, assumes that all query relevant samples are alike while each irrelevant sample is irrelevant in its own way <ref type="bibr" target="#b40">[41]</ref>. Thus, the relevant samples are required to be close to each other in the projected subspace. However, this assumption is usually unreliable in Web image search.</p><p>The query relevant samples may vary in appearance and corresponding visual features. For example, in query "animal", query relevant images are different from each other, as shown in Fig. <ref type="figure" target="#fig_0">3</ref>. For this reason, instead of requiring relevant images to be close to each other in the projected subspace, it is more proper to remain the local geometry of the relevant images while separating relevant images from all irrelevant ones. Therefore, the local patch for a labelled relevant image should preserve both the local geometry of relevant images and the discriminative information between the relevant images and all irrelevant images. This paper models the local patch for the low-dimensional representation of the labelled relevant image as <ref type="bibr" target="#b6">(7)</ref> are 's nearest neighbors in the labelled relevant image set " ", and The are its nearest neighbors in the labelled irrelevant image set " ". The combination coefficient is a trade-off factor between the two parts.</p><p>The first part in ( <ref type="formula">7</ref>) is used to preserve the local geometry of labelled relevant images before and after projection, thus the linear combination coefficient vector is required to reconstruct from its neighboring relevant images with minimal error (8) Solving problem <ref type="bibr" target="#b7">(8)</ref>, we can get with the local gram matrix . To rewrite <ref type="bibr" target="#b6">(7)</ref> in a more compact form, we consider its two parts separately. For the first part, which models the local geometry of relevant images <ref type="bibr" target="#b8">(9)</ref> where and with .</p><p>The second part models the discriminative information for separating relevant image from all irrelevant ones, i.e., <ref type="bibr" target="#b9">(10)</ref> where and</p><p>.</p><p>By combining ( <ref type="formula">9</ref>) and ( <ref type="formula">10</ref>) together into (7), we have</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Local Patches for Labelled Irrelevant Images</head><p>Discriminative information is also partially encoded in all irrelevant images, so we construct local patches for labelled irrelevant images by separating each irrelevant image from all relevant images. Because each irrelevant image is irrelevant in its own way, it could be unreasonable to keep the local geometry of the irrelevant images. In this paper, we model the local patch for the low-dimensional representation of labelled irrelevant image as <ref type="bibr" target="#b10">(11)</ref> The is 's nearest neighbors in the labelled relevant image set " ". The matrix can be calculated in the way similar to that of computing in ( <ref type="formula">10</ref>) by setting and .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Global Patches for All Images</head><p>In active reranking, users would like to label only a small number of images, so it is lavish and unreasonable to abandon a large number of unlabelled images. With only the labelled images, the learned subspace will bias to that spanned by these labelled images and cannot generalize well to the large amount of unlabelled data. Therefore, some semi-supervised methods have been proposed which also take the unlabelled images into utilization. However, because only relevant images are lying on an unknown manifold and the distribution of irrelevant images is nearly flat, conventional manifold regularizations which assume both relevant and irrelevant samples are drawn from unknown manifolds prone to over-fit to unlabelled samples. As a consequence, another method will be considered in this paper to model unlabelled images in active reranking.</p><p>To make use of both the labelled and unlabelled images, the most important thing is to exploit the information contained in them. Inspired by the main idea in the cross domain learning <ref type="bibr" target="#b15">[16]</ref> and the transfer learning <ref type="bibr" target="#b31">[32]</ref>, in this paper, we introduce the global patches to both labelled and unlabelled images. The global patches transfer the local geometry and the discriminative information, which is exploited in the domain of labelled images, to the domain of unlabelled images. With the global patches, we aim to preserve the principal subspace to keep the submanifold of relevant images. The noise information contained in the ambient space should be eliminated. The principal component analysis (PCA) is a suitable choice, which maximizes the mutual information between the ambient space and the corresponding projected subspace <ref type="bibr" target="#b12">[13]</ref>. Another reason for us to use PCA here is the rule of Occam's razor <ref type="bibr" target="#b23">[24]</ref>, i.e., the utilization of PCA is helpful to avoid the over-fitting caused by using conventional manifold regularizations.</p><p>To illustrate the advantage of global patches for dimension reduction, a synthetic example is shown in Fig. <ref type="figure" target="#fig_1">4</ref>. Fig. <ref type="figure" target="#fig_1">4</ref>(a) shows the synthetic 3-D dataset and its projection on the 2-D planes for a nice view. In this dataset, there are 8 labelled samples, 4 relevant and 4 irrelevant, accompanied with abundant unlabelled samples. The relevant samples are all marked by "*", with big red "*" for the 4 labelled relevant samples and small black "*" for the unlabelled relevant ones. The irrelevant samples are marked by "o", where big blue "o" and small green "o" denote the labelled and unlabelled irrelevant samples respectively. The irrelevant samples scatter in the space and the relevant images are distributed on a manifold approximately.</p><p>We have tried many different dimension reduction algorithms and the results are illustrated in Fig. <ref type="figure" target="#fig_1">4(b)-(k)</ref>. For each dimension reduction algorithm, we have computed the projection plane (the upper part of subfigure) and the projected 2-D data (the lower part of subfigure). With these conventional algorithms, the relevant and irrelevant samples are overlapped in the projected subspace and the submanifold of the relevant samples is not well preserved, as illustrated in the figure. This is caused by the problems existing in these algorithms as aforementioned.</p><p>To avoid these problems, the proposed LGD learns the submanifold by transferring both the local geometry and the discriminative information from labelled samples to all unlabelled samples. Global patches are built for each sample (including both labelled and unlabelled) to complete the cross domain knowledge transferring process. According to the alignment scheme in <ref type="bibr" target="#b39">[40]</ref>, the global patch for the low-dimensional representation of the image is modeled in a similar way to local patches <ref type="bibr" target="#b11">(12)</ref> where is the centroid of the projected low-dimensional feature. Here we use a variant version of the original definition of PCA to achieve a formula-level consistency for both local and global patches.</p><p>We rewrite <ref type="bibr" target="#b11">(12)</ref> as where with are the rest images beyond , vector and . By combining both local and global patches, LGD approximates the intrinsic submanifold of relevant samples, as shown To investigate the effectiveness of the PCA based global patches, we replace them with LPP based patches, which are built in a similar way for each sample. We name this LPP based LGD as LGD-LPP and show its performance in Fig. <ref type="figure" target="#fig_1">4(e)</ref>. This result is unsatisfactory because LPP assumes there is a manifold for both labelled and unlabelled samples which violates the true distribution of irrelevant samples. On the other hand, by using PCA based global patches, the subspace with maximum variance is preserved, so manifold structure of relevant samples can also be preserved. By integrating global patches and local patches, we can discover the intrinsic submanifold of relevant samples, and separate relevant samples from irrelevant samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Patch Coordinate Alignment</head><p>Each patch has its own coordinate system. With the calculated local and global patches, we can align them together into a consistent coordinate. For each image can be rewritten as , where and is the selection matrix. The is defined according to <ref type="bibr" target="#b37">[38]</ref>- <ref type="bibr" target="#b39">[40]</ref> as where is the index vector for samples in .</p><p>Then, we can combine all the patches defined in ( <ref type="formula">7</ref>), <ref type="bibr" target="#b10">(11)</ref>, and (12) together <ref type="bibr" target="#b12">(13)</ref> where and is a control parameter.</p><p>By imposing , the projection matrix can be obtained by solving the standard eigendecomposition problem <ref type="bibr" target="#b13">(14)</ref> where is consisting of the eigenvectors corresponding to the largest eigenvalues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. BAYESIAN RERANKING</head><p>To verify the effectiveness of the proposed active reranking method, we apply the SInfo active sample selection strategy and the LGD dimension reduction algorithm to reranking. Both SInfo and LGD are general and can be directly applied to various reranking algorithms, e.g., VisualRank <ref type="bibr" target="#b16">[17]</ref>. In this paper, we take the Bayesian reranking <ref type="bibr" target="#b33">[34]</ref> as the basic reranking algorithm for illustration.</p><p>We first give a brief introduction for Bayesian reranking. In this method, reranking is explicitly formulated into a global timization problem. The optimal reranked score list is obtained by minimizing the following energy function: <ref type="bibr" target="#b14">(15)</ref> where is the initial text search score list, is a trade-off parameter and is a graph which is constructed with nodes being the images and the weights being their visual similarities, and is the regularizer, which will be detailed below.</p><p>The two terms on the right hand side of (15) correspond to two assumptions, i.e., the visual consistency and the ranking consistency, respectively. The first term, i.e., the regularization term, penalizes the ranking score inconsistency within visually similar samples. The second term is the ranking distance term which penalizes the derivation of the reranked results from the initial text-based search results.</p><p>For the regularization term, the local kernel is adopted <ref type="bibr" target="#b15">(16)</ref> where is the local kernel matrix <ref type="bibr" target="#b32">[33]</ref>. A point-wise distance is adopted for the ranking distance <ref type="bibr" target="#b16">(17)</ref> With ( <ref type="formula">16</ref>) and ( <ref type="formula">17</ref>), we obtain where with . Then, a closedform solution for is given by ( <ref type="formula">18</ref>)</p><p>When applying the Bayesian reranking for active reranking, modifications will be made to incorporate the new obtained information, i.e., the images' labels obtained from SInfo and the effective feature learned via LGD. For a labelled image, its is set as its ground truth label ("1" for relevant and "0" for irrelevant) and large (set as 100 in this paper) is adopted to ensure equal or very close to its ground truth label. The graph is built with the learned to model the visual consistency precisely.</p><p>In active reranking, at the very beginning, the Bayesian reranking is performed in the original feature space without labelled images. Then, with the derived , SInfo is conducted to select informative images for labeling. By interacting with the user, the labels of these images are obtained with which the effective feature is learned via LGD. With the latest labelled image set as well as , Bayesian reranking is performed to derive a new . The final reranking result is obtained by sorting the images according to in a descending order.</p><p>Usually, several interaction rounds are performed to achieve a satisfactory performance. Therefore, in next interaction round, SInfo and LGD are performed with the new obtained in the last round. The overall procedure of our active reranking is summarized as follows: The initial ranking score list was set randomly since we had no textual information to simulate the text-based search process. At the beginning stage, one relevant and one irrelevant sample were randomly selected as the labelled set and the rest were taken as the unlabelled. The initial reranked results ["RerankInitial" curve in Fig. <ref type="figure" target="#fig_3">5</ref> (bottom)] were obtained by reranking without user interactions. Parameters in each method were determined empirically in this paper to achieve its best performance.</p><p>In each interaction round, only one sample was selected for labeling. For each dataset, we have given the reranked results after 4 interaction rounds with different active sample selection strategies. We performed 100 random trials and showed the averaged performance, measured by the widely used noninterpolated Average Precision (AP) <ref type="bibr" target="#b29">[30]</ref>. The AP averages the precision values obtained when each relevant image occurs.</p><p>We compared SInfo with other three sample selection strategies, i.e., "Error Reduction" <ref type="bibr" target="#b42">[43]</ref>, "Most Uncertain" <ref type="bibr" target="#b3">[4]</ref> and "Random". In "Most Uncertain", the most ambiguity samples are selected for interaction according to (3). While in "Random", the query samples are selected randomly. The comparison results, as shown in Fig. <ref type="figure" target="#fig_3">5</ref> (bottom), demonstrate that the proposed strategy outperforms the rival methods consistently on all three datasets. This is because "Error Reduction" and "Most Uncertain" suffer from the small sample size problem. SInfo is more robust because it takes both ambiguity and representativeness into consideration, and thus alleviates the influence of the small sample size problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. EXPERIMENTS ON WEB IMAGE SEARCH DATASET</head><p>We also conducted experiments on a real Web image search dataset. In this dataset, there are 105 queries selected seriously from a commercial image search engine query log as well as popular tags of Flickr. These queries cover a large range of topics, including named person, named object, general object and scene. For each query, a maximum of 1 000 images returned by commercial image search engines, i.e., Google, Live and Yahoo, were collected as the initial text-based search results. This dataset contains 94 341 images in total. For each query, three participants were asked to judge whether the returned images are query relevant or irrelevant. An image is labelled as query relevant if at least two of the three participants judged it as relevant, and vice versa.</p><p>Images are represented by 428-D low-level visual features, including 225-D color moment in LAB color space, 128-D wavelet texture as well as 75-D edge distribution histogram. For the initial text search score list , because images are all downloaded from Web search engines (e.g., Google, Live and Yahoo), we only know ranks of images in the text-based search and their scores are not available. According to <ref type="bibr" target="#b13">[14]</ref>, the normalized rank is adopted as the pseudo score, for the th ranked image, where and is the number of images returned by the Web search engine for a query term.</p><p>For active sample selection, five images were selected to interact with the user in each interaction round and four rounds were considered. Therefore, for each query, there were 20 images labelled by the user totally. The performance is also measured by average precision (AP) <ref type="bibr" target="#b29">[30]</ref>. We calculated the APs at different positions from top-1 to top-100 to obtain the AP curve. We averaged the APs over all the 105 queries to get the mean average precision (MAP) for overall performance evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Active Reranking With SInfo</head><p>In this section, we will investigate the effectiveness of SInfo sample selection strategy and compare it with other three methods: "Error Reduction" <ref type="bibr" target="#b42">[43]</ref>, "Most Uncertain" <ref type="bibr" target="#b3">[4]</ref>, and "Random." To be noted, here both the reranking and the active sample selection were conducted in the original feature space. The effectiveness of the LGD dimension reduction algorithm will be discussed in Section VII-B, in comparing with other representative ones.</p><p>Fig. <ref type="figure" target="#fig_4">6</ref> summarizes the comparison results. The "Baseline" curve gives the performance of the text-based search results and the "RerankInitial" curve is the performance of the unsupervised reranking without user interactions. The "SInfo", "Error Reduction", "Most Uncertain", and "Random" curves denote the performances of the reranked results with query images selected according to these four strategies respectively. Fig. <ref type="figure" target="#fig_4">6</ref> shows the effectiveness of the proposed active reranking framework as well as the superiority of the proposed SInfo sample selection strategy. Curves in this figure show that user's labeling information helps enhance the reranking performance. User interactions can improve the average performance, no matter which sample selection strategy is adopted. Moreover, among these four strategies, SInfo performs best and achieves a significant performance improvement. This is because SInfo considers both the ambiguity and the representativeness while the "Most Uncertain" and "Random" only take one side of them into account. For "Error Reduction" and "Most Uncertain", they both suffer from the small sample size problem while our method alleviates this influence by taking representativeness into account in an unsupervised manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Active Reranking With LGD</head><p>To test the effectiveness of LGD discussed in Section IV, we conducted the active reranking in the projected subspace by using different dimension reduction algorithms. The SInfo sample selection strategy was adopted in this experiment.</p><p>We compared LGD with several representative algorithms, including unsupervised algorithm, i.e., PCA <ref type="bibr" target="#b12">[13]</ref>, supervised ones, i.e., BDA <ref type="bibr" target="#b40">[41]</ref>, LDE <ref type="bibr" target="#b4">[5]</ref> and SLPP <ref type="bibr" target="#b1">[2]</ref>, as well as semi-supervised ones, i.e., SML <ref type="bibr" target="#b21">[22]</ref>, SDA <ref type="bibr" target="#b2">[3]</ref> and LGD-LPP. The subspace dimension was set to 100 for all algorithms empirically. Fig. <ref type="figure">7</ref> shows the results. The "SInfo" curve denotes the reranked results of active reranking which is conducted in the original feature space without dimension reduction with the samples selected via SInfo. This curve is identical to the "SInfo" curve in Fig. <ref type="figure" target="#fig_4">6</ref>. The performance of reranking via different dimension reduction algorithms is denoted as SInfo+DR algorithm name, e.g., "SInfo LGD" for performance of LGD. Fig. <ref type="figure">7</ref> shows that LGD performs best among these algorithms and achieves a more satisfactory performance than "SInfo". It reflects the effectiveness of LGD in localizing the visual characteristics of the user intention. For the other dimension reduction algorithms, reranked performances are either slightly improved or dramatically decreased. PCA fails to capture the user-driven intention since it ignores the labeling information. BDA, LDE, and SLPP, which are all supervised dimension reduction algorithms, only utilize a few labelled images. Thus, the subspace learned by them is biased to that spanned by several labelled images and cannot generalize well to the large amount of unlabelled ones.</p><p>For semi-supervised algorithms, SDA is unsuitable for the reranking task because it assumes that images in an identical class are sampled from a Gaussian. However, in Web image search, each irrelevant image is irrelevant in its own way and thus images in the irrelevant class are not similar to each other, i.e., it is inconvenient to assume that irrelevant images are from an identical Gaussian. Therefore, SDA performed poorly. SML assumes that all images are sampled from a nonlinear manifold. In image search, irrelevant images usually scatter in the whole space, i.e., they may be distributed uniformly. SML is prone to over-fit to unlabelled images because of the improper manifold regularization assumption. To justify this point, we replaced the Laplacian regularization in SML with the global patches in LGD. This method is denoted as SML-PCA. The experimental results of SML-PCA with varying trade-off parameter (controls the influence of global patches) are given in Fig. <ref type="figure">8</ref>. The figure shows that SML-PCA performs much better than SML, but not as well as LGD. The result of LGD-LPP further confirms that improper manifold regularization is harmful. In contrast with them, the proposed LGD duly learned the submanifold of the relevant images and overcome the difficulties discussed above by preserving the local geometry of the labelled relevant images through local patches and the global structure of the whole image set via global patches. In Figs. <ref type="bibr" target="#b18">19</ref> and 20, we further illustrate the active reranked results on queries "George W. Bush" and "zebra". For each query, the top-20 ranked images are shown for both the text-based search result and the active reranked result. For a nice view, we mark the query irrelevant images appeared in the result with cross " ". These figures show that the proposed active reranking method is effective to target user's intention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. LGD With Random Sample Selection</head><p>In Section VII-B, we have shown that, when samples are selected via SInfo, the performance of reranking conducted in the original feature space, i.e., the "SInfo" curve in Fig. <ref type="figure">7</ref>, is consistently improved when LGD is utilized. As illustrated in Fig. <ref type="figure">7</ref>, "SInfo+LGD" performed better than "SInfo". To verify the sensitivity of LGD to sample selection strategy, we further conducted experiments for LGD when samples were randomly selected. The experimental results are given in Fig. <ref type="figure" target="#fig_6">9</ref>, in which the result of LGD with SInfo is also given for comparison. From this figure, we can see that "Random LGD" outperforms "Random" and "SInfo+LGD" outperforms "SInfo". It demonstrates the robustness of LGD to varying sample selection strategies. Further comparing the performance of LGD with "Random" and "SInfo", we can see that "SInfo LGD" achieves better performance than "Random+LGD". This is because more informative samples are selected in "SInfo" and thus with which LGD can learn the user intentions more effectively. In other words, a better active sample selection algorithm can bring more benefits to LGD. This phenomenon shows that both sample selection and dimension reduction are important for active reranking and thus should be elaborately developed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. PARAMETER SENSITIVITY</head><p>In this section, we analyse the sensitivity of important parameters in SInfo and LGD for active reranking. The analyses are performed based on the experiments conducted on the Web image search dataset. The experiments are conducted with SInfo active sample selection and LGD dimension reduction, if not explicitly stated otherwise. We first analyse some important fac- tors: in (3) for SInfo, in <ref type="bibr" target="#b6">(7)</ref> and in <ref type="bibr" target="#b12">(13)</ref> for LGD. And then we investigate the influence of the interaction rounds of active sample selection and the dimension of the projected feature in LGD. The mean AP averaged over AP@1 to AP@100 is utilized for overall performance evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Evaluation on Ambiguity Trade-Off Parameter</head><p>The in (3) plays an important role in balancing the ambiguity estimation, which is one of the two critical aspects in SInfo. With close to 1, the ambiguity is derived entirely from the reranked result and the ambiguity contained in the text search prior is ignored. Fig. <ref type="figure" target="#fig_7">10</ref> shows the performance of SInfo subject to different . In this experiment, the reranking is conducted in the original feature. The "RerankInitial", i.e., reranking without user interactions, is also given for comparison, denoted by the solid line in Fig. <ref type="figure" target="#fig_7">10</ref>. Fig. <ref type="figure" target="#fig_7">10</ref> shows that the performance of SInfo increases when growing and arrives at the peak with . This value is close to the best setup for the text search prior that have been reported in other applications which is around 0.85 <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b16">[17]</ref>. By further comparing with "RerankInitial", we can see that SInfo outperforms it consistently no matter which is adopted. It illustrates the effectiveness of SInfo for reranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evaluation on Local Patch Trade-Off Parameter</head><p>We also investigated the influence of the trade-off parameter in <ref type="bibr" target="#b6">(7)</ref> for LGD when building the local patch for labelled relevant images. A large reflects the importance of separating irrelevant samples from relevant ones, i.e., the discriminative information, with less attention given to the local geometry of relevant images. Fig. <ref type="figure" target="#fig_2">11</ref> shows the performance of LGD with different , from which we can have the following observations.</p><p>• When is small, e.g., less than 0.3, the performance is unsatisfactory and even worse than "SInfo" (solid line in Fig. <ref type="figure" target="#fig_2">11</ref>). This is because that in this situation the local geometry within labelled relevant images is mainly preserved while important discriminative information is less considered. This phenomenon reveals the importance of the dis- criminative information contained in the labelled relevant and irrelevant images. • The performance of LGD increases when growing and reaches the optimal value at . However, the AP decreases when larger than this best setup and gives a steady performance when in which case the discriminative information dominates the local patch and the local geometry is ignored. Therefore, both the local geometry and the discriminate information reflect the information contained in local patches from different aspects for complimentary. A suitable combination of them is essential to achieve a good performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Evaluation on Local-Global Patch Trade-Off Parameter</head><p>Both the local and global patches reflect data information from different aspects. To investigate the contributions of these two parts, we have tested the performance of LGD with different trade-offs . When , only local patches are utilized. When , only global patches are involved and LGD degrades to PCA in this case. A proper is demanded to balance them. According to our empirical comparisons, the best setup for is 0.03, as shown in Fig. <ref type="figure" target="#fig_2">12</ref>. The solid line in this figure indicates the performance of "SInfo", i.e., reranking in the original feature space without dimension reduction. Fig. <ref type="figure" target="#fig_2">12</ref> shows that LGD outperforms it consistently with various and LGD is robust.</p><p>As shown in Fig. <ref type="figure" target="#fig_2">12</ref>, the improvement of LGD over PCA occurs in a range of [0.01, 0.05] for . This range seems to be a little narrow. However, it is worth emphasizing that only a small part of images (around % in experiments, half for relevant and half for irrelevant images) are labelled. As a consequence, the number of global patches is much more than that of the labelled relevant and irrelevant patches. After eliminating issue of the patch number imbalance, the range for is moderate, i.e., it is around [1.0, 5.0].</p><p>For the comparison between LGD and PCA, in Fig. <ref type="figure" target="#fig_2">12</ref>, we only give the overall performance of mean AP averaging over top-1 to top-100 ranked images. We refer the reader back to Fig. <ref type="figure">7</ref> for sufficient details. Fig. <ref type="figure">7</ref> shows that LGD outperforms PCA consistently on top-1 to top-100 ranked images. It is worth emphasizing that it is very difficult to improve the baselines for Web data based applications and 1% improvement is usually acknowledged, e.g., TRECVID <ref type="bibr" target="#b18">[19]</ref>. The top-20 images are important in Web search because they are displayed on the first page and dominant the user's evaluation of the search results. Comparing with PCA, much more improvements are obtained by LGD, i.e., LGD finds at least one more relevant image for top-20 ranked images every five runs. This is practically significant. Fig. <ref type="figure" target="#fig_2">13</ref> shows the average performance of LGD versus PCA over top-1 to top-20, top-21 to top-40, top-41 to top-60, and top-1 to top-60 ranked images, which corresponds to the first 3 pages of results (assuming 20 images are displayed on each page). LGD improves PCA consistently.</p><p>Besides the AP, another evaluation criterion <ref type="bibr" target="#b16">[17]</ref> is also introduced for performance evaluation. It is the average number of irrelevant images per query among the top-k ranked results. Fig. <ref type="figure" target="#fig_2">14</ref> illustrates the statistical results. Among the top-20 ranked images, LGD gives an average of 2.26 irrelevant results and represents about 10 percent drop, compared with the 2.51 obtained by SInfo. However, PCA gives 2.50 irrelevant results which are very close to that given by SInfo. For overall evaluation, compared with SInfo, LGD shows about 10% drop consistently while PCA only gives less than 5%.</p><p>Finally, considering the complexity of Web images (collected from varying sources, taken from different viewpoints, with different size, qualities/resolutions and complex backgrounds, and high diversity), this improvement is practically acceptable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Evaluation on Number of Interaction Rounds for Active Sample Selection</head><p>More labelled images will bring more information and thus a better performance can be achieved. However, users usually lose their patience after a few interaction rounds. Therefore, it is important to find out a good trade-off between the reranking performance and the number of the interaction rounds. In this experiment, we investigated the performance of reranking with interaction rounds varying from 1 to 20. In each round, 5 images are selected via SInfo for labeling. LGD is adopted to learn the effective subspace for reranking.</p><p>The experimental results are illustrated in Fig. <ref type="figure" target="#fig_3">15</ref>. Zero interaction round means that the reranking conducted without user interactions, i.e., the "Reranking Initial". When interaction round increases from 0 to 4, the performance receives dramatic improvements steadily. However, when more interactions are performed, the performance increases slowly and even shows slightly decreasing at certain rounds. As a consequence, reranking with 4 interaction rounds is a good choice by considering both the reranking performance and user tolerance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Influence of Labelled Image Size on Model Parameters</head><p>In Sections VIII-B and C, we have discussed the influence of parameters and in LGD to the reranking performance when 20 images (4 interaction rounds with 5 images labelled per round) are labelled. In this section, we turn to investigate the influence of the number of labelled images on these model parameters. Fig. <ref type="figure" target="#fig_10">16</ref> shows the performance curves of with different number of labelled images while Fig. <ref type="figure" target="#fig_11">17</ref> illustrates that of .</p><p>The in <ref type="bibr" target="#b6">(7)</ref> is utilized to balance the influence of the local geometry and the discriminative information in labelled relevant patch. A larger indicates more emphasis is assigned to separating the labelled relevant images from irrelevant ones while a smaller reflects that more attention is assigned to the local geometry of relevant images. In Fig. <ref type="figure" target="#fig_10">16</ref>(a), we can see that when only 5 images are labelled, a smaller (less than 0.3) gives better performance which indicates that the local geometry is more important. Because the irrelevant images are much more diverse than the relevant ones, over-fitting may occur if more emphasis is assigned to the discriminative information with only few labelled images. When more images are labelled, the discriminative information is more reliable and thus a larger is  preferred. Fig. <ref type="figure" target="#fig_10">16(c</ref>) and (d) shows that the best performance is achieved when is around 1.0 which means the local geometry and the discriminative information are equally important.</p><p>The in ( <ref type="formula">13</ref>) is utilized to control the influence of the global patches. Fig. <ref type="figure" target="#fig_11">17</ref>(a) shows that a larger is preferred when fewer images are labelled. With few labelled images, little information is contained in them and thus the global patches play the main role. Fig. <ref type="bibr">17(d)</ref> shows that when the number of labelled images is augmented, the discriminative information and the local geometry become robust and thus a smaller provides better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Evaluation on Dimension of the Projected Subspace</head><p>LGD aims to learn a submanifold from the ambient visual feature space to express the user's intention. To find out a proper dimension of the projected feature, the following experiment has been done to investigate the influence of the dimension. Fig. <ref type="figure" target="#fig_12">18</ref> shows the performance of LGD with features projected onto the subspaces with different dimensions. When the dimension is too low, e.g., less than 50, the learned subspace is insufficient to encode the intention so the reranking performance is poor. When dimension equals or closes to that of the ambient feature space, i.e., 428 in this paper, no or less benefit can be obtained from LGD. From our experiments, the active reranking achieved its best performance with the dimension of 100, which gave a good trade-off. Besides, lower dimension leads to a less computational cost for active reranking.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. CONCLUSION</head><p>This paper has presented a novel active reranking framework for Web image search by using user interactions. To target the user's intention effectively and efficiently, we have proposed an active sample selection strategy and a dimension reduction algorithm, to reduce labeling efforts and to learn the visual characteristics of the intention respectively. To select the most informative query images, the structural information based active sample selection strategy takes both the ambiguity and the representativeness into consideration. To learn the visual characteristics, a new local-global discriminative dimension reduction algorithm transfers the local information in the domain of the labelled images domain to the whole image database. The experiments on both synthetic datasets and a real Web image search dataset have demonstrated the effectiveness of the proposed active reranking scheme, including both the sample selection strategy and the dimension reduction algorithm.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. For query "animal", the query relevant images vary largely in both appearance (a) and visual features (b). In (b), the utilized 428-D visual features include 225-D color moment, 128-D wavelet texture and 75-D edge distribution histogram.</figDesc><graphic coords="5,303.66,67.86,246.00,99.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Three-dimensional synthetic dataset for dimension reduction illustration. In this dataset, big red "*" and big blue "o" denote labelled relevant and irrelevant samples, respectively. Small black "*" and small green "o" are unlabelled relevant and irrelevant samples, respectively. As given in (b), LGD reveals the submanifold of the relevant samples and separates the relevant samples from the irrelevant ones in the projected 2-D subspace. When other dimension reduction algorithms are adopted, the relevant and irrelevant samples are overlapped in the projected subspace, as shown in (c)-(k). (a) The 3-D synthetic data and its 2-D projections on the three planes, i.e., XY, XZ, and YZ, (b) LGD, (c) Local patches, (d) Global patches, (e) LGD-LPP, (f) BDA, (g) BMFA, (h) LDE, (i) SLPP, (j) SDA, (k) SML.</figDesc><graphic coords="7,53.82,68.82,482.00,267.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 :</head><label>1</label><figDesc>Initialization: the image set , the number of interaction rounds T, labelled image set and . 2: /* Perform Bayesian reranking to get */ Bayesian reranking . 3: For to T do 1) /* Perform SInfo to select a set of image */ SInfo /* Update */ 2) /* Perform LGD to learn a new */ 3) /* Perform Bayesian reranking to derive a new */ Bayesian reranking 4: End for 5: Return VI. EXPERIMENTS ON SYNTHETIC DATASETS In this section, we used three synthetic datasets to illustrate the effectiveness of the SInfo sample selection strategy, as shown in Fig. 5 (top). In each dataset, the relevant samples are marked with red stars ("*") while the irrelevant ones are marked with blue circles ("o").</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Active reranking on synthetic datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. MAP over all queries with different sample selection strategies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .Fig. 8 .</head><label>78</label><figDesc>Fig. 7. MAP over all queries with different dimension reduction algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Performance of LGD with samples selected via random and SInfo respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Performance of SInfo with different . The solid line indicates the performance of "RerankInitial", i.e., reranking without user interactions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 11 .Fig. 12 .</head><label>1112</label><figDesc>Fig. 11. Performance of LGD with different . The solid line indicates the performance of "SInfo", i.e., active reranking in the original feature space without dimension reduction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 13 .Fig. 14 .Fig. 15 .</head><label>131415</label><figDesc>Fig. 13. Average AP over the first three pages of results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Performance curves of with different number of labelled images. (a) # Labeled = 5, (b) # Labeled = 10, (c) # Labeled = 15, (d) # Labeled = 20.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. Performance curves of with different number of labelled images. (a) # Labeled = 5, (b) # Labeled = 10, (c) # Labeled = 15, (d) # Labeled = 20.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 18 .</head><label>18</label><figDesc>Fig. 18. Performance of LGD with features projected onto the subspaces with different dimensions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 19 .</head><label>19</label><figDesc>Fig. 19. Query "George W. Bush".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 20 .</head><label>20</label><figDesc>Fig. 20. Query "zebra".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="3,43.74,66.82,502.00,134.00" type="bitmap" /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>. This work was supported by the Nanyang Technological University Nanyang SUG Grant (M58020010), the Microsoft Operations PTE LTD-NTU Joint R&amp;D (M48020065), and the K. C. Wong Education Foundation Award.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Dacheng Tao (M'07) received the B.Eng. degree from the University of Science and Technology of China, the M.Phil. degree from the Chinese University of Hong Kong, and the Ph.D. degree from the University of London, London, U.K. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Orthogonal laplacianfaces for face recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="page" from="3608" to="3614" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Using Graph Model for Face Analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Sci. Dept., Univ. Illinois</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>Urbana-Champaign</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semi-supervised discriminant analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Computer Vision</title>
		<meeting>IEEE Int. Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Support vector machine concept-dependent active learning for image retrieval</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Local discriminant embedding and its variants</title>
		<author>
			<persName><forename type="first">H.-T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Conf. Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="846" to="853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Real time google and live image search re-ranking</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Int. Conf. Multimedia</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The use of multiple measurements in taxonomic problems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Fisher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1936">1936</date>
			<biblScope unit="page" from="179" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Image classification using correlation tensor analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="page" from="226" to="234" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Correlation metric for generalized feature extraction</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="page" from="2229" to="2235" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning a maximum margin subspace for image retrieval</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="page" from="189" to="201" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Locality preserving projections</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A semi-supervised active learning framework for image retrieval</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Int. Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="302" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Analysis of a complex of statistical variables into principal components</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hotteling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Ed. Psych</title>
		<imprint>
			<biblScope unit="page" from="417" to="441" />
			<date type="published" when="1933">1933</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Video search reranking via information bottleneck principle</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Int. Conf. Multimedia</title>
		<meeting>ACM Int. Conf. Multimedia</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="35" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Video search reranking through random walk over document-level context graph</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Int. Conf. Multimedia</title>
		<meeting>ACM Int. Conf. Multimedia</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="971" to="980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Domain adaptation for statistical classifiers</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Iii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res</title>
		<imprint>
			<biblScope unit="page" from="101" to="126" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Pagerank for product image search</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baluja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. World Wide Web</title>
		<meeting>Int. Conf. World Wide Web</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="307" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Transductive inference for text classification using support vector machines</title>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Machine Learning</title>
		<meeting>Int. Conf. Machine Learning</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="200" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A reranking approach for contextbased concept fusion in video indexing and retreival</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Int. Conf. Image and Video Retrieval</title>
		<meeting>ACM Int. Conf. Image and Video Retrieval</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="333" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A sequential algorithm for training text classifiers</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Gale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Int. Conf. Research and Development in Information Retrieval</title>
		<meeting>ACM Int. Conf. Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Discriminant locally linear embedding with high-order tensor data</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="page" from="342" to="352" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semantic manifold learning for image retrieval</title>
		<author>
			<persName><forename type="first">Y.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-T</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Int. Conf. Multimedia, 2005</title>
		<meeting>ACM Int. Conf. Multimedia, 2005</meeting>
		<imprint>
			<biblScope unit="page" from="6" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Transductive component analysis</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Data Mining Series</title>
		<meeting>IEEE Int. Conf. Data Mining Series</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="433" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Applying occam&apos;s razor in modeling cognition: A bayesian approach</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Myung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Pitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psych. Bull. Rev</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Active learning using pre-clustering</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smeulders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Machine Learning</title>
		<meeting>Int. Conf. Machine Learning</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="623" to="630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">On Estimation of a Probability Density Function and Mode</title>
		<author>
			<persName><forename type="first">E</forename><surname>Parzen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962">1962</date>
			<biblScope unit="page" from="1065" to="1076" />
		</imprint>
	</monogr>
	<note>The annals of mathematical statistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Nonlinear dimensionality reduction by locally linear embedding</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="page" from="2323" to="2326" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Geometric mean for subspace selection</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-J</forename><surname>Maybank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="page" from="260" to="274" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Nonparametric discriminant analysis in relevance feedback for content-based image retrieval</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Pattern Recognition</title>
		<meeting>IEEE Int. Conf. Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1013" to="1016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<ptr target="http://trec.nist.gov/pubs/trec10/appendices/mea-sures.pdf" />
		<title level="m">Trec-10 Proceddings Appendix on Common Evaluation Measures</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A global geometric framework for nonlinear dimensionality reduction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="page" from="2319" to="2323" />
			<date type="published" when="2000-12">Dec. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning one more thing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Joint Conf. Artificial Intelligence</title>
		<meeting>Int. Joint Conf. Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1217" to="1225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Transductive video annotation via local learnable kernel classifier</title>
		<author>
			<persName><forename type="first">X</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Multimedia &amp; Expo</title>
		<meeting>IEEE Int. Conf. Multimedia &amp; Expo</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1509" to="1512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Bayesian video search reranking</title>
		<author>
			<persName><forename type="first">X</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Int. Conf. Multimedia</title>
		<meeting>ACM Int. Conf. Multimedia</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="131" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m">Statistical Learning Theory</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Bootstrapping svm active learning by incorporating unlabelled images for image retrieval</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Int. Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="629" to="634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Marginal fisher analysis and its variants for human gait recognition and content-based image retrieval</title>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="page" from="2811" to="2821" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Patch alignment for dimensionality reduction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="page" from="1299" to="1313" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Discriminative locality alignment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Computer Vision</title>
		<meeting>European Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="725" to="738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Principal manifolds and nonlinear dimensionality reduction via tangent space alignment</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="page" from="313" to="338" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Small sample learning during multimedia retrieval using biasmap</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Int. Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="11" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Semi-supervised learning using gaussian fields and harmonic functions</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Machine Learning</title>
		<meeting>Int. Conf. Machine Learning</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="912" to="919" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Combining active leanring and semi-suppervised learning using gaussian fields and harmonic functions</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Machine Learning</title>
		<meeting>Int. Conf. Machine Learning</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="58" to="65" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
