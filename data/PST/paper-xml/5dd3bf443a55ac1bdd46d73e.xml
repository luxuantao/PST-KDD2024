<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pangolin: An Efficient and Flexible Graph Pattern Mining System on CPU and GPU</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-01-17">17 Jan 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xuhao</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Roshan</forename><surname>Dathathri</surname></persName>
							<email>roshan@cs.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gurbinder</forename><surname>Gill</surname></persName>
							<email>gill@cs.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Keshav</forename><surname>Pingali</surname></persName>
							<email>pingali@cs.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Pangolin: An Efficient and Flexible Graph Pattern Mining System on CPU and GPU</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-01-17">17 Jan 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1911.06969v2[cs.DC]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>There is growing interest in graph pattern mining (GPM) problems such as motif counting. GPM systems have been developed to provide unified interfaces for programming algorithms for these problems and for running them on parallel systems. However, existing systems may take hours to mine even simple patterns in moderate-sized graphs, which significantly limits their real-world usability.</p><p>We present Pangolin, a high-performance and flexible inmemory GPM framework targeting shared-memory CPUs and GPUs. Pangolin is the first GPM system that provides high-level abstractions for GPU processing. It provides a simple programming interface based on the extend-reducefilter model, which enables users to specify application-specific knowledge for search space pruning and isomorphism test elimination. We describe novel optimizations that exploit locality, reduce memory consumption, and mitigate the overheads of dynamic memory allocation and synchronization.</p><p>Evaluation on a 28-core CPU demonstrates that Pangolin outperforms existing GPM frameworks Arabesque, RStream, and Fractal by 49×, 88×, and 80× on average, respectively. Acceleration on a V100 GPU further improves performance of Pangolin by 15× on average. Compared to state-of-theart hand-optimized GPM applications, Pangolin provides competitive performance with less programming effort.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Applications that use graph data are becoming increasingly important in many fields such as world wide web, advertising, social media, and biology. Graph analytics algorithms such as PageRank and SSSP have been studied extensively and many frameworks have been proposed to provide both high performance and high productivity <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b74">75]</ref>. Another important class of graph problems deals with graph pattern mining (GPM), which has plenty of applications in areas such as chemical engineering <ref type="bibr" target="#b26">[27]</ref>, bioinformatics <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b23">24]</ref>, and social sciences <ref type="bibr" target="#b32">[33]</ref>. GPM discovers relevant patterns in a given graph. One example is triangle counting, which is used to mine graphs in security applications <ref type="bibr" target="#b83">[84]</ref>.</p><p>. Another example is motif counting <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b10">11]</ref>, which counts the frequency of certain structural patterns; this is useful in evaluating network models or classifying vertex roles. Fig. <ref type="figure">1</ref> illustrates the 3-vertex and 4-vertex motifs.</p><p>Compared to graph analytics, GPM algorithms are more difficult to implement on parallel platforms; for example, unlike graph analytics algorithms, they usually generate enormous amounts of intermediate data. GPM systems such as Arabesque <ref type="bibr" target="#b80">[81]</ref>, RStream <ref type="bibr" target="#b84">[85]</ref>, and Fractal <ref type="bibr" target="#b27">[28]</ref> have been developed to provide abstractions for improving programmer productivity. Instead of the vertex-centric model used in graph analytics systems <ref type="bibr" target="#b61">[62]</ref>, Arabesque proposed an embeddingcentric programming model. In Arabesque, computation is applied on individual embeddings (i.e., subgraphs) concurrently. It provides a simple programming interface that substantially reduces the complexity of application development. However, existing systems suffer dramatic performance loss compared to hand-optimized implementations. For example, Arabesque and RStream take 98s and 39s respectively to count 3-cliques for the Patent graph with 2.7M vertices and 28M edges, while a custom solver (KClist) <ref type="bibr" target="#b24">[25]</ref> counts it in 0.16s. This huge performance gap significantly limits the usability of existing GPM frameworks in realworld applications.</p><p>The first reason for this poor performance is that existing GPM systems provide limited support for applicationspecific customization. The state-of-the-art systems focus on generality and provide high-level abstraction to the user for ease-of-programming. Therefore, they hide as many execution details as possible from the user, which substantially limits the flexibility for algorithmic customization. The complexity of GPM algorithms is primarily due to combinatorial enumeration of embeddings and isomorphism tests to find canonical patterns. Hand-optimizing implementations exploit application-specific knowledge to aggressively prune the enumeration search space or elide isomorphism tests or both. Mining frameworks need to support such optimizations to match performance of hand-optimized applications.</p><p>The second reason for poor performance is inefficient implementation of parallel operations and data structures. Programming parallel processors requires exploring trade-offs between synchronization overhead, memory management, load balancing, and data locality. However, the state-ofthe-art GPM systems target either distributed or out-ofcore platforms, and thus are not well optimized for sharedmemory multicore/manycore architectures.</p><p>In this paper, we present Pangolin, an efficient in-memory GPM framework. Pangolin provides a simple yet flexible embedding-centric programming interface, based on the extendreduce-filter model, which enables application-specific customization (Section 3). Application developers can implement aggressive pruning strategies to reduce the enumera-  tion search space, and apply customized pattern classification methods to elide generic isomorphism tests (Section 4).</p><p>To make full use of parallel hardware, we optimize parallel operations and data structures, and provide helper routines to the users to compose higher level operations. Pangolin is built as a lightweight layer on top of the Galois <ref type="bibr" target="#b66">[67]</ref> parallel library and LonestarGPU <ref type="bibr" target="#b16">[17]</ref> infrastructure, targeting both shared-memory multicore CPUs and GPUs. Pangolin includes novel optimizations that exploit locality, reduce memory consumption, and mitigate overheads of dynamic memory allocation and synchronization (Section 5).</p><p>Experimental results (Section 6) on a 28-core CPU demonstrate that Pangolin outperforms existing GPM frameworks, Arabesque, RStream, and Fractal, by 49×, 88×, and 80× on average, respectively. Furthermore, Pangolin on V100 GPU outperforms Pangolin on 28-core CPU by 15× on average. Pangolin provides performance competitive to state-of-theart hand-optimized GPM applications, but with much less programming effort. To mine 4-cliques in a real-world webcrawl graph (gsh) with 988 million vertices and 51 billion vertices, Pangolin takes ∼ 6.5 hours on a 48-core Intel Optane PMM machine <ref type="bibr" target="#b35">[36]</ref> with 6 TB (byte-addressable) memory. To the best of our knowledge, this is the largest graph on which 4-cliques have been mined.</p><p>In summary, Pangolin makes the following contributions:</p><p>• We investigate the performance gap between state-of-theart GPM systems and hand-optimized approaches, and point out two key features absent in existing systems: pruning enumeration space and eliding isomorphism tests. • We present a high-performance in-memory GPM system, Pangolin, which enables application-specific optimizations and provides transparent parallelism on CPU or GPU. To the best of our knowledge, it is the first GPM system that provides high-level abstractions for GPU processing. • We propose novel techniques that enable the user to aggressively prune the enumeration search space and elide isomorphism tests. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background and Motivation</head><p>We describe GPM concepts, applications, as well as algorithmic and architectural optimizations in state-of-the-art hand-optimized GPM solvers. Lastly, we point out performance limitations of existing GPM frameworks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Graph Pattern Mining</head><p>Given an input graph G and a pattern P which is a subgraph defined by the user (e.g., triangle or clique), the goal of GPM is to find the embeddings, i.e., subgraphs in G which are isomorphic to P . In the input graph in Fig. <ref type="figure">2</ref>, colors represent vertex labels, and numbers denote vertex IDs. The 3-vertex pattern is a blue-red-green chain, and there are four embeddings of this pattern in the input graph, shown on the right of the figure. In a specific GPM problem, the user may be interested in some statistical information (i.e., pattern frequency), instead of listing all the embeddings. The measure of the frequency of P in G, termed support, is also defined by the user. For example, in triangle counting, the support is defined as the total count of triangles. In some problems, the user might be interested in multiple patterns. In this work, we focus on connected patterns only.</p><p>There are two types of GPM problems targeting two types of embeddings. In a vertex-induced embedding, a set of vertices is given and the subgraph of interest is obtained from these vertices and the set of edges in the input graph connecting these vertices. Triangle counting uses vertexinduced embeddings. In an edge-induced embedding, a set of edges is given and the subgraph is formed by including all the endpoints of these edges in the input graph. Frequent subgraph mining (FSM) is an edge-induced GPM problem.</p><p>A GPM algorithm enumerates embeddings of the given pattern(s). If duplicate embeddings exist (automorphism), the algorithm chooses one of them as the canonical one (namely canonical test) and collects statistical information about these canonical embeddings such as the total count. The canonical test needs to be performed on each embedding, and can be complicated and expensive for complex problems such as FSM. Enumeration of embeddings in a graph grows exponentially with the embedding size (number of vertices or edges in the embedding), which is computationally expensive and consumes lots of memory. In addition, a graph isomorphism (GI) test is needed for each embedding to determine whether it is isomorphic to a pattern. Unfortunately, the GI problem is not solvable in polynomial time <ref type="bibr" target="#b33">[34]</ref>. It leads to compute and memory intensive algorithms <ref type="bibr" target="#b47">[48]</ref> that are time-consuming to implement.</p><p>Graph analytics problems typically involve allocating and computing labels on vertices or edges of the input graph iteratively. On the other hand, GPM problems involve generating embeddings of the input graph and analyzing them. Consequently, GPM problems require much more memory and computation to solve. The memory consumption is not only proportional to the graph size, but also increases exponentially as the embedding size increases <ref type="bibr" target="#b80">[81]</ref>. Furthermore, GPM problems require compute-intensive operations, such as isomorphism test and automorphism test on each embedding. Thus, GPM algorithms are more difficult to develop, and conventional graph analytics systems <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b87">88,</ref><ref type="bibr" target="#b25">26]</ref> are not sufficient to provide a good trade-off between programmability and efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Hand-Optimized GPM Applications</head><p>We consider 4 applications: triangle counting (TC), clique finding (CF), motif counting (MC), and frequent subgraph mining (FSM). Given the input graph which is undirected, TC counts the number of triangles while CF enumerates all complete subgraphs 1 (i.e., cliques) contained in the graph. TC is a special case of CF as it counts 3-cliques. MC counts the number of occurrences (i.e., frequency) of each structural pattern (also known as motif or graphlet). As listed in Fig. <ref type="figure">1</ref>, k-clique is one of the patterns in k-motifs.</p><p>FSM finds frequent patterns in a labeled graph. A measure of frequency called support is provided by the application developer, and all patterns with support above a given threshold are considered to be frequent and must be discovered. A simple definition of support is the count of the embeddings associated with the pattern (used in TC, CF, MC). A more widely used support definition is minimum image-based (MNI) support (a.k.a. domain support), which has the anti-monotonic property 2 . It is calculated as the minimum number of distinct mappings for any vertex (i.e., domain) in the pattern over all embeddings of the pattern. In Fig. <ref type="figure">2</ref>, the MNI support of the pattern is min{3, 2, 1} = 1.</p><p>Several hand-optimized implementations exist for each of these applications on multicore CPU <ref type="bibr" target="#b75">[76,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b79">80]</ref>, GPU <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b48">49]</ref>, distributed CPU <ref type="bibr" target="#b77">[78,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b78">79]</ref>, and multi-GPU <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b69">70]</ref>. They employ application-specific optimizations to reduce algorithm complexity. The complexity of GPM algorithms is primarily due to two aspects: combinatorial enumeration and isomorphism test. Therefore, hand-optimized implementations focus on either pruning the enumeration search space or eliding isomorphism test or both. We describe some of these techniques briefly below.</p><p>Pruning Enumeration Search Space: In general GPM applications, new embeddings are generated by extending existing embeddings and then they may be discarded because they are either not interesting or a duplicate (automorphism). However, in some applications like CF <ref type="bibr" target="#b24">[25]</ref>, duplicate embeddings can be detected eagerly before extending current embeddings, based on properties of the current embeddings. We term this optimization as eager pruning. Eager pruning can significantly reduce the search space. Furthermore, the input graphs are converted into directed acyclic graphs (DAGs) in state-of-the-art TC <ref type="bibr" target="#b42">[43]</ref>, CF <ref type="bibr" target="#b24">[25]</ref>, and MC <ref type="bibr" target="#b67">[68]</ref> solvers, to significantly reduce the search space.</p><p>Eliding Isomorphism Test: In most hand-optimized TC, CF, and MC solvers, isomorphism test is completely avoided by taking advantage of the pattern characteristics. For example, a parallel MC solver, PGD <ref type="bibr" target="#b2">[3]</ref>, uses an ad-hoc method for a specific k. Since it only counts 3-vertex and 4vertex motifs, all the patterns (two 3-motifs and six 4-motifs as shown in Fig. <ref type="figure">1</ref>) are known in advance. Therefore, some special (and thus easy-to-count) patterns (e.g., cliques 3 ) are counted first, and the frequencies of other patterns are obtained in constant time using the relationship among patterns 4 . In this case, no isomorphism test is needed, which is 1 A k-vertex complete subgraph is a connected subgraph in which each vertex has degree of k − 1 (i.e., any two vertices are connected). 2 The support of a supergraph should not exceed the support of a subgraph; this allows the GPM algorithm to stop extending embeddings as soon as they are recognized as infrequent. 3 Cliques can be identified by checking connectivity among vertices without generic isomorphism test. 4 For example, the count of diamonds can be computed directly from the counts of triangles and 4-cliques <ref type="bibr" target="#b2">[3]</ref>.</p><p>typically an order-of-magnitude faster <ref type="bibr" target="#b2">[3]</ref>.</p><p>Summary: Most of the algorithmic optimizations exploit application-specific knowledge, which can only be enabled by application developers. A generic GPM framework should be flexible enough to allow users to compose as many of these optimization techniques as possible, and provide parallelization support for ease of programming. Pangolin is the first GPM framework to do so.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Existing GPM Frameworks</head><p>Existing GPM systems target either distributed-memory <ref type="bibr" target="#b80">[81,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b44">45]</ref> or out-of-core <ref type="bibr" target="#b84">[85,</ref><ref type="bibr" target="#b86">87,</ref><ref type="bibr" target="#b62">63]</ref> platforms, and they make tradeoffs specific for their targeted architectures. None of them target in-memory GPM on a multicore CPU or a GPU. Consequently, they do not pay much attention to reducing the synchronization overheads among threads within a CPU/GPU or reducing memory consumption overheads. Due to this, naively porting these GPM systems to run on a multicore CPU or GPU would lead to inefficient implementations. We first describe two of these GPM systems briefly and then discuss their major limitations.</p><p>Arabesque <ref type="bibr" target="#b80">[81]</ref> is a distributed GPM system. It proposes "think like an embedding" (TLE) programming paradigm, where computation is performed in an embedding-centric manner. It defines a filter-process computation model which consists of two functions: (1) filter, which indicates whether an embedding should be processed and (2) process, which examines an embedding and may produce some output.</p><p>RStream <ref type="bibr" target="#b84">[85]</ref> is an out-of-core single-machine GPM system. Its programming model is based on relational algebra. Users specify how to generate embeddings using relational operations such as select, join, and aggregate. It stores intermediate data (i.e., embeddings) on disk while the input graph is kept in memory for reuse. It streams data (or table) from disk and uses relational operations that may produce more intermediate data, which is stored back on disk.</p><p>Limitations in API: Most of the application-specific optimizations like pruning enumeration search space and avoiding isomorphism test are missing in existing GPM frameworks, as they focus on providing high-level abstractions but lack support for application-specific customization. The absence of such key optimizations in existing systems results in a huge performance gap when compared to hand-optimized implementations. Moreover, some frameworks like Rstream support only edge-induced embeddings but for applications like CF, the enumeration search space is much smaller using vertex-induced exploration than edge-induced one.</p><p>Data Structures for Embeddings: Data structures used to store embeddings in existing GPM systems are not efficient. Both Arabesque and RStream store embeddings in an array of structures (AoS), where the embedding structures consists of a vertex set and an edge set. Arabesque also proposes a space efficient data structure called the Overapproximating Directed Acyclic Graph (ODAG), but it requires extra canonical test for each embedding, which has been demonstrated to be very expensive for large graphs <ref type="bibr" target="#b80">[81]</ref>.</p><p>Materialization of Data Structures: The list or array of intermediate embeddings in both Arabesque and RStream is always materialized in memory and in disk, respectively. This has significant overheads as the size of such data grows exponentially. Such materialization may not be needed if the embeddings can be filtered or processed immediately.</p><p>Dynamic Memory Allocation: As the number of (intermediate) embeddings are not known before executing the algorithm, memory needs to be allocated dynamically for them. Moreover, during parallel execution, different threads might allocate memory for embeddings they create or enumerate. Existing systems use standard (std) maps and sets, which internally use a global lock to dynamically allocate memory. This limits the performance and scalability.</p><p>Summary: Existing GPM systems have limitations in their API, execution model, and implementation. Pangolin addresses these issues by permitting application-specific optimizations in its API, optimizing the execution model, and providing an efficient, scalable implementation on multicore CPU and GPU. These optimizations can be applied to existing embedding-centric systems like Arabesque.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Design of Pangolin Framework</head><p>Fig. <ref type="figure">3</ref> illustrates an overview of the Pangolin system. Pangolin provide a simple API (purple box) to the user for writing GPM applications. The unified execution engine (orange box) follows the embedding-centric model. Important common operations are encapsulated and provided to the user in the helper routines (blue box), which are optimized for both CPU and GPU. The embedding list data structure (green box) is also optimized for different architectures to exploit hardware features. Thus, Pangolin hides most of the architecture oriented programming complexity and achieves high performance and high productivity simultaneously. In this section, we describe the execution model, programming interface (i.e., API), and example applications of Pangolin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Execution Model</head><p>Algorithm 1 describes the execution engine in Pangolin which illustrates our extend-reduce-filter execution model. To begin with, a worklist of embeddings is initialized with all the single-edge embeddings (line 4). The engine then works in an iterative fashion (line 6). In each iteration, i.e., level, there are three phases: Extend (line 8), Reduce (line 10) and Filter (line 12). Pangolin exposes necessary details in each phase to enable a more flexible programming interface (Section 3.2) than existing systems; for example, Pangolin exposes the Extend phase which is implicit in Arabesque.</p><p>The Extend phase takes each embedding in the input worklist and extends it with a vertex (vertex-induced) or an edge (edge-induced). Newly generated embeddings then form the output worklist for the next level. The embedding size is increased with level until the user defined maximum size is reached (line 14). Fig. <ref type="figure" target="#fig_2">4</ref> shows an example of the first iteration of vertex-based extension. The input worklist consists of all the 2-vertex (i.e., single-edge) embeddings. For each embedding in the worklist, one vertex is added to yield a 3-vertex embedding. For example, the first 2vertex embedding {0, 1} is extended to two new 3-vertex embeddings {0, 1, 2} and {0, 1, 3}.</p><p>After vertex/edge extension, a Reduce phase is used to extract some pattern-based statistical information, i.e., pattern frequency or support, from the embedding worklist. The Reduce phase first classifies all the embeddings in the worklist into different categories according to their patterns, and then computes the support for each pattern category, forming pattern-support pairs. All the pairs together constitute a pattern map (p map in line 10). Fig. <ref type="figure" target="#fig_3">5</ref> shows an example of the reduction operation. The three embeddings (top)</p><formula xml:id="formula_0">Algorithm 1 Execution Model for Mining 1: procedure MineEngine(G(V ,E), MAX SIZE) 2:</formula><p>EmbeddingList in wl, out wl double buffering</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3:</head><p>PatternMap p map</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>Init(in wl) insert single-edge embeddings</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>level ← 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>while true do</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>out wl ← ∅ clear the new worklist</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8:</head><p>Extend(in wl, out wl)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9:</head><p>p map ← ∅ clear the pattern map 10:</p><p>Reduce(out wl, p map)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11:</head><p>in wl ← ∅ clear the old worklist</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>12:</head><p>Filter(out wl, p map, in wl)</p><p>13:</p><formula xml:id="formula_1">level ← level + 1</formula><p>14: for each embedding emb ∈ in wl in parallel do</p><formula xml:id="formula_2">if level = MAX SIZE -</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3:</head><p>for each vertex v in emb do</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>if toExtend(emb, v) = true then</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>for each vertex u in adj(v) do</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>if toAdd(emb, u) = true then</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>insert emb ∪ u to out wl 8: procedure Reduce(queue, p map) 9:</p><p>for each embedding emb ∈ queue in parallel do</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>10:</head><p>Pattern pt ← getPattern(emb)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11:</head><p>Support sp ← getSupport(emb)</p><p>12:</p><formula xml:id="formula_3">p map[pt] ← Aggregate(p map[pt], sp)</formula><p>13: procedure Filter(in wl, p map, out wl) 14:</p><p>for each embedding emb ∈ in wl in parallel do</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>15:</head><p>if toPrune(emb, p map) = f alse then</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>16:</head><p>insert emb to out wl can be classified into two categories, i.e., triangle and wedge (bottom). Within each category, this example counts the number of embeddings as the support. As a result, we get the pattern-map as {[triangle, 2], [wedge, 1]}. After reduction, a Filter phase may be needed to remove those embeddings which the user are no longer interested in; e.g., FSM removes infrequent embeddings in this phase. Note that Reduce and Filter phases are not necessary for all applications, and they can be disabled by the user. If they are used, they are also executed after initializing single-edge embeddings (line 4) and before entering the main loop (line 6). Thus, infrequent single-edge embeddings are filtered out to collect only the frequent ones before the main loop starts. Note that this is omitted from Algorithm 1 due to lack of space. If Reduce is enabled but Filter is disabled, then reduction is only required and executed for the last iteration, as the pattern map produced by reduction is not used in prior iterations (dead code).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Programming Interface</head><p>Pangolin exposes flexible and simple interfaces to the user to express application-specific optimizations. Listing 1 lists user-defined functions (APIs) and Algorithm 2 describes how these functions (marked in blue) are invoked by the Pangolin execution engine. A specific application can be created by defining these APIs. Note that all the functions are not mandatory; each of them has a default return value.</p><p>In the Extend phase, we provide two functions, toAdd and toExtend, for the user to prune embedding candidates   aggressively. When they return false, the execution engine avoids generating an embedding and thus the search space is reduced. More specifically, toExtend checks whether a vertex in the current embedding needs to be extended. Extended embeddings can have duplicates due to automorphism. Fig. <ref type="figure" target="#fig_4">6</ref> illustrates automorphism: two different embeddings <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b3">4)</ref> and <ref type="bibr" target="#b1">(2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b3">4)</ref> can be extended into the same embedding <ref type="bibr" target="#b1">(2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4)</ref>. Therefore, only one of them (the canonical embedding) should be kept, and the other (the redundant one) should be removed. This is done by a canonical test in toAdd, which checks whether the newly generated embedding is a qualified candidate. An embedding is not qualified when it is a duplicate or it does not have certain user-defined characteristics. Only qualified embeddings are added into the next worklist. Application-specific knowledge can be used to specialize the two functions. If left undefined, toExtend returns true and toAdd does a default canonical test. Note that the user specifies whether the embedding exploration is vertex-induced or edge-induced. The only difference for edge-induced extension is in lines 5 to 7: instead of vertices adjacent to v, edges incident on v are used.</p><p>In the Reduce phase, getPattern function specifies how to obtain the pattern of an embedding. Finding the canonical pattern of an embedding involves an expensive isomorphism test. This can be specialized using application-specific knowledge to avoid such tests. If left undefined, a canonical pattern is returned by getPattern. In this case, to reduce the overheads of invoking the isomorphism test, embeddings in the worklist are first reduced using their quick patterns <ref type="bibr" target="#b80">[81]</ref>, and then quick patterns are aggregated using their canonical patterns. In addition, getSupport and Aggregate functions specify the support of an embedding and the reduction operator for the support, respectively.</p><p>Lastly, in the Filter stage, toPrune is used to specify those embeddings the user is no longer interested in. This depends on the support for the embedding's canonical pattern (that is in the computed pattern map).</p><p>Complexity Analysis. Consider an input graph G with n vertices and maximum embedding size k. In the Extend phase of the last level (which dominates the execution time and complexity), there are up to O(n k−1 ) embeddings in the input worklist. Each embedding has up to k − 1 vertices to extend. Each vertex has up to dmax neighbors (candidates). In general, each candidate needs to check connectivity with k − 1 vertices, with a complexity of O(log(dmax)) (binary search). An isomorphism test needs to be performed for each newly generated embedding (size of k) to find its pattern. The state-of-the-art algorithm to test isomorphism has a complexity of O(e √ klogk ) <ref type="bibr" target="#b6">[7]</ref>. Therefore, the overall worst-</p><formula xml:id="formula_4">case complexity is O(n k−1 k 2 dmaxlog(dmax)e √ klogk ).</formula><p>Pangolin also provides APIs to process the embeddings or pattern maps at the end of each phase (e.g., this is used in clique-listing, which a variant of clique-finding that requires listing all the cliques). We omit this from Algorithm 2 and Listing 1 for the sake of brevity. To implement the application-specific functions, users are required to write C++ code for CPU and CUDA device functions for GPU (compiler support can provide a unified interface for both CPU and GPU in the future). Listing 2 lists the helper routines provided by Pangolin. These routines are commonly used in GPM applications; e.g., to check connectivity, to test canonicality, as well as an implementation of domain support. They are available on both CPU and GPU, with efficient implementation on each architecture.</p><p>Comparison With Other GPM APIs: Existing GPM frameworks do not expose toExtend and getPattern to the application developer (instead, they assume these functions always return true and a canonical pattern, respectively). Note that existing embedding-centric frameworks like Arabesque can be extended to expose the same API functions in Pangolin so as to enable application-specific optimizations (Section 4), but this is difficult for relational model based systems like RStream, as the table join operations are inflexible to allow this fine-grained control.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Applications in Pangolin</head><p>TC, CF, and MC use vertex-induced embeddings, while FSM uses edge-induced embeddings. Listings 3 to 5 show CF, MC, and FSM implemented in Pangolin (we omit TC due to lack of space). For TC, extension happens only once, i.e., for each edge (v0, v1), v1 is extended to get a neighbor v2. We only need to check whether v2 is connected to v0. If it is, this 3-vertex embedding (v0, v1, v2) forms a triangle. For CF in Listing 3, the search space is reduced by extending only the last vertex in the embedding instead of extending every vertex. If the newly added vertex is connected to all the vertices in the embedding, the new embedding forms a clique. Since cliques can only grow from smaller cliques (e.g., 4-cliques can only be generated by extending 3-cliques), all the non-clique embeddings are implicitly pruned. Both TC and CF do not use Reduce and Filter phases.</p><p>Listing 4 shows MC. An extended embedding is added only if it is canonical according to automorphism test. In the Reduce phase, the quick pattern of each embedding is first obtained and then the canonical pattern is obtained using an isomorphism test. In Section 4.2, we show a way to customize this pattern classification method for MC to improve performance. Filter phase is not used by MC.</p><p>FSM is the most complicated GPM application. As shown in Listing 5, it uses the custom domain support routines provided by Pangolin. An extended embedding is added only if the new embedding is (automorphism) canonical. FSM uses the Filter phase to remove embeddings whose patterns are not frequent from the worklist. Despite the complexity of FSM, the Pangolin implementation is still much simpler than hand-optimized FSM implementations <ref type="bibr" target="#b78">[79,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b29">30]</ref>, thanks to the Pangolin API and helper routines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Supporting Application-Specific Optimizations in Pangolin</head><p>In this section, we describe how Pangolin's API and execution model supports application-specific optimizations that: (1) enable enumeration search space pruning and (2) enable the eliding of isomorphism tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Pruning Enumeration Search Space</head><p>Directed Acyclic Graph (DAG): In typical GPM applications, the input graph is undirected. In some vertexinduced GPM applications, a common optimization technique is orientation which converts the undirected input graph into a directed acyclic graph (DAG) <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b4">5]</ref>. Instead of enumerating candidate subgraphs in an undirected graph, the direction significantly cuts down the combinatorial search space. Orientation has been adopted in triangle counting <ref type="bibr" target="#b70">[71]</ref>, clique finding <ref type="bibr" target="#b24">[25]</ref>, and motif counting <ref type="bibr" target="#b67">[68]</ref>. Fig. <ref type="figure">7</ref> illustrates an example of the DAG construction process. In this example, vertices are ordered by vertex ID.</p><p>Edges are directed from vertices with smaller IDs to vertices with larger IDs. Generally, vertices can be ordered in any total ordering, which guarantees the input graph is converted into a DAG. In our current implementation, we establish the order <ref type="bibr" target="#b40">[41]</ref> among the vertices based on their degrees: edges will point towards the vertex with higher degree. When there is a tie, the edge points to the vertex with the larger vertex ID. Other orderings can be included in the future. In Pangolin, the user can enable orientation by simply setting a macro.</p><p>Eager Pruning: In some applications like MC and FSM, all vertices in an embedding may need to be extended before determining whether the new embedding candidate is a (automorphism) canonical embedding or a duplicate. However, in some applications like TC and CF <ref type="bibr" target="#b24">[25]</ref>, duplicate embeddings can be detected eagerly before extending current embeddings. In both TC and CF, all embeddings obtained by extending vertices except (the last) one will lead to duplicate embeddings. Thus, as shown in Listing 3, only the last vertex of the current embedding needs to be extended. This aggressive pruning can significantly reduce the search space. The toExtend function in Pangolin enables the user to specify such eager pruning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Eliding Isomorphism Test</head><p>Exploiting Memoization: Pangolin avoids redundant computation in each stage with memoization. Memoization is a tradeoff between computation and memory usage. Since GPM applications are usually memory hungry, we only do memoization when it requires small amount of memory and/or it dramatically reduce complexity. For example, in the Filter phase of FSM, Pangolin avoids isomorphism test to get the pattern of each embedding, since it has been done in the Reduce phase. This recomputation is avoided by maintaining a pattern ID (hash value) in each embedding after isomorphism test, and setting up a map between the pattern ID and pattern support. Compared to isomorphism test, which is extremely compute and memory intensive, storing the pattern ID and a small pattern support map is relatively lightweight. In MC, which is another application to find multiple patterns, the user can easily enable memoization for the pattern id in each level. In this case, when it goes to the next level, the pattern of each embedding can be identified with its pattern id in the previous level with much less computation than a generic isomorphism test. As shown in Fig. <ref type="figure">8</ref>, to identify a 4-cycle from a wedge or a diamond from a triangle, we only need to check if vertex 3 is connected to both vertex 1 and 2.</p><p>Customized Pattern Classification: In the Reduce phase, embeddings are classified into different categories based on their patterns, as shown in Fig. <ref type="figure" target="#fig_3">5</ref>. To get the pattern of an embedding, a generic way is to convert the embedding into a canonical graph that is isomorphic to it (done in two steps, as explained in Section 3. Rstream, Pangolin uses the Bliss <ref type="bibr" target="#b47">[48]</ref> library for getting the canonical graph or pattern for an embedding. This graph isomorphism approach is applicable to embeddings of any size, but it is very expensive as it requires frequent dynamic memory allocation and consumes a huge amount of memory. For small embeddings, such as 3-vertex and 4-vertex embeddings in vertex-induced applications and 2-edge and 3-edge embeddings in edge-induced applications, the canonical graph or pattern can be computed very efficiently. For example, we know that there are only 2 patterns in 3-MC (i.e., wedge and triangle in Fig. <ref type="figure">1</ref>). The only computation needed to differentiate the two patterns is to count the number of edges (i.e., a wedge has 2 edges and a triangle has 3), as shown in Listing 6. This specialized method significantly reduces the computational complexity of pattern classification. The getPattern function in Pangolin enables the user to specify such customized pattern classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Implementation on CPU and GPU</head><p>The user implements application-specific optimizations using the Pangolin API and helper functions, and Pangolin transparently parallelizes the application. Pangolin provides an efficient and scalable parallel implementation on both shared-memory multicore CPU and GPU. Its CPU implementation is built using the Galois <ref type="bibr" target="#b66">[67]</ref> libray and its GPU implementation is built using the LonestarGPU <ref type="bibr" target="#b16">[17]</ref> infrastructure. Pangolin includes several architectural optimizations. In this section, we briefly describe some of them: (1) exploiting locality and fully utilizing memory bandwidth <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b7">8]</ref>; (2) reducing the memory consumption; (3) mitigating the overhead of dynamic memory allocation; (4) minimizing synchronization and other overheads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data Structures for Embeddings</head><p>Since the number of possible k-embeddings in a graph increases exponentially with k, storage for embeddings grows rapidly and easily becomes the performance bottleneck. Most existing systems use array-of-structures (AoS) to organize the embeddings, which leads to poor locality, especially for GPU computing. In Pangolin, we use structure of arrays (SoA) to store embeddings in memory. The SoA layout is particularly beneficial for parallel processing on GPU as memory accesses to the embeddings are fully coalesced.</p><p>Fig. <ref type="figure" target="#fig_8">9</ref> illustrates the embedding list data structure. On the left is the prefix-tree that illustrates the embedding extension process in Fig. <ref type="figure" target="#fig_2">4</ref>. The numbers in the vertices are vertex IDs (VIDs). Orange VIDs are in the first level L1, and blue VIDs belong to the second level L2. The grey level L0 is a dummy level which does not actually exist but is used to explain the key ideas. On the right, we show the corresponding storage of this prefix tree. For simplicity, we only show the vertex-induced case. Given the maximum size k, the embedding list contains k − 1 levels. In each level, there are two arrays, index array (idx) and vertex ID array (vid). In the same position of the two arrays, an element of index and vertex ID consists of a pair (idx, vid). In level Li, idx is the index pointing to the vertex of the same embedding in the previous level Li−1, and vid is the i-th vertex ID of the embedding. Each embedding can be reconstructed by backtracking from the last level lists. For example, to get the first embedding in level L2, which is a vertex set of {0, 1, 2}, we use an empty vertex set at the beginning. We start from the first entry (0, 2) in L2, which indicates the last vertex ID is '2' and the previous vertex is at the position of '0'. We put '2' into the vertex set {2}. Then we go back to the previous level L1, and get the 0-th entry (0, 1). Now we put '1' into the vertex set {1, 2}. Since L1 is the lowest level and its index is the same as the vertex ID in level L0, we put '0' into the vertex set {0, 1, 2}.</p><p>For the edge-induced case, the strategy is similar but requires one more column his in each level to indicate the history information. Each entry is a triplet (vid, his, idx) that represents an edge instead of a vertex, where his indicates at which level the source vertex of this edge is, while vid is the ID of the destination vertex. In this way we can backtrack the source vertex with his and reconstruct the edge connectivity inside the embedding. Note that we use three distinct arrays for vid, his and idx, which is also an SoA layout. This data layout can improve temporal locality with more data reuse. For example, the first vid in L1 (v1) is connected to two vertices in L2 (v2 &amp; v3). Therefore v1 will be reused. Considering high-degree vertices in power-law graphs, there are lots of reuse opportunities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Avoiding Materializaton of Data Structures</head><p>Loop Fusion: Existing GPM systems first collect all the embedding candidates into a list and then call the userdefined function (like toAdd) to select embeddings from the list. This leads to materializaton of the candidate embeddings list. In contrast, Pangolin preemptively discards embedding candidates using the toAdd function before adding it to the embedding list (as shown in Algorithm 2), thereby avoiding the materialization of the candidate embeddings (this is similar to loop fusion in array languages). This significantly reduces memory allocations, yielding lower memory usage and execution time.</p><p>Blocking Schedule: Since the memory consumption increases exponentially with the embedding size, existing systems utilize either distributed memory or disk to hold the data. However, Pangolin is a shared memory framework and could run out of memory for large graphs. In order to support processing large datasets, we introduce an edgeblocking technique in Pangolin. Since an application starts expansion with single-edge embeddings, Pangolin blocks the initial embedding list into smaller chunks, and processes all levels (main loop in Algorithm 1) for each chunk one after another. As shown in Fig. <ref type="figure">10</ref>, there are n edges in the initial embedding list (e0 ∼ en−1). Each chunk contains 4 edges which are assigned to the 2 threads (t0 ∼ t1) to process. Af- ter all levels of the current chunk are processed, the threads move to the next chunk and continue processing until all chunks are processed. The chunk size Cs is a parameter to tune; Cs is typically much larger than the number of threads. Blocking will not affect parallelism because there are a large number of edges in each chunk that can be processed concurrently. Note that the FILTER phase requires strict synchronization in each level, so edge-blocking cannot be applied for applications that use it. For example, we need to gather embeddings for each pattern in FSM in order to compute the domain support. Due to this, all embeddings needs to be processed before moving to the next level, so we disable blocking for FSM. Currently, edge-blocking is used specifically for bounding memory usage, but it is also potentially beneficial for data locality with an appropriate block size. We leave this for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Dynamic Memory Allocation</head><p>Inspection-Execution: Compared to graph analytics applications, GPM applications need significantly more dynamic memory allocations and memory allocation could become a performance bottleneck. A major source of memory allocation is the embedding list. As the size of embedding list increases, we need to allocate memory for the embeddings in each round. When generating the embedding list, there are write conflicts as different threads write to the same shared embedding list. In order to avoid frequent resize and insert operation, we use inspection-execution technique to generate the embedding list.</p><p>The generation include 3 steps. In the first step, we only calculate the number of newly generated embeddings for each embedding in the current embedding list. We then use parallel prefix sum to calculate the start index for each current embedding, and allocate the exact amount of memory for all the new embeddings. Finally, we actually write the new embeddings to update the embedding list, according to the start indices. In this way, each thread can write to the shared embedding list simultaneously without conflicts. Fig. <ref type="figure">11</ref> illustrates the inspection process. At level i, there are 4 embeddings e0, e1, e2, e3 in the embedding list, which will generate 1, 2, 1, 3 new embeddings respectively. We get the start indices (0, 1, 3, 4) using prefix sum, and then allocate memory for the level i + 1 embedding list. Next, each embedding writes generated embeddings from its start index in the level i + 1 list (concurrently).</p><p>Although inspection-execution requires iterating over the embeddings twice, making this tradeoff for GPU is reasonable for two reasons. First, it is fine for the GPU to do the recomputation as it has a lot of computation power. Second, improving the memory access pattern to better utilize memory bandwidth is more important for GPU. This is also a more scalable design choice for the CPU as the number of cores on the CPU are increasing.</p><p>Scalable Allocators: Pattern reduction in FSM is another case where dynamic memory allocation is frequently and their properties (d is the average degree). To check which vertices in the embedding are directly connected to vertex 9, we use '2', '5', and '8' as the keys to search in the neighbor list of vertex 9. Using binary search we find '2' and '5' are connected to '9'. invoked. To compute the domain support of each pattern, we need to gather all the embeddings associated with the same pattern (see Fig. <ref type="figure">2</ref>). This gathering requires resizing the vertex set of each domain. The C++ standard std library employs a concurrent allocator implemented by using a global lock for each allocation, which could seriously limit performance and scalability. We leverage the Galois memory allocator to alleviate this overhead. Galois provides an in-built efficient and concurrent memory allocator that implements ideas from prior scalable allocators <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b71">72]</ref>. The allocator uses per-thread memory pools of huge pages. Each thread manages its own memory pool. If a thread has no more space in its memory pool, it uses a global lock to add another huge page to its pool. Most allocations thus avoid locks. Pangolin uses variants of std data structures provided by Galois that use the Galois memory allocator. For example, this is used for maintaining the pattern map. On the other hand, our GPU infrastructure currently lacks support for efficient dynamic memory allocation inside CUDA kernels. To avoid frequent resize operations inside kernels, we conservatively calculate the memory space required and pre-allocate bit vectors for kernel use. This pre-allocation requires much more memory than is actually required, and restricts our GPU implementation to smaller inputs for FSM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Other Optimizations</head><p>GPM algorithms make extensive use of connectivity operations for determining how vertices are connected in the input graph. For example, in k-cliques, we need to check whether a new vertex is connected to all the vertices in the current embedding. Another common connectivity operation is to determine how many vertices are connected to given vertices v0 and v1, which is usually obtained by computing the intersection of the neighbor lists of the two vertices. A naive solution of connectivity checking is to search for one vertex v0 in the other vertex v1's neighbor list sequentially. If found, the two vertices are directly connected. To reduce complexity and improve parallel efficiency, we employ binary search for the connectivity check. Fig. <ref type="figure" target="#fig_10">12</ref>  Table <ref type="table" target="#tab_5">2</ref>: Execution time (sec) of applications in GPM frameworks on 28 cores (option: minimum support for 3-FSM; k for others). AR, RS, KA, FR, and PA: Arabesque, RStream, Kaleido, Fractal, and Pangolin respectively. '-': out of memory or disk, or timed out in 30 hours. FR for Yo is omitted due to failed execution. FR does not contain TC. † KA results are reported from their paper.</p><p>memory efficiency <ref type="bibr" target="#b42">[43]</ref>. We provide efficient CPU and GPU implementations of these connectivity operations as helper routines, such as isConnected (Listing 2), which allow the user to easily compose pruning strategies in applications. In summary, when no algorithmic optimization is applied, programming in Pangolin should be as easy as previous GPM systems like Arabesque. In this case, performance gains over Arabesque is achieved due to the architectural optimizations (e.g., data structures) in Pangolin. To incorporate algorithmic optimizations, the user can leverage Pangolin API functions (e.g., toExtend and toAdd) to express application-specific knowledge. While this involves slightly more programming effort, the user can get an order of magnitude performance improvement by doing so.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Evaluation</head><p>In this section, we compare Pangolin with state-of-art GPM frameworks and hand-optimized applications. We also analyze Pangolin performance in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Setup</head><p>We compare Pangolin with the state-of-the-art GPM frameworks: Arabesque <ref type="bibr" target="#b80">[81]</ref>, RStream <ref type="bibr" target="#b84">[85]</ref>, G-Miner <ref type="bibr" target="#b17">[18]</ref>, Kaleido <ref type="bibr" target="#b86">[87]</ref>, Fractal <ref type="bibr" target="#b27">[28]</ref>, and AutoMine <ref type="bibr" target="#b62">[63]</ref>. Arabesque, G-Miner, and Fractal support distributed execution, while the rest support out-of-core execution. All of them support execution only on CPUs. Kaleido and AutoMine results are reported from their papers because they are not publicly available. We also compare Pangolin with the state-of-the-art hand-optimized GPM applications <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b78">79,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b48">49]</ref>.</p><p>We test the 4 GPM applications discussed in Section 3.3, i.e., TC, CF, MC, and FSM. k-MC and k-CF terminate when subgraphs reach a size of k vertices. For k-FSM, we mine the frequent subgraphs with k − 1 edges. Table <ref type="table" target="#tab_3">1</ref> lists the input graphs used in the experiments. We assume that input graphs are symmetric, have no self-loops, and have no duplicated edges. We represent the input graphs in memory in a compressed sparse row (CSR) format. The neighbor list of each vertex is sorted by ascending vertex ID.</p><p>The first 3 graphs -Mi, Pa, and Yo -have been previously used by Arabesque, RStream, and Kaleido. We use the same graphs to compare Pangolin with these existing frameworks. In addition, we include larger graphs from SNAP Collection <ref type="bibr" target="#b54">[55]</ref> (Lj, Or), Koblenz Network Collection <ref type="bibr" target="#b52">[53]</ref> (Tw), DistGraph <ref type="bibr" target="#b78">[79]</ref>(Pdb), and a very large web-crawl <ref type="bibr" target="#b13">[14]</ref> (Gsh). Except Pdb, other larger graphs do not have vertex labels, therefore, we only use them to test TC, CF, and MC. Pdb is used only for FSM.</p><p>Unless specified otherwise, CPU experiments were conducted on a single machine with Intel Xeon Gold 5120 CPU 2.2GHz, 4 sockets (14 cores each), 190GB memory, and 3TB SSD. AutoMine was evaluated using 40 threads (with hyperthreading) on Intel Xeon E5-2630 v4 CPU 2.2GHz, 2 sockets (10 cores each), 64GB of memory, and 2TB of SSD. Kaleido was tested using 56 threads (with hyperthreading) on Intel Xeon Gold 5117 CPU 2.0GHz, 2 sockets (14 cores each), 128GB memory, and 480GB SSD. To make our comparison fair, we restrict our experiments to use only 2 sockets of our machine, but we only use 28 threads without hyperthreading. For the largest graph, Gsh, we used a 2 socket machine with Intel's second generation Xeon scalable processor with 2.2 Ghz and 48 cores, equipped with 6TB of Intel Optane PMM <ref type="bibr" target="#b35">[36]</ref> (byte-addressable memory technology). Our GPU platforms are NVIDIA GTX 1080Ti (11GB memory) and Tesla V100 (32GB memory) GPUs with CUDA 9.0. Unless specified otherwise, GPU results reported are on V100.</p><p>RStream writes its intermediate data to the SSD, whereas other frameworks run all applications in memory. We exclude preprocessing time and only report the computation time (on the CPU or GPU) as an average of 3 runs. We also exclude the time to transfer data from CPU to GPU as it is trivial compared to the GPU compute time.  <ref type="table" target="#tab_7">3a</ref> and Table <ref type="table" target="#tab_8">4</ref> respectively (because it does not have other applications or datasets respectively). Note that Kaleido and AutoMine results on 28-core and 20-core CPU, respectively, are reported from their papers. We evaluate the rest on our 28-core CPU, except that we evaluate Pangolin for gsh on 48-core CPU. Fractal and AutoMine use DFS-based exploration, whereas the rest use BFS-based exploration. Pangolin is an orderof-magnitude faster than Arabesque, RStream, Fractal, and G-Miner. Pangolin outperforms Kaleido in all cases except 4-MC on patent. Pangolin on CPU is comparable or slower than AutoMine but outperforms it by exploiting the GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">GPM Frameworks</head><p>For small inputs (e.g., TC and 3-CF with Mi), Arabesque suffers non-trivial overhead due to the startup cost of Giraph. For large graphs, however, due to lack of algorithmic (e.g., eager pruning and customized pattern classification) and data structure optimizations, it is also slower than Pangolin. On average, Pangolin is 49× faster than Arabesque.</p><p>For RStream, the number of partitions P is a key performance knob. For each configuration, we choose P to be the best performing one among 10, 20, 50, and 100. RStream only supports edge-induced exploration and does not support pattern-specific optimization. This results in extremely large search spaces for CF and MC because there are many   more edges than vertices. In addition, RStream does not scale well because of the intensive use of mutex locks for updating shared data. Lastly, Pangolin avoids inefficient data structures and expensive redundant computation (isomorphism test) used by RStream. Pangolin is 88× faster than RStream on average (Kaleido <ref type="bibr" target="#b86">[87]</ref> also observes that RStream is slower than Arabesque).</p><p>On average, Pangolin is 2.6× faster than Kaleido (7.4×, 3.3×, 2.4×, and 1.6× for TC, CF, MC, and FSM respectively). This is mainly due to DAG construction and customized pattern classification in Pangolin.</p><p>Pangolin is on average 80× faster than Fractal. Fractal is built on Spark and suffers from overheads due to it. More importantly, some optimizations in hand-optimized DFS-based applications like PGD <ref type="bibr" target="#b2">[3]</ref> and KClist <ref type="bibr" target="#b24">[25]</ref> are not supported in Fractal, which limits its performance.</p><p>AutoMine uses a key optimization <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b24">25]</ref> to remove redundant computation that can only be enabled in DFSbased exploration. Due to this, when pattern size k is large like in 5-CF and 4-MC, AutoMine is faster than Pangolin. However, since Pangolin uses BFS-based exploration which easily enables GPU acceleration, Pangolin on GPU is on average 5.8× faster than AutoMine. It is not clear how to enable DFS mode for GPU efficiently, especially when k is large. Note that for all the applications, AutoMine can only do counting but not listing, because it has no automorphism test during extension (instead it uses post-processing to address the multiplexity issue). FSM in AutoMine uses frequency (which is not anti-monotonic) instead of domain support, and thus it is not comparable to FSM in Pangolin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Hand-Optimized GPM Applications</head><p>We compare hand-optimized implementations with Pangolin on CPU and GPU. We report results for the largest datasets supported on our platform for each application. Note that all hand-optimized applications involve substantially more programming effort than Pangolin ones. Handoptimized TC has 4× more lines of code (LoC) than Pangolin TC. The other hand-optimized applications have one or two orders of magnitude more LoC than Pangolin ones.</p><p>In Table <ref type="table" target="#tab_7">3a</ref>, we compare with GAP <ref type="bibr" target="#b9">[10]</ref> and DistTC <ref type="bibr" target="#b40">[41]</ref>, the state-of-the-art TC implementations on CPU and GPU, respectively. It is clear from Table <ref type="table" target="#tab_5">2</ref> and Table <ref type="table" target="#tab_7">3a</ref> that TC implementations in existing GPM frameworks are orders of magnitude slower than the hand-optimized implementation in GAP. In contrast, Pangolin performs similar to GAP on the same CPU. Pangolin is also faster than DistTC on the same GPU due to its embedding list data structure, which has better load balance and memory access behavior.</p><p>Table <ref type="table" target="#tab_7">3b</ref> compares our 4-clique with KClist <ref type="bibr" target="#b24">[25]</ref>, the stateof-the-art CF implementation. Pangolin is 10 to 20× slower than KClist on the CPU, although GPU acceleration of Pangolin significantly reduces the performance gap. This is because KClist constructs a shrinking local graph for each edge, which significantly reduces the search space. This optimization can only enabled in the DFS exploration. In Table 3c, we observe the same trend for 3-MC compared with PGD, the state-of-the-art MC solver for multicore CPU <ref type="bibr" target="#b2">[3]</ref> and GPU <ref type="bibr" target="#b69">[70]</ref>. Note that PGD can only do counting, but not listing, as it only counts some of the patterns and the other patterns' counts are calculated directly using some formulas. In contrast, MC in Pangolin can do both counting and listing. Another limitation of PGD is that it can only handle 3-MC and 4-MC, while Pangolin handles arbitrary k. As PGD for GPU (PGD-GPU) <ref type="bibr" target="#b69">[70]</ref> is not released, we estimate PGD-GPU performance using their reported speedup <ref type="bibr" target="#b69">[70]</ref> on Titan Black GPU. Pangolin-GPU is 20% to 130% slower.</p><p>Table <ref type="table" target="#tab_7">3d</ref> and Table <ref type="table" target="#tab_7">3e</ref> compares our 3-FSM and 4-FSM, respectively, with DistGraph <ref type="bibr" target="#b78">[79,</ref><ref type="bibr" target="#b79">80]</ref>. DistGraph supports both shared-memory and distributed platforms. DistGraph supports a runtime parameter σ, which specifies the minimum support, but we had to modify it to add the maximum size k. On CPU, Pangolin outperforms DistGraph for 3-FSM in all cases, except for Pa with support 5K. For graphs that fit in the GPU memory (Mi, Pa), Pangolin on GPU is 6.9× to 290× faster than DistGraph. In comparison, the GPU implementation of DistGraph is only 4× to 9× faster than its CPU implementation <ref type="bibr" target="#b48">[49]</ref> (we are not able able to run their GPU code and we cannot compare with their reported results as they do not evaluate the same datasets). For 4-FSM, Pangolin is 22% to 240% slower than DistGraph. The slowdown is mainly due to the algorithmic differences: DistGraph adopts DFS exploration and a recursive approach which reduces computation and memory consumption, while Pangolin does BFS exploration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Scalability and GPU Performance</head><p>Although Pangolin is an in-memory processing system, Pangolin can scale to very large datasets by using large memory systems. To demonstrate this, we evaluate Pangolin on the Intel Optane PMM system and mine a very large realworld web crawl, Gsh. As shown in Table <ref type="table" target="#tab_8">4b</ref>, TC and 3-CF only take 2 and 11 minutes, respectively. 4-CF is much more compute and memory intensive, so it takes ∼ 6.5 hours. To  the best of our knowledge, this is the largest graph dataset for which 4-CF has been mined. Fig. <ref type="figure" target="#fig_0">13</ref> illustrates how the performance of Pangolin applications scales as the number of threads increases for different applications on Yo. Pangolin achieves good scalability by utilizing efficient, concurrent, scalable data structures and allocators. For TC, we observe near linear speedup over single-thread execution. In contrast, FSM's scalability suffers due to the overheads of computing domain support.</p><p>To test weak scaling, we use the RMAT graph generator <ref type="bibr" target="#b49">[50]</ref> to generate graphs with vertices |V | from 2 20 to 2 25  and average degree d = 20. Fig. <ref type="figure" target="#fig_12">14</ref> reports the execution time normalized to that of rmat20 (log-log scale). The execution time grows exponentially as the graph size increases because the enumeration search space grows exponentially. Fig. <ref type="figure" target="#fig_3">15</ref> illustrates speedup of Pangolin applications on GPU over 28 threads CPU. Note that due to the limited memory size, GPUs fail to run some applications and inputs. On average, 1080Ti and V100 GPUs achieve a speedup of 6× and 15× respectively over the CPU execution. Specifically, we observe substantial speedup on CF and MC. For example, the V100 GPU achieves 50× speedup on 4-MC for Yo, demonstrating the suitability of GPUs for these compute intensive applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Memory Consumption</head><p>The peak memory consumption for Arabesque, RStream, and Pangolin is illustrated in Fig. <ref type="figure" target="#fig_13">16</ref>. All systems are evaluated on the same 28-core CPU platform. We observe that Arabesque always requires the most memory because it is implemented in Java using Giraph <ref type="bibr" target="#b36">[37]</ref> framework that allocates a huge amount of memory. In contrast, Pangolin avoids this overhead and reduces memory usage. Since Pangolin does in-memory computation, it is expected to consume much more memory than RStream which stores its embeddings in disk. However, we find that the difference in memory usage is trivial because aggressive search space pruning and customized pattern classification significantly reduce memory usage. Since this small memory cost brings substantial performance improvement, we believe Pangolin makes a reasonable trade-off. For 4-MC, RStream runs out of memory due to its edge-induced exploration (Arabesque and Pangolin are using vertex-induced exploration).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Impact of Optimizations</head><p>We evaluate the performance improvement due to the optimizations described in Section 4 and Section 5. Due to lack of space, we present these comparisons only for the CPU implementations, but the results on the GPU are similar. Fig. <ref type="figure" target="#fig_15">17a</ref> shows the impact of orientation (DAG) and userdefined eager pruning (Prune) on 4-CF. Both techniques significantly improve performance for TC (not shown) and CF. Fig. <ref type="figure" target="#fig_15">17b</ref> demonstrates the advantage of using Galois memory allocators instead of std allocators. This is particularly important for FSM as it requires intensive memory allocation for counting support. Fig. <ref type="figure" target="#fig_15">17c</ref> illustrates that customized pattern classification used in MC and FSM yields huge performance gains by eliding expensive generic isomorphism tests. Fig. <ref type="figure" target="#fig_15">17d</ref> shows that materialization of temporary embeddings causes 11% to 37% slowdown for MC. This overhead exists in every application of Arabesque (and RStream), and is avoided in Pangolin. In Fig. <ref type="figure">18a</ref>, we evaluate the performance of our proposed embedding list data structure with SoA layout and inspection-execution. Compared to the straight-forward embedding queue (mimic the AoS implementation used in Arabesque and RStream), the k-MC performance is 2.1× to 4.7× faster. Another optimization is employing binary search for connectivity check. Fig. <ref type="figure">18b</ref> shows that binary search can achieve up to 6.6× speedup compared to linear search. Finally, Fig. <ref type="figure" target="#fig_8">19</ref> illustrates the last level cache (LLC) miss counts in the vertex extension phase of k-CF. We compare two data structure schemes for the embeddings, AoS and SoA. We observe a sharp reduction of LLC miss count by switching from AoS to SoA. This further confirms that SoA has better locality than AoS, due to the data reuse among embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Related Work</head><p>GPM Applications: Hand-optimized GPM applications target various platforms. For triangle counting, Shun et al. <ref type="bibr" target="#b75">[76]</ref> present a parallel, cache-oblivious TC solver on multicore CPUs that achieves good cache performance without finetuning cache parameters. Load balancing is applied in distributed TC solvers <ref type="bibr" target="#b77">[78,</ref><ref type="bibr" target="#b34">35]</ref> to evenly distribute workloads. TriCore <ref type="bibr" target="#b42">[43]</ref> is a multi-GPU TC solver that uses binary search to increase coalesced memory accesses, and it employs dynamic load balancing.</p><p>Chiba and Nishizeki (C&amp;N) <ref type="bibr" target="#b22">[23]</ref> proposed an efficient kclique listing algorithm which computes the subgraph induced by neighbors of each vertex, and then recurses on the subgraph. Danisch et al. <ref type="bibr" target="#b24">[25]</ref> refine the C&amp;N algorithm for parallelism and construct DAG using a core value based ordering to further reduce the search space. PGD <ref type="bibr" target="#b2">[3]</ref> counts 3 and 4-motifs by leveraging a number of proven combinatorial arguments for different patterns. Some patterns (e.g., cliques) are counted first, and the frequencies of other patterns are obtained in constant time using these combinatorial arguments. Escape <ref type="bibr" target="#b67">[68]</ref> extends this approach to 5vertex subgraphs and leverages DAG to reduce search space.</p><p>Frequent subgraph mining (FSM) <ref type="bibr" target="#b43">[44]</ref> is one of the most important GPM applications. gSpan <ref type="bibr" target="#b85">[86]</ref> is an efficient sequential FSM solver which implements a depth-first search (DFS) based on a lexicographic order called minimum DFS Code. GraMi <ref type="bibr" target="#b29">[30]</ref> proposes an approach that finds only the minimal set of instances to satisfy the support threshold and avoids enumerating all instances. This idea has been adopted by most other frameworks. DistGraph <ref type="bibr" target="#b78">[79]</ref> parallelizes gSpan for both shared-memory and distributed CPUs. Each worker thread does the DFS walk concurrently. To balance workload, it introduces a customized dynamic load balancing strategy which splits tasks on the fly and recomputes the embedding list from scratch after the task is sent to a new worker. Scalemine <ref type="bibr" target="#b0">[1]</ref> solves FSM with a twophase approach, which approximates frequent subgraphs in phase-1, and uses collected information to compute the exact solution in phase-2.   Other important GPM applications includes maximal cliques <ref type="bibr" target="#b19">[20]</ref>, maximum clique <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b1">2]</ref>, and subgraph listing <ref type="bibr" target="#b73">[74,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b53">54]</ref>. They employ various optimizations to reduce computation and improve hardware efficiency. They inspired our work to design a flexible interface for user-defined optimizations. However, they achieve high performance at the cost of tremendous programming efforts, while Pangolin provides a unified model for ease of programming.</p><p>GPM Frameworks: For ease-of-programming, GPM systems such as Arabesque <ref type="bibr" target="#b80">[81]</ref>, RStream <ref type="bibr" target="#b84">[85]</ref>, G-Miner <ref type="bibr" target="#b17">[18]</ref>, and Kaleido <ref type="bibr" target="#b86">[87]</ref> have been proposed. They provide a unified programming interface to the user which simplifies application development. However, their interface is not flexible enough to enable application specific optimizations. Instead of the BFS exploration used in these frameworks, Fractal <ref type="bibr" target="#b27">[28]</ref> employs a DFS strategy to enumerate subgraphs, which reduces memory footprint. AutoMine <ref type="bibr" target="#b62">[63]</ref> is a compilerbased GPM system using DFS exploration. In contrast, Pangolin uses the BFS approach that is inherently more load-balanced, and is better suited for GPU acceleration. In the future, we plan to also support DFS exploration. Evo-Graph <ref type="bibr" target="#b72">[73]</ref> is a GPU framework supporting both graph analytics and mining. However, as it is not designed specifically for GPM, many features such as automorphism and isomorphism test are not supported, which places a lot of burden on the programmer for complex GPM problems.</p><p>Approximate GPM: There are approximate solvers for TC <ref type="bibr" target="#b82">[83,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b81">82]</ref>, CF <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b45">46]</ref>, MC <ref type="bibr" target="#b76">[77,</ref><ref type="bibr" target="#b14">15]</ref>, and FSM <ref type="bibr" target="#b5">[6]</ref>. ASAP <ref type="bibr" target="#b44">[45]</ref> is an approximate GPM framework that supports various GPM applications. It extends graph approximation theory to general patterns and incurs less than 5% error. Since approximation reduces computation, ASAP is much faster than exact frameworks like Arabesque, and scales to large graphs. Chen and Lui <ref type="bibr" target="#b18">[19]</ref> propose another approximate GPM framework based on random walk. Compared to approximate solutions, Pangolin focuses on exact GPM and achieves high performance without sacrificing accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion</head><p>We present Pangolin, a high-performance, flexible GPM system on shared-memory CPUs and GPUs. Pangolin provides a simple programming interface that enables the user to specify eager enumeration search space pruning and customized pattern classifications. To exploit locality, Pangolin uses an efficient structure of arrays (SoA) for storing embeddings. It avoids materialization of temporary embeddings and blocks the schedule of embedding exploration to reduce the memory usage. It also uses inspection-execution and scalable memory allocators to mitigate the overheads of dynamic memory allocation. These application-specific and architectural optimizations enable Pangolin to outperform prior GPM frameworks, Arabesque, RStream, and Fractal, by 49×, 88×, and 80×, on average, respectively, on the same 28-core CPU. Moreover, Pangolin on V100 GPU is 15× faster than that on the CPU on average. Thus, Pangolin provides performance competitive with hand-optimized implementations but with much better programming experience. To mine 4-cliques in a web-crawl (gsh) with 988 million vertices and 51 billion edges, Pangolin takes ∼ 6.5 hours on a 48-core Intel Optane machine with 6 TB memory.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 : 3 -</head><label>13</label><figDesc>Figure 1: 3-vertex motifs (top) and 4-vertex motifs (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: An example of the GPM problem.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: An example of vertex extension.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Reduction operation that calculates pattern frequency using a pattern map.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: An example of automorphism.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Listing 4 :</head><label>4</label><figDesc>bool toAdd(Embedding emb, Vertex v) { return isAutoCanonical(emb, v); } Support getSupport(Embedding emb) { return 1; } Pattern getPattern(Embedding emb) { return getIsoCanonicalBliss(emb); } Support Aggregate(Support s1, Support s2) { return s1 + s2; } Motif counting (vertex induced) in Pangolin. bool toAdd(Embedding emb, Edge e) { return isAutoCanonical(emb,e) } Support getSupport(Embedding emb) { return getDomainSupport(emb); } Pattern getCanonicalPattern(Embedding emb) { return getIsoCanonicalBliss(emb); } Support Aggregate(Support s1, Support s2) { return mergeDomainSupport(s1, s2); } bool toPrune(Embedding emb, PatternMap map) { return (getPatternSupport(emb, map) &lt; MIN_SUPPORT) } Listing 5: Frequent subgraph mining (edge induced) in Pangolin.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>Figure 7: Convert an undirected graph into a DAG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>2). Like Arabesque and Pattern getPattern(Embedding emb) { if (emb.size() == 3) { if (emb.getNumEdges() == 3) return P1; else return P0; } else return getIsoCanonicalBliss(emb); } Listing 6: Customized pattern classification for 3-MC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: An example of the embedding list data structure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 :Figure 11 :</head><label>1011</label><figDesc>Figure 10: Edge blocking.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 12 :</head><label>12</label><figDesc>Figure12: Binary search for connectivity check. The current embedding is {2, 5, 8}, which we are trying to extend by adding vertex 9. To check which vertices in the embedding are directly connected to vertex 9, we use '2', '5', and '8' as the keys to search in the neighbor list of vertex 9. Using binary search we find '2' and '5' are connected to '9'.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Strong scaling using Yo graph. σ=500 for FSM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 14 :</head><label>14</label><figDesc>Figure 14: Execution time for RMAT graphs (log-log scale).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 16 :</head><label>16</label><figDesc>Figure 16: Peak memory usage in Arabesque, RStream, and Pangolin for Pa (4-MC in RStream runs out of memory).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>k-MC (avoid materialization)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 17 :</head><label>17</label><figDesc>Figure 17: Speedup due to various optimizations: (a) eager pruning and DAG; (b) Galois scalable memory allocator; (c) customized pattern classification; (d) avoiding materialization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 18 :Figure 19 :</head><label>1819</label><figDesc>Figure 18: k-MC speedup of (a) using embedding list (SoA+inspection-execution) over using embedding queue (AoS) and (b) binary search over linear search.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>•</head><label></label><figDesc>We propose novel optimizations that exploit locality, reduce memory usage, and mitigate overheads of dynamic memory allocation and synchronization on CPU and GPU.</figDesc><table><row><cell>• We evaluate Pangolin on a multicore CPU and a GPU</cell></row><row><cell>to demonstrate that Pangolin is substantially faster than</cell></row><row><cell>existing GPM frameworks. Compared to hand-optimized</cell></row><row><cell>applications, it provides competitive performance while</cell></row><row><cell>requiring less programming effort.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Listing 2: Helper routines provided to the user by Pangolin.</figDesc><table><row><cell cols="2">1 // connectivity checking routines</cell></row><row><cell cols="2">2 bool isConnected(Vertex u, Vertex v)</cell></row><row><cell>3</cell><cell></cell></row><row><cell cols="2">4 // canonical test routines</cell></row><row><cell cols="2">5 bool isAutoCanonical(Embedding emb, Vertex v)</cell></row><row><cell cols="2">6 bool isAutoCanonical(Embedding emb, Edge e)</cell></row><row><cell cols="2">7 Pattern getIsoCanonicalBliss(Embedding emb)</cell></row><row><cell cols="2">8 Pattern getIsoCanonicalEigen(Embedding emb)</cell></row><row><cell>9</cell><cell></cell></row><row><cell cols="2">10 // to get domain (MNI) support</cell></row><row><cell cols="2">11 Support getDomainSupport(Embedding emb)</cell></row><row><cell cols="2">12 Support mergeDomainSupport(Support s1, Support s2)</cell></row><row><cell cols="2">13 Support getPatternSupport(Embedding emb)</cell></row><row><cell cols="2">14 Support getPatternSupport(Edge e)</cell></row><row><cell cols="2">1 bool toExtend(Embedding emb, Vertex v) {</cell></row><row><cell>2</cell><cell>return (emb.getLastVertex() == v);</cell></row><row><cell>3 }</cell><cell></cell></row><row><cell cols="2">4 bool toAdd(Embedding emb, Vertex u) {</cell></row><row><cell>5</cell><cell>for v in emb.getVertices() except last:</cell></row><row><cell>6</cell><cell>if (!isConnected(v, u)) return false;</cell></row></table><note>7 return true; 8 } Listing 3: Clique finding (vertex induced) in Pangolin.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Input graphs (symmetric, no loops, no duplicate edges)</figDesc><table><row><cell>Graph</cell><cell>Source</cell><cell># V</cell><cell># E</cell><cell cols="2">d Labels</cell></row><row><cell>Mi</cell><cell>Mico [30]</cell><cell>100,000</cell><cell cols="2">2,160,312 22</cell><cell>29</cell></row><row><cell>Pa</cell><cell>Patents [40]</cell><cell>2,745,761</cell><cell cols="2">27,930,818 10</cell><cell>37</cell></row><row><cell>Yo</cell><cell>Youtube [21]</cell><cell>7,066,392</cell><cell cols="2">114,190,484 16</cell><cell>29</cell></row><row><cell>Pdb</cell><cell>ProteinDB [79]</cell><cell>48,748,701</cell><cell>387,730,070</cell><cell>8</cell><cell>25</cell></row><row><cell>Lj</cell><cell>LiveJournal [55]</cell><cell>4,847,571</cell><cell cols="2">85,702,474 18</cell><cell>0</cell></row><row><cell>Or</cell><cell>Orkut [55]</cell><cell>3,072,441</cell><cell cols="2">234,370,166 76</cell><cell>0</cell></row><row><cell>Tw</cell><cell>Twitter [53]</cell><cell>21,297,772</cell><cell cols="2">530,051,090 25</cell><cell>0</cell></row><row><cell>Gsh</cell><cell cols="4">Gsh-2015 [14] 988,490,691 51,381,410,236 52</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>illustrates an example of binary search for connectivity check. This is particularly efficient on GPU, as it improves GPU</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Mi</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Pa</cell><cell></cell><cell></cell><cell></cell><cell>Yo</cell><cell></cell></row><row><cell>App</cell><cell>Option</cell><cell>AR</cell><cell cols="2">RS KA  †</cell><cell>FR</cell><cell>PA</cell><cell>AR</cell><cell>RS</cell><cell>KA  †</cell><cell>FR</cell><cell>PA</cell><cell>AR</cell><cell>RS</cell><cell>KA  †</cell><cell>PA</cell></row><row><cell>TC</cell><cell></cell><cell>30.8</cell><cell>2.6</cell><cell>0.2</cell><cell></cell><cell cols="2">0.02 100.8</cell><cell>7.8</cell><cell>0.5</cell><cell></cell><cell>0.08</cell><cell>601.3</cell><cell>39.8</cell><cell>2.2</cell><cell>0.3</cell></row><row><cell></cell><cell>3</cell><cell>32.2</cell><cell>7.3</cell><cell>0.5</cell><cell>24.7</cell><cell>0.04</cell><cell>97.8</cell><cell>39.1</cell><cell cols="2">0.6 350.2</cell><cell>0.2</cell><cell>617.0</cell><cell>862.3</cell><cell>2.2</cell><cell>0.7</cell></row><row><cell>CF</cell><cell>4</cell><cell>41.7</cell><cell>637.8</cell><cell>3.9</cell><cell>30.6</cell><cell cols="2">1.6 108.1</cell><cell>62.1</cell><cell cols="2">1.1 410.1</cell><cell cols="2">0.4 1086.9</cell><cell>-</cell><cell>7.8</cell><cell>3.1</cell></row><row><cell></cell><cell>5</cell><cell>311.9</cell><cell cols="3">-183.6 488.9</cell><cell cols="2">60.5 108.8</cell><cell>76.9</cell><cell cols="2">1.5 463.5</cell><cell cols="2">0.5 1123.6</cell><cell>-</cell><cell>19.0</cell><cell>7.3</cell></row><row><cell>MC</cell><cell>3 4</cell><cell cols="14">36.1 7137.5 353.0 -198.2 243.2 175.6 779.8 1.4 41.2 0.2 101.6 3886.9 -152.3 561.1 209.1 5132.8 4.7 236.3 0.9 538.4 89387.0 -4989.0 4405.3 35.5 5.5</cell></row><row><cell></cell><cell>300</cell><cell>104.9</cell><cell>56.8</cell><cell cols="2">7.4 780.5</cell><cell cols="2">3.9 340.7</cell><cell>230.1</cell><cell cols="2">25.5 720.3</cell><cell>14.7</cell><cell>666.9</cell><cell>1415.1</cell><cell>132.6</cell><cell>96.9</cell></row><row><cell>3-FSM</cell><cell>500 1000</cell><cell>72.2 48.5</cell><cell>57.9 52.9</cell><cell cols="2">8.2 773.1 7.8 697.2</cell><cell cols="2">3.6 433.6 3.0 347.3</cell><cell>208.6 194.0</cell><cell cols="2">26.4 817.0 28.7 819.9</cell><cell>15.8 18.1</cell><cell>576.5 693.2</cell><cell>1083.9 1179.3</cell><cell>133.3 136.2</cell><cell>97.8 98.0</cell></row><row><cell></cell><cell>5000</cell><cell>36.4</cell><cell>35.6</cell><cell cols="2">3.9 396.3</cell><cell cols="2">2.4 366.1</cell><cell>172.2</cell><cell cols="2">31.5 915.5</cell><cell>27.0</cell><cell>758.6</cell><cell>1248.1</cell><cell>155.0</cell><cell>102.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2</head><label>2</label><figDesc>reports the execution time of Arabesque, RStream, Kaleido, Fractal, and Pangolin. The execution time of G-Miner and AutoMine is reported in Table</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Execution time (sec) of Pangolin (PA) and hand-optimized solvers (σ: minimum support). PA-GPU and DistTC-GPU are on V100 GPU; PGD-GPU is on Titan Black GPU; rest are on 28 core CPU. † PGD-GPU results are reported from their paper.</figDesc><table><row><cell></cell><cell cols="3">AM  † PA-CPU PA-GPU</cell><cell>AM  †</cell><cell>PA</cell></row><row><cell>TC 3-MC 4-MC 5-CF</cell><cell>0.04 0.12 22.0 11.4</cell><cell>0.02 0.20 175.6 60.5</cell><cell>0.001 0.02 5.3 9.7</cell><cell cols="2">TC 3-CF 4-CF 45399 23475 4966 139.3 -659.3</cell></row><row><cell></cell><cell></cell><cell>(a) Mi.</cell><cell></cell><cell>(b) Gsh.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Execution time (sec) of Pangolin (PA) and AutoMine (AM). Pangolin for Gsh is evaluated on Intel Optane-PMM machine. † AutoMine results are reported from its paper.</figDesc><table /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Scalemine: Scalable parallel frequent subgraph mining in a single large graph</title>
		<author>
			<persName><forename type="first">E</forename><surname>Abdelhamid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Abdelaziz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kalnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Khayyat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jamour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, SC &apos;16</title>
				<meeting>the International Conference for High Performance Computing, Networking, Storage and Analysis, SC &apos;16<address><addrLine>Piscataway, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="1" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Scalable maximum clique computation using mapreduce</title>
		<author>
			<persName><forename type="first">A</forename><surname>Aboulnaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 IEEE International Conference on Data Engineering (ICDE 2013), ICDE &apos;13</title>
				<meeting>the 2013 IEEE International Conference on Data Engineering (ICDE 2013), ICDE &apos;13<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="74" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Efficient graphlet counting for large networks</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duffield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Biomolecular network motif counting and discovery by color coding</title>
		<author>
			<persName><forename type="first">N</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Hajirasouliha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hormozdiari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sahinalp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="241" to="249" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Color-coding: A new method for finding simple paths, cycles and other small subgraphs within large graphs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Zwick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-sixth Annual ACM Symposium on Theory of Computing, STOC &apos;94</title>
				<meeting>the Twenty-sixth Annual ACM Symposium on Theory of Computing, STOC &apos;94<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="326" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Approximate graph mining with label costs</title>
		<author>
			<persName><forename type="first">P</forename><surname>Anchuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Zaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Barkol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Golan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;13</title>
				<meeting>the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="518" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Computational complexity and the classification of finite simple groups</title>
		<author>
			<persName><forename type="first">L</forename><surname>Babai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Kantor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Luks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th Annual Symposium on Foundations of Computer Science (sfcs 1983)</title>
				<imprint>
			<date type="published" when="1983-11">Nov 1983</date>
			<biblScope unit="page" from="162" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Analysis and optimization of the memory hierarchy for graph processing workloads</title>
		<author>
			<persName><forename type="first">A</forename><surname>Basak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<date type="published" when="2019-02">Feb 2019</date>
			<biblScope unit="page" from="373" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Locality exists in graph processing: Workload characterization on an ivy bridge server</title>
		<author>
			<persName><forename type="first">S</forename><surname>Beamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Patterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 IEEE International Symposium on Workload Characterization, IISWC &apos;15</title>
				<meeting>the 2015 IEEE International Symposium on Workload Characterization, IISWC &apos;15<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="56" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The GAP benchmark suite</title>
		<author>
			<persName><forename type="first">S</forename><surname>Beamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
		<idno>CoRR, abs/1508.03619</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Higher-order organization of complex networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Gleich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">353</biblScope>
			<biblScope unit="issue">6295</biblScope>
			<biblScope unit="page" from="163" to="166" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Hoard: A scalable memory allocator for multithreaded applications</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Blumofe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS IX</title>
				<meeting>the Ninth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS IX<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="117" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ceci: Compact embedding cluster index for scalable subgraph matching</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bhattarai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 International Conference on Management of Data, SIGMOD &apos;19</title>
				<meeting>the 2019 International Conference on Management of Data, SIGMOD &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1447" to="1462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The WebGraph framework I: Compression techniques</title>
		<author>
			<persName><forename type="first">P</forename><surname>Boldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vigna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Thirteenth International World Wide Web Conference (WWW 2004)</title>
				<meeting>of the Thirteenth International World Wide Web Conference (WWW 2004)<address><addrLine>Manhattan, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="595" to="601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Counting graphlets: Space vs time</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bressan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chierichetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Leucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Panconesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth ACM International Conference on Web Search and Data Mining, WSDM &apos;17</title>
				<meeting>the Tenth ACM International Conference on Web Search and Data Mining, WSDM &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="557" to="566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Motif counting beyond five nodes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bressan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chierichetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Leucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Panconesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Knowl. Discov. Data</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="48" />
			<date type="published" when="2018-04">Apr. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A quantitative study of irregular programs on gpus</title>
		<author>
			<persName><forename type="first">M</forename><surname>Burtscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nasre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE International Symposium on Workload Characterization (IISWC)</title>
				<imprint>
			<date type="published" when="2012-11">Nov 2012</date>
			<biblScope unit="page" from="141" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">G-miner: An efficient task-oriented graph mining system</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth EuroSys Conference</title>
				<meeting>the Thirteenth EuroSys Conference<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mining graphlet counts in online social networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C S</forename><surname>Lui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Knowl. Discov. Data</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2018-04">Apr. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fast algorithms for maximal clique enumeration with limited memory</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;12</title>
				<meeting>the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1240" to="1248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Dataset for statistics and social network of youtube videos</title>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://netsg.cs.sfu.ca/youtubedata/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Falcon: A graph manipulation language for heterogeneous systems</title>
		<author>
			<persName><forename type="first">U</forename><surname>Cheramangalath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nasre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Srikant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Archit. Code Optim</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2015-12">Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Arboricity and subgraph listing algorithms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Chiba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nishizeki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="210" to="223" />
			<date type="published" when="1985-02">Feb. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Predicting protein function by frequent functional association pattern mining in protein interaction networks</title>
		<author>
			<persName><forename type="first">Y.-R</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Info. Tech. Biomed</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="36" />
			<date type="published" when="2010-01">Jan. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Listing k-cliques in sparse real-world graphs*</title>
		<author>
			<persName><forename type="first">M</forename><surname>Danisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Balalau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sozio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 World Wide Web Conference, WWW &apos;18</title>
				<meeting>the 2018 World Wide Web Conference, WWW &apos;18<address><addrLine>Republic and Canton of Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="589" to="598" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Gluon: A communication-optimizing substrate for distributed heterogeneous graph analytics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-V</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dryden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Snir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation</title>
				<meeting>the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="752" to="768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Frequent substructure-based approaches for classifying chemical compounds</title>
		<author>
			<persName><forename type="first">M</forename><surname>Deshpande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kuramochi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1036" to="1050" />
			<date type="published" when="2005-08">Aug 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Fractal: A general-purpose graph pattern mining system</title>
		<author>
			<persName><forename type="first">V</forename><surname>Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H C</forename><surname>Teixeira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guedes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Meira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Parthasarathy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 International Conference on Management of Data, SIGMOD &apos;19</title>
				<meeting>the 2019 International Conference on Management of Data, SIGMOD &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1357" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Beyond triangles: A distributed framework for estimating 3-profiles of large graphs</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Elenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Borokhovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Dimakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;15</title>
				<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="229" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Grami: Frequent subgraph and pattern mining in a single large graph</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elseidy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Abdelhamid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Skiadopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kalnis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
				<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2014-03">Mar. 2014</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="517" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Many-core graph workload analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Eyerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Heirman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Bois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Fryman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Hur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis, SC &apos;18</title>
				<meeting>the International Conference for High Performance Computing, Networking, Storage, and Analysis, SC &apos;18<address><addrLine>Piscataway, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Parallelizing sequential graph computations</title>
		<author>
			<persName><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM International Conference on Management of Data</title>
				<meeting>the 2017 ACM International Conference on Management of Data<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A puzzle concerning triads in social networks: Graph constraints and the triad census</title>
		<author>
			<persName><forename type="first">K</forename><surname>Faust</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Networks</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="221" to="233" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Computers and Intractability: A Guide to the Theory of NP-Completeness</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Garey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>W. H. Freeman &amp; Co</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">PDTL: Parallel and distributed triangle listing for massive graphs</title>
		<author>
			<persName><forename type="first">I</forename><surname>Giechaskiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Panagopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Yoneki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 44th International Conference on Parallel Processing</title>
				<imprint>
			<date type="published" when="2015-09">Sep. 2015</date>
			<biblScope unit="page" from="370" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Single machine graph analytics on massive datasets using intel optane DC persistent memory</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pingali</surname></persName>
		</author>
		<idno>CoRR, abs/1904.07162</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Apache</forename><surname>Giraph</surname></persName>
		</author>
		<ptr target="http://giraph.apache.org/" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">PowerGraph: Distributed Graph-parallel Computation on Natural Graphs</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;12</title>
				<meeting>the 10th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;12<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="17" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Fast triangle counting on the gpu</title>
		<author>
			<persName><forename type="first">O</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yalamanchili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-M</forename><surname>Munguía</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Irregular Applications: Architectures and Algorithms, IA3 &apos;14</title>
				<meeting>the 4th Workshop on Irregular Applications: Architectures and Algorithms, IA3 &apos;14<address><addrLine>Piscataway, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A B</forename></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename></persName>
		</author>
		<ptr target="http://www.nber.org/patents/" />
		<title level="m">The NBER patent citation data file: Lessons, insights and methodological tools</title>
				<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">DistTC: High performance distributed triangle counting</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Jatala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPEC 2019 23rd IEEE High Performance Extreme Computing</title>
				<imprint>
			<date type="published" when="2019-09">September 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Multigraph: Efficient graph processing on gpus</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sukumaran-Rajam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sadayappan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)</title>
				<imprint>
			<date type="published" when="2017-09">Sep. 2017</date>
			<biblScope unit="page" from="27" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Tricore: Parallel triangle counting on gpus</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SC18: International Conference for High Performance Computing, Networking, Storage and Analysis</title>
				<imprint>
			<date type="published" when="2018-11">Nov 2018</date>
			<biblScope unit="page" from="171" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Efficient mining of frequent subgraphs in the presence of isomorphism</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Prins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third IEEE International Conference on Data Mining</title>
				<imprint>
			<date type="published" when="2003-11">Nov 2003</date>
			<biblScope unit="page" from="549" to="552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Asap: Fast, approximate graph pattern mining at scale</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkataraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Braverman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;18</title>
				<meeting>the 12th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;18<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="745" to="761" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A fast and provable method for estimating clique counts using turán&apos;s theorem</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Seshadhri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web, WWW &apos;17</title>
				<meeting>the 26th International Conference on World Wide Web, WWW &apos;17<address><addrLine>Republic and Canton of Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="441" to="449" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Path sampling: A fast and provable method for estimating 4-vertex subgraph counts</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Seshadhri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pinar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web, WWW &apos;15</title>
				<meeting>the 24th International Conference on World Wide Web, WWW &apos;15<address><addrLine>Republic and Canton of Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="495" to="505" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Engineering an efficient canonical labeling tool for large and sparse graphs</title>
		<author>
			<persName><forename type="first">T</forename><surname>Junttila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kaski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Meeting on Algorithm Engineering &amp; Expermiments</title>
				<meeting>the Meeting on Algorithm Engineering &amp; Expermiments<address><addrLine>Philadelphia, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Society for Industrial and Applied Mathematics</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="135" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Parallel graph mining with gpus</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kessl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Talukder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Anchuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Zaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems</title>
		<title level="s">Programming Models and Applications</title>
		<meeting>the 3rd International Conference on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Scalable simd-efficient graph processing on gpus</title>
		<author>
			<persName><forename type="first">F</forename><surname>Khorasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">N</forename><surname>Bhuyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 International Conference on Parallel Architecture and Compilation (PACT), PACT 15</title>
				<meeting>the 2015 International Conference on Parallel Architecture and Compilation (PACT), PACT 15<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">3950</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">DUALSIM: Parallel subgraph enumeration in a massive graph on a single machine</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Bhowmick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Jarrah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 International Conference on Management of Data, SIGMOD &apos;16</title>
				<meeting>the 2016 International Conference on Management of Data, SIGMOD &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1231" to="1245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Turboflux: A fast continuous subgraph matching system for streaming graph data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 International Conference on Management of Data, SIGMOD &apos;18</title>
				<meeting>the 2018 International Conference on Management of Data, SIGMOD &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="411" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Konect: the koblenz network collection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kunegis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on World Wide Web</title>
				<meeting>the 22nd International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1343" to="1350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Scalable subgraph enumeration in mapreduce</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
				<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2015-06">June 2015</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="974" to="985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<title level="m">Snap: Stanford network analysis platform</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Network motif discovery: A gpu approach</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE 31st International Conference on Data Engineering</title>
				<imprint>
			<date type="published" when="2015-04">April 2015</date>
			<biblScope unit="page" from="831" to="842" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Simd-x: Programming and processing of graph algorithms on gpus</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 USENIX Conference on Usenix Annual Technical Conference, USENIX ATC 19</title>
				<meeting>the 2019 USENIX Conference on Usenix Annual Technical Conference, USENIX ATC 19<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">411427</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Cuda-meme: Accelerating motif discovery in biological sequences using cuda-enabled graphics processing units</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Maskell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="2170" to="2177" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">GraphLab: A New Parallel Framework for Machine Learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Conf. Uncertainty in Artificial Intelligence, UAI &apos;10</title>
				<meeting>Conf. Uncertainty in Artificial Intelligence, UAI &apos;10</meeting>
		<imprint>
			<date type="published" when="2010-07">July 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Finding the maximum clique in massive graphs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
				<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2017-08">Aug. 2017</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1538" to="1549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Distributed graph pattern matching</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on World Wide Web, WWW &apos;12</title>
				<meeting>the 21st International Conference on World Wide Web, WWW &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="949" to="958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Pregel: A system for large-scale graph processing</title>
		<author>
			<persName><forename type="first">G</forename><surname>Malewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Austern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Bik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Dehnert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Leiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Czajkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;10</title>
				<meeting>the ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="135" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Automine: Harmonizing high-level abstraction and high performance for graph mining</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mawhirter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM Symposium on Operating Systems Principles, SOSP 19</title>
				<meeting>the 27th ACM Symposium on Operating Systems Principles, SOSP 19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">509523</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Scalable lock-free dynamic memory allocation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Michael</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN 2004 Conference on Programming Language Design and Implementation, PLDI &apos;04</title>
				<meeting>the ACM SIGPLAN 2004 Conference on Programming Language Design and Implementation, PLDI &apos;04<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="35" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Network motifs: Simple building blocks of complex networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Milo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shen-Orr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Itzkovitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kashtan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chklovskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Alon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">298</biblScope>
			<biblScope unit="issue">5594</biblScope>
			<biblScope unit="page" from="824" to="827" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Scalable large near-clique detection in large-scale networks via sampling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mitzenmacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pachocki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tsourakakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;15</title>
				<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="815" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A lightweight infrastructure for graph analytics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lenharth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM Symposium on Operating Systems Principles (SOSP), SOSP &apos;13</title>
				<meeting>the 24th ACM Symposium on Operating Systems Principles (SOSP), SOSP &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="456" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Escape: Efficiently counting all 5-vertex subgraphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pinar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Seshadhri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vishal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web, WWW &apos;17</title>
				<meeting>the 26th International Conference on World Wide Web, WWW &apos;17<address><addrLine>Republic and Canton of Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1431" to="1440" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Approximate triangle counting algorithms on multi-cores</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Conference on Big Data</title>
				<imprint>
			<date type="published" when="2013-10">Oct 2013</date>
			<biblScope unit="page" from="127" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Leveraging multiple gpus and cpus for graphlet counting in large networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management, CIKM &apos;16</title>
				<meeting>the 25th ACM International on Conference on Information and Knowledge Management, CIKM &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1783" to="1792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Finding, counting and listing all triangles in large graphs, an experimental study</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Conference on Experimental and Efficient Algorithms, WEA&apos;05</title>
				<meeting>the 4th International Conference on Experimental and Efficient Algorithms, WEA&apos;05<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="606" to="609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Scalable locality-conscious multithreaded memory allocation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Antonopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Nikolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Symposium on Memory Management, ISMM &apos;06</title>
				<meeting>the 5th International Symposium on Memory Management, ISMM &apos;06<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="84" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Evograph: On-the-fly efficient mining of evolving graphs on gpu</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">High Performance Computing</title>
				<editor>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kunkel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Yokota</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Balaji</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Keyes</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="97" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Parallel subgraph listing in a large-scale graph</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;14</title>
				<meeting>the 2014 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="625" to="636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Ligra: A lightweight graph processing framework for shared memory</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Blelloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP), PPoPP &apos;13</title>
				<meeting>the 18th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP), PPoPP &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="135" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Multicore triangle computations without tuning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tangwongsan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE 31st International Conference on Data Engineering</title>
				<imprint>
			<date type="published" when="2015-04">April 2015</date>
			<biblScope unit="page" from="149" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Complex network analysis using parallel approximate motif counting</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Slota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Madduri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE 28th International Parallel and Distributed Processing Symposium</title>
				<imprint>
			<date type="published" when="2014-05">May 2014</date>
			<biblScope unit="page" from="405" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Counting triangles and the curse of the last reducer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Suri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vassilvitskii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on World Wide Web, WWW &apos;11</title>
				<meeting>the 20th International Conference on World Wide Web, WWW &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="607" to="614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">A distributed approach for graph mining in massive networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Talukder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Zaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1024" to="1052" />
			<date type="published" when="2016-09">Sept. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Parallel graph mining with dynamic load balancing</title>
		<author>
			<persName><forename type="first">N</forename><surname>Talukder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Zaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Big Data (Big Data)</title>
				<imprint>
			<date type="published" when="2016-12">Dec 2016</date>
			<biblScope unit="page" from="3352" to="3359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Arabesque: A system for distributed graph mining</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H C</forename><surname>Teixeira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Serafini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Siganos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Zaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aboulnaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Symposium on Operating Systems Principles, SOSP &apos;15</title>
				<meeting>the 25th Symposium on Operating Systems Principles, SOSP &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="425" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Fast counting of triangles in large real networks without counting: Algorithms and laws</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Tsourakakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2008 Eighth IEEE International Conference on Data Mining</title>
				<imprint>
			<date type="published" when="2008-12">Dec 2008</date>
			<biblScope unit="page" from="608" to="617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Doulion: Counting triangles in massive graphs with a coin</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Tsourakakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;09</title>
				<meeting>the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="837" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Parallel triangle counting and k-truss identification using graph-centric methods</title>
		<author>
			<persName><forename type="first">C</forename><surname>Voegele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/Amazon/DARPA GraphChallenge</title>
				<imprint>
			<publisher>IEEE HPEC</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Rstream: Marrying relational algebra with streaming for efficient graph mining on a single machine</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thorpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;18</title>
				<meeting>the 12th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;18<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="763" to="782" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">gspan: graph-based substructure pattern mining</title>
		<author>
			<persName><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 IEEE International Conference on Data Mining</title>
				<meeting>the 2002 IEEE International Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2002-12">Dec 2002</date>
			<biblScope unit="page" from="721" to="724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Kaleido: An efficient out-of-core graph mining system on A single machine</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<idno>CoRR, abs/1905.09572</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Gemini: A Computation-centric Distributed Graph Processing System</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;16</title>
				<meeting>the 12th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;16<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="301" to="316" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
