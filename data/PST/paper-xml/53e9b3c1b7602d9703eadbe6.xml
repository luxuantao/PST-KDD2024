<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automated detection and localisation of duplicated regions affected by reflection, rotation and scaling in image forensics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2011-03-05">5 March 2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sergio</forename><surname>Bravo-Solorio</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Electronics</orgName>
								<orgName type="institution">The University of Liverpool</orgName>
								<address>
									<addrLine>Brownlow Hill</addrLine>
									<postCode>L69 3GJ</postCode>
									<settlement>Liverpool</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Asoke</forename><forename type="middle">K</forename><surname>Nandi</surname></persName>
							<email>aknandi@liverpool.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Electronics</orgName>
								<orgName type="institution">The University of Liverpool</orgName>
								<address>
									<addrLine>Brownlow Hill</addrLine>
									<postCode>L69 3GJ</postCode>
									<settlement>Liverpool</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Automated detection and localisation of duplicated regions affected by reflection, rotation and scaling in image forensics</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2011-03-05">5 March 2011</date>
						</imprint>
					</monogr>
					<idno type="MD5">CC6D30B454AE775989F73966E46A3E30</idno>
					<idno type="DOI">10.1016/j.sigpro.2011.01.022</idno>
					<note type="submission">Received 21 April 2010 Received in revised form 22 January 2011 Accepted 31 January 2011</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Image forensics Copy-move Log-polar mapping Security</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Although the detection of duplicated regions plays an important role in image forensics, most of the existing methods aimed at detecting duplicates are too sensitive to geometric changes in the replicated areas. As a result, a slight rotation can be used not only for the copied region to fit better the scene in the image, but also to hinder the detection of the tampering. In this paper, a novel forensic method is presented to detect duplicated regions, even when the copied portions have undergone reflection, rotation and/or scaling. To achieve this, overlapping blocks of pixels are mapped to log-polar coordinates, and then summed along the angle axis, to produce a one-dimensional (1-D) descriptor invariant to reflection and rotation. Besides, scaling in rectangular coordinates results in a simple translation of the descriptor. The dimension-reduced representation of each block has a favourable impact in the computational cost of the search of similar regions. Extensive experimental results, including a comparative evaluation with two existing methods, are presented to demonstrate the effectiveness of the proposed method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Existing digital image technology provides sophisticated processing tools that can be used to produce forgeries which cannot be easily identified, even by trained observers. This has raised serious concerns about the use of digital images in areas that handle sensible information, such as medical and military applications. Table <ref type="table" target="#tab_0">1</ref> presents a general classification of the techniques conceived to address such concerns. The concept of Trustworthy Digital Camera, introduced by Friedman <ref type="bibr" target="#b0">[1]</ref>, can be considered an active technique, whereby a digital signature is computed within the camera at the time of capturing, and then appended to the image as metadata. This method is non-invasive, as the image is not distorted at all by this process. Digital watermarking describes other active techniques, whereby certain information is imperceptibly embedded in images <ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref>. However, this approach is invasive in the sense that certain distortion is unavoidable during the embedding process. In practice, active techniques are limited to controlled environments, such as surveillance cameras, where the capturing devices are equipped with appropriate electronic components either to compute the digital signature or to embed the watermark. Image forensics, in contrast, aims to determine whether an image has been manipulated, without relying on any information generated a priori <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. Sometimes, these techniques work on the assumption that forgeries may alter the underlying statistics of images, even though no traces can be visually identified <ref type="bibr" target="#b6">[7]</ref>. Typically, however, because of the difficulty of the problem, forensic evidence will often rely on various methods, rather than one specific algorithm <ref type="bibr" target="#b4">[5]</ref>.</p><p>Copy-move, one of the most commonly considered manipulations, involves concealing unwanted objects in the image with regions of pixels copied from another part of the same image <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref>. To allow further visual inspection, the duplicated areas should be localised additional post-processing operations, which could undermine the detection/localisation performance, should be considered. For example, the detection of cloned areas altered by JPEG compression has been studied in <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b9">10]</ref>, while Mahdian et al. <ref type="bibr" target="#b8">[9]</ref> and Dybala et al. <ref type="bibr" target="#b10">[11]</ref> have focused on the detection of replicated regions affected by blurring and filtering, respectively. Nevertheless, these methods are susceptible to geometric changes in the copied portion.</p><p>This concern was first addressed by Myna et al. <ref type="bibr" target="#b11">[12]</ref>. Here, overlapping blocks of wavelet coefficients in the coarser sub-band of the lower resolution level are mapped to log-polar coordinates. The resulting blocks are lexicographically sorted and analysed to identify similar pairs. The formed pairs are iteratively filtered by discarding those that do not fulfil the similarity criteria in the subsequent wavelet resolution levels. Huang et al. <ref type="bibr" target="#b13">[13]</ref> presented a different approach, whereby rotation/scalinginvariant descriptors are extracted by means of the scale invariant feature transform (SIFT). The algorithm is confined to the search for pairs of similar descriptors. However, the detected replicated areas are not delimited by this method. In <ref type="bibr" target="#b14">[14]</ref>, overlapping pixel-blocks are mapped to scaling-invariant descriptors derived from the Fourier-Mellin transform (FMT). Then, a hash function is applied on every descriptor to identify identical matches. Nonetheless, such a rigid detection mechanism makes the system too sensitive to rotations of more than 101. In Lin et al.'s method <ref type="bibr" target="#b15">[15]</ref>, overlapping pixel-blocks are mapped to luminance-dependent features. Then, the radix sort algorithm is adopted to perform an efficient search for similar feature vectors. Nonetheless, this method cannot cope with scaling or rotation by arbitrary angles (it only supports 901, 1801 and 2701). During the writing and revision of this manuscript, we became aware of recent works in <ref type="bibr" target="#b16">[16]</ref><ref type="bibr" target="#b17">[17]</ref><ref type="bibr" target="#b18">[18]</ref>. Compared with Huang's scheme, the SIFT-based methods in <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b17">17]</ref> additionally estimate the parameters of the geometric transformation between the duplicated areas. In <ref type="bibr" target="#b17">[17]</ref>, such parameters are used to produce a transformed version of the image to delimit the areas of the duplicates by means of a correlation map. Ryu et al. <ref type="bibr" target="#b18">[18]</ref> compute the Zernike moments of overlapping pixel-blocks to produce rotation-invariant feature vectors, which are lexicographically sorted to find potential duplicates. However, neither scaled nor reflected duplicates can be detected with this scheme.</p><p>Forensic techniques aimed at detecting image interpolation <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b20">[20]</ref><ref type="bibr" target="#b21">[21]</ref><ref type="bibr" target="#b22">[22]</ref>, could be used to identify regions affected by rotation and scaling. However, duplicated areas affected by geometric distortions that do not require interpolation (e.g. reflection) would go unnoticed by these methods. Furthermore, the detection performance of these schemes can be seriously undermined by postprocessing operations, such as JPEG compression <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b19">19]</ref>.</p><p>To overcome all these shortcomings, this paper presents a comprehensive novel forensic method to detect duplicated regions that have undergone geometric changes, particularly reflection, rotation and scaling. Overlapping blocks of pixels are independently mapped to 1-D reflection/rotation-invariant descriptors derived from log-polar maps. This dimension-reduced representation of the blocks enables an efficient search for duplicates in terms of memory usage. In addition, a refinement mechanism is proposed to identify clusters of duplicated blocks that have been affected by geometric distortions. Extensive experimental results demonstrate the effectiveness of the proposed method. The remainder of the paper is organised as follows. Section 2 elucidates on the 1-D descriptors, while the proposed forensic method is presented in Section 3. Section 4 elaborates on the parameter settings, and Section 5 presents extensive experimental results, along with a comparative evaluation of the proposed scheme against Myna et al.'s <ref type="bibr" target="#b11">[12]</ref> and Huang et al.'s <ref type="bibr" target="#b13">[13]</ref> methods. Finally, the paper is concluded in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Solving reflection, rotation and scaling</head><p>To cope with reflection, rotation and scaling, blocks of pixels are mapped to the 1-D descriptors derived from their log-polar maps (LPM). This approach was inspired by the mechanism proposed in <ref type="bibr" target="#b23">[23]</ref> to address the synchronisation problems caused by rotation, scaling and translation. In <ref type="bibr" target="#b23">[23]</ref>, however, 1-D descriptors resulted from the sum a LPM along the log-radius axis, thereby achieving properties distinct to the descriptors proposed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Computing the 1-D descriptors</head><p>Consider the point ðx,yÞ 2 R<ref type="foot" target="#foot_1">2</ref> , which can be written using (natural) log-polar coordinates as x ¼ expðrÞcosy, and y ¼ expðrÞsiny, where r 2 R and 0 r yo2p. Let ðxu,yuÞ denote the coordinates of a reflected, rotated and scaled point, which can be written in log-polar coordinates as</p><formula xml:id="formula_0">xu ¼ expðr þ logmÞcosðjÀyÞ and yu ¼ expðr þ logmÞsinðjÀyÞ:<label>ð1Þ</label></formula><p>Consider a block of pixels 2 B i (x,y) and its log-polar representation B i ðr,yÞ. A 1-D descriptor ṽi is computed as</p><formula xml:id="formula_1">ṽi ðrÞ ¼ X y B i ðr,yÞ:<label>ð2Þ</label></formula><p>A reflected, rotated and scaled version of B i can be expressed in log-polar coordinates as B i uðr,yÞ ¼ B i ðr þ logm,jÀyÞ. Observe that scaling and rotation in the original rectangular coordinates results in a simple translation of the log-polar map. A descriptor for this block can be computed by</p><formula xml:id="formula_2">ṽi uðrÞ ¼ X y B i uðr,yÞ ¼ X ŷ B i ðrþ logm, ŷÞ,<label>ð3Þ</label></formula><p>where ŷ ¼ ðjÀyÞ. Since cosines and sines are periodic functions, and a whole period is being considered, and the </p><p>Hence, the descriptors are invariant to both reflection and rotation, i.e. ṽi ðrÞ ¼ ṽi uðrÞ, when B i u is a mirrored and/ or rotated version of B i . Furthermore, ṽi ðrÞ ¼ ṽi uðrÀlogmÞ, when B i u is a scaled version of B i by a factor m. In discrete signals, however, loss due to interpolation and round-off errors must be considered. Because of the well-known translation properties of the Fourier transform <ref type="bibr" target="#b24">[24]</ref>, the Fourier magnitude of both descriptors is expected to be very closely correlated to each other, i.e.</p><formula xml:id="formula_4">cð Ṽ i , Ṽ i uÞ ¼ Ṽ T i Ṽ i u ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ð Ṽ T i Ṽ i Þð Ṽ i uT Ṽ i uÞ q % 1,<label>ð5Þ</label></formula><p>where c is the correlation coefficient, Ṽ i and Ṽ i u are the Fourier magnitudes of ṽi and ṽi u, respectively. Compared to complete log-polar maps, the proposed 1-D descriptors simplify the identification of reflected duplicated blocks. Moreover, since every single block will be compared with several blocks, it is a good idea to form a list with the descriptors, each one corresponding to a different block, before the search stage. Thus, instead of storing a complete m r Â n y log-polar map for every block, it will only be necessary to store a vector of length m r . Further still, the computational cost of the whole system decreases, as it will only need to compute the fast Fourier transform (FFT) of every 1-D descriptor, whose complexity is given by Oðm r log 2 m r Þ, instead of computing the FFT of complete log-polar maps, whose complexity is Oððm r n y Þlog 2 ðm r n y ÞÞ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed method</head><p>An input colour image X, of size n 1 Â n 2 , is first tiled as blocks of pixels selected by sliding, pixel by pixel, a window of size q Â q, from the top-left corner to the bottom-right corner, in a raster-scan order. Let A i denote the i-th block of pixels, for i=1,y,m, where m =(n 1 À q+1) (n 2 À q+1). Fig. <ref type="figure" target="#fig_1">1</ref> depicts the proposed algorithm, which is composed of the three stages detailed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Feature extraction</head><p>The algorithm starts with the computation of feature vectors dependent on the colour and luminance of every block. The rationale behind this is that duplicated blocks are expected to be mapped to similar feature vectors, even if they have undergone reflection, rotation and/or scaling (see Section 4). Thus, the search for duplicates can be confined to the comparison of blocks with similar feature vectors, thereby avoiding the use of a computationally expensive exhaustive search.</p><p>The centre of each block A i will be the centre of a disc of diameter q, which fits just inside the block. Let f 1 i , f 2 i and f 3 i be three features independently computed as the average of the red, blue and green colour of the pixels within the disc. Luo et al. <ref type="bibr" target="#b9">[10]</ref> pointed out that the average of the colour channels is not significantly modified by JPEG compression or Gaussian blurring. In Section 4, it will be shown that such colour-dependent features are resilient to rotation and mild scaling. A fourth feature f 4 i is computed as follows. Given a colour pixel, its luminance is calculated as Y=0.2126 r + 0.7152g + 0.0722b,where r, g and b are its red, green and blue components, respectively. The probability distribution function is calculated using the luminance of all the pixels within a disc. From this, the entropy is calculated as,</p><formula xml:id="formula_5">f 4 i ¼ À P k p k log 2 p k</formula><p>, where p k is the probability of each luminance value in the disc.</p><p>A problem typically faced by methods aimed at detecting duplicates is posed by areas of uniform luminance (e.g. sky) <ref type="bibr" target="#b4">[5]</ref>, which can produce a significant number of false matches. Although the proposed method has the same shortcoming, the feature f 4 i can be used to identify blocks with insufficient textural information (lowentropy values). Thus, blocks whose entropy falls below a user-defined threshold e min could be readily discarded. However, this could prevent the system from detecting duplicates in areas with scarce textural information.</p><p>Finally, a list L is formed with feature vectors</p><formula xml:id="formula_6">ðf 1 i ,f 2 i ,f 3 i ,f 4 i Þ corresponding to the remaining blocks.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Search for similar blocks</head><p>Let B i be the luminance channel of the i-th block associated to the i-th feature vector in L, denoted as</p><formula xml:id="formula_7">f i ¼ ðf 1 i ,f 2 i ,f 3 i ,f 4 i Þ.</formula><p>Additionally, let (x i ,y i ) be the coordinates (the centre) of B i in the image X, and Ṽ i denote the Fourier magnitude of the 1-D descriptor, ṽi , derived from B i .</p><p>To search for a potential duplicate of the block B i , the correlation coefficient c ij cð Ṽ i , Ṽ j Þ is computed, using (5), for every j 4i that satisfies the following conditions: </p><formula xml:id="formula_8">(a) d ij 4 t d , (b) jf k i Àf k j j rt h ,</formula><formula xml:id="formula_9">d ij ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ðx i Àx j Þ 2 þðy i Ày j Þ 2 q</formula><p>. The first condition is necessary to discard blocks in proximity to B i , which may lead to an increase of false matches. The two other conditions are used to determine whether the feature vectors f j and f i are similar to each other. This procedure could be performed by exhaustively comparing the feature vector f i to the remainder (m À 1) feature vectors in L. However, this can be significantly optimised by lexicographically sorting the list L, in a preliminary step of the search stage, in order to bring similar feature vectors closer to each other. Thus, the comparisons for Ṽ i can stop once a descriptor Ṽ u is reached, such that jf 1 i Àf 1u j 4t h . Let c ir be the higher correlation coefficient computed for Ṽ i . If c ir is greater than a predefined similarity threshold t sim , calculate the offsets defined as x d ir ¼ jx i Àx r j and y d ir ¼ jy i Ày r j. Then, if x i r x r , generate a tuple ð x d ir , y d ir ,x i , y i ,x r ,y r Þ; otherwise, create a tuple ð x d ir , y d ir ,x r ,y r ,x i ,y i Þ. For convenience, the first and second pairs of coordinates in a tuple will be referred to as ''source'' and ''target'' coordinates, respectively. Finally, form a list Q with all the created tuples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Final refinement</head><p>At this stage, Q typically contains a significant number of false matches. For instance, Fig. <ref type="figure" target="#fig_3">2(a)</ref> shows the whole set of unrefined matches detected in an example forgery (the ''source'' and ''target'' coordinates are depicted as dark-grey and light-grey spots, respectively). Note that the false matches clearly render the bitmap useless. This example illustrates how important the refinement mechanism is to produce reasonable results.</p><p>The methods in <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b9">10]</ref> work on the assumption that the cloned regions have not been affected by geometric distortions, e.g. see Fig. <ref type="figure" target="#fig_4">3(a)</ref>. Thus, their refinement mechanisms are confined to the search for densely packed groups of matches separated by identical offsets. Unfortunately, such an approach would be utterly inadequate when the replicated areas have undergone geometric distortions, as the coordinates of every duplicated block are likely to be separated by different offsets, as shown in Fig. <ref type="figure" target="#fig_4">3(b)</ref>.</p><p>In the following refinement mechanism the coordinates in Q are examined to identify clusters of points given by tuples containing similar -i.e. not necessarily identical -offsets.</p><p>To optimise the procedure, Q is lexicographically sorted to bring tuples with similar offsets closer to each other, thereby reducing the number of required comparisons. Let D be the maximum offset to be examined in each iteration of the following algorithm; in practice, we have found that the system performs well with D=32. clusters of more than t min points<ref type="foot" target="#foot_2">3</ref> within a window of size w Â w. If the ''target'' coordinates of a cluster also form a packed group of more than t min points within a window w Â w, as illustrated in Fig. <ref type="figure" target="#fig_3">2</ref>(c), the cluster is considered a valid duplicate and the tuples are appended to a final list S. Conversely, if the ''target'' coordinates form a cloud of disperse points, as in Fig. <ref type="figure" target="#fig_3">2</ref>(d), the cluster is discarded. 3: Remove, from Q, all the tuples in F and repeat the steps 1-3 while Q is not empty.</p><p>Finally, a bitmap is encoded with the coordinates in the tuples in S.</p><p>The actions taken to optimise the proposed algorithm can be summarised as follows: (1) Discard pixel-blocks with low-entropy luminance, thereby reducing the occurrence of false matches typically found in large regions of uniform pixels (e.g. sky). ( <ref type="formula" target="#formula_1">2</ref>) Avoid computing the feature vector distance of pixel-blocks close to each other, which could otherwise produce false matches. (3) To avoid a computationally expensive exhaustive search, sort the list of colour/luminance-dependent features vectors to reduce the number of comparisons necessary in the search stage. (4) In the refinement stage, sort the list of tuples (i.e. Q) to bring tuples with similar offsets closer to each other, thereby reducing the number of necessary comparisons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Parameters set-up</head><p>To find suitable values for the thresholds t h , t e and t sim , required in Section 3.2, the following experiment  was formulated with 700 images, sized 640 Â 480, in the Caltech-256 dataset <ref type="bibr" target="#b25">[25]</ref>  of images. First, the images were split into non-overlapping pixel-blocks. Two block-sizes, 24 Â 24 and 32 Â 32, were individually tested. It was empirically found that these block-sizes provide a fair balance between false detections and the correct detection of smaller duplicates.</p><p>The following 35 distortions were tested, one at a time, in each pixel-block: (1) JPEG compression, at quality factors varying from 60 to 100 with increments of 10;  by angles varying from 4 01 to 901 with increments of 51;</p><p>(3) scaling by factors (see footnote 4) varying from 0.95 to 1.05 with increments of 0.01.</p><p>The following results were obtained using blocks sized 24 Â 24 (comparable results were achieved using blocks of size 32 Â 32). Fig. <ref type="figure">4(a)</ref> shows that the absolute difference between the colour-dependent features (f 1 , f 2 and f 3 ), extracted from the distorted blocks, and from the original blocks remained below 2 in over 93% of the total cases. Fig. <ref type="figure">4</ref>(b) shows that, in over 97% of the cases, the absolute difference between the entropy-dependent   <ref type="figure">7</ref>. Results of the extensive tests using a block-size 32 Â 32. 4 The distorted blocks were additionally translated a random amount within the range [ À 0.5,0.5], in a random direction, to emulate real forgeries. feature (f 4 ) computed from the distorted blocks and from the original blocks remained below 0.3. Additionally, the figure illustrates that the correlation coefficient between the Fourier magnitude of the 1-D descriptor extracted from the distorted blocks and from the original blocks lay above 0.9995 in over 90% of the total cases. Hence, the thresholds were set as: t h ¼ 2, t e ¼ 0:3, and t sim ¼ 0:9995. Fig. <ref type="figure">5</ref> shows the percentages of blocks whose features simultaneously satisfied the conditions (b) and (c), in Section 3.2, using the thresholds above. For rotation, results are very similar independent of the rotation degree for each of the block-sizes of 24 Â 24 and 32 Â 32. Yet, results for 32 Â 32 blocks are better than those for 24 Â 24 blocks. For scaling, results increase as the scaling factor tends to 1 (for either end) for each of the block-sizes of 24 Â 24 and 32 Â 32. Although results for both block-sizes are virtually the same at scaling factor values of 0.95 and 1.05, those for 32 Â 32 blocks tend to be better than those for 24 Â 24 blocks, as the scaling factor approaches 1. For the sake of brevity, we only present the results for scaling and rotation. However, it is worth mentioning that over 97% of the blocks satisfied the thresholds, even after compression using JPEG-quality factor of 60.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental results</head><p>Two standard metrics will be adopted to evaluate the localisation performance quantitatively: the True Positive Rate (TPR = TP/P) and the True Negative Rate (TNR= TN/N), where TP is the number of pixels correctly deemed part of a duplicate, TN is the number of pixels that were correctly regarded as part of no duplicate, P is the actual number of pixels that belong to any duplicate, and N is the actual number of pixels that belong to no duplicate. Note that an ideal detection would simultaneously render TPR= 1 and TNR= 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Extensive evaluation</head><p>The block-sizes 24 Â 24 and 32 Â 32 were tested using the parameter settings discussed in the preceding section; additional parameters were set, through empirical observation, as: e min = 2 and t d ¼ 40. The experiment was conducted on 100 images, sized 400 Â 600, available in the Caltech-256 data set <ref type="bibr" target="#b25">[25]</ref>.</p><p>The original, non-tampered, images were first analysed in non-compressed and JPEG compressed format. Table <ref type="table" target="#tab_3">2</ref> shows the number of images that were mistakenly regarded as containing duplicates ðTNRa1Þ. The number of false matches decreased by roughly 10% when using 32Â 32 blocks, compared with the results obtained when using 24 Â 24 blocks. Observe that the tested mild JPEG compression did not have a substantial impact on the number of false detections. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 3</head><p>Results of false detections, out of a total 20 original images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Myna et al. [12]</head><p>Huang et al. <ref type="bibr" target="#b13">[13]</ref> Proposed False matches 7 20 3</p><p>To evaluate the robustness of the proposed method, a square region was selected from a random location in every test image; tested sizes: 80 Â 80 and 120 Â 120. Before being pasted to another random location, within the same image, a post-processing operation was applied to the selected region. The following manipulations were independently tested: (1) no further distortion (simple copy-move); (2) horizontal reflection; (3) rotation: 51, 201, 401, 601, 801, 1001, 1201, 1401, 1601, 1751 and 1801; (4) scaling factors: 0.96, 0.98, 1.01, 1.03 or 1.05. Thus, every image was used to generate a set of 36 forgeries, each of which was analysed by the proposed detector in non-compressed and JPEG format (at quality factors 80 and 100). Hence, a total of 7200 forgeries were analysed.</p><p>The number of correctly detected forgeries ðTPRa0Þ, using 24 Â 24 blocks, are summarised in Figs. <ref type="figure" target="#fig_6">6(a)-(c</ref>). Results obtained using 32 Â 32 blocks are shown in Figs. <ref type="figure">7(a)-(c</ref>). In general, the performance achieved by the proposed system is significantly better in the presence of larger duplicates. Nonetheless, for smaller duplicates, sized 80 Â 80, the use of 24 Â 24 blocks led to a slight increase in the number of correct detections.</p><p>The localisation results achieved using 24 Â 24 are comparable to those obtained when using 32 Â 32. In both cases, it was observed that the tests that led to higher TPRs are the ones that also led to lower TNRs, and vice versa. For example, the highest average TPR (0.96) were obtained from the reflection test, while the 1401rotation test led to the lower average TPR (0.58). On the other hand, the average TNRs obtained from the reflection and the 1401-rotation tests were assessed to be 0.98 and 0.99, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Comparison tests</head><p>The proposed scheme was compared with Myna et al.'s <ref type="bibr" target="#b11">[12]</ref> and Huang et al. <ref type="bibr" target="#b13">[13]</ref> methods. Our interest in these schemes stems from the fact that both were aimed to detect duplicates that have undergone scaling and rotation by arbitrary angles, unlike the methods in <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b14">14]</ref>. These methods were implemented using the parameters suggested by the authors. <ref type="foot" target="#foot_3">5</ref> Based on the detection performance observed in the previous experiment, the block-size of the proposed scheme was set to 24 Â 24.</p><p>A set of 20 natural images, sized 300 Â 400, were used as test images. Half of the images exhibited characteristics expected to pose a challenge for the tested detectors (e.g. intrinsic symmetries or large areas with smooth texture). The remainder images contained large regions with rather coarse textures. The three methods were implemented in C++, running on a 32-bit CPU 2.80 GHz, with 2 GB RAM. On average, the analysis of an image sized 300 Â 400 took 750 s using Myna et al.'s method, 5 s using Huang et al.'s method, and 90 s using the proposed scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1.">Example forgeries</head><p>The first column of Fig. <ref type="figure" target="#fig_9">8</ref> shows four images (of the 20 test images) used to generate the example forgeries in the second column. The rest of the columns show the detection results obtained with Myna et al.'s, Huang et al.'s and the proposed schemes, respectively. Each forgery contains a different distortion (from top to bottom): (1) rotation 301; (2) scaling 0.94; (3) rotation 21 and scaling 1.05; (4) horizontal reflection, rotation 801 and scaling 0.98. The actual duplicates are delimited by the white contour, while the areas regarded as duplicates by the detectors are depicted as grey patches, whose size and shape depends on the algorithm itself. The proposed method managed to detect effectively the duplicates in the four forgeries. Myna et al.'s scheme only managed to detect the duplicates in the second forgery, while Huang et al.'s system failed to detect the duplicates in the last two forgeries. From this small set of four images, the average TPR and the average TNR were assessed to be: TPR=0.17 and TNR= 0.98, using Myna et al.; TPR=0.34 and TNR= 0.94, using Huang et al.; TPR= 0.79 and TNR= 0.99, using the proposed scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.">False matches</head><p>The 20 non-tampered test images were analysed with the three schemes. The number of images mistakenly classified as forgeries, out of the total 20, is shown in Table <ref type="table">3</ref>. Unlike the other two schemes, the proposed method managed to validate correctly all the images that contained symmetric structures, e.g. see the top row of Fig. <ref type="figure" target="#fig_10">9</ref>. Observe that, in the same image, several false duplicates were reported by the other two methods. The proposed scheme failed to validate some of the images containing large areas of rather smooth texture, as in the image at the bottom row of Fig. <ref type="figure" target="#fig_10">9</ref>. Nevertheless, the other two methods also failed to regard the image as duplicate-free. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3.">Testing against different distortions</head><p>Each one of the 20 images was used to produce a set of seven forgeries, each one containing a square duplicated region, sized 100 Â 100, which was subjected to one of the following distortions:  <ref type="formula" target="#formula_3">4</ref>) and ( <ref type="formula" target="#formula_4">5</ref>)) [Rot. + Sc.]; (7) Rotation, scaling and reflection (using the same parameters as in <ref type="bibr" target="#b5">(6)</ref>, in addition to reflection) [Rot. + Sc.+Ref.]. A total of 140 non-compressed forgeries were submitted to the three detectors.</p><p>Fig. <ref type="figure" target="#fig_11">10</ref>(a) shows the number of forgeries correctly detected ðTPRa0Þ, while the average TPRs and the average TNRs, assessed from every forgery correctly detected, are presented in Figs. <ref type="figure" target="#fig_11">10(b</ref>) and (c), respectively. As expected, nearly all the duplicates affected by reflection went undetected by Myna et al.'s scheme. Surprisingly, Huang et al.'s method seemed to have succeeded in detecting all the reflected duplicates. However, a closer look at the individual tests revealed that these were misleading results caused by false matches. For example, observe that all the duplicates reported by Huang et al.'s system, in Fig. <ref type="figure" target="#fig_2">11</ref>, correspond to false matches. This also explains the low average TPR achieved by this method in the tests involving reflection. Across the tests, the proposed method exhibited a consistently high detection performance, especially for the copy-move, the reflection and the scaling tests. The few forgeries that went unnoticed by the proposed detector involved some amount of rotation. Throughout the tests, the average TPRs and the average TNRs achieved by the propose scheme were higher than those achieved by the other two methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>A new forensic method has been proposed to detect and localise duplicated regions that have undergone reflection, rotation and/or scaling, even after JPEG compression. This problem had not been comprehensively addressed in current literature. To perform an efficient search, in terms of memory usage, overlapping blocks of pixels are mapped to 1-D descriptors derived from logpolar maps. Additionally, feature vectors, extracted from every single block, are used to reduce the computational cost of the search stage. Finally, a refinement stage has been proposed to cope with duplicated regions that have undergone geometric changes.</p><p>Extensive experimental results have been presented to evaluate the effectiveness of the proposed method. Results showed that our scheme outperforms an existing LPM-based method, in terms of detection/localisation accuracy and computational cost. Furthermore, the proposed method succeeded in validating a significantly higher number of non-tampered images, compared with an existing SIFT-based method. As recently proposed in <ref type="bibr" target="#b16">[16]</ref>, a clustering mechanism could be incorporated to the SIFT-based method to mitigate the false alarms. However, it is unclear whether such a mechanism would be of any help in images with intrinsic symmetries, which typically produce several clusters of false matches. The main challenge for the proposed method was posed by images containing large scarcely textured regions. Hence, as in virtually all existing image forensic techniques, human intervention is still required to interpret the results reported by our method. An interesting avenue for future research is to incorporate further features to the refinement mechanism as an attempt to reduce the incidence of false alarms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>1 accurately. Moreover, Contents lists available at ScienceDirect journal homepage: www.elsevier.com/locate/sigpro Signal Processing 0165-1684/$ -see front matter &amp; 2011 Elsevier B.V. All rights reserved. doi:10.1016/j.sigpro.2011.01.022</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Block-diagram of the proposed detector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 :</head><label>1</label><figDesc>Taking the offsets x d a 1 b 1 and y d a 1 b 1 in the top tuple in Q as a reference, select all the tuples that contain offsets within the ranges ½ x d a 1 b 1 ÀD, x d a 1 b 1 þD and ½ y d a 1 b 1 , y d a 1 b 1 þ2D. Fig. 2(b) shows pairs of points separated by similar offsets in an example forgery. Form a new list F with the selected tuples. 2: Considering only the ''source'' coordinates in F, identify</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Points given by ''source'' coordinates (dark-grey) and ''target'' coordinates (light-grey). (a) Unrefined matches detected in an example image. (b) Example of matches separated by similar offsets. (c) Example of valid duplicate. (d) Example of invalid duplicate.</figDesc><graphic coords="4,76.01,56.57,396.00,77.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Offsets separating the coordinates of duplicated blocks. (a) Copypaste. (b) Rotation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Fig. 4. Results for the similarity criteria (block-size: 24 Â 24). (a) Average of the colour components. (b) Entropy of the luminance channel and correlation coefficient of the 1-D descriptors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. Results of the extensive tests using a block-size 24 Â 24.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig.</head><label></label><figDesc>Fig. 7. Results of the extensive tests using a block-size 32 Â 32.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Each row represents a different test (from top to bottom): rotation; scaling; rotation and scaling; reflection, rotation and scaling. In each row, the first column contains the original image, the second column is the forgery, while the rest of the columns depict the results obtained with Myna et al.'s, Huang et al.'s and the proposed methods, respectively.</figDesc><graphic coords="8,75.92,413.78,396.42,240.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. False matches found in non-tampered images. In each row, the first column contains the original image, and the rest of the columns show the results obtained with Myna et al.'s, Huang et al.'s and the proposed method, respectively.</figDesc><graphic coords="9,72.63,56.57,394.92,161.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Comparison results. (a) Correctly detected forgeries. (b) Average TPR results. (c) Average TNR results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>(1) no further distortion [copymove]; (2) horizontal reflection [Ref.]; (3) rotation by a random angle selected from {901, 1801, 2701} [Rot.*]; (4) rotation by a random angle within the range (01, 3601) [Rot.]; (5) scaling by a random factor within the range (0.95,1.05) [Sc.]; (6) rotation and scaling (with random parameters as in (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Classification of techniques for integrity verification of images.</figDesc><table><row><cell></cell><cell>Active</cell><cell>Passive</cell></row><row><cell>Non-invasive</cell><cell>Trustworthy digital cameras</cell><cell>Image forensics</cell></row><row><cell>Invasive</cell><cell>Digital watermarking</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>for k= 1,2,3, and (c) jf 4 i Àf 4 j j rt e , where t d , t h and t e are predefined thresholds, discussed in Section 4, and</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>. The test images depicted diverse contents, from objects to landscapes, excluding synthetically generated content (e.g. vector graphics). Such a diversity is expected to enable the definition of threshold values suitable for the analysis of a vast variety</figDesc><table><row><cell></cell><cell>100%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>90%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Percentage of blocks</cell><cell>30% 40% 50% 60% 70% 80% 20%</cell><cell></cell><cell>JPEG</cell><cell cols="2">Scaling</cell><cell cols="2">Rotation Avg. red channel</cell></row><row><cell></cell><cell>10%</cell><cell></cell><cell></cell><cell></cell><cell cols="3">Avg. green channel Avg. blue channel</cell></row><row><cell></cell><cell>0%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell></cell><cell>0.5</cell><cell></cell><cell>1</cell><cell>1.5</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Absolute difference</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Correlation coefficient</cell></row><row><cell></cell><cell cols="2">0.9995</cell><cell>0.9994</cell><cell>0.9993</cell><cell>0.9992</cell><cell cols="2">0.9991</cell><cell>0.999</cell></row><row><cell></cell><cell>100%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>90%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Percentage of blocks</cell><cell>20% 30% 40% 50% 60% 70% 80%</cell><cell cols="4">1-D descriptors Luminance entropy</cell><cell></cell><cell>JPEG</cell></row><row><cell></cell><cell>10%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Rotation Scaling</cell></row><row><cell></cell><cell>0%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell></cell><cell>0.05</cell><cell>0.1</cell><cell>0.15</cell><cell>0.2</cell><cell>0.25</cell><cell>0.3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Absolute difference</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc>Results of false detections, out of a total 100 original images.</figDesc><table><row><cell>Detector's</cell><cell>Non-compressed</cell><cell>JPEG quality factor</cell><cell></cell></row><row><cell>block-size</cell><cell>format</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>100</cell><cell>80</cell></row><row><cell>24 Â 24</cell><cell>33</cell><cell>32</cell><cell>33</cell></row><row><cell>32 Â 32</cell><cell>20</cell><cell>19</cell><cell>21</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The term localisation has been adopted from fragile watermarking literature.Signal Processing 91 (2011) 1759-1770</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>The index i is merely included for the sake of consistency with the notation used in the next section.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>In our experiments, the values w= 16 and t min =230 led to the better results when 24 Â 24 blocks are employed in the Block sorting stage (recall Section 3.1). Nonetheless, t min should be slightly increased for larger block-sizes.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>As the authors in<ref type="bibr" target="#b11">[12]</ref> suggested no suitable settings, we made every effort to find the parameter set-up that provided the better results in Myna et al.'s method.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>Sergio Bravo-Solorio is supported by the National Council of Science and Technology (CONACyT) of Mexico.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The trustworthy digital camera: restoring credibility to the photographic image</title>
		<author>
			<persName><forename type="first">G</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Consumer Electronics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="905" to="910" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Bloom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fridrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kalker</surname></persName>
		</author>
		<title level="m">Digital Watermarking and Steganography</title>
		<imprint>
			<publisher>Morgan Kauffman</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>second ed.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Security of fragile authentication watermarks with localization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fridrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Security and Watermarking of Multimedia Contents</title>
		<meeting>Security and Watermarking of Multimedia Contents<address><addrLine>SPIE, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">4675</biblScope>
			<biblScope unit="page" from="691" to="700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multiscale fragile watermarking based on the Gaussian mixture model</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-P</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3189" to="3200" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Detection of copy-move forgery in digital images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fridrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Soukal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lukaš</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Digital Forensic Research Workshop</title>
		<meeting>Digital Forensic Research Workshop</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="55" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Exposing digital forgeries by detecting duplicated image regions</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Farid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<pubPlace>Dartmouth College</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exposing digital forgeries by detecting traces of resampling</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Farid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="758" to="767" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An efficient match-based duplication detection algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Langille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Canadian Conference on Computer and Robot Vision</title>
		<meeting>the 3rd Canadian Conference on Computer and Robot Vision</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="64" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Detection of copy-move forgery using a method based on blur moment invariants</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mahdian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Forensic Science International</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="180" to="189" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Robust detection of region-duplication forgery in digital images</title>
		<author>
			<persName><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICPR-IAPR International Conference on Pattern Recognition</title>
		<meeting>ICPR-IAPR International Conference on Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="746" to="749" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Detecting filtered cloning in digital images</title>
		<author>
			<persName><forename type="first">B</forename><surname>Dybala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jennings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Letscher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MM&amp;SEC-Workshop on Multimedia and Security</title>
		<meeting>MM&amp;SEC-Workshop on Multimedia and Security<address><addrLine>Dallas, TX, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Detection of region duplication forgery in digital images using wavelets and log-polar mapping</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Myna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Venkateshmurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Patil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on</title>
		<meeting>the International Conference on</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Example of a reflected duplicate and the results obtained by Huang et al.&apos;s method. Computational Intelligence and Multimedia Applications</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="371" to="377" />
			<pubPlace>Washington, DC, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Detection of copy-move forgery in digital images using SIFT algorithm</title>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial Application</title>
		<meeting>IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial Application</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="272" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An efficient and robust method for detecting copy-move forgery</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bayram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sencar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Memon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP-IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>ICASSP-IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1053" to="1056" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fast copy-move forgery detection</title>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-T</forename><surname>Kao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">WSEAS Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="188" to="197" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Geometric tampering estimation by means of a SIFT-based forensic analysis</title>
		<author>
			<persName><forename type="first">I</forename><surname>Amerini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ballan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Caldelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Del Bimbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Serra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP-IEEE International Conference on Acoustics Speech and Signal Processing</title>
		<meeting>ICASSP-IEEE International Conference on Acoustics Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1702" to="1705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Detecting image region duplication using SIFT features</title>
		<author>
			<persName><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP-IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<meeting>ICASSP-IEEE International Conference on Acoustics, Speech, and Signal Processing<address><addrLine>Dallas, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1706" to="1709" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Detection of copy-rotate-move forgery using Zernike moments</title>
		<author>
			<persName><forename type="first">S.-J</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IH-Information Hiding</title>
		<meeting>IH-Information Hiding<address><addrLine>Calgary, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="51" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fast and reliable resampling detection by spectral analysis of fixed linear predictor residue</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kirchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MM&amp;SEC-Workshop on Multimedia and Security</title>
		<meeting>MM&amp;SEC-Workshop on Multimedia and Security<address><addrLine>Oxford, United Kingdom</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Detection of resampling supplemented with noise inconsistencies analysis for image forensics</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mahdian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCSA-Proceedings of the International Conference on Computational Sciences and its Applications</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="546" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On the detectability of local resampling in digital images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kirchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Electronic Imaging: Security, Forensics, Steganography, and Watermarking of Multimedia Contents X</title>
		<meeting>Electronic Imaging: Security, Forensics, Steganography, and Watermarking of Multimedia Contents X</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">6819</biblScope>
			<biblScope unit="page">681915</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Blind authentication using periodic properties of interpolation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mahdian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="529" to="538" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Rotation, scale, and translation resilient watermaking for images</title>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bloom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="767" to="782" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Bracewell</surname></persName>
		</author>
		<title level="m">The Fourier Transform and its Application</title>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Caltech-256 object category dataset</title>
		<author>
			<persName><forename type="first">G</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Holub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<idno>7694</idno>
		<ptr target="http://authors.library.caltech.edu/7694S" />
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
