<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Graph Robustness Benchmark: Benchmarking the Adversarial Robustness of Graph Machine Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-11-08">8 Nov 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Qinkai</forename><surname>Zheng</surname></persName>
							<email>qinkai@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution" key="instit1">Tsinghua University ‡ Microsoft Research</orgName>
								<orgName type="institution" key="instit2">Redmond • Fudan University Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xu</forename><surname>Zou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution" key="instit1">Tsinghua University ‡ Microsoft Research</orgName>
								<orgName type="institution" key="instit2">Redmond • Fudan University Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Now at Meta AI</orgName>
								<address>
									<settlement>Seattle</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yukuo</forename><surname>Cen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution" key="instit1">Tsinghua University ‡ Microsoft Research</orgName>
								<orgName type="institution" key="instit2">Redmond • Fudan University Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Da</forename><surname>Yin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution" key="instit1">Tsinghua University ‡ Microsoft Research</orgName>
								<orgName type="institution" key="instit2">Redmond • Fudan University Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiarong</forename><surname>Xu</surname></persName>
							<email>jiarongxu@fudan.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Yang</forename><surname>Yang</surname></persName>
							<email>yangya@zju.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">Now at Meta AI</orgName>
								<address>
									<settlement>Seattle</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution" key="instit1">Tsinghua University ‡ Microsoft Research</orgName>
								<orgName type="institution" key="instit2">Redmond • Fudan University Zhejiang University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Now at Meta AI</orgName>
								<address>
									<settlement>Seattle</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<region>Redmond</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Graph Robustness Benchmark: Benchmarking the Adversarial Robustness of Graph Machine Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-11-08">8 Nov 2021</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2111.04314v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Adversarial attacks on graphs have posed a major threat to the robustness of graph machine learning (GML) models. Naturally, there is an ever-escalating arms race between attackers and defenders. However, the strategies behind both sides are often not fairly compared under the same and realistic conditions. To bridge this gap, we present the Graph Robustness Benchmark (GRB) with the goal of providing a scalable, unified, modular, and reproducible evaluation for the adversarial robustness of GML models. GRB standardizes the process of attacks and defenses by 1) developing scalable and diverse datasets, 2) modularizing the attack and defense implementations, and 3) unifying the evaluation protocol in refined scenarios. By leveraging the GRB pipeline, the end-users can focus on the development of robust GML models with automated data processing and experimental evaluations. To support open and reproducible research on graph adversarial learning, GRB also hosts public leaderboards across different scenarios. As a starting point, we conduct extensive experiments to benchmark baseline techniques. GRB is open-source and welcomes contributions from the community. Datasets, codes, leaderboards are available at https://cogdl.ai/grb/home.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Graph machine learning (GML) models, from network embedding <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref> to graph neural networks (GNNs) <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref>, have shown promising performance in various domains, such as social network analysis <ref type="bibr" target="#b0">[1]</ref>, molecular graphs <ref type="bibr" target="#b4">[5]</ref>, and recommender systems <ref type="bibr" target="#b9">[10]</ref>. However, GML models are known to be vulnerable to adversarial attacks <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18]</ref>. Attackers can modify the original graph by adding or removing edges <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20]</ref>, perturbing node attributes <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref>, or injecting malicious nodes <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18]</ref> to conduct adversarial attacks. Despite the relatively minor changes to the graph, the performance of GML models can be impacted dramatically.</p><p>Threatened by adversarial attacks, a line of attempts have been made to have robust GML models. For example, recent GNN architectures such as RobustGCN <ref type="bibr" target="#b20">[21]</ref>, GRAND <ref type="bibr" target="#b21">[22]</ref>, and ProGNN <ref type="bibr" target="#b22">[23]</ref> are designed to improve the adversarial robustness of GNNs. In addition, pre-processing based methods, such as GNN-SVD <ref type="bibr" target="#b23">[24]</ref> and GNNGuard <ref type="bibr" target="#b24">[25]</ref>, alleviate the impact of attacks by leveraging the intrinsic graph properties and thus improve the model robustness. Despite various efforts in this direction, there are several common limitations from both the attacker and the defender sides: 1. Unrealistic Attack/Defense Scenarios. The existing attack and defense setups are often ambiguously defined with unrealistic assumptions, such as ignoring the real-world capabilities of attackers and defenders, resulting in less practical applications. 2. Lack of A Unified Evaluation Protocol. Previous works often use different settings (e.g., datasets, data splittings, attack constraints) in their experiments, resulting in biases in the evaluation and thus making it difficult to fairly compare different methods. 3. Lack of Scalability. Most existing attacks and defenses are performed on very small-scale graphs (e.g., &lt;10,000 nodes) without considering different levels of attack/defense difficulties, which are far from the scale and complexity of real-world applications.</p><p>To date, there exist several well-established GML benchmarks. For example, the Open Graph Benchmark (OGB) <ref type="bibr" target="#b25">[26]</ref> offers abundant datasets and a unified evaluation pipeline for GML. Benchmarking GNNs <ref type="bibr" target="#b26">[27]</ref> is a standardized benchmark with consistent experimental settings. However, they mainly focus on evaluating the performance of GML models, regardless of their robustness. DeepRobust <ref type="bibr" target="#b27">[28]</ref> is a toolkit with implementations of attacks and defenses on both image and graph data, which by design is not a GML benchmark. Therefore, to address the aforementioned limitations, there is an urgent need for public benchmarks on evaluating the adversarial robustness of GML models.</p><p>In this paper, we propose the Graph Robustness Benchmark (GRB)-the first attempt to benchmark the adversarial robustness of GML models. The goal of GRB is to provide a reproducible framework that enables a fair evaluation for both adversarial attacks &amp; defenses on GML models under unified settings. To achieve this, GRB is designed to have the following properties:</p><p>1. Refined Attack/Defense Scenarios. GRB includes two refined attack scenarios: graph modification and graph injection, covering the majority of works in the field. By revisiting the limitations of previous works, we formalize precise definitions for both attackers' and defenders' capabilities, including available information to use and allowed actions, forming more realistic evaluations. 2. Scalable and Unified Evaluations. GRB contains various datasets of different orders of magnitude in size, with a specific robustness-focused splitting scheme for various levels of attacking/defending difficulties. It also provides a unified evaluation pipeline that calibrates all experimental settings, enabling fair comparisons for both attacks and defenses. 3. Reproducible and Public Leaderboards. GRB offers a modular code framework * that supports the implementations of a diverse set of baseline methods covering GML models, attacks, and defenses. Additionally, it hosts public leaderboards across all evaluation scenarios, which will be continuously updated to track the progress in this community.</p><p>Overall, GRB serves as a scalable, unified, modular, and reproducible benchmark on evaluating the adversarial robustness of GML models. It is designed to facilitate the robust developments of graph adversarial learning, summarizing existing progress, and generating insights into future research.</p><p>2 Adversarial Robustness in Graph Machine Learning</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Definition</head><p>In graph machine learning, adversarial robustness refers to the ability of GML models to maintain their performance under potential adversarial attacks. Take the task of node classification as an instance, for an undirected attributed graph G = (A, F) where A ∈ R N ×N represents the adjacency matrix of N nodes and F ∈ R N ×D denotes the set of node features with D dimensions. Define a GML model M : G → Z where Z ∈ [0, 1] N ×L , which maps a graph G to probability vectors with L classes. Generally, the objective of adversarial attacks on GML models can be formulated as: max where G = (A , F ) is the attacked graph, and d A and d F are distance metrics in the metric space (A, d A ) and (F, d F ). The attacker tries to maximize the number of incorrect predictions by GML models, under the constraints ∆ A and ∆ F . For instance, ∆ A can be the limited number of modified edges and ∆ F can be the limited range of modified features (Cf. Section 3 for detailed discussions). ---FLIP <ref type="bibr" target="#b28">[29]</ref> ---NEA <ref type="bibr" target="#b28">[29]</ref> ---FGSM <ref type="bibr" target="#b11">[12]</ref> --Nettack <ref type="bibr" target="#b11">[12]</ref> --RL-S2V <ref type="bibr" target="#b29">[30]</ref> --Metattack <ref type="bibr" target="#b12">[13]</ref> ---STACK <ref type="bibr" target="#b30">[31]</ref> ---AFGSM <ref type="bibr" target="#b15">[16]</ref> ---SPEIT <ref type="bibr" target="#b16">[17]</ref> ---TDGIA <ref type="bibr" target="#b17">[18]</ref> ---GRB Mod. Scenario ---GRB Inj. Scenario ---GRB Support † The table represents the original settings, while methods can be adapted to other settings by using GRB's modualr coding framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Revisiting Adversarial Attacks and Defenses in GML</head><p>In the work of Szegedy et al. <ref type="bibr" target="#b31">[32]</ref>, the existence of adversarial examples was revealed for ML models in image classification-imperceptible perturbations on inputs have ineligible impact on outputs of models. Recent works (in Table 1) show that GML models are no exception. Graph adversarial attacks can mainly be categorized into two types according to the attack approach: graph modification attack and graph injection attack. Graph modification attacks directly modify the existing graph, by adding or removing edges (e.g., DICE <ref type="bibr" target="#b18">[19]</ref>, FGA <ref type="bibr" target="#b10">[11]</ref>, FLIP <ref type="bibr" target="#b28">[29]</ref>, NEA <ref type="bibr" target="#b28">[29]</ref>, STACK <ref type="bibr" target="#b30">[31]</ref>), or further modifying node features (e.g., Nettack <ref type="bibr" target="#b11">[12]</ref>, FGSM <ref type="bibr" target="#b11">[12]</ref>, RL-S2V <ref type="bibr" target="#b29">[30]</ref>, Metattack <ref type="bibr" target="#b12">[13]</ref>). Differently, graph injection attacks add new malicious nodes without modifying the original graph (e.g., AFGSM <ref type="bibr" target="#b15">[16]</ref>, SPEIT <ref type="bibr" target="#b16">[17]</ref>, TD-GIA <ref type="bibr" target="#b17">[18]</ref>). Facing the problem of scalability, some attacks are not applicable to large graphs due to their high time complexity <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b29">30]</ref> or expensive memory consumption <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b28">29]</ref>.</p><p>Defenses can mainly be categorized into two types: preprocess-based defense and model-based defense. The first type regards the attacked graphs as noisy ones and defenders can preprocess the adjacency matrix (e.g., GNN-SVD <ref type="bibr" target="#b23">[24]</ref>, GNN-Jaccard <ref type="bibr" target="#b32">[33]</ref>) or the features of nodes (e.g., feature transformation <ref type="bibr" target="#b16">[17]</ref>), to alleviate the effect of perturbations. The second type achieves robustness through model enhancement, either by robust training schemes (e.g., adversarial training <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref>) or new model architectures (e.g., RobustGCN <ref type="bibr" target="#b20">[21]</ref>, GNNGuard <ref type="bibr" target="#b24">[25]</ref>). Some defenses also suffer from the problem of scalability, due to the need of calculation on large dense matrices <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>Notwithstanding the significant progress, existing works share some common limitations: (1) Lack of scalability: Most works only consider very small graphs and cannot be scaled up to larger ones due to time/memory complexity. (2) Lack of generalization: Most attacks/defenses are evaluated on very basic GML models, but not on other variants. Meanwhile, some methods are only effective for specific models with ad-hoc designs, which makes the results less generalized and practical.</p><p>(3) Ill-defined scenarios: The scenarios and assumptions proposed in some previous works are not realistic, e.g., the unnoticeability under poisoning setting ignores the real capability of the defenders (Cf. Appendix A.3 for details). Besides, there are no unified standards on evaluating the adversarial robustness. Different settings (e.g., the choice of datasets, random splitting, different constraints) introduce biases, which makes it hard to compare the effectiveness of different methods. In light of these challenges, there is an urgent need for benchmarking the adversarial robustness of GML. To overcome the limitations of previous works, we propose the Graph Robustness Benchmark (GRB)-a standardized benchmark for evaluating the adversarial robustness of GML. To ensure GRB's scalability, we include datasets of different sizes with scalable attack/defense baselines. To have a unified process, we standardize the evaluation scenarios with precise constraints and realistic assumptions on attackers and defenders. To make GRB easy-to-use, we provide a modular pipeline that facilitates the implementation of GML models, attacks, and defenses. To guarantee the reproducibility, we open-source and maintain the GRB public leaderboards that are continuously updated to track the progress of the community.</p><p>Altogether, GRB serves as a scalable, unified, modular, reproducible benchmark on evaluating the adversarial robustness of GML models. We present the solutions to achieve these goals for GRB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Unified Evaluation Scenario of GML Adversarial Robustness</head><p>To evaluate the adversarial robustness, it is essential to be aware of the capabilities of potential attackers. We categorize attacks into the following aspects (as shown in Table <ref type="table" target="#tab_0">1</ref>): In practice, the most common real-world case is that the GML models have already been trained for specific tasks and deployed in a secret way, i.e., black-box and evasion settings. Thus, in GRB, we propose two unified evaluation scenarios under these settings, graph modification and graph injection.</p><p>Graph Modification. This has been the most studied scenario, in which attackers can directly modify the graph (by adding/removing edges or perturbing node attributes) to attack the GML models. Under real-world conditions, this is theoretically possible but practically difficult, as the modification attacks require the authority to access the target nodes in order to to change their contents. Nevertheless, this scenario enables us to understand how the GML models behave under intended modifications.</p><p>Graph Injection. This scenario was first introduced in the KDDCUP 2020 task of Graph Adversarial Attacks &amp; Defenses † , which targeted at injecting new nodes to a large-scale academic graph. It is more realistic than the modification one since injecting new nodes is more practically possible than modifying the existing ones. However, the task in KDDCUP 2020 considers a transductive setting, i.e., test nodes (except for their labels) are available during training. In this case, defenders can simply memorize benign nodes and identify the injected nodes, making it an imperfect setting.</p><p>Thus, to further GRB's practical usage (Cf. Appendix A.3 for detailed discussions), we make the following assumptions for both scenarios: ( 3. For both sides: Attackers/defenders can of course make assumptions even in the black-box scenario. For instance, attackers can assume that the target system deploys a certain type of GML models, then it can be used as the surrogate model to conduct transfer attacks. Moreover, it is not reasonable to assume that the defense mechanism can be completely held secretly, known as the Kerckhoffs' principle <ref type="bibr" target="#b35">[36]</ref>. If a defense wants to be general and universal, it should guarantee part of the robustness even when attackers have some knowledge about it. In GRB, we evaluate an attack vs. multiple defenses (vice versa), thus the assumptions can hardly violate the black-box conditions. As a result, the objective for both sides is to be generally effective against all potential methods rather than just a single one.</p><p>By following the above rules, we provide unified evaluation scenarios for attacks and defenses in a principled way. It is worth noting that these unified scenarios are not the only valid ones, GRB will include more scenarios as this field eveloves over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The Modular GRB Pipeline</head><p>GRB offers a modular pipeline, which is based on PyTorch <ref type="bibr" target="#b36">[37]</ref> as well as other popular GML libraries like CogDL <ref type="bibr" target="#b37">[38]</ref> and DGL <ref type="bibr" target="#b38">[39]</ref>. Specifically, it contains the following modules: (1) Dataset: GRB provides data-loaders for GRB datasets and applies necessary preprocessing including splitting and feature normalization; it also supports external datasets like OGB <ref type="bibr" target="#b25">[26]</ref> or user-defined datasets.</p><p>(  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">The GRB Baselines</head><p>Currently, GRB covers a rich set of baselines for the GML models, attacks, and defenses.</p><p>Seven GML models: GCN <ref type="bibr" target="#b3">[4]</ref>, GAT <ref type="bibr">[6]</ref>, GIN <ref type="bibr" target="#b6">[7]</ref>, APPNP <ref type="bibr" target="#b7">[8]</ref>, TAGCN <ref type="bibr" target="#b19">[20]</ref>, GraphSAGE <ref type="bibr" target="#b4">[5]</ref>, SGCN <ref type="bibr" target="#b8">[9]</ref>. Note that these models are not originally designed to increase robustness.</p><p>Twelve Attacks: Seven modification attacks-RND <ref type="bibr" target="#b11">[12]</ref>, DICE <ref type="bibr" target="#b18">[19]</ref>, FGA <ref type="bibr" target="#b10">[11]</ref>, FLIP <ref type="bibr" target="#b28">[29]</ref>, NEA <ref type="bibr" target="#b28">[29]</ref>, STACK <ref type="bibr" target="#b30">[31]</ref>, and PGD <ref type="bibr" target="#b33">[34]</ref>-and five injection attacks-RND, FGSM <ref type="bibr" target="#b39">[40]</ref>, PGD <ref type="bibr" target="#b33">[34]</ref>, SPEIT <ref type="bibr" target="#b16">[17]</ref>, and TDGIA <ref type="bibr" target="#b17">[18]</ref>. More details can be found in Appendix A.4.2.</p><p>Five Defenses: GRB adopts RobustGCN (R-GCN) <ref type="bibr" target="#b20">[21]</ref>, GNN-SVD <ref type="bibr" target="#b23">[24]</ref>, and GNNGuard <ref type="bibr" target="#b24">[25]</ref>. Additionally, we find that techniques like layer normalization (LN) <ref type="bibr" target="#b40">[41]</ref> and adversarial training (AT) <ref type="bibr" target="#b33">[34]</ref>, if properly used in the proposed evaluation scenarios, can significantly increase the robustness of various GML models. The LN can be applied on the input features and after each graph convolutional layer (except for the last one). The idea is to stabilize the dynamics of input and hidden states to alleviate the impact of adversarial perturbations. The AT uses modification/injection attacks during training to make GML models more robust. Note that most of previous works only use AT to perturb the existing graph, however, we find that AT also works well by injecting new nodes during training. These two defenses are general and scalable, and the experiment results show that they outperform previous dedicated methods. Thus, we include them in GRB as strong baselines for defenses. More details can be found in Appendix A.4.3.  <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b17">18]</ref> and are reprocessed for GRB. The basic statistics of these datasets are shown in Table <ref type="table" target="#tab_4">2</ref>. More details about datasets can be found in Appendix A.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">The GRB Datasets</head><p>Data Splitting. GRB introduces a new splitting data scheme designed for evaluating the GML adversarial robustness. Its key idea is based on the assumption that nodes with lower degrees are easier to attack, as demonstrated in <ref type="bibr" target="#b17">[18]</ref>. If a target node has few neighbors, it is more likely to be influenced by adversarial perturbations aggregated from its neighbors. Thus, we construct test subsets with different average degrees to represent different difficulties. First, we rank all nodes by their degrees. Second, we filter out 5% nodes with the lowest degrees (e.g., isolated nodes that are too easy to attack) and 5% nodes with the highest degrees (e.g., nodes connected to hundreds of other nodes that are too hard to attack). Third, we divide the rest of nodes into three equal partitions without overlapping, and randomly sample 10% nodes (without repetition) from each partition. Finally, we get three test subsets with different degree distributions as shown in Figure <ref type="figure" target="#fig_4">4</ref>, which are defined as Easy/Medium/Hard/Full ('E/M/H/F') with 'F' containing all test nodes. For the rest of nodes, we divide them into the training set (60%) and validation set (10%).</p><p>Feature Normalization. Initially, the features in each dataset have various ranges. To unify their constraints and to have values in the same scale (e.g., range [−1, 1]), we apply a standardization followed by an arctan transformation:</p><formula xml:id="formula_1">F = 2 π arctan( F −mean(F ) std(F )</formula><p>). The statistics of datasets after the splitting scheme and the feature normalization can be found in Appendix A.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>With the support of GRB's modular framework, we conduct extensively experiments to evaluate the adversarial robustness of GML models under the unified evaluation protocol, from which insights are generated into the developments of the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>Baselines. (1) For GML models, we include 7 baselines: GCN <ref type="bibr" target="#b3">[4]</ref>, GAT <ref type="bibr">[6]</ref>, GIN <ref type="bibr" target="#b6">[7]</ref>, APPNP <ref type="bibr" target="#b7">[8]</ref>, TAGCN <ref type="bibr" target="#b19">[20]</ref>, GraphSAGE <ref type="bibr" target="#b4">[5]</ref>, SGCN <ref type="bibr" target="#b8">[9]</ref>. All models are salable to large graphs. (2) For modification attacks, we include 7 baselines: RND, DICE <ref type="bibr" target="#b18">[19]</ref>, FGA <ref type="bibr" target="#b10">[11]</ref>, FLIP <ref type="bibr" target="#b28">[29]</ref>, NEA <ref type="bibr" target="#b28">[29]</ref>, STACK <ref type="bibr" target="#b30">[31]</ref>, and PGD <ref type="bibr" target="#b33">[34]</ref>, among which RND, DICE, FLIP, and PGD are scalable to large graphs. FGA, NEA, and PGD need to train a surrogate model to conduct transfer attacks. (3) For injection attacks, we include 5 baselines: RND, FGSM <ref type="bibr" target="#b39">[40]</ref>, PGD <ref type="bibr" target="#b33">[34]</ref>, SPEIT <ref type="bibr" target="#b16">[17]</ref>, TDGIA <ref type="bibr" target="#b17">[18]</ref>. They are all scalable and FGSM, PGD, SPEIT, TDGIA need to train a surrogate model to conduct transfer attacks. (4) For defenses, we include R-GCN <ref type="bibr" target="#b20">[21]</ref>, GNN-SVD <ref type="bibr" target="#b23">[24]</ref>, GNNGuard <ref type="bibr" target="#b24">[25]</ref>. Among which only R-GCN is scalable, since the other two methods require calculation on dense adjacency matrix. Thus, we also adapt two general defense methods, layer normalization (LN) <ref type="bibr" target="#b40">[41]</ref> and adversarial training (AT) <ref type="bibr" target="#b33">[34]</ref> to the proposed scenarios. More details and hyper-parameter settings can be found in Appendix A.4 A.5.</p><p>Evaluation Metrics. For attacks: (1) Avg.: Average accuracy of all defenses (including vanilla GML models). ( <ref type="formula" target="#formula_0">2</ref>) Avg. 3-Max: Average accuracy for the 3 most robust methods. (3) Weighted: Weighted accuracy, calculated by:s</p><formula xml:id="formula_2">ATK w = n i=1 w i s i , w i = 1/i 2 n j=1 (1/j 2 ) , s i = (S DEF descend ) i where S DEF</formula><p>descend is the set of defense scores in a descending order. The metric attaches more weight to more robust methods. For defenses: (1) Avg.: Average accuracy of all attacks. (2) Avg. 3-Min: Average accuracy of the 3 most effective attacks. (3) Weighted: Weighted accuracy across various attacks, calculated by:s</p><formula xml:id="formula_3">DEF w = n i=1 w i s i , w i = 1/i 2 n j=1</formula><p>(1/j 2 ) , s i = (S ATK ascend ) i where S ATK ascend is the set of attack scores in an ascending order. The metric attaches more weight to more effective attacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Results</head><p>We show an example of GRB leaderboard, robust ranking of GML models, and various factors that affect the adversarial robustness in GML. More results can be found in Appendix and on our website.</p><p>An Example of the GRB Leaderboard. Following the process in Figure <ref type="figure" target="#fig_0">1</ref>, we evaluate the performance of attacks vs. defenses in graph injection scenario. Table <ref type="table" target="#tab_5">3</ref> shows an example of leaderboard for grb-aminer dataset. Each attack is repeated 10 times to report the error bar. Both attacks and defenses are ranked by the weighted accuracy under 'F' difficulty, where red and blue indicate the best results of attacks/defenses in each difficulty. Note that the metric is not fixed and will be updated when there are more effective methods. For instance, when there are more powerful attacks, the ranking will change so as the attached weights. It is reasonable that less effective attacks become less important on the final ranking of defenses, the same for defenses. As a result, GRB leaderboard can indicate the most robust defenses and the most effective attacks.   Robust Ranking of GML Models. In Figure <ref type="figure" target="#fig_5">5</ref> and 6, we show the rankings of GML models for all five datasets in graph injection scenario. The ranking is determined by s DEF w calculated by multiple attacks, which makes the results more general than previous works (only consider very few attacks and vanilla GML models). We find that the rankings are different across datasets, indicating that the robustness is related to the properties of graph data. Similar situations can be found in other graph benchmarks. For example in OGB, there is no dominant GML model, the performance of certain model architecture may vary a lot across datasets. Thus, we suggest that when giving conclusions about robustness in GML, one should not only consider the model itself but also take the graph data into account. GRB provides scalable datasets of various domains, which can help to investigate the robustness of GML models in different situations. Among current vanilla GML models, we find that GAT and GIN generally perform better under attacks in several datasets, which might be due to the higher expressiveness of model architecture. Meanwhile, models like APPNP and SGCN that rely on high-order message propagation seem to be sensible to perturbations on the graph. Besides, GML models with defense mechanisms (i.e., R-GCN, GNNGuard) are generally more robust. Moreover, we find simple methods like LN can be applied to all GML models to increase robustness. In the following, we further analyze some factors that affect the adversarial robustness of GML models. Effect of Difficulties. The new splitting scheme investigates the effect of the average degree of target nodes on the attack performance. In Figure <ref type="figure" target="#fig_7">7</ref>, attacks tend to better decrease the performance on nodes with lower degrees, which confirms the assumption that these low-degree nodes are more vulnerable. Moreover, according to Figure <ref type="figure" target="#fig_5">5</ref> and 6, the robustness on these nodes is indeed harder to achieve. This phenomenon encourages future work to deal with these vulnerable nodes to design more robust GML models.  Effect of Constraints. As shown in Figure <ref type="figure" target="#fig_9">8 and 9</ref>, for both graph modification and graph injection scenarios, the variation of constraints on the ratio of modification/injection affects the effectiveness of attacks. Meanwhile, the ranking of methods nearly agrees with different constraints. Without loss of generality, it is reasonable to fix a specific constraint to build GRB leaderboards, where the relative robustness of GML models will still be indicative.</p><p>Effect of General Defenses. Figure <ref type="figure" target="#fig_10">10</ref> and 11 shows the results of the adapted LN and AT for all five datasets. LN is a node-wise normalization technique, which can alleviate the perturbations on node features as well as hidden features in each layer of GML models. AT applies adversarial attacks during training via modification or injection, which changes the decision boundary of models to tolerate perturbed nodes. The results indicate that these approaches can generally increase the robustness of various types of GML models, which can serve as simple but strong baselines for future works. The details of these algorithms can be found in Appendix A.4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>To improve and facilitate the evaluation of the adversarial robustness in GML, we revisit the limitations of previous works and present the Graph Robustness Benchmark (GRB), a scalable, unified, modular, and reproducible benchmark. It has scalable datasets, unified evaluation scenarios, as well as a  modular coding framework that ensures the reproducibility and promotes the development of future methods. Extensive experiments with GRB provide insights on the understanding of the adversarial robustness in GML. We welcome the community to contribute more advanced GML models, attacks and defenses to further enrich GRB and to promote the research of this field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Broader Impact</head><p>Positive Impact. GRB provides a general framework for GML attacks and defenses. On one hand, it will help researchers to develop more robust GML models against attacks. On the other hand, it will also help possible attackers to develop better attack methods to turn down defenses. More public information of potential attacks will make it harder to conduct secret attacks based on private methods. As a result, more generally robust defense mechanisms can be designed.</p><p>Negative Impact. By exposing the attack methods widely, the GML models may face more threats. Attackers can use the benchmark to design destructive attacks that may cause damage to GML-based systems. Additionally, GRB has some limitations. For example, it only considers homogeneous graphs rather than heterogeneous ones for now. It focuses on node classification, while other tasks like link prediction and graph classification are also vulnerable. We will regularly update GRB (e.g., adding task-specific modules, designing related metrics.) to overcome these limitations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Maintenance Plan</head><p>Open Source. We host the GRB homepage (https://cogdl.ai/grb/home) with detailed introduction, leaderboards, and documentations. The codes are available in (https://github.com/ THUDM/grb). All materials are accessible to ensure reproducibility.</p><p>Submissions of New Methods. GRB will regularly include SOTA methods by updating the "method zoo". To welcome the contribution of the community, we allow submissions through google form. There are detailed examples and rules that guide researchers to add new attacks or defenses. Results will be updated on leaderboards to track the progress of the domain.</p><p>Extension of Tasks. Due to the modular design, GRB can be extended to other tasks. It requires adding task-specific functions in each module (dataset, model, trainer, attack, defense, etc.). Other common functions in GML can be reused for different tasks. There are online examples (https: //github.com/THUDM/grb/tree/master/examples) showing how to use GRB for other tasks, e.g., graph classification. In the future, GRB will support more GML tasks and define related threat models and metrics to unify the evaluation of adversarial robustness. high-performance deep learning library. In 32th Advances in Neural Information Processing Systems (NeurIPS), pages 8024-8035, 2019.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head><p>A.1 Datasets GRB includes five datasets of different scales, the details of them are as following:</p><p>• grb-cora: Small-scale citation networks. Each node represents a research paper, and each edge represents a citation relationship between two papers. Instead of using the popular version of Cora used in Planetoid <ref type="bibr" target="#b43">[44]</ref>, we use a refined version <ref type="bibr" target="#b41">[42]</ref>, which removes duplicated nodes and generates indirect pre-trained word embeddings as node features to solve the problem of information leakage in the original version. As a result, the features become 302-dimension continuous features rather than 1433-dimension binary features in the original version. The task is to classify papers into 7 categories.</p><p>• grb-citeseer: Small-scale citation networks. Similar to grb-cora, we use a refined version <ref type="bibr" target="#b41">[42]</ref> of CiteSeer, which eliminates identical papers and generates text embeddings by pre-trained BERT <ref type="bibr" target="#b44">[45]</ref> model. The resulting features are 768-dimension continuous features rather than 3703-dimension binary features in the original version. The task is to classify papers into 6 categories.</p><p>• grb-flickr: Medium-scale social networks. We adopt the Flickr dataset from <ref type="bibr" target="#b42">[43]</ref>, which contains descriptions and common properties of online images. The dataset is processed with a new splitting scheme and feature normalization mentioned in 4. The task is to classify images into 7 categories.</p><p>• grn-reddit: Large-scale social networks. We adopt the Reddit dataset from <ref type="bibr" target="#b42">[43]</ref>, which contains the communities of online posts based on user comments. The task is to classify communities into 41 categories.</p><p>• grb-aminer: Large-scale citation networks. The papers are collected from the academic searching engine Aminer <ref type="bibr" target="#b45">[46]</ref>, and the dataset was used in KDD-CUP 2020 Graph Adversarial Attack &amp; Defense competition. The task is to classify papers into 18 categories.</p><p>All five datasets are processed by the new splitting scheme and feature normalization mentioned in 4. The datasets are saved in the format of numpy <ref type="bibr" target="#b46">[47]</ref> zipped format (with .npz extension), and each has four files: adj.npz, features.npz, index.npz and labels.npz. The data can be loaded by using the Dataset module in GRB. All data are maintained and can be found in https://cogdl.ai/grb/datasets, where we will continuously update to ensure the accessibility for a long term. We use MIT license for data and codes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Related Works</head><p>In other domains like image classification, there are already standards <ref type="bibr" target="#b47">[48]</ref> or benchmarks <ref type="bibr" target="#b48">[49]</ref> [50] for evaluating adversarial robustness. Besides, there exists a toolkit like DeepRobust <ref type="bibr" target="#b27">[28]</ref> that implements adversarial attacks and defenses for both image classification and GML tasks. There are currently several benchmarks in GML. Open Graph Benchmark (OGB) <ref type="bibr" target="#b25">[26]</ref> develops a diverse set of scalable and realistic datasets, which facilitates the evaluation of GML models. Dwivedi et al. <ref type="bibr" target="#b26">[27]</ref> proposes a reproducible GNN benchmarking framework to facilitate researchers to add new models conveniently for arbitrary datasets. These benchmarks mainly focus on the performance but not the robustness of GNNs. so far, there is no benchmark on evaluating the adversarial robustness of GML models, i.e. the robustness in the presence of adversarial attacks. Nevertheless, it is an important but challenging task, which requires avoiding pitfalls in previous works and proposing a better solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Rethinking Ill-defined Evaluation Scenarios in Previous Works</head><p>Many of the previous adversarial attacks <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b12">13]</ref> consider the poisoning attack and develop the notion of unnoticeability, similar to Eq. 1. The initial idea is to imitate the same notion in image classification task: the differences of adversarial examples, compared with clean examples, should be tiny and unnoticeable, so that humans can still easily recognize the objects in images. That's why l p -norm is a widely-used constraint, as it corresponds to the visual sense of humans.</p><p>In the poisoning setting of graph modification attacks, the attackers assume that the graph is perturbed with corrupted nodes and edges, in a way that the perturbed graph is close to the original one. However, this assumption is controversial: If defenders have the original graph, they can simply train the model on that one; If defenders do not have the original graph (the general case for data poisoning where defenders can not tell whether the data are benign or not), then it does not make sense to keep unnoticeability. In this case, we only have G = (A , F ) but not G = (A, F) in Eq. 1, making it almost impossible to compare them. Previous works propose to compare the graph properties, like degree distribution <ref type="bibr" target="#b11">[12]</ref>, feature statistics <ref type="bibr" target="#b32">[33]</ref> or topological properties <ref type="bibr" target="#b19">[20]</ref>. However, all these comparisons need to be done in presence of the original graph. This is different from the case of images, where unnoticeability can be easily judged by humans even without ground-truth images.</p><p>The attackers may perturb the graph structure or attributes within the scope of unnoticeability defined by themselves, while defenders have to depend on their own observations to discover. For example, Nettack <ref type="bibr" target="#b11">[12]</ref> proposes to keep the degree distribution of modified graph similar to the original one. However, even if defenders notice that the degree distribution is different, it is still hard to identify specific malicious nodes or edges from the entire graph. On the contrary, defenses like GNNGuard <ref type="bibr" target="#b24">[25]</ref> can use the dissimilarity between features to alleviate effects of perturbations. We argue that it is inadequate to simply adopt the notion from image classification, and to make two graphs "similar" in whatever way. Indeed, there is not an absolute definition, but it is recommended that: "Unnoticeability" shall be considered from the defenders' view instead of the attackers'.</p><p>As a starting point, we consider very basic constraints in GRB (e.g., a limited number of modified edges or nodes). Pre-defined complex constraints might ignore the real capability of attackers and defenders, and might be obsoleted as the research goes. Thus, we do not add too many constraints and we insist that the notion like "unnoticeability" will be refined during the arms race between attackers and defenders. For example, if an advanced defense proposes a measure to identify malicious nodes with high probability, then the attackers can decide by themselves to refine the constraints based on this measure. There will be a trade-off, considering more constraints for one specific defense might result in less effectiveness for other methods. That's also why GRB considers a general metric across multiple attacks/defenses rather than a single pair of attack/defense. We insist that finding methods that are generally more effective bring much more value in practical applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4.1 GML Models</head><p>GCN (Graph Convolutional Networks) <ref type="bibr" target="#b3">[4]</ref> introduces a layer-wise propagation rule for graphstructured data which is motivated from a first-order approximation of spectral graph convolutions. GAT (Graph Attention Networks) <ref type="bibr">[6]</ref> leverages masked self-attention layers where nodes can attend over their neighborhoods' features with different weights. GIN (Graph Isomorphic Networks) <ref type="bibr" target="#b6">[7]</ref> is a theoretically guaranteed framework for analyzing the expressive power of GNNs to capture different graph structures. APPNP (Approximated Personalized Propagation of Neural Predictions ) <ref type="bibr" target="#b7">[8]</ref> utilizes an improved propagation scheme based on personalized PageRank to construct a simple model with fast approximation. TAGCN (Topological Adaptive Graph Convolutional Networks) <ref type="bibr" target="#b19">[20]</ref> provides a systematic way to design a set of fixed-size learnable filters to perform convolutions on graphs. GraphSAGE <ref type="bibr" target="#b4">[5]</ref> is a general inductive framework that leverages node features to generate node embeddings for previously unseen data. SGCN (Simplified Graph Convolutional Networks) <ref type="bibr" target="#b8">[9]</ref> removes nonlinearities and collapses weight matrices between consecutive layers, resulting in a linear model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4.2 Adversarial Attacks</head><p>Modification Attacks. RND (Random) <ref type="bibr" target="#b11">[12]</ref> is a random attack strategy that only modifies the structure of the graph. DICE (Delete Internally Connect Externally) <ref type="bibr" target="#b18">[19]</ref> deletes edges with the label, and adds edges with different labels. FGA (Fast Gradient Attack) <ref type="bibr" target="#b10">[11]</ref> calculates the gradient of dense adjacency matrix related to the classification loss and identifies the most vulnerable edges to perturb. FLIP (Flipping attack) <ref type="bibr" target="#b28">[29]</ref> is a deterministic approach that first ranks all nodes in ascending order according to their degrees, then flips their edges from the lower degree nodes to higher degree nodes. NEA (Network Embedding Attack) <ref type="bibr" target="#b28">[29]</ref> is a black-box attack originally designed for attacking Deepwalk. STACK (Strict Black-box Attack) <ref type="bibr" target="#b30">[31]</ref> does not require any knowledge of the target model and does not need training a surrogate model. It uses a generic graph filter unifying different GML models as an estimation for applying optimization attacks. PGD (Projected Gradient Descent) <ref type="bibr" target="#b33">[34]</ref> is originally an attack only modifying the features of inputs. Here, we adapt it to first randomly perturb edges of the graph, then optimize the features of target nodes by projected gradient descent.</p><p>Injection Attacks. In graph injection scenario, RND (Random) refers to randomly injecting new nodes with features randomly generated from the Gaussian distribution. FGSM (Fast Gradient Sign Method) <ref type="bibr" target="#b39">[40]</ref> linearizes the cost function around the current value of parameters, obtaining an optimal max-norm constrained perturbation, which is called the "fast gradient sign method" of generating adversarial examples. We use an iterative version of FGSM to conduct a graph injection attack. PGD (Projected Gradient Descent) <ref type="bibr" target="#b33">[34]</ref> is a universal "first-order adversary", i.e., the strongest attack utilizing the local first-order information about the network. The feature initialization is different from FGSM. SPEIT <ref type="bibr" target="#b16">[17]</ref> is the first place solution in KDD-CUP 2020 Graph Adversarial Attack &amp; Defense competition. It consists of adversarial adjacent matrix generation and enhanced feature gradient attacks, which are designed as a universal black-box graph injection attack. TDGIA (Topological Defective Graph Injection Attack) <ref type="bibr" target="#b17">[18]</ref> is an effective graph injection attack that tackles the topological defectiveness of graphs. By sequentially injecting malicious nodes around nodes that are topologically vulnerable, TDGIA can significantly influence the accuracy of GML models.</p><p>Since the proposed scenario in GRB is a black-box one, all the above attacks are first applied to a surrogate model (trained by the attackers themselves), and then transfer to the target model. As demonstrated in <ref type="bibr" target="#b17">[18]</ref>, the choice of surrogate model will influence the transferability of attacks. When using raw GCN as the surrogate model, attacks can generally achieve better performance. Thus in GRB experiments, we use GCN as the surrogate model for all attacks. Nevertheless, we encourage future researchers to further investigate the effect of transferability by testing other methods. GNN-SVD <ref type="bibr" target="#b23">[24]</ref> utilizes a low-rank approximation of the graph, that uses only the top singular components for its reconstruction. GNN-Guard <ref type="bibr" target="#b24">[25]</ref> introduces the neighbor importance estimation and the layer-wise graph memory for defenses. RobustGCN (R-GCN) <ref type="bibr" target="#b50">[51]</ref> is a GCN variant that is specially designed against adversarial attacks on graphs. It adapts the random perturbation of features from VAE <ref type="bibr" target="#b51">[52]</ref> and encodes both the mean and variance of the node representation thus makes the GNNs more robust. However, we found that methods like GNN-SVD and GNNGuard are not scalable to large-scale graphs due to the calculation of large dense matrices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4.3 Defenses</head><p>To have stronger baseline defenses, we propose two methods that are scalable and can generally improve the performance of GML models.</p><p>The adapted layer normalization (LN). LN <ref type="bibr" target="#b40">[41]</ref> computes the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. It is originally used to stabilize the hidden state dynamics in recurrent networks. We found that it can also help to improve the adversarial robustness of GML models. Unlike the original version that is only used after hidden layers, we use LN first on the input features, and then after every graph convolutional layer except the last one. The process of the proposed LN is illustrated in Figure <ref type="figure" target="#fig_12">12</ref>. The experiment results in Section 4 show that the proposed LN can generally improve the adversarial robustness of different types of GML models.</p><p>The adapted adversarial training (AT) in graph injection scenario. The AT <ref type="bibr" target="#b33">[34]</ref> is originally designed for defending adversarial attacks in image classification. The idea is to generate adversarial examples during training to change the classification distribution of models, which makes it difficult to perturb the results. Previous works <ref type="bibr" target="#b34">[35]</ref> show that AT is also helpful for GML models, but it only considers the problem of graph modification attack, where the original graph can be modified. In our case, the defense is against graph injection attack, thus we propose a variant of AT that conduct graph injection attack during training. The procedure of the proposed AT is as following: (1) Initialization: the training graph is first used to train GML models for a few iterations as a warm-up. ( <ref type="formula" target="#formula_0">2</ref>) FGSM attack: we conduct FGSM attack for a few steps on the current model to inject malicious nodes to attack training nodes. ( <ref type="formula">3</ref>) Update gradients: we then train on the injected graph and minimize the classification loss of training nodes (excluding the injected nodes). ( <ref type="formula">4</ref>) Repetition: we repeat this AT process until the training loss converges. Finally, we are able to construct more robust GML models. Interestingly, we found that AT with FGSM can also defend against other attacks, which shows great generality. Besides, the proposed AT can be easily adapt to any kind of GML models and scalable to large graphs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5.1 Hyper-Parameter Settings</head><p>Hyper-Parameters of GML Models and Defenses. The hyper-parameters of vanilla GML models and defenses are shown in Table <ref type="table" target="#tab_8">6</ref>, 7, 8, 9, 10, where GCNGuard stands for GCN+GNNGuard, GATGuard for GAT+GNNGuard, GCN-SVD for GCN+GNN-SVD, and LN for the proposed layer normalization. For the proposed adversarial training (AT), the hyper-parameters are shown in Table <ref type="table" target="#tab_7">5</ref>.</p><p>Under the proposed AT, GML models are trained while being continuously attacked by FGSM attack for a few steps per training iterations. Note that in each iteration, the attack is independent of previous iterations, only based on the weights of the model in the current iteration. The other hyper-parameters are exactly the same as training GML models.</p><p>Hyper-Parameters for Adversarial Attacks. The hyper-parameters of attacks are shown in Table <ref type="table" target="#tab_14">12</ref>.</p><p>For graph modification, following the most common setting in previous works, attackers are allowed to perturb a limited number of edges in the graph (∆ A : the number of modified edges less than a ratio γ e of all edges). For graph injection, we follow the heuristic setting of KDDCUP 2020, attackers are allowed to inject new nodes with limited edges (∆ A : less than N n injected nodes each with less than N e edges; ∆ F : constrained range of features [F min , F max ].). Nevertheless, more definitions of unnoticeabilty can be developed by attackers and defenders when using GRB. Since the proposed scenario in GRB is a black-box one, all the above attacks are first applied to a surrogate model (trained by the attackers themselves), and then transfer to the target model. As demonstrated in <ref type="bibr" target="#b17">[18]</ref>, the choice of surrogate model will influence the transferability of attacks. When using raw GCN as the surrogate model, attacks can generally achieve better performance. Thus in GRB experiments, we use GCN as the surrogate model for all attacks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.6 Detailed Experiment Results</head><p>We conduct extensive experiments on all datasets and build a leaderboard for each dataset. Here we show the results of graph injection scenario with Top-5 attacks vs. Top-10 defenses, full leaderboards can be found in https://cogdl.ai/grb/leaderboard. Both attacks and defenses are ranked by the weighted accuracy, where red and blue indicated the best results in each difficulty. It can be seen that different methods vary performance in different datasets. And it is also hard for attacks to be generally effective, especially in the presence of the proposed strong defense baselines. The runtime of attacks on large-scale graphs (grb-aminer, grb-reddit) can be found in Table <ref type="table" target="#tab_13">11</ref>.    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of GRB's attack vs. defense (graph injection) scenario: Black-box: attackers only have access to the attributed graph but not the target models; Inductive: target models are trained in an inductive setting (test nodes are unseen during training); Injection: attackers are allowed to inject new nodes without modifying the existing ones; Evasion: attacks happen during model inference. All attacks and defenses are evaluated under unified settings to be fairly compared.</figDesc><graphic url="image-1.png" coords="2,108.00,72.00,396.00,137.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>G | arg max l∈[ 1 ,</head><label>1</label><figDesc>...,L] M(G ) = arg max l∈[1,...,L] M(G)| s.t. d A (A , A) ≤ ∆ A and d F (F , F) ≤ ∆ F (1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: GRB Framework.</figDesc><graphic url="image-2.png" coords="4,306.00,119.79,198.00,128.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: GRB usage examples. Left: Train GCNs on the grb-cora dataset. Right: Apply the TDGIA attack on the trained model. GRB facilitates the usage of GML models, attacks,and defenses.</figDesc><graphic url="image-3.png" coords="6,108.00,72.00,395.98,150.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: GRB's splitting scheme. Difficulties are related to the average degree of test nodes.</figDesc><graphic url="image-4.png" coords="7,108.00,72.00,395.97,70.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Ranking of vanilla GML models in graph injection scenario for all five datasets.</figDesc><graphic url="image-5.png" coords="8,108.00,426.61,396.00,90.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Ranking of top 10 defensed GML models in graph injection scenario for all five datasets.</figDesc><graphic url="image-6.png" coords="8,108.00,550.60,395.98,95.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Effect of dataset difficulties on the performance of graph injection attacks.</figDesc><graphic url="image-7.png" coords="9,108.00,216.23,395.99,76.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Effect of constraints on GML models. Left: graph modification. Right: graph injection.</figDesc><graphic url="image-8.png" coords="9,108.00,390.65,194.04,85.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Effect of constraints on attacks. Left: graph modification. Right: graph injection.</figDesc><graphic url="image-9.png" coords="9,307.47,390.52,194.04,85.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Effect of the adapted LN on the adversarial robustness of vanilla GML models for all five datasets. Adding LN can generally increase robustness of GML models.</figDesc><graphic url="image-10.png" coords="10,108.00,72.00,396.02,72.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Effect of the adapted AT on the adversarial robustness of vanilla GML models for all five datasets. Adding AT can generally increase robustness of GML models.</figDesc><graphic url="image-11.png" coords="10,108.00,188.72,396.00,73.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: The proposed layer normalization in GRB. It is applied on the input and after every graph convolutional layer except the last one.</figDesc><graphic url="image-12.png" coords="16,385.20,487.84,118.80,128.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>A categorization of graph adversarial attacks. There are mainly two scenarios: graph modification and graph injection. GRB supports the implementation of all types of methods. †</figDesc><table><row><cell>Adversarial Attack</cell><cell cols="3">Knowledge Black. White. Poi. Eva. Mod. Inj. Objective Approach Scalability</cell></row><row><cell>DICE [19]</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>FGA [11]</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>The GML models are trained in trusted data and used to classify unseen data (e.g., new users), i.e., the validation and test data is unseen during training. (3) Evasion: Attacks will only happen during the inference phase. Furthermore, we clarify attackers' and defenders' capabilities in GRB:1. For attackers: (a) They have knowledge about the entire graph (including all nodes, edges and labels but excluding the labels of the test nodes), but do not have knowledge about the target model or defense mechanism. (b) For graph modification, following the most common setting in previous works, attackers are allowed to perturb a limited number of edges in the graph (∆ A : the number of modified edges less than a ratio γ e of all edges). (c) For graph injection, we follow the heuristic setting of KDDCUP 2020, attackers are allowed to inject new nodes with limited edges (∆ A : less than N n injected nodes each with less than N e edges; ∆ F : constrained range of features [F min , F max ].). (d) They are not allowed to modify the original graph for training. (e) They are allowed to get predictions from the target model through a limited number of queries.</figDesc><table><row><cell>2. For defenders: (a) They have knowledge about the graph excluding the test nodes to be attacked.</cell></row><row><cell>(b) They are allowed to use any method to increase the adversarial robustness, but do not have</cell></row><row><cell>prior knowledge about the edges/nodes that are modified/injected.</cell></row></table><note>1) Black-box: Both attackers and defenders do not have knowledge about the methods each other applied. (2) Inductive:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Statistics of five GRB datasets covering from small-to large-scale graphs.</figDesc><table><row><cell>Dataset</cell><cell>Scale</cell><cell>#Nodes</cell><cell>#Edges</cell><cell cols="2">#Feat. #Classes</cell><cell>Feat. Range (original)</cell><cell>Feat. Range (normalized)</cell></row><row><cell>grb-cora</cell><cell>Small</cell><cell>2,680</cell><cell>5,148</cell><cell>302</cell><cell>7</cell><cell>[-2.30, 2.40]</cell><cell>[-0.94, 0.94]</cell></row><row><cell>grb-citeseer</cell><cell>Small</cell><cell>3,191</cell><cell>4,172</cell><cell>768</cell><cell>6</cell><cell>[-4.55, 1.67]</cell><cell>[-0.96, 0.89]</cell></row><row><cell>grb-flickr</cell><cell>Medium</cell><cell>89,250</cell><cell>449,878</cell><cell>500</cell><cell>7</cell><cell>[-0.90, 269.96]</cell><cell>[-0.47, 1.00]</cell></row><row><cell>grb-reddit</cell><cell>Large</cell><cell cols="2">232,965 11,606,919</cell><cell>602</cell><cell cols="2">41 [-28.19, 120.96]</cell><cell>[-0.98, 0.99]</cell></row><row><cell>grb-aminer</cell><cell>Large</cell><cell>659,574</cell><cell>2,878,577</cell><cell>100</cell><cell>18</cell><cell>[-1.74, 1.62]</cell><cell>[-0.93, 0.93]</cell></row><row><cell cols="8">Scalability. GRB includes five datasets of different scales, grb-cora, grb-citeseer, grb-flickr, grb-</cell></row><row><cell cols="7">reddit, and grb-aminer. The original datasets are gathered from previous works</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>grb-aminer leaderboard (Top 5 ATK. vs. Top 10 DEF.) in graph injection scenario.</figDesc><table><row><cell></cell><cell cols="2">Defenses</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>Avg.</cell><cell>Avg. 3-Max</cell><cell>Weighted</cell></row><row><cell cols="2">Attacks</cell><cell></cell><cell>GAT+AT</cell><cell cols="2">R-GCN+AT SGCN+LN</cell><cell>R-GCN</cell><cell>GCN+LN</cell><cell>GATLN</cell><cell>GIN+LN</cell><cell cols="2">TAGCN+LN TAGCN+AT</cell><cell>GAT</cell><cell>Accuracy</cell><cell>Accuracy</cell><cell>Accuracy</cell></row><row><cell></cell><cell></cell><cell cols="8">E 59.54±0.05 56.83±0.06 56.73±0.06 56.12±0.07 53.51±0.21 43.93±0.41 51.10±0.12</cell><cell>54.63±0.20</cell><cell>49.59±0.50</cell><cell cols="2">42.40±0.52 52.44±0.17</cell><cell>57.70±1.31</cell><cell>58.08±0.04</cell></row><row><cell>1</cell><cell>TDGIA</cell><cell cols="8">M 68.39±0.02 65.61±0.02 66.11±0.02 65.23±0.03 66.78±0.05 61.84±1.20 64.49±0.10 H 75.83±0.02 72.35±0.02 72.10±0.00 71.94±0.02 73.39±0.02 75.22±0.04 72.92±0.02</cell><cell>64.62±0.02 68.94±0.03</cell><cell>67.27±0.04 73.98±0.01</cell><cell cols="2">62.47±1.01 65.28±0.23 75.03±0.03 73.17±0.01</cell><cell>67.48±0.68 75.36±0.34</cell><cell>67.69±0.02 75.33±0.01</cell></row><row><cell></cell><cell></cell><cell cols="8">F 67.69±0.03 63.62±0.32 62.20±0.15 61.99±0.22 60.38±1.46 59.69±1.57 59.59±0.42</cell><cell>59.06±1.75</cell><cell>57.24±5.04</cell><cell cols="2">56.63±6.75 60.81±1.71</cell><cell>64.52±2.32</cell><cell>65.74±0.21</cell></row><row><cell></cell><cell></cell><cell cols="8">E 59.54±0.07 56.80±0.05 56.94±0.10 55.64±0.10 56.15±0.06 56.13±0.07 54.24±0.09</cell><cell>56.61±0.06</cell><cell>56.59±0.08</cell><cell cols="2">57.36±0.09 56.60±0.04</cell><cell>57.95±1.14</cell><cell>58.62±0.05</cell></row><row><cell>2</cell><cell>SPEIT</cell><cell cols="8">M 68.37±0.03 65.46±0.03 66.20±0.02 65.25±0.05 66.75±0.03 67.49±0.06 65.05±0.06 H 75.94±0.04 72.27±0.03 72.36±0.03 71.86±0.03 73.41±0.01 75.34±0.03 72.87±0.03</cell><cell>64.47±0.04 68.88±0.05</cell><cell>66.95±0.05 73.98±0.02</cell><cell cols="2">66.81±0.04 66.28±0.02 73.83±0.04 73.07±0.01</cell><cell>67.60±0.59 75.08±0.82</cell><cell>67.86±0.03 75.33±0.02</cell></row><row><cell></cell><cell></cell><cell cols="8">F 68.04±0.03 64.05±0.04 64.84±0.04 64.06±0.04 65.51±0.02 64.02±0.04 63.11±0.02</cell><cell>62.59±0.04</cell><cell>63.77±0.06</cell><cell cols="2">63.58±0.06 64.36±0.02</cell><cell>66.13±1.38</cell><cell>66.89±0.02</cell></row><row><cell></cell><cell></cell><cell cols="8">E 59.56±0.06 57.53±0.06 57.41±0.06 56.38±0.11 57.76±0.05 58.83±0.10 54.41±0.13</cell><cell>58.07±0.12</cell><cell>58.14±0.04</cell><cell cols="2">57.46±0.10 57.55±0.03</cell><cell>58.85±0.57</cell><cell>59.09±0.05</cell></row><row><cell>3</cell><cell>RND</cell><cell cols="8">M 68.22±0.04 65.86±0.03 66.29±0.03 65.34±0.06 67.03±0.03 68.62±0.05 65.54±0.06 H 75.75±0.02 72.66±0.02 72.42±0.03 72.00±0.03 73.52±0.02 75.63±0.03 73.36±0.03</cell><cell>64.98±0.08 69.30±0.06</cell><cell>67.34±0.04 74.04±0.02</cell><cell cols="2">67.71±0.06 66.69±0.02 75.36±0.03 73.40±0.01</cell><cell>68.18±0.38 75.58±0.17</cell><cell>68.24±0.03 75.39±0.01</cell></row><row><cell></cell><cell></cell><cell cols="8">F 67.72±0.04 64.98±0.02 65.31±0.04 64.45±0.04 66.17±0.02 67.54±0.04 64.36±0.06</cell><cell>64.33±0.03</cell><cell>66.42±0.03</cell><cell cols="2">66.23±0.04 65.75±0.02</cell><cell>67.23±0.58</cell><cell>67.34±0.03</cell></row><row><cell></cell><cell></cell><cell cols="8">E 59.70±0.06 57.71±0.05 57.73±0.09 57.19±0.07 57.60±0.08 57.05±0.17 54.69±0.09</cell><cell>58.18±0.07</cell><cell>58.27±0.09</cell><cell cols="2">58.46±0.11 57.66±0.05</cell><cell>58.81±0.64</cell><cell>59.14±0.05</cell></row><row><cell>4</cell><cell>PGD</cell><cell cols="8">M 68.40±0.05 66.12±0.02 66.39±0.04 65.67±0.04 67.04±0.03 68.24±0.04 65.64±0.08 H 75.83±0.03 72.91±0.02 72.47±0.04 72.18±0.05 73.52±0.02 75.55±0.05 73.58±0.04</cell><cell>65.17±0.05 69.64±0.05</cell><cell>67.32±0.03 73.89±0.02</cell><cell cols="2">67.85±0.05 66.78±0.02 74.34±0.04 73.39±0.01</cell><cell>68.16±0.23 75.24±0.65</cell><cell>68.12±0.03 75.36±0.02</cell></row><row><cell></cell><cell></cell><cell cols="8">F 68.01±0.02 65.41±0.01 65.54±0.03 65.05±0.03 66.22±0.02 66.49±0.04 64.63±0.04</cell><cell>64.82±0.04</cell><cell>66.32±0.02</cell><cell cols="2">66.14±0.04 65.86±0.01</cell><cell>66.94±0.76</cell><cell>67.37±0.02</cell></row><row><cell></cell><cell></cell><cell cols="8">E 59.71±0.05 57.69±0.08 57.62±0.06 57.16±0.08 57.60±0.06 56.97±0.09 54.67±0.08</cell><cell>58.20±0.10</cell><cell>58.23±0.06</cell><cell cols="2">58.46±0.07 57.63±0.05</cell><cell>58.81±0.65</cell><cell>59.15±0.04</cell></row><row><cell>5</cell><cell>FGSM</cell><cell cols="8">M 68.37±0.02 66.10±0.03 66.38±0.04 65.70±0.05 67.03±0.04 68.27±0.04 65.61±0.08 H 75.82±0.02 72.92±0.04 72.48±0.03 72.18±0.05 73.52±0.02 75.55±0.05 73.60±0.04</cell><cell>65.16±0.05 69.64±0.04</cell><cell>67.30±0.02 73.90±0.01</cell><cell cols="2">67.84±0.07 66.78±0.02 74.34±0.04 73.39±0.01</cell><cell>68.16±0.23 75.23±0.65</cell><cell>68.11±0.02 75.35±0.02</cell></row><row><cell></cell><cell></cell><cell cols="8">F 68.00±0.02 65.41±0.02 65.54±0.04 65.05±0.04 66.22±0.02 66.50±0.06 64.65±0.04</cell><cell>64.82±0.03</cell><cell>66.34±0.03</cell><cell cols="2">66.15±0.06 65.87±0.01</cell><cell>66.95±0.75</cell><cell>67.37±0.01</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>00</cell><cell>59.47±0.00</cell><cell>59.62±0.00</cell><cell cols="2">59.88±0.00 59.12±0.00</cell><cell>60.29±0.37</cell><cell>60.42±0.00</cell></row><row><cell cols="2">6 W/O Attack</cell><cell cols="8">M 68.28±0.00 66.14±0.00 67.11±0.00 66.35±0.00 67.00±0.00 68.98±0.00 66.26±0.00 H 75.85±0.00 73.05±0.00 72.69±0.00 72.66±0.00 73.46±0.00 75.64±0.00 73.69±0.00</cell><cell>65.41±0.00 69.84±0.00</cell><cell>67.53±0.00 74.10±0.00</cell><cell cols="2">68.41±0.00 67.15±0.00 75.76±0.00 73.67±0.00</cell><cell>68.56±0.30 75.75±0.09</cell><cell>68.59±0.00 75.52±0.00</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>02</cell><cell>68.99±0.04</cell><cell>73.91±0.01</cell><cell>74.08±0.03</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell cols="8">F 67.73±0.03 63.96±0.21 63.19±0.10 62.80±0.15 62.18±0.98 61.58±1.05 61.00±0.28</cell><cell>60.54±1.18</cell><cell>59.82±3.38</cell><cell>59.37±4.53</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table><note>E 59.67±0.00 58.08±0.00 60.22±0.00 58.53±0.00 58.14±0.00 60.78±0.00 56.83±0.F 67.93±0.00 65.76±0.00 66.68±0.00 65.85±0.00 66.20±0.00 68.47±0.00 65.59±0.00 64.91±0.00 67.08±0.00 68.02±0.00 66.65±0.00 68.14±0.24 68.11±0.00 Avg. Accuracy E 59.62±0.02 57.44±0.03 57.77±0.03 56.84±0.04 56.79±0.04 55.62±0.06 54.33±0.04 57.53±0.05 56.74±0.09 55.67±0.10 ---M 68.34±0.01 65.88±0.01 66.41±0.01 65.59±0.02 66.94±0.02 67.24±0.19 65.43±0.03 64.97±0.02 67.28±0.01 66.85±0.18 ---H 75.84±0.01 72.69±0.01 72.42±0.01 72.14±0.02 73.47±0.01 75.49±0.01 73.33±0.02 69.38±0.02 73.98±0.00 74.78±0.02 ---F 67.90±0.01 64.87±0.05 65.02±0.03 64.41±0.04 65.12±0.25 65.45±0.26 63.65±0.07 63.42±0.29 64.53±0.84 64.46±1.13 ---Avg. 3-Min Accuracy E 59.55±0.03 57.05±0.04 57.02±0.03 56.05±0.07 55.73±0.07 52.33±0.12 53.25±0.07 56.43±0.07 54.77±0.16 52.41±0.17 ---M 68.28±0.01 65.64±0.02 66.20±0.01 65.28±0.03 66.84±0.02 65.85±0.40 65.02±0.04 64.69±0.03 67.17±0.02 65.66±0.34 ---H 75.80±0.02 72.42±0.02 72.29±0.01 71.93±0.02 73.42±0.01 75.36±0.02 73.05±0.02 69.04±0.03 73.92±0.01 74.17±0.03 ---F 67.78±0.02 64.22±0.11 64.12±0.06 63.50±0.08 64.02±0.49 63.39±0.53 62.35±0.14 61.99±0.58 62.44±1.69 62.11±2.26 ---Weighted Accuracy E 59.53±0.04 56.93±0.04 56.94±0.04 55.93±0.08 54.63±0.14 48.21±0.27 52.23±0.08 55.55±0.14 52.18±0.33 47.45±0.35 ---M 68.25±0.02 65.57±0.02 66.17±0.02 65.28±0.02 66.79±0.02 63.85±0.80 64.77±0.07 64.60±0.03 67.06±0.03 64.07±0.68 ---H 75.78±0.02 72.37±0.02 72.20±0.01 71.92±0.03 73.41±0.01 75.30±0.02 72.98±0.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Statistics of GRB datasets after new splitting scheme and feature normalization.</figDesc><table><row><cell>Dataset</cell><cell>Splitting</cell><cell>Avg. Deg.</cell><cell>Avg.Deg. (E / M / H / F)</cell><cell>Feature range (original)</cell><cell>Feature range (normalized)</cell></row><row><cell>grb-cora grb-citeseer grb-flickr grb-reddit grb-aminer</cell><cell>Train / Val 0.6 / 0.1 Test: E / M / H / F 0.1 / 0.1 / 0.1 / 0.3</cell><cell cols="3">3.84 2.61 10.08 99.65 29.23/68.36/150.99/82.86 [-28.19, 120.96] 1.53/2.96/5.23/3.24 [-2.30, 2.40] 1.01/1.74/3.82/2.19 [-4.55, 1.67] 5.00/6.02/11.03/7.35 [-0.90, 269.96] 8.73 1.99/5.12/13.25/6.79 [-1.74, 1.62]</cell><cell>[-0.94, 0.94] [-0.96, 0.89] [-0.47, 1.00] [-0.98, 0.99] [-0.93, 0.93]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Hyper-parameters for adversarial training for five datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="6">Attack Step size # Steps/Iter # Injection # Edges Feature range</cell></row><row><cell>grb-cora</cell><cell>FGSM</cell><cell>0.01</cell><cell>10</cell><cell>20</cell><cell>20</cell><cell>[-0.94, 0.94]</cell></row><row><cell cols="2">grb-citeseer FGSM</cell><cell>0.01</cell><cell>10</cell><cell>30</cell><cell>20</cell><cell>[-0.96, 0.89]</cell></row><row><cell>grb-flickr</cell><cell>FGSM</cell><cell>0.01</cell><cell>10</cell><cell>200</cell><cell>100</cell><cell>[-0.47, 0.99]</cell></row><row><cell>grb-reddit</cell><cell>FGSM</cell><cell>0.01</cell><cell>10</cell><cell>500</cell><cell>200</cell><cell>[-0.98, 0.99]</cell></row><row><cell cols="2">grb-aminer FGSM</cell><cell>0.01</cell><cell>10</cell><cell>500</cell><cell>100</cell><cell>[-0.93, 0.93]</cell></row></table><note>A.5 ReproducibilityReproducibility is one of the main features of GRB. For reproducing results on leaderboards, all necessary components are available, including model weights, attack parameters, generated adversarial results, etc. Besides, GRB provides scripts that allow users to reproduce results by a single command line. All codes are available in https://github.com/THUDM/grb, where the implementation details and examples can be found. GRB also provides full documentation for each module and function. All experiments can be reproduced in a single NVIDIA V100 GPU (with 32 GB memory).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Hyper-parameters of GML models for grb-cora dataset.</figDesc><table><row><cell>Model</cell><cell cols="2">#Params Hidden sizes</cell><cell>LR</cell><cell cols="2">Dropout Optimizer</cell><cell>Others</cell></row><row><cell>GCN</cell><cell>28,167</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>GCN+LN</cell><cell>29,027</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>SAGE</cell><cell>160,320</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>full-batch</cell></row><row><cell>SAGE+LN</cell><cell>161,180</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>full-batch</cell></row><row><cell>SGCN</cell><cell>28,771</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=4</cell></row><row><cell>SGCN+LN</cell><cell>29,027</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=4</cell></row><row><cell>R-GCN</cell><cell>56,334</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>TAGCN</cell><cell>84,103</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=2</cell></row><row><cell>TAGCN+LN</cell><cell>84,963</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=2</cell></row><row><cell>GAT</cell><cell>217,940</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>num_heads=4</cell></row><row><cell>GAT+LN</cell><cell>219,568</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>num_heads=4</cell></row><row><cell>APPNP</cell><cell>19,847</cell><cell>64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>alpha=0.01, k=10</cell></row><row><cell>APPNP+LN</cell><cell>20,579</cell><cell>64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>alpha=0.01, k=10</cell></row><row><cell>GIN</cell><cell>45,194</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>GIN+LN</cell><cell>46,054</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>GCNGuard</cell><cell>24,010</cell><cell>64, 64</cell><cell>0.001</cell><cell>0.1</cell><cell>Adam</cell><cell></cell></row><row><cell>GATGuard</cell><cell>151,639</cell><cell>64, 64</cell><cell>0.001</cell><cell>0.1</cell><cell>Adam</cell><cell>num_heads=4</cell></row><row><cell>GCN-SVD</cell><cell>24,007</cell><cell>64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>Hyper-parameters of GML models for grb-citeseer dataset.</figDesc><table><row><cell>Model</cell><cell cols="2">#Params Hidden sizes</cell><cell>LR</cell><cell cols="2">Dropout Optimizer</cell><cell>Others</cell></row><row><cell>GCN</cell><cell>57,926</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>GCN+LN</cell><cell>59,718</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>SAGE</cell><cell>718,924</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>full batch</cell></row><row><cell>SAGE+LN</cell><cell>720,716</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>full batch</cell></row><row><cell>SGCN</cell><cell>59,462</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=4</cell></row><row><cell>SGCN+LN</cell><cell>59,718</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=4</cell></row><row><cell>R-GCN</cell><cell>115,852</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>TAGCN</cell><cell>173,382</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=2</cell></row><row><cell cols="2">TAGCN+LN 175,174</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=2</cell></row><row><cell>GAT</cell><cell>336,200</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>num_heads=4</cell></row><row><cell>GAT+LN</cell><cell>338,760</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>num_heads=4</cell></row><row><cell>APPNP</cell><cell>49,606</cell><cell>64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>alpha=0.01, k=10</cell></row><row><cell>APPNP+LN</cell><cell>51,270</cell><cell>64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>alpha=0.01, k=10</cell></row><row><cell>GIN</cell><cell>74,953</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>GIN+LN</cell><cell>76,745</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>GCNGuard</cell><cell>53,769</cell><cell>64, 64</cell><cell>0.001</cell><cell>0.1</cell><cell>Adam</cell><cell></cell></row><row><cell>GATGuard</cell><cell>269,899</cell><cell>64, 64</cell><cell>0.001</cell><cell>0.1</cell><cell>Adam</cell><cell>num_heads=4</cell></row><row><cell>GCN-SVD</cell><cell>53,766</cell><cell>64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>Hyper-parameters of GML models for grb-flickr dataset.</figDesc><table><row><cell>Model</cell><cell cols="2">#Params Hidden sizes</cell><cell>LR</cell><cell cols="2">Dropout Optimizer</cell><cell>Others</cell></row><row><cell>GCN</cell><cell>169,863</cell><cell>256, 128, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>GCN+LN</cell><cell>171,631</cell><cell>256, 128, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>SAGE</cell><cell cols="3">496,146 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>full batch</cell></row><row><cell>SAGE+LN</cell><cell cols="3">497,658 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>full batch</cell></row><row><cell>R-GCN</cell><cell cols="3">196,110 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>TAGCN</cell><cell cols="3">293,383 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=2</cell></row><row><cell cols="4">TAGCN+LN 294,895 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=2</cell></row><row><cell>GAT</cell><cell cols="3">799,316 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>num_heads=4</cell></row><row><cell>GAT+LN</cell><cell cols="3">802,364 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>num_heads=4</cell></row><row><cell>APPNP</cell><cell>65,031</cell><cell>128</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>alpha=0.01, k=10</cell></row><row><cell>APPNP+LN</cell><cell>66,287</cell><cell>128</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>alpha=0.01, k=10</cell></row><row><cell>GIN</cell><cell cols="3">164,874 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>GIN+LN</cell><cell cols="3">166,386 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>GCNGuard</cell><cell>81,546</cell><cell>128, 128</cell><cell>0.001</cell><cell>0.1</cell><cell>Adam</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 :</head><label>9</label><figDesc>Hyper-parameters of GML models for grb-reddit dataset.</figDesc><table><row><cell>Model</cell><cell cols="5">#Params Hidden sizes LR Dropout Optimizer</cell><cell>Others</cell></row><row><cell>GCN</cell><cell cols="3">115,497 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>GCN+LN</cell><cell cols="3">117,213 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>SAGE</cell><cell cols="3">643,536 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>full batch</cell></row><row><cell>SAGE+LN</cell><cell cols="3">645,252 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>full batch</cell></row><row><cell>SGCN</cell><cell cols="3">116,701 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=4</cell></row><row><cell>SGCN+LN</cell><cell cols="3">117,213 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=4</cell></row><row><cell>R-GCN</cell><cell cols="3">230,994 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>TAGCN</cell><cell cols="3">345,641 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=2</cell></row><row><cell cols="4">TAGCN+LN 347,357 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=2</cell></row><row><cell>GAT</cell><cell>104,950</cell><cell>64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>num_heads=2</cell></row><row><cell>GAT+LN</cell><cell>106,410</cell><cell>64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>num_heads=2</cell></row><row><cell>APPNP</cell><cell>82,473</cell><cell>128</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>alpha=0.01, k=10</cell></row><row><cell>APPNP+LN</cell><cell>83,933</cell><cell>128</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>alpha=0.01, k=10</cell></row><row><cell>GIN</cell><cell cols="3">182,316 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>GIN+LN</cell><cell cols="3">184,032 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 10 :</head><label>10</label><figDesc>Hyper-parameters of GML models for grb-aminer dataset.</figDesc><table><row><cell>Model</cell><cell cols="5">#Params Hidden sizes LR Dropout Optimizer</cell><cell>Others</cell></row><row><cell>GCN</cell><cell>48,274</cell><cell cols="2">128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>GCN+LN</cell><cell>48,986</cell><cell cols="2">128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>SAGE</cell><cell cols="3">156,184 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>full batch</cell></row><row><cell>SAGE+LN</cell><cell cols="3">156,896 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>full batch</cell></row><row><cell>SGCN</cell><cell>48,474</cell><cell cols="2">128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=4</cell></row><row><cell>SGCN+LN</cell><cell>48,986</cell><cell cols="2">128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=4</cell></row><row><cell>R-GCN</cell><cell>96,548</cell><cell cols="2">128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>TAGCN</cell><cell cols="3">144,018 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=2</cell></row><row><cell cols="4">TAGCN+LN 144,730 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>k=2</cell></row><row><cell>GAT</cell><cell>177,624</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>num_heads=2</cell></row><row><cell>GAT+LN</cell><cell>178,848</cell><cell>64, 64, 64</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>num_heads=2</cell></row><row><cell>APPNP</cell><cell>15,250</cell><cell>128</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>alpha=0.01, k=10</cell></row><row><cell>APPNP+LN</cell><cell>15,706</cell><cell>128</cell><cell>0.01</cell><cell>0.5</cell><cell>Adam</cell><cell>alpha=0.01, k=10</cell></row><row><cell>GIN</cell><cell cols="3">115,093 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row><row><cell>GIN+LN</cell><cell cols="3">115,805 128, 128, 128 0.01</cell><cell>0.5</cell><cell>Adam</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 11 :</head><label>11</label><figDesc>Runtime (/s) of graph injection attacks on large-scale graphs.</figDesc><table><row><cell></cell><cell cols="3">Difficulty RAND FGSM</cell><cell>PGD</cell><cell>SPEIT</cell><cell>TDGIA</cell></row><row><cell></cell><cell>F</cell><cell>10.32</cell><cell cols="4">1110.92 1112.95 1119.10 6892.12</cell></row><row><cell>grb-reddit</cell><cell>H M</cell><cell>10.14 9.97</cell><cell cols="2">243.32 1067.18 801.40 244.10</cell><cell cols="2">263.65 3179.26 950.90 3126.48</cell></row><row><cell></cell><cell>E</cell><cell>11.64</cell><cell>304.03</cell><cell>305.44</cell><cell cols="2">319.04 4053.48</cell></row><row><cell></cell><cell>F</cell><cell>12.93</cell><cell>954.53</cell><cell>953.14</cell><cell cols="2">961.66 4079.35</cell></row><row><cell>grb-aminer</cell><cell>H M</cell><cell>12.87 11.62</cell><cell>212.41 932.04</cell><cell>213.44 926.10</cell><cell cols="2">233.08 2673.79 372.64 2612.44</cell></row><row><cell></cell><cell>E</cell><cell>12.61</cell><cell>218.53</cell><cell>219.93</cell><cell cols="2">239.57 2640.93</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 12 :</head><label>12</label><figDesc>Hyper-parameters for attacks for five datasets in graph injection scenario.</figDesc><table><row><cell>Dataset</cell><cell cols="3">Attack Step size # Iter</cell><cell># Injection (E/M/H/F)</cell><cell># Edges</cell><cell>Feature Range</cell><cell>Others</cell></row><row><cell></cell><cell>RND</cell><cell>-</cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell>Random features</cell></row><row><cell></cell><cell>PGD</cell><cell>0.01</cell><cell>1000</cell><cell></cell><cell></cell><cell></cell><cell>-</cell></row><row><cell>grb-cora</cell><cell>FGSM</cell><cell>0.01</cell><cell>1000</cell><cell>20/20/20/60</cell><cell>20</cell><cell>[-0.94, 0.94]</cell><cell>-</cell></row><row><cell></cell><cell>SPEIT</cell><cell>0.01</cell><cell>1000</cell><cell></cell><cell></cell><cell></cell><cell>-</cell></row><row><cell></cell><cell>TDGIA</cell><cell>0.01</cell><cell>1000</cell><cell></cell><cell></cell><cell></cell><cell>Sequential</cell></row><row><cell></cell><cell>RND</cell><cell>-</cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell>Random features</cell></row><row><cell></cell><cell>PGD</cell><cell>0.01</cell><cell>1000</cell><cell></cell><cell></cell><cell></cell><cell>-</cell></row><row><cell>grb-citeseer</cell><cell>FGSM</cell><cell>0.01</cell><cell>1000</cell><cell>30/30/30/90</cell><cell>20</cell><cell>[-0.96, 0.89]</cell><cell>-</cell></row><row><cell></cell><cell>SPEIT</cell><cell>0.01</cell><cell>1000</cell><cell></cell><cell></cell><cell></cell><cell>-</cell></row><row><cell></cell><cell>TDGIA</cell><cell>0.01</cell><cell>1000</cell><cell></cell><cell></cell><cell></cell><cell>Sequential</cell></row><row><cell></cell><cell>RND</cell><cell>-</cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell>Random features</cell></row><row><cell></cell><cell>PGD</cell><cell>0.01</cell><cell>2000</cell><cell></cell><cell></cell><cell></cell><cell>-</cell></row><row><cell>grb-flickr</cell><cell>FGSM</cell><cell>0.01</cell><cell>2000</cell><cell>200/200/200/600</cell><cell>100</cell><cell>[-0.47, 0.99]</cell><cell>-</cell></row><row><cell></cell><cell>SPEIT</cell><cell>0.01</cell><cell>2000</cell><cell></cell><cell></cell><cell></cell><cell>-</cell></row><row><cell></cell><cell>TDGIA</cell><cell>0.01</cell><cell>2000</cell><cell></cell><cell></cell><cell></cell><cell>Sequential</cell></row><row><cell></cell><cell>RND</cell><cell>-</cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell>Random features</cell></row><row><cell></cell><cell>PGD</cell><cell>0.01</cell><cell>2000</cell><cell></cell><cell></cell><cell></cell><cell>-</cell></row><row><cell>grb-reddit</cell><cell>FGSM</cell><cell>0.01</cell><cell>2000</cell><cell>500/500/500/1500</cell><cell>200</cell><cell>[-0.98, 0.99]</cell><cell>-</cell></row><row><cell></cell><cell>SPEIT</cell><cell>0.01</cell><cell>2000</cell><cell></cell><cell></cell><cell></cell><cell>-</cell></row><row><cell></cell><cell>TDGIA</cell><cell>0.01</cell><cell>2000</cell><cell></cell><cell></cell><cell></cell><cell>Sequential</cell></row><row><cell></cell><cell>RND</cell><cell>-</cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell>Random features</cell></row><row><cell></cell><cell>PGD</cell><cell>0.01</cell><cell>5000</cell><cell></cell><cell></cell><cell></cell><cell>-</cell></row><row><cell>grb-aminer</cell><cell>FGSM</cell><cell>0.01</cell><cell>5000</cell><cell>500/500/500/1500</cell><cell>100</cell><cell>[-0.93, 0.93]</cell><cell>-</cell></row><row><cell></cell><cell>SPEIT</cell><cell>0.01</cell><cell>5000</cell><cell></cell><cell></cell><cell></cell><cell>-</cell></row><row><cell></cell><cell>TDGIA</cell><cell>0.01</cell><cell>5000</cell><cell></cell><cell></cell><cell></cell><cell>Sequential</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 13 :</head><label>13</label><figDesc>GRB leaderboard (Top 5 Attacks vs. Top 10 Defenses) for grb-cora dataset.</figDesc><table><row><cell></cell><cell cols="2">Defenses</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>Avg.</cell><cell>Avg. 3-Max</cell><cell>Weighted</cell></row><row><cell cols="2">Attack</cell><cell></cell><cell>R-GCN+AT</cell><cell>GAT+AT</cell><cell>SGCN+LN</cell><cell cols="2">R-GCN TAGCN+LN</cell><cell>GIN+LN</cell><cell>APPNP+LN</cell><cell>GIN+AT</cell><cell cols="2">GATGuard GCN+LN</cell><cell>Accuracy</cell><cell>Accuracy</cell><cell>Accuracy</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="4">79.97±1.56 80.97±1.23 66.16±1.96 74.62±2.80</cell><cell>63.28±1.76</cell><cell cols="3">55.60±2.13 71.57±0.86 54.48±1.76</cell><cell>64.93±0.00</cell><cell cols="2">48.06±2.38 52.01±0.09</cell><cell>53.48±0.25</cell><cell>53.44±0.17</cell></row><row><cell>1</cell><cell>SPEIT</cell><cell cols="5">M 84.11±0.38 84.55±0.44 80.60±1.18 81.16±1.39 H 88.51±0.80 89.78±1.00 89.74±0.71 88.47±0.54</cell><cell>74.59±1.86 89.85±0.55</cell><cell cols="3">64.10±1.05 75.67±1.12 63.36±1.39 80.37±1.10 80.64±1.14 63.51±3.22</cell><cell>63.06±0.00 69.03±0.00</cell><cell cols="2">69.18±2.24 47.31±0.09 88.55±1.32 42.72±0.07</cell><cell>50.35±1.25 47.34±2.27</cell><cell>50.89±0.24 48.44±0.12</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell cols="4">85.21±0.41 85.35±0.19 75.65±0.87 79.85±0.48</cell><cell>71.73±1.14</cell><cell cols="3">64.75±0.62 73.11±0.76 63.05±1.37</cell><cell>65.67±0.00</cell><cell cols="2">59.45±0.64 45.86±0.05</cell><cell>48.56±0.98</cell><cell>48.95±0.12</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="4">81.68±1.81 80.52±0.72 72.05±3.19 68.13±3.50</cell><cell>73.36±3.86</cell><cell cols="3">68.77±2.56 64.18±1.71 63.02±3.37</cell><cell>64.93±0.00</cell><cell cols="2">65.93±4.07 50.12±0.14</cell><cell>53.22±1.01</cell><cell>53.30±0.12</cell></row><row><cell>2</cell><cell>TDGIA</cell><cell cols="5">M 83.96±0.53 84.25±0.40 81.49±0.71 77.57±1.86 H 88.21±0.18 90.30±0.00 88.92±0.80 86.83±0.85</cell><cell>82.17±3.29 87.39±1.81</cell><cell cols="3">73.58±2.81 74.44±1.52 70.19±1.84 84.52±1.28 78.58±1.30 80.63±3.06</cell><cell>63.06±0.00 69.03±0.00</cell><cell cols="2">76.34±2.16 47.21±0.06 86.64±1.63 45.17±0.07</cell><cell>51.58±0.22 48.53±1.14</cell><cell>51.06±0.10 48.68±0.06</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell cols="4">84.43±0.27 84.55±0.50 77.39±1.05 74.58±1.76</cell><cell>79.67±1.53</cell><cell cols="3">76.14±1.80 68.16±2.10 70.51±1.58</cell><cell>65.67±0.00</cell><cell cols="2">72.58±2.71 46.24±0.04</cell><cell>49.75±0.84</cell><cell>49.73±0.09</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="4">83.02±1.26 80.60±1.04 73.88±2.41 67.80±2.24</cell><cell>74.78±2.36</cell><cell cols="3">70.07±1.79 66.19±1.50 62.65±1.33</cell><cell>64.93±0.00</cell><cell cols="2">68.58±3.00 50.11±0.11</cell><cell>53.19±0.98</cell><cell>53.29±0.14</cell></row><row><cell>3</cell><cell>PGD</cell><cell cols="5">M 83.84±1.15 84.81±0.67 82.20±1.18 78.51±1.57 H 88.88±0.50 90.48±0.67 89.96±0.75 85.86±0.83</cell><cell>83.36±1.39 89.48±1.07</cell><cell cols="3">77.35±1.02 73.21±1.83 69.25±2.18 85.97±0.82 78.47±1.29 80.82±0.89</cell><cell>63.06±0.00 69.03±0.00</cell><cell cols="2">77.80±1.26 47.24±0.08 88.32±0.56 45.18±0.05</cell><cell>51.64±0.20 48.50±1.14</cell><cell>51.11±0.09 48.68±0.06</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell cols="4">85.60±0.38 85.43±0.34 81.90±0.90 76.77±0.74</cell><cell>83.22±0.60</cell><cell cols="3">78.58±0.51 66.49±0.68 71.30±0.94</cell><cell>65.67±0.00</cell><cell cols="2">78.21±0.68 46.26±0.04</cell><cell>49.81±0.89</cell><cell>49.83±0.08</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="4">82.35±0.95 80.19±0.97 73.95±2.46 67.01±1.40</cell><cell>74.03±1.72</cell><cell cols="3">70.48±1.60 64.67±1.71 62.46±2.30</cell><cell>64.93±0.00</cell><cell cols="2">68.39±1.27 52.72±0.03</cell><cell>54.71±0.33</cell><cell>54.71±0.07</cell></row><row><cell>4</cell><cell>FGSM</cell><cell cols="5">M 84.25±1.24 85.11±0.64 82.46±0.93 77.87±1.43 H 89.22±0.59 90.59±0.40 90.30±0.50 86.23±1.16</cell><cell>84.29±1.02 89.55±0.67</cell><cell cols="3">78.77±1.09 73.10±1.13 69.74±1.60 86.08±0.78 78.80±1.45 80.93±0.91</cell><cell>63.06±0.00 69.03±0.00</cell><cell cols="2">78.47±1.30 48.71±0.16 87.13±0.96 43.58±0.08</cell><cell>51.81±0.67 48.20±1.74</cell><cell>51.93±0.09 48.84±0.08</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell cols="4">85.01±0.41 85.33±0.72 81.53±1.27 76.62±0.90</cell><cell>83.00±0.61</cell><cell cols="3">78.26±0.88 67.09±1.18 71.64±0.78</cell><cell>65.67±0.00</cell><cell cols="2">77.60±1.14 48.26±0.03</cell><cell>51.45±0.77</cell><cell>51.61±0.06</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="4">82.28±0.93 80.26±1.24 76.57±2.44 73.54±1.44</cell><cell>78.36±1.74</cell><cell cols="3">68.81±0.82 67.95±1.68 67.69±1.05</cell><cell>64.93±0.00</cell><cell cols="2">74.29±1.86 52.31±0.06</cell><cell>53.65±0.24</cell><cell>53.65±0.14</cell></row><row><cell>5</cell><cell>RND</cell><cell cols="5">M 84.18±1.00 84.44±0.88 82.05±0.72 79.33±1.24 H 88.99±0.51 90.71±0.31 90.19±0.41 87.20±0.75</cell><cell>84.11±0.34 90.04±0.24</cell><cell cols="3">76.68±1.05 73.88±1.64 72.72±1.68 84.52±0.73 80.03±1.11 82.87±0.83</cell><cell>63.06±0.00 69.03±0.00</cell><cell cols="2">80.11±1.08 48.89±0.05 89.29±0.75 44.74±0.07</cell><cell>51.70±0.32 49.19±0.26</cell><cell>51.57±0.11 48.77±0.18</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell cols="4">85.36±0.41 84.95±0.58 82.85±1.29 79.53±0.74</cell><cell>84.22±0.58</cell><cell cols="3">76.75±0.89 68.93±0.92 74.11±0.71</cell><cell>65.67±0.00</cell><cell cols="2">81.34±0.60 48.32±0.04</cell><cell>50.98±0.17</cell><cell>50.74±0.07</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="4">84.70±0.00 81.34±0.00 81.72±0.00 82.09±0.00</cell><cell>79.10±0.00</cell><cell cols="3">70.15±0.00 77.99±0.00 68.28±0.00</cell><cell>64.93±0.00</cell><cell cols="2">79.10±0.00 52.04±0.01</cell><cell>53.70±0.88</cell><cell>54.15±0.08</cell></row><row><cell cols="2">6 W/O Attack</cell><cell cols="5">M 83.96±0.00 84.33±0.00 82.84±0.00 83.21±0.00 H 89.55±0.00 91.04±0.00 91.04±0.00 89.18±0.00</cell><cell>85.45±0.00 90.67±0.00</cell><cell cols="3">76.87±0.00 82.46±0.00 73.51±0.00 84.70±0.00 88.06±0.00 82.84±0.00</cell><cell>63.06±0.00 69.03±0.00</cell><cell cols="2">81.72±0.00 49.67±0.01 89.93±0.00 45.94±0.01</cell><cell>52.67±0.50 50.01±0.56</cell><cell>52.65±0.09 49.99±0.00</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell cols="4">86.07±0.00 85.57±0.00 85.20±0.00 84.83±0.00</cell><cell>85.07±0.00</cell><cell cols="3">77.24±0.00 82.84±0.00 74.88±0.00</cell><cell>65.67±0.00</cell><cell cols="2">83.58±0.00 49.21±0.01</cell><cell>51.82±0.33</cell><cell>51.77±0.04</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="4">82.33±0.40 80.65±0.54 74.05±1.05 72.20±1.01</cell><cell>73.82±0.78</cell><cell cols="3">67.31±0.56 68.76±0.54 63.10±0.38</cell><cell>64.93±0.00</cell><cell>67.39±0.84</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Avg.</cell><cell cols="5">M 84.05±0.34 84.58±0.21 81.94±0.30 79.61±0.60</cell><cell>82.33±0.49</cell><cell cols="3">74.56±0.45 75.46±0.50 69.80±0.92</cell><cell>63.06±0.00</cell><cell>77.27±0.49</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Accuracy</cell><cell>H</cell><cell cols="4">88.89±0.21 90.49±0.18 90.02±0.27 87.29±0.33</cell><cell>89.50±0.41</cell><cell cols="3">84.36±0.36 80.77±0.23 78.60±0.96</cell><cell>69.03±0.00</cell><cell>88.31±0.38</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell cols="4">85.28±0.15 85.20±0.21 80.75±0.41 78.69±0.27</cell><cell>81.15±0.42</cell><cell cols="3">75.29±0.49 71.10±0.40 70.91±0.43</cell><cell>65.67±0.00</cell><cell>75.46±0.49</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="4">80.93±0.61 79.91±0.61 70.14±1.74 67.61±1.32</cell><cell>69.58±1.09</cell><cell cols="3">63.92±0.83 64.89±0.88 59.17±0.66</cell><cell>64.93±0.00</cell><cell>60.34±1.48</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Avg. 3-Min</cell><cell cols="5">M 83.46±0.31 84.14±0.22 81.07±0.36 77.74±0.93</cell><cell>79.90±0.82</cell><cell cols="3">71.29±1.07 73.07±0.83 67.10±1.28</cell><cell>63.06±0.00</cell><cell>74.28±0.90</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Accuracy</cell><cell>H</cell><cell cols="4">88.36±0.28 90.06±0.34 89.39±0.37 86.17±0.53</cell><cell>88.58±0.80</cell><cell cols="3">82.97±0.42 78.41±0.38 74.66±1.77</cell><cell>69.03±0.00</cell><cell>87.16±0.61</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell cols="4">84.79±0.23 84.77±0.34 78.01±0.50 75.99±0.42</cell><cell>78.07±0.78</cell><cell cols="3">72.46±0.81 67.10±0.76 68.12±0.65</cell><cell>65.67±0.00</cell><cell>69.83±0.88</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="4">80.19±0.86 79.62±0.61 68.40±1.64 66.85±1.66</cell><cell>66.67±1.12</cell><cell cols="3">59.85±1.37 64.50±0.99 57.05±1.00</cell><cell>64.93±0.00</cell><cell>54.51±1.73</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Weighted</cell><cell cols="5">M 83.27±0.41 84.00±0.30 80.70±0.44 77.37±1.24</cell><cell>77.02±1.13</cell><cell cols="3">67.76±0.85 72.63±1.04 65.40±1.27</cell><cell>63.06±0.00</cell><cell>71.83±1.38</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Accuracy</cell><cell>H</cell><cell cols="4">88.22±0.31 89.80±0.60 89.15±0.49 85.91±0.56</cell><cell>88.05±1.28</cell><cell cols="3">81.70±0.69 78.00±0.67 69.13±2.45</cell><cell>69.03±0.00</cell><cell>86.71±0.94</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell cols="4">84.65±0.23 84.62±0.33 76.86±0.58 75.45±0.96</cell><cell>74.96±0.91</cell><cell cols="3">68.64±0.68 66.79±0.98 65.73±0.89</cell><cell>65.67±0.00</cell><cell>64.82±0.60</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 14 :</head><label>14</label><figDesc>grb-citeseer leaderboard (Top 5 ATK. vs. Top 10 DEF.) in graph injection scenario.</figDesc><table><row><cell></cell><cell cols="2">Defenses</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>Avg.</cell><cell>Avg. 3-Max</cell><cell>Weighted</cell></row><row><cell cols="2">Attack</cell><cell></cell><cell>GAT+AT</cell><cell cols="5">R-GCN+AT SAGEAT GATGuard GCNGuard SGCN+LN</cell><cell>R-GCN</cell><cell>GIN+LN</cell><cell>TAGCN+LN</cell><cell>GIN+AT</cell><cell>Accuracy</cell><cell>Accuracy</cell><cell>Accuracy</cell></row><row><cell></cell><cell></cell><cell cols="4">E 70.88±0.83 67.49±1.01 68.68±1.64</cell><cell>65.52±0.00</cell><cell>56.43±0.00</cell><cell cols="3">49.78±2.57 52.29±2.76 48.53±1.60</cell><cell>44.89±4.98</cell><cell cols="2">47.30±8.94 52.01±0.09</cell><cell>53.48±0.25</cell><cell>53.44±0.17</cell></row><row><cell>1</cell><cell>SPEIT</cell><cell cols="4">M 72.16±0.44 71.00±1.12 70.81±1.79 H 78.18±0.49 79.69±0.37 77.46±0.67</cell><cell>63.64±0.00 72.10±0.00</cell><cell>62.70±0.00 74.64±0.09</cell><cell cols="3">55.05±1.74 61.63±3.24 49.78±2.12 66.87±1.73 77.08±1.91 56.86±1.31</cell><cell>52.66±4.65 69.03±4.80</cell><cell cols="2">47.34±9.06 47.31±0.09 51.10±6.38 42.72±0.07</cell><cell>50.35±1.25 47.34±2.27</cell><cell>50.89±0.24 48.44±0.12</cell></row><row><cell></cell><cell></cell><cell cols="4">F 73.85±0.22 71.30±0.64 71.62±1.39</cell><cell>67.08±0.00</cell><cell>64.54±0.13</cell><cell cols="3">53.64±1.43 59.32±3.65 52.82±0.93</cell><cell>51.09±6.38</cell><cell cols="2">44.71±9.62 45.86±0.05</cell><cell>48.56±0.98</cell><cell>48.95±0.12</cell></row><row><cell></cell><cell></cell><cell cols="4">E 71.00±0.67 66.68±1.30 68.18±1.33</cell><cell>65.52±0.00</cell><cell>56.43±0.00</cell><cell cols="3">57.15±1.87 48.81±3.56 53.92±2.98</cell><cell>47.27±2.58</cell><cell cols="2">51.95±10.85 50.12±0.14</cell><cell>53.22±1.01</cell><cell>53.30±0.12</cell></row><row><cell>2</cell><cell>TDGIA</cell><cell cols="4">M 72.54±0.47 71.76±1.21 71.13±1.10 H 78.28±0.37 79.72±0.49 77.27±0.87</cell><cell>63.64±0.00 72.10±0.00</cell><cell>62.70±0.00 74.61±0.00</cell><cell cols="3">60.91±0.95 60.97±2.82 49.22±3.91 70.50±1.89 73.92±1.91 57.80±4.13</cell><cell>49.09±6.61 65.61±3.54</cell><cell cols="2">51.69±7.68 47.21±0.06 66.08±6.43 45.17±0.07</cell><cell>51.58±0.22 48.53±1.14</cell><cell>51.06±0.10 48.68±0.06</cell></row><row><cell></cell><cell></cell><cell cols="4">F 73.89±0.40 71.75±0.78 72.25±0.62</cell><cell>67.08±0.00</cell><cell>64.58±0.00</cell><cell cols="3">59.76±2.10 56.69±1.77 52.16±2.47</cell><cell>46.87±4.99</cell><cell cols="2">59.01±5.47 46.24±0.04</cell><cell>49.75±0.84</cell><cell>49.73±0.09</cell></row><row><cell></cell><cell></cell><cell cols="4">E 71.44±1.03 69.00±0.75 69.28±0.73</cell><cell>65.52±0.00</cell><cell>56.46±0.17</cell><cell cols="3">52.38±1.56 49.87±2.20 52.38±2.41</cell><cell>50.88±4.01</cell><cell cols="2">56.61±2.45 50.11±0.11</cell><cell>53.19±0.98</cell><cell>53.29±0.14</cell></row><row><cell>3</cell><cell>FGSM</cell><cell cols="4">M 72.47±0.48 73.23±0.51 71.25±0.67 H 78.40±0.38 79.94±0.31 77.24±0.96</cell><cell>63.64±0.00 72.10±0.00</cell><cell>62.67±0.10 74.36±0.75</cell><cell cols="3">60.22±1.19 58.53±1.76 57.43±1.53 71.03±1.09 71.94±1.26 70.72±1.29</cell><cell>61.76±2.49 77.90±1.40</cell><cell cols="2">61.85±1.49 47.24±0.08 71.66±2.18 45.18±0.05</cell><cell>51.64±0.20 48.50±1.14</cell><cell>51.11±0.09 48.68±0.06</cell></row><row><cell></cell><cell></cell><cell cols="4">F 73.86±0.28 73.63±0.50 72.40±0.60</cell><cell>67.08±0.00</cell><cell>64.56±0.04</cell><cell cols="3">58.05±0.88 55.07±1.43 61.36±1.03</cell><cell>63.39±1.21</cell><cell cols="2">62.54±0.81 46.26±0.04</cell><cell>49.81±0.89</cell><cell>49.83±0.08</cell></row><row><cell></cell><cell></cell><cell cols="4">E 71.22±0.75 69.19±0.66 69.06±0.79</cell><cell>65.52±0.00</cell><cell>56.40±0.10</cell><cell cols="3">53.39±1.94 47.77±1.29 54.70±1.99</cell><cell>51.16±2.93</cell><cell cols="2">58.02±2.31 52.72±0.03</cell><cell>54.71±0.33</cell><cell>54.71±0.07</cell></row><row><cell>4</cell><cell>PGD</cell><cell cols="4">M 72.60±0.67 72.91±0.61 70.91±0.64 H 78.18±0.40 79.94±0.34 77.53±0.93</cell><cell>63.64±0.00 72.10±0.00</cell><cell>62.70±0.00 74.61±0.00</cell><cell cols="3">60.34±1.00 57.77±1.58 58.78±1.70 70.69±1.56 71.79±1.67 71.57±1.84</cell><cell>62.10±1.96 78.21±0.97</cell><cell cols="2">60.75±3.33 48.71±0.16 71.41±1.80 43.58±0.08</cell><cell>51.81±0.67 48.20±1.74</cell><cell>51.93±0.09 48.84±0.08</cell></row><row><cell></cell><cell></cell><cell cols="4">F 73.84±0.26 73.58±0.36 72.38±0.54</cell><cell>67.08±0.00</cell><cell>64.46±0.16</cell><cell cols="3">58.31±0.62 54.90±1.58 61.60±0.95</cell><cell>64.25±1.48</cell><cell cols="2">63.21±1.19 48.26±0.03</cell><cell>51.45±0.77</cell><cell>51.61±0.06</cell></row><row><cell></cell><cell></cell><cell cols="4">E 71.07±0.47 67.56±1.04 68.34±0.54</cell><cell>65.52±0.00</cell><cell>56.34±0.28</cell><cell cols="3">54.64±2.04 51.94±1.64 60.88±1.22</cell><cell>69.06±1.48</cell><cell cols="2">60.66±1.42 52.31±0.06</cell><cell>53.65±0.24</cell><cell>53.65±0.14</cell></row><row><cell>5</cell><cell>RND</cell><cell cols="4">M 72.48±0.34 71.82±0.41 71.13±0.57 H 78.37±0.44 79.84±0.42 77.93±0.72</cell><cell>63.64±0.00 72.10±0.00</cell><cell>62.73±0.09 74.58±0.22</cell><cell cols="3">57.21±1.82 61.38±1.08 63.10±1.93 68.18±1.85 75.24±1.81 72.41±1.34</cell><cell>70.53±1.23 78.37±0.87</cell><cell cols="2">62.79±1.02 48.89±0.05 72.41±0.40 44.74±0.07</cell><cell>51.70±0.32 49.19±0.26</cell><cell>51.57±0.11 48.77±0.18</cell></row><row><cell></cell><cell></cell><cell cols="4">F 74.00±0.45 72.95±0.68 72.70±0.47</cell><cell>67.08±0.00</cell><cell>64.55±0.16</cell><cell cols="3">55.79±0.95 60.43±0.71 65.66±0.43</cell><cell>73.06±0.58</cell><cell cols="2">65.24±0.51 48.32±0.04</cell><cell>50.98±0.17</cell><cell>50.74±0.07</cell></row><row><cell></cell><cell></cell><cell cols="4">E 70.22±0.00 71.16±0.00 70.22±0.00</cell><cell>65.52±0.00</cell><cell>56.43±0.00</cell><cell cols="3">71.16±0.00 68.75±0.15 63.95±0.00</cell><cell>69.59±0.00</cell><cell cols="2">64.26±0.00 52.04±0.01</cell><cell>53.70±0.88</cell><cell>54.15±0.08</cell></row><row><cell cols="2">6 W/O Attack</cell><cell cols="4">M 73.04±0.00 73.04±0.00 71.79±0.00 H 78.37±0.00 80.88±0.00 78.06±0.00</cell><cell>63.64±0.00 72.10±0.00</cell><cell>62.70±0.00 74.61±0.00</cell><cell cols="3">75.55±0.00 70.16±0.19 64.58±0.00 79.62±0.00 80.41±0.16 69.59±0.00</cell><cell>73.67±0.00 77.43±0.00</cell><cell cols="2">65.20±0.00 49.67±0.01 73.98±0.00 45.94±0.01</cell><cell>52.67±0.50 50.01±0.56</cell><cell>52.65±0.09 49.99±0.00</cell></row><row><cell></cell><cell></cell><cell cols="4">F 73.88±0.00 75.03±0.00 73.35±0.00</cell><cell>67.08±0.00</cell><cell>64.58±0.00</cell><cell cols="3">75.44±0.00 73.16±0.09 66.04±0.00</cell><cell>73.56±0.00</cell><cell cols="2">67.82±0.00 49.21±0.01</cell><cell>51.82±0.33</cell><cell>51.77±0.04</cell></row><row><cell></cell><cell></cell><cell cols="4">E 70.97±0.26 68.51±0.41 68.96±0.47</cell><cell>65.52±0.00</cell><cell>56.41±0.06</cell><cell cols="3">56.42±0.53 53.24±0.73 55.73±0.42</cell><cell>55.48±1.32</cell><cell>56.47±2.73</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Avg.</cell><cell cols="4">M 72.55±0.21 72.29±0.26 71.17±0.34</cell><cell>63.64±0.00</cell><cell>62.70±0.02</cell><cell cols="3">61.55±0.65 61.74±0.93 57.15±1.00</cell><cell>61.64±1.06</cell><cell>58.27±1.47</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Accuracy</cell><cell cols="4">H 78.30±0.17 80.00±0.13 77.58±0.29</cell><cell>72.10±0.00</cell><cell>74.57±0.13</cell><cell cols="3">71.15±0.50 75.06±0.71 66.49±0.67</cell><cell>74.42±1.31</cell><cell>67.78±1.47</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell cols="4">F 73.89±0.11 73.04±0.17 72.45±0.17</cell><cell>67.08±0.00</cell><cell>64.54±0.04</cell><cell cols="3">60.16±0.55 59.93±0.57 59.94±0.63</cell><cell>62.04±1.70</cell><cell>60.42±1.30</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell cols="4">E 70.37±0.29 67.19±0.80 68.08±0.64</cell><cell>65.52±0.00</cell><cell>56.38±0.10</cell><cell cols="3">51.58±0.94 48.25±0.95 51.09±0.74</cell><cell>47.07±1.85</cell><cell>51.32±4.97</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Avg. 3-Min</cell><cell cols="4">M 72.17±0.26 71.44±0.37 70.50±0.56</cell><cell>63.64±0.00</cell><cell>62.69±0.03</cell><cell cols="3">57.22±1.16 58.43±1.16 51.98±1.52</cell><cell>54.06±2.00</cell><cell>52.96±3.03</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Accuracy</cell><cell cols="4">H 78.05±0.20 79.59±0.21 77.00±0.40</cell><cell>72.10±0.00</cell><cell>74.51±0.25</cell><cell cols="3">68.16±0.90 72.31±0.96 61.27±1.55</cell><cell>70.49±2.41</cell><cell>62.42±2.81</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell cols="4">F 73.68±0.12 71.94±0.36 71.86±0.30</cell><cell>67.08±0.00</cell><cell>64.49±0.08</cell><cell cols="3">55.61±0.58 55.19±0.62 55.26±1.07</cell><cell>53.69±3.32</cell><cell>55.31±2.84</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell cols="4">E 70.26±0.29 66.91±0.80 67.73±0.82</cell><cell>65.52±0.00</cell><cell>56.33±0.19</cell><cell cols="3">50.83±1.23 47.83±1.09 49.98±0.93</cell><cell>46.26±2.89</cell><cell>47.56±6.43</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Weighted</cell><cell cols="4">M 72.04±0.27 71.03±0.58 70.09±0.74</cell><cell>63.64±0.00</cell><cell>62.68±0.06</cell><cell cols="3">56.51±1.39 57.80±1.03 50.29±2.25</cell><cell>51.08±3.58</cell><cell>48.58±5.29</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Accuracy</cell><cell cols="4">H 77.94±0.22 79.53±0.22 76.79±0.41</cell><cell>72.10±0.00</cell><cell>74.40±0.51</cell><cell cols="3">67.47±1.09 71.97±1.10 58.78±1.41</cell><cell>67.53±2.85</cell><cell>56.76±4.16</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell cols="4">F 73.64±0.15 71.59±0.34 71.48±0.66</cell><cell>67.08±0.00</cell><cell>64.44±0.12</cell><cell cols="3">55.05±1.00 54.95±0.76 53.66±1.23</cell><cell>49.94±3.72</cell><cell>49.84±6.03</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 15 :</head><label>15</label><figDesc>grb-flickr leaderboard (Top 5 ATK. vs. Top 10 DEF.) in graph injection scenario. 35±0.18 49.95±0.18 47.16±0.07 46.44±0.10 49.10±0.14 45.06±0.09 46.70±0.28 43.48±0.04 44.73±0.21 42.99±0.01 ---H 45.15±0.10 47.43±0.37 42.37±0.06 45.30±0.07 45.55±0.13 43.66±0.07 45.92±0.18 37.78±0.04 39.72±0.13 34.47±0.01 ---F 47.91±0.09 47.81±0.08 47.25±0.05 46.57±0.06 45.13±0.05 43.99±0.09 43.98±0.18 43.91±0.03 43.88±0.10 42.46±0.01 ---</figDesc><table><row><cell></cell><cell cols="2">Defenses</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>Avg.</cell><cell>Avg. 3-Max</cell><cell>Weighted</cell></row><row><cell cols="2">Attack</cell><cell></cell><cell>R-GCN+AT</cell><cell>GAT+LN</cell><cell>SAGE+LN</cell><cell>GINLN</cell><cell>GCN+AT</cell><cell>SAGE+AT</cell><cell>GAT</cell><cell>GIN+AT</cell><cell>SAGE</cell><cell>APPNP+LN</cell><cell>Accuracy</cell><cell>Accuracy</cell><cell>Accuracy</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="10">53.41±0.12 53.36±0.22 51.43±0.15 50.96±0.29 52.89±0.22 52.87±0.13 53.62±0.36 50.15±0.14 51.65±0.45 49.78±0.03</cell><cell>52.01±0.09</cell><cell>53.48±0.25</cell><cell>53.44±0.17</cell></row><row><cell>1</cell><cell>SPEIT</cell><cell cols="11">M 49.79±0.26 49.21±0.26 47.83±0.09 46.19±0.14 48.05±0.24 48.91±0.12 52.04±0.33 43.62±0.10 44.54±0.12 42.94±0.03 H 44.72±0.15 46.78±0.54 43.41±0.12 44.79±0.09 44.83±0.14 43.51±0.15 50.32±0.20 37.33±0.12 37.17±0.17 34.33±0.02</cell><cell>47.31±0.09 42.72±0.07</cell><cell>50.35±1.25 47.34±2.27</cell><cell>50.89±0.24 48.44±0.12</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell cols="10">47.14±0.13 46.39±0.13 47.62±0.04 46.18±0.09 43.52±0.07 48.17±0.14 49.91±0.17 43.73±0.05 43.66±0.07 42.30±0.01</cell><cell>45.86±0.05</cell><cell>48.56±0.98</cell><cell>48.95±0.12</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="10">53.99±0.13 51.87±0.49 50.89±0.15 48.24±0.15 53.79±0.17 44.06±0.23 48.23±0.56 50.08±0.16 49.99±0.33 50.07±0.05</cell><cell>50.12±0.14</cell><cell>53.22±1.01</cell><cell>53.30±0.12</cell></row><row><cell>2</cell><cell>FGSM</cell><cell cols="11">M 51.79±0.13 51.42±0.20 47.89±0.13 46.43±0.14 51.54±0.13 44.24±0.17 46.17±0.41 44.81±0.14 44.24±0.22 43.59±0.06 H 46.87±0.17 49.32±0.09 43.69±0.11 46.76±0.16 49.35±0.08 46.46±0.22 45.24±0.29 42.58±0.30 45.90±0.16 35.56±0.08</cell><cell>47.21±0.06 45.17±0.07</cell><cell>51.58±0.22 48.53±1.14</cell><cell>51.06±0.10 48.68±0.06</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell cols="10">50.20±0.08 50.47±0.15 47.58±0.08 46.94±0.07 48.58±0.09 43.10±0.14 42.78±0.27 45.28±0.10 43.33±0.19 44.16±0.09</cell><cell>46.24±0.04</cell><cell>49.75±0.84</cell><cell>49.73±0.09</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="10">54.02±0.18 51.88±0.40 50.77±0.19 48.36±0.19 53.68±0.18 43.95±0.24 48.33±0.71 50.04±0.15 49.95±0.42 50.05±0.07</cell><cell>50.11±0.11</cell><cell>53.19±0.98</cell><cell>53.29±0.14</cell></row><row><cell>3</cell><cell>PGD</cell><cell cols="11">M 51.74±0.22 51.65±0.21 47.77±0.16 46.69±0.23 51.53±0.10 44.26±0.17 45.91±0.40 44.95±0.27 44.38±0.43 43.56±0.10 H 46.81±0.13 49.28±0.13 43.75±0.17 46.75±0.22 49.32±0.14 46.45±0.18 45.24±0.26 42.47±0.27 46.17±0.19 35.55±0.08</cell><cell>47.24±0.08 45.18±0.05</cell><cell>51.64±0.20 48.50±1.14</cell><cell>51.11±0.09 48.68±0.06</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell cols="10">50.22±0.11 50.62±0.12 47.56±0.07 46.94±0.10 48.58±0.09 43.09±0.15 42.90±0.24 45.24±0.10 43.32±0.14 44.14±0.07</cell><cell>46.26±0.04</cell><cell>49.81±0.89</cell><cell>49.83±0.08</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="10">55.13±0.08 54.17±0.17 51.83±0.08 52.29±0.06 54.35±0.07 53.61±0.05 54.66±0.12 49.95±0.02 51.50±0.12 49.72±0.01</cell><cell>52.72±0.03</cell><cell>54.71±0.33</cell><cell>54.71±0.07</cell></row><row><cell>4</cell><cell>TDGIA</cell><cell cols="11">M 51.45±0.12 51.30±0.44 46.86±0.08 48.54±0.17 50.86±0.31 50.03±0.16 52.67±0.24 43.20±0.07 49.31±1.04 42.88±0.00 H 45.26±0.10 48.19±0.17 42.04±0.09 46.09±0.07 44.97±0.30 43.16±0.09 50.33±0.13 37.33±0.05 44.04±0.08 34.41±0.01</cell><cell>48.71±0.16 43.58±0.08</cell><cell>51.81±0.67 48.20±1.74</cell><cell>51.93±0.09 48.84±0.08</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell cols="10">48.97±0.05 51.25±0.07 47.13±0.07 49.05±0.05 47.54±0.06 49.52±0.05 52.46±0.09 43.77±0.01 50.63±0.08 42.30±0.00</cell><cell>48.26±0.03</cell><cell>51.45±0.77</cell><cell>51.61±0.06</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="10">53.90±0.20 53.31±0.18 51.73±0.14 51.16±0.15 53.62±0.10 53.19±0.12 52.77±0.22 50.36±0.08 53.25±0.23 49.83±0.03</cell><cell>52.31±0.06</cell><cell>53.65±0.24</cell><cell>53.65±0.14</cell></row><row><cell>5</cell><cell>RND</cell><cell cols="11">M 51.22±0.15 52.01±0.15 47.82±0.12 48.21±0.15 51.78±0.14 49.84±0.19 51.06±0.30 44.11±0.03 49.85±0.18 43.04±0.06 H 46.38±0.15 49.33±0.18 42.90±0.13 46.79±0.14 48.95±0.12 45.03±0.15 49.29±0.25 39.10±0.09 45.13±0.28 34.50±0.03</cell><cell>48.89±0.05 44.74±0.07</cell><cell>51.70±0.32 49.19±0.26</cell><cell>51.57±0.11 48.77±0.18</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell cols="10">49.32±0.10 51.09±0.08 47.47±0.07 48.58±0.06 51.00±0.09 49.18±0.07 50.84±0.20 44.36±0.03 49.00±0.08 42.31±0.01</cell><cell>48.32±0.04</cell><cell>50.98±0.17</cell><cell>50.74±0.07</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="10">54.94±0.12 52.58±0.00 51.68±0.00 50.48±0.00 52.97±0.00 53.18±0.00 49.50±0.00 50.72±0.00 52.77±0.00 51.55±0.00</cell><cell>52.04±0.01</cell><cell>53.70±0.88</cell><cell>54.15±0.08</cell></row><row><cell cols="2">6 W/O Attack</cell><cell cols="11">M 53.23±0.13 52.75±0.00 47.83±0.00 48.03±0.00 52.03±0.00 51.27±0.00 50.06±0.00 44.87±0.00 51.63±0.00 45.01±0.00 H 48.70±0.08 49.65±0.00 42.90±0.00 46.43±0.00 49.59±0.00 47.10±0.00 50.80±0.00 40.10±0.00 47.96±0.00 36.12±0.00</cell><cell>49.67±0.01 45.94±0.01</cell><cell>52.67±0.50 50.01±0.56</cell><cell>52.65±0.09 49.99±0.00</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell cols="10">52.28±0.06 51.66±0.00 47.47±0.00 48.31±0.00 51.53±0.00 50.52±0.00 50.12±0.00 45.23±0.00 50.79±0.00 44.23±0.00</cell><cell>49.21±0.01</cell><cell>51.82±0.33</cell><cell>51.77±0.04</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="10">54.23±0.07 52.86±0.16 51.38±0.05 50.25±0.09 53.55±0.07 50.14±0.07 51.19±0.15 50.22±0.04 51.52±0.12 50.17±0.02</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Avg.</cell><cell cols="11">M 51.54±0.07 51.39±0.10 47.67±0.05 47.35±0.06 50.96±0.04 48.09±0.07 49.65±0.09 44.26±0.06 47.32±0.19 43.50±0.02</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Accuracy</cell><cell>H</cell><cell cols="10">46.46±0.05 48.76±0.11 43.12±0.05 46.27±0.04 47.84±0.08 45.29±0.04 48.54±0.08 39.82±0.06 44.40±0.10 35.08±0.02</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell cols="10">49.69±0.04 50.25±0.03 47.47±0.03 47.67±0.03 48.46±0.02 47.26±0.04 48.17±0.09 44.60±0.03 46.79±0.06 43.24±0.01</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="10">53.74±0.09 52.11±0.26 51.03±0.10 49.03±0.07 53.14±0.09 46.96±0.14 48.69±0.25 50.00±0.07 50.46±0.22 49.78±0.02</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Avg. 3-Min</cell><cell cols="11">M 50.81±0.10 50.62±0.17 47.44±0.07 46.44±0.11 50.13±0.09 45.81±0.09 47.38±0.19 43.65±0.04 44.38±0.21 42.95±0.02</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Accuracy</cell><cell>H</cell><cell cols="10">45.45±0.07 48.05±0.21 42.62±0.05 45.77±0.04 46.25±0.15 43.90±0.08 46.59±0.17 37.92±0.04 42.11±0.15 34.41±0.01</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>F</cell><cell cols="10">48.48±0.06 49.16±0.04 47.35±0.04 46.69±0.04 46.52±0.04 44.79±0.07 45.19±0.14 43.95±0.02 43.44±0.10 42.30±0.00</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>E</cell><cell cols="10">53.62±0.08 51.97±0.33 50.92±0.12 48.67±0.09 53.02±0.12 45.43±0.18 48.62±0.42 49.97±0.06 50.22±0.26 49.80±0.01</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Weighted</cell><cell cols="2">M 50.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Accuracy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 16 :</head><label>16</label><figDesc>grb-reddit leaderboard (Top 5 ATK. vs. Top 10 DEF.) in graph injection scenario.</figDesc><table><row><cell></cell><cell cols="2">Defenses</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>Avg.</cell><cell>Avg. 3-Max</cell><cell>Weighted</cell></row><row><cell cols="2">Attack</cell><cell></cell><cell>GIN+LN</cell><cell cols="2">TAGCN+LN TAGCN+AT</cell><cell>GAT+LN</cell><cell cols="2">R-GCN+AT TAGCN</cell><cell cols="2">GCN+LN SAGE+AT</cell><cell>SAGE</cell><cell>SGCN+LN</cell><cell>Accuracy</cell><cell>Accuracy</cell><cell>Accuracy</cell></row><row><cell></cell><cell></cell><cell cols="2">E 89.57±0.05</cell><cell>90.59±0.02</cell><cell>70.17±0.28</cell><cell cols="8">84.18±0.03 88.38±0.02 78.83±0.18 80.79±0.17 86.29±0.03 71.00±0.11 76.36±0.03 81.62±0.08</cell><cell>89.52±0.90</cell><cell>89.17±0.03</cell></row><row><cell>1</cell><cell>TDGIA</cell><cell cols="2">M 98.29±0.01 H 99.54±0.00</cell><cell>97.79±0.00 99.16±0.00</cell><cell>98.02±0.01 98.54±0.01</cell><cell cols="8">96.20±0.01 95.50±0.01 96.62±0.01 97.66±0.00 94.07±0.01 95.66±0.02 92.27±0.01 96.21±0.00 98.17±0.01 95.68±0.02 97.77±0.01 99.14±0.01 90.60±0.01 98.43±0.02 93.33±0.01 97.04±0.01</cell><cell>98.03±0.21 99.28±0.18</cell><cell>97.97±0.01 99.18±0.00</cell></row><row><cell></cell><cell></cell><cell cols="2">F 95.92±0.01</cell><cell>95.89±0.01</cell><cell>93.12±0.01</cell><cell cols="8">93.73±0.01 93.08±0.01 91.77±0.01 91.09±0.02 90.16±0.01 85.98±0.03 86.61±0.01 91.74±0.00</cell><cell>95.18±1.03</cell><cell>95.24±0.01</cell></row><row><cell></cell><cell></cell><cell cols="2">E 91.92±0.04</cell><cell>91.58±0.03</cell><cell>91.73±0.05</cell><cell cols="8">87.18±0.08 88.81±0.02 88.41±0.05 89.81±0.05 86.65±0.03 83.10±0.07 76.55±0.10 87.57±0.02</cell><cell>91.74±0.14</cell><cell>91.35±0.03</cell></row><row><cell>2</cell><cell>SPEIT</cell><cell cols="2">M 98.27±0.01 H 99.54±0.01</cell><cell>97.84±0.01 99.20±0.01</cell><cell>97.98±0.02 98.81±0.01</cell><cell cols="8">96.19±0.02 95.28±0.01 96.60±0.02 97.77±0.01 94.03±0.02 96.74±0.02 92.26±0.03 96.30±0.00 98.17±0.01 96.04±0.01 97.97±0.01 99.22±0.01 90.69±0.03 98.22±0.03 93.43±0.02 97.13±0.00</cell><cell>98.03±0.18 99.32±0.16</cell><cell>97.97±0.01 99.21±0.01</cell></row><row><cell></cell><cell></cell><cell cols="2">F 96.31±0.02</cell><cell>96.31±0.02</cell><cell>95.77±0.02</cell><cell cols="8">93.76±0.02 93.59±0.01 93.76±0.03 95.57±0.01 90.21±0.02 92.96±0.04 87.02±0.03 93.53±0.01</cell><cell>96.13±0.26</cell><cell>95.96±0.01</cell></row><row><cell></cell><cell></cell><cell cols="2">E 91.77±0.06</cell><cell>91.53±0.05</cell><cell>92.60±0.04</cell><cell cols="8">87.38±0.05 89.06±0.01 90.52±0.05 89.70±0.03 86.78±0.03 88.24±0.06 78.51±0.12 88.61±0.02</cell><cell>91.97±0.46</cell><cell>91.92±0.03</cell></row><row><cell>3</cell><cell>FGSM</cell><cell cols="2">M 98.26±0.01 H 99.55±0.01</cell><cell>97.74±0.01 99.02±0.01</cell><cell>98.13±0.01 99.16±0.01</cell><cell cols="8">96.18±0.01 95.47±0.01 96.94±0.03 97.68±0.01 94.01±0.02 96.52±0.04 92.65±0.01 96.36±0.01 98.17±0.02 95.94±0.01 98.32±0.01 99.08±0.01 91.01±0.02 98.48±0.02 93.65±0.02 97.24±0.00</cell><cell>98.04±0.22 99.27±0.21</cell><cell>97.99±0.01 99.23±0.01</cell></row><row><cell></cell><cell></cell><cell cols="2">F 96.48±0.01</cell><cell>95.90±0.01</cell><cell>96.74±0.01</cell><cell cols="8">93.91±0.01 93.57±0.01 95.24±0.02 95.22±0.01 90.54±0.02 93.78±0.03 89.01±0.03 94.04±0.01</cell><cell>96.37±0.35</cell><cell>96.32±0.01</cell></row><row><cell></cell><cell></cell><cell cols="2">E 92.04±0.04</cell><cell>91.75±0.04</cell><cell>92.60±0.03</cell><cell cols="8">87.09±0.04 88.87±0.03 89.55±0.05 90.00±0.04 86.71±0.03 88.12±0.09 77.27±0.10 88.40±0.02</cell><cell>92.13±0.36</cell><cell>91.94±0.02</cell></row><row><cell>4</cell><cell>RND</cell><cell cols="2">M 98.28±0.02 H 99.54±0.01</cell><cell>97.82±0.01 99.13±0.01</cell><cell>98.13±0.01 99.00±0.01</cell><cell cols="8">96.17±0.02 95.42±0.02 96.84±0.03 97.75±0.01 94.07±0.02 97.14±0.02 92.43±0.03 96.40±0.01 98.17±0.01 96.21±0.02 98.15±0.01 99.12±0.00 90.89±0.03 98.34±0.03 93.50±0.01 97.21±0.01</cell><cell>98.08±0.19 99.27±0.19</cell><cell>98.02±0.01 99.21±0.00</cell></row><row><cell></cell><cell></cell><cell cols="2">F 96.60±0.01</cell><cell>96.30±0.02</cell><cell>96.54±0.01</cell><cell cols="8">93.84±0.02 93.23±0.02 94.88±0.03 95.63±0.01 90.37±0.03 94.59±0.02 87.72±0.03 93.97±0.01</cell><cell>96.48±0.13</cell><cell>96.27±0.01</cell></row><row><cell></cell><cell></cell><cell cols="2">E 91.74±0.06</cell><cell>91.56±0.04</cell><cell>92.63±0.04</cell><cell cols="8">87.39±0.04 89.06±0.02 90.58±0.06 89.72±0.04 86.77±0.03 88.25±0.10 78.53±0.07 88.62±0.02</cell><cell>91.98±0.47</cell><cell>91.94±0.03</cell></row><row><cell>5</cell><cell>PGD</cell><cell cols="2">M 98.26±0.01 H 99.55±0.01</cell><cell>97.74±0.01 99.02±0.01</cell><cell>98.12±0.02 99.16±0.01</cell><cell cols="8">96.19±0.01 95.46±0.02 96.94±0.01 97.68±0.01 94.01±0.03 96.52±0.05 92.65±0.04 96.36±0.01 98.18±0.01 95.94±0.01 98.32±0.01 99.08±0.01 91.00±0.03 98.47±0.03 93.66±0.02 97.24±0.00</cell><cell>98.04±0.22 99.26±0.21</cell><cell>97.98±0.01 99.23±0.00</cell></row><row><cell></cell><cell></cell><cell cols="2">F 96.48±0.02</cell><cell>95.91±0.01</cell><cell>96.74±0.01</cell><cell cols="8">93.91±0.02 93.56±0.01 95.24±0.03 95.23±0.02 90.54±0.02 93.75±0.02 88.99±0.03 94.03±0.01</cell><cell>96.38±0.35</cell><cell>96.32±0.01</cell></row><row><cell></cell><cell></cell><cell cols="2">E 92.19±0.00</cell><cell>92.11±0.00</cell><cell>93.05±0.00</cell><cell cols="8">87.97±0.00 89.14±0.00 90.99±0.00 90.17±0.00 86.86±0.00 89.96±0.00 83.12±0.00 89.56±0.00</cell><cell>92.45±0.43</cell><cell>92.41±0.00</cell></row><row><cell cols="2">6 W/O Attack</cell><cell cols="2">M 98.30±0.00 H 99.55±0.00</cell><cell>97.82±0.00 99.16±0.00</cell><cell>98.23±0.00 99.03±0.00</cell><cell cols="8">96.27±0.00 95.75±0.00 97.07±0.00 97.74±0.00 93.86±0.00 97.21±0.00 93.48±0.00 96.57±0.00 98.20±0.00 96.46±0.00 98.12±0.00 99.12±0.00 90.72±0.00 98.30±0.00 93.84±0.00 97.25±0.00</cell><cell>98.12±0.21 99.28±0.19</cell><cell>98.06±0.00 99.23±0.00</cell></row><row><cell></cell><cell></cell><cell cols="2">F 96.68±0.00</cell><cell>96.37±0.00</cell><cell>96.77±0.00</cell><cell cols="8">94.15±0.00 93.78±0.00 95.39±0.00 95.68±0.00 90.48±0.00 95.16±0.00 90.15±0.00 94.46±0.00</cell><cell>96.61±0.17</cell><cell>96.46±0.00</cell></row><row><cell></cell><cell></cell><cell cols="2">E 91.53±0.01</cell><cell>91.52±0.02</cell><cell>88.80±0.05</cell><cell cols="7">86.87±0.02 88.89±0.01 88.15±0.03 88.37±0.04 86.68±0.01 84.78±0.03 78.39±0.03</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Avg.</cell><cell cols="2">M 98.28±0.00</cell><cell>97.79±0.01</cell><cell>98.10±0.01</cell><cell cols="7">96.20±0.01 95.48±0.01 96.84±0.01 97.71±0.00 94.01±0.01 96.63±0.01 92.62±0.01</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Accuracy</cell><cell cols="2">H 99.54±0.00</cell><cell>99.12±0.00</cell><cell>98.95±0.00</cell><cell cols="7">98.17±0.01 96.05±0.01 98.11±0.01 99.13±0.00 90.82±0.01 98.37±0.01 93.57±0.01</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell cols="2">F 96.41±0.01</cell><cell>96.11±0.01</cell><cell>95.95±0.01</cell><cell cols="7">93.88±0.01 93.47±0.01 94.38±0.01 94.74±0.01 90.38±0.01 92.70±0.01 88.25±0.01</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell cols="2">E 91.03±0.02</cell><cell>91.22±0.02</cell><cell>84.82±0.10</cell><cell cols="7">86.15±0.03 88.69±0.01 85.59±0.07 86.73±0.07 86.55±0.01 80.73±0.05 76.72±0.05</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Avg. 3-Min</cell><cell cols="2">M 98.26±0.01</cell><cell>97.75±0.01</cell><cell>98.04±0.01</cell><cell cols="7">96.17±0.01 95.38±0.01 96.69±0.01 97.67±0.00 93.96±0.01 96.23±0.03 92.32±0.02</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Accuracy</cell><cell cols="2">H 99.54±0.00</cell><cell>99.06±0.00</cell><cell>98.78±0.01</cell><cell cols="7">98.16±0.01 95.86±0.01 97.95±0.01 99.09±0.00 90.67±0.01 98.28±0.01 93.42±0.01</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell cols="2">F 96.24±0.01</cell><cell>95.90±0.01</cell><cell>95.14±0.01</cell><cell cols="7">93.78±0.01 93.29±0.01 93.47±0.01 93.85±0.01 90.24±0.02 90.89±0.02 87.12±0.01</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell cols="2">E 90.31±0.03</cell><cell>90.92±0.02</cell><cell>77.42±0.19</cell><cell cols="7">85.18±0.02 88.55±0.02 82.26±0.13 83.75±0.12 86.43±0.02 75.84±0.07 76.73±0.03</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Weighted</cell><cell cols="2">M 98.26±0.01</cell><cell>97.75±0.01</cell><cell>98.01±0.01</cell><cell cols="7">96.17±0.01 95.34±0.01 96.65±0.01 97.67±0.00 93.91±0.00 95.98±0.02 92.32±0.02</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Accuracy</cell><cell cols="2">H 99.53±0.00</cell><cell>99.04±0.00</cell><cell>98.67±0.01</cell><cell cols="7">98.16±0.01 95.79±0.01 97.87±0.01 99.09±0.00 90.66±0.01 98.26±0.02 93.39±0.00</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell cols="2">F 96.09±0.01</cell><cell>95.93±0.01</cell><cell>94.14±0.01</cell><cell cols="7">93.76±0.01 93.19±0.00 92.64±0.01 92.49±0.01 90.22±0.01 88.46±0.03 86.99±0.01</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 17 :</head><label>17</label><figDesc>grb-aminer leaderboard (Top 5 ATK. vs. Top 10 DEF.) in graph injection scenario.</figDesc><table><row><cell></cell><cell cols="2">Defenses</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>Avg.</cell><cell>Avg. 3-Max</cell><cell>Weighted</cell></row><row><cell cols="2">Attacks</cell><cell></cell><cell>GAT+AT</cell><cell cols="2">R-GCN+AT SGCN+LN</cell><cell>R-GCN</cell><cell>GCN+LN</cell><cell>GATLN</cell><cell>GIN+LN</cell><cell cols="2">TAGCN+LN TAGCN+AT</cell><cell>GAT</cell><cell>Accuracy</cell><cell>Accuracy</cell><cell>Accuracy</cell></row><row><cell></cell><cell></cell><cell cols="8">E 59.54±0.05 56.83±0.06 56.73±0.06 56.12±0.07 53.51±0.21 43.93±0.41 51.10±0.12</cell><cell>54.63±0.20</cell><cell>49.59±0.50</cell><cell cols="2">42.40±0.52 52.44±0.17</cell><cell>57.70±1.31</cell><cell>58.08±0.04</cell></row><row><cell>1</cell><cell>TDGIA</cell><cell cols="8">M 68.39±0.02 65.61±0.02 66.11±0.02 65.23±0.03 66.78±0.05 61.84±1.20 64.49±0.10 H 75.83±0.02 72.35±0.02 72.10±0.00 71.94±0.02 73.39±0.02 75.22±0.04 72.92±0.02</cell><cell>64.62±0.02 68.94±0.03</cell><cell>67.27±0.04 73.98±0.01</cell><cell cols="2">62.47±1.01 65.28±0.23 75.03±0.03 73.17±0.01</cell><cell>67.48±0.68 75.36±0.34</cell><cell>67.69±0.02 75.33±0.01</cell></row><row><cell></cell><cell></cell><cell cols="8">F 67.69±0.03 63.62±0.32 62.20±0.15 61.99±0.22 60.38±1.46 59.69±1.57 59.59±0.42</cell><cell>59.06±1.75</cell><cell>57.24±5.04</cell><cell cols="2">56.63±6.75 60.81±1.71</cell><cell>64.52±2.32</cell><cell>65.74±0.21</cell></row><row><cell></cell><cell></cell><cell cols="8">E 59.54±0.07 56.80±0.05 56.94±0.10 55.64±0.10 56.15±0.06 56.13±0.07 54.24±0.09</cell><cell>56.61±0.06</cell><cell>56.59±0.08</cell><cell cols="2">57.36±0.09 56.60±0.04</cell><cell>57.95±1.14</cell><cell>58.62±0.05</cell></row><row><cell>2</cell><cell>SPEIT</cell><cell cols="8">M 68.37±0.03 65.46±0.03 66.20±0.02 65.25±0.05 66.75±0.03 67.49±0.06 65.05±0.06 H 75.94±0.04 72.27±0.03 72.36±0.03 71.86±0.03 73.41±0.01 75.34±0.03 72.87±0.03</cell><cell>64.47±0.04 68.88±0.05</cell><cell>66.95±0.05 73.98±0.02</cell><cell cols="2">66.81±0.04 66.28±0.02 73.83±0.04 73.07±0.01</cell><cell>67.60±0.59 75.08±0.82</cell><cell>67.86±0.03 75.33±0.02</cell></row><row><cell></cell><cell></cell><cell cols="8">F 68.04±0.03 64.05±0.04 64.84±0.04 64.06±0.04 65.51±0.02 64.02±0.04 63.11±0.02</cell><cell>62.59±0.04</cell><cell>63.77±0.06</cell><cell cols="2">63.58±0.06 64.36±0.02</cell><cell>66.13±1.38</cell><cell>66.89±0.02</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">† https://www.biendata.xyz/competition/kddcup_2020_formal/</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Avg</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deepwalk: online learning of social representations</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 20th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</title>
				<editor>
			<persName><forename type="first">A</forename><surname>Sofus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Claudia</forename><surname>Macskassy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jure</forename><surname>Perlich</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Wei</forename><surname>Leskovec</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rayid</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><surname>Ghani</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</title>
				<editor>
			<persName><forename type="first">Balaji</forename><surname>Krishnapuram</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mohak</forename><surname>Shah</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Charu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dou</forename><surname>Aggarwal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rajeev</forename><surname>Shen</surname></persName>
		</editor>
		<editor>
			<persName><surname>Rastogi</surname></persName>
		</editor>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="855" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec</title>
		<author>
			<persName><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining (WSDM)</title>
				<meeting>the Eleventh ACM International Conference on Web Search and Data Mining (WSDM)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="459" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Predict then propagate: Graph neural networks meet personalized pagerank</title>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Klicpera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Simplifying graph convolutional networks</title>
		<author>
			<persName><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amauri</forename><forename type="middle">H</forename><surname>Souza</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Fifty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning (ICML)</title>
				<meeting>the 36th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Graph convolutional neural networks for web-scale recommender systems</title>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pong</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="974" to="983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Fast gradient attack on network embedding</title>
		<author>
			<persName><forename type="first">Jinyin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangyang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Xuan</surname></persName>
		</author>
		<idno>abs/1809.02797</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adversarial attacks on neural networks for graph data</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Akbarnejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2847" to="2856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adversarial attacks on graph neural networks via meta learning</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Attacking graph convolutional networks via rewiring</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tyler</forename><surname>Derr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingfei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1906">1906.03750, 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adversarial attacks on graph neural networks via node injections: A hierarchical reinforcement learning approach</title>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianfeng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsung-Yu</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasant</forename><forename type="middle">G</forename><surname>Honavar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Web Conference 2020 (WWW)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="673" to="683" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Scalable attack on graph data by injecting vicious nodes</title>
		<author>
			<persName><forename type="first">Jihong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minnan</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fnu</forename><surname>Suya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jundong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijiang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinghua</forename><surname>Zheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004.13825. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">KDD CUP 2020 ML Track 2 Adversarial Attacks and Defense on Academic Graph 1st Place Solution</title>
		<author>
			<persName><forename type="first">Qinkai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixiao</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanhao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingmin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minhao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qibo</forename><surname>Sun</surname></persName>
		</author>
		<ptr target="https://github.com/" />
		<imprint>
			<date type="published" when="2020">Stanislas0/KDD_CUP_2020_MLTrack2_SPEIT, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Tdgia: Effective injection attacks on graph neural networks</title>
		<author>
			<persName><forename type="first">Xu</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinkai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evgeny</forename><surname>Kharlamov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialiang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining (KDD)</title>
				<meeting>the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining (KDD)</meeting>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hiding individuals and communities in a social network</title>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Waniek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tomasz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Michalak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Talal</forename><surname>Wooldridge</surname></persName>
		</author>
		<author>
			<persName><surname>Rahwan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="147" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Topology adaptive graph convolutional networks</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanghang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanhang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">José Mf</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soummya</forename><surname>Kar</surname></persName>
		</author>
		<idno>abs/1710.10370</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Robust graph convolutional networks against adversarial attacks</title>
		<author>
			<persName><forename type="first">Dingyuan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1399" to="1407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Graph random neural networks for semi-supervised learning on graphs</title>
		<author>
			<persName><forename type="first">Wenzheng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evgeny</forename><surname>Kharlamov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">33th Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Graph structure learning for robust graph neural networks</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaorui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianfeng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining (KDD)</title>
				<editor>
			<persName><forename type="first">Rajesh</forename><surname>Gupta</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">Aditya</forename><surname>Prakash</surname></persName>
		</editor>
		<meeting>the 26th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="66" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">All you need is low (rank): Defending against adversarial attacks on graphs</title>
		<author>
			<persName><forename type="first">Negin</forename><surname>Entezari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saba</forename><forename type="middle">A</forename><surname>Al-Sayouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amirali</forename><surname>Darvishzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evangelos</forename><forename type="middle">E</forename><surname>Papalexakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirteenth ACM International Conference on Web Search and Data Mining (WSDM)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="169" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Gnnguard: Defending graph neural networks against adversarial attacks</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006.08149, 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Open graph benchmark: Datasets for machine learning on graphs</title>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">33th Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Benchmarking graph neural networks</title>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Prakash Dwivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaitanya</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<idno>abs/2003.00982</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Deeprobust: A pytorch library for adversarial attacks and defenses</title>
		<author>
			<persName><forename type="first">Yaxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<idno>abs/2005.06149</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Adversarial attacks on node embeddings via graph poisoning</title>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning (ICML), volume 97 of Proceedings of Machine Learning Research</title>
				<meeting>the 36th International Conference on Machine Learning (ICML), volume 97 of Machine Learning Research</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="695" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Adversarial attack on graph structured data</title>
		<author>
			<persName><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
				<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="1123" to="1132" />
		</imprint>
	</monogr>
	<note>of Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Query-free black-box adversarial attacks on graphs</title>
		<author>
			<persName><forename type="first">Jiarong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanhao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunping</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiangang</forename><surname>Lu</surname></persName>
		</author>
		<idno>abs/2012.06757</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Adversarial examples on graph data: Deep insights into attack and defense</title>
		<author>
			<persName><forename type="first">Huijun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuriy</forename><surname>Tyshetskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Docherty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liming</forename><surname>Zhu</surname></persName>
		</author>
		<idno>abs/1903.01610</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Vladu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Graph adversarial training: Dynamically regularizing based on graph structure</title>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">La cryptographie militaire</title>
		<author>
			<persName><forename type="first">Auguste</forename><surname>Kerckhoffs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1883">1883</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Köpf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Pytorch: An imperative style</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Cogdl: An extensive toolkit for deep learning on graphs</title>
		<author>
			<persName><forename type="first">Yukuo</forename><surname>Cen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenyu</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qibin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhen</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingcheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aohan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiguang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guohao</forename><surname>Dai</surname></persName>
		</author>
		<idno>preprint, abs/2103.00959</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Deep graph library: Towards efficient and scalable deep learning on graphs</title>
		<author>
			<persName><forename type="first">Minjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingfan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Da</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Gai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihao</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mufei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinjing</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lei Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Ryan Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno>abs/1607.06450</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">Layer normalization. ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Dimensional reweighting graph convolution networks</title>
		<author>
			<persName><forename type="first">Xu</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiuye</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijun</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Graphsaint: Graph sampling based inductive learning method</title>
		<author>
			<persName><forename type="first">Hanqing</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongkuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajitesh</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajgopal</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><forename type="middle">K</forename><surname>Prasanna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Revisiting semi-supervised learning with graph embeddings</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33nd International Conference on Machine Learning (ICML)</title>
				<meeting>the 33nd International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="40" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
				<meeting>the 2019 Conference of the North American Chapter<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Arnetminer: extraction and mining of academic social networks</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhong</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="990" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The numpy array: a structure for efficient numerical computation</title>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Van Der Walt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Colbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gael</forename><surname>Varoquaux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in science &amp; engineering</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="22" to="30" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">On evaluating adversarial robustness</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anish</forename><surname>Athalye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<idno>abs/1902.06705</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Benchmarking adversarial robustness on image classification</title>
		<author>
			<persName><forename type="first">Yinpeng</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi-An</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihao</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="318" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Robustbench: a standardized adversarial robustness benchmark</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maksym</forename><surname>Andriushchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikash</forename><surname>Sehwag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Flammarion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mung</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prateek</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hein</surname></persName>
		</author>
		<idno>abs/2010.09670</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Robust graph representation learning via neural sparsification</title>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongjin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingchao</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenchao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno>RND E 59.56±0.06 57.53±0.06 57.41±0.06 56.38±0.11 57.76±0.05 58.83±0.10 54.41±0.13 58.07±0.12 58.14±0.04 57.46±0.10 57.55±0.03 58.85±0.57 59.09±0.05</idno>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">W/O</forename><surname>Attack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>59</surname></persName>
		</author>
		<idno>67±0.00 58.08±0.00 60.22±0.00 58.53±0.00 58.14±0.00 60.78±0.00 56.83±0.00 59.47±0.00 59.62±0.00 59.88±0.00 59.12±0.00 60.29±0.37 60.42±0.00</idno>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
