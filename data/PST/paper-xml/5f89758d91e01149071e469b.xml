<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Under review as a conference paper at ICLR 2021 REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<title level="a" type="main">Under review as a conference paper at ICLR 2021 REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T14:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Self-supervised learning has emerged as a strategy to reduce the reliance on costly supervised signals by pretraining representations only using unlabeled data. These methods combine heuristic proxy classification tasks with data augmentations and have achieved significant success, but our theoretical understanding of this success remains limited. In this paper we analyze self-supervised representation learning using a causal framework. We show how data augmentations can be more effectively utilized through explicit invariance constraints on the proxy classifiers employed during pretraining. Based on this, we propose a novel selfsupervised objective, Representation Learning via Invariant Causal Mechanisms (RELIC), that enforces invariant prediction of proxy targets across augmentations through an invariance regularizer which yields improved generalization guarantees. Further, using causality we generalize contrastive learning, a particular kind of self-supervised method, and provide an alternative theoretical explanation for the success of these methods. Empirically, RELIC significantly outperforms competing methods in terms of robustness and out-of-distribution generalization on ImageNet, while also significantly outperforming these methods on Atari achieving above human-level performance on 51 out of 57 games.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Training deep networks often relies heavily on large amounts of useful supervisory signal, such as labels for supervised learning or rewards for reinforcement learning. These training signals can be costly or otherwise impractical to acquire. On the other hand, unsupervised data is often abundantly available. Therefore, pretraining representations for unknown downstream tasks without the need for labels or extrinsic reward holds great promise for reducing the cost of applying machine learning models. To pretrain representations, self-supervised learning makes use of proxy tasks defined on unsupervised data. Recently, self-supervised methods using contrastive objectives have emerged as one of the most successful strategies for unsupervised representation learning <ref type="bibr" target="#b28">(Oord et al., 2018;</ref><ref type="bibr" target="#b18">Hjelm et al., 2018;</ref><ref type="bibr" target="#b4">Chen et al., 2020a)</ref>. These methods learn a representation by classifying every datapoint against all others datapoints (negative examples). Under assumptions on how the negative examples are sampled, minimizing the resulting contrastive loss has been justified as maximizing a lower bound on the mutual information (MI) between representations <ref type="bibr" target="#b31">(Poole et al., 2019)</ref>. However, <ref type="bibr" target="#b40">(Tschannen et al., 2019)</ref> has shown that performance on downstream tasks may be more tightly correlated with the choice of encoder architecture than the achieved MI bound, highlighting issues with the MI theory of contrastive learning. Further, contrastive approaches compare different views of the data (usually under different data augmentations) to calculate similarity scores. This approach to computing scores has been empirically observed as a key success factor of contrastive methods, but has yet to be theoretically justified. This lack of a solid theoretical explanation for the effectiveness of contrastive methods hinders their further development.</p><p>To remedy the theoretical shortcomings, we analyze the problem of self-supervised representation learning through a causal lens. We formalize intuitions about the data generating process using a causal graph and leverage causal tools to derive properties of the optimal representation. We show that a representation should be an invariant predictor of proxy targets under interventions on features that are only correlated, but not causally related to the downstream targets of interest. Since neither causally nor purely correlationally related features are observed and thus performing actual interventions on them is not feasible, for learning representation with this property we use data augmentations to simulate a subset of possible interventions. Based on our causal interpretation, we propose a regularizer which enforces that the prediction of the proxy targets is invariant across data augmentations. We propose a novel objective for self-supervised representation learning called REpresentation Learning with Invariant Causal mechanisms (RELIC). We show how this explicit invariance regularization leverages augmentations more effectively than previous self-supervised methods and that representations learned using RELIC are guaranteed to generalize well to downstream tasks under weaker assumptions than those required by previous work <ref type="bibr" target="#b34">(Saunshi et al., 2019)</ref>.</p><p>Next we generalize contrastive learning and provide an alternative theoretical explanation to MI for the success of these methods. We generalize the proxy task of instance discrimination commonly used in contrastive learning using the causal concept of refinements <ref type="bibr" target="#b3">(Chalupka et al., 2014)</ref>. Intuitively, a refinement of a task can be understood as a more fine-grained variant of the original problem. For example, a refinement for classifying cats against dogs would be the task of classifying individual cat and dog breeds. The instance discrimination task results from the most fine-grained refinement, e.g. discriminating individual cats and dogs from one another. We show that using refinements as proxy tasks enables us to learn useful representations for downstream tasks. Specifically, using causal tools, we show that learning a representation on refinements such that it is an invariant predictor of proxy targets across augmentations is a sufficient condition for these representations to generalize to downstream tasks (cf. Theorem 1). In summary, we provide theoretical support both for the general form of the contrastive objective as well as for the use of data augmentations. Thus, we provide an alternative explanation to mutual information for the success of recent contrastive approaches namely that of causal refinements of downstream tasks.</p><p>We test RELIC on a variety of prediction and reinforcement learning problems. First, we evaluate the quality of representations pretrained on ImageNet with a special focus on robustness and out-ofdistribution generalization. RELIC performs competitively with current state-of-the-art methods on ImageNet, while significantly outperforming competing methods on robustness and out-of-distribution generalization of the learned representations when tested on corrupted ImageNet (ImageNet-C <ref type="bibr" target="#b16">(Hendrycks &amp; Dietterich, 2019)</ref>) and a version of ImageNet that consist of different renditions of the same classes (ImageNet-R <ref type="bibr" target="#b17">(Hendrycks et al., 2020)</ref>). In terms of robustness, RELIC also significantly outperforms the supervised baseline with an absolute reduction of 4.9% in error. Unlike much prior work that specifically focuses on computer vision tasks, we test RELIC for representation learning in the context of reinforcement learning on the Atari suite <ref type="bibr" target="#b1">(Bellemare et al., 2013)</ref>. There we find that RELIC significantly outperforms competing methods and achieves above human-level performance on 51 out of 57 games.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions.</head><p>• We formalize problem of self-supervised representation learning using causality and propose to more effectively leverage data augmentations through invariant prediction.</p><p>• We propose a new self-supervised objective, REpresentation Learning with Invariance Causal mechanisms (RELIC), that enforces invariant prediction through an explicit regularizer and show improved generalization guarantees.</p><p>• We generalize contrastive learning using refinements and show that learning on refinements is a sufficient condition for learning useful representations; this provides an alternative explanation to MI for the success of contrastive methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS</head><p>Problem setting. Let X denote the unlabelled observed data and Y = {Y t } T t=1 be a set of unknown tasks with Y t denoting the targets for task t. The tasks {Y t } T t=1 can represent both a multi-environment as well as a multi-task setup. Our goal is to pretrain with unsupervised data a representation f (X) that will be useful for solving the downstream tasks Y.</p><p>Causal interpretation. To effectively leverage common assumptions and intuitions about data generation of the unknown downstream tasks for the learning algorithm, we propose to formalize them using a causal graph. We start from the following assumptions: a) the data is generated from content and style variables, with b) only content (and not style) being relevant for the unknown</p><formula xml:id="formula_0">S C Y 1 Y T X f (X) Y R</formula><p>Data generation Representation Learning . . . downstream tasks and c) content and style are independent, i.e. style changes are content-preserving. For example, when classifying dogs against giraffes from images, different parts of the animals constitute content, while style could be, for example, background, lighting conditions and camera lens characteristics. By assumption, content is a good representation of the data for downstream tasks and we therefore cast the goal of representation learning as estimating content. In the following, we compactly formalize these assumptions with a causal graph<ref type="foot" target="#foot_0">1</ref> , see Figure <ref type="figure" target="#fig_0">1a</ref>.</p><p>Let C and S be the latent variables describing content and style. In Figure <ref type="figure" target="#fig_0">1a</ref>, the directed arrows from C and S to the observed data X (e.g. images) indicate that X is generated based on content and style. The directed arrow from C to the target Y t (e.g. class labels) encodes the assumption that content directly influences the target tasks, while the absence of any directed arrow from S to Y t indicates that style does not. Thus, content C has all the necessary information to predict Y t . The absence of any directed path between C and S in Figure <ref type="figure" target="#fig_0">1a</ref> encodes the intuition that these variables are independent, i.e. C ? ? S.</p><p>Using the independence of mechanisms <ref type="bibr" target="#b30">(Peters et al., 2017)</ref>, we can conclude that under this causal model performing interventions on S does not change the conditional distribution P (Y t |C), i.e. manipulating the value of S does not influence this conditional distribution. Thus, P (Y t |C) is invariant under changes in style S. We call C an invariant representation for Y t under S, i.e.</p><formula xml:id="formula_1">p do(S=si) (Y t | C) = p do(S=sj ) (Y t | C) 8 s i , s j 2 S,<label>(1)</label></formula><p>where p do(S=s) denotes the distribution arising from assigning S the value s with S the domain of S (Pearl, 2009). Specifically, using C as a representation allows for us to predict targets stably across perturbations, i.e. content C is both a useful and robust representation for tasks Y.</p><p>Since the targets Y t are unknown, we will construct a proxy task Y R in order to learn representations from unlabeled data X only. In order to learn useful representations for Y t , we will construct proxy tasks that represents more fine-grained problems than Y t ; for a more formal treatment of proxy tasks please refer to Section 3. Further, to learn invariant representations, such as C, we enforce Equation <ref type="formula" target="#formula_1">1</ref>which requires us to observe data under different style interventions, i.e. we need data that describes the same content under varying style. Since we do not have access to S, to simulate style variability we use content-preserving data augmentations (e.g. rotation, grayscaling, translation, cropping for images). Specifically, we utilize data augmentations as interventions on the style variable S, i.e. applying data augmentation a i corresponds to intervening on S and setting it to s ai . 2 Although we are not able to generate all possible styles using a fixed set of data augmentations, we will use augmentations that generate large sets of diverse styles as this allows us to learn better representations. Note that the heuristic of estimating similarity based on different views from contrastive learning can be interpreted as an implicit invariance constraint.</p><p>RELIC objective. Equation 1 provides a general scheme to estimate content (c.f. Figure <ref type="figure" target="#fig_0">1a</ref>). We operationalize this by proposing to learn representations such that prediction of proxy targets from the representation is invariant under data augmentations. The representation f (X) must fulfill the following invariant prediction criteria</p><formula xml:id="formula_2">(Invariant prediction) p do(ai) (Y R |f (X)) = p do(aj ) (Y R |f (X)) 8a i , a j 2 A.<label>(2)</label></formula><p>A = {a 1 , . . . , a m } is the set of data augmentations which simulate interventions on the style variables and p do(a) denotes p do(S=sa) .</p><p>To achieve invariant prediction, we propose to explicitly enforce invariance under augmentations through a regularizer. This gives rise to an objective for self-supervised learning we call Representation Learning via Invariant Causal Mechanisms (RELIC). We write this objective as</p><formula xml:id="formula_3">E X⇠p(X) E a lk ,aqt ⇠A⇥A X b2{a lk ,aqt} L b (Y R , f(X)) s.t. KL ⇣ p do(a lk ) (Y R | f (X)), p do(aqt) (Y R | f (X)) ⌘  ⇢</formula><p>where L is the proxy task loss and KL is the Kullback-Leibler (KL) divergence. Note that any distance measure on distributions can be used in place of the KL divergence. We explain the remaining terms in detail below.</p><p>Concretely, as proxy task we associate to every datapoint x i the label y R i = i. This corresponds to the instance discrimination task, commonly used in contrastive learning <ref type="bibr" target="#b11">(Hadsell et al., 2006)</ref>. We take pairs of points (x i , x j ) to compute similarity scores and use pairs of augmentations a lk = (a l , a k ) 2 A ⇥ A to perform a style intervention. Given a batch of samples {x i } N i=1 ⇠ D, we use</p><formula xml:id="formula_4">p do(a lk ) (Y R = j | f (x i )) / exp (f (x a l i ), h(x a k j</formula><p>))/⌧ . with x a data augmented with a and ⌧ a softmax temperature parameter. We encode f using a neural network and choose h to be related to f , e.g. h = f or as a network with an exponential moving average of the weights of f (e.g. target networks similar to <ref type="bibr" target="#b9">(Grill et al., 2020)</ref>). To compare representations we use the function (f (x i ), h(x j )) = hg(f (x i )), g(h(x j ))i where g is a fullyconnected neural network often called the critic.</p><p>Combining these pieces, we learn representations by minimizing the following objective over the full set of data x i 2 D and augmentations</p><formula xml:id="formula_5">a lk 2 A ⇥ A N X i=1 X a lk log exp ( (f (x a l i ), h(x a k i ))/⌧ ) P M m=1 exp ( (f (x a l i ), h(x a k m ))/⌧ ) + ↵ X a lk ,aqt KL(p do(a lk ) , p do(aqt) )<label>(3)</label></formula><p>with M the number of points we use to construct the contrast set and ↵ the weighting of the invariance penalty. We used the shorthand p do(a) for p do(a</p><formula xml:id="formula_6">) (Y R = j | f (x i ))</formula><p>. With appropriate choices for , g, f and h above, Equation 3 recovers many recent state-of-the-art methods (c.f. Table <ref type="table">5</ref> in Section A). Figure <ref type="figure" target="#fig_0">1b</ref> presents a schematic of the RELIC objective.</p><p>The explicit invariance penalty encourages the within-class distances (for a downstream task of interest) of the representations learned by RELIC to be tightly concentrated. We show this empirically in Figure <ref type="figure" target="#fig_1">2</ref> and theoretically in Appendix B. In the following section we provide theoretical justification for using an instance discrimination-based contrastive loss using a causal perspective. We also show (cf. Theorem 1 below) that minimizing the contrastive loss alone (i.e. ↵ = 0) does not guarantee generalization. Instead, invariance across augmentations must be explicitly enforced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">GENERALIZING CONTRASTIVE LEARNING</head><p>Learning with refinements. In contrastive learning, the task of instance discrimination, i.e. classifying the dataset {(x i , y R i = i)|x i 2 D}, is used as the proxy task. To better understand contrastive learning and motivate this proxy task, we generalize instance discrimination using the causal concept of refinements <ref type="bibr" target="#b3">(Chalupka et al., 2014)</ref>. Intuitively, a refinement of one problem is another more fine-grained problem. If task Y t is to classify cats against dogs, then a refinement of Y t is the task of classifying cats and dogs into their individual breeds. See Figure <ref type="figure">4</ref> for a further visual example. For any set of tasks, there exist many different refinements. However, the most fine-grained refinement corresponds exactly to classifying the dataset {(x i , y R i = i)|x i 2 D}. Thus, the instance discrimination task used in contrastive learning is a specific type of refinement. For a definition and formal treatment of refinements please refer to Appendix D.</p><p>Let Y R be targets of a proxy task that is a refinement for all tasks in Y. Leveraging causal tools, we connect learning on refinements to learning on downstream tasks. Specifically, we provide a theoretical justification for exchanging unknown downstream tasks with these specially constructed proxy tasks. We show that if f (X) is an invariant representation for Y R under changes in style S, then f (X) is also an invariant representation for tasks in Y under changes in style S. Thus by enforcing invariance under style interventions on a refinement, we learn representations that generalize to downstream tasks. <ref type="foot" target="#foot_2">3</ref> This is summarized in the following theorem.</p><p>Theorem 1. Let Y = {Y t } T t=1 be a family of downstream tasks. Let Y R be a refinement for all tasks in Y. If f (X) is an invariant representation for Y R under style interventions S, then f (X) is an invariant representation for all tasks in Y under style interventions S, i.e.</p><formula xml:id="formula_7">p do(si) (Y R | f (X)) = p do(sj ) (Y R | f (X)) ) p do(si) (Y t | f (X)) = p do(sj ) (Y t | f (X)) (4)</formula><p>for all s i , s j 2 S with p do(si) = p do (S=si)  . Thus, f (X) is a representation that generalizes to Y.</p><p>Theorem 1 states that if Y R is a refinement of Y then learning a representation on Y R is a sufficient condition for this representation to be useful on Y. For a formal exposition of these points and accompanying proofs, please refer to Appendix D. Recall that the instance discrimination proxy task is the most fine-grained refinement, and so the right hand side of 4 is satisfied for any downstream task satisfying the stated assumptions of the theorem.</p><p>We generalize contrastive learning through refinements and connect representations learned on refinements and downstream tasks in Theorem 1. Thus, using causality we provide an alternative explanation to mutual information for the success of contrastive learning. Note that our methodology of refinements is not limited to instance discrimination tasks and is thus more general than currently used contrastive losses. Real world data often includes rich sources of metadata which can be used to guide the construction of refinements by grouping the data according to any available meta-data.</p><p>Note that the coarser we can create a refinement, the more data efficient we can expect to be when learning representations for downstream tasks. Further, we can also expect to require less supervised data to finetune the representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RELATED WORK</head><p>Contrastive objectives and mutual information maximization. Many recent approaches to selfsupervised learning are rooted in the well-established idea of maximizing mutual information (MI), e.g. Contrastive Predictive Coding (CPC) <ref type="bibr" target="#b28">(Oord et al., 2018;</ref><ref type="bibr" target="#b15">Hénaff et al., 2019)</ref>, Deep InfoMax (DIM) <ref type="bibr" target="#b18">(Hjelm et al., 2018)</ref> and Augmented Multiscale DIM (AMDIM) <ref type="bibr" target="#b0">(Bachman et al., 2019)</ref>. These methods are based on noise contrastive estimation (NCE) <ref type="bibr" target="#b10">(Gutmann &amp; Hyvärinen, 2010)</ref> which, under specific conditions, can be viewed as a bound on MI <ref type="bibr" target="#b31">(Poole et al., 2019)</ref>. The resulting objective functions are commonly referred to as InfoNCE.</p><p>The precise role played by mutual information maximization in self-supervised learning is subject to some debate. <ref type="bibr" target="#b40">(Tschannen et al., 2019)</ref> argue that the performance on downstream tasks is not correlated with the achieved bound on MI, but may be more tightly correlated with encoder architecture and capacity. Importantly, InfoNCE objectives require custom architectures to ensure the network does not converge to non-informative solutions thus precluding the use of standard architectures. Recently, several works <ref type="bibr" target="#b13">(He et al., 2019;</ref><ref type="bibr" target="#b4">Chen et al., 2020a)</ref> successfully combined contrastive estimation with a standard ResNet-50 architecture. In particular, SimCLR <ref type="bibr" target="#b4">(Chen et al., 2020a)</ref> relies on a set of strong augmentations<ref type="foot" target="#foot_3">4</ref> , while <ref type="bibr" target="#b13">(He et al., 2019)</ref> uses a memory bank. Inspired by target networks in reinforcement learning, <ref type="bibr" target="#b9">(Grill et al., 2020)</ref> proposed BYOL: an algorithm for self-supervised learning which remarkably does not use a contrastive objective. Although theoretical explanation for the good performance of BYOL is presently missing, interestingly the objective, an `2 distance between two different embeddings of the input data resembles the `2 form of our regularizer proposed in Equation 5 in Appendix B. Recently, <ref type="bibr" target="#b34">(Saunshi et al., 2019)</ref> proposed a learning theoretic framework to analyze the performance of contrastive objectives. However, without strong assumptions on intra-class concentration they note that contrastive objectives are fundamentally limited in the representations they are able to learn. RELIC explicitly enforces intra-class concentration via the invariance regularizer, ensuring that it generalizes under weaker assumptions. Unlike <ref type="bibr" target="#b34">(Saunshi et al., 2019)</ref> who do not discuss augmentations, we incorporate augmentations into our theoretical explanation of contrastive methods.</p><p>The reasons for the improvement in performance from AMDIM through to SimCLR and BYOL are not easily explained by either the MI maximization or the learning theoretic viewpoint. Further, it is not clear why relatively minor architectural differences between the methods result in significant differences in performance nor is it obvious how current state-of-the-art can be improved. In contrast to prior art, the performance of RELIC is explained by connections to causal theory. As such it gives a clear path for improving results by devising problem appropriate refinements, interventions and invariance penalties. Furthermore, the use of invariance penalties in RELIC as dictated by causal theory yields significantly more robust representations that generalize better than those learned with SimCLR or BYOL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Causality and invariance.</head><p>Recently, the notion of invariant prediction has emerged as an important operational concept in causal inference <ref type="bibr" target="#b29">(Peters et al., 2016)</ref>. This idea has been used to learn classifiers which are robust against domain shifts <ref type="bibr" target="#b8">(Gong et al., 2016)</ref>. Notably, <ref type="bibr" target="#b14">(Heinze-Deml &amp; Meinshausen, 2017)</ref> propose to use group structure to delineate between different environments where the aim is to minimize the classification loss while also ensuring that the conditional variance of the prediction function within each group remains small. Unlike <ref type="bibr" target="#b14">(Heinze-Deml &amp; Meinshausen, 2017)</ref> who use supervised data and rely on having a grouping in the training data, our approach does not rely on ground-truth targets and can flexibly create groupings of the training data if none are present. Further, we enforce invariant prediction within the group by constraining the distance between distributions resulting from contrasting data across groups.</p><p>The relationship between causal inference and semi-supervised learning has been explored in <ref type="bibr" target="#b35">(Schölkopf et al., 2012)</ref>. In particular, in order for unlabeled data to be helpful for learning, the relationship between the predictors and targets must be anti-causal. Our setting is somewhat different as we assume a latent decomposition of the observed variables and learn representations based on proxy targets which are refinements of the true targets.</p><p>Our invariance penalty is similar in practise to consistency regularizers which have recently gained popularity in semi-supervised learning <ref type="bibr" target="#b33">(Sajjadi et al., 2016;</ref><ref type="bibr" target="#b42">Xie et al., 2019;</ref><ref type="bibr" target="#b36">Sohn et al., 2020)</ref>. These typically supplement the supervised training signal with a term which enforces similarity between the function's output on two views of data. Although recently proposed consistency methods are heuristic, they have deeper roots in the more rigorous co-training approach to semi-supervised learning from multiple views <ref type="bibr">(Blum &amp; Mitchell, 1998;</ref><ref type="bibr" target="#b20">Kakade &amp; Foster, 2007;</ref><ref type="bibr" target="#b37">Sridharan &amp; Kakade, 2008;</ref><ref type="bibr" target="#b25">McWilliams &amp; Montana, 2012;</ref><ref type="bibr" target="#b26">McWilliams et al., 2013)</ref>. The main conceptual difference between our approach and consistency-based methods is that we do not have access to a supervised training signal and that the RELIC penalty is motivated from the underlying causal graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>We first visualize the influence of the explicit invariance constraint in RELIC on the linear separability of the learned representations. We then evaluate RELIC on a number of prediction and reinforcement learning tasks for usefulness and robustness. For the prediction tasks, we test RELIC after pretraining the representation in a self-supervised way on the training set of the ImageNet ILSVRC-2012 dataset <ref type="bibr" target="#b32">(Russakovsky et al., 2015)</ref>. We evaluate RELIC in the linear evaluation setup on ImageNet and test its robustness and out-of-distribution generalization on datasets related to ImageNet. Unlike much prior work in contrastive learning which focuses specifically on computer vision tasks, we test RELIC also in the context of learning representations for reinforcement learning. Specifically, we test RELIC on the suite of Atari games <ref type="bibr" target="#b1">(Bellemare et al., 2013)</ref> which consists of 57 diverse games of varying difficulty.</p><p>Linear evaluation. In order to understand how representations learned by RELIC differ from other methods, we compare it against those learned by AMDIM and SimCLR in terms of Fischer's linear discriminant ratio <ref type="bibr" target="#b7">(Friedman et al., 2009)</ref>:</p><formula xml:id="formula_8">F LDA = kµ k µ k 0 k 2 / P i,j2C k kf (x i ) f (x j )k 2 where µ k = 1 |C k | P i2C k f (x i )</formula><p>is the mean of the representations of class k and C k is the index set of that class. A larger F LDA implies that classes are more easily separated with a linear classifier. This can be achieved by either increasing distances between classes (numerator) or shrinking within-class variance (denominator).</p><p>Figure <ref type="figure" target="#fig_1">2</ref> shows the distribution of F LDA for RELIC, SimCLR and AMDIM after training as measured on the (downsampled) ImageNet validation set. The distance between medians of RELIC and SimCLR is 162. AMDIM is tightly concentrated close to 20. The invariance penalty ensures thateven though labels are a-priori unknown-for RELIC within-class variability of f is concentrated leading to better linear separability between classes in the downstream task of interest.This is reflected in the rightward shift of the distribution of F LDA in Figure <ref type="figure" target="#fig_1">2</ref> for RELIC compared with SimCLR and AMDIM which do not impose such a constraint.  <ref type="bibr" target="#b2">(Caron et al., 2020)</ref> † 75.3 -ResNet-50 with target network MoCo v2 <ref type="bibr" target="#b5">(Chen et al., 2020b)</ref> 71.1 -BYOL <ref type="bibr" target="#b9">(Grill et al., 2020</ref>  <ref type="bibr" target="#b2">(Caron et al., 2020)</ref> and <ref type="bibr">InfoMin (Tian et al., 2020)</ref>, but note that these methods use stronger augmentations which alone have been shown to boost performance by over 5%.</p><p>A fair comparison between different objectives can only be achieved under the same architecture and the same set of augmentations.</p><p>Robustness and generalization. We evaluate robustness and out-of-distribution generalization of RELIC's representation on datasets Imagenet-C <ref type="bibr" target="#b16">(Hendrycks &amp; Dietterich, 2019)</ref> and ImageNet-R <ref type="bibr" target="#b17">(Hendrycks et al., 2020)</ref>, respectively. To evaluate RELIC's representation, we train a linear classifier on top of the frozen representation following the procedure described in <ref type="bibr" target="#b4">(Chen et al., 2020a)</ref>  Reinforcement Learning. Much prior work in contrastive learning has focused specifically on computer vision tasks. In order to compare these approaches in a different domain, we investigate representation learning in the context of reinforcement learning. We compare RELIC as an auxiliary loss against other state of the art self-supervised losses on an agent trained on 57 Atari games. Using human normalized scores as a metric, we use the original architecture and hyperparameters of the R2D2 agent <ref type="bibr" target="#b21">(Kapturowski et al., 2019)</ref> and supplement it with a second encoder trained with a given representation learning loss. When auxiliary losses are present, the Q-Network takes the output of the second encoder as an input. The Q-Network and the encoder are trained with separate optimizers. For the augmentation baseline, the Q-Network takes two identical encoders trained end-to-end. Table <ref type="table" target="#tab_4">4</ref> shows a comparison between RELIC, SimCLR, BYOL, CURL <ref type="bibr" target="#b38">(Srinivas et al., 2020)</ref>, and feeding augmented observations directly to the agent <ref type="bibr" target="#b23">(Kostrikov et al., 2020)</ref>. We find that RELIC has a significant advantage over competing self-supervised methods, performing best in 25 out of 57 games. The next best performing method, CURL performs best in 11 games. Note that none of these methods outperform R2D2 <ref type="bibr" target="#b21">(Kapturowski et al., 2019)</ref> which achieves superhuman performance in 52 games. Although previously published work shows the auxiliary tasks help on Atari, this is in the very low-data regime. Here we show that ReLIC is able to close the gap in the more common Atari set up. We hypothesize that the performance penalty resulting from adding auxiliary self-supervised losses stems from the naive combining of the outputs of the two encoders; we will explore alternative options for combining encoder outputs in future. Full details are presented in Section E.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this work we have analyzed self-supervised learning using a causal framework. Using a causal graph, we have formalized the problem of self-supervised representation learning and derived properties of the optimal representation. We have shown that representations need to be invariant predictors of proxy targets under interventions on features that are only correlated, but not causally related to the downstream tasks. We have leveraged data augmentations to simulate these interventions and have proposed to explicitly enforce this invariance constraint. Based on this, we have proposed a that enforces invariant prediction of proxy targets across augmentations using an invariance regularizer. Further, we have generalized contrastive methods using the concept of refinements and have shown that learning a representation on refinements using the principle of invariant prediction is a sufficient condition for these representations to generalize to downstream tasks. With this, we have provided an alternative explanation to mutual information for the success of contrastive methods. Empirically we have compared RELIC against recent self-supervised methods on a variety of prediction and reinforcement learning tasks. Specifically, RELIC significantly outperforms competing methods in terms of robustness and out-of-distribution generalization of the representations it learns on ImageNet. RELIC also significantly outperforms related self-supervised methods on the Atari suite achieving superhuman performance on 51 out of 57 games. We aim to investigate the construction of more coarse-grained refinements and the empirical evaluation of different kinds of refinements in future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (a) Causal graph formalizing assumptions about content and style of the data and the relationship between targets and proxy tasks. The dashed arrows are not causal and represent learning, while the dashdotted lines denote that Y R is a refinement Y t 's. All other arrows are causal. (b) RELIC objective. KL refers to the Kullback-Leibler divergence, while x-entropy denotes cross entropy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Distribution of the linear discriminant ratio (F LDA , see text) of f for RELIC, SimCLR and AMDIM (y-axis clipped to aid visualization).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Accuracy (in %) under linear evaluation on Ima-geNet for different self-supervised representation learning methods. Methods with * use SimCLR augmentations. Methods with † use custom, stronger augmentations.</figDesc><table><row><cell>Method</cell><cell></cell><cell cols="2">Top-1 Top-5</cell></row><row><cell>ResNet-50 architecture</cell><cell></cell><cell></cell><cell></cell></row><row><cell>PIRL</cell><cell></cell><cell>63.6</cell><cell>-</cell></row><row><cell>CPC v2</cell><cell></cell><cell>63.8</cell><cell>85.3</cell></row><row><cell>CMC</cell><cell></cell><cell>66.2</cell><cell>87.0</cell></row><row><cell>SimCLR (Chen et al., 2020a)</cell><cell>*</cell><cell>69.3</cell><cell>89.0</cell></row><row><cell>SwAV (Caron et al., 2020)</cell><cell>*</cell><cell>70.1</cell><cell>-</cell></row><row><cell>RELIC (ours)</cell><cell>*</cell><cell>70.3</cell><cell>89.5</cell></row><row><cell cols="2">InfoMin Aug. (Tian et al., 2020)  † SwAV</cell><cell>73.0</cell><cell>91.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>and appendix E.5.2. For Imagenet-C we report the mean Corruption Error (mCE) and Corruption Errors for Noise corruptions in Table3. RELIC has significantly lower mCE than both the supervised ResNet-50 baseline and the unsupervised methods SimCLR and BYOL. Also, it has the lowest Corruption Error on 14 out of 15 corruptions when compared to SimCLR and BYOL. Thus, we see that RELIC learns the most robust representation. RELIC also outperforms SimCLR and BYOL on ImageNet-R showing its superior out-of-distribution generalization ability; see Table2. For further details and results please consult E.5. Top-1 error rates for different self-supervised representation learning methods on ImageNet-R. All models are trained only on clean ImageNet images and RELIC T refers to RELIC using a ResNet-50 with target network as in BYOL<ref type="bibr" target="#b9">(Grill et al., 2020)</ref>.</figDesc><table><row><cell>Method</cell><cell cols="5">Supervised SimCLR RELIC BYOL RELIC T</cell></row><row><cell>Top-1 Error (%)</cell><cell>63.9</cell><cell>81.7</cell><cell>77.4</cell><cell>77.0</cell><cell>76.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Mean Corruption Error (mCE), mean relative Corruption Error (mrCE) and Corruption Errors for the "Noise" class of corruptions (Gaussian, Shot, Impulse) on ImageNet-C. The mCE value is the average across 75 different corruptions. Methods are trained only on clean ImageNet images.</figDesc><table><row><cell>Method</cell><cell cols="5">mCE mrCE Gaussian Shot Impulse</cell></row><row><cell>Supervised</cell><cell cols="2">76.7 105.0</cell><cell>80.0</cell><cell>82.0</cell><cell>83.0</cell></row><row><cell>ResNet-50 architecture:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SimCLR</cell><cell cols="2">87.5 111.9</cell><cell>79.4</cell><cell>81.9</cell><cell>89.6</cell></row><row><cell>ReLIC</cell><cell>76.4</cell><cell>87.7</cell><cell>67.8</cell><cell>70.7</cell><cell>77.0</cell></row><row><cell>ResNet-50 with target network:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>BYOL</cell><cell>72.3</cell><cell>90.0</cell><cell>65.9</cell><cell>68.4</cell><cell>73.7</cell></row><row><cell>ReLIC</cell><cell>70.8</cell><cell>88.4</cell><cell>63.6</cell><cell>65.7</cell><cell>69.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Human Normalized Scores of Auxiliary Methods over 57 Atari Games.</figDesc><table><row><cell>Atari Performance</cell><cell cols="2">RELIC SimCLR</cell><cell>CURL</cell><cell>BYOL</cell><cell>Augmentation</cell></row><row><cell>Capped mean</cell><cell>91.46</cell><cell>88.76</cell><cell>90.72</cell><cell>89.43</cell><cell>80.60</cell></row><row><cell>Number of superhuman games</cell><cell>51</cell><cell>49</cell><cell>49</cell><cell>49</cell><cell>34</cell></row><row><cell>Mean</cell><cell cols="4">3003.73 2086.16 2413.12 1769.43</cell><cell>503.15</cell></row><row><cell>Median</cell><cell>832.50</cell><cell>592.83</cell><cell>819.56</cell><cell>483.39</cell><cell>132.17</cell></row><row><cell>40% Percentile</cell><cell>356.27</cell><cell>266.07</cell><cell>409.46</cell><cell>224.80</cell><cell>94.35</cell></row><row><cell>30% Percentile</cell><cell>202.49</cell><cell>174.19</cell><cell>190.96</cell><cell>150.21</cell><cell>80.04</cell></row><row><cell>20% Percentile</cell><cell>133.93</cell><cell>120.84</cell><cell>126.10</cell><cell>118.36</cell><cell>57.95</cell></row><row><cell>10% Percentile</cell><cell>83.79</cell><cell>37.19</cell><cell>59.09</cell><cell>44.14</cell><cell>32.74</cell></row><row><cell>5% Percentile</cell><cell>20.87</cell><cell>12.74</cell><cell>20.56</cell><cell>7.75</cell><cell>2.85</cell></row><row><cell cols="6">new self-supervised objective, Representation Learning via Invariant Causal Mechanisms (RELIC),</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">See(Peters et al.,  </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2017" xml:id="foot_1">) for a review of causal graphs and causality 2 Since neither content nor style are a priori known, choosing a set of augmentations implicitly defines which aspects of the data are considered style and which are content.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">Note that since refinements are more fine-grained that the original task, if a representation captures a refinement then it also captures the downstream tasks as strictly more information is needed to solve the refinement.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">The set of augmentations includes Gaussian blurring, various colour distortions, flips and random cropping.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning representations by maximizing mutual information across views</title>
		<author>
			<persName><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Buchwalter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="15509" to="15519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The arcade learning environment: An evaluation platform for general agents (extended abstract)</title>
		<author>
			<persName><forename type="first">G</forename><surname>Marc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yavar</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Naddaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName><surname>Bowling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eleventh annual conference on Computational learning theory</title>
				<meeting>the eleventh annual conference on Computational learning theory</meeting>
		<imprint>
			<date type="published" when="1998">2013. 1998</date>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="92" to="100" />
		</imprint>
	</monogr>
	<note>Avrim Blum and Tom Mitchell. Combining labeled and unlabeled data with co-training</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Unsupervised learning of visual features by contrasting cluster assignments</title>
		<author>
			<persName><forename type="first">M</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<idno>ArXiv, abs/2006.09882</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Krzysztof</forename><surname>Chalupka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederick</forename><surname>Eberhardt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.2309</idno>
		<title level="m">Visual causal feature learning</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05709</idno>
		<title level="m">A simple framework for contrastive learning of visual representations</title>
				<imprint>
			<date type="published" when="2020">2020a</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Improved baselines with momentum contrastive learning</title>
		<author>
			<persName><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<idno>ArXiv, abs/2003.04297</idno>
		<imprint>
			<date type="published" when="2020">2020b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On the evolution of random graphs</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Erdős</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alfréd</forename><surname>Rényi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Publ. Math. Inst. Hung. Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="60" />
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The elements of statistical learning</title>
		<author>
			<persName><forename type="first">Jerome</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Springer series in statistics</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Domain adaptation with conditional transferable components</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Frieze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michał</forename><surname>Karoński ; Mingming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tongliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dacheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clark</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="2839" to="2848" />
		</imprint>
	</monogr>
	<note>Introduction to random graphs</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Bootstrap your own latent: A new approach to self-supervised learning</title>
		<author>
			<persName><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florent</forename><surname>Altché</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Pierre H Richemond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaohan</forename><surname>Avila Pires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Daniel Guo</surname></persName>
		</author>
		<author>
			<persName><surname>Gheshlaghi Azar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07733</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Noise-contrastive estimation: A new estimation principle for unnormalized statistical models</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</title>
				<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
				<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.05722</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Conditional variance penalties and domain shift robustness</title>
		<author>
			<persName><forename type="first">Christina</forename><surname>Heinze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-Deml</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolai</forename><surname>Meinshausen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.11469</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Data-efficient image recognition with contrastive predictive coding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Olivier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Hénaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName><surname>Van Den Oord</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.09272</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Benchmarking neural network robustness to common corruptions and perturbations</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
				<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">The many faces of robustness: A critical analysis of out-of-distribution generalization</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Dorundo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tyler</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samyak</forename><surname>Parajuli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Guo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.16241</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karan</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.06670</idno>
		<title level="m">Learning deep representations by mutual information estimation and maximization</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno>ArXiv, abs/1502.03167</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multi-view regression via canonical correlation analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dean</forename><forename type="middle">P</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computational Learning Theory</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="82" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Recurrent experience replay in distributed reinforcement learning</title>
		<author>
			<persName><forename type="first">Steven</forename><surname>Kapturowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Ostrovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Dabney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Remi</forename><surname>Munos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Iclr</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Revisiting self-supervised visual representation learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="1920" to="1929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Image augmentation is all you need: Regularizing deep reinforcement learning from pixels</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Kostrikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.13649</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multi-view predictive partitioning in high dimensions</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Mcwilliams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Montana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Analysis and Data Mining: The ASA Data Science Journal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="304" to="321" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Correlated random features for fast semi-supervised learning</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Mcwilliams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joachim</forename><forename type="middle">M</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="440" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Representation learning with contrastive predictive coding</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Causal inference by using invariant prediction: identification and confidence intervals</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bühlmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolai</forename><surname>Meinshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="947" to="1012" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Elements of causal inference: foundations and learning algorithms</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">On variational bounds of mutual information</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5171" to="5180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Regularization with stochastic transformations and perturbations for deep semi-supervised learning</title>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehran</forename><surname>Javanmardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tolga</forename><surname>Tasdizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1163" to="1171" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A theoretical analysis of contrastive unsupervised representation learning</title>
		<author>
			<persName><forename type="first">Nikunj</forename><surname>Saunshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orestis</forename><surname>Plevrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrishikesh</forename><surname>Khandeparkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5628" to="5637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">On causal and anticausal learning</title>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eleni</forename><surname>Sgouritsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joris</forename><surname>Mooij</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1206.6471</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Fixmatch: Simplifying semi-supervised learning with consistency and confidence</title>
		<author>
			<persName><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ekin D Cubuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.07685</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">An information theoretic framework for multi-view learning</title>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Sridharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sham</surname></persName>
		</author>
		<author>
			<persName><surname>Kakade</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Aravind</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Laskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.04136</idno>
		<title level="m">Curl: Contrastive unsupervised representations for reinforcement learning</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">What makes for good views for contrastive learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yonglong Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilip</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><surname>Isola</surname></persName>
		</author>
		<idno>ArXiv, abs/2005.10243</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">On mutual information maximization for representation learning</title>
		<author>
			<persName><forename type="first">Josip</forename><surname>Michael Tschannen</surname></persName>
		</author>
		<author>
			<persName><surname>Djolonga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Paul K Rubenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName><surname>Lucic</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.13625</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Learning robust global representations by penalizing local predictive power</title>
		<author>
			<persName><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Songwei Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><forename type="middle">Chase</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><surname>Lipton</surname></persName>
		</author>
		<idno>ArXiv, abs/1905.13549</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.12848</idno>
		<title level="m">Unsupervised data augmentation</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Large batch training of convolutional networks</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Gitman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Ginsburg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.03888</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
