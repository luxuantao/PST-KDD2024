<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Creating probabilistic databases from duplicated data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2009-08-20">20 August 2009</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Oktie</forename><surname>Hassanzadeh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Renée</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
							<email>miller@cs.toronto.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">D</forename><surname>Cd</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Creating probabilistic databases from duplicated data</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2009-08-20">20 August 2009</date>
						</imprint>
					</monogr>
					<idno type="MD5">BDD76EFBF71021DA9C4109A6251DC58C</idno>
					<idno type="DOI">10.1007/s00778-009-0161-2</idno>
					<note type="submission">Received: 14 September 2008 / Revised: 10 June 2009 / Accepted: 26 June 2009 /</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Probabilistic databases</term>
					<term>Duplicate detection</term>
					<term>String databases</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A major source of uncertainty in databases is the presence of duplicate items, i.e., records that refer to the same real-world entity. However, accurate deduplication is a difficult task and imperfect data cleaning may result in loss of valuable information. A reasonable alternative approach is to keep duplicates when the correct cleaning strategy is not certain, and utilize an efficient probabilistic query-answering technique to return query results along with probabilities of each answer being correct. In this paper, we present a flexible modular framework for scalably creating a probabilistic database out of a dirty relation of duplicated data and overview the challenges raised in utilizing this framework for large relations of string data. We study the problem of associating probabilities with duplicates that are detected using stateof-the-art scalable approximate join methods. We argue that standard thresholding techniques are not sufficiently robust for this task, and propose new clustering algorithms suitable for inferring duplicates and their associated probabilities. We show that the inferred probabilities accurately reflect the error in duplicate records.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The presence of duplicates is a major concern for the quality of data in large databases. To detect duplicates, entity resolution, also known as duplication detection or record linkage is used as a part of the data-cleaning process to identify records that potentially refer to the same entity. Numerous deduplication techniques exist to normalize data and remove erroneous records <ref type="bibr" target="#b41">[42]</ref>. However, in many real-world applications accurately merging duplicate records and fully eliminating erroneous duplicates is still a very human-labor intensive process. Furthermore, full deduplication may result in the loss of valuable information.</p><p>An alternative approach is to keep all the data and introduce a notion of uncertainty for records that have been determined to potentially refer to the same entity. Such data would naturally be inconsistent, containing sets of duplicate records. Various methodologies exist with different characteristics for managing uncertainty and inconsistency in data <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b50">51]</ref>. A large amount of previous work addresses the problem of efficient query evaluation on probabilistic databases in which it is assumed that meaningful probability values are assigned to the data in advance. Given these probabilities, a query can return answers together with a probability of the answer being correct, or alternatively return the top-k most likely answers. For such approaches to work over duplicate data, the record probabilities must accurately reflect the error in the data.</p><p>To illustrate this problem, consider the dirty relations of Fig. <ref type="figure">1</ref>. To assign probabilities, we must first understand which records are potential duplicates. For large data sets, a number of scalable approximate join algorithms exist which return pairs of similar records and their similarity scores (e.g., <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b37">38]</ref>). Given the result of an approximate join, we can group records into sets of potential duplicates using a number of 123 Fig. <ref type="figure">1</ref> A sample dirty database with Company, Product and Price relations techniques. The most simple technique is to group all records whose similarity is within some threshold value. We show that using simple thresholding with such techniques to determine groups (clusters) of duplicates often results in poor accuracy. This is to be expected as thresholding does not take into account the characteristics of the data or the duplicate detection task. To overcome this, we consider existing and new scalable clustering algorithms that are designed to produce high-quality clusterings even when the number of clusters is unknown.</p><p>In Fig. <ref type="figure">1</ref>, the clustering is indicated by the cluster identifier in the cid attribute. Records that share a cluster identifier are potential duplicates. Once a clustering is determined, we consider how to generate probabilities. For our uncertainty model, we adopt the model of Andritsos et al. <ref type="bibr" target="#b1">[2]</ref> and Dalvi and Suciu <ref type="bibr" target="#b21">[22]</ref> called disjoint-independent databases. In this model, tuples within a cluster (potential duplicates) are mutually disjoint. Tuples in different clusters are independent. This reflects the intuition that errors are introduced for different (real-world) entities independently. So, the probability that t 1 (from Cluster c 1 ) is in the clean (deduplicated) database is independent of the probability of t 8 (from Cluster c 2 ) being in the clean database. An important motivation for our choice of uncertainty model is that efficient queryanswering techniques are known for large classes of queries over such databases, which is important since keeping duplicate information is only worthwhile if it can be queried and used effectively in decision making. As further motivation, the probabilistic databases we create can be used as input to query evaluation techniques which model clustering uncertainty (that is the uncertainty introduced by the clustering process itself) <ref type="bibr" target="#b9">[10]</ref>. We elaborate on this in Sect. 2.4.</p><p>We also consider clustering techniques that produce overlapping clusters. In this approach, records that have been assigned to multiple clusters are no longer independent. Such probabilistic databases require more complex query-processing techniques which might be supported by the lineage mechanisms of systems like Trio <ref type="bibr" target="#b50">[51]</ref> or world-set semantics of MayBMS <ref type="bibr" target="#b2">[3]</ref>.</p><p>To assign probabilities within a cluster, we follow the common wisdom in uncertain data management which has noted that record probabilities are mostly internal to the system and useful primarily for ranking answers <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b42">43]</ref>. Hence, in this work, we do not consider different probability distributions within clusters, but focus instead on assigning confidence scores that accurately reflect the error in the records. That is, among a set of duplicate records, a record with less error should have a lower probability than a record containing more error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Outline and contributions</head><p>In this paper, we propose a flexible modular framework for scalably creating a probabilistic database out of a dirty relation of duplicated data (Sect. 2). This framework consists of three separate components. The input to the first component is a base relation R and the output of the third component is a probabilistic relation. Our framework complements and extends some existing entity resolution and approximate join algorithms, permitting their results to be used in a principled way within a probabilistic database management system. We study this framework for the case of string data, where the input relation consists of duplicated string records and no additional information exists or is usable to enhance the deduplication process. This in fact is the case in many real-world problems.</p><p>For each component of our framework, we briefly overview the state-of-the-art (Sects. 2.1-2.3) to further describe the characteristics of our framework in comparison with other deduplication techniques. We also present a detailed discussion of query evaluation over probabilistic databases focusing on how the probabilistic databases we create can be used. We justify the scalability and adaptability of our framework and the need for thorough evaluation of the performance of each component. We perform this evaluation using a methodology (summarized in Sect. 2.5) heavily based on existing evaluation methods.</p><p>We present an overview of several string similarity measures used in state-of-the-art similarity join techniques and benchmark the accuracy of these measures in our framework (Sect. 3). Unlike previous comparisons, we focus on measures useful for duplicate detection <ref type="bibr" target="#b32">[33]</ref>. Given pairs of similar records, we present several clustering algorithms for string data suitable for our framework (Sect. 4).</p><p>We address the problem of assigning probabilities (confidence scores) to records within each cluster that naturally reflect the relative error in the record (Sect. 5). We present several algorithms based on a variety of well-performing similarity measures for strings, and an algorithm using the information bottleneck method <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b46">47]</ref> which assigns probabilities based on the relative information content of records within a cluster.</p><p>An important characteristic of our framework is its modularity with components that are reusable for other cleaning tasks. Hence, we thoroughly benchmark each component individually to evaluate the effectiveness of different techniques in terms of both accuracy and running time. For each component, we present a summary of the results of extensive experiments which used many datasets with different characteristics to ensure that our framework is robust. We used several existing and some novel measures of accuracy in our evaluations. We also present an end-to-end evaluation of the components when used together for creating a probabilistic database.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Framework</head><p>Figure <ref type="figure">2</ref> shows the components of our framework. The input to this framework is a base relation R and the output is a probabilistic relation. In this work, we focus on creating a framework using scalable algorithms that do not rely on a specific structure in the input relation R. There are duplicate detection algorithms that can take advantage of other types of input such as co-citation or co-occurrence information <ref type="bibr" target="#b12">[13]</ref>. Such information may be available in bibliographic co-citation data or in social networks. However, we do not consider these specialized algorithms as such information is often not present in the data.</p><p>An important characteristic of our framework is its modularity. This makes our framework adaptable to other data-cleaning tasks. As new deduplication techniques are developed, they may replace one or both of our first two components. Moreover, if the input relation contains additional information that can be used to enhance the accuracy of deduplication, these different methods may be used. Furthermore, by dividing the system into three separate modules, we are able to evaluate the performance of each module individually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Similarity join</head><p>The first component of the system is the similarity join module. The input to this module is a relation R = {r i : 1 ≤ i ≤ N }, and the output is a set of pairs (r i , r j ) ∈ R×R where r i Fig. <ref type="figure">2</ref> Components of the framework and r j (i &lt; j) are similar and a similarity score for each pair. In existing join approaches, two records are considered similar when their similarity score based on a similarity function sim() is above a threshold θ . Many join methods typically model records as strings. We denote by r the set of q-grams (sequences of q consecutive characters of a string) in r . For example, for t = 'db lab', t = {'d','db', 'b' ,'l','la', 'ab', 'b'} for tokenization using 2-grams. <ref type="foot" target="#foot_0">1</ref> In certain cases, a weight may be associated with each token.</p><p>Similarity join methods use a variety of different similarity measures for string data <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b30">31]</ref>. Recently, there has been an increasing interest in using measures from the information retrieval field <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b44">45]</ref>. In <ref type="bibr" target="#b30">[31]</ref>, several such similarity measures are introduced and benchmarked for approximate selection where the goal is to sort the tuples in a relation based on their similarity with a query string. The extension of approximate selection to approximate join is not considered. Furthermore, the effect of threshold values on accuracy for approximate joins is also not considered. To fill in this gap, we show that the performance of the similarity predicates in a similarity join is slightly different (than in selection) mainly due to the effect of choosing a single threshold for matching all the tuples as opposed to ranking the tuples and choosing a different threshold for each selection query.</p><p>Our work is motivated by the recent advancements that have made similarity join algorithms highly scalable. Signature-based approaches (e.g., <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b44">45]</ref>) address the efficiency and scalability of similarity joins over large datasets. Many techniques are proposed for set-similarity join, which can be used along with qgrams for the purpose of (string) similarity joins, and are mostly based on the idea of creating signatures for sets (strings) to reduce the search space. Some signature generation schemes are derived from dimensionality reduction. One efficient approach uses the idea of Locality Sensitive Hashing <ref type="bibr" target="#b35">[36]</ref> in order to hash similar sets into the same values with high probability and, therefore, provides an approximate solution. Arasu et al. <ref type="bibr" target="#b3">[4]</ref> proposed algorithms specifically for set-similarity joins that are exact and outperform previous approximation methods in their framework, although parameters of the algorithms require extensive tuning. More recent work <ref type="bibr" target="#b7">[8]</ref> proposes algorithms based on novel indexing and optimization strategies that do not rely on approximation or extensive parameter tuning and outperform previous state-of-the-art approaches. One advantage of our approach is that all these techniques can be applied to make this first component of the framework scalable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Clustering</head><p>The clustering module outputs a set of clusters of records c 1 , . . . , c k where records in each cluster are highly similar and records in different clusters are more dissimilar. Most of the data-clustering algorithms assume that clusters are disjoint, i.e., c i ∩ c j = ∅ for all i, j ∈ 1 . . . k. We will also present algorithms for a model in which clusters are not disjoint, i.e., records may be present in two or more clusters. This makes sense for the duplication detection problem where it may be impossible to allocate a record with certainty to a single cluster. Record t 8 in the database of Fig. <ref type="figure">1</ref> is an example of such a record where there may be uncertainty as to whether t 8 belongs to cluster c 2 or c 1 .</p><p>Given our framework, we consider clustering techniques that do not require as input the number of clusters. There is a large body of work on clustering, including the use of clustering for information retrieval <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b33">34]</ref> and record linkage <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b40">41]</ref>. We consider existing and new techniques that do not require input parameters such as the number of clusters. In this sense, our motivation is similar to the use of generative models and unsupervised clustering in entity resolution <ref type="bibr" target="#b13">[14]</ref>. Notably however, we are dealing with large datasets and scalability is an important goal. Moreover, as noted earlier, our evaluation is based on the assumption that structural or co-occurrence information does not exist or such information cannot effectively be used to enhance deduplication. The only input to our clustering component is the result of a similarity join, i.e., the similar pairs and the similarity scores between them. Our algorithms will generally be linear in this input, with the exception that some techniques will require sorting of this input.</p><p>Therefore, we do not consider relational clustering algorithms or any of the new generative clustering models. Notably, algorithms like latent dirichlet allocation (LDA) <ref type="bibr" target="#b13">[14]</ref> are not scalable at present. For example, one recent promising application of LDA to entity resolution requires hours of computation on relatively small data sets of less than 10,000 entities <ref type="bibr" target="#b11">[12]</ref>.</p><p>The majority of existing clustering algorithm that do not require the number of clusters as input <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b49">50]</ref> do not meet the requirements of our framework. Specifically, they may require another parameter to be set by the user and/or they may be computationally expensive and far from practical. There are other clustering algorithms that produce nondisjoint clusters, like Fuzzy C-Means <ref type="bibr" target="#b10">[11]</ref>, but like K-Means they require the number of clusters. We refer the reader to <ref type="bibr" target="#b24">[25]</ref> and references therein for details of numerous clustering algorithms used for duplicate detection. A thorough experimental comparison of diverse clustering algorithms from the Information Retrieval, Machine Learning, and Data Management literature can be found elsewhere <ref type="bibr" target="#b31">[32]</ref>. These include the disjoint algorithms presented in this paper (Sect. 4), as well as algorithms not considered here, like correlation clustering and its optimizations <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b22">23]</ref> that were shown to not perform well (or not better than those we consider) for the duplicate detection task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Creating a probabilistic database</head><p>The final component of our framework creates a probabilistic database. Managing uncertainty and inconsistency has been an active research topic for a long time. Various methodologies exist with different characteristics that handle uncertainty and inconsistency in a variety of applications <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b50">51]</ref>. A large amount of previous work addresses the problem of efficient query evaluation on databases in which it is assumed that a probability value is assigned to each record in the database beforehand. The vast majority of approaches do not address the problem of creating probabilistic databases. A common assumption is that the probabilities reflect the reliability of the data source, for example, based on the reliability of the device (e.g. RFID sensor) that generates the data or statistical information about the reliability of a web data source. The Price relation in Fig. <ref type="figure">1</ref> is an example of such database, where it is assumed that there is an existing knowledge about the reliability of the data sources that provide the prices.</p><p>Andritsos et al. <ref type="bibr" target="#b1">[2]</ref> propose a method for creating a probabilistic database for duplicated categorical data. In categorical data, the similarity between two attribute values is either 0 (if the values are different) or 1 (if the values are the same). They first cluster the relation using a scalable algorithm based on the Agglomerative Information Bottleneck <ref type="bibr" target="#b46">[47]</ref>, and then assign a probability to each record within a cluster that represents the probability of that record being in the clean database. However, they do not evaluate the accuracy of the probabilities assigned. The Andritsos et al. <ref type="bibr" target="#b1">[2]</ref> work creates a database with row-level uncertainty (probabilities are associated with records). Gupta and Sarawagi <ref type="bibr" target="#b28">[29]</ref> present a method for creating a probabilistic database with both row-and column-level uncertainty from statistical models of structure extraction. In structure extraction, unlike duplicate detection, there is uncertainty about not only the correctness/existence of a record, but also the correctness of attribute values within each record.</p><p>Dalvi and Suciu <ref type="bibr" target="#b20">[21]</ref> propose an online approach for generating the probabilities in which the SQL queries are allowed to have approximate equality predicates that are replaced at execution time by a user defined MATCH() operator. Accurate and efficient implementation of a MATCH() operator is not a trivial task as partly shown in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Query evaluation</head><p>An important motivation for our work is the increased value that can be found from effectively modeling duplicates and their uncertainty. To realize this value, we must be able to query and use the database we create. Consider again our example of Fig. <ref type="figure">1</ref>. It may be possible to normalize (or standardize) the names of companies and their location by, for example, choosing one common convention for representing cities. However, in other attributes there may be true disagreement on what the real value should be. For the first company (Altera), we do not know how many employees (emp#) it has. By keeping all values and using some of the query-answering techniques described in this subsection, we can still give users meaningful answers to queries. For example, if we want to find small companies (with less than 1000 employees), we know not to return Altera. If we want to know the total number of employees in New York, we can again use our assigned probabilities to give probabilities for the possible answers to this query.</p><p>In this subsection, we briefly discuss several queryprocessing techniques suitable for probabilistic databases generated by our framework. We begin with a recent proposal for modeling and querying possible repairs in duplicate detection. We then discuss two other proposals that have considered efficient query evaluation on the specific probabilistic database we create (that is disjoint-independent databases). We then consider techniques for top-k query evaluation on probabilistic databases along with a new proposal for using probabilistic information (of the type we can create) to help in data cleaning. Finally, we describe a simple extension to our framework to create databases with attribute-level uncertainty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Querying repairs of duplicate data</head><p>Beskales et al. <ref type="bibr" target="#b9">[10]</ref> present an uncertainty model for representing the possible clusterings generated by any fixed parametrized clustering algorithm, as well as efficient techniques for query evaluation over this model. Any probabilistic database generated by our framework can be viewed as a duplication repair in this model. Their approach provides a way of modeling clustering uncertainty on top of our probabilistic databases. Hence, their queries use both the probabilities we assign and in addition account for possible uncertainty in the clustering itself (e.g., uncertainty in the assignment of tuples to clusters). Their model is based on the notion of U-Clean relations. A U-Clean relation R c of an unclean relation R is defined as a set of c-records. A c-record is a representative record of a cluster along with two additional attributes C and P. The attribute C of a c-record is the set of record identifiers in R that are clustered together to form the c-record, and the attribute P is the parameter settings of the clustering algorithm A that leads to the generation of the cluster C. In Beskales et al. <ref type="bibr" target="#b9">[10]</ref>, possible parameter values are represented using a continuous random variable τ , and P is an interval for τ that results in C. Here, we consider possible parameter values as a discrete random variable θ , and P as the set of thresholds θ used for the similarity join component that results in the cluster C. Let θ l denote the lower bound and θ u denote the upper bound for the threshold. For many string similarity joins, θ l = 0 and θ u = 1. Applying A to the unclean relation R with parameter θ , generates a possible clustering of R, denoted by A(R, θ).</p><p>Consider again the Company relation in the dirty database of Fig. <ref type="figure">1</ref>. Assume that any threshold less than or equal to 0.3 results in one clusters {t 1 , t 2 , t 3 , t 4 , t 5 , t 6 , t 7 , t 8 }, threshold θ = 0.4 results in two clusters {t 1 , t 2 , t 3 , t 4 , t 8 } and {t 5 , t 6 , t 7 }, and any threshold above 0.4 and below 0.7 results in two clusters {t 1 , t 2 , t 3 , t 4 } and {t 4 , t 5 , t 6 , t 7 }. Figure <ref type="figure" target="#fig_0">3</ref> shows the C and P attributes of the corresponding U-Clean relation.</p><p>The set of all clusterings χ is defined as {A(R, θ) : θ ∈ {θ l , . . . , θ u }}. Let function f θ (t) be the probability that t is the suitable parameter setting. The probability of a specific clustering X ∈ χ , denoted Pr(X ), is derived as follows:</p><formula xml:id="formula_0">Pr(X ) = θ u t=θ l f θ (t) • h(t, X )<label>(1)</label></formula><p>where h(t, X ) = 1 if A(R, t) = X , and 0 otherwise. In our framework, the function f θ (t) can be derived by manual inspection of a possibly small subset of the clustering results, and calculating (and normalizing) the quality measures presented in Sect. 4.3 over a subset of the data using different thresholds. Efficient algorithms are proposed in <ref type="bibr" target="#b9">[10]</ref> for evaluation of Selection, Projection, Join (SPJ), and aggregation queries. Moreover, an extension of this model is presented in which the uncertainty in merging the clusters (or choosing the representative record for each cluster) is also considered. Our probability assignment component (Sect. 5) can be used to generate such U-Clean relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Clean answers over duplicated data</head><p>This approach, presented by Andritsos et al. <ref type="bibr" target="#b1">[2]</ref>, requires a probabilistic database with row-level uncertainty, where probabilities are assigned in a way such that for each i ∈ 1 . . . k, t∈C i prob(t) = 1. Such a database is referred to as a dirty database. The probability values reflect the probability of the record being the best representation of the real entity. Even if the database does not contain a completely clean record, such a database can be used for accurate query answering.</p><p>Consider the example dirty database in Fig. <ref type="figure">1</ref>. This database consists of three dirty relations: Company with original schema Company(tid, name, emp#, hq), Product with original schema Product(pid, product, tidFk) and Price with original schema Price(tid, product, price). Two new attributes are introduced in all the relations: cid for the identifier of the clustering produced by the clustering component, and prob for the tuple probabilities. In relation Product, a new attribute cidFk is introduced for the identifier of the company referenced by Product.tidFk. The values of this attribute are updated using a process called identifier propagation which runs after the clustering phase and adds references to the cluster identifiers of the tuples in all the relations that refer to those tuples.</p><p>A candidate database D cd for the dirty database D is defined as a subset of D that for every cluster c i of a relation in D, there is exactly one tuple t from c i such that t is in D cd . Candidate databases are related to the notion of possible worlds, which has been used to give semantics to probabilistic databases. Notice, however, that the definition of candidate database imposes specific conditions on the tuple probabilities: the tuples within a cluster must be exclusive events, in the sense that exactly one tuple of each cluster appears in the clean database, and the probabilities of tuples from different clusters are independent. For the example database in Fig. <ref type="figure">1</ref> without the relation Price, the candidate databases are:</p><p>Clearly, not all the candidate databases are equally likely to be clean. This is modeled with a probability distribution, which assigns to each candidate database a probability of being clean. Since the number of candidate databases may be huge (exponential in the worst case), the distribution is not given by extension. Instead, probabilities of each tuple are used to calculate the probability of a candidate database being the clean one. Since tuples are chosen independently, the probability of each candidate database can be obtained as the product of the probability of each of its tuples: Pr(D cd ) = t∈D cd prob(t). Although the clean database is not known, a query can be evaluated by being applied to the candidate databases. Intuitively, a result is more likely to be in the answer if it is obtained from candidates with higher probability of being clean. A clean answer to a query q is, therefore, defined as a tuple t such that there exists a candidate database D cd such that t ∈ q(D cd ). The probability of t is: p =</p><formula xml:id="formula_1">D cd :t∈q(D cd ) Pr(D cd ).</formula><p>The clean answers to a query can be obtained directly from the definition if we assume that the query can be evaluated for each candidate database. However, this is an unrealistic assumption due to the potentially huge number of candidate databases. Andritsos et al. <ref type="bibr" target="#b1">[2]</ref> propose a solution to this problem by rewriting the SQL queries to queries that can be applied directly on the dirty database in order to obtain the clean answers along with their probabilities. The following two examples illustrate this approach.</p><p>Example 1 Consider a query q 1 for the dirty database in Fig. <ref type="figure">1</ref> that retrieves all the companies that have at least 5K employees.</p><p>Company cluster c 1 has more than 5K employees in all the candidate databases and, therefore, is a clean answer with probability 1. The cluster c 2 , however, has at least 5K employees only in the candidate databases that include tuple t 8 . The probability of this candidate database is 0.184. The following re-written query returns the clean answers along with their probability values.</p><p>select cid, sum(prob) from company where emp# &gt;= 5K group by cid</p><p>The previous example focuses on a query with just one relation. However, as shown in the next example, the rewriting strategy can be extended to queries involving foreign key joins.</p><p>Example 2 Consider a query q 2 for the dirty database in Fig. <ref type="figure">1</ref> that selects the products and the companies for those companies that have at most 5K employees.</p><p>The product cluster c 4 associated with company cluster c 2 appears in every candidate database and the employee count of c 2 is always at most 5K . Therefore, (c 4 , c 2 ) has probability 1 of being a clean answer. The query answer (c 3 , c 2 ) appears only in the result of applying the query q2 to the candidate databases that include tuples t 8 and p 2 (D cd 33 , D cd 34 , D cd 35 and D cd 36 ), and sum of their probabilities is 0.064. (c 3 , c 1 ) does not appear in any of the candidate databases and, therefore, is not a clean answer (i.e., has probability zero). It is easy to see that the clean answers can be obtained by the following rewriting of the query. The above rewriting strategy works only for a certain class of queries. Let q be a select-project-join (SPJ) query. The identifier of a relation is defined as the attribute containing the cluster id (which identifies the tuples which are duplications). The join graph G of q is defined as a directed graph such that the vertices of G are the relations used in q, and there is an arc from R i to R j if a non-identifier attribute of R i is equated with the identifier attribute of R j . Andritsos et al. <ref type="bibr" target="#b1">[2]</ref> define an SPJ query q with join graph G as a rewritable query if (1) all the joins involve the identifier of at least one relation (2) G is a tree (3) a relation appears in the from clause at most once, and (4) the identifier of the relation at the root of G appears in the select clause. These conditions rule out, for example, joins that do not involve an identifier attribute and queries that are cyclic or contain self joins.</p><p>Dalvi and Suciu <ref type="bibr" target="#b21">[22]</ref> present a theoretical study of the problem of query evaluation over dirty databases (also known as disjoint independent databases). They present a dichotomy for the complexity of query evaluation for queries without self-joins: evaluating every query is either PTIME or #P-hard. #P-hard queries are called hard queries and are in one of the following forms (the underlined attributes are the keys of the relations):</p><p>-</p><formula xml:id="formula_2">h 1 = R(x), S(x, y), T (y) -h 2 = R(x, y), . . . , R k (x, y), S(y) -h 3 = R(x, y), . . . , R k (x, y), S 1 (x, y), . . . , S m (x, y)</formula><p>The hardness of any conjunctive query without self-joins follows from a reduction from one of these three queries. Any query that is not hard (#P-hard) is referred to as safe and can be evaluated in PTIME.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.3">Top-k query evaluation</head><p>The problem of evaluating top-k query results on probabilistic databases has been studied in previous work <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b47">48]</ref>. Different types of top-k queries are possible for uncertain data. Consider the following queries over the dirty database of Fig. <ref type="figure">1:</ref> -Find the location of the headquarters of companies that have a product selling for more than $300, return only the top k locations (ranked according to their probabilities). -Find the top k most expensive products.</p><p>-Find the companies that have the k most expensive products (ranking based on the price in all the possible worlds).</p><p>Here again, these queries can be answered by materializing all the candidate databases, obtaining answers for each candidate database, and aggregating the probabilities of identical answers, which could be prohibitively expensive because of the huge number of candidate databases. For evaluation of the first query, the fact that the user is interested only in the top 3 most probable answers can be used to make the query evaluation more efficient. Ré et al. <ref type="bibr" target="#b42">[43]</ref> present an approach for generating the top-k probable query answers using Monte-Carlo simulation. In this approach, the top k answers of a SQL query (according to their probabilities) are returned, and their probabilities are approximated only to the extent needed to compute their ranking. Although the probabilities are approximate, the answers are guaranteed to be the correct k highest ranked answers. The queries considered in this work are of the following form:</p><p>Fig. <ref type="figure">4</ref> The sample dirty database of Fig. <ref type="figure">1</ref> with attribute-level uncertainty</p><formula xml:id="formula_3">TOP k SELECT B, agg 1 (A 1 ), agg 2 (A 2 ), • • • FROM R WHERE C GROUP BY B</formula><p>The aggregate operators can be sum, count, min and max; avg is not supported.</p><p>The other type of top-k query requires finding the top k tuples according to their price values (or some other scoring function). The second and third queries above are examples of such queries. Soliman et al. <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b48">49]</ref> present a single framework for processing both score and uncertainty leveraging current DBMS storage and query-processing capabilities. Their work is based on an uncertainty model that includes generation rules, which are arbitrary logical formulas that determine the valid worlds. Tuples that are not correlated using generation rules are independent. Such a model is particularly useful for duplicate detection. The disjointness (mutual exclusion) of tuples within clusters can be expressed using generation rules. In addition, two clusters can share a single tuple with a generation rule that states that the shared tuple cannot be present in both clusters. Therefore, for the example database in Fig. <ref type="figure">1</ref> where there may be uncertainty as to whether t 8 belongs to cluster c 2 or c 1 , it is possible to include a new tuple t 8 in cluster c 1 which has the same values as tuple t 8 , using the generation rule (t 8 ⊕ t 8 ) which means that both tuples cannot be present in a single candidate database. This model makes it possible to use the non-disjoint clustering algorithms we propose in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.4">Cleaning with quality guarantees</head><p>Another interesting application of uncertain data management for duplicate detection is cleaning the data in order to increase the quality of certain query results. Cheng et al. <ref type="bibr" target="#b18">[19]</ref> recently proposed a framework for this purpose. In their work, they present the PWS-quality metric, which is a universal measure that quantifies the level of ambiguity of query answers under the possible world's semantics. They provide efficient methods for evaluating this measure for two classes of queries:</p><p>-Non-rank-based queries, where a tuple's qualification probability is independent of the existence of other tuples. For example, range queries, i.e., queries that return a set of tuples having an attribute value that is in a certain range. -Rank-based queries, where a tuple's qualification probability depends on the existence of other tuples, such as MAX query which is the main focus of the techniques in this framework.</p><p>Using the PWS-quality, a set of uncertain objects in the database can be chosen to be cleaned by the user, in order to achieve the best improvement in the quality of query answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.5">Attribute-level uncertainty</head><p>We have limited our discussions so far to databases with tuple-level (row-level) uncertainty. It is also possible to use the probability assignment methods we present in this paper to create databases with attribute-level (column-level) uncertainty. This can be done easily by applying our techniques to each attribute individually (essentially applying our techniques to a column-store version of the database). Figure <ref type="figure">4</ref> shows such a database for the sample dirty relations in Fig. <ref type="figure">1</ref>.</p><p>Relations with attribute-level uncertainty can either be transformed to several relations with tuple-level uncertainty and be used along with one of the query evaluation techniques described in this section, or they can be stored and queried in more efficient frameworks designed for efficient handling of attribute-level uncertainty <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b45">46]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Evaluation framework</head><p>To generate datasets for our experiments, we use an enhanced version of the UIS database generator which has been effectively used in the past to evaluate duplicate detection algorithms and has been made publicly available <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b34">35]</ref>. We follow a relatively standard methodology of using the data generator to inject different types and percentages of errors to a clean database of string attributes. The erroneous records made from each clean record are put in a single cluster (which we use as ground truth) in order to be able to measure quality (precision and recall) of the similarity join and clustering modules. The generator permits the creation of data sets of varying sizes, error types and distributions and thus is a very flexible tool for our evaluation. The types of typographical errors injected by the data generator are based on studies on common errors present in string data in real database <ref type="bibr" target="#b36">[37]</ref>. Therefore, the synthetic datasets resemble real dirty databases, but allow thorough evaluation of the results based on robust quality measures.</p><p>Our data generator provides the following parameters to control the error injected in the data:</p><p>-the size of the dataset to be generated -the fraction of clean records to be utilized to generate erroneous duplicates -distribution of duplicates: the number of duplicates generated for a clean record can follow a uniform, Zipfian or Poisson distribution. -percentage of erroneous duplicates: the fraction of duplicate records in which errors are injected by the data generator. -extent of error in each erroneous record: the percentage of characters that will be selected for injecting character edit error (character insertion, deletion, replacement or swap) in each record selected for error injection. -token swap error: the percentage of word pairs that will be swapped in each record that is selected for error injection.</p><p>We use two different clean sources of data: a data set consisting of company names and a data set consisting of titles from DBLP. Statistical details for the two datasets are shown in Table <ref type="table" target="#tab_0">1</ref>. Note that we can generate reasonably large datasets out of these clean sources. For the company name dataset, we also inject domain-specific abbreviation errors, e.g., replacing Inc. with Incorporated and vice versa. We describe the characteristics of the specific datasets generated for evaluating each component (parameters used to create datasets) in the related sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Similarity join module</head><p>There are a large number of similarity functions for string data. The choice of the similarity function highly depends on the characteristics of the datasets. In what follows, we briefly describe the similarity measures that are suitable for our framework. Since one of our main goals in this work is scalability, we only consider those similarity measures that could have efficient implementation. Our contribution in this section is benchmarking accuracy of these measures in order to choose the measure with highest performance for this framework. <ref type="foot" target="#foot_1">2</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Similarity measures</head><p>The similarity measures that fit in our framework are those based on q-grams created out of strings along with a similarity measure that has been shown to be effective in previous work. The measures discussed here share one or both of the following properties.</p><p>-High scalability: There are various techniques proposed in the literature as described in Sect. 2.1 for enhancing the performance of the similarity join operation using q-grams along with these measures. -High accuracy: Previous work has shown that these measures perform better or equally well in terms of accuracy when compared with other string similarity measures. Specifically, these measures have shown good accuracy in name-matching tasks <ref type="bibr" target="#b19">[20]</ref> or in approximate selection <ref type="bibr" target="#b30">[31]</ref>. We include these measures to compare their accuracy to the scalable measures. The results of our experiments show that some highly scalable measures outperform other highly accurate but non-scalable measures in terms of accuracy on the approximate join task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Edit similarity</head><p>Edit-distance is widely used as the measure of choice in many similarity join techniques. Specifically, previous work <ref type="bibr" target="#b27">[28]</ref> has shown how to use q-grams for an efficient implementation of this measure in a declarative framework. Recent work on enhancing performance of similarity join has also proposed techniques for scalable implementation of this measure <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b37">38]</ref>.</p><p>Edit distance between two string records r 1 and r 2 is defined as the transformation cost of r 1 to r 2 , tc(r 1 , r 2 ), which is equal to the minimum cost of edit operations applied to r 1 to transform it to r 2 . Edit operations include character insert (inserting a new character in r 1 to transform it into r 2 , delete (deleting a character from r 1 for the transformation) and substitute (substitute a character in r 1 with a new character for the transformation) <ref type="bibr" target="#b29">[30]</ref>. The edit similarity is defined as</p><formula xml:id="formula_4">sim edit (r 1 , r 2 ) = 1 - tc(r 1 , r 2 ) max{|r 1 |, |r 2 |} (2)</formula><p>There is a cost associated with each edit operation. There are several cost models proposed for edit operations for this measure. The most commonly used measure called Levenshtein edit distance, which we will refer to as edit distance in this paper, uses unit cost for all the operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Jaccard and weighted Jaccard</head><p>Jaccard similarity is the fraction of tokens in r 1 and r 2 that are present in both. Weighted Jaccard similarity is the weighted version of Jaccard similarity, i.e., sim WJaccard (r 1 , r 2 ) = t∈r 1 ∩r 2 w R (t)</p><formula xml:id="formula_5">t∈r 1 ∪r 2 w R (t)<label>(3)</label></formula><p>where w R (t) is a weight function that reflects the commonality of the token t in the relation R. We choose a slightly modified form of the inverse document frequency (IDF) weights based on the Robertson/Sparck-Jones (RSJ) weights for the tokens which was shown to be effective in our experiments and in previous work <ref type="bibr" target="#b30">[31]</ref>:</p><formula xml:id="formula_6">w R (t) = log N -n t + 0.5 n t + 0.5 (<label>4</label></formula><formula xml:id="formula_7">)</formula><p>where N is the number of tuples in the base relation R and n t is the number of tuples in R containing the token t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Measures from IR</head><p>A well-studied problem in information retrieval is the problem of finding the documents that are the most relevant to a query. In the measures for this problem, records are treated as documents and q-grams are seen as words (tokens) of the documents. Therefore, the same techniques for finding relevant documents to a query can be used to return similar records to a query string. In the rest of this subsection, we present three measures that have been shown to have higher performance for the approximate selection problem <ref type="bibr" target="#b30">[31]</ref>. Note that IR models may be asymmetric, but we are able to still use them since we are using self-joins for duplicate detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cosine w/tf-idf</head><p>The tf-idf cosine similarity is a well-established measure in the IR community which leverages the vector space model. This measure determines the closeness of the input strings r 1 and r 2 by first transforming the strings into unit vectors and then measuring the angle between their corresponding vectors. The cosine similarity with tf-idf weights is given by</p><formula xml:id="formula_8">sim Cosine (r 1 , r 2 ) = t∈r 1 ∩r 2 w r 1 (t) • w r 2 (t)<label>(5)</label></formula><p>where w r 1 (t) and w r 2 (t) are the normalized tf-idf weights for each common token in r 1 and r 2 , respectively. The normalized tf-idf weight of token t in a given string record r is defined as follows:</p><formula xml:id="formula_9">w r (t) = w r (t) t ∈r w r (t ) 2 , w r (t) = t f r (t) • id f (t)</formula><p>where t f r (t) is the term frequency of token t within string r and id f (t) is the inverse document frequency with respect to the entire relation R.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BM25</head><p>The BM25 similarity score for a query r 1 and a string record r 2 is defined as follows:</p><formula xml:id="formula_10">sim BM25 (r 1 , r 2 ) = t∈r 1 ∩r 2 ŵr 1 (t) • w r 2 (t)<label>(6)</label></formula><p>where</p><formula xml:id="formula_11">ŵr 1 (t) = (k 3 + 1) • t f r 1 (t) k 3 + t f r 1 (t) w r 2 (t) = w (1) R (t) (k 1 + 1) • t f r 2 (t) K (r 2 ) + t f r 2 (t)</formula><p>w ( <ref type="formula" target="#formula_0">1</ref>)</p><formula xml:id="formula_12">R (t) = log N -n t + 0.5 n t + 0.5 K (r ) = k 1 (1 -b) + b |r | avg rl</formula><p>and t f r (t) is the frequency of the token t in string record r , |r | is the number of tokens in r , avg rl is the average number of tokens per record, N is the number of records in the relation R, n t is the number of records containing the token t and k 1 , k 3 and b are set of independent parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hidden Markov model</head><p>The approximate string matching could be modeled by a discrete Hidden Markov process which has been shown to have better performance than Cosine w/tfidf in the IR literature <ref type="bibr" target="#b39">[40]</ref> and high accuracy and low running time for approximate selection <ref type="bibr" target="#b30">[31]</ref>. This particular Markov model consists of only two states where the first state models the tokens that are specific to one particular "String" and the second state models the tokens in "General English", i.e., tokens that are common in many records. A complete description of the model and possible extensions are presented elsewhere <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b39">40]</ref>.</p><p>The HMM similarity function accepts two string records r 1 and r 2 and returns the probability of generating r 1 , given r 2 is a similar record:</p><formula xml:id="formula_13">sim HMM (r 1 , r 2 ) = t∈r 1 (a 0 P(t|G E) + a 1 P(t|r 2 )) (<label>7</label></formula><formula xml:id="formula_14">)</formula><p>where a 0 and a 1 = 1-a 0 are the transition state probabilities of the Markov model and P(t|G E) and P(t|r 2 ) is given by P(t|r 2 ) = number of times t appears in r 2 |r 2 | P(t|G E) = r ∈R number of times t appears in r r ∈R |r|</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4">Hybrid measures</head><p>The implementation of these measures involves two similarity functions, one that compares the strings by comparing their word tokens and another similarity function which is more suitable for short strings and is used for comparison of the word tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GES</head><p>The generalized edit similarity (GES) which is a modified version of fuzzy match similarity <ref type="bibr" target="#b15">[16]</ref>, takes two strings r 1 and r 2 , tokenizes the strings into a set of words and assigns a weight w(t) to each token. GES defines the similarity between the two given strings as a minimum transformation cost required to convert string r 1 to r 2 and is given by</p><formula xml:id="formula_15">sim GES (r 1 , r 2 ) = 1 -min tc(r 1 , r 2 ) wt (r 1 ) , 1.0<label>(8)</label></formula><p>where wt (r 1 ) is the sum of weights of all tokens in r 1 and tc(r 1 , r 2 ) is the minimum cost of a sequence of the following transformation operations:</p><p>-token insertion: inserting a token t in r 1 with cost w(t).c ins where c ins is the insertion factor constant and is in the range between 0 and 1. In our experiments, c ins = 1. -token deletion: deleting a token t from r 1 with cost w(t).</p><p>-token replacement: replacing a token t 1 by t 2 in r 1 with cost (1sim edit (t 1 , t 2 )) • w(t) where sim edit is the editdistance between t 1 and t 2 .</p><p>SoftTFIDF SoftTFIDF is another hybrid measure proposed by Cohen et al. <ref type="bibr" target="#b19">[20]</ref>, which relies on the normalized tf-idf weight of word tokens and can work with any arbitrary similarity function to find the similarity between word tokens. In this measure, the similarity score is defined as follows:</p><formula xml:id="formula_16">sim SoftTFIDF (r 1 , r 2 ) = t 1 ∈C(θ,r 1 ,r 2 ) w(t 1 , r 1 ) • w(arg max t 2 ∈r 2 (sim(t 1 , t 2 )), r 2 ) • max t 2 ∈r 2 (sim(t 1 , t 2 ))<label>(9)</label></formula><p>where w(t, r ) is the normalized tf-idf weight of word token t in record r and C(θ, r 1 , r 2 ) returns a set of tokens t 1 ∈ r 1 such that for t 2 ∈ r 2 we have sim(t 1 , t 2 ) &gt; θ for some similarity function sim() suitable for comparing word strings. In our experiments, sim(t 1 , t 2 ) is the Jaro-Winkler similarity as suggested by Cohen et al. <ref type="bibr" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation</head><p>We only evaluate the accuracy of the similarity measures, since there has been several studies on the scalability of these measures, but little work studying the accuracy of the join operation. The accuracy is known to be dataset-dependent and there is no common framework for evaluation and comparison of accuracy of different similarity measures and techniques. This makes comparing their accuracy a difficult task. Nevertheless, we argue that it is possible to evaluate relative performance of different measures for approximate joins by using datasets containing different types of well-known quality problems such as typing errors and differences in notations and abbreviations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets</head><p>In order to evaluate the effectiveness of different similarity measures described in this section, we use the same datasets used in an evaluation of approximate selection <ref type="bibr" target="#b30">[31]</ref>.</p><p>As described in Sect. 2.5, the errors in these datasets include commonly occurring typing mistakes (edit errors, character insertion, deletion, replacement, and swap), token swap and abbreviation errors (e.g., replacing Inc. with Incorporated and vice versa). For the results presented in this section, the datasets are generated by the data generator out of the clean company names dataset described in Table <ref type="table" target="#tab_0">1</ref>.</p><p>The errors in the datasets have a uniform distribution. For each dataset, on average 5,000 dirty records are created out of 500 clean records. We have also run experiments on datasets generated using different parameters. For example, we generated data using a Zipfian distribution, and we also used data from the other clean source in Table <ref type="table" target="#tab_0">1</ref> (DBLP titles). We also created larger datasets. For these other datasets, the accuracy trends remain the same. Table <ref type="table" target="#tab_1">2</ref> shows the description of all the datasets used for the results in this paper. We used eight different datasets with mixed types of errors (edit errors, token swap and abbreviation replacement). Moreover, we used five datasets with only a single type of error (3 levels of edit errors, token swap or abbreviation replacement errors) to measure the effect of each type of error individually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Measures</head><p>We use well-known measures from IR, namely precision, recall, and F 1 , for different values of the threshold to evaluate the accuracy of the similarity join operation. We perform a self-join on the input table using a similarity measure with a fixed threshold θ . Precision (Pr) is defined as the percentage of duplicate records among the records that have a similarity score above the threshold θ . In our datasets, duplicate records are marked with the same cluster ID as described above. Recall <ref type="bibr">(Re)</ref> is the ratio of the number of duplicate records that have similarity score above the threshold θ to the total number of duplicate records. Therefore, a join that returns all the pairs of records in the two input tables as output has low (near zero) precision and recall of 1.</p><p>A join that returns an empty answer has precision 1 and zero recall. The F 1 measure is the harmonic mean of precision Settings For the measures based on q-grams, we set q = 2 since it yields the best accuracy in our experiments for all these measures. We use the same parameters for BM25 and HMM score formula that were suggested elsewhere <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b43">44]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Appendix A contains the full precision-recall curves for all the measures described above. The results of our experiments show that the "dirtiness" of the input data greatly affects the value of the threshold that results in the most accurate join. For all the measures, a lower value of the threshold is needed as the degree of error in the data increases. For example, Weighted Jaccard achieves the best F 1 score over the dirty group of datasets with threshold 0.3, while it achieves the best F 1 for the low-error datasets at threshold 0.55. BM25 and HMM are less sensitive and the best value of the threshold varies from 0.25 for dirty datasets to 0.3 for low-error datasets. We will discuss later how the degree of error in the data affects the choice of the most accurate measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of types of errors</head><p>Figure <ref type="figure">5</ref> shows the maximum F 1 score for different values of the threshold for different measures on datasets containing only edit-errors (the EDL, EDM and EDH datasets). These figures show that weighted Jaccard and Cosine have the highest accuracy followed by Jaccard, and edit similarity on the low-error dataset EDL. By increasing the amount of edit error in each record, HMM performs as well as weighted Jaccard, although Jaccard, edit similarity, and GES perform much worse on high edit error datasets. Considering the fact that edit-similarity is mainly proposed for capturing edit errors, this shows the effectiveness of weighted Jaccard and its robustness with varying amount </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 7</head><p>Maximum F 1 score for different measures on dirty, medium and low-error group of datasets of edit errors. Figure <ref type="figure">6</ref> shows the effect of token swap and abbreviation errors on the accuracy of different measures. This experiment indicates that edit similarity is not capable of modeling such errors. HMM, BM25 and Jaccard also are less capable of modeling abbreviation errors than cosine with tf-idf, SoftTFIDF and weighted Jaccard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison of measures</head><p>Figure <ref type="figure">7</ref> shows the maximum F 1 score for different values of the threshold for different measures on dirty, medium-and low-error datasets. Here, we have aggregated the results for all the dirty data sets together (respectively, the moderately dirty or medium data sets and the low-error data sets). The results show the effectiveness and robustness of weighted Jaccard and cosine in comparison with other measures. Again, HMM is among the most accurate measures when the data is extremely dirty, and has relatively low accuracy when the percentage of error in the data is low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Our choice of similarity measure</head><p>Unless specifically mentioned, we use weighted Jaccard similarity as the measure of choice for the rest of the paper due to its relatively high efficiency and accuracy compared with other measures. Note that this similarity predicate can be implemented declaratively and used as a join predicate in a standard RDBMS engine <ref type="bibr" target="#b30">[31]</ref>, or used with some of the specialized, high performance, approximate join algorithms as described in Sect. 2. Specifically, the Weighted Enumeration (WtEnum) signature generation algorithm can be used to significantly improve the running time of the join <ref type="bibr" target="#b3">[4]</ref>. In addition, novel indexing and optimization techniques can be utilized to make the join even faster <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Clustering module</head><p>Here, we consider algorithms for clustering records based on the output of the similarity join module. So the input to this module is a set of similar pairs of records and the output is a set of clusters of records C = {c 1 , . . . , c k } where records in each cluster are highly similar. We present two groups of algorithms, one for creating disjoint clusters, i.e., non-overlapping clusters that partition the base relation, and the other for non-disjoint clustering, i.e., we allow a few records to be present in two or more clusters. The scalable similarity join will eliminate large portions of the data (records without duplicates) from the clustering. Specifically, the similarity graph used in the clustering will be much smaller after using a similarity join. Of course, we want to be able to handle large amounts of error in the data, so we do also focus on clustering techniques that can still handle large data sets containing hundreds of thousands of potential duplicates. But the combination of a scalable similarity join, with a clustering technique that can handle large similarity graphs, greatly enhances the end-to-end scalability of the overall approach and permits the generation of probability values (Sect. 5) on very large databases.</p><p>There exists a variety of clustering algorithms in the literature each with different characteristics. However, as mentioned earlier, we are dealing with a rather different clustering problem here. First of all, we use only the output of the similarity join module for the clustering. Our goal of clustering is to create a probabilistic database and, therefore, we need to seek specific characteristics that fit this goal. For example, a few extra records in a cluster is preferable to a few missing records, since the few extra records will get less probability in the probability assignment component. Moreover, since the similarity join module needs a threshold for the similarity measure which is hard to choose and dataset-dependent, we seek clustering algorithms that are less sensitive to the choice of the threshold value. A comprehensive study of the performance of clustering algorithms in duplicate detection including the disjoint algorithms presented here and several more sophisticated clustering algorithms can be found elsewhere <ref type="bibr" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Disjoint algorithms</head><p>In this group of algorithms, the goal is to create clusters of similar records C = {c 1 , . . . , c k } where the value of k is unknown, c i ∈C c i = R and c i ∩ c j = ∅ for all c i , c j ∈ C, i.e., clusters are disjoint and partition the base relation.</p><p>We can think of the source relation as a graph G(U, V ) in which each node u ∈ U presents a record in the base relation and each edge (u, v) ∈ V connects two nodes u and v having corresponding records that are similar, i.e., their similarity score based on some similarity function sim() is above a specified threshold θ . Note that the graph is undirected, i.e., (u, v) = (v, u). The task of clustering the relation is then clustering the nodes in the graph. In our implementation, we do not materialize the graph. In fact, all the algorithms can be efficiently implemented by a single scan of the list of similar pairs returned by the similarity join module, although some require the list to be sorted by similarity score. We only use the graph G to illustrate our techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Algorithm1: partitioning</head><p>In this algorithm, Partitioning (or transitive closure), we cluster the graph of records by finding the connected components in the graph and putting the records in each component in a separate cluster. This can be done by first assigning each node to a different cluster and then scanning the list of similar pairs and merging clusters of all connected nodes. Figure <ref type="figure" target="#fig_2">8a</ref> shows the result of this algorithm on a sample graph. As Fig. <ref type="figure" target="#fig_2">8a</ref> shows, this algorithm may put many records that are not similar in the same cluster. Partitioning is a common algorithm used in early entity resolution work <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b34">35]</ref>, and is included as a baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Algorithm2: CENTER</head><p>This algorithm, which we call CENTER as in <ref type="bibr" target="#b33">[34]</ref> performs clustering by partitioning the graph of the records so that each cluster has a center and all records in the cluster are similar to the center. This can be performed by a single scan of the sorted list of similar pairs. The first time a node u appears in the scan, it is assigned as the center of the cluster. All the subsequent nodes v that appear in a pair (u, v) are assigned to the cluster of u and are not considered again. Figure <ref type="figure" target="#fig_2">8b</ref> shows how this algorithm clusters a sample graph of records, where node u 1 is the first node in the sorted list of similar records and node u 2 appears right after all the nodes similar to u 1 , and node u 3 appears after all the nodes similar to u2. This algorithm may result in more clusters than Partitioning since it puts into one cluster only those records that are similar to one record which is the center of the cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Algorithm3: MERGE-CENTER</head><p>MERGE-CENTER, or MC, is similar to CENTER, but merges two clusters c i and c j whenever a record similar to the center node of c j is already in the cluster c i , i.e., it is similar to a node that is the center or is similar to the center (or one of the center nodes) of the cluster c i (Note that when two clusters are merged, we do not choose a single center node in this algorithm, so each cluster can have multiple center nodes). As with CENTER, this is done using a single scan of the list of similar records, but keeping track of the records that are already in a cluster. The first time a node u appears in the scan, it is assigned as the center of the cluster. All the subsequent nodes v that appear in a pair (u, v) and are not present in any cluster, are assigned to the cluster of u, and are not selected as the center of any other cluster. Whenever a pair (u, v ) is encountered such that v is already in another cluster, all the nodes in the cluster of u (records similar to u) are merged with the cluster of v . Figure <ref type="figure" target="#fig_2">8c</ref> shows the clusters created by this algorithm assuming again that the nodes u 1 , u 2 and u 3 are the first three nodes in the sorted list of similar records that are selected as the center of a cluster. As shown in the Figure, this algorithm creates fewer clusters for the sample graph than the CENTER algorithm, but more than the partitioning algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Non-disjoint algorithms</head><p>In this group of algorithms, we do not require c i ∩ c j = ∅ for all i, j ∈ 1 . . . k. For this purpose, we use the results of the similarity join module along with the similarity scores of the similar records. The idea is to have a core for each cluster that consists of the records that are highly similar, and marginal records for each cluster that are relatively less similar. The core of the clusters are created based on the results of the similarity join with similarity score above a high threshold θ 1 . The marginal records are added to the clusters based on the results of the similarity join with a threshold θ 2 ≤ θ 1 . Using the terminology from probabilistic record linkage <ref type="bibr" target="#b25">[26]</ref>, we can say that we put the records that match with the center of the cluster in its core, and records that probably match with the center in the marginal records of the cluster. Each record appears in the core of only one cluster, but may appear in the marginal records of more than one cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Algorithm4: non-disjoint clustering</head><p>Our first non-disjoint algorithm, ND, creates a set of core clusters (in a similar way to MERGE-CENTER), and then a set of records are added to each cluster which are less similar to the center of the cluster. The algorithm performs as follows. Assume that we have the list of records with similarity score above a threshold θ 2 along with their similarity score from the output of the similarity join module. The algorithm starts by scanning the list. The first time a node u appears in the scan, it is assigned as the center of the core of the cluster. All the subsequent nodes v that appear in a pair (u, v), have sim(u, v) ≥ θ 1 , and are not present in the core of any other cluster, are assigned to the core of the cluster of u and are not selected as the center of any other cluster. Other pairs (u, v) that have sim(u, v) ≤ θ 1 (but have sim(u, v) ≥ θ 2 ) are added as the marginal members of the cluster. Whenever a pair (u, v ) with sim(u, v ) ≥ θ 1 is encountered such that v is already in the core of another cluster, all the nodes in the cluster of u are merged with the cluster of v .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Algorithm5: improved non-disjoint clustering with information bottleneck method</head><p>The ND algorithm performs well when thresholds θ 1 and θ 2 are chosen accurately. However, the choice of the thresholds highly depends on the similarity measure used in the similarity join module and the type of errors in the datasets.</p><p>Therefore, it is plausible to be able to choose a low value for the lower threshold θ 2 and then enhance the accuracy of the clustering by pruning extra records from each cluster in a uniform way regardless of the value of the thresholds. Here, we adopt an approach from the information theory field called the information bottleneck in order to enhance the results of non-disjoint clustering. The idea is to prune those marginal records in clusters that are less similar to the records in the core of the clusters. Our ND-IB algorithm is based on the Agglomerative Information Bottleneck (IB) algorithm for clustering data <ref type="bibr" target="#b46">[47]</ref> which we briefly explain here.</p><p>Assume R is the set of records, n = |R| is the number of records, T is the set of qgrams of the strings, and d = |T | is the total number of qgrams in all records. In the information bottleneck method for clustering data, the goal is to partition the records in R into k clusters C = {c 1 , c 2 , . . . , c k } where each cluster c i ∈ C is a non-empty subset of R such that c i ∩ c j = ∅ for all i, j. Giving equal weight to each record r ∈ R, we define p(r ) = 1 n . We also set the probability of a qgram t given a record p(t|r ) = id f (t) t ∈r id f (t ) where id f (t) is the inverse document frequency of qgram t in the relation. For c ∈ C, the elements of R, T and C are related as follows:</p><formula xml:id="formula_17">p(c) = r ∈c p(r ) (10) p(t|c) = 1 p(c) r ∈c p(r ) p(t|r )<label>(11)</label></formula><p>Merging two clusters c i and c j is performed by setting the following parameters for the new cluster c * :</p><formula xml:id="formula_18">p(c * ) = p(c i ) + p(c j ) p(t|c * ) = p(c i ) p(c * ) p(t|c i ) + p(c j ) p(c * ) p(t|c j )<label>(12)</label></formula><p>In the IB algorithm, clustering is performed by first assuming that each record is a separate cluster and then iteratively merging the clusters nk times to reduce the number of clusters to k. In each iteration, two clusters are chosen to be merged so that the amount of information loss as a result of merging the clusters is minimum. Information loss is given by the following formula <ref type="bibr" target="#b46">[47]</ref>:</p><formula xml:id="formula_19">δ I (c i , c j ) = [p(c i ) + p(c j )] • D J S [ p(t|c i ), p(t|c j )] (<label>13</label></formula><formula xml:id="formula_20">)</formula><p>where D J S [ p(t|c i ), p(t|c j )] is equal to:</p><formula xml:id="formula_21">p(c i ) p(c * ) D K L [ p(t|c i ), p] + p(c j ) p(c * ) D K L [ p(t|c i ), p]<label>(14)</label></formula><p>where:</p><formula xml:id="formula_22">p = p(c i ) p(c * ) p(t|c i ) + p(c j ) p(c * ) p(t|c j ) (<label>15</label></formula><formula xml:id="formula_23">)</formula><formula xml:id="formula_24">D K L [ p, q] = r ∈R p(r ) log p(r ) q(r )<label>(16)</label></formula><p>The pruning algorithm for our non-disjoint clustering performs as follows. For each cluster (1) the records in the core of the cluster are merged using the merge operation and put in cluster c core . (2) For each record r i in the set of marginal records M = {r 1 , . . . , r k }, the amount of information loss for merging r i with the core cluster c core , il i = δ I (r i , c core ), is calculated. (3) It is assumed that avg il is the average value of il i for i ∈ 1 . . . k and stddev il is the standard deviation.</p><p>Those marginal records that have il i ≥ avg ilstddev il are pruned from the cluster. The intuition behind this algorithm is that by using the information in all the qgrams of the records from the core of the cluster that are identified to be duplicates (and match), we can identify which of the marginal records (that probably match) are more probably duplicates that belong to that cluster. For this, the records in the core of each cluster are merged using the merge operation (Equation <ref type="formula" target="#formula_18">12</ref>). If merging a marginal record with the core of the cluster would result in high information loss, then the record is removed from the marginal records of the cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation</head><p>Datasets The datasets used for accuracy results in this section are the same datasets described in Table <ref type="table" target="#tab_0">1</ref> of Sect. 3.2. Most of the results presented here are for the medium error group of these datasets. In our evaluation, we note when the trends on the other groups of datasets are different than those shown in this report. Note again that we limited the size of the datasets only for our experiments on accuracy. For running time experiments, we used the data generator with DBLP titles dataset of Table <ref type="table" target="#tab_0">1</ref> to generate larger datasets. In order to show that these results are not limited to the specific datasets we used here, we have made the results of our extensive experiments over various datasets (with different sizes, types and distribution of errors) publicly available at http://dblab. cs.toronto.edu/project/stringer/evaluation/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Accuracy measures</head><p>We evaluate the quality of the clustering algorithms based on several measures from the clustering literature and also measures that are suitable for evaluation of these clusterings in duplicate detection. The latter measures are taken from Hassanzadeh et al. <ref type="bibr" target="#b31">[32]</ref>. Suppose that we have a set of k ground truth clusters G = {g 1 , . . . , g k } of the base relation R and let C denote a clustering of records into k clusters {c 1 , . . . , c k } produced by a clustering algorithm. Consider mapping f from elements of G to elements of C, such that each cluster g i is mapped to a cluster c j = f (g i ) that has the highest percentage of common elements with g i . We define precision, Pr i , and recall, Re i , for a cluster g i , 1 ≤ i ≤ k as follows:</p><formula xml:id="formula_25">Pr i = | f (g i ) ∩ g i | | f (g i )| and Re i = | f (g i ) ∩ g i | |g i |<label>(17)</label></formula><p>Intuitively, Pr i measures the accuracy with which cluster f (g i ) reproduces cluster g i , while Re i measures the completeness with which f (g i ) reproduces class g i . We define the precision and recall of the clustering as the weighted averages of the precision and recall over all ground truth clusters. More precisely</p><formula xml:id="formula_26">Pr = k i=1 |g i | |R| Pr i and Re = k i=1 |g i | |R| Re i<label>(18)</label></formula><p>Again, we also use the F 1 -measure (the harmonic mean of precision and recall). We think of precision, recall, and F 1 -measure as indicative values of the ability of the algorithm to reconstruct the indicated clusters in the dataset. However, since in our framework the number of clusters created by the clustering algorithm is not fixed and depends on the datasets and the thresholds used in the similarity join, we should also take into account this value in our quality measure. We use two other measures more suitable for our framework. The first, called clustering precision, CPr i , is the ratio of the pairs of records in each cluster c i that are in the same ground truth cluster g j :</p><formula xml:id="formula_27">c i = f (g j ), i.e., CPr i = |(t, s) ∈ c i × c i |t = s ∧ ∃ j ∈ 1 . . . k, (t, s) ∈ g j × g j | |c i | 2<label>(19)</label></formula><p>Clustering precision, CPr, is then the average of CPr i for all clusters with size ≥2. Cpr measures the ability of the clustering algorithm to put the records that must be in the same cluster in one cluster regardless of the number and the size of the clusters. We also need to have a measure that penalizes those algorithms that create more or fewer clusters than the ground truth number of clusters. PCPr is CPr multiplied by the percentage of the extra or missing clusters in the result of clustering, i.e.,</p><formula xml:id="formula_28">PCPr = k k CPr k &lt; k k k CPr k ≥ k (<label>20</label></formula><formula xml:id="formula_29">)</formula><p>Partitioning and CENTER algorithms We measure the quality of clustering algorithms based on different thresholds of the similarity join. The table below shows the values for our medium-error datasets and thresholds that result in the best F1 measure and the best PCPr measure values. We have chosen these thresholds to show how the threshold value could affect the accuracy of the algorithms, and also justify using the PCPr measure. Similar trends can be observed for other thresholds and datasets.</p><p>Partitioning Note that the number of clusters in the ground truth datasets is 500. The last row in the table shows the number of clusters generated by each algorithm. These results show that, precision, recall and F 1 measures cannot alone determine the best algorithm since they do not take into account the number of clusters generated. As it can be seen, the best value of F 1 measure among different thresholds is 0.910 for partitioning and 0.877 while the corresponding number of clusters are 994 and 1305 respectively. However, the best value of PCPr among different thresholds is 0.554 for partitioning and 0.593 for CENTER, with 353 and 472 clusters in the results respectively. This justifies using CPr and PCPr measures. Also note that the accuracy of these algorithms highly depend on the threshold used for the similarity join module. The results above show that the CENTER algorithm is more suitable than the partitioning algorithm for identification of the correct number of clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MERGE-CENTER (MC) algorithm</head><p>The accuracy results for the MERGE-CENTER algorithm for the medium error datasets are shown below. The results are for the similarity threshold that produced the best PCPr results although the trend is the same for both algorithms with any fixed threshold. These results show that the MC algorithm results in significant improvement in all accuracy measures comparing with CENTER and Partitioning algorithms.  answers with lower probability values. For these results, we set the threshold θ = 0.3 for MC, the lower threshold θ 2 = 0.2 and the higher threshold θ 1 = 0.4 for non-disjoint algorithms, and we use our low-error datasets. We observed a similar trend using many different thresholds and other datasets. In fact non-disjoint algorithms become more effective when used on highly erroneous datasets as partly shown in Fig. <ref type="figure" target="#fig_3">9</ref>. A key benefit of using the non-disjoint algorithm with information bottleneck (IB) is that the clustering algorithm becomes less sensitive to the value of the threshold used for the similarity join. In the above results, changing the threshold for the MC algorithm to θ = 0.4 results in a much higher PCPr but lower CPr score and setting θ = 0.2 results in a significant drop in PCPr but higher CPr. The last row shows the average number of clusters to which each record belongs, e.g., in the non-disjoint algorithm with the threshold used for the results in this table, each record is present in 3.3 clusters on average. As it can be seen, PCPr and CPr are slightly decreased but in return, the average number of clusters for each record is significantly decreased. This results in decreasing the overhead associated with having non-disjoint clusters as well as increasing the precision of the clustering. Effect of amount of error In order to show the effect of the amount of error in the datasets on the accuracy of the algorithms, we measure the CPr score of all the clustering algorithms, with threshold θ = 0.5 for disjoint algorithms and lower threshold θ 2 = 0.3 and higher threshold θ 1 = 0.5 for non-disjoint algorithms. Figure <ref type="figure" target="#fig_3">9</ref> shows the results. For all datasets, the relative performance of the algorithms remains the same. All algorithms perform better on lower error datasets. MERGE-CENTER algorithm becomes more effective on cleaner datasets comparing with Partitioning and CEN-TER algorithms. Non-disjoint algorithms become less effective on cleaner datasets mainly due to higher accuracy of the disjoint algorithm with the threshold used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Partitioning</head><formula xml:id="formula_30">MC ND ND-IB θ = 0.3 θ 1 = 0.4, θ 1 = 0.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance results</head><p>We ran our experiments using a Dell 390 Precision desktop with 2.66 GHz Intel Core2 Extreme Quad-Core Processor QX6700, 4 GB of RAM running 32-bit Windows Vista. Each experiment is run multiple times to obtain statistical significance. Figures <ref type="figure">10</ref> and<ref type="figure">11</ref> show the running time of the disjoint and non-disjoint algorithms. These results are obtained from DBLP datasets of size 10-100 K records. The average percentage of erroneous duplicates is 50%, and the average percentage of errors in each duplicate record, the average amount of token swaps, and the average amount of abbreviation errors is 30%. For disjoint algorithms, a fix threshold of θ = 0.5 is chosen for the similarity join and for non-disjoint algorithms lower threshold of θ = 0.4 and higher threshold of θ = 0.6 is chosen, although we observed a similar trend with many other threshold values. As expected, the Partitioning algorithm is the fastest in disjoint algorithms since it does not need the output of the similarity join to be sorted. CEN-TER and MERGE-CENTER both require the output to be sorted, and MERGE-CENTER has an extra merge operation which makes it a little slower than CENTER. The results for non-disjoint algorithms show that the overhead for the information bottleneck pruning makes the algorithm 5-10 times slower, but still reasonable for an offline process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Probability assignment module</head><p>Assuming that the records in the base relation R are clustered using a clustering technique, the output of the probability assignment module is a probabilistic database in which each record has a probability value that reflects the error in the record. We present two classes of algorithms here. One based on the similarity score between the records in each cluster, and the other based on information theory concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Algorithms</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MaxSim Algorithm</head><p>In this algorithm, first a record in each cluster is chosen as the representative of a cluster and then the probability value is assigned to each record that reflects the similarity between the record and the cluster representative. This algorithm is based on the assumption that there exists a record in the cluster that is clean (has no errors) or has less errors, and that this record is the most similar record to other records in the cluster. Therefore, this record is chosen as the cluster representative and the probability of the other records being clean is proportional to their similarity score with the cluster's representative.</p><p>Figure <ref type="figure" target="#fig_5">12</ref> shows the generic procedure for finding probabilities in this approach. For each cluster, the record that has the maximum sum of similarity score with all other records in the cluster (based on some similarity function sim()) is chosen as the cluster representative. The probability assigned to each record is basically the similarity score between the representative and the record, normalized for each cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Information bottleneck method</head><p>Here, we present a technique for assigning probability values to records within each cluster based on the Information Bottleneck (IB) approach. While similar in spirit to the method of Andritsos et al. <ref type="bibr" target="#b1">[2]</ref>, our method is designed specifically for dirty string data. Assume again that R is the set of all records, T is the set of qgrams of the records, C is the set of all the clusters and T c i is the set of all qgrams in the records inside cluster c i ∈ C. Giving equal weight to each record r ∈ R, we define p(r ) = 1 n . The probability of a qgram given a record can be set as p(t|r ) = 1  |r | (equal values, as shown in the example below) or p(t|r ) = id f (t) t ∈r id f (t ) (based on importance of the tokens, which is our choice for the experiments). For c ∈ C, the elements of R, T and C are related by Eqs. 10 and 11 in Sect. 4. Merging two clusters c i and c j is performed by the merge operation using Eq. 12 (Sect. 4).</p><p>Figure <ref type="figure" target="#fig_0">13</ref> shows the steps involved in this algorithm. To find a cluster representative for cluster c i , we merge the records in the cluster using the merge operation. The result is the probability distribution p(t|c i ) for all qgrams t ∈ T c i . We define the cluster representative to be (T c i , p(t|c i )), i.e., the set of all the qgrams of the records in the cluster c i along with their probability values p(t|c i ). Note that a cluster representative does not necessarily consist of qgrams of a single record in that cluster. The probability value for each record in the cluster is basically the sum of the values of the probabilities p(t|c i ) for the qgrams in the record r divided by the length of the record, normalized so that the probabilities of the records inside a cluster sum to 1. The intuition behind this algorithm is that by using the information from all the q-grams in the cluster, a better cluster representative can be found. This is based on the assumption that in the cluster c i , the q-grams that belong to a "clean" record are expected to appear more in the cluster and therefore have a higher p(t|c i ) Fig. <ref type="bibr" target="#b13">14</ref> Example IB representative calculation value. As a result, the records containing q-grams that are frequent in the cluster (and are more likely to be clean) will have higher probability values.</p><p>Example 3 Suppose R is a set of four strings r 1 = "William Turner", r 2 = "Willaim Turner", r 3 = "Willliam Turnet", and r 4 = "Will Turner" in a cluster. Figure <ref type="figure">14</ref> shows the initial p(t|r ) values for each record r and q-gram t, as well as the final probability distribution values for the cluster representative. <ref type="foot" target="#foot_2">3</ref> The output of the algorithm is p c (r 1) = 0.254, p c (r 2) = 0.240, p c (r 3) = 0.233 and p c (r 4) = 0.272.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation</head><p>Measure We evaluate the effectiveness of the probability assignment techniques by introducing a measure that shows how sorting by the assigned probability values will preserve the correct order of the error in the records. We call this measure order preserving ratio (OPR). OPR is calculated as follows. For each cluster, we create an ordered list of records L output = (r 1 , . . . , r k ) sorted by the probability values assigned to the records, i.e., p a (r i ) ≤ p a (r j ) iff i ≤ j where p a (r ) is the probability value assigned to the record r . Suppose the correct order of the records is L correct and the true probability value of the record r being the clean one is p t (r ). We can measure the extent to which the sorted output list preserves the original order by counting the percentage of pairs (r i , r j ) for which r i appears before r j in both L output and L correct , i.e.,</p><formula xml:id="formula_31">OPR C = |(r i , r j )|r i , r j ∈ L output , i ≤ j, p t (r i ) ≤ p t (r j )| k 2<label>(21)</label></formula><p>Note that k 2 is the total number of pairs in L output . OPR is the average of OPR c -0.5 0.5 over all clusters. Since 0.5 is the average value of OPR c if the records are sorted randomly, OPR shows the extent to which the ordering by probabilities is better than a random ordering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We use the same data generator to create a dataset of strings with different amounts of error within the strings, marking each string with the percentage of error in that string which allows sorting the records based on the relative amount of error and obtaining the ground truth. We ran experiments on datasets with varying sizes and degree of error made out of the company names and DBLP titles datasets (Table <ref type="table" target="#tab_0">1</ref>). The trends observed are similar over all datasets. We report the results for a dataset containing 1000 clusters generated out of our clean company name dataset. Table <ref type="table" target="#tab_6">3</ref> shows the OPR values for this dataset for IB and MaxSim algorithm.</p><p>We have tried MaxSim with different string similarity functions described in Sect. 3 for similarity join module, namely Weighted Jaccard (WJaccard), SoftTfIdf, Generalized Edit Similarity (GES), Hidden Markov Models (HMM), BM25 and Cosine similarity with tf-idf weights (Cosine w/tfidf). Interestingly, MaxSim produces the best results when used with Weighted Jaccard similarity, the measure of our choice for the similarity join module described in Sect. 3. The IB algorithm performs as well as MaxSim with the best choice of similarity function in terms of accuracy. Table <ref type="table" target="#tab_6">3</ref> also shows the running time for these algorithms for a DBLP title dataset of 20K records. The trend is similar for larger datasets and the algorithms scale linearly. The IB algorithm is also significantly faster than MaxSim with weighted Jaccard. Another advantage of IB over the MaxSim algorithm is that the cluster representatives can be stored and updated very efficiently, but for the MaxSim algorithm, when a record is added to database, the algorithm must be run again to find the new representative. This makes the IB algorithm suitable for large dynamic databases, and also for on-line calculation of the probabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Putting it all together</head><p>In Sect. 4, we showed how the quality of the clusters is affected by the similarity measure and threshold used in the similarity join module. However, the results presented so far in this section are based on a perfect clustering as input to the probability assignment module. In this part, we will show the results of our experimental evaluation of the effect of the quality of the clusters on the quality of the probabilities. Our goal is to ensure that when creating a probabilistic database, the errors introduced in the first two modules (the clustering errors) do not compound the potential errors in our probability assignment module in a way that makes the final probabilities meaningless. Here again, we create an ordered list of records L = (r 1 , . . . , r k ) for each cluster c l ∈ C, sorted by the probability values assigned to the records, i.e., p a (r i ) ≤ p a (r j ) iff i ≤ j where p a (r ) is the probability value assigned to the record r . Let p t (r ∈ c l ) be the probability value of the record r being the ground truth cluster f (c l ) if t ∈ f (c l ) and zero otherwise. We can measure the extent to which the sorted output list preserves the original order in the matched ground truth cluster f (c l ) by counting the percentage of pairs (r i , r j ) for which at least one of r i and r j are in f (c l ), p t∈c (r i ) ≤ p t∈c (r j ) and r i appears before r j in L, i.e.,</p><formula xml:id="formula_32">|(r i , r j )|r i , r j ∈ L , i ≤ j, p t (r i ∈ c l ) ≤ p t (r j ∈ c l )| -e k 2 -e e = |(r i , r j )|r i , r j / ∈ f (c l )|</formula><p>This is based on the assumption that we are indifferent about the order of the records that are not in the matched ground truth cluster. OPR t is the average of the value calculated in the formula above over all output clusters in C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The table below shows OPR t values for the same dataset used for the results in The results above show that the quality of the clustering does affect the effectiveness of the probability assignment module. This effect is not significant when the clusters have higher accuracy. However, the quality of the probability values further decreases as the accuracy of the clustering decreases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Case study on real data</head><p>In this section, we report the results of applying our framework to a real-world dirty data source. In order to effectively evaluate our framework, we need a dirty data source that contains several possibly dirty attributes with duplicate clusters of various sizes and characteristics. Many real-world dirty data sources meet these requirements. Examples include the bibliographic data available on DBLP, CiteSeer and DBWorld, the clinical trial data available on ClinicalTrials.gov, shopping information on Yahoo! Shopping, and hotel information from Yahoo! Travel <ref type="bibr" target="#b8">[9]</ref>. For the experiments in this section, we use the Cora dataset <ref type="bibr" target="#b38">[39]</ref>, which contains computer science research papers integrated from several sources. It has been used in several other duplicate detection projects <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b38">39]</ref> and we take advantage of previous labelings of the tuples into clusters. To the best of our knowledge, Cora is the only real-world dirty database freely available for which the ground truth is known, and that meets the requirements for evaluation of this framework.</p><p>We use a version of Cora that is available in XML format, and transform the data into four relational tables: the pubstr table contains a single string attribute which is obtained by concatenation of the title, venue and author attributes, pubtitles which contains the titles of the publications, pubauthors that contains the author names, and pubvenues that contains the venue information including name, date, and volume number. The statistics of these tables are shown in Table <ref type="table" target="#tab_10">4</ref>.   Figure <ref type="figure">15</ref> shows the maximum F 1 score across different thresholds for all the similarity measures over the four tables. The relative performance of the similarity measures differs considerably for each of these tables. This is expected since (1) the attributes have different characteristics such as length, amount and type of errors, and (2) these tables are relatively small, and failure of an algorithm on a small subset the records can notably affect the average values of the accuracy measures. However, it can be seen that those algorithms that performed better in our experiments in Sect. 3 are more robust across the four tables. For example, the weighted Jaccard similarity measure performs reasonably well for all the four tables, although it is not the best measure for any of them. Note that again due to the small size of these tables, weighted measures do not perform as expected since the IDF weights over a small collection do not reasonably reflect the commonality of the tokens. We would not expect this to be the case for larger real-world dirty data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Clustering algorithms results</head><p>In order to compare the performance of clustering algorithms on the datasets, we again compare the maximum value of the F 1 score and PCPr that the algorithms can achieve using different thresholds. Figure <ref type="figure" target="#fig_7">16</ref> shows the results. All the clustering algorithms perform better on the pubstr and pubtitles tables. The reason for this is that for the pubauthors table, our framework's duplicate detection phase (i.e., a string similarity join along with a clustering algorithm) results in many false positives due to the existence of highly similar (or exactly equal) author names that refer to different real-world entities. The same is true for the pubvenues table. As stated in Sect. 2, previous work has addressed this problem by using more complex, iterative clustering algorithms that can take advantage of additional co-occurrence information existing in the data. However, the relative high quality of the clusters for pubstr table shows the effectiveness of our framework in detection of duplicate publications by a simple concatenation of all the attributes and without the use of co-occurrence information (indeed collective resolution has been developed precisely for highly ambiguous domains like author name).</p><p>If the same threshold is used for all the algorithms, CEN-TER produces clusters of much higher quality when used with a low threshold, while the trend for Partitioning is the opposite. MERGE-CENTER is more robust to the value of the threshold than both Partitioning and CENTER when the same threshold is used. Figure <ref type="figure" target="#fig_8">17</ref> shows this fact for pubstr table. Similar trends were observed in all other datasets.</p><p>The following table shows the effectiveness of the nondisjoint algorithms for the pubstr table. Again, similar trends were observed for the other tables. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Probability assignment</head><p>The evaluation of the probability assignment algorithms for this dataset is inherently a difficult task since the ground truth is not known (only the cluster labels are known). It is hard to determine the correct ordering of the records within each cluster. However, we have performed a qualitative evaluation of the results over the output probabilistic tables using simple queries similar to the queries in the examples of Sect. 2.4.2.</p><p>Overall results are consistent with the results shown in Sect. 5. Moreover, the results clearly show the advantage of the probabilistic approach for management of duplicated data, as opposed to cleaning the data upfront. As one example, we used a query retrieving conference title, volume and other information for conferences held in 1995. Over a cleaned database (where we have kept the most probable tuple in each cluster), the query results are less informative, sometimes omitting potentially valuable information about a conference that was contained in attribute values of lower probability tuples. However, using consistent query answering techniques <ref type="bibr" target="#b1">[2]</ref>, queries over our probabilistic database can report how much collective evidence there is (among all the tuples no matter how dirty) for different values. Our sample SQL queries, along with their rewritings obtained using the approach discussed in Sect. 2.4.2 <ref type="bibr" target="#b1">[2]</ref> and a subset of their results are available online at our project's web page: http:// dblab.cs.toronto.edu/project/stringer/evaluation/ Also, several probabilistic tables created from synthetic and real dirty databases using different thresholds and algorithms are published on the above page. We hope that these probabilistic databases can serve as a benchmark for evaluation of probabilistic data management techniques in the future. Our future plan includes extending the real datasets by, for example, hand labeling a subset of the clinical trials data we have gathered in our LinkedCT<ref type="foot" target="#foot_3">4</ref> project. This could provide probabilistic databases for management of duplicated data in an important real-world domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We proposed a framework for managing potentially duplicated data that leverages existing approximate join algorithms together with probabilistic data management techniques. Our approach consists of three phases: application of a (scalable) approximate join technique to identify the similarity between pairs of records; clustering of records to identify sets of records that are potential duplicates; and the assignment of a probability value to each record in the clusters that reflects the error in the record. We presented and benchmarked a set of scalable algorithms for clustering records based on their similarity scores and on their information content. We also introduced and evaluated algorithms for probability assignment.</p><p>The modularity of our framework makes it amenable for a variety of data-cleaning tasks. For example, in domains where aggregate constraints for deduplication are known <ref type="bibr" target="#b17">[18]</ref>, these constraints can replace our unsupervised clustering techniques, and our probability assignment methods can still be used to create a probabilistic database for querying and analysis.</p><p>Figures <ref type="figure" target="#fig_2">18</ref> and<ref type="figure" target="#fig_3">19</ref> show the precision, recall, and F 1 values for all measures described in Sect. 2, over the datasets we have defined with mixed types of errors. For all measures except HMM and BM25, horizontal axis of the precision/recall graph is the value of the threshold. For HMM and BM25, the horizontal axis is the percentage of maximum value of the threshold, since these measure do not return a score between 0 and 1. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 U</head><label>3</label><figDesc>Fig. 3 U-Clean relation created from the Company relation in the dirty database of Fig. 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>select p.cid, p.cidFk, sum(p.prob * c.prob) from company c, product p where p.cidFk = c.cid and c.emp# &lt;= 5K group by p.cid, c.cid</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 8</head><label>8</label><figDesc>Fig. 8 Illustration of disjoint clustering algorithms. a Partitioning, b CENTER, c MERGE-CENTER (MC)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 9</head><label>9</label><figDesc>Fig. 9 CPr score of clustering algorithms for datasets with different amount of error</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 10 Fig. 11</head><label>1011</label><figDesc>Fig. 10 Running time: disjoint algorithms</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 12</head><label>12</label><figDesc>Fig. 12 MaxSim algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Fig. 15 Maximum F 1 score for Cora datasets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 16</head><label>16</label><figDesc>Fig. 16 Accuracy of clustering algorithms on Cora dataset, a maximum F 1 score, b maximum PCPr score</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 17</head><label>17</label><figDesc>Fig.<ref type="bibr" target="#b16">17</ref> PCPr score for different thresholds on pubstr table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 18 Fig. 19</head><label>1819</label><figDesc>Fig.<ref type="bibr" target="#b17">18</ref> Accuracy of similarity join using edit-similarity, Jaccard and Weighted Jaccard measures relative to the value of the threshold on different datasets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Statistics of clean datasets</figDesc><table><row><cell>Dataset</cell><cell>#rec.</cell><cell>Avg. rec. length</cell><cell>#words/rec.</cell></row><row><cell>Company names</cell><cell>2,139</cell><cell>21.03</cell><cell>2.92</cell></row><row><cell>DBLP titles</cell><cell>10,425</cell><cell>33.55</cell><cell>4.53</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Datasets used for the results in this paper</figDesc><table><row><cell>Group</cell><cell cols="2">Name Percentage of</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Erroneous Errors in</cell><cell cols="2">Token Abbr.</cell></row><row><cell></cell><cell></cell><cell cols="3">duplicates duplicates swap</cell><cell>error</cell></row><row><cell>Dirty</cell><cell>D1</cell><cell>90</cell><cell>30</cell><cell>20</cell><cell>50</cell></row><row><cell></cell><cell>D2</cell><cell>50</cell><cell>30</cell><cell>20</cell><cell>50</cell></row><row><cell cols="2">Medium Error M1</cell><cell>30</cell><cell>30</cell><cell>20</cell><cell>50</cell></row><row><cell></cell><cell>M2</cell><cell>10</cell><cell>30</cell><cell>20</cell><cell>50</cell></row><row><cell></cell><cell>M3</cell><cell>90</cell><cell>10</cell><cell>20</cell><cell>50</cell></row><row><cell></cell><cell>M4</cell><cell>50</cell><cell>10</cell><cell>20</cell><cell>50</cell></row><row><cell>Low Error</cell><cell>L1</cell><cell>30</cell><cell>10</cell><cell>20</cell><cell>50</cell></row><row><cell></cell><cell>L2</cell><cell>10</cell><cell>10</cell><cell>20</cell><cell>50</cell></row><row><cell></cell><cell>AB</cell><cell>50</cell><cell>0</cell><cell>0</cell><cell>50</cell></row><row><cell>Single Error</cell><cell>TS</cell><cell>50</cell><cell>0</cell><cell>20</cell><cell>0</cell></row><row><cell></cell><cell>EDL</cell><cell>50</cell><cell>10</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell>EDM</cell><cell>50</cell><cell>20</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell>EDH</cell><cell>50</cell><cell>30</cell><cell>0</cell><cell>0</cell></row></table><note><p>and recall, i.e., F 1 = 2 × Pr × Re Pr + Re We measure precision, recall, and F 1 for different values of the similarity threshold 123 θ . For comparison of different similarity measures, we use the maximum F 1 score across different thresholds.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3</head><label>3</label><figDesc>OPR values/times for IB &amp; MaxSim algs</figDesc><table><row><cell>Algorithm</cell><cell></cell><cell>OPR</cell><cell>Time (ms)</cell></row><row><cell>IB</cell><cell></cell><cell>0.683</cell><cell>749</cell></row><row><cell>MaxSim</cell><cell>WJaccard</cell><cell>0.674</cell><cell>4324</cell></row><row><cell></cell><cell>SoftTfIdf</cell><cell>0.653</cell><cell>1280</cell></row><row><cell></cell><cell>GES</cell><cell>0.490</cell><cell>1249</cell></row><row><cell></cell><cell>HMM</cell><cell>0.485</cell><cell>3852</cell></row><row><cell></cell><cell>BM25</cell><cell>0.480</cell><cell>4009</cell></row><row><cell></cell><cell>Cosine w/tfidf</cell><cell>0.470</cell><cell>5397</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>MeasureWe need to slightly modify OPR to measure the quality of the probability values when the clustering is imperfect. We call this measure OPR t . Suppose that we have a set of k ground truth clusters G = {g 1 , . . . , g k } of the base relation R and let C denote a clustering of records into k clusters {c 1 , . . . , c k } produced by a clustering algorithm. Consider mapping f from elements of C to elements of G, such that each cluster c i is mapped to a cluster f (c i ) that has the highest percentage of common elements with c i .</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3 .</head><label>3</label><figDesc>The values are shown for a perfect clustering as well as clusters created by (disjoint) MERGE-CENTER algorithm performed on the output of similarity join with Weighted Jaccard similarity measure and different values of the similarity threshold, and using the IB algorithm for probability assignment. Similar trends were observed for other clustering algorithms. Moreover, the relative performance of IB and MaxSim algorithms remained the same as Table3and, therefore, we do not report OPR t values for them.</figDesc><table><row><cell>Similarity threshold</cell><cell>F1</cell><cell>PCPr</cell><cell cols="2">Cluster# OPR t</cell></row><row><cell>Perfect clustering</cell><cell cols="3">1.000 1.000 500</cell><cell>0.832</cell></row><row><cell>(No similarity join)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>θ = 0.1</cell><cell cols="2">0.008 0.004</cell><cell>2</cell><cell>0.571</cell></row><row><cell>θ = 0.2</cell><cell cols="2">0.479 0.389</cell><cell>259</cell><cell>0.655</cell></row><row><cell>θ = 0.3</cell><cell cols="2">0.726 0.335</cell><cell>934</cell><cell>0.713</cell></row><row><cell>θ = 0.4</cell><cell cols="3">0.724 0.118 1673</cell><cell>0.700</cell></row><row><cell>θ = 0.5</cell><cell cols="3">0.614 0.042 2370</cell><cell>0.625</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>15 Maximum F 1 score for Cora datasets</figDesc><table><row><cell></cell><cell>0.950</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.000</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.900</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.900</cell><cell></cell><cell></cell></row><row><cell>Maximum F1</cell><cell>0.650 0.700 0.750 0.800 0.850</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Maximum PCPr</cell><cell>0.500 0.600 0.700 0.800</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.600</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.400</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.550</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.300</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.500</cell><cell>pubstr</cell><cell>pubtitles</cell><cell>pubauthors</cell><cell>pubvenues</cell><cell></cell><cell>0.200</cell><cell>pubstr</cell><cell>pubtitles</cell><cell>pubauthors</cell><cell>pubvenues</cell></row><row><cell cols="2">Partitioning</cell><cell>0.897</cell><cell>0.877</cell><cell>0.729</cell><cell>0.664</cell><cell cols="2">Partitioning</cell><cell>0.839</cell><cell>0.900</cell><cell>0.551</cell><cell>0.526</cell></row><row><cell cols="2">CENTER</cell><cell>0.828</cell><cell>0.861</cell><cell>0.729</cell><cell>0.642</cell><cell cols="2">CENTER</cell><cell>0.866</cell><cell>0.877</cell><cell>0.342</cell><cell>0.322</cell></row><row><cell>MC</cell><cell></cell><cell>0.880</cell><cell>0.879</cell><cell>0.717</cell><cell>0.679</cell><cell>MC</cell><cell></cell><cell>0.919</cell><cell>0.889</cell><cell>0.477</cell><cell>0.363</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 4</head><label>4</label><figDesc>Statistics of the tables in Cora dataset</figDesc><table><row><cell>Dataset</cell><cell>#rec.</cell><cell>#clusters</cell><cell>Avg. len.</cell><cell>#words/rec.</cell></row><row><cell>pubstr</cell><cell>1, 878</cell><cell>185</cell><cell>118.22</cell><cell>17.76</cell></row><row><cell>pubtitles</cell><cell>1, 878</cell><cell>185</cell><cell>50.84</cell><cell>6.13</cell></row><row><cell>pubauthors</cell><cell>714</cell><cell>240</cell><cell>13.76</cell><cell>2.78</cell></row><row><cell>pubvenues</cell><cell>615</cell><cell>131</cell><cell>47.07</cell><cell>8.58</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>= 0.2 θ 1 = 0.1, θ 2 = 0.3 θ 1 = 0.1, θ 2 = 0.3</figDesc><table><row><cell></cell><cell>MC</cell><cell>ND</cell><cell></cell><cell>ND-IB</cell></row><row><cell></cell><cell cols="3">θ Diff.(MC)</cell><cell></cell><cell>Diff.(MC)</cell></row><row><cell>F1</cell><cell>0.789</cell><cell cols="2">0.756 -0.033</cell><cell cols="2">0.833 +0.043</cell></row><row><cell>PCPr</cell><cell>0.728</cell><cell cols="2">0.965 +0.238</cell><cell cols="2">0.952 +0.224</cell></row><row><cell>CPr</cell><cell>0.975</cell><cell cols="2">0.998 +0.022</cell><cell cols="2">0.984 +0.009</cell></row><row><cell cols="2">C./rec. 1.0</cell><cell>2.7</cell><cell>+1.7</cell><cell>1.8</cell><cell>+0.8</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Strings are first padded with whitespaces at the beginning and the end, then all whitespaces are replaced with q -1 occurrences of special unused symbol (e.g., a $).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>A presentation of the evaluation was given at the International Workshop on Quality in Databases<ref type="bibr" target="#b32">[33]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>We omit the initial and ending grams ' w', 't ', 'r ' to fit this on the page.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>http://linkedct.org.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments We thank Periklis Andritsos, Lise Getoor and Chen Li for their detailed reviews, insights, and support for this work. We also thank Mohammad Sadoghi and George Beskales for their helpful input.</p><p>Appendix A: A Similarity join evaluation: precision/recall curves</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Aggregating inconsistent information: ranking and clustering</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ailon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Charikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Symp. on Theory of Computing (STOC)</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="684" to="693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Clean answers over dirty databases: a probabilistic approach</title>
		<author>
			<persName><forename type="first">P</forename><surname>Andritsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fuxman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Proc. of the Int&apos;l Conf. on Data Eng</title>
		<imprint>
			<biblScope unit="page">30</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fast and simple relational processing of uncertain data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Antova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Olteanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. of the Int&apos;l Conf. on Data Eng</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="983" to="992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Efficient exact set-similarity joins</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arasu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ganti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kaushik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int&apos;l Conf. on Very Large Data Bases (VLDB)</title>
		<meeting>of the Int&apos;l Conf. on Very Large Data Bases (VLDB)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="918" to="929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Large-scale deduplication with constraints using dedupalog</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arasu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. of the Int&apos;l Conf. on Data Eng</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="952" to="963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The star clustering algorithm for static and dynamic information organization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pelekhov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Graph Algorithm. Appl</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="95" to="129" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Correlation clustering</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chawla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="89" to="113" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Scaling up all pairs similarity search</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Bayardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int&apos;l World Wide Web Conference (WWW)</title>
		<meeting><address><addrLine>Banff</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="131" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Swoosh: a generic approach to entity resolution</title>
		<author>
			<persName><forename type="first">O</forename><surname>Benjelloun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Garcia-Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Menestrina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Whang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Very Large Data Bases</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="255" to="276" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Modeling and querying possible repairs in duplicate detection</title>
		<author>
			<persName><forename type="first">G</forename><surname>Beskales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Soliman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">F</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<idno>CS-2009-15</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int&apos;l Conf. on Very Large Data Bases (VLDB)</title>
		<meeting>of the Int&apos;l Conf. on Very Large Data Bases (VLDB)</meeting>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
		<respStmt>
			<orgName>Available as University of Waterloo</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Report</note>
	<note>To Appear</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Pattern Recognition with Fuzzy Objective Function Algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bezdek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Dordrecht</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A latent dirichlet model for unsupervised entity resolution</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the SIAM International Conference on Data Mining (SDM)</title>
		<meeting>of the SIAM International Conference on Data Mining (SDM)<address><addrLine>Bethesda</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="47" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Collective entity resolution in relational data</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Eng. Bull</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="4" to="12" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">MYSTIQ: a system for finding more answers by using probabilities</title>
		<author>
			<persName><forename type="first">J</forename><surname>Boulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mandhani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mathur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Re</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Int&apos;l Conf. on the Mgmt. of Data</title>
		<imprint>
			<biblScope unit="page" from="891" to="893" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Robust and efficient fuzzy match for online data cleaning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ganjam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ganti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Int&apos;l Conf. on the Mgmt. of Data</title>
		<imprint>
			<biblScope unit="page" from="313" to="324" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Robust identification of fuzzy duplicates</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ganti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. of the Int&apos;l Conf. on Data Eng</title>
		<meeting><address><addrLine>Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="865" to="876" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Leveraging aggregate constraints for deduplication</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Das Sarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ganti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kaushik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Int&apos;l Conf. on the Mgmt. of Data</title>
		<imprint>
			<biblScope unit="page" from="437" to="448" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cleaning uncertain data with quality guarantees</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow. (PVLDB)</title>
		<meeting>VLDB Endow. (PVLDB)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="722" to="735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A comparison of string distance metrics for name-matching tasks</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Fienberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IJCAI-03 Workshop on Information Integration on the Web (IIWeb-03)</title>
		<meeting>of IJCAI-03 Workshop on Information Integration on the Web (IIWeb-03)<address><addrLine>Acapulco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="73" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Efficient query evaluation on probabilistic databases</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Very Large Data Bases</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="523" to="544" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Management of probabilistic data: foundations and challenges</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Int&apos;l Conf. on the Mgmt. of Data</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Correlation clustering in general weighted graphs</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Demaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Emanuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fiat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Immorlica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theor. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">361</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="172" to="187" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Data integration with uncertainty</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Halevy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int&apos;l Conf. on Very Large Data Bases (VLDB)</title>
		<meeting>of the Int&apos;l Conf. on Very Large Data Bases (VLDB)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="687" to="698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Duplicate record detection: a survey</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Elmagarmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Ipeirotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Verykios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Know. Data Eng</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A theory for record linkage</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">P</forename><surname>Fellegi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Sunter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">328</biblScope>
			<biblScope unit="page" from="1183" to="1210" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Graph clustering and minimum cut trees</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Flake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Tarjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tsioutsiouliklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internet Math</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="385" to="408" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Approximate string joins in a database (Almost) for free</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gravano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Ipeirotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Koudas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int&apos;l Conf. on Very Large Data Bases (VLDB)</title>
		<meeting>of the Int&apos;l Conf. on Very Large Data Bases (VLDB)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="491" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Creating probabilistic databases from information extraction models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int&apos;l Conf. on Very Large Data Bases (VLDB)</title>
		<meeting>of the Int&apos;l Conf. on Very Large Data Bases (VLDB)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="965" to="976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Algorithms on strings, trees, and sequences</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gusfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Science and Computational Biology</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Benchmarking Declarative Approximate Selection Predicates</title>
		<author>
			<persName><forename type="first">O</forename><surname>Hassanzadeh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007-02">February 2007</date>
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Framework for evaluating clustering algorithms in duplicate detection</title>
		<author>
			<persName><forename type="first">O</forename><surname>Hassanzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int&apos;l Conf. on Very Large Data Bases (VLDB)</title>
		<meeting>of the Int&apos;l Conf. on Very Large Data Bases (VLDB)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Accuracy of approximate string joins using grams</title>
		<author>
			<persName><forename type="first">O</forename><surname>Hassanzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sadoghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Workshop on Quality in Databases (QDB)</title>
		<meeting>of the International Workshop on Quality in Databases (QDB)<address><addrLine>Vienna</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Scalable techniques for clustering the web</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Haveliwala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gionis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Indyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int&apos;l Workshop on the Web and Databases (WebDB)</title>
		<meeting>of the Int&apos;l Workshop on the Web and Databases (WebDB)<address><addrLine>Dallas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="129" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Real-world data is dirty: data cleansing and the merge/purge problem</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Stolfo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Know. Discov</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="37" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Locality-preserving hashing in multidimensional spaces</title>
		<author>
			<persName><forename type="first">P</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vempala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Symp. on Theory of Computing (STOC)</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="618" to="625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Techniques for automatically correcting words in text</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kukich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="377" to="439" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">VGRAM: Improving performance of approximate queries on string collections using variable-length grams</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int&apos;l Conf. on Very Large Data Bases (VLDB)</title>
		<meeting>of the Int&apos;l Conf. on Very Large Data Bases (VLDB)<address><addrLine>Vienna</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="303" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Efficient clustering of high-dimensional data sets with application to reference matching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int&apos;l Conf. on Knowledge Discovery &amp; Data Mining</title>
		<meeting>of the Int&apos;l Conf. on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="169" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A hidden Markov model information retrieval system</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R H</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Leek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="214" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">An efficient domain-independent algorithm for detecting approximately duplicate database records</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Monge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Elkan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGMOD Workshop on Data Mining and Knowledge Discovery (DMKD)</title>
		<meeting>of SIGMOD Workshop on Data Mining and Knowledge Discovery (DMKD)</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Data cleaning: problems and current approaches</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rahm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hai Do</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Eng. Bull</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="3" to="13" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Efficient Top-k query evaluation on probabilistic data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Re</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. of the Int&apos;l Conf. on Data Eng</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="886" to="895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Understanding inverse document frequency: on theoretical arguments for IDF</title>
		<author>
			<persName><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Doc</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="503" to="520" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Efficient set joins on similarity predicates</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sarawagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kirpal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Int&apos;l Conf. on the Mgmt. of Data</title>
		<imprint>
			<biblScope unit="page" from="743" to="754" />
			<date type="published" when="2004">2004</date>
			<pubPlace>Paris</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Representing tuple and attribute uncertainty in probabilistic databases</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Deshpande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM Workshops</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="507" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Slonim</surname></persName>
		</author>
		<title level="m">The Information Bottleneck: Theory and Applications</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>The Hebrew University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Top-k query processing in uncertain databases</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Soliman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">F</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Proc. of the Int&apos;l Conf. on Data Eng</title>
		<imprint>
			<biblScope unit="page" from="896" to="905" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Probabilistic top-k and ranking-aggregate queries</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Soliman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">F</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst. (TODS)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="54" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Graph Clustering By Flow Simulation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Van Dongen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>University of Utrecht</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Trio: a system for integrated management of data, accuracy, and lineage</title>
		<author>
			<persName><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Innovative Data Systems Research (CIDR)</title>
		<meeting>of the Conference on Innovative Data Systems Research (CIDR)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="262" to="276" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
