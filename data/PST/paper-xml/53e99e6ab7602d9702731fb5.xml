<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Suggestive Interface for Image Guided 3D Sketching</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Steve</forename><surname>Tsang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ravin</forename><surname>Balakrishnan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Karan</forename><surname>Singh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Abhishek</forename><surname>Ranjan</surname></persName>
							<email>aranjan@dgp.toronto.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Suggestive Interface for Image Guided 3D Sketching</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C87DF5130A9F91A2ED649B4B21C8037C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.6 [Computer Graphics]: Methodology and Techniques -Interaction Techniques; H.5.2 [Information Interfaces and Presentation]: User Interfaces -Interaction styles Design</term>
					<term>Algorithms Image based interaction</term>
					<term>sketching interfaces</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present an image guided pen-based suggestive interface for sketching 3D wireframe models. Rather than starting from a blank canvas, existing 2D images of similar objects serve as a guide to the user. Image based filters enable attraction, smoothing, and resampling of input curves, and allows for their selective application using pinning and gluing techniques. New input strokes also invoke suggestions of relevant geometry that can be used, reducing the need to explicitly draw all parts of the new model. All suggestions appear in-place with the model being built, in the user's focal attention space. A curve matching algorithm seamlessly augments basic suggestions with more complex ones from a database populated with previously used geometry. The interface also incorporates gestural command input, and interaction techniques for camera controls that enable smooth transitions between orthographic and perspective views.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Current digital 3D modeling software enable the creation and manipulation of extremely sophisticated geometric objects, and have been widely adopted by practitioners in industry. The user interface for these 3D modelers, however, are typically quite complex, relying on the standard WIMP interaction metaphor to perform all tasks, typically using a mouse and keyboard as the primary input devices. The skills designers, artists, and architects have in working with various rich physical media is simply not leveraged; instead, a whole new skillset has to be developed for working with the digital tools. Given that the fidelity of current digital tools often do not approach the physical ones, many traditional methods continue to be used in the industry. In particular, in the early stages of designing a 3D model, paper and pencil is typically used to quickly create and iterate on concept sketches. However, there is currently no mechanism for easily integrating these concept sketches into the digital 3D modeling pipeline. At present, these pencil and paper sketches are not used for anything more than an external visual reference when the designs are transformed to 3D models by artists who painstakingly build the model from low level graphical primitives.</p><p>Notable recent research <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b22">23]</ref> has sought to improve this situation by creating prototype 3D modelers with a gesture and sketching interface that allow users to quickly and directly sketch their model, rather than working with low level primitives. A suggestive interface <ref type="bibr" target="#b8">[9]</ref> can also assist the user by giving useful suggestions for subsequent actions based on the current context. While these efforts are a huge step forward, these interfaces still do not adequately leverage the still invaluable pencil and paper sketches. This paper presents a new style of interface for 3D modeling that extends gestural and suggestive interfaces by integrating scanned images of concept sketches into the modeling process (Figure <ref type="figure">1</ref>). These images serve as a guide to the user when sketching the 3D model. Image based filters can guide the user's input curves by attracting them towards curves in the image. User control is achieved via pinning and gluing techniques. The system also suggests relevant new geometry by approximately matching the user's input strokes against a database populated with standard and previously used geometry, resulting in a system that improves with use. Gestural commands, along with interaction techniques for camera control and switching between image planes, result in a fluid interface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. Screen shot showing geometry in-place with images</head><p>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. CHI 2004, April 24-29, 2004, Vienna, Austria. Copyright 2004 ACM 1-58113-702-8/04/0004...$5.00.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BACKGROUND</head><p>We draw on several related areas in our work, including gesture based interfaces, predictive and suggestive interfaces, recognition systems, image understanding, constraint based systems, and curve creation techniques.</p><p>Gestural interfaces depart from the WIMP metaphor by inferring actions from user input strokes, rather than relying on explicit manipulation of onscreen widgets. This interaction style has been explored in 2D pen-based applications <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b17">18]</ref>. The SKETCH system <ref type="bibr" target="#b22">[23]</ref> was the first gesture-based interface for creating 3D scenes. The Teddy system <ref type="bibr" target="#b11">[12]</ref> for sketching freeform 3D models improved upon the usability of SKETCH <ref type="bibr" target="#b22">[23]</ref> by using a smaller but easily understood gesture set, at the expense of being able to create only relatively simple objects. To reduce the complexities inherent in large gesture sets, our system uses a small gesture set for command input, and a single technique for drawing curves and lines. SKETCH <ref type="bibr" target="#b22">[23]</ref> and Teddy <ref type="bibr" target="#b11">[12]</ref> are similar in that users start from a blank canvas and explicitly create every single piece of geometry. Igarashi and Hughes <ref type="bibr" target="#b8">[9]</ref> extended ideas from predictive interfaces <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b16">17]</ref> by providing suggestions of geometry that could be used next. The suggestions in <ref type="bibr" target="#b8">[9]</ref> were inferred based on hints provided by the user at the immediate past timestep. The Pegasus system <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref> interactively beautified input strokes by inferring desirable properties from surrounding context. Our system builds upon these ideas by using a dynamically updated database of possible candidates from which suggestions are extracted based on an approximate curve matching algorithm.</p><p>Recognition-based systems for handwriting, speech, and text input techniques also face the problem of resolving ambiguity amongst multiple candidates <ref type="bibr" target="#b14">[15]</ref>. Multiple candidates are also generated when searching for good possibilities within large parameter spaces in other graphics applications <ref type="bibr" target="#b15">[16]</ref>. Our interface also generates multiple candidate suggestions, and seamlessly presents the top few options spatially in-place with the existing geometry, rather than in a separate space as in <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b10">11]</ref>, reducing the need for users to context switch between different screen locales. Our system, like <ref type="bibr" target="#b8">[9]</ref>, presents the top candidates from a discrete space of possibilities, unlike <ref type="bibr" target="#b15">[16]</ref> which presents representative examples of a large continuous space.</p><p>Constraint based systems impose limits on subsequent actions by inferring user's past operations <ref type="bibr" target="#b7">[8]</ref>. Examples include drawing systems that impose graphical constraints <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b12">13]</ref>, and layout systems <ref type="bibr" target="#b7">[8]</ref> that provide options based on user provided examples. While the inferred options in these cases are dynamic rules, our system, like <ref type="bibr" target="#b8">[9]</ref>, infers static options that are interactively utilized as needed.</p><p>We use curves as the primary drawing primitive in our system. Our curve drawing technique draws upon previous work in two handed curve drawing <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7]</ref>, and interfaces for sketching 3D curves <ref type="bibr" target="#b1">[2]</ref>. Curves are also important to image processing and computer vision <ref type="bibr" target="#b20">[21]</ref>, where feature curves extracted from images are used for image matching, segmentation, and filtering. Active contour models or snakes <ref type="bibr" target="#b21">[22]</ref> provide a framework whereby curves can evolve on images to track features based on energy minimization. Intelligent scissors <ref type="bibr" target="#b18">[19]</ref> builds upon active contour models to interactively segment images. Saund et al. <ref type="bibr" target="#b19">[20]</ref> explored using image processing techniques to interactively manipulate hand drawn sketches, but their focus was not on creating 3D geometry. Another difference from prior art is that our images are not a finished product to be tracked precisely but rather an evolving approximate guide towards a final model. We combine the energy minimization concept of snakes with interactively sketched constraints to allow images to selectively influence curves as an integrated part of our sketching workflow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SYSTEM HARDWARE</head><p>The primary input device is a pen on a Wacom digitizing tablet. The pen has a barrel button with two click actionsforward, backward; and an active eraser end. On a 1GHz laptop with an NVidia GeForce2Go 16Mb graphics card, we achieve 30Hz update rates. Our software will also run on a TabletPC, however, current TabletPCs do not have sufficient graphics acceleration to achieve interactive rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTERACTION TECHNIQUES Spatially Integrated Construction Planes</head><p>3D models in our system are created by drawing the relevant 2D profile curves on orthographic construction planes from the three primary viewpoints -top, side, front. Rather than viewing these construction planes in separate 2D views as is typically done in 3D modeling software, in a manner similar to <ref type="bibr" target="#b5">[6]</ref> our construction planes are spatially integrated into a 3D cuboid working volume, and can be moved within that volume to enable curve drawing at different locations (Figure <ref type="figure" target="#fig_0">2a</ref>). This integration provides the user with information on the correspondence between the different viewpoints without switching visual context. In addition to 2D planar curves on the primary construction planes, the system also supports drawing 3D non-planar curves by projecting 2D curves onto previously created 3D surfaces in the scene (Figure <ref type="figure" target="#fig_0">2b</ref>), similar to <ref type="bibr" target="#b6">[7]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Camera Controls</head><p>In perspective view, camera tumbling and zooming is performed by using the keyboard arrow keys, or by holding down a keyboard modifier key while moving the pen.</p><p>Clicking the backward pen button with cursor on a construction plane transitions to an orthographic view of that plane, and vice versa. All transitions are animated to maintain continuity of context <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Curve and Line Creation</head><p>We use a one-handed version of the two-handed tape drawing technique used in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref> for creating 2D curves on the construction planes (Figure <ref type="figure" target="#fig_1">3</ref>). This previous work used the non-dominant hand to change the length of the drawing vector, and consequently the variation of the resulting curve. We fix the drawing vector's length to allow for onehanded operation. By default, all input is treated as a curve, but pressing the stylus' forward button constrains drawing to straight lines. 3D curves are created using the techniques described in <ref type="bibr" target="#b6">[7]</ref>, and we refer the reader to that paper for the details. In curve drawing, all points of intersection with other curves in the scene are highlighted to enable users to align new curves to existing ones. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gestures</head><p>By default, all stylus stroke input to the system is treated as curve and line drawings. However, when the user presses hard on the stylus tip (i.e., pressure exceeds a threshold of 800 out of 1024 units), it is assumed that gestural commands are being input. In order to maintain usability and keep ambiguity to a minimum, we use a very small set of three gestures: stroke, cut, and delete.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stroke</head><p>This is a simple straight line gesture (Figure <ref type="figure" target="#fig_2">4a</ref>), used for selecting/deselecting curves and construction planes. In perspective view, a stroke that intersects any curve in the scene makes that curve and its associated construction plane active. Once active, the curve can be edited, or moved by moving its plane. A stroke that intersects a suggested curve (to be described) confirms the inclusion of that curve into the scene. A stroke that intersects one of the edges of the bounding cuboid will generate a new active construction plane in the appropriate dimension depending on the intersected edge. A stroke that does not intersect any edge or curve will deselect the currently selected curve, if any. In an orthographic view (i.e., when drawing), strokes are only recognized when they intersect curves that lie on the currently active plane. This is to avoid inadvertent switching to another construction plane.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cut</head><p>The cut gesture (Figure <ref type="figure" target="#fig_2">4b</ref>) is a v-shaped two-segment gesture. When the cut gesture intersects a scene curve, the curve is cut into two segments at the intersection point. In perspective view, cut gestures can be applied to any scene curve, whereas in orthographic view cutting is limited to curves on the currently active construction plane. Cut gestures cannot be applied to suggested curves that have yet to become a permanent part of the scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Delete</head><p>The delete gesture (Figure <ref type="figure" target="#fig_2">4c</ref>) is a N-shaped three-segment gesture. In perspective mode, a delete gesture that intersects any curve, including suggested curves, deletes that curve from the scene. In orthographic view, only curves in the active construction plane can be deleted. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image Guided Drawing</head><p>One of the primary goals of our system was to integrate scans of concept sketches into the 3D modeling workflow, and to use those sketches as guides for creation of new geometry. Currently, our system allows for images of sketches to be imported and placed on any of the three primary construction planes. Once loaded, these images can be used to influence the shape and position of drawn curves, using three interaction techniques: snapping, pinning, and gluing. At present, we do not yet support loading images onto arbitrarily shaped construction surfaces that can be defined by the user for non-planar 3D curve creation. Loading images onto an arbitrary surface is synonymous with texture mapping and thus a straightforward extension to our current implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Snapping</head><p>When an image is loaded into a construction plane, image maps are created for various image attributes. Since our images are often concept line sketches with lines built from multiple strokes, we filter the images to remove noise in sketch stroke and intensity. We then precompute continuous intensity maps by letting strokes bleed intensity value into neighboring regions using reaction-diffusion (Figure <ref type="figure" target="#fig_3">5</ref>). We then iteratively move and resample points on the sketched curves to minimize their overall energy. The active contour model <ref type="bibr" target="#b21">[22]</ref> defines the energy of a snake as a combination of internal curve energy and external energy resulting from image guides and user constraints. The internal energy is a measure of bending and stretching of points on the curve, and can be reduced by Laplacian smoothing and arc-length minimization. The image energy at a point on the curve is a measure of various image attributes in a localized region of the image around the point. Attributes such as image intensity attracts curves to light or dark areas, image gradient attracts a curve to sharp edges. The individual energy terms in our system are under user control via gluing and pinning techniques. Roughly sketched curves can thus be quickly smoothed, resampled, and attracted to underlying image features (Figure <ref type="figure" target="#fig_4">6</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gluing</head><p>It is often desirable to constrain parts of a drawn curve from being affected by the image snapping algorithm. We support this via a "gluing" operation, which is performed by drawing along the curve using the eraser end of the stylus (i.e., flip the stylus). Parts of the curve that lie within the glued area remain invariant while the rest of the curve is attracted to the plane's underlying image (Figure <ref type="figure" target="#fig_5">7</ref>). Although we designed this technique to support image guided drawing, we have it to be useful when editing curves directly, without running the image snapping algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pinning</head><p>We have found it useful to be able to specify a point on the image that the drawn curve should pass through, and designed a pinning technique to support this functionality. A drawn curve is first selected, and a pin point is specified by pressing the pen down on the construction plane. Dragging the tip away from the pin point adjusts the area of influence of the subsequent attractor algorithm. This area of influence is a circle centered at the pin point with radius equal to the distance from the cursor to the pin point. Parts of the curve that lie within this influence area behave like a rubber band being pulled to the pin point (Figure <ref type="figure" target="#fig_6">8</ref>). Pinning can also be used independently of image snapping.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Suggestions</head><p>When the user is drawing curves, our system provides ongoing suggestions of possible geometry that could be quickly used without the need to draw that geometry. The suggestions are inferred from characteristics of the currently drawn curve. Our work is motivated by Igarashi and Hughes <ref type="bibr" target="#b8">[9]</ref>, but differs in two ways. First, we present the top three candidate suggestions in the same viewing space as the model being created, unlike <ref type="bibr" target="#b8">[9]</ref> where suggestions are displayed in a separate location on screen. This reduces the need for users to switch their focus of attention between viewing suggestions and drawing curves. Second, we provide two types of suggestions:</p><p>• algorithmically generated suggestions that infer simple subsequent geometry possibilities. For simplicity, we consider only two possibilities, closure and extrusion. • database suggestions of previously used geometry extracted from a database by approximate matching to signature characteristics of user selected scene curves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Closure Suggestions</head><p>When a curve has been drawn beyond a certain length and is not relatively straight, a curve is suggested that closes the newly drawn curve (Figure <ref type="figure" target="#fig_7">9</ref>). Straightness is determined by iterating through the points of the newly drawn curve and summing the absolute angles between successive points. If the resulting sum is greater than a threshold (70°), then a closing curve is suggested. The suggested curve can be accepted into or deleted from the scene using the stroke and delete gestures respectively. Unused suggestions fade away after a 10 second time interval. This avoids burdening the user with explicitly dealing with unwanted suggestions as they proceed with their work. This accept/delete/ignore interaction is used for all suggestions in our system.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Database Suggestions</head><p>Our system maintains a database of previously created geometry that has been explicitly saved by the user to provide suggestions for future drawings. Geometry in the database is processed to create a set of curve-signatures.</p><p>Curve signatures are created by deconstructing the model curves into a network of tangent continuous curve segments. Half the fuselage curve in Figure <ref type="figure" target="#fig_10">11a</ref>, for example, is segmented into 5 pieces with three relatively straight curves defining the wing. The lengths of these curve segments are normalized with respect to the overall length of the model curves and stored along with their mean curvature and relative orientation to each other. The curvesignatures thus provide a scale invariant representation of geometry in the database.</p><p>When new curves are drawn, their curve-signature is matched against those in the suggestion database. We first compute a correspondence between the drawn curve segments and those in the database by graph matching. An overall match distance is then computed by the difference in length, orientation, and curvature of corresponding curve segments. Match distances less than a specified threshold are displayed as suggestions. Up to three top ranking matches are presented as suggestions to the user, within the working cuboid. In addition, additional lower-ranking matches can also be browsed using a widget that appears at the bottom of the screen. Should the user decide to increase the rank of one of the lower ranking suggestions, they simply click on that suggestion in the widget and it will appear within the working cuboid. Figure <ref type="figure" target="#fig_10">11</ref> illustrates. These database suggestions effectively allow users to seamlessly leverage off previously created geometry, without having to explicitly browse or import them from the file system in a traditional manner. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Curve Editing</head><p>Our system supports several different ways to edit curves that preserve the fluidity of the interface. To edit a curve, it must first be selected using a stroke gesture. Once a curve is selected (Figure <ref type="figure" target="#fig_11">12a</ref>), touching the pen on the selected curve's construction plane without intersecting the curve itself invokes the pinning editing operation (Figure <ref type="figure" target="#fig_11">12b-d</ref>).</p><p>Note that the pinning operation does not require that an image be previously loaded. A gluing operation can also be performed using the eraser end of the pen.</p><p>If the tip of the pen intersects the selected curve, a new curve or straight line can be drawn using the standard curve/line drawing technique. When the new curve has been drawn, it will be merged into the selected curve in one of two ways, depending on where the starting point of the new curve intersects the originally selected curve:</p><p>• If the starting point of the new curve is on one of the ends of the originally selected curve, it is assumed that the user wishes to extend the selected curve. The two curves are thus merged (Figure <ref type="figure" target="#fig_11">12e-g</ref>). Note that the act of drawing the new curve could trigger suggestions as shown in Figure <ref type="figure" target="#fig_11">12f</ref>.</p><p>• If the starting point of the new curve intersects some other part of the originally selected curve, it is assumed that the user wishes to edit a midsection of the curve, beginning at the intersection point (Figure <ref type="figure" target="#fig_11">12h</ref>). The closest point on the original curve to the final endpoint of the new curve is determined, via the suggested curve (Figure <ref type="figure" target="#fig_11">12i</ref>), and the new curve is thus smoothly incorporated into the original curve, displacing the unwanted segment.</p><p>Cut and delete gestures can also be used for editing, as shown in (Figure <ref type="figure" target="#fig_11">12j</ref>-l). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DISCUSSION</head><p>The motivation for this research came out of frustration expressed by designers at the inability to use their pen on paper concept sketches meaningfully in the construction of a 3D model. It was evident from looking at the evolving state of these sketches that the problem statement was to design an image guided sketching system rather than a system that attempted to accurately reproduce the feature curves of the input image. The second design requirement was simplicity of use that inspired our largely modeless workflow using gestures to invoke various actions. Finally, virtually all free-form industrial design must obey certain geometric and style constraints and involves the reuse of various geometric constructs. Rather than hard-code an increasing set of design constraints and primitive shapes, we introduced the notion of a user defined suggestion database. These geometric databases, comprising models built to specifications of style and design constraints, are dynamically searched for potential matches during the sketching process. This would allow a user to quickly incorporate previous work either as a starting point for a new model, or to reuse geometry that had been previously certified in parts of a new model.</p><p>While our system is still in the research prototype stage, we thought that it was important to get some early feedback from potential users. An equal amount of time was spent by two users on both the breadth of the interface and on building models resulting in the following feedback:</p><p>• The use of a 3D cuboid working volume as the virtual sketchpad -within which the image planes, interactive sketching, and suggestions are visually integrated -is quite effective. This enables the user to maintain an overall spatial awareness of the task at hand • The fixed drawing vector length simplifies the curve drawing paradigm but tends to create curves of limited maximum curvature. In practice this is not a problem since high curvature regions can be drawn as two tangent discontinuous segments and then smoothed locally by Laplacian smoothing.</p><p>• Pinning and gluing techniques, originally designed for use with image planes were found to be a useful general way of precisely constraining curves.</p><p>• We found that keeping the gesture set small made it robust and easy to understand and remember.</p><p>• In general, precise control over pressure while drawing on a tablet was hard to master. For this reason we only used one pressure threshold to distinguish gestures from curve drawing. Different users naturally apply different amounts of average pressure to the pen and the threshold that distinguishes drawing from gestures should be calibrated for each user independently.</p><p>• While the system in its present state is tailored to early conceptual design that did not require high precision, users were able to establish precision when needed by incorporating suggestions from the database.</p><p>• One user mentioned that curve-signatures would be a great way to search and index into arbitrary visual databases. Indeed in our approach, when saving a model to the suggestion database, the images and other related information can be linked with the model and recalled by sketching its curve-signature.</p><p>• At present, suggestion database matches are shown in place as an affine transformation of their original construction. It was mentioned that it would be useful to indicate as additional suggestions, versions of the geometry that was left unchanged as well as one that was locally deformed to better conform to the sketched curve.</p><p>To test the versatility of our system we used it to construct 2D line sketches of various facial expressions from images.</p><p>The system was then used to index into this database and distinguish various facial expressions with just a few sketch strokes (Figure <ref type="figure" target="#fig_12">13</ref>). For our current database sizes of around 10 models the curve matching algorithm was able to perform robustly at interactive rates. A study into the scalability of suggestion databases is subject to future work as well as exhaustive user testing of our system.</p><p>A direction for future work would be to extend our system to construct 3D curves while still working with multiple 2D image planes. We hope to do this by compositing the many 2D image maps, such as that seen in Figure <ref type="figure" target="#fig_3">5</ref> to a single 3D volume map that can attract the curves in 3D instead of on a 2D manifold. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION</head><p>Overall, our system has demonstrated how a simple sketching interface when augmented appropriately with gestures, concept images, and suggestions can become a compelling and effective design tool. The airplane model in Figure <ref type="figure" target="#fig_0">2a</ref> was built in under 5 minutes using the system described in this paper by one of the authors of this paper.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. (a) Three primary construction planes displayed in pink, green and blue. Clicking on any of the planes, or the relevant tabs on the top left corner, makes it the active drawing plane. (b) Arbitrary surfaces can also be defined and used as construction planes. a b</figDesc><graphic coords="2,317.40,546.48,120.00,95.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Curve drawing. (a) Pen down. (b) Pen moves to define the drawing vector. (c) Dragging drawing vector creates curve with smoothness defined by length of drawing vector. (d-e) Pen up ends curve at start point of drawing vector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Gestures. (a) Stroke. (b) Cut. (c) Delete.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Intensity bleeding of line sketch. (a) Before snapping. (b) After snapping.</figDesc><graphic coords="3,316.80,571.44,120.00,95.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Snapping. (a) User draws curves roughly based on lines of underlying image. (b-f) Successive timesteps of snapping algorithm attracts the curves to the image lines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Gluing. (a) User drawn curve does not match underlying image exactly. (b-c) Blue swath indicates that art of the curve is glued. (d). Running the snapping algorithm attracts the unglued parts of the curve to the underlying image lines, while leaving the glued parts unchanged.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Pinning. (a) Curve is selected, and pin point located. (b) Dragging pen away from pin point increases area of influence. (c) Parts of curve that intersect the pinning area of influence behave like a rubber band attached to the pin point. (d) Lifting the pen confirms the pinning</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. Closure suggestions. (a). A new curve is begun. (b) When length and curvature threshold is exceeded, a closed curve is suggested (shown in green). (c) User continues with drawing, suggestion accommodate changes. (d) User finishes drawing, and can select or ignore the suggested closed curve.</figDesc><graphic coords="5,54.24,545.76,120.36,95.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. Extrude suggestions. (a) First set of curves created. (b) Perpendicular construction plane selected. (c) New curve drawn. Note mirroring of geometry. (d) Two extrusion curves are suggested (shown in green). (e) Perspective view highlights the extruded suggestions. (f) Top extruded suggestion selected.</figDesc><graphic coords="5,317.04,341.28,120.36,95.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. Database suggestions. (a) A set of curves is drawn as a template. (b) Database match results in two high ranking suggestions (shown in green) displayed within working cuboid. Widget at bottom of screen displays additional possibilities. (c) Perspective view. Note that the views in the widget change as well. (d) For illustration purposes, user selects a lower ranking alternative from the widget, and it is displayed in the cuboid. (e) Suggestion is accepted, and user drawn template deleted.</figDesc><graphic coords="6,316.80,384.24,240.60,168.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12 .</head><label>12</label><figDesc>Figure 12. Curve editing. (a) Curve is selected. (b) Pin point specified outside the curve. (c) Pin influence region increased, curve rubberbands to pin point. (d) Pinning operation completed, rubberband deformation is accepted. (e) A new curve that starts at the endpoint of selected curve extends it. (f) New curve can trigger suggestions (shown in green). (g) Suggestion is ignored and new curve completed, resulting in extended original curve. (h) A new curve is drawn that intersects some middle point on selected curve. (i). New curve replaces unwanted segment of original curve. Suggestion appears (shown in green). (j). Suggestion is ignored and disappears, a cut gesture divides the curve into two sections. (k) One segment is selected (shown in red). (l) Delete gesture removes selected curve.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 13 .</head><label>13</label><figDesc>Figure 13. (a-d) Example face geometry in suggestion database. (e) Sketch of initial face. (f) Suggested face</figDesc><graphic coords="7,316.80,410.88,241.08,245.40" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We thank members of the Dynamic Graphics Project lab at the University of Toronto for assistance throughout this project, and MITACS for financial support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fitzmaurice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kurtenbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
		<title level="m">Digital tape drawing. ACM UIST 1999 Symposium on User Interface Software and Technology</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="161" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">An interface for sketching 3D curves. ACM I3DG 1999 Symposium on Interactive 3D Graphics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Markosian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zeleznik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="17" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Eager: programming repetitive tasks by example</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cypher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="33" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Drawing with constraints. The Visual Computer</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="39" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Ambiguous intentions: a paper-like interface for creative design</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM UIST Symposium on User Interface Software and Technology</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="183" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kurtenbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fitzmaurice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Buxton</surname></persName>
		</author>
		<title level="m">Interaction techniques for 3D modeling on large displays. ACM I3DG 1999 Symposium on Interactive 3D Graphics</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="17" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Creating principal 3D curves with digital tape drawing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kurtenbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fitzmaurice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Buxton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM CHI 2002 Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="121" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A synergistic approach to specifying simple number independent layouts by example</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="285" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A suggestive interface for 3D drawing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Igarashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hughes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM UIST Symposium on User Interface Software and Technology</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="173" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Interactive beautification: a technique for rapid geometric design</title>
		<author>
			<persName><forename type="first">T</forename><surname>Igarashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Matsuoka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kawachiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tanaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM UIST Symposium on User Interface Software and Technology</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="105" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Pegasus: A drawing system for rapid geometric design</title>
		<author>
			<persName><forename type="first">T</forename><surname>Igarashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Matsuoka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kawachiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tanaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of ACM CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="24" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Teddy: a sketching interface for 3D freeform design</title>
		<author>
			<persName><forename type="first">T</forename><surname>Igarashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Matsuoka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tanaka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>ACM SIGGRAPH</publisher>
			<biblScope unit="page" from="409" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Inferring graphical constraints with Rockit. HCI Conference</title>
		<author>
			<persName><forename type="first">S</forename><surname>Karsenty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Landay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Weikart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="137" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Interactive sketching for the early stages of design</title>
		<author>
			<persName><forename type="first">J</forename><surname>Landay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Interaction techniques for ambiguity resolution in recognition based interfaces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mankoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Abowd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM UIST Symposium on User Interface Software and Technology</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Design galleries: A general approach to setting parameters for computer graphics and animation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Marks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Andalman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Beardsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hodgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mirtich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ruml</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ryall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Seims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shieber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH Conference on Computer Graphics and Interactive Techniques</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="389" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Specifying graphical procedures by example</title>
		<author>
			<persName><forename type="first">D</forename><surname>Maulsby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kittlitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH Conference on Computer Graphics and Interactive Techniques</title>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="127" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pen-based interaction techniques for organizing material on an electronic whiteboard</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">V</forename><surname>Melle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kurtenbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM UIST Symposium on User Interface Software and Technology</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="127" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Intelligent scissors for image composition</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mortensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Barrett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH Conference on Computer Graphics and Interactive Techniques</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Perceptually-supported image editing of text and graphics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Saund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Larner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mahoney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM UIST Symposium on User Interface Software and Technology</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="183" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Image processing, analyis and machine vision</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sonka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Hlavac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Boyle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>PWS Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Snakes: Active contour models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="321" to="331" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">SKETCH: An interface for sketching 3D scenes</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Zeleznik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Herndon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hughes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH 1996 Conference on Computer Graphics and Interactive Techniques</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="163" to="170" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
