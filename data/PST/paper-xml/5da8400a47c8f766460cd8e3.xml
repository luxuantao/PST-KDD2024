<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An online-learning-based evolutionary many-objective algorithm</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-09-02">2 September 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Haitong</forename><surname>Zhao</surname></persName>
							<email>zhaohaitong214@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<postCode>110819</postCode>
									<settlement>Shenyang</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Software College of Northeastern University</orgName>
								<address>
									<addrLine>No.195, Chuangxin Road</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Hunnan District</orgName>
								<address>
									<postCode>110169</postCode>
									<settlement>Shenyang</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Changsheng</forename><surname>Zhang</surname></persName>
							<email>zhangchangsheng@mail.neu.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">Software College</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<postCode>110819</postCode>
									<settlement>Shenyang</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Software College of Northeastern University</orgName>
								<address>
									<addrLine>No.195, Chuangxin Road</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Hunnan District</orgName>
								<address>
									<postCode>110169</postCode>
									<settlement>Shenyang</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Software College of Northeastern University</orgName>
								<address>
									<addrLine>No. 195, Chuangxin Road</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Hunnan District</orgName>
								<address>
									<postCode>110169</postCode>
									<settlement>Shenyang</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An online-learning-based evolutionary many-objective algorithm</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-09-02">2 September 2019</date>
						</imprint>
					</monogr>
					<idno type="MD5">770D39C6409CE440C2D41114BF0B8EB9</idno>
					<idno type="DOI">10.1016/j.ins.2019.08.069</idno>
					<note type="submission">Received 24 January 2019 Revised 26 August 2019 Accepted 28 August 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Many-objective optimization Evolutionary algorithm Decomposition strategy Online-learning</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>When optimizing many-objective problems (MaOP), the same strategy might behave differently when facing problems with different features. Therefore, obtaining problem features helps to obtain high-quality solutions. However, in practice, the problem features are unknown during the optimization process. In this case, learning to adjust strategies to match the problem features is a challenging work. In this paper, a learning-based algorithm is proposed, aimed to enhance the generalization ability. On the basis of a decompositionbased many-objective optimization framework, a learning automaton (LA) is included in the algorithm. The LA adjusts the evolutionary strategies of the algorithm to adapt to the problem characteristics, according to the feedback information during the optimizing procedure. An external archive is employed to store the Pareto non-dominant solutions. Based on the external archive, a reference vector adjustment strategy is designed to enhance the capability of solving problems with a degenerate or discrete Pareto front (PF). To validate the performance of the proposed algorithm, a comparison experiment is conducted on a novel authority test suite. Five state-of-the-art algorithms are selected as peer algorithms. The results of the experiment indicate that the proposed algorithm obtains satisfactory performance in determining the convergence and the approximation of the PF.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The many-objective optimization problem (MaOP) refers to an optimization problem constrained by four or more conflicting optimization objectives <ref type="bibr" target="#b16">[17]</ref> . The MaOP can be defined as the following mathematical model:</p><formula xml:id="formula_0">Minimize f (x ) = ( f 1 (x ) , f 2 (x ) , . . . , f m (x )) , x ∈<label>(1)</label></formula><p>where f j ( x ) is an objective function in the MaOP, for j = 1 , 2 , m, and m is the number of objectives, m ≥ 4. x = (x 1 , x 2 , x D ) represents a candidate solution, where D is the dimension of the decision space.</p><p>is a consecutive searching space. Let h j be a consecutive function, needs to satisfy:</p><formula xml:id="formula_1">= { x ∈ R n | h j ≤ 0 , j = 1 , 2 , . . . , m }<label>(2)</label></formula><p>When a solution is optimized on one objective, its fitness on others might be exacerbated. During the optimization process of an MaOP, a group of non-dominated solutions is utilized to represent the achieved optimal solutions of an MaOP. In this group, every individual represents a tradeoff for different objectives. In other words, different objective weight vector is assigned to each solution in the optimal solution set.</p><p>When optimizing MaOP, there are two fundamental difficulties to face: 1) The loss of the selection pressure <ref type="bibr" target="#b17">[18]</ref> . During the optimization process, especially in an early stage, the traditional Pareto-based evaluation method cannot distinguish candidate solutions with preferable quality <ref type="bibr" target="#b21">[22]</ref> . 2) The reduction of algorithm efficiency. The generation and selection of candidate solutions cost a great deal of computation time because of the high dimensionality of the objective space. These difficulties in solving MaOP are primarily due to the unpredictability of the characteristics of the MaOP. Only during the optimization process can the feature of the problem be perceived by analyzing the optimizing status. Therefore, using the problem feature information obtained thus far to guide the subsequent optimizing in an algorithm running process might be a feasible way to cope with the above difficulties.</p><p>As evolutionary many-objective optimization algorithm (EMaOA) is an efficient approach for solving MaOPs. It utilizes the evolutionary strategy for generating candidate solutions <ref type="bibr" target="#b0">[1]</ref> . According to the optimization strategies, the EMaOAs can be classified into four categories: 1) dominance-based EMaOA <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b25">26]</ref> , 2) decomposition-based EMaOA, 3) indicator-based EMaOA <ref type="bibr" target="#b43">[44]</ref> and 4) dimensionality-reduction-based EMaOA <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b27">28]</ref> .</p><p>The decomposition-based EMaOA is welcomed in the MaOP optimization. It decomposes the MaOP into several subproblems, which are optimized in parallel. In most of the existing studies, a group of pre-set uniformly distributed reference vectors is adopted to decompose the problem <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b45">46]</ref> . For MaOPs with irregular Pareto fronts (PFs), several reference vector adjustment strategies <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b47">48]</ref> are presented to adjust the distribution of the reference vector set. It is worth noting that for decomposition-based EMaOAs, the feature of each sub-problem is unknown before the optimization. If more features can be obtained during the optimization, the efficiency and the generalization capability can be enhanced.</p><p>The existing decomposition-based EMaOAs optimize all sub-problems with the same strategy. Moreover, the features of sub-problems are not being used effectively. This will make the optimization processes of the sub-problems unbalanced:</p><p>• There are different kinds of problems with different kinds of features. The sub-problems can be considered as singleobjective problems. Different sub-problems have specific features. • Different types of algorithms perform differently for specific problems. For example, most algorithms can converge rapidly when solving unimodal problems. For multi-modal problems, the searching step of the algorithm influences the efficiency and the accuracy of the results. • For some specific problems, to achieve a satisfactory performance, the algorithm needs to adjust its strategy during the optimization.</p><p>Because the features of the problem are unknown, the optimization process of an MaOP is complex and difficult to predict. For a decomposition-based EMaOA, at different stages of the optimization process, the target of each sub-problem changes. Furthermore, the searching status of each sub-problem constantly switches between exploration and exploitation. Obviously, the algorithm should employ different searching strategies for exploration and exploitation. When optimizing the MaOP, if the features of the problem can be obtained in detail, the algorithm could employ a targeted strategy. Therefore, the performance and efficiency of the algorithm can be improved. Unfortunately, in practice, the MaOP shows different characteristics at different times. For different optimization processes, different features may appear in the same period. This appends more difficulties for the optimization of the MaOP.</p><p>At present, machine learning has made great progress. Machine learning technology can play an important role in analyzing the features of the MaOP and guiding the algorithm to adopt a targeting strategy. There are several types of research that combing meta-heuristics with machine learning algorithms <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b26">27]</ref> . Some researchers explored the utilization of machine learning methods as a surrogate to replace the traditional fitness evaluation <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b32">33]</ref> . In fact, because MaOP is complicated, the application of machine learning methods to the optimization of MaOP has a broader perspective <ref type="bibr" target="#b13">[14]</ref> . For most of the existing machine learning methods used in MaOP optimization, their complexity is much greater than that of the EMaOA. In this case, although the optimization accuracy might be improved significantly, the time-consuming optimization process limits the application of these approaches. The purpose of this paper is to use an efficient machine learning method to obtain the problem feature and searching status, and, in turn, enhance the performance of the EMaOA.</p><p>In this paper, the online-learning-based reference vector evolutionary many-objective algorithm guided by the referencevector-based decomposition strategy (RVMEA/OL), is proposed. The RVMEA/OL employs a learning-based technology to enhance its generalization capability. The contributions of this paper are outlined as follows:</p><p>(1) An online-learning-based reproduction strategy is presented. This strategy employs an LA to obtain the feature of the problem and the searching state according to the feedback information from the environment. According to this, it adjusts the mutation strategy for each sub-problem in different status situations to enhance the optimization performance. (2) A reference vector clustering strategy is developed. The reference vectors in the same group share the same mutation strategy. (3) An external archive is employed to maintain the diversity of the population. (4) A reference vector adjustment strategy is proposed. It adjusts the distribution of the reference vectors according to solution information about the external archive.</p><p>(5) A comparison experiment is implemented. The experiment compares the performance of the RVMEA/OL and typical EMaOAs to verify the performance of the pro-posed algorithm.</p><p>The rest of this paper is organized as follows: In the second part, the relevant background knowledge involved in the research is reviewed. The third part describes the design and implementation of the proposed algorithm in detail. The fourth part verifies the performance of the proposed algorithm by comparison experiment. The fifth part summarizes the full paper and proposes outlooks for the direction of future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background knowledge and related works</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Reference-vector-based decomposition strategy</head><p>When decomposing the MaOP, the proposed algorithm utilizes the decomposition strategy presented in <ref type="bibr" target="#b5">[6]</ref> . This strategy employs a pre-set reference vector set containing N reference vectors. Each reference vector corresponds to a sub-problem. After the reproduction stage, the algorithm merges the off-spring population with the parent population. The algorithm chooses the current optimum for each sub-problem. To reduce the calculation in the candidate evaluation, according to Eq. ( <ref type="formula" target="#formula_2">3</ref>) , the candidate solutions are mapped into the first quadrant of an M -dimensional objective space:</p><formula xml:id="formula_2">F t,i = F t,i -Z min t (<label>3</label></formula><formula xml:id="formula_3">)</formula><p>where F t,i is the i th candidate solution set of the t th generation, Z min t is the ideal point, and F t,i is the i th translated solution.</p><p>Let the number of objectives be M ; then, Z </p><formula xml:id="formula_4">z min t,m = min x ∈ f i (x ) , i = 1 , 2 , . . . , M<label>(4)</label></formula><p>The distance between reference vectors and candidate solutions is a vital basis for the selection of candidate solutions. After the calculation according to Eq. ( <ref type="formula" target="#formula_2">3</ref>) , the candidate solutions and reference vectors can be regarded as vectors starting from the origin of coordinates. Therefore, their distance can be measured according to their vectorial angle:</p><formula xml:id="formula_5">angle ( v 1 , v 2 ) = arccos v 1 • v 2 || v 1 || • || v 2 || (5)</formula><p>For the selection stage, first, the distance between each candidate solution and each reference vector is calculated. Each candidate solution is associated to its nearest reference vector. Then, the candidate population is divided into several subpopulations. Next, one candidate solution is selected from each subpopulation. In this paper, the angle-penalized distance (APD) is the indicator for the candidate solution evaluation. The APD value comprehensively considers the convergence performance and the distribution performance of the candidate solutions. For candidate solution F t,i , its APD value is calculated as the following:</p><formula xml:id="formula_6">d t,i, j = (1 + P (θ t,i, j )) • || F t,i ||<label>(6)</label></formula><p>where || F t,i || is the norm of F t,i . It reflects the convergence performance of F t,i . P ( θ t,i,j ) is used to control the diversity of the Pareto-optimal solution set and is calculated as follows:</p><formula xml:id="formula_7">P (θ t,i, j ) = M • t t max α • θ t,i, j γ v i, j (7) γ v i, j = min i ∈{ 1 , ... ,N} &lt; v t,i , v t, j &gt; (8)</formula><p>where M represents the number of objectives, t max is the maximum number of iterations, and t is the current iteration number. Parameter α controls the rate of change of P ( θ t,i,j ), θ t,i,j is the angle between individual i and individual j , and γ v i, j is the minimum angle between reference vector v j and other reference vectors. In this way, the algorithm can prevent θ t,i,j from becoming too large or small due to the excessive distribution of the candidate solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Online learning and reinforcement learning</head><p>Since the environmental status during an optimization process is dynamically changed with time, the online learning method is adopted for designing the learning model in this study. In contrast to offline machine learning in which the best model is generated for the entire training data set at once, the data for online learning is available in sequential order <ref type="bibr" target="#b11">[12]</ref> . Generally, online learning is used in areas where it is computationally infeasible to train over the entire dataset, or it is necessary for the algorithm to dynamically adapt to new patterns in the data.</p><p>Reinforcement learning concerns how to take actions in the current state to enable the cumulative reward to be maximized <ref type="bibr" target="#b40">[41]</ref> , according to the feedback information from the environment. For reinforcement learning, the environment is typically regarded as a Markov decision process (MDP). For reinforcement learning, usually, the information from the environment provides the evaluation for the current action, instead of giving instruction to the learning system on how to take actions on the next stage. Since the environment is stochastic during the optimization of an EMaOA, the optimization can be regarded as an MDP. Therefore, in this paper, the learning automaton <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref> is employed as a method of reinforcement learning. The learning automaton selects its current action based on experience from the environment. A learning automaton is defined as a quadruple { α, β, p, U } where α is the action set. When the α is considered as a finite set, the learning automaton is called a finite action learning automaton (FALA). The β is the feedback/reinforcement signal obtained from the environment; frequently, the feedback signals are 0, 1 with zero called the penalty feedback and one called the reward feedback. The p is the transition probability vector, it stores the probability of being selected for each action. The U is the updating scheme. As shown in Fig. <ref type="figure" target="#fig_0">1</ref> , for an FALA, at time t , the FALA obtains feedback information β( t ) from the environment. Then the updating scheme U updates p to influence the decision making of the automaton. The automaton selects an action from the finite action set according to p . The learning automaton repeats the process of obtaining environmental information and adjusting its actions according to the feedback to maximize the reward.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Related works</head><p>The decomposition-based EMaOA has become a research hotspot due to its performance on controlling the solution distribution. Multiple studies have been presented to enhance optimization capability.</p><p>Since the purpose of optimization is to obtain the solution that is as accurate as possible, improving the optimization quality is always the goal of researchers. In <ref type="bibr" target="#b34">[35]</ref> , three decomposition strategies are presented and analyzed. These decomposition strategies achieve an effective decomposition of the problem. Balancing the convergence and diversity of the solution set is a tough task for MaOP optimization. To handle this, RVEA <ref type="bibr" target="#b5">[6]</ref> presented the APD to calculate the fitness of candidate solutions. A maximum-vector-angle-first principle is used in the environment selection of the VaEA <ref type="bibr" target="#b7">[8]</ref> . For the MOEA/DD <ref type="bibr" target="#b24">[25]</ref> , a unified paradigm combining the decomposition-based and dominance-based strategies is proposed to control the convergence and diversity of solutions during the evolutionary process. The result of the environmental selection has a significant effect on the optimization quality. The MOEA/D-SAS <ref type="bibr" target="#b3">[4]</ref> enhances its performance by presents a sorting and selection mechanism. In addition, in <ref type="bibr" target="#b12">[13]</ref> , the decomposition-based dominance relation and boundary intersection-based diversity factor are proposed for candidate solutions' selection. Although existing algorithms have achieved satisfactory convergence, the performance of their strategies has strong relevance to the problem features. The generalization ability of EMaOA needs to be enhanced.</p><p>Studies have revealed that the performance of EMaOAs with pre-set reference/weight vectors is restricted when facing MaOPs with discrete or degenerated PFs. Several strategies are proposed to handle irregular PFs. For the MOEA/D-SAS, it allows solutions to associate with the same reference vectors, and reference vectors can be associated with no solution. In this case, the distribution of the solutions could be closer to the shape of irregular PFs. The MaOEA/D-2ADV <ref type="bibr" target="#b2">[3]</ref> proposes two types of adjustment for reference vectors. It employs a gradual increase of reference vectors to conduct fast convergence. Moreover, a vector evaluation strategy facilitates adjusting reference vectors to fit the shape of the PF. The existing vector adjustments cost too much in terms of computational resources. This problem needs to be improved to meet the demands in practice.</p><p>Introducing the machine learning method into MaOP optimization is a novel idea to provide specific optimization strategies for problem characteristics. In CSEA <ref type="bibr" target="#b32">[33]</ref> , a neural network is utilized to predict the relationship between candidate solutions and reference solutions. The Tr-DMOEA uses a transfer learning technique to generate an effective initial population by reusing past optimization experiences. The existing learning-based EMaOAs needs experiences of the previous optimization. However, in the real world, the experiences are difficult to obtain. Furthermore, the experiences provide no help to solve the problems of generalization. The teach-learning-based optimization (TLBO) has the advantage of not needing specific parameter tuning on the problem characteristic. Studies such as the INM-TLBO <ref type="bibr" target="#b44">[45]</ref> , EMOTLBO <ref type="bibr" target="#b31">[32]</ref> , and MO-ITLBO <ref type="bibr" target="#b33">[34]</ref> have verified that the TLBO can solve problems with multiple optimization objectives well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Designing and implementation of the RVMEA/OL</head><p>This part introduces the designing and implementation of the proposed algorithm RVMEA/OL. Then the performance of the proposed algorithm is analyzed from the aspects of algorithm structure and efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Motivation</head><p>Obtaining the features and searching status of each sub-problem is a key issue for enhancing the performance of a decomposition-based EMaOA. There are some difficulties that constrains the algorithm from obtaining the problem features:</p><p>(1) The feature of each sub-problem is unknown before the optimization process. As analyzed in the introduction part, the specific optimization strategy is more conducive to access high-quality solutions efficiently. (2) Since the algorithm can only obtain partial feature of the problem, the feature of a sub-problem can be varied during the optimization procedure. At different searching stages, the problem shows different kinds of features. (3) For different sub-problems, the problem has variety. Therefore, optimal strategies are different. For a decompositionbased EMaOA, it is important to assign a suitable optimization strategy for each sub-problem according to the problem feature and the realtime status. (4) There is no global optimal strategy for all kinds of problems. For each sub-problem, the searching aims to use an optimal solution to represent a part of the PF.</p><p>Since the problem features cannot be obtained directly, adopting suitable strategies is a feasible way to utilizing the problem feature to accelerate the convergence. Both the adaptive strategy of evolutionary strategies and the reinforcement learning approach can achieve strategy adjustments. Compared to the adaptive evolutionary strategy, the reinforcement learning strategy has its own advantages. The reinforcement learning technique tends to choose strategies with better performance. It can guide the algorithm to take advantageous strategies with limited environment knowledge. Meanwhile, exploration is considered. The selection mechanism ensures that the fitness of all candidate strategies can be evaluated. In contrast, the adaptive evolutionary strategy consumes more computational resources when exploring the effect of strategies in the searching space.</p><p>To utilize the reinforcement learning technique to select a suitable strategy, the feedback mechanism should be welldesigned. Since the target of the decomposition-based MaOP optimization is to optimize each sub-problem, the optimized degree of a sub-problem can be regarded as a feedback signal to adjust the searching strategies of the sub-problems. The feedback information reflects the matching degree of the current searching strategy and the current problem feature. If the quality of the solution of a sub-problem is improved significantly, we can believe the current strategy is available for the current environment. Otherwise, the current optimization strategy is not suitable for this period of time. The detailed design of the reinforcement-learning-based evolutionary strategy selection is described in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Algorithm description</head><p>The RVMEA/OL has a similar framework to the traditional EMaOA. The difference is, in this optimization framework, specific novel strategies are proposed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Initialization</head><p>In the initialization stage, N individuals are generated randomly obeying the uniform distribution to construct the initial population. The canonical simplex-lattice design <ref type="bibr" target="#b7">[8]</ref> method is adopted in deciding the reference vectors. Given the number of objective M and division parameter H , the number of reference vectors is calculated according to Eq. ( <ref type="formula" target="#formula_8">9</ref>) :</p><formula xml:id="formula_8">N = H + M -1 M -1<label>(9)</label></formula><p>A neighborhood matrix NH is designed to record the neighbor information of each reference vector. Let T be the neighborhood size, and the NH has N rows and T column. The i th row of NH records T closest reference vectors to the i th reference vector v i . An external archive AN is initialized to store the non-dominated solutions. A transition matrix TM i is assigned for sub-problem i to record the transition probability of each mutation strategy on this sub-problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Online-learning-guided reproduction strategy</head><p>For the learning-guided reproduction strategy, an FALA is employed to facilitate the algorithm to obtain a satisfactory solution by taking appropriate searching strategies.</p><p>There are three alternative mutation strategies for each sub-problem. There are three evolutionary strategies in the proposed algorithm. The first strategy is the original DE mutation strategy. The second strategy is motivated by enhancing the exploitation capability. It is more inclined to search for the area near the current optimal solution. And the third strategy comes from the previous research of the authors. This strategy utilizes the updating information to guide the evolutionary directions, in order to accelerate the convergence speed <ref type="bibr" target="#b46">[47]</ref> . The strategies are described in detail as follows:</p><p>Strategy 1 : For the first mutation strategy, to the current sub-problem i , three random individuals x r 1 ,t , x r 2 ,t and x r 3 ,t are selected from the union of the current optimum solution and the optimal solutions of the neighbors of sub-problem i . A variation intermediate is generated by putting these random individuals into Eq. ( <ref type="formula">10</ref>) :</p><formula xml:id="formula_9">v i = x r 1 ,t + F • (x r 2 ,t -x r 3 ,t ) (10)</formula><p>Strategy 2 : For the second mutation strategy, the variation intermediate is generated by adding the vectorial difference of two randomly selected neighbors to the optimum solution of the current sub-problem, according to Eq. <ref type="bibr" target="#b10">(11)</ref> .</p><formula xml:id="formula_10">v i = x i,t + F • (x j,t -x k,t ) (11)</formula><p>Strategy 3 : The third mutation strategy is guided by the updating direction of the optimal solution of each sub-problem. To achieve this, an archive H is introduced to store the population of the previous iteration. For the t th generation, the updating direction of the i th sub-problem is calculated by subtracting its optimum solution of the t th iteration with the optimal solution of the (t -1) th generation. This procedure is described by Eq. ( <ref type="formula" target="#formula_11">12</ref>) :</p><formula xml:id="formula_11">D t,i = P t,i -P t-1 ,i<label>(12)</label></formula><p>As shown in Eq. ( <ref type="formula" target="#formula_12">13</ref>) , the mutation intermediate is generated under the guidance of the updating direction with the probability of r , otherwise, the intermediate is generated by the same method in Strategy 1 :</p><formula xml:id="formula_12">v j,i,t = x j,i,t + F • D j,i,t , if rand() ≤ r v i = x r 1 ,t + F • (x r 2 ,t -x r 3 ,t ) , otherwise<label>(13)</label></formula><p>After the generation of mutation intermediates, the same crossover method is utilized by the three mutation strategies to generate the offspring individual u i,j,t , as described by Eq. ( <ref type="formula" target="#formula_13">14</ref>) :</p><formula xml:id="formula_13">u j,i,t = v j,i,t , if rand() ≤ CR or j = j rand x j,i,t , otherwise<label>(14)</label></formula><p>During the optimization process, the FALA controls which mutation strategy to execute for each sub-problem. This FALA is a quadruple { s, β, p, U }, where the action set s = s 1 , s 2 , s 3 represents the action using strategy 1, strategy 2 or strategy 3.</p><p>At the starting stage, the FALA selects a random action from { s 1 , s 2 , s 3 } for each sub-problem.</p><p>Assuming that at time t -1 , the mutation strategy of the algorithm is switched from s i to s j , the s i and s j construct a transition pair ( s i , s j ). We suppose that the transition pair ( s i , s j ) has occurred h times at time t .</p><p>At time t , each sub-problem has executed the selected mutation strategy for a certain number of iterations. At this time, the FALA should evaluate the performance of the current mutation strategies and decide which action to take for the following process. The FALA uses the reword function r () to measure the contribution of the current mutation strategy. The reward function r ( i,j ) ( h ) is calculated according to Eq. ( <ref type="formula" target="#formula_14">15</ref>) :</p><formula xml:id="formula_14">r (i, j) (h ) = | AP D h (P h -1 ) -AP D h (P h ) | AP D h ( P h ) (<label>15</label></formula><formula xml:id="formula_15">)</formula><p>where APD h () is the APD function at the h th occurrence of action pair ( s i , s j ). P h and P h -1 are the optimal solution sets at the s th and (s -1) th occurrence time of the strategy pair ( s i , s j ) respectively.</p><p>The Q ( i,j ) ( h ) represents the cumulative reward. Because the environment is unknown and dynamically changing, it is reasonable to think that the recent information about the environment is more valuable. A parameter α is introduced into the calculation of the reward to discount the past reward. In this paper, the α is fixed at 0.1. The Q ( i,j ) ( h ) is calculated according to Eq. ( <ref type="formula" target="#formula_16">16</ref>) :</p><formula xml:id="formula_16">Q (i, j) (h ) = Q (i, j) (h -1) + α[ r (i, j) (h ) -Q (i, j) (h -1)]<label>(16)</label></formula><p>The feedback signal λ ( i,j ) ( t ) means the reward/penalty signal of the strategy transition pair ( s i , s j ) at time t . It is calculated according to Eq. ( <ref type="formula" target="#formula_17">17</ref>) :</p><formula xml:id="formula_17">λ (i, j) (t) = 0 . 1 + m • Q (i, j) (s ) (<label>17</label></formula><formula xml:id="formula_18">)</formula><p>The λ ( i,j ) ( t ) is utilized to update the transition probability, and the transition probability determines which mutation strategy will be utilized for the following optimization process. At time t , the LA needs to decide whether to continue using s j or use other mutation strategies. When selecting a mutation strategy for the following searching, the transition probability of s j is calculated according to Eq. ( <ref type="formula" target="#formula_19">18</ref>) :</p><formula xml:id="formula_19">p (i, j) (t) = p (i, j) (t -1) + λ (i, j) (t -1) β(t -1)(1 -p (i, j) (t -1)) -λ (i, j) (t -1)(1 -β(t -1)) p (i, j) (t -1)<label>(18)</label></formula><p>for mutation strategy l with l = j , and the transition probability is calculated according to Eq. ( <ref type="formula" target="#formula_20">19</ref>) :</p><formula xml:id="formula_20">p (i, j) (t) = -λ (i, j) (t -1) β(t -1) p (i, j) (t -1) + λ (i, j) (t -1)(1 -β(t -1))[ 1 r-1 -p (i, j)(t-1) ]<label>(19)</label></formula><p>A transition strategy is designed in the learning-based reproduction strategy to decide the condition of changing the mutation strategies. This is a key technique to make the mutation strategy matching the current searching status. In this paper, the improvement extent of a sub-problem and the maximum execution iteration are utilized to judge whether the mutation strategy should be changed. At time t , for sub-problem i , if the improvement extent of the APD value AP D (i,t) (P t ) -AP D (i,t) (P t-1 ) is smaller than a pre-set threshold , or the current mutation strategy has been executed for more than I iterations, the LA will stop using the current mutation strategy, update the transition matrix TM i , and select the mutation strategy for the following optimization process.</p><p>The parameter h and t are unknown number in Eqs. ( <ref type="formula" target="#formula_14">15</ref>) &amp; ( <ref type="formula" target="#formula_16">16</ref>) . As can be seen in the Eqs. ( <ref type="formula" target="#formula_19">18</ref>) &amp; ( <ref type="formula" target="#formula_20">19</ref>) , each transition pair in the transition table has certain probability to be selected. And there are exploration designs in Eqs. ( <ref type="formula" target="#formula_14">15</ref>) &amp; ( <ref type="formula" target="#formula_16">16</ref>) , that ensures the occurrence of each transition pair during the optimizing process. The frequency of occurrence of different transition pairs can reflect the adaptation capabilities of the mutation strategies to the optimization process. Therefore, the transition probability can be updated according to the frequency of occurrence of the transition pairs. The mutation strategies are selected according to their transition probabilities. In this paper, the -RouletteGreedy is employed. Using the -RouletteGreedy selection <ref type="bibr" target="#b26">[27]</ref> strategy, the algorithm can explore the performance of different combinations of actions. With the continuing process of the optimization, the algorithm is increasingly more inclined to adopt mutation strategies with the optimal transition probabilities.</p><p>The learning-based reproduction strategy is summarized in Algorithm 1 . At time t , for each sub-problem i , the algorithm first updates the transition matrix. It calculates the current reward. Then, it uses them to calculate the reward/penalty signal. According to the signal, the transition probabilities of the candidate mutation strategies are updated. The algorithm uses the -RouletteGreedy strategy to select the mutation strategy for the next stage. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Reference vector clustering</head><p>The reference vector clustering approach is proposed to reduce the computational burden. A great number of reference vectors are generated by the algorithm. If the algorithm maintains a transition matrix for each sub-problem, the computation will become unacceptable. To alleviate the computation pressure, the reference vector clustering method divides the uniformly distributed reference vectors into several clusters. Each cluster contains adjacent reference vectors. The specific method is as follows: after generating the reference vector set, the algorithm generates a group of more sparse vectors by implementing the simplex-lattice design method. The algorithm calculates the distance between each reference vector and each sparse vector. In addition, each reference vector is associated with its closest sparse vector. Let the number of sparse vectors be g , such that the reference vectors are divided into g clusters. The algorithm assigns a transition matrix for each cluster. The sub-problems in the same group share the same action at the same time. Fig. <ref type="figure">2</ref> is an example of the reference vector partition in two dimensions.</p><p>The algorithm employs the mean rewards of the sub-problems as the reward of group i :</p><formula xml:id="formula_21">r ( i, j)(i ) = 1 s s p=1 r (i, j) ,p ( v p ) , where v 1 , . . . v s ∈ group i (20)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4.">Referene vector adjustment</head><p>To handle MaOPs with irregular PFs, a reference vector adjustment strategy is presented. This reference vector adjustment strategy is based on information on the external non-dominated solution archive. During the optimization process, the nondominated solutions are stored in the external archive AN . The algorithm uses an array NC to record the source of the non-dominated solutions. The NC counts how many non-dominated solutions each sub-problem contributes. During the selecting stage, as described in the second part, the candidate solutions are associated with their nearest reference vectors. If a reference vector is not associated with any candidates for q consecutive iterations, this reference is eliminated, and a new reference vector will be generated to fill the reference vector set. The reference vector re-generation approach is out-lined count the associated candidate solution of v i ;</p><p>3:</p><formula xml:id="formula_22">if associated( v i ) == 0 then 4: move v i from V to V E; 5:</formula><p>end if 6: end for 7: randomly remove a vector from V E; 8: emerge V E into V ; 9: for each reference vector v i do 10:</p><p>calculating the selected probabilities of v i according to Eq. ( <ref type="formula" target="#formula_23">21</ref>); 11: end for 12: random vector v r i , v r j = roul etteSel ection () ; 13: generate a new reference vector v n according to Eq. ( <ref type="formula" target="#formula_25">22</ref>); 14: add the v n into V ; 15: associate the v n with its nearest sparse vector; 16: if a sparse vector is not associated with any reference vector then 17: remove this sparse vector; 18: end if</p><formula xml:id="formula_23">p i = nc i N j=1 nc j (<label>21</label></formula><formula xml:id="formula_24">)</formula><p>After the selection, the new reference vector v n is generated between the random reference vectors v i and v j :</p><formula xml:id="formula_25">v n = v i + v j 2 (<label>22</label></formula><formula xml:id="formula_26">)</formula><p>After its generation, the v n will be associated with its nearest sparse vector. During the reference vector adjustment process, the distribution of the reference vectors is changed. If a sparse vector is not associated with any reference vector, the algorithm will eliminate this sparse vector. In this case, the algorithm can make the distribution of the approximation set approach the shape of the PF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.5.">Algorithm framework</head><p>The main framework of the RVMEA/OL is described in Algorithm 3 . The novel strategies are designed in the reproduction part. The reference vector adjustment strategy is performed at the end of each iteration. In addition, the algorithm outputs the external archive as the solution of the MaOP.</p><p>Algorithm 3 Framework of algorithm RVMEA/OL.</p><p>Input: the problem to be optimized; Output: a group of non-dominated solutions and their objective function values;</p><p>1: initialize population P t ; 2: reference vector partition; 3: while stop criteria=false do 4:</p><p>generate offspring population Qt according to Algorithm 1; 5:</p><formula xml:id="formula_27">P t = P t ∪ Q t ; 6:</formula><p>objective value translation according to Eq. (3); select optimal solution of each sub-problem;</p><p>10:</p><p>use the optimal solutions to construct the new population P t+1 ;</p><p>11:</p><p>record the correspondence between the solutions and the reference vectors;</p><p>12:</p><p>calculate the updating directions according to Eq. ( <ref type="formula" target="#formula_11">12</ref>);</p><p>13:</p><p>updating the z min by Eq. ( <ref type="formula" target="#formula_4">4</ref>);</p><p>14:</p><p>updating non-dominated solution archive AN; <ref type="bibr">15:</ref> examine and adjust reference vector set according to Algorithm 2; 16: end while 17: output AN;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Discussion</head><p>By employing the learning automaton as a reinforcement learning method, the algorithm obtains the matching level of the problem feature and the current strategy. This is an indirect way to acquire the feature of the sub-problems. In traditional EMaOAs, the only information from the environment is the evolutionary direction. Although the evolutionary direction has positive guidance on the optimization, in the early stage of the execution, there is still greater randomness in the search process. The environmental information provides definite guidance for the optimization of the algorithm. The LA obtains the optimization extent of each sub-problem every regular interval. The optimization extent is an important feedback signal. It reflects whether the current mutation strategy is suitable for the current optimization situation, i.e., the current feature of the problem. By adjusting the transition probability, the algorithm selects the suitable mutation strategies during the optimization process continually. This mechanism makes use of the characteristic of the problem feature during the optimization process. For each sub-problem, the learning-based mutation strategy takes a specific strategy for its contemporary feature.</p><p>The three mutation strategies in this algorithm can deal with different situations during optimization. The first mutation strategy has a large shift range, and the offspring individual generated by the first mutation strategy has strong randomness. This characteristic can help the algorithm to escape the local optimum. For the first mutation strategy, three random individuals are selected to generate the mutation intermedia. Comparing to the other mutation strategies, this strategy contains greater randomness. If the difference between the selected individuals is large, the resulting variant intermediates may differ significantly from the previous optimal solution. In another word, the mutation intermediate could be far away from the previous solution. During the optimizing procedure, especially for facing problems with multi-modals, the algorithm faces the risk of falling into local optimal. The cause of this phenomenon is the lack of a diversity maintenance strategy. The design of the first mutation strategy facilitates the introduction of diverse individuals into the algorithm. When trapped by the local optimum, it has certain probability to generate individuals that is out of the local optimum area. Therefore, the characteristic of the first mutation strategy can help the algorithm to get out of the local optimal. For the second mutation strategy, the random individuals are chosen from a neighborhood. Therefore, the new individual will be generated within a small region. When the algorithm is in a refining stage to increase the accuracy of the solution, this mutation strategy will help. For the third mutation strategy, it is guided by the evolutionary direction with the probability of r ; otherwise, the offspring individual will be generated in a small area. In the later stage of the execution, the main target of the algorithm is acquiring more accurate solutions around the areas where the potential optimal solution might exist. For this situation, the third mutation strategy can help the approximation solution converge rapidly.</p><p>The reference vector clustering method divides the reference vectors into several groups. The solutions of adjacent subproblems are more similar on the weights of the objectives. The sub-problems in the same cluster share a similar environment, i.e., the feature of the problem. The algorithm uses the mean rewards as the reward of the group because it can reflect the improved degree of the entire group. If the distribution of the reference vectors is adjusted, then, because the new vector is added to its nearest cluster, the reference vector clustering method still works.</p><p>Compared to the hC-DEEPSO algorithm <ref type="bibr" target="#b28">[29]</ref> , the main difference between it and the strategy adopted in this manuscript is: In the hC-DEEPSO, the evolutionary strategy is adjusted by adjusting the mutation parameters. And the parameters are adjusted by using a mutation strategy. That is to say, the adjustment process of the parameters contains randomness. When optimizing the many-objective problems, we want to limit the randomness in the exploration process, in order to accelerate the convergence. Therefore, for the proposed RVMDE/OL in this manuscript, the mutation strategy is adjusted according to the performance of the current strategy and the optimizing potential of the candidate strategies <ref type="bibr" target="#b8">[9]</ref> . The proposed reference vector adjustment approach is utilized to handle MaOPs with irregular PFs. When generating new reference vectors, the information of the external archive is considered. Since the external archive stores the nondominated solutions, the source of the non-dominated solutions can reflect the information about the shape of the PF. The roulette selection strategy in the reference vector adjustment can reduce the misleading by a sparse non-dominated solution set. The proposed reference vector adjustment strategy in this paper contains less randomness the existing approaches. Compared to the learning-based reference re-distribution methods, the proposed approach operates under a lower complexity. This is essential for solving real-time problems.</p><p>An iteration of the optimization process can be subdivided into six parts: reproduction, objective translation, population partition, APD calculation, elitist selection, and transition probability updating. Let M be the dimensionality of the objective space and Q the dimensionality of the decision space; then, the computational complexity of reproduction is O ( NQ ). The complexity of the objective translation is O ( M ). Both the population partition and APD calculation have the computational complexity of O ( M 2 ). The minimum complexity elitist selection is O ( N log 2 N ). The computational complexity of the transition probability matrix updating is O ( N ). In conclusion, the complexity of one iteration of the RVMEA/OL is O ( M 2 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiemnt</head><p>In this section, to evaluate the performance of the proposed RVMEA/OL in solving MaOPs, a series of experiments is implemented. The MOEA/D, NSGA-III, RVEA, VaEA <ref type="bibr" target="#b7">[8]</ref> and MOEA/DD <ref type="bibr" target="#b24">[25]</ref> are chosen as representatives of typical EMaOAs. The performance of the RVMEA/OL is compared with the performance of the typical EMaOAs from the aspects of convergence, solution quality, and reflection of the shape of the PF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experiment setting</head><p>A novel many-objective test suite presented by H. Li et al. <ref type="bibr" target="#b23">[24]</ref> is chosen as test cases in this experiment. Ten challenging test cases are involved in this test suite, named as MaOP1-10 in this paper. The MaOP1-5 have regular shapes of PFs. The shapes of PFs of MaOP5-10 are irregular: they are discrete or degenerated.</p><p>As decomposition-based algorithms, the MOEA/D has a satisfactory performance on regular MaOPs. The MOEA/DD, RVEA, and VaEA achieve a good balance on convergence and diversity. The distribution of their solution can fit the shape of the PFs. The RVEA contains a reference adjustment mechanism, and it has outstanding performance on irregular MaOPs. The NSGA-III is a state-of-the-art dominance-based algorithm. It has a satisfactory performance on convergence and distribution. The complexity of the baseline algorithms is O ( M 2 ).</p><p>The IGD+ indicator <ref type="bibr" target="#b19">[20]</ref> is used in evaluating the quality of the Pareto-optimal solution sets of different algorithms. It is a modified version of the inverted generational distance (IGD) <ref type="bibr" target="#b39">[40]</ref> indicator. A lower IGD+ value indicates that the nondominated solution set is of favorable quality.</p><p>To ensure the accuracy of the comparison experiment, the constant population size is adopted by all tested algorithms. For decomposition-based EMaOA with pre-set reference vectors in a high-dimensional objective space, two layers of reference points are utilized to generate reference vectors, thus preventing the number of reference vectors from becoming too large. For this experiment, when the objective number M ≥ 8, the two-layer reference vector generation strategy is performed. The generation method for reference vectors and the population sizes are summarized in Table <ref type="table" target="#tab_1">1</ref> .</p><p>For the reference vector partition operator in RVMEA/OL, according to Eq. ( <ref type="formula" target="#formula_12">13</ref>) , the calculation of the number of sparse vectors and the number of reference vectors in a group for M = 3 , 5, 10 and 15 are listed in Table <ref type="table" target="#tab_3">2</ref> .</p><p>The values of the parameters of the baseline algorithms are set according to the original literatures <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b45">46]</ref> of the algorithms, to guarantee the performance of the compared algorithms.</p><p>In this experiment, the maximum number of evaluations is used as the termination criterion. The maximum number is fixed according to the number of objectives. It is set at 30,0 0 0 when M = 3 and M = 5 , and when M = 10 and M = 15 , it is set at 50,0 0 0. To ensure the fairness of the experiment, each algorithm is tested by running each test case thirty times independently. The code of the proposed algorithm can be accessed through https://github.com/martinplus/RVDE .  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Sensitivity analysis</head><p>Four parameters are introduced into the RVMEA/OL: m, τ , I and . Since the parameters have a certain influence on the performance of the algorithm, to ensure that the proper values of the introduced parameters are employed and explore the influence of the parameters on algorithm performance, a sensitivity analysis is implemented. Three values are considered for each parameter: m ∈ {1, 2, 3}, τ ∈ {0.3, 0.5, 0.7}, I ∈ {3, 5, 7}, and ∈ {0.0025, 0.0050, 0.0075} ( Fig. <ref type="figure" target="#fig_3">3</ref> ).</p><p>The orthogonal experiment <ref type="bibr" target="#b36">[37]</ref> is utilized to analyze the impact of the parameters on the algorithm performance. An L 27 orthogonal table <ref type="bibr" target="#b41">[42]</ref> is introduced to investigate the significance of the influences of parameters. The experiments are implemented on MaOP2, MaOP4, MaOP5, and MaOP7. The execution of the algorithm is repeated thirty times on each test case to ensure the veracity of the experiment. The IGD+ value of the solution of each run is collected. Fig <ref type="figure" target="#fig_4">4</ref> indicates the influence of each parameter setting on the performance of the proposed algorithm. To ensure the solution quality, for the following experiments, the parameter setting that achieves the best IGD+ mean is regarded as the best value of the parameter. According to the experimental results, the best parameter setting for the RVMEA/OL is { m = 1 , τ = 0 . 5 , I = 5 , = 0 . 005 } . The analysis of variance (ANOVA) <ref type="bibr" target="#b37">[38]</ref> can reflect the influences of the parameters on the performance of the algorithm. According to the IGD+ results on the selected test cases, an ANOVA experiment is implemented. The results of the ANOVA experiment are shown in Tables <ref type="table" target="#tab_4">3</ref><ref type="table">4</ref><ref type="table">5</ref><ref type="table">6</ref>, the SS means the sum of squares, the DoF is the degree of freedom, the MS represents the mean of squares, and the F is the F ratio. The significance level is set at 0.05 in this experiment, and by looking up the F distribution table, the influence level of the parameter can be ascertained: F 2 , 18 (0 . 05) = 3 . 55 ; therefore, if the F ratio satisfies F &gt; 3.55, the parameter has a significant influence on the algorithm. In the last column of the tables, the "+" symbol means the parameter has a significant impact on the performance of the algorithm. It can be observed that on MaOP2, MaOP4, MaOP5, and MaOP7, the four parameters have a significant influence on the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results and comparison</head><p>In this section, first, the convergence performance of the algorithms is compared to verify the availability of the proposed RVMEA/OL and investigate its convergence speed. Next, the performance of the algorithms is tested on test cases MaOP1-10. The experimental results are analyzed from the aspects of the statistics of the IGD+ indicator and the reflection of the shape of the PF. All experiments are implemented on a computer with an Intel i7-6700k CPU and 16GB of memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Convergence analysis</head><p>The convergence experiment plays two roles: verifying the availability of the proposed algorithm and reflecting the performance of the algorithm. If the experimental results of the proposed algorithm do not converge, the algorithm design does not make sense. According to the slope of the convergence curve, the convergence speed of the tested algorithms can be compared. By comparing the end of the convergence curve, the performance of the algorithm is reflected.</p><p>The convergence experiment is implemented on MaOP2-7. For each test case, all the tested algorithms are executed 30 times. Every ten iterations, the current Pareto optimal solution set is recorded, and its quality is evaluated by the IGD+  indicator. The algorithm calculates the average IGD+ of each period. The convergence plots in Fig. <ref type="figure" target="#fig_4">4</ref> are drawn according to the iteration counts and the corresponding mean IGD+ values. Because of that the optimization procedure of the many-objective problem is time consuming, it is not appropriate to repeat the experiment too many times. However, If the number of repeated experiments is insufficient, the generality of the experimental results cannot be guaranteed. Therefore, it is vital to balance the computation time consuming and the effectiveness of the statistical results when setting the number of independent repeat experiments. The central boundary theorem describes the distribution of the mean of a random sample of a population with finite variance. When the sample size is large enough, the mean distribution is an approximately normal distribution. Considering this, and in order to guarantee this premise, many works <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b39">40]</ref> use the number of 30 runs when want to show the performance of one stochastic method over another or try to perform as fine-tuning of parameters.</p><p>As shown in Fig. <ref type="figure" target="#fig_4">4</ref> , the RVMEA/OL has satisfactory convergence performance. In the first half of the optimization process, the convergence curve of the RVMEA/OL has a high slope, which indicates the RVMEA/OL has good convergence speed. On the convergence plots, the convergence curve of the RVMEA/OL ends at a lower location, it means the solution quality of the proposed algorithm is satisfactory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Analysis based on statistic comparison</head><p>In Tables <ref type="table" target="#tab_5">7</ref> and<ref type="table" target="#tab_6">8</ref> , the experimental results of the tested algorithms on small-scale problems and large-scale problems are compared, respectively. The experimental data are counted and presented in the tables in the form of "mean/variance". The data in boldface represents the best mean value or variance in a row. To conduct a more accurate study of the performance of each algorithm, the Wilcoxon signed-rank method <ref type="bibr" target="#b14">[15]</ref> is introduced into the comparison to verify the difference between the experimental results of RVMEA/OL and experimental results of other tested algorithms. For this experiment, the significance level is set to 95%. With the p -v alue ≤ 0 . 05 , the proposed algorithm is significantly better than the peer algorithms. For Tables <ref type="table" target="#tab_5">7</ref> and<ref type="table" target="#tab_6">8</ref> , in the columns of MOEA/D, NSGA-III, RVEA, MOEA/DD and VaEA, the symbols of "+ " or "-" are marked after the experimental results. The "+ " indicates the experimental results of RVMEA/OL are significantly better than that of the compared algorithms, and the "-" represents other conditions. The p -v alues of the hypothesis tests are shown in Tables <ref type="table" target="#tab_7">9</ref> and<ref type="table" target="#tab_8">10</ref> . As shown in Table <ref type="table" target="#tab_5">7</ref> , when M = 3 , the RVMEA/OL obtains the optimal mean and variance simultaneously on six test cases. It performs better than other baseline algorithms on variance on three test cases. In addition, it obtains the best mean on one test case. The mean and variance of experimental results of the RVMEA/OL are optimal on MaOP3, MaOP5-8, and MaOP10. On MaOP2, MaOP4, and MaOP9, the variance of the results of the RVMEA/OL are optimal. On MaOP1, the RVMEA/OL obtains the minimum mean value. For the case of M = 5 , the variance of the RVMEA/OL is optimal on seven test cases. The mean value and variance of the experimental results on MaOP1-5, MaOP8, MaOP9, and MaOP10. On MaOP6, the mean value of the results of the RVMEA/OL is the best among the tested algorithms. According to the result of the Wilcoxon hypothesis test, when M = 3 , the experimental results of the RVMEA/OL are significantly better than those of the other algorithms on MaOP1, MaOP3, MaOP5-8, MaOP10. When M = 5 , the RVMEA/OL significantly outperforms the compared algorithm on MaOP1-6, MaOP9, and MaOP10. It can be observed that for small-scale problems, i.e. problems constrained by a small number of objectives, the performance of the RVMEA/OL is better than other tested algorithms on most of the test cases. For these problems, the RVMEA/OL has efficient optimization performance and satisfactory stability.</p><p>According to Table <ref type="table" target="#tab_6">8</ref> , for large-scale test cases, when M = 10 , the experimental results of the RVMEA/OL are optimal on both the mean value and variance on seven test cases: MaOP1-4, MaOP7, MaOP9, and MaOP10. On MaOP5 and MaOP6, the mean value of results of the RVMEA/OL is better than the results of other algorithms. On MaOP8, the RVMEA/OL is the optimal on the variance than the compared algorithms. When the number of objectives rises to M = 15 , on the test cases of MaOP1-7, the results of the RVMEA/OL is better than the results of the compared algorithms on mean value and variance. The RVMEA/OL obtains the best mean value on MaOP9. The results of the Wilcoxon test indicate that the RVMEA/OL outperforms all compared algorithms on MaOP1-6 and MaOP10 when M = 10 . When M = 15 , the experimental results of the RVMEA/OL are significantly optimal compared with the results of other algorithms on MaOP1-5, MaOP7, and MaOP9. For large-scale test cases, although the complexity of the problems is increased, the RVMEA/OL maintains satisfactory performance. On most of the test cases, the performance of the RVMEA/OL is better than the compared algorithms.</p><p>For MaOP, the algorithm should not only make the approximation set become close to the PF, but also make the distribution of the solution set as extensive as possible within the coverage range of the PF. Reflecting the shape of the PF is an important target of the EMaOAs. The parallel coordinates plot <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b35">36]</ref> was introduced as a tool to measure the approximation degree of the solution set to the PF. It is an efficient method to realize the visualization of high dimensional data. The parallel coordinates plot displays the evaluation of each objective function on a parallel axis and the value of the objective functions are connected by a polyline. For Figs. 5 to 6 , the parallel plots are drawn according to experimental results on MaOP6 and MaOP8 when M = 10 . The MaOP6 and MaOP8 have an irregular PF. It can be observed that the proposed RVMEA/OL has the closest approximation of the PFs among the tested algorithms. A satisfactory approximation of the PF brings two benefits: 1) The solution set shows more possible weight combinations for different objectives, which provides a more comprehensive reference for decision makers. 2) Because the evaluation of solution quality is based on the distance from the approximation set to the PF, if the approximation set has an extensive distribution, compared to a concentrated solution, it has better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Performance on solving reactive power optimization problem</head><p>To justify the impact of the proposed algorithm over real problem scenarios. The RVMEA/OL is tested on the reactive power optimization problem. This problem can be modeled as a MaOP with four target objectives <ref type="bibr" target="#b48">[49]</ref> .</p><p>The target of the reactive power optimization is to minimize the active power loss, node voltage deviation, and the index of power supply capability, and maximize the voltage stability. To optimize the four objectives, the optimizing targets are transformed into four minimization single problems. The objective functions are listed as Eq. ( <ref type="formula">23</ref>) to Eq. ( <ref type="formula" target="#formula_29">26</ref>) . They represent active power loss, node voltage deviation, static voltage stability and the index of power supply capability based on power flow entropy, respectively.  </p><formula xml:id="formula_28">f 1 (X 1 , X 2 ) = k ∈ N B g k (U 2 i + U 2 j -2 U i U j cos θ ) (23)</formula><formula xml:id="formula_29">2 (X 1 , X 2 ) = k ∈ N I | U li -U * li | U li max -U li min (24) f 3 (X 1 , X 2 ) = k ∈ N B 4 U j U i - U 2 j U i (25) f 4 (X 1 , X 2 ) = e -H -e -H min e -H max -e -H min<label>(26)</label></formula><p>The equations g(X 1 , X 2 ) = 0 and h ( X 1 , X 2 ) ≤ 0 is utilized to limit the power flow and the variable bound. Control variable</p><formula xml:id="formula_30">X 1 = [ U T G , Q T C , T T B ]</formula><p>T , where U T G is the vector of generator voltage, Q T C is the vector representing VAR compensator's output, T T B is the vector of underload tap changing transformer ratio.</p><formula xml:id="formula_31">X 2 = [ U T L , Q T G ]</formula><p>T is the state variable, where U T L is the vector of load bus voltage, Q T G is the vector of generator's reactive power output. The N B is the set of system branch, U i is the voltage of a branch's head end, U j is the voltage of a branch's end.  Therefore, the reactive power optimization is modeled as a many objective problem:</p><formula xml:id="formula_32">minimize F (X 1 , X 2 ) = (F 1 (X 1 , X 2 ) , F 2 (X 1 , X 2 ) , F 3 (X 1 , X 2 ) , F 4 (X 1 , X 2 ))<label>(27)</label></formula><p>A simulation experiment is implemented on IEEE14-bus systems <ref type="bibr" target="#b20">[21]</ref> to test the performance of the RVMEA/OL. The under-load tap changing transformer branches are branch 4-7, 4-9, and 5-6. VAR compensator bases are bus 4, 5, and 9. The upper and lower limits of each variable are set according to the data provided in <ref type="bibr" target="#b48">[49]</ref> . The experimental settings of the algorithms are the same as in the fourth part.</p><p>In this experiment, multiple EMaOA algorithm are executed for forty times to construct a solution set to represent the PF. Then the tested algorithms are run to obtain their own ap-proximation set. As shown in <ref type="bibr">Table 11</ref> , the IGD+ values of the tested algorithms are calculated to compare their performance. Each algorithm is executed for thirty times. As shown in Table <ref type="table" target="#tab_9">11</ref> , the mean value and variance of the RVMEA/OL outperform the results of other baseline algorithms.</p><p>The experimental results indicate that when optimizing the reactive power optimization problem, the RVDE-RVA can provide a better trade-off of the objectives. And Fig. <ref type="figure" target="#fig_8">7</ref> shows that the RVMEA/OL obtains a better approximation set, which is closer to the PF than the baseline algorithms. The results of the RVMEA/OL is more concentrated, that means the RVMEA/OL can obtain stable results on this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Performance discussion</head><p>The results of the convergence experiment indicate that the RVMEA/OL has rapid convergence speed. In addition, its final convergence performance is satisfactory. The convergence results can reflect the efficiency of the proposed algorithm. In most circumstances, there are limited computing resources for the algorithm. This requires that the algorithm has to use fewer resources to complete the optimization in a short time. The convergence curves of RVMEA/OL illustrate that the IGD+ value of the approximation set of RVMEA/OL can converge to a small IGD+ value within fewer iteration numbers than the compared algorithms, which indicates that for application scenarios with high real-time requirements, the RVMEA/OL can obtain better performance.</p><p>The results of the statistical experiment and hypothesis test indicate that the RVMEA/OL obtains the best mean and variance on most of the test cases, regardless of the objective number. For MaOP1-4, the algorithm significantly outperforms other algorithms. This proves RVMEA/OL has significantly better performance on MaOP test cases with regular PF. The RVMEA/OL has a smaller IGD+ value and the experimental results of RVMEA/OL are more stable. For irregular test cases, i.e. MaOP5-10, although the performance of the algorithm is not as good as that on MaOP1-4, the RVMEA/OL obtains satisfactory performance on a part of the test cases, and especially when the objective number is greater than five, the performance of RVMEA/OL is significantly better. It can be noted that the performance of RVMEA/OL on irregular test cases is not very satisfactory. There are two possible reasons for this: the first is that the number of reference vectors has a definite effect on algorithm performance. If the distribution of reference vectors is too sparse, the approximation set cannot reflect the detail of the shape of PF. However, too many of the reference vectors will lead to a large amount of computation cost, which is also unacceptable. The other reason is that in the pre-set uniformly distributed reference vectors, a majority of the reference vectors can provide no help to the optimization when optimizing MaOP with degenerated PF. In this case, a reference vector adjustment strategy is needed for transferring reference vectors to the space covered by PF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, a learning-based evolutionary many-objective algorithm (RVMEA/OL) is proposed. The proposed algorithm utilizes the feature of sub-problems by evaluating the matching degree of the problem feature and searching status. A learning-based reproduction strategy is presented. This strategy employs an LA to choose suitable mutation operators according to the feedback signal. Based on the density information of the external archive, a reference vector adjustment strategy is designed in the RVMEA/OL to handle MaOPs with irregular PFs. To investigate the performance of the RVMEA/OL, a comparison experiment on ten novel and typical test cases is implemented. The experimental results indicate that the generalization ability of the RVMEA/OL is significantly enhanced. It significantly outperforms the compared algorithms on most of the test cases, regardless of the dimensionality of the objective space or the problem features.</p><p>This paper has verified the assistant effect of reinforcement learning on enhancing the efficiency and solution accuracy of the EMaOA. The performance of RVMEA/OL on MaOPs with irregular PF in high-dimensionality scenarios can still improve.</p><p>In future works, improving the optimization method for MaOP with irregular PF in an objective space with more than ten dimensionalities can be a meaningful research direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Competing Interest</head><p>None.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Interactive process between the learning automaton and the environment.</figDesc><graphic coords="4,204.54,55.72,140.16,80.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .Algorithm 2</head><label>22</label><figDesc>Fig. 2. Dividing reference vectors into groups.</figDesc><graphic coords="8,190.55,55.28,168.00,141.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Effect of parameters.</figDesc><graphic coords="11,42.25,186.77,456.00,282.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Comparison of convergence speed.</figDesc><graphic coords="13,42.25,56.13,456.00,617.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The parallel coordinate plots of the final non-dominated solution sets of (a) MOEA/D, (b) NSGA-III, (c) RVEA , (d) VaEA , (e) MOEA/DD, and (f) RVDE-RVA when M = 10 on the test case MaOP6.</figDesc><graphic coords="17,42.25,55.47,456.00,436.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>f</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. The parallel coordinate plots of the final non-dominated solution sets of (a) MOEA/D, (b) NSGA-III, (c) RVEA , (d) VaEA , (e) MOEA/DD, and (f) RVDE-RVA when M = 10 on the test case MaOP8.</figDesc><graphic coords="18,46.55,55.27,456.00,417.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Box plot of experiment on the reactive power optimization problem.</figDesc><graphic coords="19,162.24,55.28,216.00,177.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Algorithm 1</head><label>1</label><figDesc>Learning based variation strategy.</figDesc><table><row><cell>2:</cell><cell>calculate current strategy reward by Eq. (15);</cell></row><row><cell>3:</cell><cell>update cumulative reward by Eq. 16;</cell></row><row><cell>10:</cell><cell>end if</cell></row><row><cell>11:</cell><cell>end for</cell></row><row><cell>12:</cell><cell></cell></row></table><note><p><p><p><p><p><p><p><p><p><p>Input: candidate variation strategies s = s 1 , s 2 , s 3 ; transition matrix T M i ; optimal solution of sub-problem i at tth and (t -1)) th iteration: x (i, t ) , x (i, t -1) ; Output: The offspring set of the tth generation: Po t ; 1: for sub-problem i in sub-problem set do 4: calculate the reward/penalty signal according to Eq. (17); 5: for each strategy s i,t do 6: if s i,t == s i,t-1 then 7:</p>update the transition probability by Eq. (</p>18</p>);</p>8: else 9:</p>update the transition probability by Eq. (</p>19</p>);</p>s j ← --</p>RouletteGreedy (s, T M) ; 13: generate the mutation intermedia u i according to s j ; 14: offspring o t = crossov er(u i ) ; 15: add o t into Po t ; 16: end for</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>Layering method and population number.</figDesc><table><row><cell>M</cell><cell>Inner Layer</cell><cell>Outer Layer</cell><cell>Population Size</cell></row><row><cell>3</cell><cell>13</cell><cell>0</cell><cell>135</cell></row><row><cell>5</cell><cell>6</cell><cell>0</cell><cell>210</cell></row><row><cell>10</cell><cell>3</cell><cell>2</cell><cell>230</cell></row><row><cell>15</cell><cell>2</cell><cell>1</cell><cell>135</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc>Sparse vector number and group size.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>ANOVA results on MaOP2.</figDesc><table><row><cell>Items</cell><cell>SS</cell><cell>DoF</cell><cell>MS</cell><cell>F</cell><cell>Significance</cell></row><row><cell>m</cell><cell>1.12E-02</cell><cell>2</cell><cell>5.61E-03</cell><cell>9.52E + 01</cell><cell>+</cell></row><row><cell>τ</cell><cell>7.52E-03</cell><cell>2</cell><cell>3.76E-03</cell><cell>6.38E + 01</cell><cell>+</cell></row><row><cell></cell><cell>6.49E-03</cell><cell>2</cell><cell>3.25E-03</cell><cell>5.52E + 01</cell><cell>+</cell></row><row><cell>I</cell><cell>1.96E-03</cell><cell>2</cell><cell>9.83E-04</cell><cell>1.67E + 01</cell><cell>+</cell></row><row><cell>Error</cell><cell>1.06E-03</cell><cell>18</cell><cell>5.89E-05</cell><cell></cell><cell></cell></row><row><cell>Total</cell><cell></cell><cell>26</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Table 4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">ANOVA results on MaOP4.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Items</cell><cell>SS</cell><cell>DoF</cell><cell>MS</cell><cell>F</cell><cell>Significance</cell></row><row><cell>m</cell><cell>9.28E-03</cell><cell>2</cell><cell>4.64E-03</cell><cell>6.57E + 01</cell><cell>+</cell></row><row><cell>τ</cell><cell>8.35E-03</cell><cell>2</cell><cell>4.18E-03</cell><cell>5.92E + 01</cell><cell>+</cell></row><row><cell></cell><cell>4.36E-03</cell><cell>2</cell><cell>2.18E-03</cell><cell>3.09E + 01</cell><cell>+</cell></row><row><cell>I</cell><cell>3.33E-03</cell><cell>2</cell><cell>1.67E-03</cell><cell>2.37E + 01</cell><cell>+</cell></row><row><cell>Error</cell><cell>1.27E-03</cell><cell>18</cell><cell>7.06E-05</cell><cell></cell><cell></cell></row><row><cell>Total</cell><cell></cell><cell>26</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Table 5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">ANOVA results on MaOP5.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Items</cell><cell>SS</cell><cell>DoF</cell><cell>MS</cell><cell>F</cell><cell>Significance</cell></row><row><cell>m</cell><cell>8.62E-03</cell><cell>2</cell><cell>4.31E-03</cell><cell>5.79E + 01</cell><cell>+</cell></row><row><cell>τ</cell><cell>3.79E-03</cell><cell>2</cell><cell>1.89E-03</cell><cell>2.55E + 01</cell><cell>+</cell></row><row><cell></cell><cell>1.37E-03</cell><cell>2</cell><cell>6.85E-04</cell><cell>9.21E + 00</cell><cell>+</cell></row><row><cell>I</cell><cell>8.25E-04</cell><cell>2</cell><cell>4.13E-04</cell><cell>5.55E + 00</cell><cell>+</cell></row><row><cell>Error</cell><cell>1.34E-03</cell><cell>18</cell><cell>7.44E-05</cell><cell></cell><cell></cell></row><row><cell>Total</cell><cell></cell><cell>26</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Table 6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">ANOVA results on MaOP7.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Items</cell><cell>SS</cell><cell>DoF</cell><cell>MS</cell><cell>F</cell><cell>Significance</cell></row><row><cell>m</cell><cell>9.81E-03</cell><cell>2</cell><cell>4.91E-03</cell><cell>7.07E + 01</cell><cell>+</cell></row><row><cell>τ</cell><cell>7.64E-03</cell><cell>2</cell><cell>3.82E-03</cell><cell>5.50E + 01</cell><cell>+</cell></row><row><cell></cell><cell>2.58E-03</cell><cell>2</cell><cell>1.29E-03</cell><cell>1.86E + 01</cell><cell>+</cell></row><row><cell>I</cell><cell>1.16E-03</cell><cell>2</cell><cell>5.80E-04</cell><cell>8.35E + 00</cell><cell>+</cell></row><row><cell>Error</cell><cell>1.25E-03</cell><cell>18</cell><cell>6.94E-05</cell><cell></cell><cell></cell></row><row><cell>Total</cell><cell></cell><cell>26</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7</head><label>7</label><figDesc>Experimental results on small-scale problems.</figDesc><table><row><cell>Problem</cell><cell>M</cell><cell>MOEA/D</cell><cell>NSGA-III</cell><cell>RVEA</cell><cell>VaEA</cell><cell>MOEA/DD</cell><cell>RVMEA/OL</cell></row><row><cell>MaOP1</cell><cell>3</cell><cell>3.85E-02/</cell><cell>4.11E-02/</cell><cell>4.11E-02/</cell><cell>5.35E-02/</cell><cell>4.55E-02/</cell><cell>3.58E-02/</cell></row><row><cell></cell><cell></cell><cell>1.10E-05 +</cell><cell>4.71E-06 +</cell><cell>2.40E-04 +</cell><cell>6.87E-04 +</cell><cell>9.31E-06 +</cell><cell>3.34E-05</cell></row><row><cell></cell><cell>5</cell><cell>9.31E-02/</cell><cell>7.13E-02/</cell><cell>1.19E-01/</cell><cell>1.20E-01/</cell><cell>8.36E-02/</cell><cell>7.09E-02/</cell></row><row><cell></cell><cell></cell><cell>9.15E-06 +</cell><cell>2.09E-06 +</cell><cell>1.91E-03 +</cell><cell>3.79E-04 +</cell><cell>4.14E-05 +</cell><cell>4.49E-06</cell></row><row><cell>MaOP2</cell><cell>3</cell><cell>3.44E-02/</cell><cell>1.75E-02/</cell><cell>5.94E-02/</cell><cell>6.88E-02/</cell><cell>4.83E-02/</cell><cell>2.56E-02/</cell></row><row><cell></cell><cell></cell><cell>3.30E-05 +</cell><cell>6.29E-06-</cell><cell>2.45E-04 +</cell><cell>2.69E-04 +</cell><cell>7.63E-05 +</cell><cell>5.82E-06</cell></row><row><cell></cell><cell>5</cell><cell>6.58E-02/</cell><cell>4.22E-02/</cell><cell>6.14E-02/</cell><cell>6.72E-02/</cell><cell>5.66E-02/</cell><cell>3.99E-02/</cell></row><row><cell></cell><cell></cell><cell>2.15E-06 +</cell><cell>1.38E-05 +</cell><cell>2.75E-05 +</cell><cell>6.54E-05 +</cell><cell>1.73E-05 +</cell><cell>1.02E-06</cell></row><row><cell>MaOP3</cell><cell>3</cell><cell>1.52E-01/</cell><cell>2.38E-01/</cell><cell>1.90E-01/</cell><cell>2.75E-01/</cell><cell>2.06E-01/</cell><cell>9.42E-02/</cell></row><row><cell></cell><cell></cell><cell>4.26E-02 +</cell><cell>2.55E-02 +</cell><cell>2.43E-02 +</cell><cell>9.28E-03 +</cell><cell>6.18E-02 +</cell><cell>2.70E-03</cell></row><row><cell></cell><cell>5</cell><cell>1.32E-01/</cell><cell>8.11E-02/</cell><cell>1.46E-01/</cell><cell>3.29E-01/</cell><cell>1.67E-01/</cell><cell>7.66E-02/</cell></row><row><cell></cell><cell></cell><cell>1.47E-05 +</cell><cell>3.76E-05 +</cell><cell>1.89E-03 +</cell><cell>5.66E-04 +</cell><cell>6.47E-05 +</cell><cell>1.43E-05</cell></row><row><cell>MaOP4</cell><cell>3</cell><cell>7.39E-03/</cell><cell>8.31E-03/</cell><cell>3.28E-02/</cell><cell>5.95E-02/</cell><cell>4.04E-02/</cell><cell>9.14E-03/</cell></row><row><cell></cell><cell></cell><cell>1.70E-07-</cell><cell>8.47E-07-</cell><cell>5.47E-06 +</cell><cell>4.23E-05 +</cell><cell>1.90E-05 +</cell><cell>6.81E-08</cell></row><row><cell></cell><cell>5</cell><cell>9.32E-02/</cell><cell>4.04E-02/</cell><cell>8.72E-02/</cell><cell>7.65E-02/</cell><cell>8.27E-02/</cell><cell>3.90E-02/</cell></row><row><cell></cell><cell></cell><cell>1.76E-05 +</cell><cell>8.20E-07 +</cell><cell>7.16E-05 +</cell><cell>6.22E-05 +</cell><cell>7.43E-06 +</cell><cell>2.99E-07</cell></row><row><cell>MaOP5</cell><cell>3</cell><cell>8.24E-02/</cell><cell>1.18E-02/</cell><cell>3.43E-02/</cell><cell>1.03E-01/</cell><cell>6.57E-02/</cell><cell>1.10E-02/</cell></row><row><cell></cell><cell></cell><cell>4.66E-02 +</cell><cell>2.01E-06 +</cell><cell>4.78E-05 +</cell><cell>6.22E-06 +</cell><cell>7.09E-06 +</cell><cell>2.82E-07</cell></row><row><cell></cell><cell>5</cell><cell>1.35E-02/</cell><cell>2.25E-02/</cell><cell>7.67E-02/</cell><cell>4.86E-02/</cell><cell>8.61E-02/</cell><cell>1.25E-02/</cell></row><row><cell></cell><cell></cell><cell>2.02E-06 +</cell><cell>1.67E-04 +</cell><cell>1.30E-04 +</cell><cell>6.46E-04 +</cell><cell>3.72E-04 +</cell><cell>5.25E-07</cell></row><row><cell>MaOP6</cell><cell>3</cell><cell>7.05E-02/</cell><cell>2.82E-02/</cell><cell>6.01E-02/</cell><cell>7.59E-02/</cell><cell>6.57E-02/</cell><cell>2.49E-02/</cell></row><row><cell></cell><cell></cell><cell>2.84E-03 +</cell><cell>1.71E-05 +</cell><cell>6.75E-05 +</cell><cell>3.14E-06 +</cell><cell>6.48E-05 +</cell><cell>2.43E-06</cell></row><row><cell></cell><cell>5</cell><cell>7.02E-02/</cell><cell>2.48E-02/</cell><cell>5.55E-02/</cell><cell>6.57E-02/</cell><cell>5.94E-02/</cell><cell>2.20E-02/</cell></row><row><cell></cell><cell></cell><cell>4.48E-04 +</cell><cell>5.56E-05 +</cell><cell>5.25E-05 +</cell><cell>3.09E-05 +</cell><cell>6.48E-05 +</cell><cell>3.12E-05</cell></row><row><cell>MaOP7</cell><cell>3</cell><cell>1.71E-01/</cell><cell>1.71E-01/</cell><cell>1.43E-01/</cell><cell>1.84E-01/</cell><cell>1.64E-01/</cell><cell>1.31E-01/</cell></row><row><cell></cell><cell></cell><cell>9.23E-03 +</cell><cell>6.92E-03 +</cell><cell>1.03E-03 +</cell><cell>6.79E-03 +</cell><cell>5.77E-04 +</cell><cell>3.61E-04</cell></row><row><cell></cell><cell>5</cell><cell>1.55E-01/</cell><cell>1.06E-01/</cell><cell>1.94E-01/</cell><cell>2.09E-01/</cell><cell>1.75E-01/</cell><cell>1.17E-02/</cell></row><row><cell></cell><cell></cell><cell>2.17E-03 +</cell><cell>1.19E-03-</cell><cell>1.64E-03 +</cell><cell>4.37E-03 +</cell><cell>6.18E-04 +</cell><cell>2.50E-03</cell></row><row><cell>MaOP8</cell><cell>3</cell><cell>2.58E-01/</cell><cell>1.58E-01/</cell><cell>1.21E-01/</cell><cell>2.49E-01/</cell><cell>1.92E-01/</cell><cell>1.12E-01/</cell></row><row><cell></cell><cell></cell><cell>1.99E-02 +</cell><cell>1.85E-03 +</cell><cell>5.21E-04 +</cell><cell>6.44E-04 +</cell><cell>7.60E-03 +</cell><cell>2.00E-04</cell></row><row><cell></cell><cell>5</cell><cell>1.96E-01/</cell><cell>1.04E-01/</cell><cell>1.70E-01/</cell><cell>2.01E-01/</cell><cell>1.86E-01/</cell><cell>9.62E-02/</cell></row><row><cell></cell><cell></cell><cell>5.87E-03 +</cell><cell>9.19E-04-</cell><cell>1.39E-03 +</cell><cell>3.57E-03 +</cell><cell>1.43E-03 +</cell><cell>1.24E-04</cell></row><row><cell>MaOP9</cell><cell>3</cell><cell>2.79E-01/</cell><cell>1.02E-01/</cell><cell>1.37E-01/</cell><cell>1.49E-01/</cell><cell>1.95E-01/</cell><cell>1.08E-02/</cell></row><row><cell></cell><cell></cell><cell>1.28E-02 +</cell><cell>1.13E-02-</cell><cell>9.36E-04 +</cell><cell>5.53E-03 +</cell><cell>2.20E-04 +</cell><cell>1.79E-04</cell></row><row><cell></cell><cell>5</cell><cell>3.47E-01/</cell><cell>9.98E-02/</cell><cell>1.64E-01/</cell><cell>1.94E-01/</cell><cell>3.04E-01/</cell><cell>9.67E-02/</cell></row><row><cell></cell><cell></cell><cell>5.51E-03 +</cell><cell>6.46E-04 +</cell><cell>2.63E-03 +</cell><cell>5.10E-03 +</cell><cell>1.76E-03 +</cell><cell>5.25E-04</cell></row><row><cell>MaOP10</cell><cell>3</cell><cell>2.94E-01/</cell><cell>1.03E-01/</cell><cell>1.80E-01/</cell><cell>3.57E-01/</cell><cell>4.27E-01/</cell><cell>9.58E-02/</cell></row><row><cell></cell><cell></cell><cell>2.11E-02 +</cell><cell>4.06E-03 +</cell><cell>6.78E-03 +</cell><cell>9.44E-03 +</cell><cell>3.98E-03 +</cell><cell>3.77E-03</cell></row><row><cell></cell><cell>5</cell><cell>3.23E-01/</cell><cell>9.75E-02/</cell><cell>1.67E-01/</cell><cell>1.92E-01/</cell><cell>1.84E-01/</cell><cell>9.52E-02/</cell></row><row><cell></cell><cell></cell><cell>4.74E-03 +</cell><cell>6.84E-04 +</cell><cell>1.57E-03 +</cell><cell>5.86E-03 +</cell><cell>6.06E-03 +</cell><cell>1.83E-04</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8</head><label>8</label><figDesc>Experimental results on large-scale problems.</figDesc><table><row><cell>Problem</cell><cell>M</cell><cell>MOEA/D</cell><cell>NSGA-III</cell><cell>RVEA</cell><cell>VaEA</cell><cell>MOEA/DD</cell><cell>RVMEA/OL</cell></row><row><cell>MaOP1</cell><cell cols="2">10 1.61E-01/</cell><cell>1.92E-01/</cell><cell>5.84E-01/</cell><cell>2.93E-01/</cell><cell>1.78E-01/</cell><cell>1.51E-01/</cell></row><row><cell></cell><cell></cell><cell>1.51E-05 +</cell><cell>1.35E-04 +</cell><cell>6.34E-03 +</cell><cell>8.45E-03 +</cell><cell>3.66E-03 +</cell><cell>1.26E-05</cell></row><row><cell></cell><cell cols="2">15 1.93E-01/</cell><cell>2.70E-01/</cell><cell>7.20E-01/</cell><cell>2.99E-01/</cell><cell>2.08E-01/</cell><cell>1.86E-01/</cell></row><row><cell></cell><cell></cell><cell>3.07E-05 +</cell><cell>8.63E-04 +</cell><cell>5.52E-02 +</cell><cell>4.60E-02 +</cell><cell>6.47E-04 +</cell><cell>1.44E-05</cell></row><row><cell>MaOP2</cell><cell cols="2">10 6.91E-02/</cell><cell>3.07E-02/</cell><cell>1.00E-01/</cell><cell>1.29E-01/</cell><cell>5.37E-02/</cell><cell>2.89E-02/</cell></row><row><cell></cell><cell></cell><cell>1.42E-05 +</cell><cell>9.41E-06 +</cell><cell>4.87E-05 +</cell><cell>3.86E-04 +</cell><cell>8.61E-05 +</cell><cell>7.36E-06</cell></row><row><cell></cell><cell cols="2">15 1.18E-01/</cell><cell>3.22E-02/</cell><cell>9.37E-02/</cell><cell>1.34E-01/</cell><cell>9.63E-02/</cell><cell>2.79E-02/</cell></row><row><cell></cell><cell></cell><cell>7.36E-05 +</cell><cell>2.15E-06 +</cell><cell>1.93E-05 +</cell><cell>5.44E-05 +</cell><cell>3.47E-05 +</cell><cell>7.91E-07</cell></row><row><cell>MaOP3</cell><cell cols="2">10 3.01E-01/</cell><cell>1.31E-01/</cell><cell>2.10E-01/</cell><cell>2.42E-01/</cell><cell>1.98E-01/</cell><cell>1.21E-01/</cell></row><row><cell></cell><cell></cell><cell>6.40E-04 +</cell><cell>2.25E-04 +</cell><cell>2.86E-04 +</cell><cell>3.59E-04 +</cell><cell>7.61E-04 +</cell><cell>1.86E-04</cell></row><row><cell></cell><cell cols="2">15 3.18E-01/</cell><cell>1.68E-01/</cell><cell>1.51E-01/</cell><cell>2.59E-01/</cell><cell>2.14E-01/</cell><cell>1.38E-01/</cell></row><row><cell></cell><cell></cell><cell>6.75E-04 +</cell><cell>1.77E-03 +</cell><cell>2.37E-03 +</cell><cell>2.67E-03 +</cell><cell>3.86E-03 +</cell><cell>6.43E-04</cell></row><row><cell>MaOP4</cell><cell cols="2">10 4.13E-01/</cell><cell>6.57E-02/</cell><cell>5.46E-02/</cell><cell>7.83E-02/</cell><cell>4.10E-01/</cell><cell>5.14E-02/</cell></row><row><cell></cell><cell></cell><cell>1.15E-01 +</cell><cell>1.49E-05 +</cell><cell>1.74E-05 +</cell><cell>6.10E-04 +</cell><cell>6.60E-05 +</cell><cell>1.28E-05</cell></row><row><cell></cell><cell cols="2">15 3.19E-01/</cell><cell>6.98E-02/</cell><cell>1.80E-01/</cell><cell>5.47E-01/</cell><cell>4.13E-01/</cell><cell>5.37E-02/</cell></row><row><cell></cell><cell></cell><cell>1.09E-03 +</cell><cell>1.19E-03 +</cell><cell>3.63E-03 +</cell><cell>6.81E-03 +</cell><cell>4.33E-03 +</cell><cell>3.06E-04</cell></row><row><cell>MaOP5</cell><cell cols="2">10 2.02E-01/</cell><cell>1.87E-01/</cell><cell>2.11E-01/</cell><cell>4.57E-01/</cell><cell>2.49E-01/</cell><cell>1.62E-01/</cell></row><row><cell></cell><cell></cell><cell>5.89E-02 +</cell><cell>6.19E-05 +</cell><cell>3.98E-03 +</cell><cell>7.69E-03 +</cell><cell>3.09E-03 +</cell><cell>7.58E-05</cell></row><row><cell></cell><cell cols="2">15 2.64E-01/</cell><cell>1.94E-01/</cell><cell>3.51E-01/</cell><cell>4.66E-01/</cell><cell>2.26E-01/</cell><cell>1.79E-01/</cell></row><row><cell></cell><cell></cell><cell>3.37E-02 +</cell><cell>3.59E-04 +</cell><cell>1.55E-02 +</cell><cell>7.36E-03 +</cell><cell>3.14E-03 +</cell><cell>3.98E-05</cell></row><row><cell>MaOP6</cell><cell cols="2">10 1.05E-01/</cell><cell>1.46E-01/</cell><cell>1.19E-01/</cell><cell>1.97E-01/</cell><cell>1.10E-01/</cell><cell>8.82E-02/</cell></row><row><cell></cell><cell></cell><cell>1.39E-03 +</cell><cell>2.55E-05 +</cell><cell>1.10E-03 +</cell><cell>6.88E-03 +</cell><cell>1.63E-03 +</cell><cell>3.67E-04</cell></row><row><cell></cell><cell cols="2">15 6.52E-02/</cell><cell>1.93E-01/</cell><cell>2.33E-01/</cell><cell>2.91E-01/</cell><cell>9.30E-02/</cell><cell>6.32E-02/</cell></row><row><cell></cell><cell></cell><cell>3.60E-04-</cell><cell>2.95E-04 +</cell><cell>5.25E-03 +</cell><cell>6.42E-03 +</cell><cell>4.82E-03 +</cell><cell>2.91E-04</cell></row><row><cell>MaOP7</cell><cell cols="2">10 1.59E-01/</cell><cell>2.17E-01/</cell><cell>2.55E-01/</cell><cell>3.47E-01/</cell><cell>1.67E-01/</cell><cell>1.55E-01/</cell></row><row><cell></cell><cell></cell><cell>2.99E-05-</cell><cell>4.88E-04 +</cell><cell>1.80E-03 +</cell><cell>5.77E-03 +</cell><cell>1.06E-03 +</cell><cell>9.31E-06</cell></row><row><cell></cell><cell cols="2">15 1.04E-01/</cell><cell>2.75E-01/</cell><cell>2.83E-01/</cell><cell>1.06E-01/</cell><cell>1.04E-01/</cell><cell>9.54E-02/</cell></row><row><cell></cell><cell></cell><cell>6.35E-04 +</cell><cell>6.49E-04 +</cell><cell>8.79E-04 +</cell><cell>9.33E-04 +</cell><cell>4.67E-04 +</cell><cell>1.88E-05</cell></row><row><cell>MaOP8</cell><cell cols="2">10 1.03E-01/</cell><cell>1.76E-01/</cell><cell>2.98E-01/</cell><cell>4.92E-01/</cell><cell>3.34E-01/</cell><cell>1.39E-02/</cell></row><row><cell></cell><cell></cell><cell>9.19E-06-</cell><cell>1.51E-03 +</cell><cell>3.98E-03 +</cell><cell>6.71E-03 +</cell><cell>1.87E-03 +</cell><cell>6.89E-06</cell></row><row><cell></cell><cell cols="2">15 2.87E-01/</cell><cell>2.58E-01/</cell><cell>3.23E-01/</cell><cell>5.70E-01/</cell><cell>3.19E-01/</cell><cell>2.74E-01/</cell></row><row><cell></cell><cell></cell><cell>8.18E-03 +</cell><cell>1.08E-03-</cell><cell>1.46E-03 +</cell><cell>5.22E-03 +</cell><cell>2.78E-03 +</cell><cell>2.58E-03</cell></row><row><cell>MaOP9</cell><cell cols="2">10 1.48E-01/</cell><cell>2.02E-01/</cell><cell>3.39E-01/</cell><cell>3.96E-01/</cell><cell>2.27E-01/</cell><cell>1.47E-01/</cell></row><row><cell></cell><cell></cell><cell>1.63E-05-</cell><cell>2.19E-03 +</cell><cell>2.26E-03 +</cell><cell>6.84E-03 +</cell><cell>1.82E-03 +</cell><cell>3.14E-06</cell></row><row><cell></cell><cell cols="2">15 6.68E-01/</cell><cell>4.47E-01/</cell><cell>8.03E-01/</cell><cell>9.47E-01/</cell><cell>5.22E-01/</cell><cell>4.18E-01/</cell></row><row><cell></cell><cell></cell><cell>6.20E-03 +</cell><cell>3.36E-03 +</cell><cell>3.44E-03 +</cell><cell>5.40E-03 +</cell><cell>1.07E-02 +</cell><cell>4.07E-03</cell></row><row><cell>MaOP10</cell><cell cols="2">10 1.42E-01/</cell><cell>1.91E-01/</cell><cell>2.96E-01/</cell><cell>6.17E-01/</cell><cell>3.91E-01/</cell><cell>1.30E-01/</cell></row><row><cell></cell><cell></cell><cell>1.37E-05 +</cell><cell>1.63E-04 +</cell><cell>6.27E-03 +</cell><cell>4.66E-03 +</cell><cell>1.67E-03 +</cell><cell>1.05E-05</cell></row><row><cell></cell><cell cols="2">15 6.43E-01/</cell><cell>4.40E-01/</cell><cell>4.03E-01/</cell><cell>7.64E-01/</cell><cell>5.46E-01/</cell><cell>4.27E-01/</cell></row><row><cell></cell><cell></cell><cell>1.08E-02 +</cell><cell>4.50E-03 +</cell><cell>8.60E-03-</cell><cell>1.99E-02 +</cell><cell>1.64E-02 +</cell><cell>1.46E-02</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 9</head><label>9</label><figDesc>Wilcoxon test results when M = 5 .</figDesc><table><row><cell>Problem</cell><cell>MOEA/D</cell><cell>NSGA-III</cell><cell>RVEA</cell><cell>VaEA</cell><cell>MOEA/DD</cell></row><row><cell>MaOP1</cell><cell>0.005</cell><cell>0.05</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell></row><row><cell>MaOP2</cell><cell>0.005</cell><cell>0.05</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell></row><row><cell>MaOP3</cell><cell>0.005</cell><cell>0.05</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell></row><row><cell>MaOP4</cell><cell>0.005</cell><cell>0.05</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell></row><row><cell>MaOP5</cell><cell>0.05</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell></row><row><cell>MaOP6</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell></row><row><cell>MaOP7</cell><cell>0.05</cell><cell>0.5</cell><cell>0.005</cell><cell>0.05</cell><cell>0.005</cell></row><row><cell>MaOP8</cell><cell>0.005</cell><cell>0.5</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell></row><row><cell>MaOP9</cell><cell>0.005</cell><cell>0.05</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell></row><row><cell>MaOP10</cell><cell>0.005</cell><cell>0.05</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 10</head><label>10</label><figDesc>Wilcoxon test results when M = 15 .</figDesc><table><row><cell>Problem</cell><cell>MOEA/D</cell><cell>NSGA-III</cell><cell>RVEA</cell><cell>VaEA</cell><cell>MOEA/DD</cell></row><row><cell>MaOP1</cell><cell>0.05</cell><cell>0.005</cell><cell>0.005</cell><cell>0.05</cell><cell>0.05</cell></row><row><cell>MaOP2</cell><cell>0.005</cell><cell>0.05</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell></row><row><cell>MaOP3</cell><cell>0.005</cell><cell>0.05</cell><cell>0.05</cell><cell>0.005</cell><cell>0.005</cell></row><row><cell>MaOP4</cell><cell>0.005</cell><cell>0.05</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell></row><row><cell>MaOP5</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell></row><row><cell>MaOP6</cell><cell>0.5</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell></row><row><cell>MaOP7</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell><cell>0.05</cell><cell>0.05</cell></row><row><cell>MaOP8</cell><cell>0.05</cell><cell>0.5</cell><cell>0.005</cell><cell>0.005</cell><cell>0.05</cell></row><row><cell>MaOP9</cell><cell>0.005</cell><cell>0.05</cell><cell>0.005</cell><cell>0.005</cell><cell>0.005</cell></row><row><cell>MaOP10</cell><cell>0.005</cell><cell>0.05</cell><cell>0.5</cell><cell>0.005</cell><cell>0.005</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 11</head><label>11</label><figDesc>The comparison of IGD+ values on the practical problem.</figDesc><table><row><cell>Algorithms</cell><cell></cell><cell>MOEA/D</cell><cell>VaEA</cell><cell>RVEA</cell><cell>VaEA</cell><cell>MOEA/DD</cell><cell>RVMEA/OL</cell></row><row><cell>IGD +</cell><cell>Mean</cell><cell>1.39E-01</cell><cell>4.65E-02</cell><cell>5.22E-02</cell><cell>1.44E-01</cell><cell>1.12E-01</cell><cell>4.05E-02</cell></row><row><cell></cell><cell>variance</cell><cell>2.52E-05</cell><cell>1.67E-05</cell><cell>1.07E-05</cell><cell>1.50E-05</cell><cell>3.28E-06</cell><cell>2.57E-06</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported by the National Natural Science Foundation Program of China ( 61572116 , 61572117 ). Thanks for the reviewers and the China Scholarship Council.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A MOPSO algorithm based exclusively on pareto dominance concepts</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Alvarez-Benitez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Everson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Fieldsend</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Evolutionary Multi-Criterion Optimization</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="459" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A divide-and-conquer-based ensemble classifier learning by means of many-objective optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Asafuddoula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="762" to="777" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A decomposition-based many-objective evolutionary algorithm with two types of adjustments for direction vectors</title>
		<author>
			<persName><forename type="first">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2335" to="2348" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Decomposition-based-sorting and angle-based-selection for evolutionary multiobjective and many-objective optimization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2824" to="2837" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A many-objective evolutionary algorithm with enhanced mating and environmental selections</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="592" to="605" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A reference vector guided evolutionary algorithm for many-objective optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Olhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sendhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="773" to="791" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A surrogate-assisted reference vector guided evolutionary algorithm for computationally expensive many-objective optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Miettinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hakanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sindhya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="129" to="142" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Cornell</surname></persName>
		</author>
		<title level="m">Experiments with Mixtures: Designs, Models, and the Analysis of Mixture Data</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">403</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Differential evolution: a survey of the state-of-the-art</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="31" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An evolutionary many-objective optimization algorithm using reference-point-based nondominated sorting approach, part i: solving problems with box constraints</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="577" to="601" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Searching for Pareto-optimal solutions through dimensionality reduction for certain large-dimensional multi-objective optimization problems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Saxena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the World Congress on Computational Intelligence (WCCI-2006)</title>
		<meeting>the World Congress on Computational Intelligence (WCCI-2006)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="3352" to="3360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011-07">Jul. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A new decomposition-based NSGA-II for many-objective optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elarbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bechikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Said</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man. Cybern</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1191" to="1210" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Single-and multiobjective evolutionary optimization assisted by Gaussian random field metamodels</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Emmerich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Giannakoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Naujoks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="421" to="439" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A study on the use of non-parametric tests for analyzing the evolutionary algorithms&apos; behaviour: a case study on the CEC&apos;2005 Special Session on Real Parameter Optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lozano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Heuristics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">617</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Self-organizing map-based weight design for decomposition-based many-objective evolutionary algorithm</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-M</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="225" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Many-objective evolutionary algorithm: objective space reduction and diversity improvement</title>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="160" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A niched Pareto genetic algorithm for multiobjective optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nafpliotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Citeseer</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="82" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Parallel coordinates: a tool for visualizing multi-dimensional geometry</title>
		<author>
			<persName><forename type="first">A</forename><surname>Inselberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dimsdale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st conference on Visualization&apos;90</title>
		<meeting>the 1st conference on Visualization&apos;90</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="361" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Difficulties in specifying reference points to calculate the inverted generational distance for many-objective optimization problems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ishibuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Masuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tanigaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nojima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Symposium on Computational Intelligence in Multi-Criteria Decision-Making (MCDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="170" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Transient stability analysis of the ieee 14-bus electric power system, in: AFRICON 2007</title>
		<author>
			<persName><forename type="first">P</forename><surname>Iyambo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tzoneva</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Nd-tree-based update: a fast algorithm for the dynamic nondominance problem</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jaszkiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lust</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="778" to="791" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Transfer learning-based dynamic multiobjective optimization algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="501" to="514" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Challenging Novel Many and Multi-Objective Bound Constrained Benchmark Problems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suganthan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-01-11">11 Jan, 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An evolutionary many-objective optimization algorithm based on dominance and decomposition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kwong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="694" to="716" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Shift-based density estimation for Pareto-based algorithms in many-objective optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="348" to="365" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A learning automata-based multiobjective hyper-heuristic</title>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Özcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>John</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="73" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Objective reduction particle swarm optimizer based on maximal information coefficient for many-objective problems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">281</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Solving security constrained optimal power flow problems: a hybrid evolutionary approach</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Marcelino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Wanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Baumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Weil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Miranda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Intell</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3672" to="3690" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An introduction to kernel-based learning algorithms</title>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rätsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tsuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning automata-a survey</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Narendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Thathachar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="323" to="334" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Enhanced multi-objective teaching-learning-based optimization for machining of Delrin</title>
		<author>
			<persName><forename type="first">E</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kaviarasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Tiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="51528" to="51546" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A classification-based surrogate-assisted evolutionary algorithm for expensive many-objective optimization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="74" to="88" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A multi-objective improved teaching-learning based optimization algorithm (MO-ITLBO)</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Savsani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">357</biblScope>
			<biblScope unit="page" from="182" to="200" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Moea/d with adaptive weight adjustment</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="231" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Parallel coordinate descent methods for big data optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Richtárik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Takáč</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="433" to="484" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Study on the design and analysis methods of orthogonal experiment</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ruijiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yewang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chongwei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Exp. Technol. Manage</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="52" to="55" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Scheffe</surname></persName>
		</author>
		<title level="m">The Analysis of Variance</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">72</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Reference line-based estimation of distribution algorithm for many-objective optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl Based Syst</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="page" from="129" to="143" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">IGD indicator-based evolutionary algorithm for many-objective optimization problems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="187" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<title level="m">Reinforcement Learning: An Introduction</title>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Tables of orthogonal arrays and linear graphs</title>
		<author>
			<persName><forename type="first">G</forename><surname>Taguchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rep. Stat. Appl. Res. Un. Jap. Sci. Eng</title>
		<imprint>
			<biblScope unit="page" from="1" to="52" />
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A vector angle-based evolutionary algorithm for unconstrained many-objective optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="131" to="152" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Ranking-based elitist differential evolution for many-objective optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 5th International Conference on Intelligent Human-Machine Systems and Cybernetics</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="310" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Multi-objective individualized-instruction teaching-learning-based optimization algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="288" to="314" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">MOEA/D: a multiobjective evolutionary algorithm based on decomposition</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="712" to="731" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Decomposition-based sub-problem optimal solution updating direction-guided evolutionary many-objective algorithm</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">448</biblScope>
			<biblScope unit="page" from="91" to="111" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A two-phase many-objective evolutionary algorithm with penalty based adjustment for reference lines</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sulaman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Congress on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="page" from="2161" to="2168" />
			<date type="published" when="2016">2016. 2016</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Many-objective reactive power optimization using particle swarm optimization algorithm based on Pareto entropy</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhuansun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="923" to="928" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
