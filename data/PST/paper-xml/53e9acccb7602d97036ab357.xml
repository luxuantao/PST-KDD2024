<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Landgrebe</surname></persName>
							<email>bjeon@yurim.skku.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="institution">Sungkyunkwan University</orgName>
								<address>
									<settlement>Suwon</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Purdue University</orgName>
								<address>
									<postCode>47907-1285</postCode>
									<settlement>West Lafayette</settlement>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">49960E5AC4F3CDCDFE0F229743BED9ED</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>F OR decades, remote sensing technology has been suc- cessfully applied in many interdisciplinary applications of Earth observational data <ref type="bibr" target="#b0">[1]</ref>. The recent advent of more powerful sensor systems enables one to extract far more detailed information than ever before from the observed data, but to realize that, this goal requires the development of effective data analysis techniques which can utilize the full potential of the observed data. For example, the availability of multitemporal data sets over the same scene makes it possible to extract valuable temporal characteristics of surface cover types that may be of interest to applications requiring the monitoring of spectral or spatial characteristic changes over time <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>.</p><p>However, proper utilization of temporal contextual information calls for designing an appropriate multitemporal classifier. A few desirable properties of a multitemporal classifier are as follows <ref type="bibr" target="#b2">[3]</ref>.</p><p>1) Since there are usually only a limited number of training samples available for each temporal data set, a multitemporal classifier should not require extra training samples additional to those already available for pixelwise nontemporal classification. It will be desirable if the classifier can be trained separately for each temporal data set. In this respect, it is quite common to assume class-conditional independence of features belonging to different temporal data sets.</p><p>2) It will be also desirable for a multitemporal classifier to facilitate distribution of the computation required for classification over different times by allowing easy update of the intermediate result already computed with previous temporal data sets when a new data set becomes available. 3) A different temporal data set can have distinct properties and varying discriminating power; therefore, it would be desirable for a multitemporal classifier to accommodate different reliability factors associated with each temporal data set or its class decisions. Motivated by the notion that multitemporal classification can be thought of as a multisource classification problem <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref> where the temporal data sets are considered as separate information sources, we formulate the problem in a context similar to an -ary distributed hypothesis testing problem [6]- <ref type="bibr" target="#b9">[10]</ref>; the proposed methods are based on a fusion of "class decisions" of each separate temporal data set (called local decisions). Since only the local decisions are involved in the final step of multitemporal classification and local classifiers can make their own decisions without any additional constraints due to the fusion at later time, this approach can ease the requirements at the training stage and subsequently the computational complexity set forth above.</p><p>Different information sources can have different degrees of reliability, i.e., one data set might be more reliable than others in a specific analysis since the characteristics of sensors or data sets are not necessarily all the same. To account for this, we associate "data set reliability" with each temporal data set so that a less reliable data set has less effect on the global fusion of local decisions. Furthermore, since a certain class or a subset of classes is discriminated more successfully than the others, it will also be useful to associate a reliability factor as well to the individual class decisions which the local classifier makes. In this paper, the reliability factor associated with each class decision is called the "classwise reliability."</p><p>We propose two different multitemporal classifiers based on the decision fusion. The first one is based on an idea similar to that used by Tang et al. <ref type="bibr" target="#b9">[10]</ref> in the -ary detection. For the second approach, we modify the cost function used by Tang et al. to obtain the weighted majority decision fusion classifier, which can handle both the data set and the classwise reliabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MULTITEMPORAL CLASSIFICATION</head><p>Suppose there are co-registered multitemporal remotely sensed data sets taken over the same location. The objective of designing a multitemporal classifier is to determine the optimum decision rule for a (global) class decision of a sample temporally observed as where is the observation made at th time,</p><p>The decision is made among a set of user-defined information classes, An information class is a class which is directly useful to the user according to the specific purpose of the data analysis <ref type="bibr" target="#b10">[11]</ref>. Since information classes are not necessarily separable in the feature space, data sets are usually analyzed in the training stage, for example, through a clustering, to find a mutually exclusive and exhaustive set of subclasses or spectral (or data) classes so that each can be modeled by an appropriate probability density function <ref type="bibr" target="#b11">[12]</ref>. Due to the computational complexity and a practical limitation on the requirement of training samples, the data sets are assumed, in general, to be class-conditionally independent to each other (see <ref type="bibr" target="#b4">[5]</ref> for a discussions on this assumption) and each data set is separately analyzed in the training stage. Therefore a data set at different times has generally a distinct set of spectral classes. Let us denote as a set of spectral classes in the th temporal set,</p><p>The local class decision made using the th temporal set is denoted by which is chosen among If each temporal data set is taken as a separate information source, multitemporal classification can be considered as an example of multisource data classification which has conceptually two different approaches. One category is the data fusion approach shown in Fig. <ref type="figure" target="#fig_1">1(a)</ref>, in which the feature vectors of the data sources (or sensor) are given to a central decision procedure which makes the final decision among (see <ref type="bibr" target="#b3">[4]</ref> for a detailed review on the works in this category). Note that the optimal Bayesian multitemporal decision rule, which is in this category, chooses a class which maximizes Fleming and Hoffer <ref type="bibr" target="#b12">[13]</ref> used the stacked vector as an extended feature in the maximum likelihood (ML) classifier. However, the increased dimensionality of the feature vector requires more training samples than ordinarily required by the pixelwise classifiers altogether. P. H. Swain <ref type="bibr" target="#b2">[3]</ref> simplified the approach to derive the cascade classifier by assuming class-conditional independence of feature vectors of different data sets, thus deriving the decision rule of finding a class maximizing Note that in this approach, each data set has the same effect on the final decision of Kalayeh and Landgrebe <ref type="bibr" target="#b13">[14]</ref> proposed a multitemporal classifier which could utilize the temporal interpixel correlation context under the assumption that the class did not change over time. Since they assumed the same set of (spectral) classes for each temporal data set, all given multitemporal data sets should be processed together in the training stage to define the spectral classes, thus increasing the total number of necessary spectral classes. This increase is due to the constraint that the classes do not change over the time. In a multisource classification context, Lee et al. <ref type="bibr" target="#b4">[5]</ref> developed the statistical multisource classifier which was later extended by Benedicktsson et al. <ref type="bibr" target="#b3">[4]</ref> to accommodate reliability factors associated with data sets. The global membership function in <ref type="bibr" target="#b3">[4]</ref> is defined for as</p><p>A decision is made by selecting the class which has a maximum membership function value. Equation ( <ref type="formula" target="#formula_0">1</ref>) shows how the individual weighted posterior probability affects the global membership function where is the reliability factor associated with the th data set, Note that the cascade classifier <ref type="bibr" target="#b2">[3]</ref> is equivalent to (1) if the data set reliabilities are all set to one. The evidential reasoning approach <ref type="bibr" target="#b14">[15]</ref> has been also used to perform multisource classification with data set reliabilities. However, neither of these approaches utilize classwise reliabilities.</p><p>The second category, shown in Fig. <ref type="figure" target="#fig_1">1</ref>(b), is the decision fusion approach in which a final class decision is made by summarizing only the class decisions of each data set. The key issue of this approach is twofold; one is the design of the local classifiers and the other is the optimum fusion of local class decisions. This problem is very similar to that of -ary distributed hypothesis testing which has recently received considerable research attention <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b9">[10]</ref> in such fields as radar and military surveillance systems. Tubbs and Alltop <ref type="bibr" target="#b15">[16]</ref> considered a problem of integrating classification results from multiple sensors and suggested a decision process based on a ranked lists of class decisions. Tenny and Sandell <ref type="bibr" target="#b5">[6]</ref> first proposed a distributed detection algorithm in the case of two sensors. Chair and Varshney <ref type="bibr" target="#b6">[7]</ref> derived an optimum fusion rule when binary local decisions were given in a multiple sensor detection problem. Later, Reibman and Nolte <ref type="bibr" target="#b7">[8]</ref> reported a system-wide optimum solution for a restricted case when the statistics and thresholds of the local detectors are assumed to be identical. Tang et al. <ref type="bibr" target="#b9">[10]</ref> presented a solution to the more general case of a distributed -ary detection problem with multiple sensors. In this paper, we assume conditional independence of 's given , that is <ref type="bibr" target="#b2">(3)</ref> where is the probability that the local decision of a sample using th data set is given the global decision which is made by summarizing all the local decisions. Accounting for class dependency using some models such as the Markov chain might be effective in improving the classification accuracy but with an increased computational requirement <ref type="bibr" target="#b16">[17]</ref>. Although whether 's are truly conditionally independent or not should be scrutinized in a given circumstance, the assumption is made here just to make the classifier as simple as possible. Under the assumption in (3), the simplified decision fusion rule optimal in Bayesian minimum cost sense is to choose maximizing defined as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. DECISION FUSION IN MULTITEMPORAL CLASSIFICATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Derivation of the Jointly Likelihood Decision Fusion Rule</head><formula xml:id="formula_1">- (<label>4</label></formula><formula xml:id="formula_2">)</formula><p>We call this the jointly likelihood decision fusion multitemporal classifier. Since the local class decision can have any of spectral classes in the total number of conditional probabilities 's to estimate amounts to With large number of spectral classes, their estimation is never an easy task since it is expected to be very rare in general to find all the cases of class combinations in the training data set. One practical solution may be to assume a certain model of class transition, preferably aided by some data-specific knowledge such as development stages of an agricultural crop over time, etc. For example, one might expect, possibly by analyzing the training samples, which subset of the spectral classes a sample of a certain information class is most likely classified to. From this kind of prior knowledge, one can get a practically reasonable model of the probability</p><p>In the experiment of this paper, a simple model of ( <ref type="formula">12</ref>) and ( <ref type="formula">13</ref>) is used in applying the decision fusion rule in (4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Derivation of the Weighted Majority Decision Fusion Rule</head><p>Among the local decisions some of the decisions are more dependable in terms of reliability than others. In this case, it would be desirable if the final decision is as consistent as possible with those more reliable local decisions. However, the classifier in ( <ref type="formula" target="#formula_1">4</ref> in such a way that a less reliable local decision has limited effect on making a final decision through the selected fusion rule. Using the cost function in <ref type="bibr" target="#b5">(6)</ref>, the expected cost is given as <ref type="bibr" target="#b6">(7)</ref> It is minimized if the second term in parenthesis is maximized with respect to the decision We define a multitemporal decision fusion classifier that chooses a class maximizing defined as</p><formula xml:id="formula_3">- (<label>8</label></formula><formula xml:id="formula_4">)</formula><p>To better appreciate the role of 's, suppose they are all 1. Then, the classifier of (8) would choose a class which is a majority class indicated by 's, Therefore, it is a majority rule. With distinct 's, then, the "vote" of each local decision is weighted according to Thus the classifier will select a class attaining the most weights of 's. For this reason, this decision fusion method will be called as the "weighted majority decision fusion rule."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Data Set and Classwise Reliability</head><p>Since the decision made by each temporal data set has a potentially different reliability, we define the classwise reliability, as a reliability of a decision using the th temporal data set. In the same way, the data set reliability, denotes the reliability of the th data set as a whole. It would be very logical to assign a large cost to the case when the fusion rule fails to follow a local decision of large reliability.</p><p>Three different measures of data set reliability using class separability, equivocation, and association are introduced in <ref type="bibr" target="#b3">[4]</ref>. Although statistical separability between classes is a good candidate for assessing data set reliability, the computation involved in evaluating separability could be nontrivial if the multivariate normality assumption about the data set is not satisfied. In the context of equivocation, the data set reliability is related to the degree that a data (or spectral) class indicates a specific information class. Since the purpose of decision fusion in this paper is classification, any data set with higher classification accuracy may be assumed more reliable than the others. Note that classification can be easily obtained irrespective of assumptions on underlining probability density functions. How to estimate or associate proper reliability to each data set is an important issue which needs more attention <ref type="bibr" target="#b3">[4]</ref>. In the experiment of the proposed classifiers in this paper, however, instead of attempting to estimate optimal values of the data set reliabilities, we simply test several different values of them to monitor their effect on classification.</p><p>In the case of the classwise reliability, one can specify that it must be also large for the reliable local decision so that the global decision can be biased as much as possible to the reliable local one. Although there is no definitive measure of how much reliable a specific local decision is, we consider two measures; one is based on the detection probability, and the other on the classwise probability of correct classification. The first one is defined as, for and and <ref type="bibr" target="#b8">(9)</ref> It is nothing but the detection probability of class which is the probability of correctly classifying a sample as belonging to a class Its rationale is that any class with high detection probability should be reliable. By the way, there can be a problem in using this measure as explained in following hypothetical example. Suppose a local classifier which is very poorly designed or, whose feature vectors of a certain data set are of very poor quality assigns all samples to a particular class. In this case, the measure of (9) will assign the highest reliability of 1 to that particular class, although the decision to this class is meaningless. On the contrary, the second measure defined as <ref type="bibr" target="#b9">(10)</ref> does not have this kind of problem. It is the probability that a sample is truly from the class when the local decision is that is, ( <ref type="formula">10</ref>) is the probability that the local decision is correct. In the experiments, we have tested these two measures of classwise reliability to observe that the measure of ( <ref type="formula">10</ref>) is more effective. It is something expected since a high value of <ref type="bibr" target="#b9">(10)</ref> implies that, statistically speaking, the local decision is most likely correct; therefore, the local decision is a better one to strongly influence the global class decision of There still remains a problem in associating the data set and classwise reliability measures to actual values of weights 's. Since this appears difficult to do optimally, at least for now, a seemingly simple way as given by ( <ref type="formula">11</ref>) is used in the experiment: <ref type="bibr" target="#b10">(11)</ref> In implementing the fusion rule in <ref type="bibr" target="#b7">(8)</ref>, one needs the 's as prior information, or equivalently, the data set reliabilities 's, and the classwise reliabilities 's. Note that compared to the jointly likelihood fusion rule in (4), the weighted majority rule is applicable with much reduced prior information. The classwise reliabilities either in the form of ( <ref type="formula">9</ref>) or ( <ref type="formula">10</ref>) can be estimated easily from the classification results of representative training samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS AND DISCUSSIONS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Multitemporal Data Sets and Training</head><p>To test the proposed decision fusion approaches in multitemporal classification, experiments are carried out using three multitemporal Landsat Thematic Mapper (TM) data sets acquired over the same agricultural areas in Tippecanoe County, IN, in April, July, and September 1986, respectively. Ground truth data were gathered in July. All seven bands are used in the classification. Based on the available ground truth data, four information classes in corn, soybean, wheat, alfalfa/oat are defined in the July and September data sets. Several subclasses are developed, separately for each data set, for each of the information classes in to satisfy the multivariate normality assumption of the subclasses. Since the class "wheat" is the only green crop type observed in the April data set, and green vegetation has a substantially different spectral reflectance compared to the soil <ref type="bibr" target="#b2">[3]</ref>, it can be identified with a relatively high accuracy. For this reason, only two information classes-wheat and "the others"-are defined in the April data set. About 15 000 samples are chosen for test in each data set, and about 10% of the samples are randomly selected for training.</p><p>Initially, the pixelwise ML classifier classified each temporal data set separately, and the overall (OVA) and classaveraged classification accuracy (CAG) are used as references in evaluating the classification performance of the proposed temporal classifiers. The final (global) decision using all three multitemporal data sets are made among Note that the jointly likelihood decision fusion rule in (4) requires the class transition probabilities 's. Since indicates a class among the set of spectral classes and the global decision is made among the set of information classes there are cases where more than one class of correspond to the same information class</p><p>In the experiment of this paper, the probabilities 's are determined heuristically in such a way that the probability of a local decision which belongs to the same information class as the global one has a higher probability than the other cases: suppose the local decision corresponds to an information class and there are a total of subclasses (spectral classes) in which correspond to the information class then, we define, for <ref type="bibr" target="#b11">(12)</ref> When the local decision does not belong to the information class indicated by then <ref type="bibr" target="#b12">(13)</ref> where is a user defined number between zero and one: being one means no allowance of a class transition to a different information class. If is zero, class transition is permitted only to a different information class. Several values of are tested and some of the results are shown in Table <ref type="table" target="#tab_0">I</ref>. The values of which achieve the best performance are chosen for comparison with other classifiers. In the case of classifying July data with April data, is set to one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Multitemporal Classification with Data Fusion</head><p>For comparison, the conventional multitemporal classifier based on the data fusion in (1) classified the July data with April and September data and its results are shown in Table <ref type="table" target="#tab_1">II</ref>. Since the ground truth was gathered in July and matched best with July data, all comparisons are made with respect to the July data set. Several different data set reliability factors (from 0.6 to 1.0 at a step of 0.1 for each data set) are tested to see their effect on classification. The overall classification accuracy, however, is observed not to vary much; the maximum deviation due to different data set reliabilities is less than 2% (the result reported in Table <ref type="table" target="#tab_1">II used</ref> ). The multitemporal classification based on the data fusion in (1) generally attains better results than any of the single pixelwise maximum likelihood classification; when the September and April data sets are used together with the July data set, the increase of overall classification accuracy over the pixelwise ML classifier is about 6%. Including April data improves the classification accuracy of wheat and alfalfa/oats significantly. The September data set is also helpful in classifying the class soybeans in July data, but there is a slight degradation in classification accuracy of the alfalfa/oats (see JUL SEP case). The improvement due to including September data in classifying July data is seen to be marginal in the data fusion approach. Note that the classification accuracy in September data is generally very low except for the class corn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Multitemporal Classification with the Jointly Likelihood Decision Fusion</head><p>Table II also shows the classification accuracy of the proposed two multitemporal classifiers-the jointly likelihood decision fusion rule in (4) and the weighted majority decision fusion rule in <ref type="bibr" target="#b7">(8)</ref>. In the decision fusion approach, only limited information of local class decisions are combined compared to the data fusion which combines posterior probabilities. However, the jointly likelihood decision fusion rule is seen to perform much better than the data fusion approach in <ref type="bibr" target="#b0">(1)</ref>. Therefore, the a priori information of the joint probability, required by the jointly likelihood decision fusion rule is found to be effective in combining information for classification. Under the conditional independence assumption of it is sufficient to estimate times conditional probabilities of 's for the th data, set where is the number of classes in the th data set and , is the number of classes in As stated before, although these class transition probabilities can be estimated from the training samples, we choose to use the probability values calculated according to the model in ( <ref type="formula">12</ref>) and ( <ref type="formula">13</ref>) in the experiment to avoid additional complexity of their estimation.</p><p>In classifying July data with September and April data, the jointly likelihood decision fusion rule achieves approximately 5% overall classification accuracy increase over the best data fusion multitemporal classifier. The increase of classification accuracy is especially significant for the soybeans class ( 11%); however, the class "alfalfa/oats" experiences about 8% loss of classification accuracy and, thus, the increase of the class-averaged classification accuracy over the data fusion amounts only to 2%. Compared to the ML pixelwise classification of July data only, the jointly likelihood decision fusion achieves 10.73% of overall classification accuracy increase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Multitemporal Classification with the Weighted Majority Decision Fusion</head><p>Classification results with the weighted majority decision fusion rule are presented in Table <ref type="table" target="#tab_1">II</ref> as well (the results shown in Table <ref type="table" target="#tab_1">II</ref> are obtained with the same data set reliabilities-this corresponds to the simple majority rule; see also Table <ref type="table" target="#tab_2">III</ref>). Note that the weighted majority fusion rule of (8) further reduces the requirement for prior information: only different classwise reliability factors, 's, are for the th data set. In the experiment, instead of estimating the data set reliabilities, several different values (0-1.0) are assigned to each data set to see only minor differences in overall classification accuracy (less than 1.3%). However, the class-averaged accuracy is observed to be somewhat sensitive to the data set reliability as can be seen in Table <ref type="table" target="#tab_2">III</ref> (see the classes wheat and alfalfa/oats).</p><p>In the case of the data fusion scheme in (1), the maximum difference in the classification accuracy (both in CAG and OVA) with different data set reliabilities is less than 2%. However, the data set reliability determines in <ref type="bibr" target="#b7">(8)</ref>, and there is no other data-dependent quantity except the classwise reliability, therefore, the classification accuracy seems to be more sensitive to the data set reliability in the weighted majority rule. This indicates that estimation of optimum data set reliability (and the classwise one) is an important issue in applying the weighted majority decision fusion scheme.</p><p>As for the classwise reliability, the measures in ( <ref type="formula">9</ref>) and (10) show significant differences in their performance; classwise reliability of (10) produces significantly better results (about 6-8% improvement in OVA; 3-4% improvement in CAG) than that of (9). This can be easily understood since the classwise reliability in <ref type="bibr" target="#b9">(10)</ref> indicates more directly the possibility of a local decision being true. The results in Table II are those using <ref type="bibr" target="#b9">(10)</ref>. Note that although the weighted majority decision fusion rule requires much less prior information than the jointly likelihood decision fusion, and it is much simpler than the data fusion based rule in (1); it performs almost comparably with them at least in terms of overall classification accuracy, which proves its usefulness as a simplified multitemporal classifier. However, the experimental result also suggests need for further research on deciding optimum data set reliabilities to improve class-averaged classification accuracy as well.</p><p>Although there is further need for research on an optimum selection of data set and classwise reliabilities, the multitemporal classifiers based on decision fusion proposed in this paper are observed to perform quite successfully compared to the noncontextual ML classifier, or the multitemporal classifier with feature level fusion. Note that data fusion-based multitemporal classifiers combine posterior probabilities of each data set and therefore, all data sets must be describable with statistical probabilities. If data sets are very diverse in terms of their statistical properties, a combination of the posterior probabilities might not be able to produce desirable results since one data set with large ranges of probability values can easily dominate the global decision process. On the contrary, the decision fusion-based approach can be applied without such problems. With data set and classwise reliability, or the information about conditional probability 's, it is very straightforward to control the relative importance of a specific data set, or particular class decisions on the final global decision. Note that decision fusion approaches are computationally very simple and always applicable to classifying multitemporal data sets whenever the class decisions of each temporal data sets are available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper, two different multitemporal classifiers based on decision fusion are derived. The first one, namely, the jointly likelihood decision fusion rule, is found to give better results compared to the classifier based on data fusion by about 5% in the overall classification accuracy and about 2% in the class averaged classification accuracy. The second one, the weighted majority decision fusion rule, is shown to perform almost comparably with the data fusion and the jointly likelihood decision fusion rule at least in terms of the overall classification accuracy, even if it is supplied with much reduced a priori information compared to the jointly likelihood decision fusion rule, and it is much simpler than the data fusion rule. However, the experimental result also suggests need for further research on deciding optimum data set reliabilities to improve the class-averaged classification accuracy as much as the overall classification accuracy.</p><p>In addition to its simplicity, the proposed weighted majority decision fusion rule has a feature of handling not only the data set reliabilities but also the classwise reliabilities. Between the two different assessments of classwise reliabilities, the one based on the probability of correct classification in <ref type="bibr" target="#b9">(10)</ref>, as expected, is found to be far more effective than the one based on the other measure. This decision fusion approach in multitemporal classification is very attractive since it satisfies all three requirements of a multitemporal classifier stated in Introduction, and one can apply the method even to the problems in which a certain data set cannot be modeled by known probability density functions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Member, IEEE, and David A. Landgrebe, Life Fellow, IEEE Abstract-This paper proposes two decision fusion-based multitemporal classifiers, namely, the jointly likelihood and the weighted majority fusion classifiers, that are derived using two different definitions of the minimum expected cost. Without any overhead incurred by multitemporal processing, a user-selected conventional pixelwise classifier makes local class decisions separately using each temporal data set, and the proposed multitemporal classifiers make the global class decisions by optimally summarizing those local class decisions. The proposed weighted majority decision fusion classifier can handle not only the data set reliabilities but also the classwise reliabilities of each data set. Classification experiment using the jointly likelihood decision fusion with three remotely sensed Thematic Mapper (TM) data sets shows more than 10% overall classification accuracy improvement over the pixelwise maximum likelihood classifier. Index Terms-Decision fusion, distributed detection, distributed hypothesis testing, multitemporal classifier, reliability.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Classification structures. x k is the feature vector in the kth data set and u k is the local class decision determined using only x k : (a) Fusion of features. (b) Fusion of decisions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Suppose a conventional pixelwise classifier such as the ML classifier makes local class decisions independently using each separate temporal data set. Then the problem in the decision fusion-based multitemporal classification is how to make an optimum global decision among given the local decisions To find a decision fusion method which is optimum in the minimum expected cost sense, we define the cost incurred by determining given when the true class is The expected cost is written as (otherwise. Employing the same cost function in (2) leads to the decision fusion rule of choosing a class maximizing This implies finding a class that is most likely to occur jointly with the local decisions Note that there are total different class combinations for</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>) cannot accommodate a disparate degree of reliabilities because the cost function checks only the match of with To implement the idea of honoring reliable local decisions among a slight modification is made to the cost function. Specifically, a cost function satisfying the following relation is examined: (5) is a local cost function associated with the th data set, and it determines the cost given to an action of selecting based on the local decision A summation of all the local costs is then the actual cost assigned to the action of selecting based on We select a cost function satisfying (6) where We interpret the function if the spectral class belongs to the information class indicated by otherwise is a number associated with the local class decision It can control the relative importance of consistency between and local decision because the cost of selecting the global decision to match with the local decision is while the cost in other cases is one. According to the data set and classwise reliabilities, we select appropriate values of</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="5,309.12,80.88,245.04,237.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I BI</head><label>I</label><figDesc>-TEMPORAL CLASSIFICATION OF JULY DATA WITH SEPTEMBER DATA WITH DIFFERENT CLASS TRANSITION PROBABILITIES (EQUAL DATA SET RELIABILITY)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II CLASSIFICATION</head><label>II</label><figDesc>ACCURACY COMPARISON OF THE MULTITEMPORAL CLASSIFIERS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III WEIGHTED</head><label>III</label><figDesc>MAJORITY DECISION FUSION WITH DIFFERENT DATA SET RELIABILITIES</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The evolution of Landsat data analysis</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Landgrebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Photogramm. Eng. Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="859" to="867" />
			<date type="published" when="1997-07">July 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A knowledge-based vision system for detecting land changes at urban fringes</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="136" to="145" />
			<date type="published" when="1993-01">Jan. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Bayesian classification in a time-varying environment</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Swain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="879" to="883" />
			<date type="published" when="1978-12">Dec. 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Neural network approaches versus statistical methods in classification of multisource remote sensing data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Swain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">K</forename><surname>Ersoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="540" to="552" />
			<date type="published" when="1990-07">July 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Probabilistic and evidential approaches for multisource data analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Swain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="283" to="293" />
			<date type="published" when="1987-05">May 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Detection with distributed sensors</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Tenny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Sandell</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Aerosp. Electron. Syst</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="501" to="510" />
			<date type="published" when="1986-07">July 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Optimum data fusion in multiple sensor detection systems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Varshney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Aerosp. Electron. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="98" to="101" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Optimal detection and performance of distributed sensor systems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Reibman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">W</forename><surname>Nolte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Aerosp. Electron. Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="24" to="30" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Distributed Bayesian signal detection</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">Y</forename><surname>Hoballa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Varshney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="995" to="1000" />
			<date type="published" when="1989-09">Sept. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A distributed M-ary hypothesis testing problem with correlated observations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Pattipati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Kleinman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 28th IEEE Conf. Decision Control</title>
		<meeting>28th IEEE Conf. Decision Control<address><addrLine>Tampa, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989-12">Dec. 1989</date>
			<biblScope unit="page" from="562" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Fundamentals of pattern recognition in remote sensing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Swain</surname></persName>
		</author>
		<editor>P. H. Swain and S. Davis</editor>
		<imprint>
			<date type="published" when="1978">1978</date>
			<publisher>McGraw-Hill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Remote Sensing-The Quantitative Approach</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Fukunaga</surname></persName>
		</author>
		<title level="m">Introduction to Statistical Pattern Recognition</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic</publisher>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
	<note>nd ed</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Digital processing of Landsat MSS and topographic data to improve capabilities for computerized mapping of forest cover types</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Hoffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Bertolucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LARS Tech. Rep. 011579</title>
		<meeting><address><addrLine>West Lafayette, IN</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1979">1979</date>
		</imprint>
		<respStmt>
			<orgName>Purdue Univ.</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Utilizing multitemporal data by a stochastic model</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Kalayeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Landgrebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="792" to="795" />
			<date type="published" when="1986-09">Sept. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Evidential reasoning approach to multisource data classification in remote sensing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Swain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1257" to="1265" />
			<date type="published" when="1995-08">Aug. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Measures of confidence associated with combining classification results</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Tubbs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">O</forename><surname>Alltop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="690" to="692" />
			<date type="published" when="1991-06">May/June 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">From 1993 to 1997, he was with the Signal Processing Laboratory, Samsung Electronics, Suwon, Korea, where he was involved in video compression, the development of digital broadcasting satellite receiver, and other MPEG-related multimedia applications. Since September 1997, he has been with the School of</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Landgrebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seoul, Korea, and the Ph.D. degree from the School of Electrical Engineering</title>
		<meeting><address><addrLine>West Lafayette, IN; Suwon, Korea, as</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992-07">July 1992. 1992</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="663" to="672" />
		</imprint>
		<respStmt>
			<orgName>Seoul National University ; Purdue University ; Electrical and Computer Engineering, Sungkyunkwan University</orgName>
		</respStmt>
	</monogr>
	<note>an Assistant Professor. His research interests include multimedia signal processing, image compression, statistical pattern classification, and remote sensing. Dr. Jeon is a member of Tau Beta Pi and Eta Kappa Nu</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Landgrebe (M&apos;57-SM&apos;74-F&apos;77-LF&apos;97), for photograph and biography</title>
		<author>
			<persName><forename type="first">A</forename><surname>David</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">1188</biblScope>
		</imprint>
	</monogr>
	<note>see this issue</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
