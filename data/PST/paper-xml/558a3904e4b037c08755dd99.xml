<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1E83C7F587BE046354B387757DFC5016</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Self-convergence of Weighted Least-Squares with</head><p>Applications to Stochastic Adaptive Control Lei Guo, Member, IEEE Abstruct-A recursive least-squares algorithm with slowly decreasing weights for linear stochastic systems is found to have vector almost surely irrespective of the control law design. Such the standard least-squares. This "universal convergence" result combined with a method of random regularization then easily</p><p>In analyzing stochastic adaptive control systems, nothing can be assumed a priori about the closed-loop signals { y t , &amp;}. self-convergence property, i.e., it converges to a certain random Thus, if { Yt, 4t} has a tendency of growing up unboundedly, algorithms enjoy almost the Same nice asymptotic properties as decreasing weights in (2 <ref type="bibr">)</ref> depress the effect of instability on the estimation, and hence (2) may still give useful parameter estimates in the case of instability and lack can be applied to construct a self-convergent and uniformly controllable estimated model and thus may enable us to form a general framework for adaptive control of possibly nonminimum phase autoregressive-moving average with exogenous input (ARMAX) systems. As an application, we give a simple solution to the well-known stochastic adaptive pole-placement and linearquadratic-Gaussian (LQG) control problems in the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION ONSIDER the following linear regression model</head><formula xml:id="formula_0">Y t + l = er4t + Wt+l (1) C i = O</formula><p>where ai 2 0 is a weighting sequence; it allows us to give different weights to different measurements of interest. Various weighted least-squares (WLS) in the literature differ only in the choice of weights. The standard least-squares correspond to a; 1. It is well known that the optimal choice of weights (in the sense of minimum variance) is that { a i } is taken as the inverse of the noise variance (cf. [l] p. 36). Also, when 6' is a time-varying parameter, less (or decaying) weights should be given to the old measurements so that the estimate has good tracking performance (cf. Guo et al. [2]).</p><p>In this paper, we shall study the WLS from an adaptive control point of view. In contrast to the insights from pure estimation, we shall use slowly decreasing weights in <ref type="bibr" target="#b1">(2)</ref> which will give fewer weights to the current measurements. The motivation of doing so may be explained as follows:</p><p>of excitation. Of course, so that the WLS enjoys the similar nice asymptotic properties as the standard LS, the decreasing rate of {a,} should be chosen as slow as possible.</p><p>The first paper using WLS in stochastic adaptive control seems to have been Kumar and Moore <ref type="bibr" target="#b2">[3]</ref> where the weights are chosen according to some stability/excitation measure of {qbt}. More recently, Bercu and Duflo <ref type="bibr" target="#b3">[4]</ref> and Bercu <ref type="bibr" target="#b4">[5]</ref> obtained various interesting and useful results on WLS which are parallel and based on those of the standard least-squares. The weights in <ref type="bibr" target="#b3">[4]</ref> and <ref type="bibr" target="#b4">[5]</ref> are simpler than those in <ref type="bibr" target="#b2">[3]</ref> and are called "ponderations." All of these papers, however, concern exclusively with adaptive control of minimum phase stochastic systems.</p><p>This paper is motivated by, and aims at, the study of general stochastic adaptive control systems. The analysis of such systems has long been recognized as difficult, due to the inherent nonlinearity of the closed-loop equations and the complexity of the stochastic process involved. As a matter of fact, if the standard LS estimate is used in adaptive control design, we are, at present, only able to prove stability and optimality of the certainty equivalence minimum variance adaptive control (cf. Guo and Chen <ref type="bibr" target="#b5">[6]</ref> and Guo <ref type="bibr" target="#b6">[7]</ref>, [SI) or its generalizations under a certain minimum phase condition (cf. Meyn and Brown [91 and Ren and Kumar <ref type="bibr">[lo]</ref>). For more complicated control problems such as pole-placement and linear-quadratic-Gaussian (LQG) control, the stability analysis has been hampered by the following facts: i) the standard LS estimates may not converge (or even may not be bounded) and ii) the estimated models may not be uniformly controllable.</p><p>In this paper, our first contribution is to establish that the WLS has self-convergence property, i.e., the WLS with slowly decreasing weights converges to a certain random vector almost surely irrespective of the control law design.</p><p>This "universal convergence" result may considerably ease the painful task of analyzing stochastic adaptive control systems and may also enable us to form a general framework for adaptive control of possibly nonminimum phase autoregressive-moving average with exogenous input (AR-MAX) models. It is worth noting that the standard LS algorithm does not have the above mentioned self-convergence property, in general (see 1161).</p><p>where 0 E R" is an unknown parameter vector, yt, &amp;, and wt are the observation, regressor, and noise processes, respectively.</p><p>A common and natural way to estimate the parameter 6' is the least-squares (LS) method. That is, the estimate is the minimizer of the following criterion 0018-9286/96$05.00 0 1996 IEEE Based on this self-convergence result, the estimates modification procedure of <ref type="bibr">Lozano and Zhao [12]</ref> and the idea of random search in global optimization (cf. e.g., <ref type="bibr">[13]</ref>), a WLSbased parameter estimate, can then easily be constructed so that the corresponding estimated model is almost surely selfconvergent and uniformly controllable. This finally enables us to give a simple and complete solution to the longstanding adaptive pole-placement and LQG control problems for AR-MAX models without resorting to any projection mechanisms and conditions other than controllability and passivity, and that constitutes the other contributions of the paper.</p><p>The remainder of the paper is organized as follows: Section I1 proves the self-convergence of WLS and gives a comparison with the standard LS. Section I11 describes how to get uniformly controllable estimated models by random search method. Sections IV and V are devoted to adaptive poleplacement and LQG control problems, respectively. Some concluding remarks are made in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">SELF-CONVERGENCE OF WLS</head><p>Consider the following ARMAX model</p><formula xml:id="formula_1">A(z)Yt B(z)ut + C(z)wt, t 2 o (3) (4)<label>(5) (6)</label></formula><formula xml:id="formula_2">A ( z ) = 1 + C L ~Z + . . . + C L ~Z ' , p 2 0 B( Z ) = biz + . . . + bqzq, q 2 1 C ( z ) = 1 + c1z + . . . + c,xT, r 2 o</formula><p>where yt, ut, and wt are the system output, input, and noise sequences, respectively, and A(z), B ( z ) , and C ( z )</p><p>are polynomials in backward-shift operator z with unknown coefficients and known upper bounds p , q, and r for orders.</p><p>To describe the WLS algorithm for estimating the unknown parameter vector we need to introduce a set of functions as follows A F = ( f ( . ) : f ( z ) is slowly increasing and O0 dx &lt; oo for some M &gt; O}. <ref type="bibr" target="#b7">(8)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>JM .fo</head><p>Here, a function f ( . ) is called slowly increasing if it is positive, nondecreasing, and satisfies ~( I c ' ) = O ( f ( x ) ) for all large x &gt; 0.</p><p>The recursive WLS algorithm has the following form</p><formula xml:id="formula_3">&amp;+l = Ot + L t ( Yt+l -C 4 t )</formula><p>where the initial values BO and PO = a l , (0 &lt; Q &lt; 1) are chosen arbitrarily, and where { a t } is the weighting sequence defined by t <ref type="bibr" target="#b12">(14)</ref> with f ( . ) being any measurable function in the set F defined the necessary condition for a function f E F is that logx = o ( f ( x ) ) , as IC ---+ 00.</p><p>(15)</p><p>Typical functions in F are, for example</p><formula xml:id="formula_4">(6 &gt; 0).</formula><p>f ( . ) = log 1+5 5 , (logIC)(loglogIC)~+~, . . . . . .</p><p>In general, let f(z) be any slowly increasing function as defined above, and it can be shown (see Appendix A) that for</p><formula xml:id="formula_5">any M &gt; 0 fb") = O(f(.)), 2 &gt; 0 (16) f(x) = 0 ( l o g L z),</formula><p>for all large 2 . <ref type="bibr" target="#b15">(17)</ref> and that there exists a constant L &gt; 0 such that</p><p>The property <ref type="bibr" target="#b15">(17)</ref> together with <ref type="bibr" target="#b12">(14)</ref> implies that</p><p>The choice of weights in the WLS here is different from that in <ref type="bibr" target="#b2">[3]</ref> and is also somewhat different from that in <ref type="bibr" target="#b3">[4]</ref> and [SI. From the general definition <ref type="bibr" target="#b12">(14)</ref> for at, it is clear that the key adaptation property at E CT{&amp;, i 5 t } can be guaranteed automatically. Also, <ref type="bibr" target="#b12">(14)</ref> together with <ref type="bibr" target="#b7">(8)</ref> defines the class of weights of interest in an explicit way.</p><p>To analyze the WLS, we need the following standard assumptions:</p><formula xml:id="formula_7">Al) {tut, Ft} is a martingale difference sequence defined -1 at = O(logLrt), t 2 0.</formula><p>on the basic probability space (Q, F, P ) with</p><formula xml:id="formula_8">sup t 2 0 E[w,2+, I F ~] &lt; 00 a s . A2) The input sequence { u t } is adapted to {Ft}. A3) C-'(z) -is strictly positive real, i.e.,</formula><p>Under these conditions, the following facts parallel to those of the standard LS hold (cf. <ref type="bibr">Bercu [SI)</ref>.</p><p>Lemma I : Let the ARMAX model (3) satisfy the conditions Al)-A3). Then the WLS described by ( <ref type="formula">9</ref>)-( <ref type="formula">14</ref>) has the following properties:</p><formula xml:id="formula_9">-1p- i) IIpt+l Qt+1)I2 = O(1) ii) at[($i&amp;+l)' + (Gt -tut)'] &lt; oo a s . a.s. W f = l -A</formula><p>where Qt = 19 -Qt.</p><p>Remark2: In the white noise case (T = 0), the WLS is precisely the standard LS for the following regularized linear regression From this, a similar treatment as that for the proof of ( <ref type="formula">30</ref> 41]), we have for any 6 &gt; 0 Finally, summing up both sides of (20) from k = 0 to t , it is easy to see that Lemma 1 holds. (Note that since both the noise condition A l ) and the definition of weights {at} here are somewhat different from those used in [ 5 ] , there are some necessary differences between the proofs here and there).</p><p>The general T 2 0 case can be proved similarly by using the standard treatment for ELS together with A3) and the properties of { a t } (see Theorem 1 of Bercu <ref type="bibr" target="#b4">[5]</ref> for related Based on Lemma 1, we may now prove the following main result of this section.</p><p>Theorem 1: Let the ARMAX model (3) satisfy AI)-A3). Then the WLS described by (9)-( <ref type="formula">14</ref>) has self-convergence property, i.e., Bt converges almost surely to a finite random vector e (not necessarily equal to e). results and analysis).</p><p>U</p><formula xml:id="formula_10">Proof: Set 0 - 4t -[Yt . . . Yt--p+lUt. * . U t -q + l W t . . . Wt--r+l]T. (<label>21</label></formula><formula xml:id="formula_11">)</formula><p>Then ( <ref type="formula">3</ref>) can be rewritten as</p><formula xml:id="formula_12">Yt+l = or4; + W t + l</formula><p>and substituting this into (9) we get</p><formula xml:id="formula_13">- B t + l = e t + Lt[0,'4t + e'(4: -4t) + W t + l ] - t = BO + Li[BT$i + ST(&amp; -4i) + W i f l ] . (<label>22</label></formula><formula xml:id="formula_14">)</formula><p>Now, by taking trace on both sides of (1 1) and summing i=O up, we have \ From this, Lemma I-iii), and the Schwarz inequality, it follows that &lt; 00, a s . So by Chow's martingale convergence theorem we know that E L i w ; + 1 also converges a.s. Finally, combining all the 00 i=O above proved facts, we find from (22) that 0, converges a s . as desired.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0</head><p>We are now in a position to give a detailed comparison between WLS and LS.</p><p>Remark 3: Theorem 1 can readily be extended to general linear regression models. Under only the measurability conditions on the regressors as used here, neither the familiar stochastic gradient (SG) nor the standard LS algorithms are known to converge. In fact, for the SG we only know that the norm -811 converges (e.g., 114, p. lOS]), while for LS even the boundedness of (0,) cannot be guaranteed (see <ref type="bibr">[16,</ref> p. 367]), nor convergence. The only exceptions are the results derived in a Bayesian framework with Gaussian white noise, where it was shown that the LS estimate converges outside an exceptional set of true parameter vectors of Lebesgue measure zero (see Sternby <ref type="bibr" target="#b15">[17]</ref> and Kumar [lx]). This property has been used by <ref type="bibr">Kumar [18]</ref> to analyze a variety of adaptive control schemes for minimum phase systems and is discussed in more detail by Nassiri-Toussi and Ren <ref type="bibr" target="#b14">[16]</ref>, where it is shown that the exceptional set for convergence of LS can indeed be nonempty.</p><p>Remark 4: By Lemma 1-i) we know that</p><formula xml:id="formula_15">ll&amp;+ll12 = ~(&amp;"Pt+l)) a s .<label>(24)</label></formula><p>Consequently, a sufficient condition for strong consistency of WLS is that P,,ZmO a s .</p><p>If T = 0 and the regressor 4, is free of the initial Condition Bo, then 8t-0 for any initial condition if and only if (25) holds. The necessity can be proven as follows: By ( <ref type="formula">9</ref> ). Of course, if the moment condition in Al) is strengthened to a condition of order greater than two, then for the standard LS, (26) holds with S = 0 (see, <ref type="bibr">Lai and Wei [19]</ref>). Thus, the WLS may have a mild compromise on convergence rate (in the case of convergence to f?) compared with LS. Nevertheless, due to its self-convergence, the WLS is more convenient than LS in applications to general adaptive control systems as can be seen from the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>m. UNIFORM CONTROLLABILITY OF ESTIMATED MODELS</head><p>Let us denote</p><formula xml:id="formula_16">C(0) = [ I C 1 . . . C,-l]T, H = [ l o . . .0]<label>(28)</label></formula><p>A where n = max(p, q , T + l), and a, = b, = c k = 0 for i &gt; p , j &gt; g, IC &gt; T. Then (3) can be written in the state-space form (29) Many standard control law designs depend on the controllability of the system (29), and hence we make the following assumption:</p><p>A4) The pair [A(0), b(0)] is controllable where 0 is the It is a standard result from linear system theory that controllability of [A <ref type="bibr" target="#b7">(8)</ref>, b(B)] is equivalent to the coprimeness of the polynomials A(z) and B ( z ) defined by ( <ref type="formula">4</ref>) and ( <ref type="formula" target="#formula_1">5</ref>) and which in turn is equivalent to the nonsingularity of the Sylvester resultant (eliminant) matrix associated with 0. [Note that A4) implies that either a, or b, in (27) is nonzero, and hence Now, let Bt be the WLS estimate discussed in the last section and $ be its limit. If for the initial condition Bo the pair [A(Bo),b(#o)] is controllable, ut is a rational function of {yo, . . . , y,}, and all finite dimensional distributions of the noise process {wt} are absolutely continuous with respect to Lebesgue measure, then, following <ref type="bibr">Meyn and Caines [15]</ref> or Caines <ref type="bibr" target="#b14">[16]</ref>, we may prove that [A <ref type="bibr">(8,)</ref>, b(0,)J is controllable as. for each t 2 1 (see Appendix B).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>This, however, does not guarantee that [A(&amp;), b(f?,)] is uniformly controllable, since the limiting model [A($), b ( e ) ]</head><p>may be uncontrollable. Thus, modifications on (0,) seem to be necessary.</p><p>Here, we first follow an idea similar to that used by Lozano [ll] and Lozano and Zhao 1121 for such a modification. Let us denote /3,* = PF1'2(Q -Qt). Then, by Lemma 1-i) we know that the sequence {,B,*} is bounded almost surely, and that</p><formula xml:id="formula_17">%+l = A(0)zt + b(Q)ut + C ( Q ) W t + l yt = H x t , 20 = [~0,0...0]~.</formula><p>true system parameter. n = m=(p,q).I 8 = 0, + P,'/'oP,*. Lemma 2: Let Ot be defined by (31) with Bt being the WLS estimate defined by ( <ref type="formula">9</ref>)-( <ref type="formula">14</ref>) and {Pt} being any bounded sequence. Then under conditions of Lemma 1 we have:</p><p>i) llpL1' 2Gtll = 0(1) a s .</p><p>ii . so is to let Pt be as close to the maxima of the function ft(x)</p><p>as possible for all t 2 0.</p><p>Instead of using the deterministic search method for choosing pt as in Lozano and Zhao [12], here we use an optimization-based random search method which has the advantage that only two matrix determinants are needed to be calculated and compared at each step t. To be specific, let D be any compact subset of Rd which coincides with the closure of its interior. For example, D may be taken as simple domains like the unit ball {x E Rd :</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">I} or the unit cube</head><p>Let {qt } be an independent sequence of d-dimensional random vectors which are uniformly distributed on D. Also let { q t } and {wt} be independent. Take a number y &gt; 0 small enough so that Finally, the sequence {pt} can be recursively defined as follows (36)</p><formula xml:id="formula_18">pt = { w 1 if ft(rlt) 2 (1 + r)ftft(Pt-1) &gt; if ft(rlt) &lt; (1 + r)ft(Pt-1)</formula><p>for all t 2 1, where the initial condition is PO = qo.</p><p>Obviously, for any adaptive control sequence {ut}, {Pt, F;} is an adapted sequence where F L = ~{ w i , q,, i 5 t}. Note that, similar to the deterministic case (e.g., <ref type="bibr">[12]</ref> and <ref type="bibr" target="#b21">[24]</ref>), the introduction of the hysteresis constant y in (36) plays a role of ensuring the convergence of {&amp;} in sample path. The following key theorem states that {&amp;} defined by (36) does indeed meet our requirements (see Appendix D for the proof).</p><p>Theorem 2: Let Al)-A4) hold for the AFMAX model <ref type="bibr" target="#b2">(3)</ref>.</p><p>Then, the WLS-based parameter estimate Bt defined by (31</p><formula xml:id="formula_19">)</formula><p>with Pt chosen as in (36) has the following properties: i) {&amp;}_converges almost surely.</p><p>ii</p><formula xml:id="formula_20">) [A(Ot), b(&amp;)] is uniformly controllable a.s.</formula><p>iii) All properties of Lemma 2 hold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. ADAPTIVE POLE-PLACEMENT CONTROL</head><p>Let A* (2) be an arbitrary stable polynomial of degree 2n -1</p><p>with n = max(p,g). Then by A4) we know that there exist unique polynomials L ( z ) and R ( z ) , both of order ( n -1) with L(0) = 1, such that To ensure boundedness of the long-run average of the squared output process {yt}, it is natural to require that and this-condition will be assumed throughout the sequel.</p><formula xml:id="formula_21">A ( z ) L ( z ) + B(z)R(z) = A * ( z ) .</formula><p>the following estimated polynomials in a standard way Let { B t } be defined as in Theorem 2, from which we form</p><formula xml:id="formula_22">A t ( z ) = 1 + a l ( t ) z + ... + an(t)zn B,(z) = bl(t)z + . * . + bn(t)zn Ct(z) = 1 + c1(t)x + . . * + c n ( t ) F . (<label>41</label></formula><formula xml:id="formula_23">)</formula><p>Then by Theorem 2, the following Diophantine equation</p><formula xml:id="formula_24">A t ( z ) L t ( z ) + Bt(z)Rt(z) A*(z) (42)</formula><p>will uniquely determine polynomials Lt ( z ) and Rt ( z ) , both 1 2 27 + y2.</p><p>(35) of order-(n --1) with coefficients bounded and convergent.</p><p>From this we are able to prove that the following cesZainty equivalent pole-placement adaptive control law</p><formula xml:id="formula_25">Lt(Z)Ut = Rt(x){Yf -Y t } (43)</formula><p>is stabilizing (see Appendix E for the proof). Theorem 3: Consider the ARMAX system (3) an-d the poleplacement adaptive control law (41)-( <ref type="formula">43</ref>) with {&amp;} defined as in Theorem 2. Then the closed-loop system is stable in the sense that T Since in Theorem 3 the parameter estimate {&amp;} may not be strongly consistent, the closed-loop equation under the adaptive law (43) may not approach to the ideal one (39), in general. We now use the "attenuating excitation technique" developed in [ 151 and [ 141 to design an optimal controller.</p><p>Let { e t } be a bounded i.i.d. sequence of random variables independent of {wa, q p } with zero mean and unit variance, and let U: be defined by L ( . &gt; . , " = Rt(z){y," -Y t } .</p><p>(44)</p><p>The actual system input is taken as (45) Theorem4: Consider the ARMAX system (3) and the acaptive control law defined by (42), (44), and (45), with {et} defined as in Theorem 2. Then the closed-loop system is asymptotically optimal in the sense that The proof is also given in Appendix E.</p><p>V. ADAPTIVE LQG CONTROL Consider the following quadratic cost function</p><formula xml:id="formula_26">1 T -l J ( u ) = limsup -c [ ( y i -y:))" + Xu:] (46) T i m i=o</formula><p>where X &gt; 0, and {y;} is a known bounded deterministic reference signal.</p><p>Define the set U of admissible controls</p><formula xml:id="formula_27">t -1 U = {U : ccuz" + IIGII)") = O ( t ) ? l l ~t I l 2 = 4 t ) a=O a s . ut E Ft 'vi} (47)</formula><p>where { z a } is the state vector defined by (29). Then the optimal control minimizing J ( u ) in U is (cf. <ref type="bibr">[14, p. 761)</ref> where</p><formula xml:id="formula_28">L = -(A + b'Sb)-'b'SA dt = -(A + b'Sb)-lb'gt+i gt = - FJ'H'y,*+, = F'gt+l -H'y;</formula><p>(51)</p><formula xml:id="formula_29">F = A -b(X + b'Sb)-lb'SA. (49) (50) 00 3=0 S = A'SA -A'Sb(X + b'Sb)-'b'SA + H'N (52)<label>(53)</label></formula><p>Here we have written A and b for A <ref type="bibr" target="#b7">(8)</ref>  </p><formula xml:id="formula_30">U t = L&amp; + &amp;<label>(54)</label></formula><p>where</p><formula xml:id="formula_31">Lt = -(A + baSLbt)-'b,'StAl (55) &amp; = -(A + bzStbt)plbTct+l (56) ct = -F,"'H'y,*+,<label>(57)</label></formula><formula xml:id="formula_32">Ft = At -bt(X + blStbt)-lblStAt M j=0<label>(58)</label></formula><p>and { S t } is recursively defined by</p><formula xml:id="formula_33">St = AiSt-IAt -A,'St-lbt(A + bl x St-ibt)-lblSt-lAt + H'H, S o 2 0. (<label>59</label></formula><formula xml:id="formula_34">)</formula><p>Also in (54), {%} is the estimate for { x t } which is generated by the following adaptive filter</p><formula xml:id="formula_35">%+I = Atft + btut + Ct[yt+z -HAt2t -Hbtut] 2 0 = [yo, 0,. . . 01' .<label>(60)</label></formula><p>To get an optimal adaptive control law, we use the "attenuating excitation technique" again. Let { e t } be the same as that in (45) and {ut} be defined by ( <ref type="formula" target="#formula_30">54</ref>)-(59). Then define (61)</p><p>The following result is proven in Appendix F. Theorem 5: Consider-~e ARMAX model <ref type="bibr" target="#b2">(3)</ref> where Al), A3), and A4) hold. Let { e t } be defined as in Theorem 2 which is used in defining the adaptive LQG control laws (54) and (61). Then {ut} is stabilizing and {U:} is optimal, i.e., J ( u ) &lt; 00 and J ( u * ) = Jmin a s .</p><p>where J,,, is the minimum of the cost function (46) (see <ref type="bibr">[14, p. 2501)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUDING REMARKS</head><p>The self-convergence property of WLS together with the method of random regularization has enabled us to give a complete solution to both the stochastic adaptive poleplacement and LQG control problems for ARMAX systems, requiring only controllability of the true system together with the standard passivity condition on the noise model. The stability of the closed-loop system is achieved without introducing any excitation probing signals into the system, and the optimality is established by only incorporating with decaying excitations (which seems to be necessary).</p><p>The applications of the self-convergence property are not limited to these, and a universal procedure for the design of stochastic adaptive control laws for ARMAX models may be formed as follows: i) To get a self-convergent parameter estimate via WLS, ii) To modify the WLS estimate via (31), so that the estimated model is uniformly controllable (or satisfy other requirements, depending on specific applications), and iii) To form the adaptive control law via the certainty equivalence principle (incorporating with the "attenuating excitation technique," if necessary). Finally, we remark that generalizations of the results of the paper to multidimensional ARMAX models as studied, in e.g., <ref type="bibr" target="#b12">[14]</ref>, are straightforward, and the proofs are only notationally more complex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A PROOFS OF (15)-( 17)</head><p>First, for any f ( z ) E F and for large z &gt; 0 which proves (15). Next, for any M &gt; 0, there exists an integer m 2 1 such that M 5 Zm. Hence, following the proof ideas in [25, p. 2761, we have for 2 2 1 which is <ref type="bibr" target="#b14">(16)</ref>. Furthermore, for z E [e2" ezk+' ) ,</p><formula xml:id="formula_36">I C &gt; ] = O ( k ) = O(logloge2k) = O(loglog2)</formula><p>which implies <ref type="bibr" target="#b15">(17)</ref>. Hence the proof is completed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B CONTROLLABILITY OF [A(&amp;), b(Ot)]</head><p>Let M ( 0 ) be the Sylvester resultant matrix defined by (32).</p><p>We only need to prove that det M ( &amp; ) # 0 a.s. Vt. For this, let N(6') be defined in the same way as M ( 0 ) but with the elements' 1's in the diagonal replaced by 0. Then, by (9), we have and we get (yt+l -@Ot) = 0; hence this constant must be 1 and M(Bt+l) is nonsingular a.s. by our assumption.</p><p>If f ( w 0 , . . . , w t + l ) is not a constant, then by the absolute continuity of the distribution of {wt}, we know from Meyn and Caines <ref type="bibr" target="#b18">[20]</ref> or Caines <ref type="bibr" target="#b19">[21]</ref> that ~( W O , .</p><p>. This completes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX D</head><p>PROOF OF THEOREM 2 The proof is divided into the following four steps.</p><p>Step I : We first prove that for any t 2 0, the pair [A(&amp;), @t)] is controllable, as., or ft(,&amp;) # 0, a.s., where f t ( x ) is defined by (33).</p><p>For this, we only need to show that ft(qt) # 0 as., Vt L 0; since by the definition (36) we have We need the following fact which follows from the proof in (e.g. [21, pp. 778-7801): Let P(z1 . . . zd) be a real-valued nonzero polynomial of d real variables. Then m((z1 . ' . xd) : P(xl . . . xd) = 0) = 0, where m(.) is the Lebesgue measure on E ~. Now, by (30) and A4) we know that det M(Bt + P;"z) is an a s . nonzero polynomial for any t 2 0. Consequently, by the above fact we know that m(z : f t ( x ) = 0) = 0 a s . V t 2 0 which implies that the uniform probability measure p ( . ) defined on D satisfies p(x E D : f t ( x ) = 0) = 0, a s . Vt 2 0 since p(.) is absolutely continuous with respect to m(-).</p><p>Note that for any adaptive input {ut}, the random process ft(.) is measurable with respect to the o-algebra which means that P ( f t ( q t ) = 0) = 0 or ft(.it) # 0 as., V t 2 0. Hence the desired controllability is proven.</p><formula xml:id="formula_37">C T { W ~, V % -~, ~ 5 t } = Gt-1. Let I(.)</formula><p>Step 2: Next, we prove that there exists a positive random variable 6 , &gt; 0 such that limsup ft(qt) 2 6 , a.s.</p><p>(63)</p><formula xml:id="formula_38">t i 0 2 Denote n St = max f t (x) X E D</formula><p>Note that Bt, P: " and 6, are all Gt-l-measurable, and that qt is independent of ! where y is given as in (36).  We now prove (66) by induction. First, for t = to, by ( <ref type="formula">68</ref>) and (69) (73)</p><p>Hence, by Lemma 2 ii) and ( <ref type="formula" target="#formula_6">18</ref>) we know that for some L &gt; 0 f(Pto) 2 ft,(Pt,) -y2s 2 (2 -y2)S 2 S.</p><p>Next, assume that (66) holds fort = k 2 to, i.e., f(Pk) <ref type="bibr">6,</ref> we need to consider the case where t = k + 1. If = Pk, then (66) is true by the induction assumption. Otherwise, if P k + l # P k then by the definition (36), we know that from this, (69), and f(Pk) 2 6, we have where for the last inequality we have used (35). Hence (66) is proven.</p><p>Step 4: Finally, we prove that all the results of Theorem 2 hold. By Lemma 2 we need only to prove the properties i) and ii).</p><p>Let us first show that the limit lim f ( P t ) = f exists and f &gt; 0 a s . For this we need only to show that f ( P k ) is nondecreasing for k 2 to. This is true since when Pk+1 # P k with k 2 t o we have from (71) and (66) that Furthermore, by the uniform convergence of f t ( z ) to f(x) we know that lim f t + l ( P t ) = lim f t ( P t ) = f &gt; 0 a.s. This together with the result in Step 1 implies that property ii) is true.</p><p>For proving i) we need only to prove that {,&amp;} is convergent a s . This is true, because, otherwise, by the definition (36), (70) would hold for infinitely many k on a set r with P ( r ) &gt; 0.</p><p>Now, let such k tend to infinity we would have From this it is easy to see that T t = O ( t ) , and the proof is complete.</p><p>Proof of Theorem 4: First, in the completely similar way as the proof of Theorem 3, it is easy to show that Consequently, applying Lemma 3 of Guo and Chen <ref type="bibr" target="#b5">[6]</ref>, we know that t a=l for some constant CO &gt; 0. From thiz and (18) it follows that Pt-0, and then by Lemma 2 (i), et is a strongly consistent estimate for the true parameter 8. Consequently, Lt(z), B t ( z ) ,</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Remark I :</head><label>I</label><figDesc>It can easily be shown (see Appendix A</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>-</head><label></label><figDesc>Y t + l = 0'5, + G t + l A where [ &amp; + l , &amp; , W + ~] = &amp; G [ ~t + 1 , 4 t , w t + l ] . Hence, by the standard analysis for LS (see, e.g., [6, (A.3)]) we have t i=O P+q+r i COTt . Since f(.) is slowly increasing, by (16) in Remark 1 there exists c &gt; 0 such that f(co1 det(PGl1)) I ~(TF'~'') 5 c f ( T t ) and consequently, by (14) we have at 5 c/f(c;'det(P;;)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>on the right-hand side is convergent a s . by Chow's martingale convergence theorem (cf. [ 14, p. 36]), and the second term is convergent since condition (19) holds. Hence, the summation of the last term in(20) is bounded a.s. (thanks to the choice of the weights).As for the second last term in (20) ([14, Theorem 2.8, p.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>5 : 4 , 4 :</head><label>544</label><figDesc>)-(11) we have t -Q t + l = Pt+lP;l&amp; -Pt+l %4,Wz+1 z=o and since dt-O, WO, the lastterm, free of BO, must converge to zero, and thus Pt+lP~lQo-+O, V80 which necessarily implies (25).Remark Let A,,,@) be the minimum eigenvalue of c and the weighting sequence be taken as ak = z=o t consequently, by<ref type="bibr" target="#b21">(24)</ref>, we have for WLS This is precisely the convergence rate established for the standard LS (see114, p. 961 and [15]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>1111 and [12], although {ot) is not available here, given A4), this formula suggests the possibility of finding a bounded adapted sequence { ~t , &amp; } such that the modified estimate (31) %orresponds to a uniformly controllable model. We may call Bt the WLS-based estimate.-A %t = 0t + Py",The key point of the modification in (31) is that {&amp;} possesses almost the same nice properties as those of the WLS estimate Bt, as demonstrated in the following lemma (see Appendix C : or the proof).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>the feedback control law is generated by L(z)ut = R(Z){Y,* -Yt} (38) where {$} is an arbitrary but bounded deterministic reference sequence, then the resulting closed-loop system has characteristic polynomial A*(z) and (cf. Goodwin and Sin 1221) A*(z)yt = L(z)C(x)wt + B(z)R(z)y,*, 'dt. (39)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>M</head><label></label><figDesc>(&amp;+l) = M ( &amp; ) + N(Lt(Yt+l -&amp; e t ) ) M ( &amp; ) + (Yt+l -$l&amp;)N(L). = Let us assume that det M ( &amp; ) # 0 a s . for some t 2 0. Then det M(&amp;+1)= det M ( &amp; ) . det[l+ (yt+l -$l&amp;)M-'(Ot)N(Lt)].is a rational function of {WO,. . . , wt+l}. If it is a constant, then set wt+l = -Or&amp;', where 4: is defined by<ref type="bibr" target="#b19">(21)</ref>,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>denote the indicator function of a set. By the independence of vt and Gt-l and [14, Theorem 1.81, we have n EI(ft(rlt) = 0) = E{E[I(ft(rlt) = 0)lGt-ll) = E{/.($ E D : f t ( x ) = 0)) = 0 = q , aft(.) = O)P(d$))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>=</head><label></label><figDesc>W t + et 4t-1 + eT(4:-, -4t-1) + [Ct(z) -l]Gt = C(z)wt + ot 4t-1 + [Ct(z) -C(z)]Gt = Ct(z)wt + BZ4t-1 + [C(z) -Ct(.)](Wt -Gt).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>7</head><label>7</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>) L f(Pk) + Y f ( P k ) -(1 + Y)Y2S -Y2S L f ( P k ) + W l -2Y -r21 L f(Pk).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>This is impossible since y &gt; 0 and f &gt; 0 a.s. Hence the proof of Theorem 2 is completed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>and b(8) defined by (27), for simplicity. H is defined by (28).</figDesc><table><row><cell>Since ( A , H ) is observable and (A,b) is controllable by</cell></row><row><cell>A4), it is known that S &gt; 0 is the unique positive solution of</cell></row><row><cell>(52) and F defined by (53) is a stable matrix (cf., e.g., [14,</cell></row></table><note><p>Now, let &amp; be the estimate for 6' which isjefine? as in Theorem 2, and let At, bt, and Ct stand for A(Qt), b(Bt), and C(&amp;). The certainty equivalence LQG control takes the form P-751).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>. , wt+l) # 0 as.,</figDesc><table><row><cell>i=l</cell><cell></cell></row><row><cell>t</cell><cell></cell></row><row><cell>i=l</cell><cell></cell></row><row><cell></cell><cell>t</cell></row><row><cell>= O ( T t ) + O(1).</cell><cell>i=l</cell></row><row><cell></cell><cell cols="2">and hence M(Ot+1) is again nonsingular a s . This completes</cell></row><row><cell></cell><cell cols="2">the induction proof.</cell></row><row><cell></cell><cell></cell><cell>APPENDIX C</cell></row><row><cell></cell><cell></cell><cell>PROOF OF LEMMA 2</cell></row><row><cell></cell><cell cols="2">i) By Lemma 1-i) and (31) we have</cell></row><row><cell></cell><cell>ii) By Lemma</cell><cell>-ii) and the Kronecker Lemma</cell></row><row><cell></cell><cell>t</cell></row><row><cell></cell><cell>4; gi</cell></row><row><cell></cell><cell>i=l</cell></row><row><cell></cell><cell>but</cell></row><row><cell></cell><cell>i=l</cell><cell>i=l</cell></row><row><cell></cell><cell></cell><cell>t</cell></row><row><cell></cell><cell></cell><cell>i=l</cell></row><row><cell></cell><cell cols="2">=O(.,l)</cell><cell>t + O(a,l ai$:Pi+l$i)</cell></row><row><cell></cell><cell cols="2">and hence the assertion ii) holds.</cell></row><row><cell></cell><cell cols="2">iii) First, Lemma 1%) together with (18) in Remark 1 im-</cell></row><row><cell></cell><cell cols="2">plies that c($z&amp;)'/rt &lt; cc a.s. So, by the Kronecker 03</cell></row><row><cell></cell><cell cols="2">Lemma, C($iS,,z = o(rt) + 0(1) a s . NOW, since t=l t</cell></row><row><cell></cell><cell>Pi -Pt+l-O i=l</cell><cell>as i-cc</cell></row><row><cell></cell><cell>t</cell><cell>t</cell></row><row><cell></cell><cell>i=l</cell><cell>i=l</cell></row><row><cell></cell><cell></cell><cell>t</cell></row><row><cell></cell><cell></cell><cell>i=l</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Manuscript receivedAugust 5 , 1994; revised July 3, 1995. Recommended by Associate Editor at Large, B. Pasik-Duncan. This work was supported in part by the National Natural Science Foundation of China. The author is with Institute of Systems Science, Chinese Academy of Sciences, Beijing 100080, China. Publisher Item Identifier S 0018-9286(96)00384-4.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>&amp; I ,</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The author wishes to thank B. Bercu, H. F. Chen, R. Lozano, and J. F. Zhang for their valuable discussions and comments.</p><p>The author would also like to thank W. Ren for providing the reference [ 161.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>where Gt-l is defined as in Step 1.</p><p>Then again by properties of conditional expectation (cf. [14,  Theorem l.S]), we have = P ( D t ) .</p><p>(64)</p><p>We now proceed to show that p ( D t ) ++ 0, a s . as t -00.</p><p>Note that both {e,} and {P:'2} are convergent as.; we may then define a function f ( x ) as f(x) = t%mCOft(x), a s . x E (65) Now, let p* be a convergence point of {p;} defined in (30), then by condition A4) we know that f(P*) = 1 det M(e)l # 0. Therefore, f ( x ) $ 0, as., which necessarily implies that maxf(z) # 0, as., since f ( z ) is the absolute value of a XED real polynomial (with variables being the components of z), and since m ( D ) &gt; 0. Furthermore, it is easy to see that f t ( x ) converges to f(x) uniformly on D. Consequently, St -6 , with 6 , = maxf(x) &gt; O a.s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X E D</head><p>Since f(z) is a continuous function, we have m ( D m ) &gt; 0 as., where D, is defined by Hence, by (64) we know that Consequently, by the Borel-Cantelli-LCvy Lemma (cf. Theorem 2.5 in <ref type="bibr" target="#b12">[14]</ref>) we have which implies that 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">,</head><p>hence (63) is proved.</p><p>variables S and to such that</p><p>Step 3: We now prove that there exist positive random</p><p>where f ( z ) is defined by (65). By (62)   <ref type="bibr">THEOREM 5</ref> We first prove that {ut} is stabilizing. By Theorem 2, [A,, bt] converges a s . to a controllable pair [x,;], and it follows from [14, Theorem 3.4 ] that St defined by (59) converges to the unique positive solution s^ of the following algebraic Riccati equation</p><p>and that Ft defined by (58) converges to a stable matrix. (Note that the condition d e t A # 0 in <ref type="bibr">[14, p. 701</ref>  By a completely similar argument, we know that the control law {U:} defined by ( <ref type="formula">61</ref>) is also stabilizing. Then similar to $e proof of Theorem 4 we know that under this control law Bt is a strongly consistent estimate for the true parameter B. By this, the optimality of {U:} can easily be proved along the same lines as those in [14, pp. 264-2651. This completes the proof. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Theory and Practice of Recursive Identi$-curzon. Cambndge</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ljung</surname></persName>
		</author>
		<author>
			<persName><surname>Soderstrom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>MA MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Performance analysis of the forgetttng factor RLS algonthm</title>
		<author>
			<persName><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><surname>Ljung</surname></persName>
		</author>
		<author>
			<persName><surname>Priouret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Adaptive Contr Signal Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="525" to="537" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Convergence of adaptive mnimum variance algonthm via weightmg coefficient selection</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J B</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Automat Contr</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="146" to="153" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Moindres Carrks Pond&amp;&amp; et Poursuite</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bercu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Duflo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann Insr Henn Poincari</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="403" to="430" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Weighted estimation and tracking for ARMAX models</title>
		<author>
			<persName><surname>Bercu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIAM.7 Contr Optimization</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="89" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The 8, strom-Wittenmark self-tuning regulator revisited and ELS-based adaptive trackers</title>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H F</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Automat Contr</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="802" to="812" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Further results on least squares based adaptive mnimum vanance control</title>
		<author>
			<persName><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J Contr Optimization</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="187" to="212" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Convergence and logarithm laws of self-tuning regulators</title>
		<author>
			<persName><surname>___</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Auromahca</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Model reference adaptive control of time varying and stochastlc systems</title>
		<author>
			<persName><forename type="first">L J</forename><surname>S P Meyn</surname></persName>
		</author>
		<author>
			<persName><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Automat Contr</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1738" to="1753" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Stochastic adaptwe prediction and model reference control</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P R</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Automat Contr</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="2047" to="2060" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Singularity-free adaptive pole-placement without resorting to persistency of excitation Detailed analysis for first order systems</title>
		<author>
			<persName><surname>Lozano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="27" to="33" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adaptive pole placement without excitation probing signals</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lozano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">; A A</forename><surname>Zhigljavsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Automat Contr</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="58" />
			<date type="published" when="1991">1994 1131. 1991</date>
			<publisher>MA Kluwer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Identlfication and Stochastic Adaptive Control Boston</title>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Blrkhauser</publisher>
			<pubPlace>MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Convergence rate of least-squares identification and adaptive control for stochastic systems</title>
		<author>
			<persName><surname>__</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Contr</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1459" to="1476" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On the convergence of least squares estimation in white noise</title>
		<author>
			<persName><forename type="first">K</forename><surname>Nassiri-Toussi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="364" to="368" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On consistency for the method of least squares using martingale theory</title>
		<author>
			<persName><forename type="first">J</forename><surname>Stemby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="346" to="352" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Convergence of adaptive control schemes using leastsquares estimates</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="416" to="424" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Least-squares estimation in stochastic regression models with application to identification and control of dynamic systems</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Z</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="154" to="166" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The zero divisor problem of multivariable stochastic adaptive control</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Meyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Caines</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Syst. Contr. Lett</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="235" to="238" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Adaptive Filtering, Prediction and Control</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Caines</surname></persName>
		</author>
		<editor>22j G. C. Goodwin and K. S. Sin</editor>
		<imprint>
			<date type="published" when="1984">1988. 1984</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>New York Wiley; Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
	<note>Linear Stochastic Systems</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Detectability and stabilizability of time-varying discrete-time linear systems</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D 0</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Contr. Optim</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="20" to="32" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Design issues in adaptive control</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Middleton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Goodwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename><surname>Mayne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="50" to="58" />
			<date type="published" when="1988-01">Jan. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">P6lya and G. Szego, Problems and Theorems in Analysis</title>
		<author>
			<persName><forename type="first">G</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1972">1972</date>
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="volume">1</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
