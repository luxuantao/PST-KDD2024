<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Application of online-training SVMs for real-time intrusion detection with different considerations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2005-02-21">21 February 2005</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zonghua</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science</orgName>
								<orgName type="institution">Japan Advanced Institute of Science and Technology</orgName>
								<address>
									<addrLine>1-1</addrLine>
									<postCode>923-1292</postCode>
									<settlement>Asahidai, Nomi</settlement>
									<region>Ishikawa</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Hong</forename><surname>Shen</surname></persName>
							<email>shen@jaist.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science</orgName>
								<orgName type="institution">Japan Advanced Institute of Science and Technology</orgName>
								<address>
									<addrLine>1-1</addrLine>
									<postCode>923-1292</postCode>
									<settlement>Asahidai, Nomi</settlement>
									<region>Ishikawa</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Application of online-training SVMs for real-time intrusion detection with different considerations</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2005-02-21">21 February 2005</date>
						</imprint>
					</monogr>
					<idno type="MD5">D729675F55EDBD659F27A4706B67D09B</idno>
					<idno type="DOI">10.1016/j.comcom.2005.01.014</idno>
					<note type="submission">Received 10 June 2004; revised 16 January 2005; accepted 28 January 2005</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T17:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Computer security</term>
					<term>Intrusion detection</term>
					<term>Anomaly detection</term>
					<term>Support vector machines</term>
					<term>Text categorization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As intrusion detection essentially can be formulated as a binary classification problem, it thus can be solved by an effective classification technique-Support Vector Machine (SVM). Additionally, some text processing techniques can also be employed for intrusion detection, based on the characterization of the frequencies of the system calls executed by the privileged programs. Based on the intersection of these two research domains, i.e. pattern recognition and text categorization, and breaking the strong traditional assumption that training data for intrusion detectors are readily available with high quality in batch, the conventional SVM, Robust SVM and one-class SVM have been modified respectively based on the idea from Online SVM in this paper, and their performances are compared with that of the original algorithms. After elaborate theoretical analysis, concrete experiments with 1998 DARPA BSM data set collected at MIT's Lincoln Labs are carried out. These experiments verify that the modified SVMs can be trained online and the results outperform the original ones with fewer support vectors (SVs) and less training time without decreasing detection accuracy. Both of these achievements could significantly benefit an effective online intrusion detection system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>As computer networks play an increasingly vital role in modern society with rapid increases in the functionality, connectivity and accessibility, more and more efforts are being put to their security, because a major attack can significantly reduce the capability of information systems. Any exploitable weakness of networks that can be used by hackers and criminals can potentially cause great losses to people. As backup measures for intrusion prevention, such as user authentication, authorization, encryption, etc. intrusion detection techniques are attracting increasing attention, and some achievements have been applied widely, with limited performance.</p><p>Briefly, the aim of intrusion detection is to identify malicious attacks that might threaten the security from the normal activities of information systems. Existing intrusion techniques fall into two general categories: anomaly detection and misuse detection. Anomaly detection techniques mainly focus on establishing normal activities pattern (set or rule) U, and any current activity u that deviates from U is treated as an intrusion. On the contrary, misuse detection techniques attempt to create a model of attack signatures J, when a current signature j matches J, it is regarded as an intrusion. However, defects exist in both anomaly detection and misuse detection, false positives (j is misclassified to U) and false negatives (novel attack j2J is ignored) often cause these techniques to fail. Due to the complementary nature of these two approaches, the intuitive approach to design an effective intrusion detection system is to combine them together. Generally, the criterion for evaluating the efficiency of an IDS is its ability to detect underlying attacks, while minimizing the false positive rate.</p><p>Based on the analysis of the available literature on intrusion detection, we found that two elements are essential to intrusion detection, namely, a data model of the observable subjects or events, and the corresponding techniques for characterizing and analyzing the data model. Specifically, several questions should be answered carefully: What observable subjects should be selected for monitoring and analyzing? What attributes should be considered for characterizing these related subjects? What existing approaches or novel methods can be employed to detect anomalies based on the characterized observation? It is well known that a computer and network system generally contains two components: hosts and communication links among hosts. Consequently, network traffic data, from captured data packets travelling on the communication links, and audit data, which record the sequence of events on the hosts, can be selected as observable subjects. Actually, those two domains can be further exploited for seeking more particular and effective observation, such as command line strings, system call traces, and resource consumption patterns in the host audit data, or the intrinsic features, traffic features, and content features of the network packets. Based on the characterization of the data model, all techniques that are effective for distinguishing intrusions from normal behaviors are worthy of consideration. Up to now, techniques drawn from statistics <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b29">31,</ref><ref type="bibr" target="#b30">32]</ref>, data mining <ref type="bibr" target="#b17">[18]</ref>, pattern recognition <ref type="bibr" target="#b5">[6]</ref>, machine learning <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b23">25]</ref>, and other research fields have extensively and effectively been applied to intrusion detection.</p><p>The available approaches for intrusion detection focus on improving detection accuracy and restraining false alarms, and given enough time, most of them can achieve satisfactory results in terms of these criteria. However, in practice, intrusion detection is a real-time critical mission, that is, intrusions should be detected as soon as possible or at least before the attack eventually succeeds. In addition, there is usually an initial training period for an intrusion detector to characterize the observable subject's behavior, and most existing methods are based on the assumption that high quality labelled training data are readily available. This assumption severely limits their application in practice. In fact, intrusion detectors must undergo frequent retraining, to incorporate periodically new examples into the training data for classifying novel attacks and changes from normal behavior. Therefore, running time and training time should also be considered in addition to detection accuracy and false alarms when designing an effective IDS.</p><p>Various methods have been introduced for detecting intrusions at the level of privileged processes in UNIX OS, because of its special properties, such as sensitivity to intrusions, stability over time, and limited range of behaviors, hence any exploitation of vulnerabilities in privileged process can give an intruder super-user status and thus commit further attacks. In <ref type="bibr" target="#b19">[20]</ref>, intrusion detection was formulated as a text processing problem based on the analogy between 'system calls/processes' and 'words/ documents'. Here, we also take system calls executed by privileged processes as observable subjects for analysis. Generally, the contributions of our work presented in this paper mainly include: † Based on the fact that original tf-idf <ref type="bibr">(</ref>  <ref type="bibr" target="#b16">[17]</ref>. That is, training data are provided in sequence online, rather than in a batch.</p><p>After an elaborate theoretical analysis, we evaluated our methods using reformulated 1998 DARPA BSM data and compared their performance with the original algorithms based on the original tf-idf weighting model. The results show that our modified SVMs can significantly reduce training time with better generalization performance and fewer support vectors while maintaining high detection accuracy. They thus require less computational overhead and running time and so are more desirable for real time intrusion detection. Furthermore, our modified weighting model based on the tf-idf weighting method suppresses the false alarm rate to an acceptable level, thus guaranteeing the proposed method to be applied in practice.</p><p>The rest of this paper is organized as follows. In Section 2, we review some related work on the existing intrusion detection techniques that used host audit data as observable subjects. Section 3 formulates the problem we solved and describes the data source that was used in our work together with the modelling of the data. In Section 4, we introduce the effective classification method-SVM, and modify three SVMs, which have different assumptions, for online training. After the analysis of the data model and the improvement of the candidate methods, experiments were implemented to evaluate the performance of our proposed methods, which is described in Section 5. Finally, our conclusions are presented in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>As we know, intrusion detection can be treated as a binary concept on a domain consisting of temporal sequences of discrete, unordered elements, such as system call traces, network packet traces, and resource consumption. So far, many effective techniques have been employed to this problem domain, including multi-variate model <ref type="bibr" target="#b30">[32]</ref>, Markov process <ref type="bibr" target="#b31">[33]</ref>, and discriminant analysis <ref type="bibr" target="#b0">[1]</ref> from statistics; neural networks <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b14">15]</ref> from pattern recognition; support vector machines <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b23">25]</ref> from machine learning; and other clustering methods and classification methods from data mining <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>.</p><p>Forrest et al. <ref type="bibr" target="#b7">[8]</ref> proposed to build program profiles with short sequences of system calls executed by running privileged programs for intrusion detection, based on the assumption that sequences of system calls in an intrusion are noticeably different from those of normal operations. The reason for selecting privileged programs as subjects is that it constitutes a natural boundary for a computer, and the range of behaviors of privileged processes is limited and relatively stable over time compared to user behavior. Subsequently, many researchers applied various techniques <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b27">29]</ref> to extend and improve the work with increasingly better performance. Warrender et al. <ref type="bibr" target="#b27">[29]</ref> even argued that the choice of data stream (short sequences of system calls) is more important than the particular method of analysis, but subsequent studies did not adequately support this conclusion. Ye et al. <ref type="bibr" target="#b29">[31]</ref> investigated the frequency and ordering properties of computer audit data, showing that the frequency property of multiple audit event types in a sequence of events is necessary for intrusion detection, and that the ordering property of multiple audit events can provide additional advantages to the frequency property. However, due to the scalability problem of complex data models (e.g. higher-order stochastic models) <ref type="bibr" target="#b31">[33]</ref>, intrusion detection techniques based on the ordering property can hardly provide a feasible solution that produces good performance with low computational overhead, especially when the intrusive audit data are mixed with the white noise of normal audit data. The frequency property, on the other hand, can provide a viable tradeoff between computational complexity and intrusion detection performance. The motivation of our work heavily based on this conclusion.</p><p>Liao et al. <ref type="bibr" target="#b19">[20]</ref> used K-Nearest Neighbor (KNN) classifier to label program behavior as normal or intrusive. Specifically, each system call in the process was treated as a word, and the collection of system calls over each program execution was treated as a document; thus the system call frequencies were used as the main property to represent program behavior. This method can be easily implemented and in general has smaller computational overhead than other techniques from statistics, data mining, etc. Using the same data model, and based on the assumption that normal cases are mixed with anomalies in the training data, Hu et al. <ref type="bibr" target="#b12">[13]</ref> applied Robust SVM <ref type="bibr" target="#b25">[27]</ref>, which can solve the over-fitting problem effectively introduced by the noise in the training data set, to intrusion detection over noisy audit data; in this situation, if an attack occurs during the training process, the undesired intrusive behavior usually is regarded as normal one, undermining the intrusion detector's accuracy <ref type="bibr" target="#b20">[21]</ref>. However, their experiments showed that intrusion detection based on the text-processing model would generate an unacceptable false positive rate, so it could hardly be applied in practice. Additionally, based on the assumption that the number of normal instances is significantly larger than that of anomalies, Eskin et al. <ref type="bibr" target="#b6">[7]</ref> proposed unsupervised anomaly detection methods with unlabelled data, and Nguyen <ref type="bibr" target="#b23">[25]</ref> employed One-class SVM <ref type="bibr" target="#b24">[26]</ref> to identify 'outliers' amongst positive examples (normal behaviors) by treating them as negative examples (abnormal behaviors). Although detection accuracy performance was comparable to some other intrusion detection techniques, the unchanged patterns which cannot reflect concept drift limit its application. Moreover, all the intrusion detectors we listed above are based on the strict assumption that training data are readily available with high quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Problem definition and objective</head><p>This section gives a general description of intrusion detectors, together with some analysis on their failure curses. The data source that will be used in the experiments, and its modelling are also presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Intrusion detectors and their failure curses</head><p>Generally, the trade-off between the ability to detect novel attacks and the ability to generate a low rate of false alters is the main criterion for evaluating an intrusion detector. Actually, from the perspective of function, intrusion detectors can be roughly regarded as a simple kind of inductive inference system. In this system, an incoming process Q i is regarded as a 'question', while the normal or anomaly models M i that stored in the memory are regarded as 'answers'. Then, given a new Q i , the system tries to find an appropriate answer M i so that IDðQ i Þ0 M i . We look for effective ID that have the highest a priori-that have 'accurate descriptions'. In generating such IDs, some primitive IDs have to be previously defined. From probabilistic prediction we can gradually to deterministic prediction, that is, whether the current 'question' is an anomaly. Due to the fact that the sample size of M is limited but the number of questions Q are infinite and longstanding, the ken and adaptability of ID is a key to answer diverse questions successfully.</p><p>Therefore, the first objective is to train IDs to be capable of learning online to adapt the changing situations, and thus construct or update corresponding M. For instance, in practice, training sequences are usually not readily available with labels and high quality, especially for a computer system with reconfiguration. In such case, the ID has to be trained online with training data provided in a sequence rather than in a batch.</p><p>Furthermore, the construction and characterization of training sequences M is the next objective needs to be considered well. </p><formula xml:id="formula_0">f IDðO t Þ Z c; or IDðO t Þ Z 0 if f IDðO t Þ! a 1 otherwise (<label>(3)</label></formula><p>Obviously, due to the lack of prior knowledge about l, and c, it is almost impossible to carry the detection model into practice directly. Moreover, a good estimates of l and a thorough understanding of distributions of the processes N(t) and M(t), which we call system normality, are not readily available, which make the detection task deem to be NP-hard. From this point of view, no matter ordering property or frequency property of O t , the ultimate goal is to characterize the observation normality as perfect as possible. For purposes of this paper, we explore and develop Support Vector Machine as an effective frequentist estimator to characterize and identify system anomalies.</p><p>In addition, based on the fact that the number of normal activities is several orders of magnitude larger than that of anomalies in our daily computer activities, Axelsson <ref type="bibr" target="#b1">[2]</ref> gave an analysis of intrusion detector's base-rate fallacy using Bayesian Theorem. He pointed out that the false alarm rate is the limiting factor for the performance of an IDS, and thus the false alarms should be suppressed as few as possible in order to achieve substantial values of the Bayesian detection rate P(Intrusion/Alarm). In practice, excessive alarms from normal activities would make the network supervisor insensitive and intrusion detector inefficient, which is a straightforward motivation for us to restrain false alerts to an acceptable level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Attributes of data source</head><p>As we mentioned in the last section, a computer network typically includes two kinds of objects-hosts, and communication links. Therefore, network traffic data and host audit trails are two main observations for capturing activities. In this study, we select the benchmark-1998 DARPA data set <ref type="bibr">[23]</ref> as our experimental data. The data is provided by the 1998 DARPA Intrusion Detection System Evaluation Program, and it contains a large sample of computer attacks embedded in normal background traffic. TCPDUMP and BSM <ref type="bibr" target="#b26">[28]</ref> (Basic Security Module) audit data were collected on a simulation network that simulated the traffic of an air force local area network, the set consists of 7 weeks of training data and 2 weeks of testing data.</p><p>TCPDUMP contains data network packets travelling over communication nets, while BSM captures activities occurring on a host machine, based on the execution records of system calls by all processes launched by users. Most traces of attacks are revealed both in TCPDUMP and BSM audit data. In our study, BSM audit data from UNIX-based host machine (SUN Solaris OS) is selected as the subject for detecting anomalies. Based on the assumption that actions in the user space can not harm the security of the system and the security-related activities that can impact the system only happen when users request services from the kernel, BSM monitors the events related to the system security and records both the instructions executed by the processor in the user space and instructions executed in the system kernel. Actually, a full system call trace gives us overwhelming information, whereas the audit trial provides a limited abstraction of the same information, such information as memory allocation, internal semaphores, and consecutive files reads do not appear. And in fact, there is usually a straightforward mapping of audit events to system calls. BSM records the execution of system calls by all processes launched by users and it also contains other detailed information about events in the system, such as user and group login identification, file names with attributes and full path, command line arguments, return code, etc. In our study, we only use the names of system calls and ignore other attributes. Former studies <ref type="bibr" target="#b11">[12]</ref> showed that privileged processes in UNIX are a good level to focus on because exploitation of vulnerabilities in privileged process can give an intruder superuser status and thus commit further attacks, and the range of behaviors of privileged processes is limited compared to that of users. Therefore, we choose system calls executed by privileged processes rather than user profiles as the observable subject. Additionally, instead of establishing privileged process profiles by short sequences of system calls, we characterize the privileged processes using the frequencies of system calls. Due to the fact that the number of system calls is limited, and based on the assumption that intrusion detection can be considered as a binary categorization problem, models and methods from the text categorization domain can be employed in a straightforward manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Data model</head><p>When the connection is established between two hosts, several sessions are generated and then many processes are executed during the connection. The atomic element of our observation is system calls, which are executed by privilege programs. Using the text processing metaphor, each system call is treated as a 'word' and the set of system calls generated by a process is treated as the 'document' <ref type="bibr" target="#b19">[20]</ref>; all the training processes are treated as a set of documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Analysis of the original data model</head><p>Based on the analogy between program processes and documents, the simple frequency weighting method and tf-idf (term frequency inverse document frequency) weighting method can be applied to transfer a process into a vector. The simple model is established as follows:</p><p>Matrix AZa ij , the collection of processes from different sessions, and a ij is the weight of system call i in process j. f ij , the frequency of system call i in process j. N, the number of processes in the collection. M, the number of distinct system calls in the collection. n i , the number of times that system call i appears in the collection.</p><p>Thus, frequency weighting is defined as:</p><formula xml:id="formula_1">a ij Z f ij<label>(4)</label></formula><p>tf-idf weighting method is defined as:</p><formula xml:id="formula_2">a ij Z f ij ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi P M lZ1 f 2 lj q !log N n i<label>(5)</label></formula><p>Based on the data model, several text categorization methods were proposed <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b19">20]</ref> for intrusion detection. Although these methods are easy to implement and effective for detecting intrusive processes with satisfactory accuracy, they are still far from ready for application in real life because of their unacceptably high false alarm rate. Careful analysis discloses the causes of generating excessive false alters: first, a session is hastily labelled as intrusive once one of its processes is detected as an anomaly; in such cases, any misclassified process would cause the whole session to be misjudged as an intrusion without discriminating other processes from the same session. Second, the correlations between the processes are ignored. Since most of attacks leave their traces in several processes and sessions, isolating processes might lose some essential information and thus decreases the detection accuracy and generates high false alarm rate. Additionally, some necessary time information is ignored, the incoming processes are dealt with independently, and the training data set is not updated in time. Thus it cannot reflect current novel behavior in a timely fashion, leaving much space for intruders to commit attacks. With these problems in mind, we attempt to establish a new data model that considers all those aspects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">New data modeling</head><p>In <ref type="bibr" target="#b19">[20]</ref>, an incoming process (new document) was compared with the training processes (existing documents) after being transformed to a vector by weighting techniques, and then KNN was used to cluster the processes according to their distance, based on the assumption that processes with similar properties will cluster together in the vector space. The applied weighting techniques are traditional tf-idf and simple frequency weighting. Due to the limited number of system calls, dimensionality reduction techniques are unnecessary. When a connection is established between two hosts, several sessions or processes will be generated, in order to reflect the source specific differences, we add some session information (such as Source Machine or session ID, which can be regarded as the topic of documents) <ref type="bibr" target="#b2">[3]</ref>. Accordingly, the tf-idf model can be improved as follows: pf s;t ðqÞ represents the process p from session s at time t which includes system call q, and is updated according to the equation: pf s;t ðqÞ Z pf s;tK1 ðqÞ C pf s;P t ðqÞ <ref type="bibr" target="#b5">(6)</ref> where, pf P t ðqÞ denotes the process frequencies in the newly added set of processes P t . The process frequencies can be used to calculate weights for the system calls q in the process p. The model is based on the fact that different sessions include different processes, and various processes have various system calls, consequently it reflects sessionspecific differences. The same system call may have different weights because it belongs to different sessions.</p><p>To specify the Eq. ( <ref type="formula">6</ref>), the weight of the system call q in the processes p can be calculated as follows at time t:</p><formula xml:id="formula_3">w t ðq; pÞ Z ð1 C log 2 f ðq; pÞÞ !log 2 ðN t =n q Þ Z p<label>(7)</label></formula><p>where f ðq; pÞ, the frequency of system call q in the process p; N t is the number of processes in the current training set; n q is the number of processes that include system call q; Z p Z ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi P q2p w t ðq; pÞ 2 q is the 2-norm of vector p.</p><p>When calculating the weights of the system calls, we apply the session-specific pf s;q instead of pf q . Therefore, information about the session could be included in our method. If no training data is available at tZ0 for a specific session, we can set pf s;0 Z 0 for its all q or identify other similar sessions s 0 , that is, pf s;0 ðqÞZ P s 0 pf s 0 ;0 ðqÞ, which happens when an intrusion detector is trained online.</p><p>Additionally, based on the fact that the number of system calls in the various processes might differ, and inspired by the work reported in <ref type="bibr" target="#b11">[12]</ref>, we divide one process into several segments by a sliding window of fixed length u, which advances with a step s, and can be determined experimentally. Here we note that only the process with a length longer than u is divided into overlapping segments by the sliding window. Specifically, hP 1 ; P 2 ; .P w i0 hP 1 ; P 2 ; .P n i ½s; w, where hP i i 1%i%w is a sub-episode of hP i i 1%i%n , for a process with length l, mZ b lK w=sC 1 c segments can derive from it, and we assume that minimal occurrence of some attacks can be detected in ½P i ; P iCw . We only take this step if the length of the process is much longer than that of the others. After dividing, m segments from the same process are all transformed into vectors and treated as individual 'documents'.</p><p>In practice, normal processes and abnormal processes in the training data should be updated frequently for restraining false alarms and detecting novel attacks. Therefore, some time information should also be considered. Here, we apply a linear time model <ref type="bibr" target="#b28">[30]</ref>, which uses a time window on the historic data. We only consider the processes within the time window m:</p><formula xml:id="formula_4">N p Z ð1 K time=mÞN p<label>(8)</label></formula><p>The processes outside the window are not considered. Actually, at the beginning of the training, time window m should large enough to include all the processes; with the increase of the number of processes, m can be adjusted manually or experimentally.</p><p>A simple example is given here to illustrate the measures we proposed. Intrusive session Eject is a buffer overflow using an eject program on Solaris OS, which might lead to a status transition from a common user to a super user. The session consists of a series of processes:</p><p>telnetd-login-tcsh-quota-cat-mail-cat-gcc-cpp-cclas-ld-ejectexploit-pwd actually, in this session, only ejectexploit is the intrusive process, and if it executes successfully, an attack might happen. The process contains following system calls: The weight of the system calls in the session Eject are only considered in the collection of the processes from the same source host. If we set the sliding window at fixed length 50, and left system calls close, close, close, close, close, exit advance with step 5, we can derive another two processes from the current process.</p><p>The final potential countermeasure to minimize the false positive rate is to consider the causal relationship between different attack attempts. With such consideration, when a process is identified as intrusive, we do not immediately treat the session it belongs to as an intrusion. As described in <ref type="bibr" target="#b22">[24]</ref>, in a series of attacks in which the intruder launches earlier attacks to prepare for later ones, there are usually strong connections between the consequences of the earlier attacks and the prerequisites of the later ones, especially in 'stealthy' attacks with multi-stages. For instance, format, the buffer overflow using the fdformat UNIX system command leads to root shell, contains two stages: ftp over files and then chmod exploit files. Thus the correlation of the attacks is formulated as a connected DAG (directed acyclic graph), HGZ(N,E), in which the set N of nodes is a set of attacks, and for each pair of nodes n 1 ,n 2 2N, there is a edge from n 1 to n 2 in E iff n 1 prepares for n 2 . Therefore, the triple (fact, prerequisite, consequence) holds for an attack happen in the multi-session scenario. Based on this assumption, when an intrusive process is detected, its neighbor processes or sessions are also considered carefully instead of immediately labelling the entire session as intrusive. Suppose in a sequence of attacks, we have four intrusive sessions Ipsweep, Eject, Land, Pod. Ipsweep performs either a port sweep or ping on multiple host addresses, Land and Pod are Dos attacks. Assuming that Ipsweep prepares for Land and Eject, Eject prepares for Pod, the relationship correlated(Eject, HG)Zprecedent(Eject, HG)gsubsequent(Eject, HG) is intuitively shown in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>The intrusive session Eject is identified as an intrusion for the malicious process ejectexploit. Actually, when obviously malicious processes appear, such as formatexpolit, ffbexploit, ejectexploit, the session should be interrupted as soon as possible. However, some intrusive processes are not obvious enough; for example, the denial of service attack process table, which consists of abuse of a legal activity, can hardly be identified because of its normal individual process. In order to detect such attacks effectively, the correlation between neighboring processes within a time window T and the precedent attacks should also be considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Online training of support vector machines based on text processing model</head><p>Most of the available intrusion detection techniques were evaluated using a labelled high quality training data set, and the data set was unchanged once attained. However, in practice, training data is not readily available, and intrusion detectors must undergo frequent training for capturing novel attacks and adapting to changes in normal behaviors. After transforming ongoing processes into vectors based on the data model presented in the last section, we applied the effective binary classification method, support vector machine, to distinguish anomalies from normal activities. In this section, we first briefly introduce conventional SVM, RSVM, and One-class SVM that based on different assumptions, and then modify these methods by a general algorithm drawn from Online SVM. A theoretical analysis of the modified method is also given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Three SVMs with different assumptions</head><p>SVM is an approximate implementation of the Structure Risk Minimization principle based on statistical learning theory rather than the Empirical Risk Minimization method, in which the classification function is derived by minimizing the Mean Square Error over the training data set such that the maximum width of the margin between the classes can be achieved <ref type="bibr" target="#b3">[4]</ref>. In order to solve various problems effectively, several improved SVM such as Robust SVM <ref type="bibr" target="#b25">[27]</ref>, One-class SVM <ref type="bibr" target="#b24">[26]</ref>, Online SVM <ref type="bibr" target="#b16">[17]</ref> have been proposed. We give a brief mathematical description of these SVMs here; more detailed descriptions can be found in the corresponding reference.</p><p>Given a training sample: D l Z fx i ; y i g l iZ1 , x i is the ith input vector, x i 2R n , y i 2½C1;K1, l is the total number of input vectors and n is the dimension of the input space. Suppose the relation between x and y is yZ sgnðf ðxÞC 3Þ, where sgn(x)Z1, if xR0 and sgn(x)ZK1, if x!0, the task uncovering function f is called classification. SVC is a maximization (minimization) algorithm used to identify a set of linear separable hyperplanes in the feature space whose formula like f ðxÞZ hw; xiC b, and 2/kwk can be regarded as a canonical representation of the separating hyperplane. Maximization of the margin between the positive examples and negative examples can be transferred to the following problem: min 1 2 jjwjj 2 s:t: y i ðhw;</p><formula xml:id="formula_5">x i i C bÞR 1 c i; 8 &lt; :<label>(9)</label></formula><p>By applying the Lagrangian multiplier, the problem can be formulated as:</p><formula xml:id="formula_6">L p Z 1 2 jjwjj 2 K X l iZ1 b i y i ðhw; x i i C bÞ C X l iZ1 b i ;<label>(10)</label></formula><p>The dual objective function is given below and the optimization problem is:</p><formula xml:id="formula_7">min L D Z 1 2 X l iZ1 X l jZ1 b i b j y i y j hx i ; x j i K X l iZ1 b i s:t: X l iZ1 b i y i Z 0; b i R 0; c i 8 &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; :<label>(11)</label></formula><p>Above equations only describe linear separable SVMs, and the general dual objective function can be rewritten in a matrix form as follows <ref type="bibr" target="#b16">[17]</ref>:</p><formula xml:id="formula_8">L D Z 1 2 b T Kb K hc; bi; (<label>12</label></formula><formula xml:id="formula_9">)</formula><p>where c is an l!l vector, bZ fb 1 ; .; b l g and KZ{K ij }, K ij Z y i y j Kðx i ; x j Þ, while K(x i , x j ) is called kernel function, which can be selected such formulas as Kðx i ; x j ÞZ hx i ; x j i d or Kðx i ; x j ÞZ e jjx i Kx j jj=s . The feasible solution of Eq. ( <ref type="formula" target="#formula_7">11</ref>) should satisfy the KTT <ref type="bibr" target="#b3">[4]</ref> conditions as follows:</p><formula xml:id="formula_10">b i Z 05 y i f i O 1; 0! b i % C5 y i f i % 1; (<label>(13)</label></formula><p>The hyperplane f(x) can be expanded from the kernel as follows:</p><formula xml:id="formula_11">f ðxÞ Z sgn X i2SV b i y i Kðx; x i Þ C b ! :<label>(14)</label></formula><p>In order to solve the over-fitting problem of a soft margin SVM due to noisy training data, Robust SVM <ref type="bibr" target="#b25">[27]</ref> minimizes only the margin of the weight w instead of minimizing the margin and the sum of misclassification errors. The objective function can be written as following:</p><formula xml:id="formula_12">min L D Z 1 2 b T Kb K hc; qi s:t: X l iZ1 b i y i Z 0; b i R 0; c i; 8 &gt; &gt; &gt; &lt; &gt; &gt; &gt; :<label>(15)</label></formula><p>where qZhg,bi, gZ fg 1 ; .g l g, and g i Z 1K lD 2 ðx i ; x * y i Þ, lR0 is a pre-determined regularization parameter measuring the influence of averaged information(distance to the class center), and D 2 ðx i ; x * y i Þ represents the normalized distance between data point x i and the center of the corresponding classes, ðx * y i ; y i 2fC1;K1gÞ, in the feature space. The slack variable lD 2 ðx i ; x * y i Þ can be justified by considering it as part of the margin. Because of this term, the RSVM algorithm will have fewer support vectors and the decision boundary will be smoother.</p><p>Another adapted algorithm, called one-class SVM algorithm, identifies 'outliers' amongst positive examples and uses them as negative examples. After mapping between input data space X and high-dimensional feature space H via a kernel, origin is treated as the only member of the second class. Then 'relaxation parameters' is used to separate the point of the first class from the origin. As a comparison with the above algorithms, we can write the objective function as:</p><formula xml:id="formula_13">min L D Z 1 2 b T Kb s:t: 0% b i % 1 vl ; X l i b i Z 1; 8 &gt; &gt; &gt; &lt; &gt; &gt; &gt; :<label>(16)</label></formula><p>where v2(0,1) is a parameter that controls the trade-off between maximizing the margin from the origin and containing most of the data in the region generated by the hyperplane. The general decision function with kernel expansion is:</p><formula xml:id="formula_14">f ðxÞ Z sgn X l iZ1 b i kðx i ; xÞ K r ! :<label>(17)</label></formula><p>If a i meets the subject conditions, r can be recovered as:</p><formula xml:id="formula_15">r Z X l jZ1 b j kðx j ; x i Þ:<label>(18)</label></formula><p>Generally, two facts usually hold during the intrusion detection process. One is that training data is always mixed with noisy data, which thus decreases the capability of detectors to capture anomalies with high accuracy and increases the probability to generate false alarms. The second is that the number of anomalies is much smaller than that of normal activities, which thus motivate us to apply robust SVM and one-class SVM, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Modified SVMs for online training</head><p>The SVMs mentioned above are used for the classification of input data that are supplied and computed in batch. It is time consuming to classify a large data set and thus these SVMs cannot meet the demands of online applications, especially for intrusion detection, which needs periodical retraining. Online SVM <ref type="bibr" target="#b16">[17]</ref>, on the other hand, have input data supplied in sequence rather than in batch, and the experiments showed it has fewer support vectors and faster convergence than the conventional SVC.</p><p>Here we would modify SVMs we discussed in the last section using the method from OSVM.</p><p>As we know, in the original SVMs a batch of training data are extracted as vectors and classified by solving the quadratic programming problems Eqs. <ref type="bibr" target="#b12">(13,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17)</ref>. The number of elements determines the dimensionality of the vectors. A final hyperplane can be achieved after computing the objective functions. Now let us consider another case, that training data can not be acquired at one time or supplied in a sequence.</p><p>For supervised SVMs, i.e. conventional SVM and Robust SVM, we can give one example for each class, the hyperplane with a maximum margin for these two examples can be found by solving the objective function Eqs. <ref type="bibr" target="#b12">(13,</ref><ref type="bibr" target="#b15">16</ref>). When a new example becomes available, corresponding to the KKT conditions <ref type="bibr" target="#b3">[4]</ref>, two cases need to be considered, that is, whether or not the current optimal boundary can classify the new example correctly. If it can be classified, then the example is not a support vector, otherwise, a new hyperplane should be determined so that it can classify three examples. The new hyperplane can be found by minimizing the objective function with the SVs obtained from the current hyperplane and the new example. At the kth step, the set of SVs can be denoted as SV k , and the existing examples are fSx k i ; Sy k i g jSV k j iZ1 , respectively. The corresponding hyperplane is (conventional SVM):</p><formula xml:id="formula_16">f k ðxÞ Z sgn X jSV i j iZ1 b k i Sy k i Kðx; Sx k i Þ C b k ! :<label>(19)</label></formula><p>Once the hyperplane is updated, the KKT conditions are checked for all k examples, and the examples which violate the KKT conditions are fed to the algorithm as new examples. With reference to Online SVM <ref type="bibr" target="#b16">[17]</ref>, we rewrote a general algorithm for the three SVMs described above to improve the performance of their training phase:</p><p>Algorithm </p><formula xml:id="formula_17">; } if (jE k jZ jfx i ; y i jy i f k ðx i Þ violates the KKT con- ditions g k iZ1 jO 0){ E k be input next step as new elements; } } while (jE l jO0) {</formula><p>Minimize Eqs. <ref type="bibr" target="#b3">(4,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8)</ref> with W l Z SV l g E l to obtain an optimal boundary f l ; } } As described in the algorithm, we can give more than one example for each class (normal and anomaly) at first, that is, the process can start at any kth steps, thus some typical attacks can be kept, meanwhile the algorithm can learn to detect novel attacks. However, because of computational overhead, the number of SVs, n, for the existing examples should not be too large, otherwise, this algorithm can perform little better than the conventional training methods. Because of its unsupervised nature, One-class SVM only takes an original point and another normal behavior at its initial training stage for subsequent classification, while anomaly points are not necessary. Some other accelerated training algorithms <ref type="bibr" target="#b13">[14]</ref> and decomposition algorithms are also worth considering in order to speed up the training phase of SVMs. Prove of the convergence of those modified SVMs is shown in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Performance evaluation of proposed methods</head><p>In Section 3, we briefly described our data source. To evaluate our proposed methods, we reformulated the training data and testing data based on the benchmark data set. We apply our three modified SVMs to the selected data, and compare the results with those of the original algorithms. The data are provided in sequence to SVMs as our need instead of in batch as the raw data format. Furthermore, the modified SVMs are based on our proposed weighting model, while the original SVMs are based on original tf-idf weighting method. Actually, based on the same weighting method, original SVMs and modified SVMs can be compared, but we did not do that for it has little contribution to evaluate our new methods. The specific implementation procedure is shown in Fig. <ref type="figure">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Training data and testing data</head><p>According to the attributes of the data source, preprocessing of the DARPA data and feature(characteristics of system calls) extraction from those data sets are necessary before employing the data model and the techniques we proposed. Basic Security Module (BSM) audit data collected from a victim Solaris machine in a simulation network by DARPA Intrusion Detection System Evaluation System is used as the experiment data here, and only the name of system calls are considered; other attributes related to them are ignored. Each session, which consists of a number of processes, corresponds to a TCP/IP connection between two hosts, and each of them was labelled with numbers (session ID). A text categorization problem based on our weighting model is formulated, and the techniques Fig. <ref type="figure">2</ref>. Evaluation procedure of the proposed intrusion detectors.</p><p>we proposed in the previous section are applied to solve it. Any attacks or anomalies during the execution of processes attempted to detect them immediately, thus guaranteeing the intrusion detection in real time.</p><p>Actually, the 1998 DARPA data has been widely criticized for some hidden factors in it <ref type="bibr" target="#b21">[22]</ref>, which might have a direct effect on the quality of the evaluation results, and thus there is always the doubt the IDSs would work well in real environments with diverse and dynamic traffic backgrounds. Following reasons need to be pointed out for the application of this evaluation framework: † It is usually hard to accumulate substantial intrusion detection data due to personal privacy, considerable recourse costs, and long-term period, which is also the reason that there are only several ID benchmark datasets are available. † The existing 1998 DARPA data has been widely applied during past 6 years, its structure and attributes are well known in ID community, which thus greatly simplify the data pre-processing stage. † Although the construction of synthetic data is a possible evaluation approach, the results can not be compared with other methods that use different data sets, and hence undermine its credibility. † Although the amount of data is limited, after preprocessing and reformulation as experimental demands, it is general enough to evaluate our proposed methods, and actually, it is not such a good witness that can vindicate the merits of our methods adequately. On the other hand, however, similar with all the other methods, we cannot exclude the probability that our proposed algorithms tend to yield worse results under real conditions. In this sense, a real experimental prototype is desirable and helpful.</p><p>The benchmark data set provides 9 weeks audit data altogether (7 weeks are labelled training data, 2 weeks are unlabelled testing data). In addition, in order to compare our methods with KNN classifier, similar pre-processing steps of data as report in <ref type="bibr" target="#b19">[20]</ref> is carried out:</p><p>1. There are 5 out of 35 (7-week training) simulation days free of attacks; 4 out of these 5 days are picked arbitrarily as training data, the left 1 day data is taken as the normal part of testing data. 2. There are total 606 distinct processes drawn from more than 2000 sessions running on the victim Solaris machine during the selected four training days, all these processes are picked as the normal part of training data; There are total 40 attack instances (hidden in more than 55 sessions) in the 7-week training data, and 30 intrusive processes among those intrusive sessions (cover most of the attack types in the training data, such as 'eject, spy, ffb, ipsweep...') are selected as anomaly part of training data. 3. The left 1 day data in step 1 (3rd day of week 7th) contains 412 sessions (total 5285 processes), and all these processes are taken as the normal part of testing data (session information are included); 24 attacks (16 are known, 8 are novel) from 2-week DARPA testing data are taken as anomaly part of our testing data.</p><p>It is worth noting that an intrusive session may contain only a small part of intrusive processes or even only one, such as eject, format, ffb, spy and so on. Therefore, 55 intrusive sessions do not mean there are 55 attacks. In fact, there are 40 clear (components of the attacks are visible in BSM data) or stealthy (components of the attack in the audit data are hide by encryption, by spreading the attack over multiple sessions or by other techniques) attack instances included in more than 55 intrusive sessions, representing all types of attacks and intrusion scenarios in the 7-week training data.</p><p>To evaluate our proposed methods that are based on different assumptions, two data sets are formulated here; one is taken as clean data, and another is taken as noisy data. As above reformulation, details of the training and testing data for those two data sets are illustrated in Table <ref type="table" target="#tab_4">1</ref>. Note that training data of the noisy data set takes only 15 out of the original 30 intrusive processes as anomalies, and the remaining 15 intrusive processes are disguised as normal processes and incorporated into the truly normal ones. The reason we formulated noisy data set is to verify the performance of Robust SVM. While for One-class SVM, we only use normal training data (i.e. 606 normal processes). The testing data for clean data set and noisy data set are same.</p><p>According to our definition, when a process is determined to be intrusive, the session with which the process is associated is classified as an attack session, and each attack counts as one detection, even with multiple sessions (for those stealthy attacks). Detection accuracy is then calculated as the rate of detected attacks, and the false positive probability is defined as the rate of misclassified normal processes (these two terms are not rigorously symmetrical here). A drawback of intrusion detection using original SVMs is that, as time passes, the old hyperplane can no longer accurately distinguish normal from abnormal activities, thus the detection accuracy decreases dramatically with an increasing false positive rate. The obvious way to handle this concept drift <ref type="bibr" target="#b15">[16]</ref> is to periodically retrain the SVMs, therefore, training time is another important factor to consider. Because the running time of SVM is proportional to the number of support vectors (SVs), we prefer SVs rather than time counting to measure their performance. Additionally, we also have a comparative study on the performance between our proposed methods with that of existing method-KNN classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Results and discussion</head><p>We did experiments over clean training data and noisy training data respectively using the SVMs we presented above. All the SVMs were implemented with the RBF kernel function (i.e. Kðx i ; x j ÞZ e jjxiKxjjj=s ), and the best hyperplanes were obtained by varying the related regulation parameters (Table <ref type="table" target="#tab_5">2</ref>). Moreover, for our modified SVMs, training data were provided in a sequence, namely, normal processes and intrusive processes were mixed up and provided one by one, while for original SVMs and KNN, training data were provided in a batch. A comparative study were carried on the performance of various SVMs, in terms of detection accuracy, false positive rate, the number of support vectors and training time.</p><p>Although the Receiver Operating Characteristic (ROC) curve is a typical method for measuring the performance of an intrusion detection technique, it provides little insight into the performance that we intend to evaluate, and we did not employ it here because the multi-variable would make it unclear. Actually, we care most about two points in the ROC, that is, detection accuracy when false positive rate is zero and the false positive rate when detection accuracy is 100%. These two terms of three different SVMs and KNN are shown in Table <ref type="table" target="#tab_6">3</ref> by adjusting the related regulation parameters after training respectively.</p><p>Following conclusions therefore can be derived from the results that shown in Table <ref type="table" target="#tab_6">3</ref>: † Online training did not cause the detection accuracy deterioration of SVMs; instead, new weighting method sometimes improved the detection performance. For example, original KNN cannot detect all the attacks hidden in testing set with noisy data (a DoS attack named process table cannot be detected due to its normal appearance), but it can do that with some false alerts using the new weighting method (considering the correlation between a particular time window). In addition, keeping zero false positive rate, a conventional SVM can detect 13 out of 24 attacks with clean training data (i.e. detection accuracy is 54.2%), while the modified SVM can detect 14 attacks; the modified RSVM and One-class SVM also had more hits than the original methods. † All the methods experienced performance deterioration with noisy training data (One-class SVM had no change because it was trained with only normal data). To get 100% hits, the conventional SVM misclassified 12.3% of normal processes as intrusive ones with clean training data, while with noisy data, the conventional SVM could not detect all the intrusive processes until all the normal processes were misclassified as intrusive ones, indicating that conventional SVM has no ability to suppress the effect brought by noisy samples, neither does KNN. † Compared with the conventional SVM, Robust SVM showed a slight decline of performance in the presence of noise, and were able to reach 100% detection accuracy while maintaining a low false positive rate.</p><p>Furthermore, as we mentioned above, intrusion detection systems usually require as low a false positive rate as possible due to the fact that too high false positive rate would make the systems ineffective. This is also the reason that most existing commercial IDSs prefer misuse ID techniques rather than anomaly ID techniques. To compare the performance of our proposed methods, the false positive rate was kept under 1% by regulating the parameters of  Another factor worth considering is the number of support vectors. As we know, SVC classify new examples by solving a quadratic programming problem, and the computational complexity of SVCs has a linear relationship to the number of SVs, therefore, SVMs with less SVs require less running time, which significantly benefits online intrusion detection. When we derived Table <ref type="table">4</ref>, we recorded the number of SVs of different SVMs, and as illustrated in Table <ref type="table" target="#tab_7">5</ref>, traditional SVM and RSVM had more support vectors over the clean training data than over the noisy training data because of the misclassified elements, and the number of SVs of our proposed methods was generally less than that of the original ones. Original One-class SVM selected 48 out of 606 normal processes as its SVs, while the modified one reduce the number of SVs to 34. Unlike SVMs, KNN has to calculate the similarity distance between the ongoing process and all the processes in the training data (the size is usually huge in practice), in order to guarantee a high detection accuracy, which thus increase its running time and response time heavily.</p><p>Besides the detection accuracy and support vectors, another aspect that must be addressed is the training time of intrusion detectors. Available intrusion detection approaches rely too strongly on the assumption that high quality labelled training data can be readily obtained, which undermines their efficiency and limits their application. An ideal IDs should be trainable with any provided data, even online. Therefore, the ability to achieve satisfied detection accuracy during as short a certain training time as possible is very important for an IDS that works online. Table <ref type="table" target="#tab_8">6</ref> shows the ratio of the training time for original SVMs to the modified method with clean data and noisy data respectively.</p><p>The training time for the modified SVMs was much less than for the original ones; RSVM and One-class SVM need more training time than conventional SVM in order to get high detection accuracy with a false positive rate less than 1%. The training time for modified SVMs represents an average performance over 50 trials, and it greatly depends on the distribution of the SVs in the training sequence. During the experiment, we found that the modified algorithms converge faster to the optimal boundary if the SVs are provided to the algorithms earlier than the in other examples. However, modified algorithms deteriorated severely when abnormal points were provided after most of the normal points had been supplied, due to the sudden change of the nature of boundaries. Under such conditions, the modified algorithms perform narrowly better than the original algorithms. In our experiment, the fastest trial only takes 8.3 s, when the normal processes and anomaly processes were provided alternately during the initial training phase, in contrast to the worst trial, which takes 223.3 s, when some anomaly processes were supplied suddenly at the end of training stage, so we averaged the performance over 50 trials for comparison with the original algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and future work</head><p>In this paper, intrusion detection was formulated as a text processing problem. Aiming to lower the high false positive rate, and based on the special characteristics of the observable subjects-system calls in privileged processes, we use a modified tf-idf text processing model with considering the time information and the correlation between the processes, the pre-requisites and consequences of the attacks, etc. In addition, we modified traditional SVM, RSVM and One-class SVM respectively, based on the method from OSVM. The preliminary experiments with the 1998 DARPA BSM audit data showed that our modified algorithms outperform conventional SVMs in terms of the number of support vectors and amount of required training time while keeping comparable detection accuracy. Specifically, the running time of the modified algorithms can be greatly reduced because of the fewer support vectors, and significant training time can be saved by the effective decomposition of the original algorithms for faster convergence. Both of these two aspects are essential to the design of an satisfactory online IDS. One significant discovery is that the modified One-class SVM can be trained online with unlabelled data sets because of its unsupervised nature, which contradicts the strong assumption that most existing methods are based on. It also inspires us to undertake further research about the application of online training with related effective unsupervised learning methods for intrusion detection, such as incremental learning methods. Although there may still be some reasons to doubt the performance of our proposed methods in practice, actually, we cannot exclude causes from the limited sample of the experiment data. Moreover, we can conclude that the characterization of the observable subjects is more important than the specific method, so the effective description of the subjects is more meaningful for improving the performance of intrusion detection that uses text processing techniques. The following aspects are worth further consideration: † Collecting more random samples particularly of intrusions from real environments, to evaluate our method. Some effective evaluation methods that offer insight into the mechanisms of anomaly detectors are worth further exploration, rather than just tallying detection accuracy with false positive rates using benchmark datasets. † Comparing our method with other intrusion detection techniques from machine learning and pattern recognition. † Some other effective incremental learning algorithms are worth consideration, for the realtime intrusion detection, and the capture of drifting system normality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Convergence of the modified SVMs</head><p>The convergence of the modified conventional SVM has been proved in Ref. <ref type="bibr" target="#b16">[17]</ref> by comparing it with the decomposition algorithm (DA). Here we only prove the convergence of modified Robust SVM and modified Oneclass SVM. As we know, the main idea of DA is that instead of immediately solving the large quadratic programming problem, small quadratic programming sub-problems are iteratively solved, and thus the iteration solution of the sub-problem brings the solution closer to the optimal solution. The training set is decomposed into two subsets, working subset B and correcting subset N. At each step, m elements exchange between the subset B and N. With the elements exchanged, the sub-problem involving the new working set is solved. The exchange between B and N repeats until no example violates the KKT conditions. Note that m is pre-determined as a constant, and the size of B and N are arbitrarily determined. The convergence of the DA for standard SVC and Robust SVC has been proved in Refs. <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b13">[14]</ref>, respectively. Similarly, the dual objective function Eq. ( <ref type="formula" target="#formula_14">17</ref>) of One-class SVM can be rewritten involving the working and correcting sets as follows: Proposition 2. Moving a variable that violates the KKT condition from N to B gives a strict improvement in the cost function when the sub-problem is re-optimized.</p><p>Proposition 1 means that the objective functions of SVMs can be decomposed by subset B and subset N, while the value of the cost function is unchanged. With Proposition 2, the solution of sub-problem is improved when an element violating the KKT conditions is moved from N to B. The difference between our modified SVMs and DAs is that modified SVMs keep SVs in the working subset and move the other elements to the correcting subset, and thus b N is a zero column vector. In addition, modified SVMs move at least one element, which violates the KKT conditions to the working subset at each step; the element can be either a new one just obtained or moved from the correcting set. Therefore, solving the sub-problem will make a improvement at each step. The following corollary given by Lau et al. <ref type="bibr" target="#b16">[17]</ref> shows that keeping the SVs in the working set will not affect the optimal solution, and we attempt to prove that it also holds for both Robust SVM and One-class SVM.</p><p>Corollary. Moving an element which is not an SV from B to N leaves the cost function unchanged and the solution is feasible in the sub-problem.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Attacks correlation graph.</figDesc><graphic coords="7,163.73,71.22,276.11,64.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>:Proposition 1 .</head><label>1</label><figDesc>b B C b T B K BN b N C b T N K NB b B C b T N K NN b N s:t: 0% b B % 1 vl ; b B C b N Z 1:All the DA of these different SVMs are based on the following two propositions. Moving a variable from B to N leaves the cost function unchanged, and the solution is feasible in the sub-problem.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>term frequency inverse document frequency) weighting model in text categorization might cause high false alarm rate in anomaly detection, a new weighting model based on the tf-idf method is established; this new model considers the special information between different processes and sessions of computer audit data. † Based on the assumption that training data are noisy (normal data are mixed up with anomalies or errors we do not expect), Robust SVM [27] is employed to discriminate anomalies and normal activities. Based on the assumption that anomalies in training data are hard to attain and the number of anomalies is much smaller than that of normal activities. One-class SVM [26] is applied to identify the few anomalies from training data. † Rejecting the assumption that high quality labelled training data is always readily available, and based on the fact that training data should be frequently updated to adapt the new normal regularity, Robust SVM and Oneclass SVM are modified based on the idea from Online SVM</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Thus it is easy to find that the performance of IDs is related directly with the value of PrfHðtÞZ 1jO t ; SetðO t ; wÞ; tg, and it increases with the value of c. Based on the equation, a simple intrusion detection model can be defined as:</figDesc><table><row><cell cols="4">property (sequential property) and frequency property. We</cell></row><row><cell cols="4">can cast those IDs in a statistical framework to analyze those</cell></row><row><cell cols="2">two properties.</cell><cell></cell></row><row><cell cols="2">Notations:</cell><cell></cell></row><row><cell cols="4">H(t): a hidden stochastic process which maps the</cell></row><row><cell cols="4">activities of legitimate users and attackers to a finite space</cell></row><row><cell cols="4">S in terms of discrete time step t; at time step t, if H(t)Z0,</cell></row><row><cell cols="4">means legitimate user traces is generated, if H(t)Z1, means</cell></row><row><cell cols="4">attacker traces is generated, and it is transparent to the</cell></row><row><cell cols="2">intrusion detectors.</cell><cell></cell></row><row><cell cols="4">h(x): a hidden stochastic process for generating event x.</cell></row><row><cell cols="4">O t : an observable subject that is captured at time step t, it</cell></row><row><cell cols="4">can represent a single event or a group of events according</cell></row><row><cell cols="4">to the specific detection method, and its generation is</cell></row><row><cell cols="3">governed by the hidden process H;</cell></row><row><cell cols="4">Set (O t ,w): a set of available subjects O i (i depends on the</cell></row><row><cell cols="4">specific anomaly detection model) with window u at time</cell></row><row><cell>step t.</cell><cell></cell><cell></cell></row><row><cell cols="4">N(t): a legitimate stochastic process that is generated at</cell></row><row><cell cols="2">time unit t, i.e. H(t)Z0;</cell><cell></cell></row><row><cell cols="4">M(t): a malicious stochastic process that is generated at</cell></row><row><cell cols="2">time unit t, i.e. H(t)Z1;</cell><cell></cell></row><row><cell cols="4">What a ID cares is the current observation O t , a pair of</cell></row><row><cell cols="4">probability distribution therefore can be considered as</cell></row><row><cell>follows:</cell><cell></cell><cell></cell></row><row><cell cols="3">PrfO t jHðtÞ Z 1; O tK1 O tK2 .O 1 ; tg</cell></row><row><cell cols="3">PrfO t jHðtÞ Z 0; O tK1 O tK2 .O 1 ; tg</cell></row><row><cell cols="4">if we do not consider the specific property of the</cell></row><row><cell cols="4">observations fO tK1 O tK2 .O 1 g, the above two probability</cell></row><row><cell cols="3">distribution can be generalized as follows:</cell></row><row><cell cols="2">PrfO t jHðtÞ Z 1; SetðO t ; wÞ; tg;</cell><cell></cell></row><row><cell cols="2">PrfO t jHðtÞ Z 0; SetðO t ; wÞ; tg</cell><cell></cell></row><row><cell cols="4">in such case, a posterior probability of intrusion detection</cell></row><row><cell cols="2">can be given as:</cell><cell></cell></row><row><cell cols="2">PrfHðtÞ Z 1jO t ; SetðO t ; wÞ; tg</cell><cell></cell></row><row><cell>Z</cell><cell cols="2">PrfO t jHðtÞ Z 1; SetðO t ; wÞ; tgð1 K lÞ PrfO t ; SetðO t ; wÞ; tg</cell><cell>(1)</cell></row><row><cell cols="4">as PrfO t ; SetðO t ; wÞ; tgZ PrfO t jHðtÞZ 0; SetðO t ; wÞ; tglC</cell></row><row><cell cols="4">PrfO t jHðtÞZ 1; SetðO t ; wÞ; tgð1K lÞ, Eq. (1) can be simpli-</cell></row><row><cell>fied as:</cell><cell></cell><cell></cell></row><row><cell cols="2">PrfHðtÞ Z 1jO t ; SetðO t ; wÞ; tg Z</cell><cell>cð1 K lÞ cð1 K lÞ C l</cell><cell>(2)</cell></row><row><cell cols="4">where lZ PrfHðtÞZ 0; SetðO t ; wÞ; tg, represents a priori</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Existing IDs mainly focus on the ordering</cell></row></table><note><p>probability of the legitimate pattern which contains u consecutive events that has been generated by h(x), and an unknown constant c Z PrfO t jHðtÞ Z 1; SetðO t ; wÞ; tg PrfO t jHðtÞ Z 0; SetðO t ; wÞ; tg for Eq. (2), PrfHðtÞZ 1jO t ; SetðO t ; wÞ; tgO a iff cO al= ð1K aÞð1K lÞ.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>close, close, close, close, open, close, close, execve, open, mmap, open, mmap, mmap, munmap, mmap, close, open, mmap, mmap, munmap, mmap, mmap, close, open, mmap, mmap, munmap, mmap, close, open, mmap, close, open, mmap, mmap, munmap, mmap, close, close, munmap, pathdonf, stat, stat, open, close, open, open, joctl, lstat, lstat, close, close, close, close, close, exit</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell cols="2">Experiment data sets</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Clean data (processes)</cell><cell cols="2">Noisy data (processes)</cell></row><row><cell></cell><cell>Normal</cell><cell>Intrusive</cell><cell>Normal</cell><cell>Intrusive</cell></row><row><cell>Training</cell><cell>606</cell><cell>30</cell><cell>621</cell><cell>15</cell></row><row><cell>Testing</cell><cell>5285</cell><cell>24 attacks</cell><cell>5285</cell><cell>24 attacks</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2</head><label>2</label><figDesc>Regulation parameters of different methods</figDesc><table><row><cell>Methods</cell><cell>Regulation parameters</cell></row><row><cell>Traditional SVM</cell><cell>s, C</cell></row><row><cell>Robust SVM</cell><cell>s, l</cell></row><row><cell>One-class SVM</cell><cell>s, v</cell></row><row><cell>KNN</cell><cell>k, t</cell></row><row><cell>General parameters</cell><cell>sliding window wZ60, time window TZ10</cell></row><row><cell cols="2">t denotes the threshold of KNN, T is the number of consecutive processes</cell></row><row><cell cols="2">being considered, rather than the real time counting.</cell></row></table><note><p><p><p>*</p>One-class SVM denoted by Oc-SVM, due to the limited margin.</p>* The value is unchanged.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3</head><label>3</label><figDesc>Two samples of the experiments with training data (hits out of 24 attacks while no FA and False Alerts (FA) out of 5285 normal processes while 100% hit)</figDesc><table><row><cell></cell><cell>Methods</cell><cell>Hits (%)</cell><cell></cell><cell>FA (%)</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Clean</cell><cell>Noisy</cell><cell>Clean</cell><cell>Noisy</cell></row><row><cell>SVM</cell><cell>Original</cell><cell>54.2</cell><cell>58.3</cell><cell>12.3</cell><cell>-a</cell></row><row><cell></cell><cell>Modified</cell><cell>58.3</cell><cell>58.3</cell><cell>11.1</cell><cell>-a</cell></row><row><cell>RSVM</cell><cell>Original</cell><cell>70.8</cell><cell>50.0</cell><cell>3.8</cell><cell>8.7</cell></row><row><cell></cell><cell>Modified</cell><cell>70.8</cell><cell>54.2</cell><cell>3.8</cell><cell>8.7</cell></row><row><cell>KNN</cell><cell>Original</cell><cell>16.7</cell><cell>12.5</cell><cell>9.9</cell><cell>-a</cell></row><row><cell></cell><cell>Modified</cell><cell>20.8</cell><cell>12.5</cell><cell>9.9</cell><cell>11.1</cell></row><row><cell>One-class</cell><cell>Original</cell><cell>70.8</cell><cell>70.8 b</cell><cell>10.1</cell><cell>10.1 b</cell></row><row><cell>SVM</cell><cell>Modified</cell><cell>75.0</cell><cell>75.0 b</cell><cell>9.8</cell><cell>9.8 b</cell></row><row><cell cols="3">a The value is unavailable.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">b The value unchanged.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc>Comparison of the number of SVs over training data sets</figDesc><table><row><cell>Training data</cell><cell>Methods</cell><cell>SVM</cell><cell>RSVM</cell><cell>Oc-SVM</cell></row><row><cell>Clean data</cell><cell>Original</cell><cell>46</cell><cell>34</cell><cell>48</cell></row><row><cell></cell><cell>Modified</cell><cell>43</cell><cell>32</cell><cell>34</cell></row><row><cell>Noisy data</cell><cell>Original</cell><cell>41</cell><cell>19</cell><cell>48 *</cell></row><row><cell></cell><cell>Modified</cell><cell>36</cell><cell>19</cell><cell>34 *</cell></row><row><cell cols="2">* The value is unchanged.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6</head><label>6</label><figDesc>Ratio of the training time for the modified SVMs/original</figDesc><table><row><cell>Training data</cell><cell>SVM (%)</cell><cell>RSVM (%)</cell><cell>One-class SVM (%)</cell></row><row><cell>Clean data</cell><cell>56.01</cell><cell>51.61</cell><cell>59.40</cell></row><row><cell>Noisy data</cell><cell>65.12</cell><cell>66.67</cell><cell>60.20</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Z. Zhang, H. Shen / Computer Communications 28 (2005) 1428-1442</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research is conducted as a program for the 'Fostering Talent in Emergent Research Fields' in Special Coordination Funds for Promoting Science and Technology by Ministry of Education, Culture, Sports, Science and Technology.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Proof. Suppose B 0 Z BK fmg; N 0 Z N g fmg; fmg 2BK SV, where'-'denotes set substraction, m represents an element which is not SV.</p><p>(1) For robust SVM, we have</p><p>The optimization problem can be formulated as follows:</p><p>(2) Similarly, for One-class SVM, we have</p><p>The optimization problem can be formulated as follows:</p><p>From Proposition 1, we know that the objective function</p><p>We note that N 0 does not contain any SV. Hence, b N 0 Z 0, for its elements are not SVs, and thus L D ðb B ; 0ÞZ L D ðb B 0 ; 0Þ, where 0 is a column vector whose all elements are 0. In addition, we have b T B y B Z b T B 0 y B 0 Z 0 and the bound constraints of robust SVM are unaffected, and obviously, the bound constraints of one class SVM are unaffected also. Therefore, both the sub-problem of Robust SVM and One-class SVM have the same solution with their corresponding proposed algorithms which modify Proposition 1 but keep CProposition 2 of the DA.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A new intrusion detection method based on discriminant analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Asaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Onabuta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Okazawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEICE Transactions of Information and Systems E</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The base-rate fallacy and the difficulty of intrusion detection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Axelsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information and System Security</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="186" to="205" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Brants</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farahat</surname></persName>
		</author>
		<title level="m">A system for new event detection, SIGIR&apos;03</title>
		<meeting><address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-08-01">July 28-August 1, 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A tutorial on support vector machines for pattern recognition</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="121" to="167" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The analysis of decomposition methods for support vector machines</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1003" to="1008" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A performance comparison of different back propagation neural networks methods in computer network intrusion detection</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N P</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Vemuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Differential Equations and Dynamical Systems</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1&amp;2</biblScope>
			<biblScope unit="page" from="201" to="221" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A geometric framework for unsupervised anomaly detection: detecting intrusions in unlabeled data, Applications of Data Mining in Computer Security</title>
		<author>
			<persName><forename type="first">E</forename><surname>Eskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Prerau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Portnoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stolfo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Kluwer, Dordecht</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A sense of self for UNIX processes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Forrest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Hofmeyr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Longstaff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1996 IEEE Symposium on Security and Privacy</title>
		<meeting>1996 IEEE Symposium on Security and Privacy<address><addrLine>Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fusion of multiple classifiers for intrusion detection in computer networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Giacinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Roli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Didaci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1795" to="1803" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">em Learning program behavior profiles for intrusion detection</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schwartbard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Shatz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of First USENIX Workshop on Intrusion Detection and Network Monitoring</title>
		<meeting>First USENIX Workshop on Intrusion Detection and Network Monitoring<address><addrLine>Santa Clara, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="51" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Statistical foundations of audit trail analysis for the detection of computer misuse</title>
		<author>
			<persName><forename type="first">P</forename><surname>Helman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liepins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Intrusion detection using sequences of system calls</title>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">A</forename><surname>Hofmeyr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Forrest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Somayaji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Security</title>
		<imprint>
			<biblScope unit="page" from="151" to="180" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Robust support vector machines for anomaly detection in computer security</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Rao</forename><surname>Vemuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2003 International Conference on Machine Learning and Applications (ICMLA&apos;03)</title>
		<meeting><address><addrLine>Los Angeles, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An accelerated training algorithm for robust support vector machine</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The neural network models for IDS based on the asymmetric costs of false negative errors and false positive errors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="69" to="75" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Klinkenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Joachims</surname></persName>
		</author>
		<title level="m">Proceedings of ICML-00, 17th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Langley</surname></persName>
		</editor>
		<meeting>ICML-00, 17th International Conference on Machine Learning<address><addrLine>San Francisco, US; Stanford, US</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="487" to="494" />
		</imprint>
	</monogr>
	<note>Detecting concept drift with support vector machines in</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Online training of support vector classifier</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">H</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1913" to="1920" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A framework for constructing features and models for intrusion detection systems</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Stolfo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information and System Security</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="227" to="261" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mining audit data to build intrusion detection models</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Stolfo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Mok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the Fourth International Conference on Knowledge Discovery and Data Mining<address><addrLine>Menlo Park, CA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="66" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Use of K-nearest neighbor classifier for intrusion detection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Vemuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and Security</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="439" to="448" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Anomaly-based intrusion detection: privacy concern and other problems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Lundin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jonhsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Networks</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="623" to="640" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Testing intrusion detection systems: a critique of the 1998 and 1999 DARPA intrusion detection system evaluations as performed by Lincoln Laboratory</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mchugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information and System Security</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="262" to="294" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Constructing Attacks Scenarios through Correlation of Intrusion Alters, CCS&apos;02</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Reeves</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">November 18-22, 2002</date>
			<pubPlace>Washington, DC, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An Application of support vector machines to anomaly detection</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Viet</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Research in Computer Science-Support Vector Machine</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Estimating the support of a high-dimensional distribution</title>
		<author>
			<persName><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1443" to="1471" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Robust support vector machine for bullet hole image classification</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics Part C</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="440" to="448" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m">SunShield Basic Security Module Guide</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>Sun Microsystems</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Detecting intrusion detection using system calls: alternative data models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Warrender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Forrest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pearlmutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Symposium on Security and Privacy</title>
		<meeting>IEEE Symposium on Security and Privacy</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="133" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A study on retrospective and on-line event detection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pierce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carebonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of SIGIR-98</title>
		<meeting>eeding of SIGIR-98<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Probabilistic techniques for intrusion detection based on computer audit data</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Masum Emran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multivariate statistical analysis of audit trails for host-based intrusion detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Masum Emran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vilber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">First-order versus high-order stochastic models for computer intrusion detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ehiabor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quality and Reliability Engineering International</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="243" to="250" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
