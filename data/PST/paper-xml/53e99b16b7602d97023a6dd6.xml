<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Stud krill herd algorithm</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013-10-17">17 October 2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Gai-Ge</forename><surname>Wang</surname></persName>
							<email>gaigewang@163.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Jiangsu Normal University</orgName>
								<address>
									<postCode>221116</postCode>
									<settlement>Xuzhou</settlement>
									<region>Jiangsu</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Amir</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
							<email>a.h.gandomi@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Civil Engineering</orgName>
								<orgName type="institution">The University of Akron</orgName>
								<address>
									<postCode>44325</postCode>
									<settlement>Akron</settlement>
									<region>OH</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Amir</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
							<email>ah_alavi@hotmail.com</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Civil and Environmental Engineering</orgName>
								<orgName type="institution">Michigan State University</orgName>
								<address>
									<addrLine>Engineering Building</addrLine>
									<postCode>48824</postCode>
									<settlement>East Lansing</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Stud krill herd algorithm</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2013-10-17">17 October 2013</date>
						</imprint>
					</monogr>
					<idno type="MD5">1AB0651E60B001D69FB74A1D41FA414A</idno>
					<idno type="DOI">10.1016/j.neucom.2013.08.031</idno>
					<note type="submission">Received 31 January 2013 Received in revised form 17 June 2013 Accepted 27 August 2013 Communicated by Prof. D. Liu</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Global optimization problem Krill herd Stud genetic algorithm Stud selection and crossover operator Multimodal function</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recently, Gandomi and Alavi proposed a meta-heuristic optimization algorithm, called Krill Herd (KH), for global optimization [Gandomi AH, Alavi AH. Krill Herd: A New Bio-Inspired Optimization Algorithm. Communications in Nonlinear Science and Numerical Simulation, 17(12), 4831-4845, 2012.]. This paper represents an optimization method to global optimization using a novel variant of KH. This method is called the Stud Krill Herd (SKH). Similar to genetic reproduction mechanisms added to KH method, an updated genetic reproduction schemes, called stud selection and crossover (SSC) operator, is introduced into the KH during the krill updating process dealing with numerical optimization problems. The introduced SSC operator is originated from original Stud genetic algorithm. In SSC operator, the best krill, the Stud, provides its optimal information for all the other individuals in the population using general genetic operators instead of stochastic selection. This approach appears to be well capable of solving various functions. Several problems are used to test the SKH method. In addition, the influence of the different crossover types on convergence and performance is carefully studied. Experimental results indicate an instructive addition to the portfolio of swarm intelligence techniques.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In management, computing science, and artificial intelligence area, in essence, optimization is a selection of a vector that can make an optimal solution for the objective function <ref type="bibr" target="#b0">[1]</ref>. With the development of the science and technology, practical engineering optimization problems are becoming more and more complex. Usually, intelligent stochastic methods have been applied to deal with these complex problems. A familiar way for categorizing techniques is to explore the attribute of the methods, and these techniques can be primarily divided into two parts canonical methods, and stochastic methods. Canonical methods always follow the same optimization path. We can repeat the process of optimization and get the same final solutions if the optimization begins with the same initial condition <ref type="bibr" target="#b0">[1]</ref>. Contrary to the canonical methods, for modern stochastic methods, their behavior has some randomness at all times, and they have no rigorous step to follow. The process of optimization cannot be repeatable, and they would always follow new different optimization path. Eventually, this randomness leads to different solutions regardless of the initial value. However, in most cases, both of them can find the optimal solutions though they have slight difference. Recently, meta-heuristic search approaches perform effectively in dealing with nonlinear problems. In all meta-heuristic search techniques, much effort has been devoted to make an appropriate trade-off between the exploration and exploitation in searching for the optimal solutions <ref type="bibr" target="#b1">[2]</ref>.</p><p>A great many robust meta-heuristic search approaches that are inspired by nature have been designed to solve complicated engineering problems <ref type="bibr" target="#b2">[3]</ref>, like parameter estimation <ref type="bibr" target="#b3">[4]</ref>, system identification <ref type="bibr" target="#b4">[5]</ref>, education <ref type="bibr" target="#b5">[6]</ref>, and engineering optimization <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>. A vast majority of meta-heuristic approaches can always find optimal or sub-optimal solutions from a population of solutions. In the last two decades, many famous optimization techniques have been developed, like artificial bee colony (ABC) <ref type="bibr" target="#b8">[9]</ref>, genetic programming (GP) <ref type="bibr" target="#b9">[10]</ref>, ant colony optimization (ACO) <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>, differential evolution (DE) <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>, evolutionary strategy (ES) <ref type="bibr" target="#b14">[15]</ref>, bat algorithm (BA) <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>, charged system search (CSS) <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>, biogeography-based optimization (BBO) <ref type="bibr" target="#b19">[20]</ref>, harmony search (HS) <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>, cuckoo search (CS) <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>, particle swarm optimization (PSO) <ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref>, big bang-big crunch algorithm <ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref>, population-based incremental learning (PBIL) <ref type="bibr" target="#b31">[32]</ref> and Contents lists available at ScienceDirect journal homepage: www.elsevier.com/locate/neucom more recently, the KH algorithm <ref type="bibr" target="#b32">[33]</ref> that is based on the simulation of the swarm behavior of krill.</p><p>In 2012, a swarm intelligence approach, namely KH method <ref type="bibr" target="#b32">[33]</ref>, was firstly presented for the global optimization problem. The KH methodology draws its analogy from the herding behavior of krill individuals in nature. The objective function used in KH method is mostly decided by the least distances of the position of the food and the biggest swarm density. The position for each krill mostly covers three parts.</p><p>KH is an effective method in exploitation. However, on occasion, it may not escape some local best solutions in multimodal fitness landscape so that it cannot search globally well <ref type="bibr" target="#b2">[3]</ref>. For regular KH approach, the search relies fully on randomness; therefore, it cannot always converge rapidly.</p><p>In standard GA (genetic algorithm) <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref>, three genetic operators (selection, crossover and mutation) repeat until a termination condition is satisfied. To improve the performance of GA, a variety of GAs has been developed. One of the well-famous methods is Stud GA (SGA) <ref type="bibr" target="#b35">[36]</ref>. In SGA, instead of stochastic selection, the best individual, the Stud, provides its useful information for all the other individuals in the population by GA operators <ref type="bibr" target="#b35">[36]</ref>.</p><p>In this paper, an effective SKH method combining KH with SGA is proposed. The aim of SKH is to accelerate convergence speed. In the first stage of SKH, we utilize basic KH to choose an optimal promising solution set. Subsequently, for more accurate modeling of the krill behavior, inspired by SGA, an updated selection and crossover operation, called stud selection and crossover (SSC) operator, is added to the approach. The SSC operator is applied to fine-tune the chosen promising solution in order to enhance its reliability and robustness for global optimization. The added SSC operator updated the krill's position according to the roulette wheel selection. The crossover operation in SSC operator can help to avoid premature convergence in the early run phase, and refine the final solutions in the later. The proposed SKH method is verified on 22 benchmarks. Experimental results indicate that SKH performs more efficiently and robust than the KH, and other 11 optimization methods.</p><p>The mainframe of this paper is provided below. Section 2 and Section 3 describe the KH and SGA methods in brief, respectively. Our SKH approach is presented in Section 4. The superiority of the SKH method is verified by 22 benchmarks in Section 5. Finally, Section 6 summarizes all the work in the present work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">KH algorithm</head><p>KH <ref type="bibr" target="#b32">[33]</ref> is a new generic stochastic optimization approach for the global optimization problem. It is inspired by the krill swarms when hunting for the food and communicating with each other. The KH approach repeats the implementation of the three movements and follows search directions that enhance the objective function value. The time-relied position is mostly determined by three movements i. foraging action; ii. movement influenced by other krill; iii. physical diffusion.</p><p>Regular KH approach adopted the Lagrangian model <ref type="bibr" target="#b32">[33]</ref> as shown in the following expression:</p><formula xml:id="formula_0">dX i dt ¼ F i þ N i þ D i<label>ð1Þ</label></formula><p>where F i , N i , and D i denote the foraging motion, the motion influenced by other krill, and the physical diffusion of the krill i, respectively. The first motion F i covered two parts: the current food location and the information about the previous location. For the krill i, we formulated this motion below:</p><formula xml:id="formula_1">F i ¼ V f β i þ ω f F old i<label>ð2Þ</label></formula><p>where</p><formula xml:id="formula_2">β i ¼ β f ood i þ β best i<label>ð3Þ</label></formula><p>and V f is the foraging speed, ω f is the inertia weight of the foraging motion in (0,1) F old i is the last foraging motion. The direction led by the second movement N i , α i , is estimated by the three effects: target effect, local effect, and repulsive effect. For a krill i, it can be formulated below:</p><formula xml:id="formula_3">N new i ¼ N max α i þ ω n N old i<label>ð4Þ</label></formula><p>and N max is the maximum induced speed, ω n is the inertia weight of the second motion in (0,1) N old i is the last motion influenced by other krill.</p><p>For the ith krill, as a matter of fact, the physical diffusion is a random process. This motion includes two components: a maximum diffusion speed and an oriented vector. The expression of physical diffusion can be given below</p><formula xml:id="formula_4">D i ¼ D max δ<label>ð5Þ</label></formula><p>where D max is the maximum diffusion speed, and δ is the oriented vector whose values are random numbers between À 1 and 1.</p><p>According to the three above-analyzed actions, the time-relied position from time t to tþΔt can be formulated by the following equation:</p><formula xml:id="formula_5">X i ðt þ ΔtÞ ¼ X i ðtÞþΔt dX i dt<label>ð6Þ</label></formula><p>Most importantly, note that Δt is an important parameter and should be regulated in terms of the special real-life problem. The reason is that, to some extent, this parameter can be treated as a scale factor of the speed and features the variations of the global best attraction, and its value is of vital importance in determining the speed of the convergence and how the KH works. More details about regular KH approach and the three main moves can be referred as <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b32">33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Genetic algorithm and SGA</head><p>SGA is based on the simple genetic algorithm, therefore firstly a brief description of GA is provided in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Genetic algorithm</head><p>Genetic algorithm (GA) is a canonical stochastic meta-heuristic search method for the global optimization in a large search space. The genetic information is encoded as genome that is implemented in an uncommon way that permits asexual reproduction that leads to the offspring that are genetically the same with the parent. While sexual reproduction can exchange and re-order chromosomes, giving birth to offspring which include a hybridization of genetic information from all parents. This operation is frequently called crossover because the chromosomes crossover when swapping genetic information. To evade premature convergence, mutation is applied to increase the diversity of the population. A general GA procedure has the following moves: randomly initializing a population of candidate solutions, generating new offspring by genetic operators. The fitness of the newly generated solutions is approximately calculated and well-fitted selection scheme is then utilized to decide which solutions will be held into the next generation. This process is then repeated until a fixed number of generations is reached or some stop criterion is satisfied.</p><p>Genetic algorithms have been widely used since it is developed, and GA has proved to succeed in solving many benchmark and real-world engineering problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">SGA</head><p>A SGA <ref type="bibr" target="#b35">[36]</ref> is a type of GA that employs the optimal genome for crossover at each generation. The idea of SGA is to employ the optimal genome to mate with all others to generate new offspring <ref type="bibr" target="#b35">[36]</ref>. Here, SGA do not use stochastic selection. The SGA can be presented as follows <ref type="bibr" target="#b36">[37]</ref>: i. Initialize a population at random ii. Choose the optimal genome (the Stud) for mating. iii. Perform crossover. iv. Repeat until stopping criteria is satisfied.</p><p>The crossover operation is the heart of the SGA. In general, the SGA implements in terms of the following steps.</p><p>Shuffle two stud elements (selected randomly). Check the diversity according to the hamming distance between the shuffled stud and the current mate:</p><p>If diversity is bigger than a set threshold, perform crossover to generate one offspring, Else, mutate the current mate to generate the child <ref type="bibr" target="#b36">[37]</ref>. Repeat for all other mates <ref type="bibr" target="#b35">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">SKH</head><p>Because the search used in the regular KH method relies completely on randomness, the KH cannot always find the optimal solutions. In KH algorithm, adaptive genetic reproduction mechanisms have been introduced so as to improve its performance <ref type="bibr" target="#b32">[33]</ref>. Nevertheless, on occasion, KH may not be successful in advancing on better solutions on some high-dimensional complicated problems. Generally, the regular KH method is skillful at investigating the search space extensively and locating the area of global best solution, but it is poor at deciding solution in a greedy way <ref type="bibr" target="#b2">[3]</ref>. In the present study, in order to considerably advance the performance of KH, similar to adaptive genetic reproduction mechanisms <ref type="bibr" target="#b32">[33]</ref>, an updated genetic reproduction schemes, called stud selection and crossover (SSC) operator, is introduced into the KH approach to develop a SKH approach to optimize the benchmark functions. The introduced SSC operator is inspired by the prestigious SGA. That is, in this paper, the attribute of natural evolution is endowed with the original krill to give birth to a variant of super krill that is well capable of implementing the SSC operator. In SKH, the SSC operator is utilized to only take over the newly generating better solutions for each krill individual; while in KH, it is inclined to accept all the updated krill. The mainframe of SSC operator is given in Algorithm 1.</p><p>From Algorithm 1, we can see that SSC operator actually covers two minor operators: selection and crossover. Similar to SGA, the idea of the SSC operator is to employ the optimal krill (the Stud) to mate with all the other krill to generate the child krill in place of a not-sogood solution. Therefore, in essence no stochastic selection is used in SSC operator. In Algorithm 1, to begin with, the Stud, i.e., the optimal krill individual is chosen as the first parent. And then, another parent is selected to mate with the stud and create two children by roulette wheel selection. Note that we must make sure the study is not selected as the second parent. Next, using two selected parents, a novel krill X i' is generated by some kind of crossover (Crossover operator). The crossover operation is the heart of SSC operator. The quality of the newly generated offspring X i' (F i' ) is estimated by the objective function. If F i' oF i , we accept this newly generated krill individual X i' as X iþ 1 in the next generation. Otherwise, the timerelated position of the krill in the search space is updated by Eq. ( <ref type="formula" target="#formula_5">6</ref>) as new solution X iþ 1 in the next generation. This is so quite greedy selection strategy that it can allow the whole population proceed to better solutions and not worsen the population all the time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1. Stud selection and crossover (SSC) operator</head><p>Begin Perform selection operator Choose the best krill (the Stud) for mating. Implement crossover operator Generate new krill X i' by crossover. Evaluate its quality/fitness F i' . if (F i' oF i ) then do</p><p>Accept the new generated solution X i' as</p><formula xml:id="formula_6">X i þ 1 else</formula><p>Update the krill by Eq. ( <ref type="formula" target="#formula_5">6</ref>)</p><formula xml:id="formula_7">as X i þ 1 end if End.</formula><p>In SKH, to begin with, the regular KH approach is applied to reduce the search area to a more promising area. Whereafter, the novel SSC operator that is a good greedy strategy is utilized to only take over improved solutions to better the quality of the solutions. Through this way, the proposed SKH approach can search the whole space extensively by basic KH method and extract useful information by SSC operator. Both good exploration of the regular KH method and the extraordinary exploitation ability of the SSC operator can be completely exerted. In fact, based on the figuration of SKH, the regular KH in SKH emphasizes the global search at the start of the process to escape from local solutions; while subsequently SSC operator inspires the local search in the search space at the later run phase of the process. Therefore, through this effective mechanism, the proposed SKH method can take full use of the extensive exploration of the KH and combat with the weak local search of the basic KH approach. Comparing with other optimization approaches, this could be an advantage for this approach as we can see in the simulations below. Most importantly, this method can further settle the serious conflict between exploration and exploitation efficiently.</p><p>By merging above-analyzed SSC operator together with regular KH method, the SKH has been developed, and the mainframe of the SKH can be described in Algorithm 2. Here, NP is the size of the parent population P.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2. SKH algorithm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Begin</head><p>Step 1: Initialization. Set The Generation Counter t ¼1; initialize the population P of NP krill; set the foraging speed V f , the maximum diffusion speed D max , and the maximum induced speed N max ; a probability of crossover p c .</p><p>Step 2: Evaluating population. Evaluate the krill population based on its position.</p><p>Step 3: While t oMaxGeneration do Sort all the krill according to their fitness.</p><p>for i¼ 1:NP (all krill) do Perform the three motions.</p><p>Update position for krill i by SSC operator in Algorithm 1.</p><p>Evaluate each krill based on its new position X i þ 1 . end for i Sort all the krill and find the current best. t ¼tþ 1;</p><p>Step 4: end while Step 5: Output the best solutions. End.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Simulation experiments</head><p>Here, a wide selection of benchmarks was utilized to investigate the effectiveness of the SKH. All the benchmarks were collected from previous researches that studied various aspects of optimization using stochastic optimization techniques. These benchmarks are given in Table <ref type="table" target="#tab_0">1</ref>. More detailed knowledge about all the benchmarks can be found in <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">The performance of SKH</head><p>In order to investigate the performance of SKH, it was compared with eleven meta-heuristic methods that are ABC <ref type="bibr" target="#b8">[9]</ref>, ACO <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b39">40]</ref>, BBO <ref type="bibr" target="#b19">[20]</ref>, DE <ref type="bibr" target="#b12">[13]</ref>, ES <ref type="bibr" target="#b14">[15]</ref>, GA <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref>, HS <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>, KH <ref type="bibr" target="#b32">[33]</ref>, PBIL <ref type="bibr" target="#b31">[32]</ref>, PSO <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b40">41]</ref>, and SGA <ref type="bibr" target="#b35">[36]</ref>. In addition, in <ref type="bibr" target="#b32">[33]</ref>, among all variants of KH method, the KH II significantly outperforms all other variants of KH method which testifies the robustness of the KH approach. Therefore, here we use KH II as basic KH method.</p><p>In the simulations below, we will use the unchanged parameters for KH, SGA, and SKH: the foraging speed V f ¼ 0.02, the maximum diffusion speed D max ¼0.005, the maximum induced speed N max ¼ 0.01, and a crossover probability of single point crossover p c ¼1 (only for SKH). (The reason why we select single point crossover is shown in Section 5.2). For ABC, ACO, BBO, DE, ES, GA, HS, PBIL, and PSO, we set the parameters as <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43]</ref>.</p><p>We ran 200 times for each method on each problem to achieve typical performances. The results of the simulations are shown in Tables <ref type="table" target="#tab_1">2</ref> and<ref type="table">3</ref>, which indicate the average and the best performance of each method. The optimal solution achieved by each method for each benchmark is marked in bold. In addition, different scales are used to normalize the results, so values cannot be comparative between them. The detailed normalization process can be found in <ref type="bibr" target="#b43">[44]</ref>.In our work, the number of the elements in all the methods is 30 (i.e., d ¼30).</p><p>From Table <ref type="table" target="#tab_1">2</ref>, on average, SKH is the most effective at finding objective function minimum on seventeen of the twenty-two benchmarks (F01, F02, F04-F07, F10-F15, and F17-F21). BBO is the second most effective, performing the best on the benchmarks F03, F16 and F22. DE ranks 3 and performs the best on the functions F08-F09. For the best solutions, Table <ref type="table">3</ref> shows that SKH performs the best on twenty of the twenty-two benchmarks which are F01-F02 and F04-F21. ACO and BBO are the second most effective, performing the best on the benchmark F22 and F03, respectively.</p><p>Besides, to look at the merits of the SKH approach in more detail, convergence plots of twelve methods are also given in our work. However, limited by the length of paper, only some most representative problems are provided in the Figs. <ref type="figure">1</ref><ref type="figure">2</ref><ref type="figure">3</ref><ref type="figure">4</ref><ref type="figure">5</ref>. The results are the average optimal objective function value obtained from 200 runs that the accurate function value, not normalized. We use KH short for KH II in the legend of following figures and next texts.</p><p>Fig. <ref type="figure">1</ref> illustrates that SKH is significantly superior to all the other approaches. For other approaches, SGA, BBO and KH rank 2, 3 and 4 eventually, while ABC, ACO, DE, ES, GA, HS, PBIL, PSO cannot find the global minimum after 50 generations. Furthermore, all the approaches start the optimization process from the same initial point; however SKH greatly outperforms all others shortly.</p><p>For this case, though converging slowly later, PSO find the best solutions initially among 12 methods; but, SKH overtakes it after 3 generations. On first glance, SKH can find the best function value for Powell function. Eventually, SGA, BBO and KH perform the second, third, and fourth best at finding the global optimal solution that converge more slowly than SKH.</p><p>Apparently, SKH converges the fastest and significantly outperforms all other approaches for this case. Here, all the approaches show the almost same starting point, however SKH outperforms the other algorithms in the whole optimization process. Carefully studying Table <ref type="table" target="#tab_1">2</ref> and Fig. <ref type="figure">3</ref>, SGA performs slightly better than BBO in this multimodal function, and both of them are inferior to the SKH and KH. Furthermore, ABC, ACO, DE, ES, GA, HS, PBIL, and PSO fail to find the satisfied solution under given conditions.</p><p>From Fig. <ref type="figure">4</ref>, it is apparent that, SKH is significantly superior to all others in the optimization process. Carefully studying Table <ref type="table" target="#tab_1">2</ref> and Fig. <ref type="figure">4</ref>, BBO, KH and SGA performs also well and rank 2, 3, and 4, respectively. All of them are inferior to the SKH method.</p><p>From Fig. <ref type="figure">5</ref>, SKH performs far better than other approaches in the optimization process for this problem. In addition, for other algorithm, SGA, BBO and KH perform very well and rank 2, 3 and 4, respectively.</p><p>From the Tables <ref type="table" target="#tab_1">2</ref> and<ref type="table">3</ref>, and Figs. <ref type="figure">1</ref><ref type="figure">2</ref><ref type="figure">3</ref><ref type="figure">4</ref><ref type="figure">5</ref>, we can conclude that our SKH approach greatly outperforms the other eleven optimization techniques. In most cases, BBO, KH and SGA are only inferior to SKH, and perform the second best among 12 approaches. At last, note that, BBO was compared with seven methods on 14 functions and an engineering problem <ref type="bibr" target="#b19">[20]</ref>. The experiments proved the robustness of BBO. Also, it is indirectly proven that our metaheuristic SKH approach is a more robust and efficient optimization approach than other meta-heuristic search methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Influence of different crossover types</head><p>In general, there are three different crossover types used in SGA, which are single point crossover, two point crossover, and uniform crossover. The choice of the crossover type is significant for all kinds of evolutionary algorithms to solve specific problems. To look at the effects among three crossover types, we implemented 200 simulations of SKH on the fourteen most representative test problems to achieve representative performances. The experimental results are recorded in Tables <ref type="table" target="#tab_2">4</ref> and<ref type="table" target="#tab_3">5</ref>. Tables <ref type="table" target="#tab_2">4</ref> and<ref type="table" target="#tab_3">5</ref> represent the optimal and mean performance of SKH approach, respectively. Here, single point crossover, two point crossover, and uniform crossover are used in SKH1, SKH2, and SKH3, respectively.</p><p>From Table <ref type="table" target="#tab_2">4</ref>, obviously, in most cases, for best solutions, it can be seen that SKH1 significantly outperforms SKH3 and SKH2 among three SKH methods. From Table <ref type="table" target="#tab_3">5</ref>, on average, it can be seen that SKH1 performs little better than SKH3; while SKH2 performs the worst among three SKH methods. In conclusion, SKH1 performs the best among three SKH methods. So, SKH1 is selected as basic SKH method in our experiments. The simulation experiments conducted in Section 5.1 and Section 5.2 show that our proposed SKH algorithm with single point crossover performed the best and most effectively when dealing with the global numerical optimization problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In the present work, the SSC operator has been introduced into the KH approach to propose an improved search approach, called SKH method, for optimization problems. In SKH, firstly, regular KH method is utilized to shrink the search area to a limited region. The SSC operator, containing selection and crossover operation, is applied to choose a good candidate solution in place of a notso-good solution in order to enhance its reliability and accurateness dealing with optimization problems. When solving the complicated problems, KH may not continue to proceed to better solutions at all times <ref type="bibr" target="#b32">[33]</ref>. Then, SSC operator is adaptively launched to re-start the search through crossover operator. With both techniques merged, SKH can balance exploration and exploitation and efficiently deal with complicated multimodal problems effectively. Furthermore, from the experimental results, we can arrive at a conclusion that the SKH considerably improves the accurateness of the global optimality and the quality of the solutions. However, similar to other meta-heuristics, SKH has a fixed limitation. We must fine-tune the control parameters every time according to specific real-life problem.</p><p>In function optimization, there are a variety of problems that still deserve further scrutiny, and many more robust optimization approaches should be developed aiming to the specific problem. The future work can be focused on the following problems. Firstly, the proposed SKH method may be applied to work out practical engineering optimization problems to prove its efficiency for dealing with real-world problems. Secondly, a newer  meta-heuristic search technique can be devised to solve more complicated optimization problems more efficiently. Thirdly, in the current work, we only proved the superiority of the SKH through numerical study. Thus, further mathematical analysis can be done using dynamic system, such as Markov chain, to prove and explain the convergence of the proposed method. Finally, there are various ways to evaluate the performance of the optimization algorithms. In this work, only the average and best values are studied against the number of generations. In future work, the performance of the SKH may be evaluated in other ways, such as their computational complexity in terms of flops of calculation, or the number of fitness function evaluations.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .Fig. 2 .Fig. 3 .Fig. 4 .Fig. 5 .</head><label>12345</label><figDesc>Fig. 1. Performance comparison for the F02 Dixon &amp; Price function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Gai-Ge Wang obtained his bachelor degree in computer science and technology from Yili Normal University, Yining, Xinjiang, China, in 2007. His masters was in the field of "Intelligent planning and planning recognition" at Northeast Normal University, Changchun, China. In 2010 he began working on his Ph.D. for developing target threat evaluation by employing computational intelligence techniques at Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences, Changchun, China. He is currently a researcher in School of Computer Science and Technology at Jiangsu Normal University, Xuzhou, China. Gai-Ge Wang has published over 20 journal papers and conference papers. His research interests are meta-heuristic optimization methods and its application in engineering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Benchmark functions.</figDesc><table><row><cell>ID</cell><cell>Name</cell><cell>ID</cell><cell>Name</cell><cell>ID</cell><cell>Name</cell><cell>ID</cell><cell>Name</cell></row><row><cell>F01</cell><cell>Ackley</cell><cell>F07</cell><cell>Penalty #2</cell><cell>F13</cell><cell>Rosenbrock</cell><cell>F19</cell><cell>Step</cell></row><row><cell>F02</cell><cell>Dixon and Price</cell><cell>F08</cell><cell>Perm #1</cell><cell>F14</cell><cell>Schwefel 2.26</cell><cell>F20</cell><cell>Sum Squares</cell></row><row><cell>F03</cell><cell>Fletcher-Powell</cell><cell>F09</cell><cell>Perm #2</cell><cell>F15</cell><cell>Schwefel 1.2</cell><cell>F21</cell><cell>Trid</cell></row><row><cell>F04</cell><cell>Griewank</cell><cell>F10</cell><cell>Powell</cell><cell>F16</cell><cell>Schwefel 2.22</cell><cell>F22</cell><cell>Zakharov</cell></row><row><cell>F05</cell><cell>Levy</cell><cell>F11</cell><cell>Quartic</cell><cell>F17</cell><cell>Schwefel 2.21</cell><cell></cell><cell></cell></row><row><cell>F06</cell><cell>Penalty #1</cell><cell>F12</cell><cell>Rastrigin</cell><cell>F18</cell><cell>Sphere</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Mean normalized optimization results.</figDesc><table><row><cell></cell><cell>ABC</cell><cell>ACO</cell><cell>BBO</cell><cell>DE</cell><cell>ES</cell><cell>GA</cell><cell>HS</cell><cell>KH</cell><cell>PBIL</cell><cell>PSO</cell><cell>SGA</cell><cell>SKH</cell></row><row><cell>F01</cell><cell>10.26</cell><cell>10.28</cell><cell>6.22</cell><cell>9.64</cell><cell>11.67</cell><cell>10.88</cell><cell>11.89</cell><cell>3.31</cell><cell>11.95</cell><cell>10.28</cell><cell>7.11</cell><cell>1.00</cell></row><row><cell>F02</cell><cell>2.7E4</cell><cell>3.3E4</cell><cell>1.3E3</cell><cell>1.1E4</cell><cell>1.0E5</cell><cell>1.4E4</cell><cell>8.9E4</cell><cell>2.2E3</cell><cell>1.1E5</cell><cell>2.6E4</cell><cell>1.1E3</cell><cell>1.00</cell></row><row><cell>F03</cell><cell>3.06</cell><cell>8.63</cell><cell>1.00</cell><cell>4.01</cell><cell>8.70</cell><cell>5.01</cell><cell>8.22</cell><cell>3.87</cell><cell>8.03</cell><cell>7.44</cell><cell>1.25</cell><cell>7.54</cell></row><row><cell>F04</cell><cell>165.36</cell><cell>31.50</cell><cell>23.56</cell><cell>97.72</cell><cell>237.51</cell><cell>110.04</cell><cell>389.58</cell><cell>16.71</cell><cell>434.74</cell><cell>178.54</cell><cell>28.21</cell><cell>1.00</cell></row><row><cell>F05</cell><cell>8.36</cell><cell>13.21</cell><cell>1.56</cell><cell>10.23</cell><cell>25.37</cell><cell>10.49</cell><cell>23.85</cell><cell>3.49</cell><cell>29.06</cell><cell>14.10</cell><cell>1.53</cell><cell>1.00</cell></row><row><cell>F06</cell><cell>3.5E7</cell><cell>4.8E7</cell><cell>5.5E5</cell><cell>1.4E7</cell><cell>1.1E8</cell><cell>6.4E6</cell><cell>1.5E8</cell><cell>2.4E5</cell><cell>2.0E8</cell><cell>1.8E7</cell><cell>7.6E4</cell><cell>1.00</cell></row><row><cell>F07</cell><cell>2.0E6</cell><cell>8.0E6</cell><cell>6.5E4</cell><cell>8.1E5</cell><cell>6.5E6</cell><cell>5.5E5</cell><cell>8.8E6</cell><cell>4.1E4</cell><cell>1.1E7</cell><cell>1.6E6</cell><cell>2.2E4</cell><cell>1.00</cell></row><row><cell>F08</cell><cell>1.3E5</cell><cell>4.4E4</cell><cell>2.8E5</cell><cell>1.00</cell><cell>107.21</cell><cell>7.8E3</cell><cell>23.48</cell><cell>5.4E4</cell><cell>2.7E3</cell><cell>500.37</cell><cell>3.1E3</cell><cell>267.90</cell></row><row><cell>F09</cell><cell>2.3E4</cell><cell>2.1E4</cell><cell>9.8E4</cell><cell>1.00</cell><cell>27.10</cell><cell>2.1E3</cell><cell>6.49</cell><cell>1.7E4</cell><cell>1.2E3</cell><cell>64.82</cell><cell>2.1E3</cell><cell>1.7E3</cell></row><row><cell>F10</cell><cell>692.72</cell><cell>2.0E3</cell><cell>171.68</cell><cell>1.1E3</cell><cell>2.7E3</cell><cell>575.38</cell><cell>2.1E3</cell><cell>346.61</cell><cell>2.2E3</cell><cell>875.41</cell><cell>62.12</cell><cell>1.00</cell></row><row><cell>F11</cell><cell>2.0E4</cell><cell>2.3E4</cell><cell>965.60</cell><cell>8.7E3</cell><cell>7.4E4</cell><cell>9.5E3</cell><cell>7.1E4</cell><cell>1.5E3</cell><cell>8.8E4</cell><cell>1.9E4</cell><cell>781.75</cell><cell>1.00</cell></row><row><cell>F12</cell><cell>3.46</cell><cell>5.96</cell><cell>1.30</cell><cell>4.82</cell><cell>6.47</cell><cell>5.18</cell><cell>6.33</cell><cell>3.05</cell><cell>6.52</cell><cell>4.90</cell><cell>2.28</cell><cell>1.00</cell></row><row><cell>F13</cell><cell>26.93</cell><cell>117.65</cell><cell>5.42</cell><cell>22.22</cell><cell>118.90</cell><cell>39.11</cell><cell>86.60</cell><cell>6.40</cell><cell>102.62</cell><cell>30.06</cell><cell>6.98</cell><cell>1.00</cell></row><row><cell>F14</cell><cell>146.62</cell><cell>99.66</cell><cell>55.76</cell><cell>175.20</cell><cell>199.75</cell><cell>88.94</cell><cell>231.32</cell><cell>160.91</cell><cell>238.14</cell><cell>236.25</cell><cell>76.49</cell><cell>1.00</cell></row><row><cell>F15</cell><cell>9.22</cell><cell>8.71</cell><cell>5.67</cell><cell>12.23</cell><cell>12.72</cell><cell>8.77</cell><cell>11.78</cell><cell>6.56</cell><cell>12.50</cell><cell>9.40</cell><cell>8.05</cell><cell>1.00</cell></row><row><cell>F16</cell><cell>3.12</cell><cell>5.72</cell><cell>1.00</cell><cell>3.49</cell><cell>7.85</cell><cell>4.38</cell><cell>6.39</cell><cell>3.30</cell><cell>6.34</cell><cell>7.99</cell><cell>1.73</cell><cell>2.40</cell></row><row><cell>F17</cell><cell>19.39</cell><cell>12.66</cell><cell>14.61</cell><cell>18.56</cell><cell>18.26</cell><cell>15.63</cell><cell>18.68</cell><cell>3.26</cell><cell>19.28</cell><cell>19.83</cell><cell>13.21</cell><cell>1.00</cell></row><row><cell>F18</cell><cell>2.0E3</cell><cell>3.8E3</cell><cell>313.40</cell><cell>1.2E3</cell><cell>5.5E3</cell><cell>2.8E3</cell><cell>4.9E3</cell><cell>238.67</cell><cell>5.8E3</cell><cell>2.2E3</cell><cell>491.27</cell><cell>1.00</cell></row><row><cell>F19</cell><cell>267.55</cell><cell>110.10</cell><cell>41.08</cell><cell>169.54</cell><cell>534.58</cell><cell>216.13</cell><cell>681.77</cell><cell>25.64</cell><cell>757.85</cell><cell>288.55</cell><cell>45.87</cell><cell>1.00</cell></row><row><cell>F20</cell><cell>127.08</cell><cell>201.70</cell><cell>20.00</cell><cell>72.14</cell><cell>320.50</cell><cell>106.34</cell><cell>303.46</cell><cell>22.17</cell><cell>361.85</cell><cell>112.56</cell><cell>24.81</cell><cell>1.00</cell></row><row><cell>F21</cell><cell>45.22</cell><cell>11.79</cell><cell>9.90</cell><cell>62.42</cell><cell>64.26</cell><cell>6.80</cell><cell>99.48</cell><cell>13.58</cell><cell>108.44</cell><cell>54.18</cell><cell>5.80</cell><cell>1.00</cell></row><row><cell>F22</cell><cell>1.42</cell><cell>1.8E6</cell><cell>1.00</cell><cell>1.82</cell><cell>2.09</cell><cell>1.54</cell><cell>9.77</cell><cell>1.20</cell><cell>1.82</cell><cell>2.06</cell><cell>1.31</cell><cell>5.83</cell></row><row><cell>Total</cell><cell>0</cell><cell>0</cell><cell>3</cell><cell>2</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>17</cell></row><row><cell>Table 3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Best normalized optimization results.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>ABC</cell><cell>ACO</cell><cell>BBO</cell><cell>DE</cell><cell>ES</cell><cell>GA</cell><cell>HS</cell><cell>KH</cell><cell>PBIL</cell><cell>PSO</cell><cell>SGA</cell><cell>SKH</cell></row><row><cell>F01</cell><cell>231.31</cell><cell>223.86</cell><cell>123.44</cell><cell>207.13</cell><cell>268.93</cell><cell>227.34</cell><cell>281.00</cell><cell>43.98</cell><cell>281.40</cell><cell>232.66</cell><cell>141.42</cell><cell>1.00</cell></row><row><cell>F02</cell><cell>1.5E5</cell><cell>1.6E5</cell><cell>4.4E3</cell><cell>8.1E4</cell><cell>8.3E5</cell><cell>3.9E4</cell><cell>5.8E5</cell><cell>1.6E4</cell><cell>8.0E5</cell><cell>6.0E4</cell><cell>4.3E3</cell><cell>1.00</cell></row><row><cell>F03</cell><cell>4.13</cell><cell>13.78</cell><cell>1.00</cell><cell>6.88</cell><cell>14.64</cell><cell>6.13</cell><cell>14.56</cell><cell>6.91</cell><cell>11.09</cell><cell>11.41</cell><cell>1.54</cell><cell>6.18</cell></row><row><cell>F04</cell><cell>77.23</cell><cell>12.54</cell><cell>9.58</cell><cell>70.50</cell><cell>172.31</cell><cell>59.57</cell><cell>310.73</cell><cell>10.74</cell><cell>361.59</cell><cell>131.05</cell><cell>14.48</cell><cell>1.00</cell></row><row><cell>F05</cell><cell>1.8E3</cell><cell>2.6E3</cell><cell>351.34</cell><cell>1.6E3</cell><cell>5.4E3</cell><cell>2.1E3</cell><cell>6.1E3</cell><cell>574.29</cell><cell>6.2E3</cell><cell>3.1E3</cell><cell>288.87</cell><cell>1.00</cell></row><row><cell>F06</cell><cell>2.4E8</cell><cell>13.55</cell><cell>4.1E3</cell><cell>6.1E7</cell><cell>1.1E9</cell><cell>2.8E6</cell><cell>9.7E8</cell><cell>5.0E5</cell><cell>1.1E9</cell><cell>1.1E8</cell><cell>365.48</cell><cell>1.00</cell></row><row><cell>F07</cell><cell>1.5E9</cell><cell>59.28</cell><cell>1.5E7</cell><cell>8.8E8</cell><cell>6.7E9</cell><cell>2.1E8</cell><cell>1.1E10</cell><cell>3.1E7</cell><cell>1.0E10</cell><cell>1.3E9</cell><cell>2.3E5</cell><cell>1.00</cell></row><row><cell>F08</cell><cell>2.4E25</cell><cell>1.1E26</cell><cell>1.1E26</cell><cell>1.2E16</cell><cell>4.6E21</cell><cell>1.1E26</cell><cell>2.9E21</cell><cell>1.0E17</cell><cell>1.1E26</cell><cell>4.5E22</cell><cell>1.1E26</cell><cell>1.00</cell></row><row><cell>F09</cell><cell>1.9E24</cell><cell>1.1E26</cell><cell>1.1E26</cell><cell>1.7E16</cell><cell>2.8E21</cell><cell>1.1E26</cell><cell>8.2E19</cell><cell>3.6E7</cell><cell>1.1E26</cell><cell>1.3E22</cell><cell>1.1E26</cell><cell>1.00</cell></row><row><cell>F10</cell><cell>2.0E5</cell><cell>6.9E5</cell><cell>3.5E4</cell><cell>3.5E5</cell><cell>5.5E5</cell><cell>7.6E4</cell><cell>7.6E5</cell><cell>7.4E4</cell><cell>8.5E5</cell><cell>2.7E5</cell><cell>1.0E4</cell><cell>1.00</cell></row><row><cell>F11</cell><cell>4.4E10</cell><cell>3.6E10</cell><cell>1.5E9</cell><cell>1.6E10</cell><cell>2.6E11</cell><cell>1.3E10</cell><cell>2.8E11</cell><cell>3.4E9</cell><cell>4.0E11</cell><cell>4.1E10</cell><cell>6.3E8</cell><cell>1.00</cell></row><row><cell>F12</cell><cell>37.06</cell><cell>64.02</cell><cell>12.74</cell><cell>51.03</cell><cell>72.55</cell><cell>42.57</cell><cell>67.30</cell><cell>30.78</cell><cell>70.03</cell><cell>53.95</cell><cell>20.79</cell><cell>1.00</cell></row><row><cell>F13</cell><cell>17.02</cell><cell>149.42</cell><cell>7.46</cell><cell>24.02</cell><cell>136.09</cell><cell>33.64</cell><cell>99.20</cell><cell>7.52</cell><cell>116.68</cell><cell>21.37</cell><cell>7.05</cell><cell>1.00</cell></row><row><cell>F14</cell><cell>1.0E5</cell><cell>5.1E4</cell><cell>3.9E4</cell><cell>1.4E5</cell><cell>1.5E5</cell><cell>4.9E4</cell><cell>1.7E5</cell><cell>1.0E5</cell><cell>1.7E5</cell><cell>1.8E5</cell><cell>4.1E4</cell><cell>1.00</cell></row><row><cell>F15</cell><cell>33.33</cell><cell>20.25</cell><cell>15.65</cell><cell>35.98</cell><cell>45.97</cell><cell>22.46</cell><cell>41.91</cell><cell>20.88</cell><cell>43.24</cell><cell>32.03</cell><cell>14.60</cell><cell>1.00</cell></row><row><cell>F16</cell><cell>24.85</cell><cell>43.78</cell><cell>5.17</cell><cell>25.53</cell><cell>63.63</cell><cell>30.91</cell><cell>54.26</cell><cell>23.78</cell><cell>53.10</cell><cell>49.72</cell><cell>13.41</cell><cell>1.00</cell></row><row><cell>F17</cell><cell>222.33</cell><cell>127.28</cell><cell>157.51</cell><cell>209.73</cell><cell>217.83</cell><cell>126.95</cell><cell>235.66</cell><cell>26.34</cell><cell>235.76</cell><cell>206.09</cell><cell>115.19</cell><cell>1.00</cell></row><row><cell>F18</cell><cell>4.0E5</cell><cell>7.1E5</cell><cell>3.4E4</cell><cell>2.0E5</cell><cell>1.1E6</cell><cell>3.5E5</cell><cell>1.1E6</cell><cell>4.1E4</cell><cell>1.2E6</cell><cell>4.3E5</cell><cell>8.1E4</cell><cell>1.00</cell></row><row><cell>F19</cell><cell>1.1E4</cell><cell>4.3E3</cell><cell>1.3E3</cell><cell>7.8E3</cell><cell>2.6E4</cell><cell>5.7E3</cell><cell>3.9E4</cell><cell>1.2E3</cell><cell>4.2E4</cell><cell>1.5E4</cell><cell>1.1E3</cell><cell>1.00</cell></row><row><cell>F20</cell><cell>1.4E4</cell><cell>2.7E4</cell><cell>2.7E3</cell><cell>1.1E4</cell><cell>5.1E4</cell><cell>8.7E3</cell><cell>4.5E4</cell><cell>3.1E3</cell><cell>6.7E4</cell><cell>1.2E4</cell><cell>2.2E3</cell><cell>1.00</cell></row><row><cell>F21</cell><cell>1.0E5</cell><cell>1.0E4</cell><cell>1.2E4</cell><cell>1.2E5</cell><cell>1.2E5</cell><cell>1.1E4</cell><cell>1.2E5</cell><cell>1.3E4</cell><cell>1.3E5</cell><cell>1.1E5</cell><cell>1.1E4</cell><cell>1.00</cell></row><row><cell>F22</cell><cell>76.44</cell><cell>1.00</cell><cell>39.78</cell><cell>76.50</cell><cell>103.35</cell><cell>52.36</cell><cell>92.70</cell><cell>51.58</cell><cell>95.75</cell><cell>65.66</cell><cell>48.53</cell><cell>73.62</cell></row><row><cell>Total</cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>20</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4</head><label>4</label><figDesc>Best normalized optimization results with different crossover.</figDesc><table><row><cell></cell><cell>SKH1</cell><cell>SKH2</cell><cell>SKH3</cell></row><row><cell>F01</cell><cell>1.00</cell><cell>3.60</cell><cell>2.88</cell></row><row><cell>F03</cell><cell>1.00</cell><cell>9.3E4</cell><cell>3.9E4</cell></row><row><cell>F04</cell><cell>1.00</cell><cell>1.01</cell><cell>1.00</cell></row><row><cell>F06</cell><cell>1.80</cell><cell>1.00</cell><cell>1.24</cell></row><row><cell>F07</cell><cell>1.00</cell><cell>11.96</cell><cell>10.11</cell></row><row><cell>F11</cell><cell>9.8E6</cell><cell>76.10</cell><cell>1.00</cell></row><row><cell>F12</cell><cell>1.00</cell><cell>28.28</cell><cell>43.91</cell></row><row><cell>F13</cell><cell>1.00</cell><cell>18.40</cell><cell>17.52</cell></row><row><cell>F14</cell><cell>1.00</cell><cell>2.2E3</cell><cell>1.9E3</cell></row><row><cell>F15</cell><cell>1.00</cell><cell>36.87</cell><cell>35.40</cell></row><row><cell>F16</cell><cell>1.00</cell><cell>15.53</cell><cell>2.96</cell></row><row><cell>F17</cell><cell>1.00</cell><cell>3.51</cell><cell>2.61</cell></row><row><cell>F18</cell><cell>495.07</cell><cell>1.77</cell><cell>1.00</cell></row><row><cell>F19</cell><cell>1.00</cell><cell>162.00</cell><cell>37.00</cell></row><row><cell>Total</cell><cell>11</cell><cell>1</cell><cell>3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5</head><label>5</label><figDesc>Mean normalized optimization results with different crossover.</figDesc><table><row><cell></cell><cell>SKH1</cell><cell>SKH2</cell><cell>SKH3</cell></row><row><cell>F01</cell><cell>1.23</cell><cell>1.14</cell><cell>1.00</cell></row><row><cell>F03</cell><cell>1.00</cell><cell>3.0E4</cell><cell>2.0E4</cell></row><row><cell>F04</cell><cell>3.22</cell><cell>1.77</cell><cell>1.00</cell></row><row><cell>F06</cell><cell>6.30</cell><cell>1.18</cell><cell>1.00</cell></row><row><cell>F07</cell><cell>1.00</cell><cell>3.25</cell><cell>3.40</cell></row><row><cell>F11</cell><cell>2.2E5</cell><cell>39.41</cell><cell>1.00</cell></row><row><cell>F12</cell><cell>1.00</cell><cell>14.38</cell><cell>9.23</cell></row><row><cell>F13</cell><cell>1.00</cell><cell>2.31</cell><cell>2.13</cell></row><row><cell>F14</cell><cell>1.00</cell><cell>938.92</cell><cell>896.62</cell></row><row><cell>F15</cell><cell>1.00</cell><cell>41.02</cell><cell>39.66</cell></row><row><cell>F16</cell><cell>1.00</cell><cell>3.51</cell><cell>1.43</cell></row><row><cell>F17</cell><cell>1.18</cell><cell>1.11</cell><cell>1.00</cell></row><row><cell>F18</cell><cell>132.20</cell><cell>22.42</cell><cell>1.00</cell></row><row><cell>F19</cell><cell>1.00</cell><cell>168.03</cell><cell>54.03</cell></row><row><cell>Total</cell><cell>8</cell><cell>0</cell><cell>6</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>G.-G.Wang  et al. / Neurocomputing 128 (2014) 363-370</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A novel hybrid bat algorithm with harmony search for global numerical optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Appl. Math</title>
		<imprint>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature-Inspired Metaheuristic Algorithms</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Luniver Press</publisher>
			<pubPlace>Frome</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Lévy-flight krill herd algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Probl. Eng</title>
		<imprint>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Parameter estimation of fuzzy neural network controller based on a modified differential evolution</title>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Tsai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="178" to="192" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The system identification and control of Hammerstein system using non-uniform rational B-spline neural network and particle swarm optimization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="216" to="223" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Test-sheet composition using analytic hierarchy process and hybrid metaheuristic algorithm TS/BBO</title>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Probl. Eng</title>
		<imprint>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Talatahari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
		<title level="m">Metaheuristics in Water, Geotechnical and Transport Engineering</title>
		<meeting><address><addrLine>Waltham, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Talatahari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
		<title level="m">Metaheuristic Applications in Structures and Infrastructures</title>
		<meeting><address><addrLine>Waltham, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A powerful and efficient algorithm for numerical function optimization: artificial bee colony (ABC) algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Basturk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="459" to="471" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-stage genetic programming: A new strategy to nonlinear system modeling</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Sci</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="page" from="5227" to="5239" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Ant Colony Optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stutzle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mining financial distress trend data using penalty guided support vector machines based on hybrid of particle swarm optimization and artificial bee colony algorithm</title>
		<author>
			<persName><forename type="first">T.-J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-F</forename><surname>Hsiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Yeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="196" to="206" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Coupled eagle strategy and differential evolution for unconstrained and constrained global optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Talatahari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Math. Appl</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="191" to="200" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Beyer</surname></persName>
		</author>
		<title level="m">The Theory of Evolution Strategies</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bat algorithm: a novel approach for global engineering optimization</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eng. Comput</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="464" to="483" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Path planning for UCAV using bat algorithm with mutation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. World J</title>
		<imprint>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A novel heuristic optimization method: charged system search</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kaveh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Talatahari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Mech</title>
		<imprint>
			<biblScope unit="volume">213</biblScope>
			<biblScope unit="page" from="267" to="289" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Charged system search for optimal design of frame structures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kaveh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Talatahari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="382" to="393" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Biogeography-based optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE. Trans. Evolut. Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="702" to="713" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A new heuristic optimization algorithm: harmony search</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">W</forename><surname>Geem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">V</forename><surname>Loganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Simulation</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="60" to="68" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Novel global harmony search algorithm for unconstrained problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="3308" to="3318" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Cuckoo search algorithm: a metaheuristic approach to solve structural optimization problems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eng. Comput</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="17" to="35" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A hybrid meta-heuristic DE/CS algorithm for UCAV three-dimension path planning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific World Journal</title>
		<imprint>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Neural Networks IEEE</title>
		<meeting>the IEEE International Conference on Neural Networks IEEE<address><addrLine>Perth, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Design optimization of tall steel buildings by a modified particle swarm algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gholizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fattahi</surname></persName>
		</author>
		<idno type="DOI">10.1002/tal.1042</idno>
		<ptr target="http://dx.doi.org/10.1002/tal.1042" />
	</analytic>
	<monogr>
		<title level="j">Struct. Des. Tall Spec</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A multi-stage particle swarm for optimum design of truss structures</title>
		<author>
			<persName><forename type="first">S</forename><surname>Talatahari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kheirollahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Farahmandpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00521-012-1072-5</idno>
		<ptr target="http://dx.doi.org/10.1007/s00521-012-1072-5" />
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1297" to="1309" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A new optimization method: Big Bang-Big Crunch</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">K</forename><surname>Erol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Eksin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Eng. Softw</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="106" to="111" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Size optimization of space trusses using big Bang-Big Crunch algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kaveh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Talatahari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Struct</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="1129" to="1140" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Optimal design of Schwedler and ribbed domes via hybrid Big Bang-Big Crunch algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kaveh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Talatahari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Constr. Steel Res</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="412" to="419" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A discrete big bang-big crunch algorithm for optimal design of skeletal structures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kaveh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Talatahari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Asian J. Civil Eng</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="103" to="122" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Population-Based Incremental Learning: A Method for Integrating Genetic Search Based Function Optimization and Competitive Learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Shumeet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<pubPlace>Pittsburgh, PA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Krill herd: a new bio-inspired optimization algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Nonlinear Sci. Numer. Simul</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="4831" to="4845" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<title level="m">Genetic Algorithms in Search, Optimization and Machine Learning</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A two-stage genetic algorithm for automatic clustering</title>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="49" to="59" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The stud GA: a mini revolution?</title>
		<author>
			<persName><forename type="first">W</forename><surname>Khatib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Parallel Problem Solving from Nature</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Eiben</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Back</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Schwefel</surname></persName>
		</editor>
		<meeting>the 5th International Conference on Parallel Problem Solving from Nature<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="683" to="691" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Performance optimization of gas turbine engine</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V R</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Khatib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engl. Appl. Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="575" to="583" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Evolutionary programming made faster</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE. Trans. Evolut. Comput</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="82" to="102" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Karamanoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm Intelligence and Bio-Inspired Computation</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Elsevier</publisher>
			<pubPlace>Waltham, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Active leading through obstacles using ant-colony algorithm</title>
		<author>
			<persName><forename type="first">R</forename><surname>Vatankhah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Etemadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alasty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-R</forename><surname>Vossoughi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boroushaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="67" to="77" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A hybrid co-evolutionary cultural algorithm based on particle swarm optimization for solving global optimization problems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="76" to="89" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A new improved firefly algorithm for global numerical optimization</title>
		<author>
			<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1166/jctn.2014.3383</idno>
		<ptr target="http://dx.doi.org/10.1166/jctn.2014.3383" />
	</analytic>
	<monogr>
		<title level="j">J. Comput. Theor. Nanosci</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="477" to="485" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Incorporating mutation scheme into krill herd algorithm for global numerical optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00521-012-1304-8</idno>
		<ptr target="http://dx.doi.org/10.1007/s00521-012-1304-8" />
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Hybrid krill herd algorithm with differential evolution for global numerical optimization</title>
		<author>
			<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-S</forename><surname>Hao</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00521-013-1485-9</idno>
		<ptr target="http://dx.doi.org/10.1007/s00521-013-1485-9" />
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
